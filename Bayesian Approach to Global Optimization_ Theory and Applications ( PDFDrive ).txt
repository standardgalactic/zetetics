Bayesian Approach to Global Optimization

Mathematics and Its Applications (Soviet Series)
Managing Editor:
M. HAZEWINKEL
Centre for Mathematics and Computer Science, Amsterdam, The Netherlands
Editorial Board:
A. A. KIRILLOY, MGU, Moscow, U.S.sR.
Yu. I. MANIN, StekiovInstitute ofMathematics, Moscow, U.S.sR.
N. N. MOISEEY, Computing Centre, Academy ofSciences, Moscow, U.s.s.R.
S. P. NOVIKOY, Landau Institute ofTheoretical Physics, Moscow, U.S.S.R.
M. C. POLYVANOY, Steklov Institute ofMathematics, Moscow, U.S.SR.
Yu. A. ROZANOY, Steklov Institute ofMathematics, Moscow, U.S.SR.

Bayesian Approach
to Global Optimization
Theory and Applications
by
Jonas Mockus
Academy of Sciences of the Lithuanian SSR,
Institute ofMathematics and Cybernetics. Vilnius, U.S.S.R.
KLUWER ACADEMIC PUBLISHERS
DORDRECHT / BOSTON / LONDON

Library of Congress Cataloging in Publication Data
Mockus, Jonas.
Bayesian approach to global optimization.
88-27188
2. Bayesian
Title.
II. Series:
(D. Reidel Publishing
(Mathematics and its applications.
Includes index.
1. Mathematical optimisation.
statistical decision theory.
1.
Mathematics and its applications
Company) •
Soviet series.
QA402.S.MS8
1989
519
Soviet series)
ISBN-I3: 978-94-010-6898-7
DOl: 10.1007/978-94-009-0909-0
e-ISBN-13: 978-94-009-0909-0
Published by Kluwer Academic Publishers,
P.O. Box 17, 3300 AA Dordrecht, The Netherlands.
Kluwer Academic Publishers incorporates
the publishing programmes of
D. Reidel, Martinus Nijhoff, Dr W. Junk and MTP Press.
Sold and distributed in the U.S.A. and Canada
by Kluwer Academic Publishers,
101 Philip Drive, Norwell, MA 02061, U.S.A.
In all other countries, sold and distributed
by Kluwer Academic Publishers Group,
P.O. Box 322, 3300 AH Dordrecht, The Netherlands.
All Rights Reserved
© 1989 by Kluwer Academic Publishers
Softcover reprint ofthe hardcover 1st edition 1989
No part of the material protected by this copyright notice may be reproduced or
utilized in any form or by any means, electronic or mechanical
including photocopying, recording or by any information storage and
retrieval system, without written permission from the copyright owner.

SERIES EDITOR'S PREFACE
·Et moi, .... si j'avait su comment en revcnir.
je o'y semis point alle.'
Jules Verne
The series is divergent; therefore we may be
able to do something with it.
O. Heaviside
One service mathematics has rendered the
human race. It has put common sense back
where it beloogs. on the topmost shelf next
to the dusty canister labelled 'discarded non-
sense',
Eric T. BclI
Mathematics is a tool for thought. A highly necessary tool in a world where both feedback and non-
linearities abound. Similarly, all kinds of parts of mathematics serve as tools for other parts and for
other sciences.
Applying a simple rewriting rule to the quote on the right above one finds such statements as:
'One service topology has rendered mathematical physics ...'; 'One service logic has rendered com-
puter science ...'; 'One service category theory has rendered mathematics ...'. All arguably true. And
all statements obtainable this way form part of the raison d'etre of this series.
This series, Mathematics and Its Applications, started in 1977. Now that over one hundred
volumes have appeared it seems opportune to reexamine its scope. At the time I wrote
"Growing specialization and diversification have brought a host of monographs and
textbooks on increasingly specialized topics.
However, the 'tree' of knowledge of
mathematics and related fields does not grow only by putting forth new branches. It
also happens, quite often in fact, that branches which were thought to be completely
disparate are suddenly seen to be related. Further, the kind and level of sophistication
of mathematics applied in various sciences has changed drastically in recent years:
measure theory is used (non-trivially) in regional and theoretical economics; algebraic
geometry interacts with physics; the Minkowsky lemma, coding theory and the structure
of water meet one another in packing and covering theory; quantum fields, crystal
defects and mathematical programming profit from homotopy theory; Lie algebras are
relevant to filtering; and prediction and electrical engineering can use Stein spaces. And
in addition to this there are such new emerging subdisciplines as 'experimental
mathematics', 'CFD', 'completely integrable systems', 'chaos, synergetics and large-scale
order', which are almost impossible to fit into the existing classification schemes. They
draw upon widely different sections of mathematics."
By and large, all this still applies today. It is still true that at first sight mathematics seems rather
fragmented and that to find, see, and exploit the deeper underlying interrelations more effort is
needed and so are books that can help mathematicians and scientists do so. Accordingly MIA will
continue to try to make such books available.
If anything, the description I gave in 1977 is now an understatement. To the examples of
interaction areas one should add string theory where Riemann surfaces, algebraic geometry, modu-
lar functions, knots, quantum field theory, Kac-Moody algebras, monstrous moonshine (and more)
all come together. And to the examples of things which can be usefully applied let me add the topic
'finite geometry'; a combination of words which sounds like it might not even exist, let alone be
applicable. And yet it is being applied: to statistics via designs, to radar/sonar detection arrays (via
finite projective planes), and to bus connections of VLSI chips (via difference sets). There seems to
be no part of (so-called pure) mathematics that is not in immediate danger of being applied. And,
accordingly, the applied mathematician needs to be aware of much more. Besides analysis and
numerics, the traditional workhorses, he may need aU kinds of combinatorics, algebra, probability,
and so on.
In addition, the applied scientist needs to cope increasingly with the nonlinear world and the
v

VI
SERIES EDITOR'S PREFACE
extra mathematical sophistication that this requires.
For that is where the rewards are. Linear
models are honest and a bit sad and depressing: proportional efforts and results. It is in the non-
linear world that infinitesimal inputs may result in macroscopic outputs (or vice versa). To appreci-
ate what I am hinting at: if electronics were linear we would have no fun with transistors and com-
puters; we would have no TV; in fact you would not be reading these lines.
There is also no safety in ignoring such outlandish things as nonstandard analysis, superspace
and anticornmuting integration, p-adic and ultrametric space. All three have applications in both
electrical engineering and physics. Once, complex numbers were equally outlandish, but they fre-
quently proved the shortest path between 'real' results. Similarly, the first two topics named have
already provided a number of 'wormhole' paths. There is no telling where all this is leading -
fortunately.
Thus the original scope of the series, which for various (sound) reasons now comprises five sub-
series: white (Japan), yellow (China), red (USSR), blue (Eastern Europe), and green (everything
else), still applies. It has been enlarged a bit to include books treating of the tools from one subdis-
cipline which are used in others. Thus the series still aims at books dealing with:
- a central concept which plays an important role in several different mathematical and/or
scientific specialization areas;
- new applications of the results and ideas from one area of scientific endeavour into another;
- influences which the results, problems and concepts of one field of enquiry have, and have had,
on the development of another.
Trying to optimize something - if possible everything - is one of the oldest preoccupations of human
kind. It is also one of the oldest parts of mathematics to try to find all kinds of extrema. And cer-
tainly from the applied point of view it is easy to see that this part of mathematics at least ought to
be applicable to virtually everything. And so it is, though it required widespread use of computing
power to really flourish. Relatively easily formulated examples of optimization problems are assign-
ment problems, optimal cooling of steel labs in a rolling mill, optimal design of a road network,
allocation and location problems in economics, and other combinatorial optimization problems.
Less obvious but equally relevant examples are problems in VLSI chip design and databases which
can be formulated as (constrained) global optimization problems (with a quadratic objective func-
tion).
Local optimization is better developed (mathematically) but it is not good enough for these
problems and global optimization requires additional ideas which go beyond calculus and varia-
tional principles. Computing power alone is not nearly enough. Even very simple optimization prob-
lems have a habit of becoming rapidly too large to be handled by routin4: programming. And so,
thanks to computing power, rather than the reverse, a large number of new areas in pure and
applied mathematics carne into being. Global optimization, the topic of this book, is one of them.
More particularly this book is about the Bayesian approach to this large and varied problem; one of
the more successful and promising approaches. Together with the theory there are a large number
of technical and industrial applications and there is also a floppy disc (MS-DOS format; FOR-
TRAN programs) with all the programs so that the reader can test and try out these ideas and pro-
grams on his own optimization problems. No doubt many will do so to experience for themselves
the power (and elegance) of these methods.
Perusing the present volume is not guaranteed to turn you into an instant expert, but it will
help, though perhaps only in the sense of the last quote on the right below.

SERIES EDITOR'S PREFACE
The shonest path between two truths in the
real domain passes
through
the complex
domain.
J. Hadamard
La physique ne nous donne pas seulement
I'occasion de resoudre des problemes ... elle
nous fait pressentir Ia solution.
H. Poincare
Bussum, October 1988
vii
Never lend books, for no one ever returns
them; the only books I have in my library
are books that other folk have lent me.
Anatole France
The function of an expen is not to be more
right than other people, but to be wrong for
more sophisticated reasons.
David Butler
Michie! HazewinkeI

CONfENTS
Series Editor's Preface
Preface
v
xiii
Chapter 1
1.1
1.2
Chapter 2
2.1
2.2
2.3
2.4
2.5
2.6
Chapter 3
3.1
3.2
3.3
3.4
3.5
Chapter 4
4.1
4.2
4.3
4.4
4.5
4.6
Chapter 5
5.1
5.2
5.3
5.4
5.5
Global optimization and the Bayesian approach
What is global optimization?
Advantages of the Bayesian approach to global optimization
The conditions of Bayesian optimality
Introduction
Reduction to dynamic programming equations
The existence of a measurable solution
The calculation of conditional expectations
The one-step approximation
The adaptive Bayesian approach
The axiomatic non-probabilistic justification of Bayesian
optimality conditions
Introduction
The linearity of the loss function
The existence of the unique a priori probability corresponding to
subjective preferences
Optimal method under uncertainty
Nonlinear loss functions
Stochastic models
Introduction
Sufficient convergence conditions
The Gaussian field
Homogeneous Wiener field
A case of noisy observations
Estimation of parameters from dependent observations
Bayesian methods for global optimization in the Gaussian case
The one-step approximation
Adaptive models
Extrapolation models
Maximum likelihood models
The comparison of algorithms
1
1
1
4
4
6
13
14
16
20
22
22
22
25
35
36
39
39
40
65
67
70
72
79
79
82
86
94
96

x
CONTENTS
5.6
The Bayesian approach to global optimization with linear
constraints
107
5.7
The Bayesian approach to global optimization with nonlinear
constraints
109
5.8
The Bayesian approach to multi-objective optimization
110
5.9
Interactive procedures and the Bayesian approach to global
optimization
113
5.10 The reduction of multi-dimensional data
114
5.11 The stopping rules
115
Chapter 6
The analysis of structure and the simplification of the optimization
problems
117
6.1
Introduction
117
6.2
Structural characteristics and the optimization problem
117
6.3
The estimation of structural characteristics
119
6.4
The estimation of a simplification error
121
6.5
Examples of the estimates
121
Chapter 7
The Bayesian approach to local optimization
125
7.1
Introduction
125
7.2
The one-dimensional Bayesian model
125
7.3
Convergence of the local Bayesian algorithm
130
7.4
Generalization of a multi-dimensional case
140
7.5
Convergence in the multi-dimensional case
144
7.6
The local Bayesian algorithm
151
7.7
Results of computer simulation
154
Chapter 8
The application of Bayesian methods
157
8.1
Introduction
157
8.2
The optimization of an electricity meter
157
8.3
The optimization of vibromotors
160
8.4
The optimization of a shock-absorber
164
8.5
The optimization of a magnetic beam deflection system
168
8.6
The optimization of small aperture coupling between a rectangular
waveguide and a microstrip line
171
8.7
The maximization of LSI yield by optimization of parameters
of differential amplifier functional blocks
175
8.8
Optimization of technology to avoid waste in the wet-etching of
printed circuit boards in iron-copper-chloride solutions
179
8.9
The optimization of pigment compounds
181
8.10 The least square estimation of electrochemical adsorption using
observations of the magnitude of electrode impedance
186
8.11 Estimation of parameters of the immunological model
189

CONTENTS
xi
8.12 The optimization of nonstationary queuing systems
191
8.13 The analysis of structure of the Steiner problem
193
8.14 The estimation of decision making by intuition on the example of
the Steiner problem
195
Chapter 9
Portable FORTRAN software for global optimization
197
9.1
Introduction
197
9.2
Parameters
198
9.3
Methods available
200
9.4
Common blocks
201
9.5
The function
201
9.6
The main program
203
9.7
The example of the main program
203
9.8
Description of routines
204
9.9
BAYESl, the global Bayesian method by Mockus
204
9.10 UNT, the global method of extrapolation type by Zilinskas
207
9.11 LPMIN, the global method of uniform search by Sobolj,
Shaltenis and Dzemyda
209
9.12 GLOPT, the global method of clustering type by Tom
212
9.13 MIG l,the global method of Monte Carlo (uniform random search)
214
9.14 MIG2, the modified version of MIG1
216
9.15 EXTR, the global one-dimensional method by Zilinskas
216
9.16 MIVAR4, the local method of variable metrics by Tieshis
219
9.17 REQP, the local method of recursive quadratic programming by
Biggs
221
9.18 FLEXI, the local simplex method by NeIder and Mead
226
9.19 LBAYES, the local Bayesian method by Mockus
229
9.20 ANAL!, the method of analysis by structure by Shaltenis
232
9.21 Portability routines
235
References
237
Index
247
Appendix 1 The software for global optimization for IMB/PC/XT/AT and
compatibles
249
Appendix 2 How the global optimization software can improve the
performance of your CAD system
251
Appendix 3 Machine dependent constants of portable FORTRAN
253
Disc: FORTRAN codes for global optimization
(inside back cover)

Preface
Global optimization is a subject of tremendous potential application. The past two
decades have witnessed increasing efforts in research and application. The result is a
collection of methods and algorithms.
Progress in the computational aspects of
global optimization has been achieved, but it is not however, as impressive as could
have been expected considering the development in power of digital computers and
the vast field of possible applications.
The possible explanation is that in global optimization there exists a wide gap
between theory and applications, between mathematical and heurristic methods.
This book is intended to narrow the gap by means of a new approach to the
development of numerical methods of global optimization. The idea of this approach
is to develop methods of optimization which are the best in the senes of average
deviation from the global minimum. To define the average deviation some a priori
distribution should be fixed. This is a distinctive property of the Bayesian approach.
A balanced coverage of the theory, applications and computations of global
optimization are given.
The general orientation of the presentation is to demonstrate the potential
computational advantages of the Bayesian approach in a manner which may assist
the practitioner in solving problems in real life applications. The corresponding
portable software is included in addition to the theory, the description of methods,
algorithms and a set of practical examples.
The advancement of global optimization promises to expand the use of
optimization methods into new applications, the important examples being the
CAD/CAM systems ad the optimal design of experiments.
Chapter 1 is a brief outline of the main advantages of the Bayesian approach.
Chapter 2 presents a general definition of Bayesian methods of global
optimization.
Chapter 3 gives the axiomatic non-probabilistic justification of the Bayesian
approach by the system of clear and simple assumptions concerning the subjective
preferences.
In Chapter 4 the family of a priori stochastic models which provide the
convergence of Bayesian mehods to the global minimum of any continuous function
is considered.
A Gaussian stochastic model is derived from the conditions of
homogeneity, independence of partial differences and continuity of sample functions.
Chapter 5 provides the expressions for the one-step approximation of the
dynamic programming equations corresponding to the Bayesian methods in the
Gaussian case. This chapter describe one of the most unconventional results of the
book: the new nonclassical stochasitc model, where the usual consistency conditions
of Kolmogorov are replaced by the weaker condition of the risk function continuity.
It gives the posssibility of avoiding the computational difficutlties connected with the
xiii

xiv
PREFACE
inversion of matrices of very high order, which is necessary using the classical
statistical models. The results of the international 'competition' of algorithms of
global optimization are discussed.
Chapter 6 discusses the methods and algorithms of reducing the dimensionality
of the problems of global optimization in a way that minimizes the average deviation
from the true solution.
Chapter 7 provides an example of how the Bayesian approach can be used to
increase the efficiency of the methods of stohastic apporximation to find local minima
of functions with 'noise'.
Chapter 8 describes th application of Bayesian methods in real-life applicationa
of engineering design and experimental planning.
Chapter 9 provides the description of the Portable FORTRAN package for
global optimization, the complete listing of which is given in the Appendix.
In the book only the case of continuous variables is considered becauses, in
this case, the neighbourhood is uniquely defined.
The methods developed for
continuous variables can also be applied to the discrete case if the rounding error can
be regarded as negligible.
I am gratefully indebted to my colleagues of the Optimal Decision Theory
Department of the Institute of Mathematics and Cybernecrics of the Academy of
Sciences of the Lithuanian S.S.R. who contributed to the development and
application of the methods of global optimization.

CHAPTER 1
GLOBAL OPTIMIZATION AND THE BAYESIAN
APPROACH
1.1 What is global optimization?
Any decision problem (with an objective function/to be minimized or maximized)
may be classified as a global optimization problem, if there is no additional
information indicating that there is only one minimum (or maximum). This definition
also includes the case of discrete optimization, when the (quantifiable) decision
variables must assume discrete values. In this book we shall consider only the case
of continuous variables because for the purpose of developing solutions the discrete
optimization problems are better regarded separately.
Global optimization as defined above is not a new mathematical subject. In the
classical textbooks the global optimization problem is usually dismissed by
statements such as: "If there are many minima (or maxima) they should all be
compared". The statement is obviously correct if it is a practical possibility
1) to find any finite number oflocal minima
2) to prove that no more local minima exist.
Such possibilities exist only in some special cases.
Generally we should abandon the hope of finding the exact global minimum
and seek some approximations to it. In such a case the main theoretical and practical
problem is how to define the approximate solutions and how to find them.
1.2
Advantages of the Bayesian approach to global optimzation
Since only an approximation to the global minimum can usually be defined we shall
classify different methods depending on the definition of the deviation from the exact
solution. In this way two main approaches can be formulated. The first one can be
called the worst case analysis, when the deviation for the worst possible condition is
sup !f(x) - /(xo) I
jeF
(1.2.1)

2
CHAPTER 1
Here 1=I(x) E F is the function to be minimized,
x E A cRm is the vector of variables,
A is the feasible set,
!f(x) - I(xo)I is the 'distance' between x and xo,
Xo is the global minimum,
F is the family of functionsf.
The more usual definition of the distance between the points x and xo, namely
IIx -xolileads to confusion if there is more than one global minimum because then the
distance Ilx -xo" is not uniquely defined.
The advantage of definition (1.2.1) is that it gives the exact upper bound of the
error of the method, but it has a disadvantage too, because the expression (1.2.1) can
go to infinity except in special cases such as the Lifshitzian functions I(x). In this
sense it is more convenient to use the second approach and to define the deviation as
an average 'distance' from the global minimum, namely
J(r(x) -I(xo)) P(d/)
F
(1.2.2)
Here P is some a-additive measure which should be fixed a priori. It is convenient to
regard P as a probability measure defined on a family of functions to be minimized by
a given method. The measure P has a similar meaning to the a priori probability in
Bayesian decision theory so the second approach is called the Bayesian approach.
The Bayesian definition of deviation (1.2.2) explains the reason for the wide
application of heuristic methods in global optimization. It almost corresponds to the
usual definition of heuristic methods, as such methods, which work reasonably well
in most real-life applications can, nevertheless, be very bad in some exceptional
cases.
The definition (1.2.2) can serve as a reasonable estimation of the efficiency of
the heuristic procedures and so help to narrow the gap between the heuristic and the
mathematical methods and to develop the efficient methods of global optimization
which are based on clear mathematical assumptions.
The important property of the Bayesian approach is that the Bayesian method
which minimizes the deviation (1.2.2) depends on the a priori distribution P. It is
both the main advantage and the main disadvantage of the Bayesian approach. The
advantage is that we can develop methods in accordance with average properties of
the function to be minimized. The disadvantage is the arbitrariness and uncertainty of
how to fix the a priori distribution P, especially when the function I(x) describes
some unique object and so the probability P cannot be derived from the
corresponding frequencies.

GLOBAL OPTIMIZATION AND THE BAYESIAN APPROACH
3
To decrease the level <;>f uncertainty some conditions are defined such as the
convergence of Bayesian methods to a global minimum of any continuous function.
The convergence conditions narrow the family of feasible a priori distributions. It
can be narrowed even further if some additional conditions are introduced.
For
example, from the conditions of continuity of sample functions, homogeneity of P
and independence of partial differences, it conforms to the Gaussian P with constant
mean I.l. and variance a2 and the covariance between the points x. and XJco
)
m
lxi_Xi,
.
- 2n (1
)
k)
1< '<I
'-1
a'k - a
-
2
,- -x -
, 1-
, ... , m
)
i=l
To justify the application of the probabilities in the cases when we are dealing,
not actually with probability but with uncertainty, the system of clear conditions
about the subjective preferences is given, when there exists a unique a priori density
function corresponding to given subjective preferences.
Any result which narrows the gap between the theory and practice of global
optimization is considered as most important because it is hardly possible to prove the
practical efficiency of methods and algorithms following only theoretical
considerations. It does not seem possible to do it empirically either. So the way
remaining is to use both theoretical and empirical means considering not only the
well-known text book test functions but also real-life examples.
To make theoretical methods computationally feasible, the theoretical models
are formulated in terms of simple and clear basic assumptions. Those assumptions
which make the models more complicated and are not absolutely necessary, are
replaced by more convenient conditions, regardless of their historic importance or
logical elegance.
The important example in this book is the replacement of the
consistency condition of Kolmogorov by the condition of the continuity of the
Bayesian risk function.

CHAPTER 2
THE CONDITIONS OF BAYESIAN OPTIMALITY
2.1.
Introductiun
Denote the objective function which we shall minimize as
f = f(x) = f(x, w),
X EA., w E Do
Suppose thatfis a continuous function of x and measurable function of w,
(2.1.1)
(2.1.2)
Here A is a compact set and Do is a set of indices wcorresponding to all continuous
functions of x E A.
Assume that we can observe (calculate or define by physical experimentiation)
the values off(Xi) at the points xi' The results of the observations will be denoted as
Yi = f(x), i = 1, ... , N
where N is the total number of observations.
Denote the vector of observations as
Zn = (Xi' Yi, i = 1, ... , n).
Define the decision function as
where dn is a mapping of (A x Rt into A.
Denote the sequence of decision function as
Suppose that
4
(2.1.3)
(2.1.4)
(2.1.5)
(2.1.6)

CONDITIONS OF BAYESIAN OPTIMALITY
dn E Dn, n = 0, ... , N
where D n is the set of all measurable mappings of (A x Rt into A and
N
dED=XD.
n=O
n
Assume that the observation points are defined by the decision function d:
5
(2.1.7)
Denote as 0 the loss function which is the deviation from the minimum off(x)
when the sequence of decision functions d is used:
o = oed) = oed, ro) = f(xN+l' ro) -
min f(x, ro).
XEA
(2.1.8)
Here xN+l is the point of the final decision which should be made after all N
observations are completed.
The average deviation Ro(d) (the risk) can be expressed as the Lebesgue
integral:
Ro(d) = E{o(d)} =fo
o(dro) pedro).
Here P is a probability measure defined on Borel sets of Q.
Taking into account (2.1.8)
Ro(d) = f f(xN+l(d), ro) pedro)-f
min f(x, ro) P(d ro).
o
0
XEA
(2.1.9)
(2.1.10)
The decision function d' ED was called, by Mockus (1972), the Bayesian
method if
R(d') = f f(xN+l(d'), ro) pedro) = inf f f(xN+l(d), ro) pedro).
o
deD
0
The condition (2.1.11) minimizes the expected deviation (2.1.10) if
If
min f(x, ro) P(d ro) I < 00
n
XEA
(2.1.11)
(2.1.12)

6
CHAPTER 2
as the second integral in (2.1.10) does not depend on d.
The definition (2.1.11) is more general than that based on the minimization of
the expected deviation (2.1.10) because the condition (2.1.11) can also be applied to
cases when (2.1.12) is violated since the expected minimum is not bounded.
2.2
Reduction to dynamic programming equations
It is convenient to reduce, see Mockus (1969, 1972) the condition (2.1.11) to
recurrent equations of dynamic programming.
Suppose there exists a decision function d" E D satisfying the recurrent
equations
Uo = in! E {ul(x,f(x» }
xeA
(2.2.1)
where E {f(x)/zN} denotes the conditional expectation of the random variablef(x) with
regard to the random vector zN and the n-th equation defines the relation between Xn+l
and zn. thus defining the n-th component of d'~ of the decision function d". The
relation between the Bayesian solution d and d" is shown by the following theorem
of Mockus (1972).
THEOREM 2.2.1. If
E {!f(xN+l(d»I} <
00
for any d E D and there exists the solution d" of(2.2.1) and
d"ED
then d" is the Bayesian method in the sense of(2.1.11).
Proof. Denote
(2.2.2)
(2.2.3)

CONDITIONS OF BAYESIAN OPTIMALITY
By the recurrent substitution
7
(2.2.4)
(2.2.5)
It is well known that under condition (2.2.2) the expression (2.2.5) can be reduced to
(2.2.6)
or using the notation (2.1.7)
(2.2.7)
As the solution of (2.2.4), we shall define a sequence of measurable decision
functions d = (do, ... ,dN) which minimize the conditional expectations with
probability 1
ug = in! E {Ul(x,f(x» }.
xeA
(2.2.8)
In accordance with the conditions of Theorem 2.2.1 there exist such measurable
decision functions
(2.2.9)
which minimize the conditional expectations (with regard to x E A):
E {f(x)/z}

8
E {U~(Zn_l ,x,f(x)lzn_ 1)},
n =N, ... , 2
E {uf(x,f(x))}.
Comparing (2.2.4) and (2.2.8) we can write
d"
d
Uo
SUO'
This means that
d"
. f
d
IlO
= In
UO'
deD
From (2.2.7)
inf U6 =
inf {f(XN+l (d))}.
deD
deD
From (2.2.13) and (2.1.11)
CHAPTER 2
(2.2.10)
(2.2.11)
(2.2.12)
(2.2.13)
Minimization with probability 1 means that the equalities (2.2.8) can be
violated on some subsets of values of vectors Zn and the a priori probability of such
subsets is zero.
We shall suppose that all a priori probability distributions are
absolutely continuous and that the conditional density is uniquely defined by the
usual ratio of the corresponding multidimensional densities.
In such a case the
condition 'with probability l' can be omitted.
EXAMPLE 2.2.1 Suppose that
f(x) = (x-W)2, A = [-1,1], Q = [-1,1], N= 1
and the a priori density function is
pew) = 1/2, WE Q

CONDITIONS OF BAYESIAN OPTIMALITY
then the decision function d" = (d~, .,. , d~) is defined by the equations
Uo = in! E{u(x,f(x))}.
xeA
Here the conditional expectation
{
(x - COl)2,
COl E Q, ~ E- Q
E f!(X)/Zl} =
(x - (02)2,
COl E- Q,
CO2 E Q
1/2(x -
COl)2 + 1/2 (x - CO~2, col E Q,
CO2 E Q
and the decision function
rx l'
COl E Q, ~ E Q
d l (Zl)
~
COl'
COl E Q,
CO2 E Q
l CO2' COl E Q,
CO2 E Q
where
COl = Xl - --J(j(Xl)), ~ = Xl + --J(j(Xl))'
Hence
so
9
E {ul(x,f(x))}
where
Qx = [max (2x - 1, -1), min (2x + 1, 1)]
therefore
d" = ± 1
and

10
Uo = 0.
Thus the point of the first observation is
and the final decision is
CHAPTER 2
r 1 - --1f(l), xj(d") = 1,
x 2 (d ")
i
= l - 1 + --1f(-l), xl(d")
EXAMPLE 2.2.2. The statistical model is
-1.
f(x)
=
X2 + CtlX, A = R, .Q = R, N = 1,
where the a priori density function of the stochastic variable 0) is n(O, 1).
Here n(O, 1) is the Gaussian density function. The expectation is zero and the
standard deviation is 1.
We may observe the stochastic function
<j>(X) = f(x) + 11,
where 11 is an independent stochastic variable - the noise - with the probability density
function n(O, 1).
In this case the conditional expectation is
XXj
E(f(x)/zj} = x2 _ -2-- (<j>(Xj) -xf),
Xl + 1
and the decision function is
hence

CONDITIONS OF BAYESIAN OPTIMALITY
thus
2
X
E{UI(X,<\>(X))} = -1/4
-2-
X + 1
11
The Bayesian decision function dOl does not exist. There exists the E-Bayes
decision function cfo. If E = 1/8, then
If Xl (el) = 1, then the final E-Bayes decision is
X2(el) = 1/4(1 - <\>(1)).
EXAMPLE 2.2.3. Consider the case when
f(x) = Ji(x),
X E Ai'
n
U A. = A,
Aj n Aj
i=l
I
whereJi(x) are independent stochastic functions.
Suppose that there are N observations which should all be uniformly
distributed in on one of the sets Ai' Assume that we know the distribution functions
where the distribution ofSis uniform in Ai'
Then from (2.1.11) the Bayesian decision
d' E
arg min EhoN}
i
corresponding average deviation
R(d') = mi.n Ei{YON} = minr YON do/lYON)'
I
I
_00
Here YON =
min
Yj and o//YON) is a distribution function of the minimum.
l~jgv
In a case of the Gaussian distribution function with parameters Ili' (Ji the
expectation of the best observed value in the set Ai

12
CHAPTER 2
IJ-i - bcri + O(1/ln N)
where
. J
In In N + In 47t - 2(1 - bo)
b = \1(2 In N) - ---:------"-
2.-Je2 In N)
Here bo= 0.5772 ... is the Euler constant.
Neglecting the remainder term O(ln In N/ .-J(ln N) we can write
In a case oflognormal distribution, see Mockus (1967), the expectation
Here r( . ) is a gamma function.
Neglecting the remainder terms
where Ei is the minimum ofNx) in Ai'
If 0::; crj::; .-Je2 In N), then the error of the last formula will not exceed 14%.
The 1ognorma1ity of the distribution function F/y) was noticed by Shaltenis
and Mockus (1963), when the problem of the optimization of multi-stage
development of rural electrical networks was investigated. The same distribution was
observed by Mockus (1964), when the problem of the optimization of electrical
meters was considered. The conditions of asymptotic normality and lognormality of
F/y) were given by Mockus (1964).
There it was assumed thatNx) could be
represented as a sum, or a product, of components which depends on different
variables. Later the conditions were extended by Mockus (1965) to the case where
each of n components fiex) can depend on r =o(nl/3) variables. The proofs were
given by Mockus (1966). Example 2.2.2 was described by Mockus (1963). It was
apparently the first time that the Bayesian approach and a stochastic model of function
f(x) were applied to the problem of global optimization. In the same paper a form of
adaptive Bayesian approach was also used when the parameters of the a priori
distribution F/,y) had to be estimated using some additional observations.
The
adaptive Bayesian approach will be discussed later in 2.6.

CONDITIONS OF BAYESIAN OPTIMALITY
2.3
The existence of a measurable solution
13
The conditions when there exists a measurable solution of the recurrent equation
(2.2.1) were given by Mockus (1978):
THEOREM 2.3.1. If the conditional expectations in the recurrent equations (2.2.1)
are the continuous functions ofx and Zn and A is a compact set, then there exists a
measurable solution d" E Dn of(2.2.1).
Proof Denote
D(z) = arg min 'V(x, z),
xeA
where
'V(x, z) = E{un+l(z, x,f(x)lz)}
and
(2.3.1)
(2.3.2)
Here D(z) is the mapping of (A x Rt into the set of 2A Of all closed subsets of
A cRm .
We shall now prove that under the conditions of Theorem 2.3.1 the function
D(z) is upper semi-continuous.
The multi-valued function D(z) is called upper semi-continuous if from the
conditions
lim i
= i,
k-.~
and
it follows that
(2.3.3)
(2.3.4)
(2.3.5)
(2.3.6)

14
CHAPTER 2
Since \jf is assumed to be a continuous function then from conditions (2.3.3),
(2.3.4 )and (2.3.5) there follows the limit condition (2.3.6). Hence the function D(z)
is upper semi-continuous.
It is well known, see Kuratowski (1968), that if the multi-valued function D(z)
is upper semi-continuous then there exists a selector of class 1, namely a
single-valued function, such that the values d(z) E D(z) and the originals of open sets
are Fa-sets (which consist of closed sets and their countable unions). Since Fa-sets
are Borel sets, see Kuratowski (1966), the function d(z) is a measurable one.
2.4
The calculation of conditional expectations
To solve the equations (2.2.1) we must calculate the conditional expectation with
regard to random vectors
zn =
(Xi, Yi' i = 1, ... , n).
The methods for the calculation of such conditional expectation are well known if the
points of the observations Xi are fixed, but not when the observation points xn+l
depend on zn- However, it will be shown that under some conditions the conditional
expectations in the case of dependent observations xi can be calculated using the
same formulae as in the case when the observations are fixed.
Suppose that there exists a continuous density function
(2.4.1)
Assume that the decision function d'l is continuous almost everywhere and that
(2.4.2)
Then

CONDITIONS OF BAYESIAN OPTIMALITY
15
x P{CO: y! ::; f(x!, CO) < y! + f1 j , Y2 ::; fed !(x!,f(x!, CO),
CO)) < Y2 + f12}
lim
.1c~O (l/(f1! f12))
.12~O
(2.4.3)
where (2.4.3) holds at the continuity points of the decision function d'r. The set of
such points has a probability 1 because the function d'r is continuous almost
everywhere and there exists a density function which is continuous.
A generalization of relation (2.4.3) to the case of an n-dimensional density
function is given by
THEOREM 2.4.1. Suppose that there exists the continuous density function
Assume that the decision functions d~, n = 1, 2, ... are continuous almost
everywhere and that
(2.4.5)
Then

16
lim
t> ~O
(l/(~l' ... , ~n))
••. .1. •••••
t> ~O
n
< Y2 + ~2' ... , Yn ~ j(d' n-l' ... , 00) < Yn + ~n}
CHAPTER 2
(2.4.6)
with probability 1.
The equality (2.4.6) for the n-dimensional case can be proved in
exactly the same way as the equality (2.4.3) for the two-dimensional case.
2.5
The one-step approximation
The solution of recurrent equations (2.2.1) is difficult. So some approximation is
indispensable.
The one-step approximation, see Mockus (1972), when the next
observation is considered as the last one, is simple and natural. In such a case
. f R n-l
. f R n-l
In
x
, Xn E arg In
x
,
xEA
xEA
l~n~N
(2.5.1)
where
R;-l
=: E (inf E (f(V)/Zn_l' x,f(X)} Izn_ 1}.
vEA
(2.5.2)
Assume the existence of the conditional density ofj(v) with regard to zn-l and denote
it by
where Y means a value ofj(v), v E A.
Let
p~(X, y')
Pv(y/Zn-l' x, y'),

CONDITIONS OF BAYESIAN OPTIMALITY
and
17
in! f~
y p~(x, y') dy.
veA
_00
Suppose
Then from (2.5.2)
It follows from assumption (2.5.3) that
= cn_l - fn-l (cn-l - y) Px(y/zn-l) dy .
-~
(2.5.3)
(2.5.4)
(2.5.5)
It was shown by Mockus (1978) that (2.5.1) is asymptotically optimal in the
sense that it converges to a global minimum of any continuous function.
The
convergence conditions will be given later in 4.2. However, when n is not large
enough, the algorithm (2.5.2) tends to seek the minimum in the neighbourhood of the
best point, more or less neglecting the areas where the observed values where not so
good.
This occurs because the influence of the remaining observations n + 2,
n + 3, '" , N is neglected in the equations (2.5.1).
If we want to make the one-step Bayesian method (2.5.1) more'global' and so
more like (2.2.1) we should include the influence of the remaining observations
n + 2, n + 3, ... , N
into the equations (2.5.1).
This can be done as a first
approximation by the substitution of eN for cn in (2.5.5).
(2.5.6)
If the results of the observations can be regarded as independent Gaussian with
expectation Il and variance 0-2, it is reasonable to assume the following equality

18
Then from Kramer (1946)
E{eN} = 11 - mI(2 In N) + O(ln N/1n In N)
and
E{cn } = 11- mI(21n n) + O(..J(ln n) /In In n).
CHAPTER 2
(2.5.7)
(2.5.8)
(2.5.8.1)
Disregarding the remainder temlS in (2.5.8) and (2.5.8.1) EN can be expressed
as
(2.5.9)
Formula (2.5.9) was derived under the assumption of independent observations.
They are actually dependent because they must satisfy (2.5.1). Hence (2.5.9) should
be adjusted to the real data, for example, by multiplication of (2.5.9) by the factor ex
and the addition of the positive number E, i.e.
where ex, E should be evaluated from the results of experimentation.
EXAMPLE 2.5.1. Suppose that it is possible to remember the results of only one
observation and that after each observation we must decide which observation to
remember: an old one or a new one. This is a special case of Bayesian methods with
limited memory considered by Mockus (1972). Denote by xi the point of the old
n
observation (the one which remains after the n-th observation). Denote by xn+ 1 the
point of the new observation. The results of the old and new observations will be
denoted by Yi and Yn+l' respectively.
n
Assume that
inf E fJ(v)/zi } = min (Yi ' 11)
x
n
n
(2.5.10)
where 11 is the a priori expectation and zi = (Xi' Yi)' This assumption is true, for
n
n
n
example, for Gaussian functions/(x) with non-negative correlation which approaches
zero when the distance between the points is large and set A is unbounded.
Denote

CONDITIONS OF BAYESIAN OPTIMALITY
19
(2.5.11)
(2.5.12)
(2.5.13)
Value a = 1 means keep an old observation, value a =0 means keep the new one.
From (2.5.11) and (2.5.12)
U ~-l (Zj
,Zn) = mi n [a min (yj
, Il) + (1 - a) min (Yn' Il)]
n-l
a
n-l
= min (yj
,Yn' Il)·
n-l
(2.5.14)
This means that the best Bayesian decision is to keep the observation with the
minimal observed values.
From (2.5.13) and (2.5.14)
Un_l (Zj
) = in! E {min (Y, Yj
, 1l)/(xj
,Yj
)}.
n-l
x
n-l
n-l
n-l
(2.5.15)
In the case of a homogeneous and isotropic Gaussian function where the
expectation is Il, the standard variance is a2 and the correlation p(x', x") between the
points x' and x" depends only on the distance 1Ix' - x" II
Un_l (Zj
) = in! (..J(2rr.)a0-1 foo
min (Y, Yj
, Il) exp (- 1/2( Y - f..ln )2 )dy
n-l
p
_00
n-l
an
(2.5.16)
where the conditional expectation
(2.5.17)
and the conditional variance

20
CHAPTER 2
(2.5.18)
It follows from (2.5.16) that the optimal Bayesian decision is to keep the
observations with minimal value and to make the next observation on the sphere of
radius rn =P-\Pn) < 00 ifYi
< Il, where Pn minimizes (2.5.16).
n-l
So example 2.5.1 explains, in Bayesian terms, the meaning of the well known
method of random search by Rastrigin (1968).
2.6.
The adaptive Bayesian approach
In the definition of Bayesian optimality (2.1.11) it was assumed that the a priori
probability P is completely known before observations are started. However, it
would be more realistic to assume that at least some parameters eof P are unknown
and can be estimated only on the base of observed values. The distributions G ofe
can also be unclear. This means that the a priori probability P is not fixed and can
change under the influence of the observed results and so
P = Pno n = 0, 1, ... N.
In such a case the condition of the Bayesian optimality
in! f 8(d, (0) Pn(doo), n = 0, 1, ... , N
deD
n
(2.6.1)
(2.6.2)
is not well-defined since Pn depends on n.
A way to give the condition (2.6.2) meaning is the one-step approximation
(2.6.3)
where each component dn of the decision function d is chosen under the assumption
that the distribution Pn will not change later.
The consistency conditions of Kolmogorov for the distributions Pn in a case
(2.6.5), when Pn depends on n, no longer seem necessary since after each n we are,
strictly speaking, considering different stochastic functions which represent different
stochastic models of the functions to be minimized. The change in Pn means that we
are updating the corresponding statistical models on the basis of the results of the
observations.
Some other conditions must be defined to provide consistency of different
statistical models if the conditions of Kolmogorov are omitted. Most natural (in the

CONDITIONS OF BAYESIAN OPTIMALITY
21
Bayesian case) is the condition of continuity of the risk function.
Under this
assumption the much simpler version of the Bayesian method will be developed in
5.2. It will be called the adaptive Bayesian method because it 'adapts'more directly
to the new observed data by changing the statistical models Pn0
The classical
Bayesian approach adapts indirectly to the observed results by means of updating the
a posteriori distributions in the framework of a fixed stochastic model, the so-called a
priori distribution.

CHAPTER 3
THE AXIOMATIC NON-PROBABILISTIC JUSTIFICATION
OF BAYESIAN OPTIMALITY CONDITIONS
3.1
Introduction
A definition of Bayesian optimality (2.1.11) was derived assuming that the following
conditions were satisfied:
3.1.1. An optimal method should minimize the average losses of deviation.
3.1.2. The losses connected with the deviation from the global minimumfo are
a linear function of the difference f(xN+l) -fa, where xN+l is the point of final
decision.
3.1.3. The function to be minimized is a sample of some stochastic function
defined by the a priori probability measure P.
Those conditions will be derived from some simple and clear assumptions later in this
chapter.
3.2
The linearity of the loss function
The losses which occur when the method of optimization d is applied to the sample of
f(x) defined by the index 0:>, will be denoted by l(d, 0:». Then the average losses can
be expressed, see De Groot (1970), by an integral (if it exists) of the loss function
l(d, 0:»
L(d) = L/(d,o:»P(do:».
(3.2.1)
The definition of the best method in the sense of the average deviation (3.2.1)
is correct if the loss function led, 0:» defines such ordering of methods that
d' ~ d"
22
(3.2.2)

AXIOMATIC NON-PROBABILISTIC JUSTIFICATION
if and only if
L(d')
~ L(d").
23
(3.2.2)
The symbol ~ in the expression (3.2.2) means that the method if is at least as
good as the method if'.
The deviation from the global minimum can be defined either in the space of
variables x E Rm or in the space of values of the functionf(x) E R. In the case of the
first definition the loss function /(d, co) would be of m-dimensional argument. The
first definition is also inconvenient when the global minimum is not unique (there
exist several points x E A where the minimal value offix) is attained) because the
distance IIx - xoll from the point of global minimum Xo is not uniquely defined.
Therefore, in this book, the deviation from the global minimum will be defined on the
space of the values of the function f(X).
This has better correspondence to the
meaning of f(x) since we should minimize the objective function f(x) but not the
distance IIx - x 011 ofx from the point of the global minimum xo' In this case the loss
function can be expressed as the function of 8
/(d, co) = 1'(8)
where
8 = 8(d, co) = f(xN+l' co) - f(xo, co) E [0, 00).
Here I' does not depend on d and co when 8 is fixed.
From (3.2.1) and (3.2.4)
L(d) = In [(d, co) P(dco) = I~ 1'(8) P'(d8),
where the probaility measure P' is defined by the equality
P'{8E B}
= P{co:8(d,co)E B}
(3.2.4)
(3.2.5)
(3.2.6)
(3.2.7)
for all Borel sets BE R.
Let us consider the method d E D as the point of the linear space and suppose
that the following assumptions hold:
ASSUMPTION 3.2.8. The set of methods D is convex. This means that if d' E D
and d" E D then ad' + (l - a) d" E D, a E [0, 1].

24
The expression
ad' + (1 - a )d"
CHAPTER 3
can be regarded as a lottery when method d' is used with probability a and method
d" is used with probability (1 - a).
ASSUMPTION 3.2.9. The set D is completely ordered by the relation~. This
means that the relation d' ~ d" or the relation d" ~ d', or both, namely, the relation
-, holds for all d', d" E D.
ASSUMPTION 3.2.10.
The ordering ~ is continuous. This means that the sets
{a : ad' + (1 - a )d" ;::: d''') and {a : d'"
~ ad' + (1 - a )d") are closed for all
d', d", d'"
E D.
ASSUMPTION 3.2.11.
The lotteries composed of indifferent methods are
indifferent. This means that if d', d" E D and d' - d" then for all d'" E D and all
a E [0, 1]
{ad' + (1 - a )d''') - {ad" + (1 - a )d"') .
THEOREM 3.2.1. Suppose that the assumptions 3.2.8 to 3.2.11 hold. Then there
exists a linearfunctional L(d) such thatfor all d', d" E D the relation
d' ~ d"
holds ifand only if
L(d')
:s; L(d").
(3.2.12)
(3.2.13)
If there exists another linear functional L'(d) satisfying conditions (3.2.12) and
(3.2. 13)/or all d', d" ED, then
L'(d) = aL(d) + b
where a > 0.
The proof is given by Herstein and Milnor (1953).
(3.2.14)
The linear functional L(d) in case (3.2.4) and (3.2.5) is defined as an integral

AXIOMATIC NON-PROBABILISTIC JUSTIFICATION
L(d) = (/'(0) P'(do)
25
(3.2.15)
where /' is a linear function of o. This means that the linearity of the loss function
(see condition 3.1.2) follows from assumptions 3.2.8 to 3.2.11 of Theorem 3.2.1
and conditions (3.2.4) and (3.2.5).
3.3
The existence of the unique a priori
probability corresponding to
subjective preferences
The assumption 3.1.3 that the functionf(x) to be minimized is a sample of some
stochastic function is true in some cases of engineering design and planning.
However, the functionf(x) is more often defined by unique conditions which
cannot be repeated in the future. One of the reasons is that the need for the designing
of a new system usu;illy arises only when technological, economic, social and
environmental conditions change.
The apparent impossibility of defining the a priori probability P in the case of
unique, unrepeatable conditions is generally supposed to be the main disadvantage of
the Bayesian approach.
However, it was shown by Katkauskaite and Zilinskas
(1977) that under some assumptions there exists the a priori probability P which
defines average losses L(d) and corresponds to the relation of subjective preferences
~ in the sense that
(3.3.1)
if and only if
(3.3.2)
Let us consider these assumptions.
It is assumed that for a fixed Xj E A,j = 1, ... , I, 1= 1,2, ... a subjective
likelihood relation is defined on the set of events B j where the event B j means that the
vector (((Xl)' ...f(xi») belongs to the I-dimensional interval
i
k
B. = X B.
I
k=1
I
where X denotes the Cartesian product and event Bf means that f(Xk) E Bl.
Here
k
j j '
k'
.
B j = (ak' bk] if bk is finite and B j = (at.. bk)
if it is not.
(3.3.3)
(3.3.4)

26
CHAPTER 3
B j can also be an empty set aI ~ bI, i =1, ... , m, k = 1, ... , l.
In the well known papers (see De Groot (1970), Fine (1973), Savage (1954))
the likelihood relation is usually assumed to be defmed not only on intervals, but also
on an algebra of intervals. This makes the testing of preferences by psychological
experimentation more complicated.
A pair of intervals B j , Bj will be called an s-pair if
aI = a£ andbI = b£, whenk :t:s
aI = a£ or bI = b£' or at =b£ or a£ =bI, when k =s
An s-pair will be called a lower (upper) s-pair if
A set of intervals Bj , i = 1, '" , l will be called an s-system if
ak = a£ and bI = b£ if k :t: s
It is obvious that the union if s-pairs is an interval.
It is assumed that the relation ~ satisfies five conditions:
ASSUMPTION 3.3.5. It is a complete ordering on a set of all intervals B j and an
empty set 0.
ASSUMPTION 3.3.6. If BI n B2 = B3 n B4 = 0, where B I , B2 and B3, B4 are
s-pairs for some s = 1, ." , l, then from B I ~ B 3, B 2 ~ B 4 it follows that
B I u B 2
~ B 3 U B 4• If one of the first two relations is strict >, then the last
relation should be strict>.
ASSUMPTION 3.3.7.
B> 0 iff Il(B) > 0, B u A - B if Il(A) = 0, Il(A) is a
Lebesgue measure of A.
ASSUMPTION 3.3.8. If B 1 > B2 > 0, then for any s = 1, ... , l there exists B3, B4
such that B 3 c B 1, B 4 C B 1, B2 - B 3 - B4, where B 3, B 1 is a lower s-pair, and
B4, B1 is an upper s-pair. Here - denotes the equivalence relation.

AXIOMATIC NON-PROBABILISTIC JUSTIFICATION
ASSUMPTION 3.3.9. If Bi - Ci and Bi n Bj = (0, Cj n Cj = 0, i = j, then
n
n
UB. - Uc.
i=l
I
i=l
I
27
Condition 3.3.5 appears rather clear and natural.
Condition 3.3.6 can be
regarded as an independence from irrelevant events; conditions 3.3.7 and 3.3.8 mean
a sort of continuity of relation~;condition 3.3.9 defines the extension of the relation
~ from intervals to an algebra of intervals.
Suppose Bj,j = I, ... ,k is an s-system such that
BjUBi = 0, j7d
foranypairi ,j = 1, ... ,k.
Denote eventf(xn) E (- 00, 00) as R or B:'.
Let
k
I
i
I
B = U B.
and
B. c X B
= R .
j=l
J
J
i=l
00
Condition 3.3.8 shows that there exist real numbers e}, ... , elk such that
B
RI-l
(
1 ]
1 -
X
- 00, e I ,
and
and so on until
B
- RI- 1 X (e k-l e k]
k
I
,I'
It follows from condition 3.3.9 that there exists such elk that
B - RI- 1 X (- 00, e/].
Then from 3.3.8 it follows that for any s, 1 :s; s :s; I there existse: such that
B - RI- 1 X (- 00, e/],
if Il(RJvJ) > 0
and
B - RI- 1 X (- 00,00) = RI,
if Il(RJvJ) =o.
(3.3.9.1)

28
CHAPTER 3
Condition (3.3.9.1) shows how the relation;::: can be extended from intervals
to finite unions of intervals.
THEOREM 3.3.1. If assumptions 3.3.5 to 3.3.9 hold, then there exists a unique
I-dimensional probability densityfunction
Px
(Yl' ... ,Yl), 1= 1,2, ...
l.···,xl
which corresponds to the subjective likelihood relation in the sense that
ifand only if
where
(3.3.10)
(3.3.11 )
(3.3.12)
(3.3.13)
Proof.
The following seven conditions hold on an algebra of finite unions of
intervals when the relation;::: is extended by equality (3.3.9.1)
3.3.18. B;:::0
3.3.20. Topological space generated by an algebra of intervals has a countable base.
3.3.21. For any finite k and s=1, ... , I there exists an s-system such that i ::;; k < 00
and
I
k
I
k
R --UB
b
., a
= _00,
=
00
j=l
J
S
S

AXIOMATIC NON-PROBABILISTIC JUSTIFICATION
B j and Bj is an s-pair for any i,j = 1, ... , k.
29
Conditions 3.3.15, 3.3.18 and 3.3.19 are the consequences of 3.3.7 and
3.3.9; conditions 3.3.16 and 3.3.17 follow from 3.3.5 and 3.3.9. Condition 3.3.20
is well known (see Kolmogorov and Fomin (1968». Now we shall prove condition
3.3.21. Let us partition R1
where both Bland B2 are finite unions of the intervals.
Then from (3.3.9.1) it
follows that for any s =1, ... , I
k-l
B 1 -
R1- 1 x U
(L{-l, ell andB2 _R1- 1 x (e/-1, e/)
j=l
where e~ = - 00, e: = 00.
From here
k-l
R1 = R1- 1 x U
(L{-1, ell u (e:-1, e/)
j=l
(3.3.22)
This means that condition (3.3.21) is true for any i if there exists a partition of
an interval (- 00, 00) into k, i ::; k < 00 subintervals such that
k-l
(-00,00) =
U
(ci-l,dl u(ek-l,ek)
j=l
where cO = _~, ek = 00
'-1'
"+1·
(d ,dl - (d, d
], ) = 1, ... , k - 2
(3.3.23)
We begin the proof of (3.3.23) by showing that for each interval (a, bl there exists a
partition of (- 00, 00) such that
k-1
(- 00, 00) = U (d-1, dl u (ek- 1, ek), k < 00, cO = _ 00, ek = 00
j=l
(3.3.23.1)

30
(d-I, d] -
(a, b], ) = 1, ... , k - 1
CHAPlER 3
(3.3.23.2)
(3.3.23.3)
Since (a, b] -< (- 00,00), then from 3.3.8 it follows that there exists cl such that
(-00, cl ) - (a, b]. If (c l , 00) ~ (a, b], then k = 2 and the proof of (3.3.23) is
completed. Otherwise, there exists c2 such that (cl , c2] - (a, b], etc.
Suppose that d is an infinite sequence. Let d ~ Co < 00. (The case d ~ 00
can be considered in a similar way).
From 3.3.8 it follows that there exists
c, - 00 < c < co' such that (c, co]-(a, b].
Since (d-l , d] - (a, b] for each), then (d-I, d+l ] >- (a, b].
Nevertheless the convergence of d to Co gives the inequality c < d < Co for
) ~ L and some L. Consequently (cf, cf-3] C (c, co] and (cf, cf+2] >- (c, co]. The
contradiction proves (3.3.23).
Let i be given, and (aI, bl] be an arbitrary finite interval. Let (- 00, 00) be
partitioned into subintervals in accordance with (3.3.23), (3.3.23.1) and (3.3.23.2)
with (a!, bl]. If the number of subintervals kl is greater than i, it is the desired
result. Otherwise consider the intervals (aI, dl], (dl, bl] where dl = (al + bl)/2.
We denote the interval which is minimal in the sense of the likelihood relation by
(a2, b2] and let (- 00,00) be partitioned once more by (3.3.23) for (a2, b2]. Now the
number of subintervals will be k2 > 2kl , if k2 ~ i, then the proof is completed. If it
is not then consider the intervals (a2, d2], (d2, b2] where d2 = (a2 + b2)/2 etc. After
a finite number of such steps we shall achieve the appropriate partition.
Since the relation ~ corresponds to the conditions (3.3.15) to (3.3.21) then it
follows, see Fine (1973), that there exists the unique function P, defined on finite
unions of the intervals Bi C Rm such that
1)
PCb)~
~ PCB) iff B) ~ Bi,
(3.3.24)
2) peRl) = 1, P(0) = 0,
k
k
P ( U
B.) = L P(B. )
i=l
I
i=l
I
(3.3.25)
(3.3.26)

AXIOMATIC NON-PROBABILISTIC JUSTlFICATION
31
It follows from 3.3.21 that P(B) is continuous in the sense that if Bj
:::> Bj _1
and (l B. = 0
then
j=l
j
~imP(B) = O.
j"""""
Suppose on the contrary
~im P(Bj ) = e > O.
j"""""
(3.3.27)
Then from 3.3.21 it follows that there exists an m-system Aj •j = 1, ... , k such that
k
Rm = U
A,
i=l
I
and
P(A ,) < E/2.
I
We can have an equivalent representation of Ai such that
since
We can also have an equivalent representation ofBj
From here and from the assumption that Bj :::> Bj _1 and (l B, = 0
it follows that
j=l
j
Then
lim hi-I = lim bi
j...."""
j...."""
and there exist M and j such that
(hi-I bl']
(i-I
i]
. > M
VI'
C
al ,ai' 1 _
.
(3.3.28)

32
However
CHAPTER 3
(3.3.29)
which contradicts (3.3.28).
It is well known that from the continuity of P, condition (3.3.27), and
conditions (3.3.24) to (3.3.26) it follows that there exists a unique expansion of P to
a Borel field, see Neveu (1969).
Condition 3.3.7 means that P is absolutely
continuous with respect to the Lebesgue measure, and so there exists the unique
I-dimensional probability density function corresponding to the relation ~.
The theorem similar to Theorem 3.3.1 was proved by Katkauskaite and
Zilinskas (1977). The difference lies in the formulation of the extension assumption.
Katkauskaite and Zilinskas (1977) assumed the condition (3.3.9.1) instead of
(3.3.9).
Theorem 3.3.1 does not say anything about the consistency of I-dimensional
density functions in Kolmogorov's sense. Theorem 3.3.1 was formulated in such a
way because it was shown in section 2.6 that the consistency is not necessary when a
priori distributions depend on n, because then we have not one stochastic function
but many.
If we wish to regard the function f(x) as a sample path of some stochastic
function, then it is necessary to set some additional consistency conditions.
Here: B:,+l = (- 00,00).
Here: lid = {I, ... , n}.
THEOREM 3.3.2. If the relation ~ satisfies conditions 3.3.30 and 3.3.31 then the
functions
PXl' ... ,x/(y!> ... , y/), I = 1,2, ... defined in Theorem 3.3.1 are a
consistentfamity ofI-dimensional probability density functions.
COROLLARY 3.3.3. If assumptions 3.3.5 to 3.3.9 and 3.3.30 and 3.3.31 hold,
then there exists a stochastic function, finite dimensional distributions of which
correspond to the relation
~.

AXIOMATIC NON-PROBABILISTIC JUSTIFICATION
33
Corollary 3.3.3 means that the function/(x) can be regarded as a sample path
of some stochastic function defined by a consistent family of i-dimensional
distribution functions (3.3.10) and (3.3.13).
The proof of Theorem 3.3.2 was given by Zilinskas (1978) for the
one-dimensional case A E R and with a slightly different formulation of condition
(3.3.9).
The extension to the multi-dimensional case A E Rm was done by Katkauskaite
and Zilinskas (1977) using the same framework of proof as in the one-dimensional
case.
EXAMPLE 3.3.1. Complete indifference.
Suppose that we have no preference for any B j• This means that
B· - B
for all non-empty B· B·
I
J
I'
r
This assumption violates the last part of condition 3.3.6.
Suppose that
(3.3.34)
BIn B 2 =B 3 n B4 =0, B l' B 2, B 4 "" 0, B3 =0, and B 1 U B 2 is an
interval.
Then from (3.3.14)
and from (3.3.7)
Then from the last part of condition 3.3.6 it follows that
Since B3 is an empty set, B3 u B4 = B4 and B1 U B2 >B4, which contradicts the
assumption (3.3.34).
EXAMPLE 3.3.2. Complete uniformity.
Suppose that

34
CHAPTER 3
where
v(Bj) = hj - aj ,
v(0) = o.
Denote
B1 = (- 00, a]
B2 = (a, 00)
B3 = (- 00, 00)
Here
B 1 (I B2 = B3 (I B4 = 0,
B1 - B3
because v(B1) = 00, v(B3) = 00 and B2 > B4.
It follows that
Relation (3.3.6) violates the last part of the condition (3.3.6).
EXAMPLE 3.3.3. Regional Uniformity.
(3.3.36)
Suppose that condition (3.3.15) holds for B j c
B, where B c R1 , for example
B = (0, It
Here all the conditions hold and there exists the unique a priori
probability density

AXIOMATIC NON-PROBABILISTIC JUSTIFICATION
35
where
(3.3.37)
(3.3.38)
The sample paths of the stochastic functionf(x) corresponding to (3.3.37) and
(3.3.38) are very irregular and not necessarily measurable as functions of x.
3.4
Optimal method under uncertainty
Sometimes it is convenient to regard the problem of optimization as a problem of
decision making under uncertainty, see De Groot (1962).
ASSUMPTION 3.4.1. For any fixed ro e n the relation d ~ dot holds if and only if
(3.4.1)
where xN+1(d) is the final decision achieved by the application of method d.
THEOREM 3.4.1.
If the assumptions 3.2.8 to 3.2.11, 3.3.5 to 3.3.9 and 3.4.1
hold, then the problem of optimization under uncertainty can be reduced to the
problem ofBayesian optimization, in a sense that
d'
~
dot
ifand only if
L(d') $ L(d')
where
(3.4.2)
(3.4.3)
and xN+l(d) is the final decision achieved by the application ofmethod d and P is a
probability measure.

36
CHAPTER 3
Proof. It follows from Theorem 3.2.1 and assumptions 3.4.1 and 3.2.8 to 3.2.11
that there exists a linear functional L(c£) such that
d'
~ d", iff L(d')
:::; L(d")
(3.4.4)
The existence of the corresponding P follows from Theorem 3.3.1 and assumptions
3.3.5 to 3.3.9.
Theorem 3.4.1 means that in case of uncertainty the optimal method should
minimize the average deviation (condition 3.1.1).
3.5
Non-linear loss functions
In some methods of global optimization based on stochastic models losses are
represented as a step function
ICy)
ICy) = ICy - Yo),
where
r0, y < 0,
= 11, Y ~ 0,
y = f(xN+l (c£), ro),
and
Yo is some fixed critical level.
(3.5.1)
Such loss functions are used by Kushner (1964), Strongin (1978) and
Zilinskas (1982).The following conditions were assumed by Zilinskas (1980) to
justify the use of a step function (3.5.1).
ASSUMPTION 3.5.1. The Gaussian conditional density functions with conditional
mean 11 and conditional variance a2 are completely ordered by the preference relation
defined on a set of pairs (11, a).
Let Yo be a desirable level of the objective functionf(x).
ASSUMPTION 3.5.2. When 11' < 11", 11" > Yo, a' > 0 then there exists a such that
the relation
(11', a') > (11", a")

AXIOMATIC NON-PROBABILISTIC JUSTIFICATION
is true, if a" S; a.
ASSUMPTION 3.5.3. When
11" > Yo
then the relation
(11', a') > (11", 0)
is true for any 11' and a' > O.
ASSUMPTION 3.5.4. There exists 11', (yo < 11' < 11") such that
(11', a') > (11", a")
for any a' > 0, 11" > Yo' a" 2: O.
ASSUMPTION 3.5.5. The loss function l(y, Yo) is continuous from the left.
37
Assumption 3.5.2 means that the larger mean will not be preferred if the
variance is not large enough. Assumption 3.5.3 means that if the mean with zero
variance exceeds the desirable level Yo it will not be preferred.
THEOREM 3.5.1.
The unique (to the scale factor) loss function satisfying
assumptions 3.5.1 to 3.5.5 is a step function
l(y, Yo) = I(y - Yo)
where
r 0, if Y S; Yo'
I(y-yO> =
~ll, if Y > Yo
(11', a') > (11", a")
ifand only if
(3.5.6)

38
r l(y, YO) n(y Ill', cr') dy
< J00
l(y, YO) n(y Ill", cr") dy.
_00
_
00
CHAPTER 3
Here n(y Ill, cr) means Gaussian density function with mean 11 and variance cr.
The proof of Theorer;n 3.5.1 is given by Zilinskas (1985).
Let us test the compatibility of assumption 3.5.4 with the condition of
continuity of relation> in the sense that for any ~ > 0 there exists a(~) > 0 such that
and
(11" -
a(~), cr') -
(11", cr' + ~),
(11" - a', cr') > (11", cr' + ~), if a' > a(~),
(11" - a", cr') -< (11", cr' + ~), if a" < a(~).
(3.5.7)
(3.5.8)
(3.5.9)
The continuity conditions (3.5.7) to (3.5.9) mean that if a(~) < 11" - Yo then
assumption 3.5.4 is compatible with the continuity of relation> but if a(~) ~ 11" - Yo
then it is not compatible.
Supposing that a(~) is an unbounded increasing function of ~ it follows that
assumption 3.5.4 contradicts the continuity of relation> if ~ is sufficiently large and
consequently a(~) ~ 11" - Yo.
The author prefers the continuity of relation>, so in this book, the linear loss
function is used to define the Bayesian methods.

CHAPTER 4
STOCHASTIC MODELS
4.1
Introduction
The convenient way to define the method of optimization which minimizes the
average deviation is to design the stochastic model of the function j(x). In many
cases the functionj(x) is determined by unique conditions which will not be repeated
and so cannot be regarded as a stochastic function in the classical sense.
Nevertheless such functions can be considered in the framework of some stochastic
model if the conditions are satisfied concerning the relations of subjective likelihood.
In the previous chapter the conditions were given for the case when there exists a
family of finite-dimensional distribution functions which correspond to the relations
of subjective likelihood.
If in addition the consistency conditions of Kolmogorov also hold, then the
objective function can be regarded as a sample of some stochastic function. If not,
then it can still be considered as a sample which is common for a sequence of
different stochastic functions which can depend on the observed data and are defined
by the corresponding sequence of finite-dimensional distribution functions, not
necessarily consistent in the Kolmogorov sense.
The classical consistent stochastic model is more convenient for theoretical
consideration because such important properties as continuity of sample functions can
be defined by simple and clear conditions, see for example section 4.4.
Unfortunately, the calculation of conditional probabilities in non-independent cases
requires some inversion and multiplication of matrices of order N which is possible
only if the number of observations N is not too large.
Otherwise the Kolmogorov
consistency should be changed to some weaker conditions, which also provide a sort
of consistency of the statistical model but are simpler for computation, see section
5.2.
In this chapter mainly classical models will be considered.
An important problem is that in some cases it can be impossible to define the
valuesj(x) directly because only the sum
h(x) = j(x) + g(x)
can be observed. This will be called the case with noise
39

40
g(x) = g(X, ro).
CHAPTER 4
Here the noise g(x) is supposed to be a stochastic function independent of!(x) with
zero expectation and bounded variance.
If the expectation of the noise g(x) is
known, but not zero, then the problem can be easily reduced to the zero noise one.
However if the expectation of the noise g(x) is unknown, its influence cannot be
eliminated and the minimization of!(x) becomes meaningless in that sense.
4.2
Sufficient convergence conditions
In most practical applications the a priori distribution P cannot be precisely defined.
Thus it would be very desirable to define a family of a priori distributions such that
the Bayesian methods would converge to a global minimum of any continuous
function. In this book we shall restrict ourselves to one-step Bayesian methods. We
shall also consider the case when the value of!(x) cannot be directly defined, i.e.
when only the sum h(x) = !(x) + g(x) can be observed, where g(x) is noise.
Let us define 'the sets
n; = (ro:!(Xi'ro) < si,i=I,
,/}
~ = (ro:g(xi'ro) < vi,i=I,
,l}
n;
(ro: h(xi' ro) < Yi, i = 1, ... , l}
I = 1,2, ...
(4.2.1)
Here Xi are fixed points from A, not necessarily the observation points. It is
assumed that probabilities P of the sets Q;, Q!, Qj are defmed by the I-dimensional
distribution function F
P-x
x (SI'''' , SI) = P{Qs
/ }
I' ... , I
P..x
x (VI' •.. , VI)
I' ... , I
(4.2.2)
Assume that there exist the corresponding probability density functions

STOCHASTIC MODELS
IYx1..... Xl (Yl' ". ,Yr)·
The conditional probability density with regard to the vector
Zn
=:
(Xj,Yj, i =: 1, .., , n)
will be denoted
41
(4.2.3)
(4.2.4)
(4.2.5)
and defined uniquely as the usual relation of corresponding multi-dimensional
probability density functions.
The conditional expectation can be expressed as
(4.2.6)
and the conditional variance as
The minimal observed value will be denoted as
Yo
=:
min y..
n
l$j$n
I
The minimum of/ex)
So
=: min lex)
xeA
The conditional distribution of/ex)
and the limit
(4.2.7)
(4.2.8)
(4.2.9)
(4.2.10)
F;
=: F~(s)
lim FS(s).
n.......
x
(4.2.11)

42
It is supposed that (4.2.11) holds at the continuity points of F;(s).
Denote the real function of the parameters a, b, C by
<I> = <l>n = <I>(a, b, c),
CHAPTER 4
(4.2.12)
where
C = cn E R.
(4.2.13)
(4.2.14)
(4.2.15)
The upper and the lower indices n, x are present in some expressions of <1>, a,
b, C to emphasise that the function <I> and the parameters a, b, C can depend on n and
x.
These indices will sometimes be omitted to make the expressions less
complicated. The point of the minimum of <l>n will be denoted as
Xn+l E arg min
<jl(~, b;, cn)'
xeA
(4.2.16)
The distance from any fIxed x E A to the nearest observation will be denoted as
(4.2.17)
Here i(x) is the index of the nearest observation.
Set A will be divided into two parts Band C by the following conditions
and
C
= {x' lim r (x) = E> o}
t
•
~~ ...
n
C = UC
DO
E
(4.2.18)
(4.2.19)
(4.2.20)
The condition (4.2.18) means that if n ~ 00 then at least one observation will
be in the neighbourhood of x. The conditions (4.2.19) and (4.2.20) mean that there
exists such a neighbourhood of x which does not contain any observation
independently of how many of them are made.

STOCHASTIC MODELS
We shall consider a case without noise
g(x) = °
and a case with noise
g(x) '# 0, E (g(x)} = 0, var (g(x)}
:s;; g <
00.
43
(4.2.21)
(4.2.22)
Since the same assumptions and notations will be considered in different
lemmas and theorems it seems more convenient to set them out and to number all of
them from the start and to use the reference numbers in what follows.
4.2.23
Assume/is a continuous function ofx e A and a measurable function
of 0>.
4.2.24
Assume setA e Rn is closed and bounded.
4.2.25
Denotea~ = J..l~, where
J..l~ is from (4.2.6).
4.2.25a Assume J..l~ is a continuous function ofx.
4.2.26
Denoteb~= a~, where a; is from (4.2.7).
4.2.26a Denote cn = min J..l;.
xeA
4.2.26b Assume min
J..l:
= YOn where YOn is from (4.2.8).
xeA
4.2.26
C Assume a~ is a continuous function of x.
4.2.27
Assume there exists a limit ~~~ a~ = a~ e R.
4.2.28
Assume there exists a limit ~~~ b: = b~ e R.
4.2.29
Assume there exists a limit
~~~ cn =Co e R.
4.2.29a Assume there exists a limit ~~ F:(s) = ~(s) in the sense of
(4.2.11) where F~(s) is a distribution function.

44
CHAPlER4
4.2.30
Assume b2= 0, if x E B, where B is defined by (4.2.18).
4.2.31
Assume b2> 0, if x E C, where C is defined by (4.2.20).
4.2.32
Assume there exists a conditional probability density Px' Px > 0,
if bx > O.
4.2.33
Assume F;(s) is a continuous function of Il~, (J~ at the continuity
points of F2(s).
4.2.34
Assume suplmin (cn, s)1 is uniformly integrable with respect to
n
P;(s).
4.2.35
Denote <!>(ax' bx' c) = (00 min (s, c) dFx(s).
4.2.36
Assume a limit of 11; when n ~ 00 is Il~ = f(x) uniformly on x E B.
4.2.36a Assume Yi = f(x) (this means zero noise).
4.2.37
Assume <!>(a', b', c) > <!>(a", b", c) if b" > 0, b' = O.
4.2.37a Assume thatf(s) is a continuous function of a, b, c.
4.2.37b Assume that <!> is a lower semicontinuous function of x E A.
LEMMA 4.2.1.
Assume conditions (4.2.27) to (4.2.31), (4.2.37) and (4.2.37a)
hold (with the exception of(4.2.29a». Then
(4.2.38)
where X"E C, X'E B.
Proof. From the continuity of <!> (conditions (4.2.37a» and conditions (4.2.27) to
(4.2.29) it follows that condition (4.2.38) is equivalent to the condition
(4.2.39)

STOCHASTIC MODELS
45
The inequality (4.2.39) follows directly from conditions (4.2.27) to (4.2.31)
and (4.2.37) (with the exception of (4.2.29a)).
LEMMA 4.2.2. Suppose the conditions ofLemma 4.2.1 hold and there exists
*
X
E argmin
<1>.
xeA
Then
C =0.
Proof Assume that there exists x" E C. Then from (4.2.31) it follows that b2-. > O.
From (4.2.30) it follows that b~ = 0 for all x E B. The meaning of (4.2.38) is that
there exists € > 0 and nc such that
(4.2.40)
if n > nc' x' E B, x" E C.
Hence from the definitions (4.2.16) and the assumption (4.2.39a) there follows
the existence of n such that
Xn+lE B.
This means that
Xn+l E A'B = C
which contradicts the definition (4.2.20) of set C.
LEMMA 4.2.3.
Suppose that the conditions (4.2.25), (4.2.26), (4.2.26a) and
(4.2.27) to (4.2.32) hold. Then the function defined by (4.2.35) corresponds to the
condition (4.2.37).
Proof.
From Chebyshev's inequality and conditions (4.2.25), (4.2.26), (4.2.27)
and (4.2.28) it follows that for k > 0
or

46
and
Since Fx is a distribution function
CHAPTER 4
(4.2.41)
(4.2.42)
(4.2.43)
In the case where b; 4
0 and a; 4
a~ from conditions (4.2.29a) and (4.2.41)
to (4.2.43) it follows that
o
f 0, if s< a~
F (s) = l
x
•
>
0
1, Ifs_ax
(4.2.44)
In the case where x E B from conditions (4.2.29), (4.2.30), (4.2.35) and
(4.2.44) it follows that
Hence in accordance with (4.2.26a) it follows that
<!>(~ 0, co) = co' if x E B.
Ifx E C, then in accordance with (4.2.31) the limit value
b~ > O.
Using assumption (4.2.32) the function (4.2.35) can be expressed as
o
0
Je
<!>(ax, bx' co) = c -
(c - s) Px ds.
_00
(4.2.45)
(4.2.46)
(4.2.47)
(4.2.48)
Within the bounds of integration the difference c - s > 0 and, in accordance
with assumption (4.2.32), the probability density Px > 0, hence
(4.2.49)

STOCHASTIC MODELS
47
Under the assumptions (4.2.30) and (4.2.31) from the equalities (4.2.46) and
(4.2.49) it follows that the function defined by (4.2.35) corresponds to the condition
(4.2.37).
Define the real function In(s), here n = 1,2, ... and s E R.
Let
l(s) = sup Iln(s)1
n
and
Suppose that
l(s) is uniformly integrable with respect to pn(s).
Assume that
where In(s) is continuous in the interval [- d, d].
(4.2.52)
(4.2.53)
(4.2.54)
LEMMA 4.2.4. Suppose conditions (4.2.29a), (4.2.53) and (4.2.54) hold. Then
~~~r
In(s) dpn(s) =r
lo(s) dpO(s).
_00
_00
Proof. It is obvious that
where
and
o~ = Ir
lo(s) dr(s) -r
In(s) dr(s) I
_00
_00
(4.2.55)
(4.2.56)

48
CHAPTER 4
From conditions (4.2.53), (4.2.54) and the convergence theorem of Loev
(1960) it follows that
o~ < e, if n > ~ .
From the condition (4.2.54) it follows that
Ilo(s) -In(s) I < e for all s E [- d, d]
(4.2.57)
(4.2.58)
if n > n ~ '.
From condition (4.2.53) and the convergence theorem of Loev (1960) it
follows that
J
In(s) dr(s) < e, if n > n~" and d ~ dc, where de ~ 00 when e ~ O.
Isl>d
(4.2.59)
From the condition (4.2.58)
(4.2.60)
From conditions (4.2.57), (4.2.59) and (4.2.60) it follows that
(4.2.61)
where
ne = max (~, n;.',
n~").
Condition (4.2.55) follows from conditions (4.2.56) and (4.2.61).
LEMMA 4.2.5. Suppose the conditions (4.2.33) and (4.2.34) hold. Then <1> defined
by (4.2.35) is a continuous function ofa, b, c.
Proof Let
In(s) = min (s, cJ.
Hence in accordance with (4.2.35) we have
<1>(a, b, c) =r
In(s) dP;(s).
_00
(4.2.62)

STOCHASTIC MODELS
From condition (4.2.33) it follows that
~~~ F;(s)
lim
F;(s) = P;(s)
n
0
J.1xn~J.1x
d' ~(l0
x
x
where the equality (4.2.63) holds at the continuity points of F2(s).
From conditions (4.2.52) and (4.2.62) it follows that
l(s) = sup1ln(s)1 = suplrnin (s, cJI
n
n
49
(4.2.63)
(4.2.64)
Hence (4.2.53) follows from (4.2.34).
It is obvious that In(s) defined by (4.2.62) is a continuous function.
Since
condition (4.2.54) holds (4.2.29a) follows directly from (4.2.63).
So all the conditions of Lemma 4.2.4 hold. This means that the expression
(4.2.55) is true and <l> is a continuous function.
LEMMA 4.2.6.
Suppose that conditions (4.2.24), (4.2.25), (4.2.26), (4.2.26a),
(4.2.26b) and (4.2.27) to (4.2.35) hold. Assume that either (25a), (26
C
) or (37b) is
true. Then
C = 0.
(4.2.65)
Proof.
In accordance with Lemma 4.2.2 the condition (4.2.65) is true if the
conditions (4.2.27) to (4.2.31) hold and function
<l> corresponds to (4.2.37),
(4.2.37a) and 4.2.39a). In accordance with Lemma 4.2.5 the condition (4.2.37a)
follows from
(4.2.33) to (4.2.35). Condition (4.2.37) follows from Lemma 4.2.3
and conditions (4.2.25), (4.2.26), (4.2.26a) and (4.2.27) to (4.2.32). The existence
of min
<l> (condition (4.2.39a ) follows from (4.2.24), (4.2.25a), (4.2.26
C
) and
xeA
(4.2.37a), otherwise it follows from (4.2.24) and (4.2.37b).
LEMMA 4.2.7. Suppose condition (4.2.36a) holds and the point offinal decision is
.
n
xOn E arg mIn Ilx •
xeA
Then under the conditions ofLemma 4.2.6
(4.2.66)

50
lim c
- s
:11.....
n -
0
for all continuousfunctionsf(x) where So is the minimum off(x).
Proof. From conditions (4.2.25), (4.2.26b) and (4.2.36
Q
) it follows that
arg min a;
= arg ~ f(x) .
xeA
1$1~
Hence expression (4.2.66) can be represented as
X On
E arg min f(x.)
l$i$n
I
CHAPTER 4
(4.2.68)
(4.2.69)
From the definition (4.2.20) of C and Lemma 4.2.6 it follows that the distance
to the nearest observation rn(x) ~ 0 when n ~ 00 for any x E A.
Hence (4.2.68) is true for any continuous function because (4.2.26a) and
(4.2.69) hold.
LEMMA 4.2.8. Suppose the assumptions ofLemma 4.2.6 and conditions (4.2.36)
hold. Then
lim c
= s
=
n.~'"
n
0
min f(x)
xeA
(4.2.70)
for any continuous function f(x).
Proof. From C =12' (Lemma 4.2.6) and from definitions (4.2.18) to (4.2.20) it
follows that
B = A.
From this equality and assumption (4.2.36) it follows that
lim sup II.t - f(x)I = O.
x
n~oo xeA
Hence for any e > 0 there exists an integer nc such that
sup
11l~ - f(x) I < e if n > nco
xeA
(4.2.71)
(4.2.72)

STOCHASTIC MODELS
Hence
\ inf Iln -
minf(x)\ < E if n > n .
xeA
x
xeA
E
From (4.2.73), condition (4.2.70) follows directly.
Under conditions (4.2.26
Q ), (4.2.26") and 4.2.36a)
c
= min Il
n
=
min f(x') = Yo
n
xeA
x
1~i~n
I
n
and
Cn+1 = min (YOn' y)
51
(4.2.73)
(4.2.74)
where YOn is minimal from n observations and y is the result of the (n + l)-th
observation. Then from (2.5.1) and (2.5.5) the one-step Bayesian method is
arg min E{c
l/z 1
n+
n
xeA
(4.2.75)
where E{cn+1/znl is the conditional expectation of cn+1 with regard to zn' From
(4.2.24) and (4.2.36a) it follows that
X
1 e
arg min r min (YOn' y)p: dy
n+
xeA-~
Now let us consider the case without noise when g =0 and (4.2.36a) holds.
(4.2.76)
THEOREM 4.2.9. Suppose that conditions ofLemma 4.2.6. and the assumption
(4.2.36a) hold. Then the Bayesian method (4.2.75) converges to the minimum of
any continuousfunction in the sense that
(4.2.77)
Proof. Theorem 4.2.9 follows from Lemma 4.2.7 since the expression (4.2.76) is a
special case of (4.2.35).
When the error is present (g 'f. 0) then, strictly speaking, the formula (4.2.76)
cannot be regarded as the Bayesian method (4.2.75) because cn+1 = min (Yon> y )

52
CHAPTER 4
only when cn = YOn andf(xn+l) = y, and that is not true in the case with noise. In
this case it would be more natural to substitute cn for YOn in the expression (4.2.76)
and to define the one-step Bayesian method as
X
1 E arg min r min (cn, s) p~ ds.
n+
xeA- OO
(4.2.79)
In the presence of noise we have not only the a priori probability P which is
defined on the space of continuous functions f(x, CD) to be minimised, but also the
probability P' defined on the space of noise functions g(x, CD). In such a case
condition (4.2.36) could be reasonably expected to hold only with some probability
P'.
THEOREM 4.2.10. Suppose that the conditions of Lemma 4.2.6 hold. Assume
that condition (4.2.36) holds with probability P'. Then the Bayesian method
(4.2.79) converges to the minimum of any continuous function in the sense of
(4.2.77) with probability P'
Proof. Theorem 4.2.10 follows from Lemma 4.2.8 because the expression (4.2.79)
is a special case of (4.2.35). It is obvious from the proof of Lemma 4.2.8 that if
(4.2.36) holds with probability P' then (4.2.70) also holds with probability r.
EXAMPLE 4.2.1.
Suppose f(x) is a Wiener process.
Let us test sufficient
convergent conditions. A positive answer is given by the following propositions.
PROPOSITION 4.2.11. (Conditions (4.2.27) and (4.2.36». There exists a limit of
conditional expectation ofthe Wiener process, when n ~ 00 for any x E A and
lim ll; = f(x)
uniformly on B.
Proof. Let
£1 = lim /11 and
£2 =
lim /12
n.... M
h ... M
where /11 = Ixi - xl, /12 = Ix - xi+l1 and Xi' xi_l are neighbours of x.
Consider the following four cases:
(4.2.80)

STOCHASTIC MODELS
1)
£1 =°and ~ = 0,
4)
£1 > 0, ~ > 0, here x E C.
The conditional expectation of the Wiener process is
In the fIrst case
In the second case
53
(4.2.81)
lim lin =
%L~" ""'x
(4.2.82)
because
lim Il; = f(x)
t.l~O
and
In the third case
lim lin =
n,..... fA'X
(4.2.83)

54
CHAPTER 4
In the fourth case
(4.2.84)
f(x + Ez)E1 +f(x - 101)102
101 + 102
n
Ilx
lim lin::
lim
n.~" l""X
l>1-7 E1
l>z-7~
In all cases the convergence is uniform.
PROPOSITION 4.2.12. (Conditions (4.2.28), (4.2.30) and (4.2.31)). There exists
a limit ofconditional variance ofthe Wiener process when n ~ 00 and
lim an :: 0
if x E B
n..... M
X
'
(4.2.85)
and
lim an > 0 if x E C
n.......
X
,
(4.2.86)
Proof. The conditional variance of the Wiener process can be expressed by
(4.2.87)
We shall consider the same four cases as in the previous proposition.
In the first case
lim an::
lim cJ:: 0
JL......
X
X
l>1-70
l>2-70
(4.2.88)
because there exist limits
lim
l>1-70
:: 0
and
:: 0 .
It is easy to see that in the second and third cases
(4.2.89)

STOCHASTIC MODELS
In the fourth case
because
55
(4.2.90)
and
lim
~1~2
C.2~E2
~1 + ~2
=
=
lim
€2~1
C.l~El
~1 +€2
=
PROPOSITION 4.2.13. (Condition 4.2.29). There exists a limit Co ofa minimum
Cn ofconditional expectation J.l~ when n ~ 00.
Proof. Since the conditional expectation J.l: of the Wiener process is a piecewise
function, then
cn = min J.l; = YOn ~ So =
xeA
mi n f(x).
xeA
(4.2.91)
Here YOn
that
min y.
is a non-increasing function. Hence there exists such co> S
l$i$n
I
lim Y
- 0
:0.....
On -
.
(4.2.92)
PROPOSITION 4.2.14.
(Conditions (4.2.29a) and (4.2.33». The distribution
function F;(s) ofa Wiener process is continuous with regard to conditional expectation
2
J.l~ and conditional variation a; at points where F;(s) is continuous and there exists a
limit distribution function F2(s).

56
Proof There exists a limit
lim
F;(s) =
F~(s)
n
0
Jlx -lax
(p ~b 0
x
x
at the continuity points of F;(s).
This is because there exists the limit
CHAPTER 4
(4.2.93)
o lfs
(S_lln)2
0
.
n
{(.J(21t) bxf
~ exp (-1/2
b~ x
) ds, bx > 0
lim
F (s) =
0
bO=O S <llx
n
n
0
x
,
x'
~
0" ~b
x
x
1,
b~ = 1, s > Il;'
(4.2.94)
uniformly on 0 < 11l~ - ~ < 0 = a~ - s
and the limit
S
0
~
{
(.J(21t) Cf f lf~ exp(-l/2(-:x)"')dS,
n
~
Fx(s) =
0,
~=O,s <a;'
1,
~=O,s > a;'
at any 0 < I(J~ - b~ I < o.
Equality (4.2.94) is true, because there exists the limit
where
and
o < 10;>- sl .
(4.2.95)
(4.2.96)

STOCHASTIC MODELS
It is easy to see that
n
1 fS
('t- Iln)2
sup
('J(2re) a f
exp (-1/2 __x
) d't
n
x
n
IlxEBs
-00
ax
n
1 fS
('t- Il' \2
= (.J(2re) q, f
-00 exp (-1/2 --!-J )d't.
ax
Here Il~ = s + €
if a~ > s
and
Il~ = a - s + € if a2 < s.
From (4.2.96) and (4.2.97) it follows that
57
(4.2.97)
= { (-/(2x)b
~rlf': exp Hi2:<~~~)')d< b> 0
0,
bx = 0, s < ax
1,
b~=O,s >a;
(4.2.98)
The function F;(s) does not depend directly on nwhen Il; and a; are fixed. In such
a case the existence of the limit
lim Fn(s) = FO(s)
n.-+oo
x
x
follows from the existence of limit (4.2.96) and the existence of limits (4.2.80) and
(4.2.85).
PROPOSITION 4.2.15. (Condition (4.2.34». Function lsi is uniformly integrable
with respect to F;(s).
Proof Let
(4.2.99)

58
CHAPTER 4
and
(4.2.100)
Here
rEI~(s)
and
n
1
-c
S -
~ln
Z
n
('J(2rr) a f f
lsi exp (-1/2(-~) ) ds, a >°
x
n
x
--00
(l
0,
~ = 0, -c <~:
={
1,
-<:f
lsl~(s)
-~
where
n
.
n
n
b = max ax' a1 = mm
~x' az = max
~x
~A
~A
~A
When lei> az then the upper limit (4.2.99) is reached at a: = b and
~: = az
because the integral (4.2.99) is nondecreasing when ~~ and a.~ increase.
The upper limit of (4.2.100) is at the point
a~ = b and
~: = a1 if - c < al'
Hence
{
('J(2rr 'j:J r 1
'I'~ (c) =
0,
1,
z
~
s - az)
f
lsi exp (-I/2(-b-
)ds
c
b = 0, c > az
b = 0, c <az
,b>O
(4.2.101)

STOCHASTIC MODELS
and
2
{
1 f-<
(S - a1)
"
C
_
('J(21t 'jJ r
--00 lsi exp (-1/2 -b-
) ds
,b > 0
"'n
~) -
0,
b = 0, - C < al
1,
b = 0, - c > a1 •
59
(4.2.102)
It follows from (4.2.101) and (4.2.102) that for any e > 0 there exists Cc such
that
"'~ (c) < e, c > cC'
and
"'~'(c) < e, c > cc'
Hence
"'n(C) =
",~(c) + ",~'(c) < 2e,
C > cC'
independently of n where
"'n(C) = J
lsi dF~(s).
Isl>c
(4.2.103)
Since "'n(c) ~ 0 uniformly with respect to n, this means (see Loev (1960) that lsi is
uniformly integrable with respect to F~(s).
Since
sup lmin (cn, s)1 ::; lsi
n
it follows that condition (4.2.34) is true.
b
PROPOSITION 4.2.16. (Conditions (4.2.37), (4.2.37a) and 4.2.37 ». Function
00
s -a )2
<!>(a, b, c) = (..J(21t 'jJ r 1 Loo min (s, c) exp (-l/2(-b-
) cis
(4.2.104)

60
where
o = ~' b = (5: and c = YOn
is a continuous function ofa, b, c, x and
<!l(a', b', c) < <!l(a", b", c)
if b" > 0 and b' = O.
CHAPTER 4
(4.2.105)
Proof. The continuity of function <!l with respect to a, b, c can be proved in the same
way as the continuity of function F;(s) with respect to IJ.;, (5:
in Proposition 4.2.14. The limit
2
1 fS
S - a )
lim
(...J(21t']J r
exp (-l/2(-b-
)ds
b.-?O
_00
From (4.2.104) and (4.2.106)
<!l(a', b', c) = min (a, c) =
C
because here
.
n
C = mm IJ.x
xeA
and
a =
IJ.~.
{
0, s < a
1, s > a
(4.2.106)
(4.2.107)
(4.2.108)
(4.2.109)
Formula (4.2.104) can be expressed in the following way
2
1
c
so-a)
<!l(a,b,c) = C- (...J(21t)b f
f-oo (c -s) exp(-l/2(-b
)ds
The second part of this expression is positive if b > 0 independently of lal < 00 and so
<!l(a", b", c) < <!l(a', b', c)
if b" > 0 and b' = O.

STOCHASTIC MODELS
61
Thus conditions (4.2.27) to (4.2.31), (4.2.33), (4.2.34), (4.2.36), (4.2.37) to
(4.2.37b) are proved.
The remaining conditions (4.2.25a), (4.2.26b), (4.2.26
C),
(4.2.32) and (4.2.36a) are obvious in the case of the Wiener process.
Similar results were obtained by Senkiene (1980) for the Wiener process with
Gaussian noise.
It is clear that any method of search which satisfies the condition of asymptotic
density (4.2.65) converges to the global minimum of any continuous functionf(x)
defined on a compact set A. The distinctive property of the Bayesian methods is that
they are generally not uniform and provide greater density of observations in the
areas around the best observed values of function f, under the following
assumptions.
Suppose that there exists sets Si cA, i = 1, ... ,n such that
n
U
Si = A, Si n Sj = 0, ifi:¢; j
i=1
Assume that
<y;:" > 0;', iff rx" > rx' ,
independently of i = 1, ... , n for any n = 1,2, .... Here
x' and x" E Si'
Suppose that
sup Jl; < in! Jl:
xeSo
xeSi
(4.2.110)
(4.2.111)
(4.2.112)
(4.2.113)
(4.2.114)
if Si
has no common borders with So' where So is a set Si
around the best
observation point Xo = arg
min f(x.).
l~i~n
I

62
Assume the risk function
$(!-t, cr, c) > $(!-t, cr + p, c),
$(!-t, cr, c) > $(!-t - a, cr, c),
where a > 0, P> 0, and that $ is a continuous function of !-t, cr, c.
Denote
rj = Ilt';' - xjll
where
x;'
E
arg min $(!-t, cr, c)
xeS.
I
(0' E
arg min $(!-t, cr, c) .
xeSo
CHAPTER 4
(4.2.115)
It is natural and convenient to define the relative density of observations as the
relation K j of radii rj and ro
K j = rj/ro
or, in accordance with condition (4.2.113), as a relation Kt of standard deviations crj
and cro where crj =0;:, x =x;' and cro =cr;, x =xo'.
LEMMA 4.2.1. If conditions (4.2.110) to (4.2.112), (4.2.114) and (4.2.115) hold
then
Kf = cr;l cro > 1
(4.2.116)
for such indices i where a corresponding set Sj has no common border with So.
Proof. From (4.2.115) and the continuity of function $ it follows that for any a > 0
there exists P> 0 such that
$(!-t - a, cr - P, c) = $(!-t, cr, c)
(4.2.116.1)

STOCHASTIC MODELS
63
From (4.2.116.1), (4.2.114) and (4.2.115) it follows that the minimum of
function <I> in the areas Sj will correspond to larger cr; than in the area So because in
the area Sj the mean values 11; are assumed to be larger, see (4.2.114).
THEOREM 4.2.12. If the assumptions (4.2.110) to (4.2.115) are true then
(4.2.117)
Here Sj has no common borders with So'
Proof. Inequality (4.2.117) follows from conditions (4.2.116) and (4.2.113).
Inequality (4.2.117) means that the distance to the next observation will be
smaller in the area around the point of best observation xo.
The condition (4.2.117) deterimines the ratio of radii rj and ro corresponding to
the sets Sj and So.
Now we shall define the value of the ratio Kj for the Gaussian distribution of
f(x) assuming that the values of the risk function <I> are the same in both sets Sj and
So·
This assumption is not restrictive when n is sufficiently large because it follows
from (4.2.35), (4.2.30), (4.2.65), (4.2.68) and (4.2.70) that the risk function
(4.2.79) will converge to the same limit So for all sets Sj'
In this case the ratio of standard deviations
and from (4.2.30) and (4.2.77) the asymptotic relation
f -f, + E
KS = lim K S =
a
0
11.....
a
E
(4.2.118)
(4.2.119)
Ratio (4.2.118) was determined from the equality of values of parameter
a = (c -Il)/cr in the sets Sa and So. The parameter a defines the risk function in the
Gaussian case, see expressions (5.1.1), (5.1.3), (5.1.5) and (5.1.6).
In the expressions (4.2.118) and (4.2.119) the following notation was used:

64
Ila = Il~, if x = xa'
fa = (L(A))-1t f(x) dx
fo = min f(x).
xeA
L(A) is Lebesgue measure (the volume) of set A.
xa'
E
arg min (j>(Il, cr, c).
xeSa
CHAPlER4
Sa is a set Sj around the observation where result Yj is nearest to the mean value
fa of function f(x).
If the standard deviations are defined by expression (5.2.8) then it follows
from (4.2.119) and (5.2.8) that
K = lim K = lim r / r = lim
:tl.... M
a
n.....
a
0
n,.... cwa
In the case (5.2.7)
ra = Ilxa'-xall = max IIx-xall
xeSa
and
ro = Ilxo' - xoll = max IIx - xoll .
xeSo
f - /'0 + €
1/2
( a
)
€
(4.2.120)
The relations (4.2.119) and (4.2.120) can be used to compare the efficiency of
non-uniform Bayesian search with uniform search. In this case radius ra roughly
corresponds to the uniform search and radius ro to the Bayesian search around the
best point and asymptotically around the global minimum. Thus the relation K can be
regarded as the relative asymptotic density of observations of the Bayesian search
round the global minimum compared with the uniform search.
It is clear from expressions (4.2.118) and (4.2.120) that the relative density is
a decreasing function of the correction parameter €. The relative density converges to
1 when € ~ 00 and increases without bounds when € ~ O. This means that if
parameter € is large then the search is nearly uniform. If the parameter € is small then

STOCHASTIC MODELS
65
only an insignificant part of the observations will be made outside the region of the
best observed point.
This corresponds well to the meaning of the correction
parameter € as defined in sections 2.5 and 5.1.
4.3.
The Gaussian field
If the probability densities (4.2.3) are Gaussian then the corresponding stochastic
function is called the Gaussian field. We shall denote the vectors of expectation by
Ils, Ilv and 11 snd the matrices of covariance by IS, IV and I, respectively, where
(4.3.1)
(4.3.2)
Here Ilt, Ilt, Ili are expectations of the random variables f(x), g(x), h(x) and <Sij'
cr'ij, crij are covariances of the pairs f(Xi),f(X); g(xi)' g(x) and h(x), h(x),
respectively. It is well known (see Anderson (1958» that the conditional probability
density will be Gaussian with expectation
(4.3.3)
and variance
(4.3.4)
where y =(Yi)' Yi =h(Xi)' i = 1, ... ,n. Here 11/ and (cr~)2 are the expectation and
variance of the objective functionf(x), 11; and (cr;)2 are the conditional expectation
and variance off(x) when vector zn = (Xi' Yi' i = 1, 2, ... , n) is fixed.
It is usually assumed that the expectation of noise is zero.
Therefore the
components crXXi' i = 1, ... , n of the vector Ix should be the covariance of the pairs
f(x),f(Xi)'
In some cases the following expressions can be more convenient.
The conditional variance off(x) when zn is fixed
n
n-l
(cr: 1)2
n
cr
= cr
(4.3.5)
xx
xx
*n-l
crx x
nn

66
Here the conditional covariance of/(x).!(xn) when zn_l is fixed
CHAPTER 4
n-2
= °xxn
(4.3.6)
and the conditional variance of
at fixed Zn is
*n-l
Ox xnn
*n-2
= ax xnn
*n-2
Ox
x
n-l
n-l
(4.3.7)
The conditional covariance of h(xn), h(Xn_l) at fixed zn is
*n-l
Ox x
n n-l
*n-2
= ax x
n n-l
(4.3.8)
The conditional expectation of/ex) when zn is fixed
n-l (y
n-l)
on
n -Ilx
n
~l
n
n
Ilx = Ilx
+
-"';"-*-~-l'-';';-
Ox x
nn
The conditional expectation of/(xn) at fixed zn_l is
(4.3.9)
n-l
Ilxn
n-2
= Ilx
+
n
(4.3.10)
The zero indices correspond to unconditional parameters

STOCHASTIC MODELS
EXAMPLE 4.3.1. In the case of independent noise with unit variance
*0
aO
+ 1
ax x
=
n n
x,rn
and
*0
r 0,
Xi'Xn
a xxn = 11, x=xn
It follows from (4.3.7) that
a*n-l
n-l
1
= ax x + .
xnxn
n
n
4.4
Homogeneous Wiener field
67
The only argument for considering the Gaussian field as a stochastic model so far
was the fact that it is commonly used and well investigated.
It would be useful to derive some stochastic model more directly from the
assumptions relevant to the problem of global optimization.
The first assumption is the continuity of samples. This means that probability
P , to be a continuous function, should be 1.
The next natural assumption is homogeneity, which means that the
I-dimensional distributions F defined in (4.2.2) should not depend on the origin of
co-ordinates.
A third assumption is desirable to narrow the class of possible stochastic
functions but here the choice is less obvious.
It is only clear that a stochastic model should not contradict the first two
assumptions and apriori concepts about the objective function and be as simple as
possible for the computation of conditional probabilitites.
The computation of
conditional probabilities is simplest in cases when f(x) and f(x), i :;r j, are
independent. However it contradicts the continuity assumption. It also contradicts

68
CHAPTER 4
a priori notions about the objective function because it is hard to imagine such a
completely irregular objective function in any real physical systems. For example,
under the assumpton thatf(x) andf(x), i '1= j are independent, the probability of the
minimum being almost at the point of maximum is the same as at any other point.
Apparently the weakest condition which satisfies the continuity assumption,
and in many cases more or less corresponds to a priori ideas about the pattern of
behaviour of an objective function, is the independences of partial differences. The
partial difference of m-th order may be regarded as an approximation of partial
derivative of m-th order and can be expressed by the following recurrent formulae
Ci>O, i=l, ... ,m.
(4.4.1)
It is well known (see Katkauskaite (1972)) that from the continuity of sample
functions f(x, (0) and the independence of differences (4.4.1) it follows that the
stochastic functionf(x) is Gaussian.
THEOREM 4.4.1 Suppose that a Gaussian stochasticfunctionf(x) is defined on an
interval [- 1, l]m with constant expectation f.l, standard variance (J2 and covariance
i
i
m
Ix -x I
(J'k =
(J2n (1 _
j
k)
J
i=l
2
Then it is continuous, homogeneous and has independent partial differences.
(4.4.2)
Proof.
Let us consider the Wiener field with an origin at the vertice Xl of an
m-dimensional cube [- 1, l]m. In such a case the covariance can be expressed as
m
'1k (xI) =
(J2n u i
i=l
(4.4.3)

STOCHASTIC MODELS
where
69
u.
I
{
min (xj - xj, x1 - x~), ifxj ~ xi
and x~ ~ xl
min (xj - xj, xl - x~), ifxj < xi
and x~ < xl
0, if neither inequality is true.
(4.4.4)
The expectation of the Wiener field is zero and variance
(4.4.5)
We can make the variance independent of the origin of co-ordinates XI by
summing 2m independent Wiener fields corresponding to the different vertices of the
cube [- 1, l]m. Then the variance of the sum
2
1
m
2
(i
zn
m
lxi_xi I
2
()
-
I- ~ (Xl)
I- n
=
()
x
'fl
tt'
I
1=1
1=1
i=l
and the covariance of the sum
2m
i
i
()2
m
2
m
lxj-Xk ')
()jk = -
I- n
u. = () n (1-
2m
I
2
1=1
i=l
i =1
(4.4.6)
(4.4.7)
This means that this stochastic function is homogeneous and can be regarded as the
sum of constant I.l. and 2m independent Wiener fields with origins at the vertices of the
cube [- 1, l]m.
Since each Wiener field is a Gaussian stochastic function with
independent partial differences, the sum of any finite number of independent Wiener
fields is also a Gaussian stochastic function with independent partial differences.
EXAMPLE 4.4.1. If m = 1, I.l. = 0, () = 1 then vertices
Xl = -1, x2 = 1
and from (4.4.5)

70
CHAPTER 4
From (4.4.3), (4.4.4) and (4.4.6)
crjixz) = 1 - max (Xj' x,J
cr; = 1/2 (cr.;(Xl) + cr;(xz)) = 1.
From (4.4.7)
The homogeneous Wiener field defined by (4.4.2) is a stochastic function which
satisfies the conditions of continuity, homogeneity and independence of partial
differences, and so it is a natural, clear and convenient stochastic model for
theoretical consideration.
4.5
A case of noisy observations
In some cases the exact values off(x) cannot be defined exactly because of errors in
calculations or physical experimentation. For example, errors of calculations usually
arise whenf(x) is obtained by numerical integration of some differential equations.
The errors of physical experimentation often arise in the optimal experimental design.
The problem with errors can be considered naturally by the Bayesian approach.
In this case only the formulae for conditional expectation and variation should be
changed.
Proper representation of different types of errors demands different stochastic
models.
For example, the errors of experimentation can often be adequately
represented as independent Gaussian variables. However, this stochastic model is
hardly acceptable for the errors of numerical integration of differential equations.
They can be better represented by a stochastic function with independent partial
differences such as (4.4.2).
In a general case the error functions can be considered as sample paths of
different, but not necessarily independent stochastic functions. This means that the
error function g can depend on two variables: on the point of observation x and its
number i. Considering this case we shall denote the value of error function gr at the

STOCHASTIC MODELS
71
point x' by 8i'(X').
The covariance between two error functions gi' and gi" at the
points x' and x"will be denoted as
(4.5.1)
It is natural to suppose that
and
Si'i'.(X', x")
=
s(x', x") • sa'
(4.5.2)
(4.5.3)
where s(x', x") =E (8i(X'), 8i<X")} is independent of i and si'i" =E (gi'(x), 8i"(X)}
is independent ofx.
For example, in the case of independent errors
r 1, i' = i"
Si'i" = l 0, i' * i"
and from (4.5.3)
r S(Xi' Xi), i' = i"= i, x' = x" = Xi
l 0, i' * i"
In the case when the same sample path of an error function is observed (linear
dependence)
Si'i" = 1 and Si'i'.(X', x") = s(x', x").
In the case when sample paths are a Markov chain, the points of observation being
the same,
Su'(x', x") = s(x', x") (1 - a)li' - i"l, °< a < 1.

72
4.6
Estimation of parameters from dependent observations
CHAPTER 4
It was shown in section 4.4 that the probability distribution P can be derived from
some natural assumptions.
However, the values of mean and variance remain
undefined and must be estimated from observations. It is not too difficult to do this if
the observations are independent. Unfortunately, it is not true if we wish to use the
results of optimization including the Bayesian one for the estimation of unknown
parameters because, with the exception of uniform random search, the points of
optimising sequences are usually dependent.
Since we have agreed that optimality is to be understood in the average sense, it
is desirable to define unbiased estimates of unknown parameters Il and cr. This is not
an easy task when observations are dependent.
Let us consider the Gaussian field f(x), x E A c Rm with mean Il and
covariance cr2p(s, t), where Il and cr are unknown and pjj =p(Xj, x) is an element of
the fixed correlation matrix. An example of such a field was given in section 4.4.
Suppose that Xj+l = dj(zj), i =0,1,2, ..., where Zj = (Xj,f(x), j = 1, ... , i) and d j is
continuous almost everywhere.
We shall investigate the maximum likelihood estimates Iln of unknown mean Il,
where
(4.6.1)
because it is unbiased when Xl
... 'Xn are fixed.
We can reasonably expect
that this property will also occur in the case of dependent observations if they are
dependent in an 'unbiased' way.
It was shown by Mockus and Senkiene (1979) that the estimate Iln is
asymptotically unbiased when
(4.6.2)
THEOREM 4.6.1. Ifcondition (4.6.2) holds, then the maximum likelihood estimate
Iln ofmean Il defined by (4.6.1) is asymptotically unbiased
Elln ~ Il when
n ~ 00.
(4.6.3)

STOCHASTIC MODELS
Proof. Let
73
where R~1 can be expressed by the recurrent formula of Frobenius, see Gantmacher
(1967)
(
p
)
(P )
-1
-1
nl
-1
-1
-1
nl
-1
R n_1+R n_1
:
B
(Pnl'"'' Pnn-l) R n_1 -R n_1
:
B
Pn n-l
Pn n-l
Here
(
Pnl )
B
= Pn n - (Pn 1> ••• , Pn n-l) R~~1
:
Pn n-l

74
CHAPTER 4
[
Pn1 J
H
= Pn n - (Pn l' ... , Pn n-l) R~~l
:
Pn n-1
Since dn, n = 0, 1, ... ,N are assumed to be continuous, then from Theorem
2.4.1 it follows that the conditional expectation and variance off(x) in the case of
dependent observations can be expressed using the same formulae (4.3.3) and
(4.3.4) as for the fixed points xl' x2' ... ,xn. In such a case the relation between the
conditional expectation of an and that of bn
[
Pn 1 J
:
-l/}+ ... +E{l/Pll}
Pnn-l
E {l/H ((1, ... , 1) R~~l
Ea
_n =Il
=Il
Eb
n
[ P
n 1 J
2
E {l/H }((1, ... , I)R~~l
:
-1) + ... +E {l/Pll}
Pn n-l
It follows from condition (4.6.2) and the Markov theorem, see Gnedenko
(1965), that for any e >°
Since
n
1
L
P~
Yj
iJ=l
IJ
n
"
-1
£.. Pio
iJ=l
IJ
~-----
"
1
L
P~
iJ=l
IJ
then it follows from the Lebesgue convergence theorem that

STOCHASTIC MODELS
n
"
-1
lin
£.J Pi'
Yi
ij=1
~
Elln = E
~
1
lin
£.J p-::
ij=1
l~
n
"
-1
E £.J Pi'
Yi
ij=1
~
n
1
E L p-::
ij=1
IJ
75
when n ~oo.
To test condition (4.6.2), we shall define some more simple conditions from
which condition (4.6.2) follows.
Suppose there exists a converse correlation matrix and it is differentiable.
-1
Pi} = Pi}'
Suppose that p~} are bounded, where
p~} = dp IdXI , l = 1, '" , m.
(4.6.4)
(4.6.5)
(4.6.6)
and that there exists a fixed sequence t n E A, n = 1, ... N where to each n there
corresponds index in such that
IItn - Xi II < EN,
EN > 0,
EN ~°when N ~ 00.
n
(4.6.7)
The purpose of the last condition is to reduce the difference between the fixed and the
random points to the E-level, where E ~°when N ~ 00.
THEOREM 4.6.2. Condition (4.6.2) follows from conditions (4.6.4) to (4.6.7).
Proof. For any k, s the difference
Pills - Pks
where
= f
1=1
(4.6.8)

76
CHAPTER 4
Since any k = 1, ... ,N corresponds to one and only one ik, then
N
LP"
k,s=l 'I!S
nL p .. ,
where Pij
i"j=l
IJ
From here and (4.6.8) it follows that
N
N
L p(xi,x) - L p('tk,'f)
ij=l
k,s=l
Omitting the remainder
NL p(x.,x.)
ij=l
I
J
NL p('tk''t) =
k,s=l
I
N
where hk = L
h~
s=1
Hence
(4.6.9)
N
Because L p('tk,'ts) is fixed, the variance of sum (4.6.9) can be expressed as
k,s=l
N
var ( L Pi")
= 4 var
ij=l
J
(4.6.10)

STOCHASTIC MODELS
where
~k/
/
/
'"
=
/:1k hk , C
Suppose that from
/:1 =
max
k=I•...•N
l=l •...•m
it follows
C ~ O.
Then
max
k,s=I •...•N
/=l •...•m
77
(4.6.11)
(4.6.12)
2
N
liN var(I Pi')
~ 0
ij=l
J
when N ~ 00.
(4.6.13)
(4.6.12) is true because for any random YI' Y2 E [- /:1, /:1] the following
inequality holds
and from (4.6.7) it follows that /:1 ~ O.
Condition (4.6.7) follows from Lemma 4.2.6 and the definition (4.2.19).
COROLLARY 4.6.3. If there exists an inverse correlation matrix R~l with bounded
derivatives and the conditions of Lemma 4.2.6 hold, then the estimate (4.6.1) is
asymptotically unbiased.
So far we have been considering only the estimate of the mean. Now let us
consider the maximum likelihood estimate cr~ of variance cr2
2
crn
N
1 L
-1
--
p.
V.v ..
N -1 ..
I
I J
1J=1
(4.6.14)

78
Here
CHAPTER 4
If the observations are fixed then the estimate (4.6.14) is unbiased. If condition
(4.6.2) holds, (j~ can be expected to be nearly unbiased for the same reasons as in the
case of the mean, also in the case of dependent observations.

CHAPTERS
BAYESIAN METHODS FOR GLOBAL OPTIMIZATION IN
THE GAUSSIAN CASE
5.1
The one-step approximation
The fonnula for the one-step Bayesian approach assuming the Gaussian distribution
is from (2.5.1) and (2.5.5)
Xn+ 1 E
arg min (1/cr) [
min (y, c) exp «-1/2) «y -ll) / cr)2) dy.
(5.1.1)
xeA
-~
Here II is the conditional expectation and cr is the conditional standard deviation of
f(x) when the observed values are
Yl = f(xl)' ... , Yn = f(xJ
and
c = min ll- e,
e > O.
XEA
(5.1.2)
Here e takes into account the influence of subsequent observations. When e is large,
the method becomes a nearly uniform search. When e approaches zero the method is
strictly one-step.
The relation (5.1.1) can be expressed as
Let
and
xn+ 1 E arg max (1/cr) [
(c - y) exp «- 1/2) «y -ll) / cr)2) dy.
xeA
-00
u = (y -ll)/cr
a = (c -ll)/cr.
79
(5.1.3)
(5.1.4)
(5.1.5)

80
CHAPTER 5
Parameter a < 0, because, as follows from (5.1.2), C < /1.
From (5.1.4),
(5.1.5) and (5.1.3) we can write
Xn+ 1 E
arg max <j>(a)
xeA
where
<j>(a) = a f_ (a - u) exp «-l/2)u2) duo
The derivative of <j> with respect to a
d<j>
d<j>
d<j> da
-=-+--
d1
ill
da d1
where
d<j>/da = d/da (aa f_ exp «-l/2)u2) du - a r~ u exp «-l/2)u2) du
= a[
u exp «-1/2)u2) duo ;::: 0 because a;::: 0
_00
and
d<j>/da = [00 (a - u) exp «-l/2)u2) du > 0
because a - u > 0 for all u E (- 00, a)
da = .!!.... ce -/1) =L
> O.
d1
d1
a
/1- c
It follows from (5.1.8), (5.1.9), (5.1.10) and (5.1.11) that
d<j>/da > 0
because
d<j>/da ;::: 0,
d<j>/da > 0 and da/da > O.
(5.1.6)
(5.1.7)
(5.1.8)
(5.1.9)
(5.1.10)
(5.1.11)
(5.1.12)
(5.1.13)

BAYESIAN METHODS IN THE GAUSSIAN CASE
81
The inequality (5.1.12) means that <1> is an increasing function of a, so from
(5.1.6)
Here
Xn+ 1 E arg max a = arg max (-Va) = arg max <1>(x)
~A
~A
~A
<1>(X) = cr/(J..l- c).
(5.1.14)
(5.1.15)
The maximum of <1> can be either on the boundary of A or at the point where the
differential of <1> is zero
d<1>
0<1> dcr
0<1> dJ..l
0<1>,
0<1>
I
-
=-- + -- = -cr +-J..l
dx
ocr dx
oJ..l dx
ocr
oJ..l
It follows from (5.1.16) that
cr'/cr = J..l'/(J..l- c).
(5.1.16)
(5.1.17)
Solution of (5.1.14) or (5.1.17) is rather time consuming in a multi-
dimensional case.
No more that 100 to 200 observations can be handled when
expressions for J..l and cr correspond to the usual multi-dimensional Gaussian
distribution.
It appears that no further substantial simplifications can be made if we wish to
satisfy the Kolmogorov consistency conditions. These consistency conditions ensure
that a sample path of the same stochastic function is considered during the process of
optimization. Some additional requirements given by Katkauskaite (1975) allow us
to consider only continuous sample paths.
It is easy to notice that the consistency conditions can make the stochastic
model less adaptive.
For example, if we update the parameters J..lo and cro of a
stochastic function on the basis of the results of observations, we violate the
consistency conditions.
However, this usually improves the results of the
optimization because it adapts the stochastic model to the observed data, so it is
reasonable to omit those conditions if by doing so we get some computational
advantage and if convergence remains.

82
CHAPTER 5
5.2
Adaptive models
There are many ways to simplify the stochastic model (5.1.1) if the usual consistency
conditions are dropped.
Let us consider the situation when the conditions of
consistency and continuity of sample paths are omitted but the conditions of
convergence of method and continuity of the function <!>(x), the maximum which
defines the next point of observation in accordance with (5.1.14), remain.
The adaptive model will be defined in the following way.
n
f(x) =J;(x); XE Ai; UA. = A; AJIA. = 0, ic:l=j; i,j=I, ... ,n
i=l
I
I
J
(5.2.1)
where each Ai contains one observation xi'
Suppose that fi(x) is a Gaussian
stochastic function, 'conditional' expectation I.l.~ is equal to the observed value Yi and
.2
'conditional' variance (J~
is an increasing function Ii of the distance di = IIx -xiii
from the point of observation Xi' namely
and
.
.2
I.l.~ = Yi
and
(J~
= Ii(d), X E Ai'
It follows from (5.1.15) and (5.2.2) that
(5.2.2)
(5.2.3)
(5.2.4)
Since <!>i(X), i = 1, ... , n are fixed by (5.2.3), the postulated continuity of <!>(x)
can be provided only by the proper choice ofAi' namely when
Ai = (x: <!>i(X)
S; <l>ix), j = 1, ... , n}.
From (5.2.4) and (5.2.5)
<!>(X)
min
<!>i(x),
l$i$n
(5.2.5)

BAYESIAN METHODS IN THE GAUSSIAN CASE
From this and from (5.1.14)
X
1 E arg max min
$.(x)
n+
xeA
l:5:i91
I
or taking (5.2.3) into consideration
X
1 E
arg max min
(Ji /('/ - c).
n+
xeA
l:5:i:5:n
x
x
83
(5.2.6)
(5.2.7)
Most of the calculations so far have been done using a Gaussian stochastic
function with conditional expectation (5.2.2) and the conditional variance
(5.2.8)
because the model is simplest in this case.
Method (5.2.7) satisfies the conditions
of Theorem 4.2.9, sufficient for the convergence of the sequence (5.2.7) to the
global minimum of any continuous function. This means that the use of an adaptive
model (5.2.2) and (5.2.7) developed without the conditions of consistency of
distribution functions and of continuity of sample paths shows the same asymptotic
results as the standard one-step stochastic model (5.1.1), which is consistent and
continuous but more complicated. The results of calculations have not shown any
substantial difference between the standard and adaptive models except reduction of
computational effort.
So far the adaptive model (5.2.7) has been regarded as a simplification of the
standard one-step Bayesian model (5.1.1) which was supposed to be an
approximation of the classical probabilistic Bayesian model (2.1.11) represented in
section 2.2 as the system of recurrent equations (2.2.1) of dynamic programming.
It seems, however, much more interesting and useful to consider the adaptive
model (5.2.7) as a different kind of stochastic model, which may correspond even
better to the basic ideas of Bayesian decision theory in the problem of global
optimization. The classical probabilistic Bayesian model (2.1.11), (2.2.1) is based
on assumptions directly borrowed from the classical theory of stochastic functions,
such as Kolmogorov's consistency conditions. However, the conditions are not so
important in some Bayesian decision problems, including global optimization, when
it is not considered necessary to see the objective function as a sample path of a fixed
stochastic function.
So it would be better to regard the adaptive Bayesian model (5.2.7) as some
non-classical stochastic model where the usual consistency conditions are replaced by
the condition of the continuity of risk function (5.1.1) and the expressions of

84
CHAPTER 5
'conditional' expectation and 'conditional' variance are made as simple as possible
ensuring the convergence to the minimum of any continuous functionf(x).
ASSUMPTION 5.2.1.
The simplicity of functions conesponds to the following
ordering
1) constant function
2) step function
3) linear function
4) piecewise-linear function
5) quadratic function
6) piecewise-quadratic function.
DEFINITION 5.2.1. A non-negative function
will be called a non-consistent conditional density function, if
r piY) dy = 1.
_00
The term 'non-consistent' is necessary to make the distinction from the usual
definition of conditional density which satisfies the consistency conditions. In this
section and later, the term 'non-consistent' is omitted if it does not lead to confusion
with the classical definition of conditional probabilities.
THEOREM 5.2.1. Suppose that
1) The conditional density function Px(y) is Gaussian with conditional mean Ilx
and conditional variance cr;.
2) The riskfunction (5.1.1) is continuous.
3) The sequence (5.1.1) satisfies the convergence conditions (4.2.65).
4) The conditional mean Ilx and the conditional standard deviation crx are
functions ofx, as simple as possible in the sense ofAssumption 5.3.1.

BAYESIAN METHODS IN THE GAUSSIAN CASE
85
Then the one-step Bayesian method is defined by expressions (5.2.7) and
(5.2.8).
Proof The simplest function which satisfies conditions (4.2.26b) is the step function
).lx =f(x) , x E A j where Ai' i =1, ... , n is the partition of A such that Xj E A j•
The simplest function which satisfies conditions (4.2.30) and (4.2.31) is the
step function: o"x = 0 ifx = Xj and o"x = h > 0 if x ;;j:. Xj, i = 1, ... , n but this function
contradicts the condition of continuity of risk function. To satisfy this condition the
conditional standard deviation o"x should be an increasing function of the distance
ILx - xjll. The simplest one in the sense of assumption 5.2.1 being
o"x = ILx - xjll2.
In this case the risk function (4.2.35) and the corresponding function $(x), see
(5.1.15), will be continuous if the partition A j, i = 1, ... , n corresponds to the
condition (5.2.5). The remaining conditions of Lemma 4.2.6 are also satsisfied. So
in this case the convergence condition holds, if there is no noise.
It follows from Theorem 4.2.10 that in the case of noisy observations the
convergence of the Bayesian method does not necessarily follow from the condition
of asymptotic density (4.2.65), as it does in the absence of noise. In the presence of
noise the convergence of the method is provided if the conditional expectation
converges to the function to be minimized, see condition (4.2.36). It is obviously
not true in the case (5.2.2), (5.2.7).
So in the noisy case the standard Bayesian
method (5.1.1) should be used instead of the adaptive one (5.2.7) if the convergence
of the method is necessary. If not, then the simpler method (5.2.7) can be used
which does not necessarily converge but provides some improvement in the average
sense of objective function with regard to the initial point. If the convergence is
needed but the standard Bayesian method is considered to be too complicated, the
following algorithm can be applied, see Mockus et al (1987).
1) The observations are restricted by the condition
rhx.'
if hx. ~ Yo
lY:'
I
Yj =
if hx . <Yo
I
where Yo is some acceptable level and hx. =!(Xj) + ~j
I

86
CHAPTER 5
2) The point of the next observation is defined by the adaptive Bayesian
method (5.2.7).
3) The final decision xN+l is defined using some statistical model which
corresponds to the condition (4.2.36).
5.3
Extrapolation models
The conditional expectation and conditional variance can also be considered in the
framework of the theory of extrapolation under uncertainty, see Zilinskas (1982).
There are five assumptions concerning conditional expectation Il~ :
ASSUMPTION 5.3.1.
1l~((Xi' cYi)' i = 1, ... ,k) = cll/((xi, Y), i = 1, ... ,k)
for any real c.
ASSUMPTION 5.3.2.
for any real c.
ASSUMPTION 5.3.3.
for any permutation of indices j(i).
ASSUMPTION 5.3.4.
1l~/CXi' Yi)' i = 1, ... ,k) = Yj' j = 1, ... , k.

BAYESIAN METHODS IN THE GAUSSIAN CASE
87
ASSUMPTION 5.3.5. There exists a mapping vi .):A x (A X Rl-1 ~ R such that
where
Here
Assumptions 5.3.1 to 5.3.4 look fairly natural. Assumption 5.3.5 restricts us
to the situations when the results of all k - 1 observations can be aggregated into one
single number v.
THEOREM 5.3.1. The unique/unction satisfying assumptions 5.3.1 to 5.3.5 is the
weighted sum:
k
f.l~«Xi' Yi), i = 1, ... , k) = Lyl (x, Xi' j = 1, ... , k)
i=l
where weights sf possess the/ollowing properties
k
k
.
L s. (x, x., J = 1, ... , k) = 1.
i=l
I
J
sf(x, Xi' j = 1, ... , k)
Here
(5.3.6)
(5.3.7)
(5.3.8)
and
{
i,
P =
~,
J,
if i ~), i ¢ I,
if i = j,
if i = I
k.
{
1,
Si(X/> xi' J= 1, ... ,k)
=
0,
i = I
(5.3.9)
Proof Suppose that x, Xi' i = 1, ... , k are fixed. Denote

88
f.l~«Xi' V), i = 1, ... , k - 1, (xk' v)) = <Pk(u, v).
It follows from assumptions 5.3.1, 5.3.2 that
<Pk(cu, cv) = c<Pk(u, v)
and
<Pk(u + c, v + c) =
<!>k(u, v) + c
in accordance with Aczel (1966).
Hence from assumption 5.3.5
CHAPTER 5
Because of the independence of permutations (assumption 5.3.3)
(5.3.10)
f.l~«Xj' Y), j = 1, ... , k)
/ = 1, ... , k - 1.
= all(x, (xi' Y), j = 1, ... ,k, j 7/i) +bll/
al +bl
(5.3.11)
It follows from (5.3.10) and (5.3.11) that f.l: is differentiable with respect to YI
for any fixed /, / =1, ... ,k and
(5.3.12)
Therefore
(5.3.13)

BAYESIAN METHODS IN THE GAUSSIAN CASE
Denote
b.
-l.-b = SJk (x, xi' i = 1, ... , k)
Gj +
j
and we shall have expression (5.3.6).
It follows from assumptions 5.3.1 and 5.3.2 that
~~«Xj' Y), j = 1, ... ,k)
= y.
Therefore
89
(5.3.14)
(5.3.15)
kL sf (x, xi' i = 1, ... , k) = 1.
j=l
Properties (5.3.8) and (5.3.9) of the weights st follow directly from
assumptions 5.3.3 and 5.3.4, respectively.
Now consider the following seven assumptions concerning conditional
variance ~x = i(x, (xi' Yi)' i = 1, ... , k).
ASSUMPTION 5.3.16. There exists a mapping cr(x, z), A2 ~ R such that
cr(x, z) = cr(z , x), cr(x, x) > cr(x, z), x:t:- z
and
where
cr = cr(x, x), cri = cr(x, x), 'Yk = 'Yk(Yl' ... , YV,
s1 = s1(x, Xj' j = 1, ... , k).
Here 'Yk depends only on the results of observations Yl> ... ,Yk and Sk depends only
on the weights s1 and the functions cr, cri which do not depend on Yl> ... , Yk'

90
ASSUMPTION 5.3.17.
CHAPTER 5
Sk (cr + cr', (crj, S/), i = 1, ... , k) = Sk (cr, (crj, s/), i = 1, ... , k) + cr'.
ASSUMPTION 5.3.18.
Sk (cr + cr', (crj + cr', s/), i = 1, ... , k) = Sk (cr, (crj, s/), i = 1, ... , k).
ASSUMPTION 5.3.19.
Sk (ccr, (ccrj, s/), i = 1, ... , k)
cSk (cr, (crj, s/), i = 1, ... , k).
ASSUMPTION 5.3.20.
for any permutation of indices
{j(i),i=I, ... ,k}
= {l,2, ... ,k}.
ASSUMPTION 5.3.21. There exists a function Uk ( • ) : R )( (R2l-1 ~ R such that
Sk (cr, (cri, sh, i = 1, ... , k) = Sk (cr, (crj, s/), i = 1, ... , k)
where
Here
U = uk(cr, (crj, s/), i = 1, ... , k - 1).
ASSUMPTION 5.3.22.
Sk(cr, (cr'i, s';k), i = 1, ... , k) = Sk (cr, (crj,s/), i = 1, ... , k)
where
"k
k···
k
"
s j
= Sj, l:t:-J, l:t:- , cr j =
and

BAYESIAN METHODS IN THE GAUSSIAN CASE
91
Assumption 5.3.16 means that the conditional variance cfxx ofj(x) whenj(x), i
= 1, ... , k are observed is a product of Yk and Sk> where Yk depends only on
Yj =j(Xj), i = 1, ... ,k and Sk depends only on cr, crj , Sj k, i = 1, ... , k.
The difference
OJ = cr - crj = cr(x, x) - cr(x, x)
can be regarded as an uncertainty of j(x) when j(x) is observed. So crj may be
considered as 'information' onj(x) obtained observingj(x) and cr may be regarded
as 'information' onj(x) obtained observingj(x).
According to the assumptions 5.3.17 and 5.3.18, conditional variance ~x of
j(x) will increase by cr' if information cr increases by cr'. Correspondingly ~x will
not change if information cr and crj, i = 1, ... , k are increased by the same level cr'.
The assumptions look fairly natural because in the case of assumption 5.3.17 the
uncertainty OJ offix) will be increased by cr' and in the case of assumption 5.3.18 the
uncertainty OJ will remain the same.
Assumption 5.3.21 is similar to assumption 5.3.5 and gives a possibility of
data aggregation. Assumption 5.3.22 states that the conditional variance will remain
the same in spite of changing weights sf and information crj if the product sf crj does
not change. This means that the weight sl and information crj play an equally
important role in defining the conditional variance.
THEOREM 5.3.2. The uniquejunction satisfying assumptions 5.3.11 to 5.3.22 is a
weighted sum ojuncertainty OJ
cfxx = i(x, (Xj, y), i = 1, ... , k)
where
OJ = cr(x, x) - cr(x, x)
and
Jt = 4(x, Xj' j =1, ... , k)
Proof It follows from 5.3.17 that
k
= Yk 2.
j=l
(5.3.23)
(5.3.24)
(5.3.25)
Sk (cr, (crj, s/), i = 1, ... ,k) = cr - Tk «crj, s/), i = 1, ... , k).

92
CHAPTER 5
Comparing assumptions 5.3.18 to 5.3.21 with the corresponding assumptions
5.3.1 to 5.3.3. and 5.3.5 it is easy to see that the properties of the function
Tk ((<Ji' S/), i = 1, ... , k) = Sk (0, (<Ji' s/), i = 1, ... , k)
as a function of <Ji are the same as those for 11: as a function of Yi if Tk and <Ji are
substituted for 11: and Yi
respectively.
So the conditional variance can be
represented as a weighted sum (5.3.23) of uncertainties 0i expressed in the same way
as the conditional expectation was expressed as a weighted sum (5.3.6).
The assumptions 5.3.1 to 5.3.5 and 5.3.16 to 5.3.22 are not restrictive enough
since almost any reasonable expressions of conditional expectation and conditional
variance can be represented as (5.3.6) and (5.3.24) respectively.
In order to define the model more precisely, we must introduce some additional
assumptions, for example the following consistency conditions.
ASSUMPTION 5.3.26. If
Vi = Yi' i = 1, ... , k - 1
and
then
Il~ ((Xi, V), i = I, ... ,k) = 11/-1 ((Xi,Y), i = 1, ... , k - 1).
ASSUMPTION 5.3.27. Function <J(x, z) defined in assumption 5.3.16 is positive
definite and
for any Xl' X2 E A.
Assumption 5.3.26 expresses the compatability of Ilk- l and Ilk. This means
that the conditional expectation will not change if the result of observation vk is equal
to the value of conditional expectation at the observed point xk'
Assumption 5.3.27 implies a sort of symmetry which means that the
conditional expectation at the point X E A with regard to the observed values

BAYESIAN METHODS IN THE GAUSSIAN CASE
93
f(x) =cr(z, X), i = 1,2 is equal to the conditional expectation at the point z E A with
regard to the observed values f(xj) =cr(x, x), i =1, 2.
THEOREM 5.3.3. If assumptions 5.3.26 and 5.3.27 hold, then the expressions
(5.3.6) and (5.3.23) correspond to those of conditional mean and conditional
variance ofthe Gaussian stochasticfunctionf(x).
and
where Lk is a matrix with the elements cr(Xj, Xj)' i, j = 1, ... , k.
The proof is given by Zilinskas (1979).
Theorem 5.3.3 shows that the price we must pay for the consistency conditions
(5.3.26) and (5.3.27) is the computation of the inverse Lk1 of matrix Lk with
elements cr( Xj, x), i, j = 1, ... , k. It can be too big if the number of observations k
is large. Besides, the consistency conditions are not necessary when adaptive models
are considered, the distribution function being allowed to change in accordance with
new data.
The idea of Zilinskas for resolving the contradiction is to choose weights from
heuristic considerations, some of which were suggested by Shepard (1965)
k
s1 = s~ (x, Xj,j = 1, ... , k) = d(x,xj) / L d(x,x.)
j=l
J
where
(5.3.28)
It is recommended by Zilinskas (1972) to use c = 3.3, if the scales in Rn are
defined by normalization of the components of x by the standard deviations of the
corresponding components of vectors Xj, i =1, ... , k, (see Zilinskas (1978)).
Another idea, that by Mockus, was described in section 5.2 of this book,
where the adaptive Bayesian models were considered. There it was supposed that

94
s. = { 1,
XE A j
I
_
0,
XE A j
CHAP1ER 5
where A j was uniquely defined by a very natural condition of continuity of the risk
function.
5.4
Maximum likelihood models
The method of maximum likelihood is well known and widely used in mathematical
statistics. So it is quite natural to apply it to the estimation of the most likely point of
a global extremum, when functionf(x) is considered as a sample of some stochastic
function.. The method developed by Strongin (1978) maximizes the likelihood of a
parameter a. of the stochastic function.
f(x) = Il:c + ~:C,
X E {xil cAe R, Xj+1 > Xj, i = 1, ... , n
(5.4.1 )
where ~:c is a Wiener process with parameter em, and Il:c is a fixed function which
depends on paramter a.
r- m(xj - Xi_I)'
i < iex.
ll:C
j = ~
m(xs + Xs-I - 20.), ~ =~
l m(xj - Xj-I)'
I > lex.
Here e and m are both positive and index s is defined by the inequality
In such a case the likelihood function is
(5.4.2)
(5.4.3)
(5.4.4)
Here Yj =f(Xj), i = 1, ... , n.
Part h(zn' a.) of the likelihood function (5.4.4) which depends on a. can be
expressed as

BAYESIAN METHODS IN THE GAUSSIAN CASE
2
2(a - as)
e2(xs -xs_1)
where
Zn = (Xj, Yj, i = 1, ... , n)
95
(5.4.5)
and
a =
s
x -x
s
s-l
2
(5.4.6)
2
Rs = m(xs - Xs_1) +
(ys - Ys- 1)
- 2(y + Y
)
m(x - x)
s
s-l'
s
s-l
The necessary maximum condition is clearly a = as' Hence
Rs
h(zn' a) = --2 .
me
(5.4.7)
This means that the maximum likelihood estimate of a is determined by (5.4.6)
where the optimal index is obtained by condition
s = arg max R .
gt~n
t
(5.4.8)
It is easy to see that when the parameter e~ 0, the functionf(x) will converge
probabilistically to the function Ilx' Hence the minimum f(x) will also converge
probabilistically to the minimum a of Ilx'
The formal proof of this is given by
Strongin (1978).
The unknown parameter m is estimated from mn from the following expression
where
m
=
n
J
1,
M
= 0
1tM , M
n
> 0
n
n
(5.4.9)
(5.4.10)

96
The algorithm of Strongin (1978) is to make the n+1-th observation
CHAP1ER 5
where as is from (5.4.6) and s is from (5.4.8).
It is supposed that A = [a, b] and the first two observations Xi' i = 1, 2 are
made at the ends of the interval A.
The stopping rule is
(5.4.11)
It was shown by Strongin (1978) that this algorithm can be regarded as
asymptotically Bayesian if the losses are defined by a step function (3.5.1) and the
variance parameter c converges to zero.
Unfortunately, it is difficult to generalize this simple algorithm to a
multi-dimensional case, because then the m-dimensional probability distributions of
the global minimum X E A c Rm must be calculated.
In the Bayesian case (5.1.1) we must calculate the one-dimensional probability
distributions of !(x) E R. The latter task is, of course, not an easy one, but it is
obviously much simpler if m > 1.
The idea of Strongin's (1978) method is to transfonn m-dimensional space to
one-dimensional space using Peano type mapping and then to perform the global
optimization by a simple one-dimensional algorithm (5.4.6), (5.4.8).
5.5
The comparison of algorithms
The comparison of algorithms by computer simulation is a rather complicated task.
The first difficulty is how to select a good set of test problems.
The second one is how to define the quality of the algorithm.
The third difficulty is how to put all algorithms in equal conditions.
The convenient way is to select as test problems those problems which are
published in well known papers and preferably have some practical connections.
Such selection helps to arrange the 'competition' of algorithms without the authors
being present.
Under the assumptions of this book the natural way is to define the quality of
the algorithm as the relation between the average deviation of the global minimum and
the computing time.
Unfortunately, the computing time depends not only on the
algorithm, but also on the computer implementation, including the parameters of the
computer and the quality of the programming. These factors are eliminated if the
number of function observations is substituted for the computing time.

BAYESIAN METHODS IN TIffi GAUSSIAN CASE
97
The conditions for the algorithms can be made more consistent if we compare
only algorithms which do not allow adaptation of parameters. The reason is that if
the user is allowed to adjust the parameters of the algorithm to the given function,
then we compare not only the quality of the algorithm, but also the abilities of the
users.
This means that during the competition the parameters of the competing
algorithms should be defined automatically, without the user's help. The user's help
is obviously desirable when real practical problems are considered.
The application of sophisticated stopping rules can also make the comparison
of the algorithms more difficult, because the reason for good results will not be clear.
Is it the good search procedure or the successful choice of the stopping rule? Thus, it
would be desirable to compare the algorithms using the same simple stopping
criterion. For example, to fix the number of observations. The other idea is to fix
the accuracy level to be the same for all algorithms of optimization and to compare the
average number of observations, see Dixon and Szego (1978). Obviously, in this
case, the question as to whether the success or failure of the algorithm of optimization
is due to the search procedure or to the stopping rule, will remain unanswered.
A good example of a set of test functions is the family of two-dimensional
functions with parameters Gij' bij' Cij' dij E (0, 1).
(5.5.1 )
where the number of components I = 7.
This family of functions satisfies our conditions, because it represents the
stress function in an elastic square plate under a cross sectional load and is widely
known, at least by the Soviet scientists. It was considered by Grishagin (1978) to
test the different versions of the method of maximum likelihood (see Strongin
(1978». The full account of the conditions of the experiment was published, so it
was relatively easy to arrange a sort of 'national competition' of algorithms by
comparison of the maximum likelihood methods with other methods, widely known
and used in the Soviet Union, such as LP type uniform search (Sobolj (1969», the
two versions of the one-step Bayesian method (Mockus (1972» and the uniform
random search (Monte-Carlo method).

98
CHAPTER 5
In all cases, after the termination of the global search, a local optimization was
performed using the simplex algorithm of NeIder and Mead (see Himmelblau
(1972)). The local search was carried out only once from the best point of the global
search. Considereing (5.5.1) it was noticed that to do the local optimization more
than once is usually too expensive if the derivative cannot be calculated directly and
so must be estimated using the function differences.
In addition to the completely automatic search, the purely interactive
optimization performed by a well known expert in the field of global optimization
was included.
Fifty sample paths corresponding to the random uniformly distributed
parameters aij' bU' Cij' dUE (0, 1) were considered.
The relation between the percentage of successful cases (when the global
minimum was found) and the total number of observations Nt = N + NL (where NL
is the number of observations for the local NeIder-Mead search) is represented in
Table 5.5.1 and Figure 5.5.1.
Index
2
3
4
5
6
Iteration number
60
48
80
46
46
30
26
90
60
100
56
38
105
62
56
44
110
81
125
80
72
135
92
140
88
86
68
44
68
200
82
52
240
96
84
340
92
370
94
400
100
78
94
Table 5.5.1.
The relation between the percentage of successful cases and the total number of
observations

BAYESIAN MElHODS IN THE GAUSSIAN CASE
%r----r--~----r__---"...-__.
80 t--+------l~H_-."".,./C----+_-""i
60 +--+--+-+-ir:lH---II--r----t----i
40 1---+----l'-7"'~--t----......---I
201---+----+-----+-------lf-----I
99
40
60
100
200
400
N
Figure 5.5.1
Relation of percentage of successful cases and the total number of observations for
different methods
Index 1 corresponds to the adaptive Bayesian algorithm (5.2.7).
Index 2 corresponds to the standard one-step Bayesian algorithm (5.1.1) with
Gaussian a priori distributions (4.4.2).
Index 3 corresponds to Strongin's algorithm (1978).
Index 4 corresponds to uniform random search (Monte-Carlo).
Index 5 corresponds to uniform deterministic LP-search.
Index 6 corresponds to the interactive search procedure performed by an
expert, see Shaltenis (1979).
The results of simulations of the adaptive Bayesian algorithm (5.2.7) using the
family of test function (5.5.1) were even better than those of the standard one-step
Bayesian methods. However, the results of simulation using another set of functions
considered by Mockus, Tieshis and Zilinskas (1978) were different. The reasons are
not yet clear. We only conclude that the adaptive Bayesian model can sometimes
better represent the real situation.
The sort of average deviation (the percentage of successful cases) which was
used by Grishagin (1978) is fairly natural for the methods of maximum likelihood

100
CHAPTER 5
(see Strongin (1978», because in those methods the zero-one type loss function is
assumed. However, Grishagin's definition of the average deviation contradicts the
assumption that the loss function is linear under which the Bayesian method (5.2.1)
was developed. This difference can apparently give some advantage to maximum
likelihood methods.
The family of functions (5.5.1) has some limitations as a set of test functions.
It cannot be generalized to the multi-dimensional case without loss of physical
meaning. It was published only in Russian, so is not easily available to most western
scientists interested in global optimization.
A different family offunctions was included in the 'international competition'
of algorithms of global optimization. The 'competition' was arranged (without the
presence of authors) by Dixon and Szego (1978).
Table 5.5.2 shows the average number of function evaluations required to
locate the global minimum.
The methods were divided into three categories.
1) Trajectory type: Gomulka's implementation (1978) of Branin's method
(1972).
2) Clustering type: Torn's method (1978), the two versions of Gomulka's
implementation (1978) of Torn's method, and Price's method (1978).
3) Sampling type: Fagiuoli's method (1978), De Biase and Frontini's method
(1978) and the one-step Bayesian method (5.1.3).
The idea of the trajectory type method is to move along the anti-gradient line to
the local minimum then possibly to the local maximum and so on.
Clustering type methods define the region of global minimum as a result of the
analysis of clusters representing the local minima
Sampling type methods are sampling the whole area A in order to prepare the
next stage of search.
Two families of functions and two fixed functions were considered.
1) Sheckel's family of functions of four variables,
2) Hartman's family of functions of three and six variables,
3) Branin's function of two variables,
4) Golstein's and Price's function of two variables.

1:0
;J>
><
trl
Methods
Test Functions
CIl
~
Shekel m=4
Hartman n=4
Branin
Golstein
~
Price
:iJ0
n=5
n=7
n=lO
m=3
m=6
m=2
m=2
ti
CIl
Z
Trajectory Type
ffi
Gomulka - Branin
5500
5020
4860
C)
;J>c::
CIl
Clustering Type
CIl
~
2
Torn
3679
3606
3874
2584
3447
1558
2499
(j
3
Gomulka-Tom 1
6654
6084
6144
;J>
CIl
4
Gomulka-Tom 2
7085
6684
7352
6766
11125
1318
trl
1495
5
Price
3800
4900
4400
2400
7600
1800
2500
Sampling Type
6
Fagiuoli
2514
2519
2518
513
2916
1600
158
7
De Biase-Frontini
620
788
1160
732
807
597
378
8
Mockus
1174
1279
1209
513
1232
189
362
Table 5.5.2
Average number of function evaluations to locate the global minimum
0
......

102
Shekel's family of functions:
n
1
f(x) = - L -----
i=l (x-a.{(x-a.)+c.
I
I
I
Ci> 0, A = {x:05,xj5,10,j=1, ... ,m}, m=4,n=5,7,1O.
ai
ci
n
1
4.0
4.0
4.0
4.0
0.1
5
2
1.0
1.0
1.0
1.0
0.2
3
8.0
8.0
8.0
8.0
0.2
4
6.0
6.0
6.0
6.0
0.4
5
3.0
7.0
3.0
7.0
0.4
6
2.0
9.0
2.0
9.0
0.6
7
7
5.0
5.0
3.0
3.0
0.3
8
8.0
1.0
8.0
1.0
0.7
10
9
6.0
2.0
6.0
2.0
0.5
10
7.0
3.6
7.0
3.6
0.5
Table 5.5.3
The parameters of Shekel's function, m = 4.
CHAPlER 5
(5.5.2)

aij
c·
Pij
I
1
3.0
10.0
30.0
1.0
0.3689
0.1170
0.2673
2
0.1
10.0
35.0
1.2
0.4699
0.4387
0.7470
3
3.0
10.0
30.0
3.0
0.1091
0.8732
0.5547
4
0.1
10.0
35.0
3.2
0.03815
0.5743
0.8828
Table 5.5.4
The parameters of Hartman's function, m=3
a··
c·
Pij
IJ
I
1
10.0
3.0
17.0
3.5
1.7
8.0
1.0
0.1312
0.1696
0.5569
0.0124
0.8283
0.5886
2
0.05
10.0
17.0
0.1
8.0
14.0
1.2
0.2329
0.4135
0.8307
0.3756
0.1004
0.9991
3
3.0
3.5
1.7
10.0
17.0
18.0
3.0
0.2348
0.1451
0.3522
0.2883
0.3047
0.6650
4
17.0
8.0
0.05 10.0
0.1
14.0
3.2
0.4047
0.8828
0.8732
0.5743
0.1091
0.0381
Table 5.5.5
The parameters of Hartman's function, m=6
t:C
;I>
~
Vl
~
~
~
Vl
Z
~o
~
~
()
~
tIl
o
w

104
Hartman's family of functions:
A =
{x:O~xj~I, j=I, ... ,m}
n = 4, m = 3, 6.
CHAPTER 5
(5.5.3)
Here Pi is the approximate location of the i-th local minimum,
ai is proportional to eigenvalues of the Hessian at the i-th local minimum,
ci > 0 is the 'depth' of the i-th local minimum (assuming that the interference of
different local minima is not strong).
Branin's function:
!(XI' x2) = a(x2 - bX? + cXI - d)2 + e(I - f> cos Xl + e,
a = 1, b = 5.1(41t2),
C = 5/1t, d = 6, e = 1O,! = 1/(81t)
-5
~ Xl
~ 10, 0
~ X2
~ 15.
There are three minima, all global.
Goldstein's and Price's function:
(5.5.4)
There are four local minima, The global one is at the point (0, -1) with the value
!= 3.

BAYESIAN METHODS IN THE GAUSSIAN CASE
105
Branin's trajectory method corresponds to the movement along the
gradient-anti-gradient line from the local minimum to the local maximum and so on
until, hopefully, the global minimum is reached.
The clustering method of Tom can be described in four steps.
1. Choose initial points by the uniform random distribution.
2. Push the points some steps towards the local minima using a local
optimizer.
3. Find clusters by using a clustering analysis technique.
If a tolerance
condition is met, stop.
4. Take a sample of points from each cluster. Return to step 2.
The local optimizer implemented by Tom's algorithm consists of two elements:
random search and linear search. The random part defines the direction of search.
The deterministic linear part controls the step size.
If in the linear search at least one of the symmetric points is better than the
origin, then the search is made in the direction of the first better point. If the linear
search is successful, the two new points are put on the same line with double
distance.
If neither of the new points show improvement, then a new pair of
observations is taken on a new random line with the distance divided by 2.
The local search stops if the step length is reduced to a given level. Later this
level will be the starting step length when the local search is repeated.
The 'seed' points in the clustering process are selected giving priority to the
points with the smallest function values. The cluster is grown by enlarging the
hypersphere around the seed point as long as the density of cluster remains greater
n
than kjv, where v = Il4AJfl is the region spanned by the points Xl' ... , xk' Here
i=l
Ai, i = 1, ... , n (AI $ ... $ A,J are the roots of the equation det (s - f.J) =0 where S
is the 'covariance' matrix corresponding to the points xl> '" , Xk'
One way to reduce the number of points in the cluster is to rank the points in
each cluster in ascending order of function values and then choose every second,
every third and so on in the hope that function values corresponding to points leading
to a lower local minimum would also be smaller.
This technique has been
implemented by Tom (1979).
In the paper of Gomulka (1978) the two versions of Torn's algorithm were
implemented. In the fIrst version the usual Torn's algorithm for the local search was

106
CHAPTER 5
used. In the second version the variable metrics type algorithm, using numerical
estimates of derivatives, was substituted for the random search routine for local
optimization. The progress of the algorithm was controlled by the current gradient
value in exactly the same way as the original implementati.on had been controlled by
the step size.
The algorithm of Price (1978) combines random search and NeIder and Mead
type routines into a single process. As an initial search, a predetermined number of
trial points is chosen at random. The function is evaluated at each trial point. The
positions and the function values corresponding to each point are stored. Then at
each iteration a new trial point is selected. The function is evaluated at the new point
and its value is compared with the worst point already stored. If the new point is
better than the old, then the latter is replaced by the new. If not, then the trial is
discarded and a fresh new point is chosen. To choose the new trial point the NeIder
and Mead type method was combined with the random choice of simplexes from the
old points.
The empirical rule for the size of the initial set is twenty-five points.
The stop criterion is not unique, e.g. after a specified number of function
evaluations or when N points fall within a sufficiently small region.
The sampling method of Fagiuoli (1978) uses a so called stochastic automaton
as a controller for the search adjusting the search probabilities according to past
experiences.
In Fagiuoli's method the region of interest is covered by a set of 'cells' and a
stochastic automaton is set up to govern the choice of cells. After a set of initial
samples have been taken a cell is selected that is most likely to contain the global
minimum. A local constrained minimum in the cell is obtained by the method of
Biggs (1975). The stochastic automaton is then updated and the procedure repeated
until the probability of further improvement is significantly reduced.
The algorithm of De Biase and Frontini is based on the sampling techniques
proposed by Archetti (1975) which are based upon the idea of Chichinadze (1967).
De Biase and Frontini constructed the spline type approximation to the probability
distribution F(y) = Plf(x) < y} of the objective function when the arguments x are
distributed uniformly in the region A. An estimate is then made of the root F(y) = 0
which means the estimate of the global minimum. It helps to estimate the distance
from the global minimum and so to arrange some stopping rules. The search is
terminated using a local optimization algorithm starting from a fixed number of points
selected from the best points. The important question of how many such points to
choose remains open. This makes the comparison with the other methods more
difficult.
The algorithm of the Bayesian sampling was of the standard one-step type
(5.5.1) with a priori distribution (4.4.2). The number of observations, N, for the

BAYESIAN METHODS IN THE GAUSSIAN CASE
107
global search was fixed. The local minimization was repeated L times from the
points x/,l = 1, ... ,L with lowest deviations 0/ from the expected values.
The
deviation 0/ was determined as follows
(5.5.5)
Here zN(l) =(Ii(Xj), Xj, i =1, ... ,N, i:!: l} and cr(f(x/)lzN(l)} means the conditional
standard deviation. For the local minimization Tieshis (1975) version of the variable
metrics algorithm was used. The local minimization was terminated if the norm of
the gradient was less than 5 • 10-4 or if the value of the function was decreasing less
than 5 • 10-4 in k iterations, where k = 2 if n = 2 and k = 4 if n > 2.
Table 5.5.2 shows the number of observations required to find the global
minimum for different methods and functions. The numbers are from Dixon and
Szego (1978).
The best performance was that of the method of De Biase and Frontini (1978).
Unfortunately there is some ambiguity in the choice of starting points for the local
search. The reasons for the success of the method also remain unclear. It is difficult
to believe that the application of even the very good stopping rule can so drastically
improve the performance of the Monte Carlo method, which is one of the least
efficient methods, see for example Table 5.5.1, index 4.
The second best was the one-step Bayesian method. However this method is
good only in the sense of the minimal number of observations which is a reasonable
criterion only if one observation is very expensive. Otherwise the simpler methods
such as, for example, Torn's (1978) or even Monte Carlo can be preferable. The
simple Bayesian method (5.2.7) was not developed at the time of the 'competition'.
5.6
The
Bayesian
approach
to
global
optimization
with
linear
constraints
So far only rectangular feasible sets have been considered, because in this case the
Bayesian risk function can be minimized approximately using the simplest methods
of uniform search such as Monte Carlo or LP-search.
Now we shall consider a more general case when the feasible region A is
defined by a system of linear inequalities
arX ~ bi' i = 1, ... , k.
(5.6.1 )

108
CHAPTER 5
We shall assume that A is bounded, nonempty and of full dimension, so that A
is a polytope that contains interior points for which the inequalitites (5.6.1) are all
satisfied as strict inequalitites.
It is reasonable to eliminate the linear equalities (if such are present) since this
reduces the dimensionality of the problem correspondingly. This means that the case
(5.6.1) can be considered as a fairly general one.
In case (5.6.1) the simple 'hit-and-run' algorithm can be used to optimize the
Bayesian risk function, (5.1.1) or (5.2.7), because this algorithm generates a random
sequence of interior points whose limiting distribution is uniform (see Mockus
(1987». The algorithm consists of the following steps.
Step 0:
Find an interior point xo. Set n = O.
Step 1:
Generate a direction vector vn with equal probability from one of the
m co-ordinate vectors and their negations.
Step 2:
Determine
T
n
b.-a. x
A.. = _1__
1 _, i = 1, ... , k.
1
T
n
a v
I
A+ = min {A.IA.>O}
l:;;i:;;k
I
1
A- = max. {A. I A. < O}
l:;;i:;;k
1
1
Step 3:
Generate u from a unifonn distribution on [0, 1] and set
(5.6.2)
(5.6.3)
(5.6.4)
(5.6.5)
Step 4:
Set n = n + 1 and go to step 1 unless a stopping criterion n= K is
satisfied.
It was shown by Barbee et al (1986) that the limiting distribution of the
sequence (5.6.5) is unifonn on A.
The number K depends on how accurately we wish to perform the
minimization of the risk function.

BAYESIAN METHODS IN TIIE GAUSSIAN CASE
109
5.7
The Bayesian approach to global optimization with nonlinear
constraints
Let us consider the case where the feasible region is determined by the following
system of inequalities, at least one of them nonlinear
fi(x)
~ 0, (i = 1, ... , k).
(5.7.1)
We shall assume, as in the linear case, that the set A defined by (5.7.1) is
bounded, nonempty and contains interior points for which inequalities (5.7.1) are all
satisfied and strict.
In such a case the 'hit-and-run' algorithm can be applied to optimize the
Bayesian risk (5.2.7) (see Mockus (1987».
This is clearly reasonable if the
calculation of the constraint functionsfi(x) is at least K . M • k times less expensive
than the calculation of the objective function /(x), where M is the number of
constraint functionfi(x) evaluations which are needed to find the intersection of the
linefi(x) = 0 and the corresponding co-ordinate vector v. If the intersection point can
be calculated using an explicit expression, which is possible in the case when.ti(x) is,
for example, a low degree polynomial, then M means the fraction of the amount of
calculations to define the intersection .ti(x) and v in relation to the amount of
calculations to determine the value of the objective function/(x).
In the case of a nonlinear constraint function only step 2 of the hit-and-run
algorithm is different:
Step 2.
Determine
'Aj is such 'A :.ti(x" + "'-i vn) = 0,
(5.7.2)
'A+
min {'A.I'A.>O}
(5.7.3)
j
l~j~k
I
I
'A- = max {\I\<O}
(5.7.4)
j
l~j~k
If the calculation of the intersections (5.7.2) is too complicated, for example if
the equations (5.7.2) have many roots, then an alternative is the penalty function
method when we pay some extra 'price' for the violation of constraints and this extra
price is added to the value of the function to be optimized, which can be the objective
function/(x) or the risk function (5.2.7).

llO
CHAPTER 5
However, there are some serious problems related to the penalty function
approach to global optimization. One of them is how to define the rectangular set B
which includes a feasible set A.
The area of global search is supposed to be the rectangular one. The efficiency
of methods of global search is inverse to the volume of the area of search, so the size
of the set B should be as small as possible.
It can happen that the relation Jl(A)/Jl(B), where Jl is the Lebesgue measure, is
so small that almost all observations will fall outside the feasible region of A so the
problem of global search will degenerate to the search for a feasible region A, which
can be performed more efficiently by some local methods. The simple example is
n
A = {x: L xi ::;; 1, 0
::;; xi ::;; 1,
i = 1, ... , n}.
i=l
In cases with very small relation Jl(A)/Jl(B) the hit-and-run algorithm can be the
reasonable alternative even if the equations (5.7.2) are complicated.
The functionf(x) is not always defined outside the area A. In this case some
extension of f(x) to the wider area B is needed, if we wish to apply the penalty
function approach to minimize f(x).
The correct definition of the penalty function is also not an easy task, because if
the penalty function is too steep, then overflow can be the trouble. If the penalty
function is not steep enough, then the minimising point can be far away from the
feasible region A.
This difficulty is not so important when the penalty function is
applied in the case of local optimization because here the sequential procedure can be
used, gradually increasing the steepness of the penalty function.
5.8
The Bayesian approach to global multi.objective optimization
Probably the most important idea in multi-objective optimization is the concept of
Pareto optimality.
The point xp is called Pareto optimal if there are no such points x E A that
fi(x)
::;; h(xp)' for all i = 1, ... , K
fi(x) < fi(xp), for at least one i .
(5.8.1)
(5.8.2)
We can approximately define the Pareto optimal set X as a by-product of any
global optimization method which satisfies the condition of asymptotic density
(4.2.65). Examples are the method of LP-search and the Bayesian method (5.2.7),
which minimize the weighted sum of objectives fi(X).
In both cases the
approximation set Xn will converge to the Pareto optimal set X for any continuous

BAYESIAN METHODS IN THE GAUSSIAN CASE
111
functions fi(x) and compact feasible set A, in the sense that the distance'n between
any point in X and the nearest point in Xn will converge to zero (it follows from
condition (4.2.65) that 'n -4 0 when n -4 00).
The approximation set Xn is defined by the following conditions: the point
xp E Xn if there are no such points Xj,j = 1, ... , n that
fi(x)
~ fi(xp), for all i = 1, ... , K
fi(x) < fi(xp)' for at least one i .
So if nothing is known about the relations and order of importance of the
objective functions fi(x), then both methods (LP-search and Bayesian) can be
regarded as asymptotically equivalent approximations of the Pareto set X. In this
case the LP-search has the advantage of simplicity.
In practical problems the decision makers usually have some ideas about the
relative importance of different components!i(x) and can express those ideas as some
weights ci corresponding to eachfi. In this case the Bayesian method minimising the
weighted sum (see Mockus (1987))
K
hC<x) = L c);(x), ci > 0
i=l
(5.8.3)
makes a better approximation of the Pareto set in areas where the scalarized objective
is good comparing it with the uniform LP-search proposed by Sobolj and Statnikov
(1981).
The reason is that in the Bayesian case the density of observations around the
best values of the scalarized objective he is considerably greater than in the other
areas. In the uniform LP-search case the density of observations is roughly the same
in all the areas including the area around the largest possible value of the weighted
sum he of objectivesfi(x).
Let us present formally the advantage of the Bayesian approach to multi-
objective optimization.
Let
'aCc) = max IIx -xo"
xeSo
(5.8.4)
Here 50 is a set 5i (see (4.2.110) to (4.2.112) ) around the point Xo with the
minimal observed value he(x) obtained by the Bayesian method (5.2.7)

112
r (c) = max Ilx-x II
u
u
xeSu
CHAPTER 5
(5.8.5)
Here Su is a set Si around the point Xu with a minimal observed value of hc(x)
corresponding to the uniform search.
In the case of constant 111 and increasing cr1 as a function of Ilx - xiII (inside the
sets S)
and
Here
and
ro(c) = ro
ro =
Ilx~ - xoll,
x~ E arg min $(11, cr, c)
xeSo
r
= Ilx' -x II, x' E arg min $(11, cr, c)
u
u
u
u
xeSu
(5.8.6)
(5.8.7)
where $ is from (4.2.79) and (5.1.1).
It follows from the definition of uniformity that in the strictly uniform case
x' E arg min $(11, cr, c)
a
xeSa
(5.8.8)
where Sa is a set Si around the observation nearest to the mean value fa of the
function f(x).
It is convenient to define the relative density of Bayesian and uniform
observations around the point with the best observed value of hc(x) as the relation
r (c)
K
= _u_
a
ro(c)
(5.8.9)

BAYESIAN METHODS IN THE GAUSSIAN CASE
From (5.8.6) to (5.8.8)
Asymptotically from (4.2.120)
K=limK
= (la-/o+E)1I2
c
:1>.....
a
E
,<.0 > 0.
113
(5.8.10)
(5.8.11)
The asymptotic expression (5.8.11) defines the relative density of a Bayesian
search for the Pareto optimal point near the global minimum of a scalarized objective
hc(x).
In this case the correction parameter E can be used to balance the subjective part
of the information expressed by the scalarized objective hc(x) and the objective part of
the information represented by the vector I(x) =11(X), ... ,fix)). If E is large then
we almost neglect the influence of the scalarized function hc(x) and simply seek the
Pareto optimal point by an almost uniform search. If E is small then almost all the
observations are made near the minimum of the scalar hc(x) and only a small
proportion of them will fall into the other parts of the feasible set A.
In some applications the multi-objective optimization is reduced to the
constrained optimization. It is important to notice that such reduction is not always
reasonable because it is much more convenient to consider the scalarized optimization
(5.8.3) than the optimization with constraints, see section 5.7
fi(x)
~ 0, i = 2, ... , K.
In addition the solution of the constrained optimization problem does not
necessarily belong to the Pareto optimum X .
5.9
Interactive procedures and the Bayesian approach to global
optimization
The Bayesian approach to global optimization can be regarded as some formalized
interactive optimization procedure. It was shown by Shaltenis (1979) that the actual
interactive procedures performed by the experts are very similar in the average sense
to the procedures of Bayesian search. It suggests that the formal (Bayesian) and
informal (interactive) procedures of search can be united in the natural way: some of
the observations may be made by interactive procedure, while other observations can

114
CHAPTER 5
be carried out in accordance with the Bayesian techniques. If, for example, we have
some knowledge about the behaviour of a function, we can use it to fix the
co-ordinates of the initial points. If we can get some ideas about the properties of the
objective function, such as the number or location of local minima, then it is
reasonable to do the additional interactive optimization after the Bayesian search. The
latter possibility is especially important if the Bayesian procedure had reached its limit
of observations.
The second important role of interaction is the choice of the parameters of the
local search such as initial points and accuracy.
It can be desirable to control the accuracy and, correspondingly, the time of the
minimization of the risk function interactively, by changing the number of its
evaluations.
In the case of nonlinearly constrained global optimization, the interactive
procedures may be necessary to make the decision as to whether the penalty function
should be used or whether it is better to include the nonlinear constraints into the
minimization of the risk function, see section 5.8.
The interactive procedures are almost inevitable in multi-objective optimization,
for example to change the parameters Cj, during the process of optimization, to
perform additional observations and to make other reasonable modification of the
procedures of search during the optimization, see Mockus (1987).
It is very difficult to design formal procedures to adjust algorithms of the
analysis of structures such as ANALI and the algorithms of optimization.
The
interactive procedures seem to be the most convenient way of arranging such
adjustment.
5.10
The reduction of multi-dimensional data
The efficiency of the interactive procedures, which were discussed briefly in section
5.9, depends on the reduction of the multi-dimensional data such as the co-ordinates
x of the points of observations and the results f(x) to the two-dimensional display
screen. The different methods of doing it can be approximately divided into two
categories.
The first, 'mathematical' one, is to represent each point from multi-dimensional
space in two dimensions with as small a distortion of the distances between the points
as possible. The methods of representation, with different complexity and different
accuracy, are discussed by Everitt (1978).
The second way can be called the 'psychological' one because there the
multi-dimensional data is represented as some familiar image on the screen. Each
parameter of the image is controlled by one dimensional data, for example by the

BAYESIAN METIIODS IN THE GAUSSIAN CASE
115
value of one variable. The most natrural example of the familiar image is the human
face, the different features of which, such as the width and height of the eyes, lips,
nose, ears, head etc. are controlled by different variables.
Because of the well
known ability of human beings to recognize faces, such representation of the
multi-dimensional points can be fairly efficient after some learning experience. The
clear advantage of the representation of different multi-dimensional points as
corresponding human faces is the familiarity of the two-dimensional image.
The disadvantage is the lack of symmetry, because the different variables are
represented as different parts of the face which is only a partially symmetric figure.
If we do not like the asymmetry of such representation more symmetric objects can
be designed to represent multi-dimensional points. Naturally in the case of these
objects we shall not have the familiarity of the human face, so probably more learning
will be needed to relate the multi-dimensional points to the objects.
The usual diagrams which represent each variable:t and the functionf(x) as
corresponding columns can also be useful with a proper choice of scales.
The most natural and convenient way is to show on the computer display, if the
system can be represented graphically, how the picture of the system is changing
during the process of optimization. The objective function in such cases can be
shown as one or more columns.
5.11
The stopping rules
A stopping rule is a natural part of any optimization algorithm.
However, the
importance of stopping rules depends on the type of problem under consideration.
Usually the maximal number of iterations is limited by the available computer time. So
the main task of a stopping rule is to stop the optimization when its continuation is
obviously unreasonable. Such a moment can be clearly defmed for example in convex
problems because here we can usually obtain a good estimate of deviation from the
optimal point. In the case of problems with known Lipshitz constant the estimate of
distance from the global minimum is also obtainable and reasonably good. In the case
of the family of continuous functions even the statistical estimation of the global
minimum is possible only under some additional assumptions about the behaviour of
the distribution function F(y) = P(j(x) < y) on its left 'tail'. This means that the
reliability of estimation depends completely on those assumptions which are not easy
to verify even if verification is possible.
For example De Biase and Frontini (1978) and De Biase (1976) assume that
F(y) can be represented by spline functions of odd degree. Betro (1981) assumes
some a priori distribution on a set of functions F(y) which is updated as a result of a
sample. In this wayan a posteriori distribution is obtained for F(y) for every y.
Boender and Rinnooy Kan (1983) assume some a priori distribution on a set of local

116
CHAPTER 5
minima, namely that a priori each number L of local minima between I and 00 is
equally probable and that the relative sizes of regions of 'attraction' follow a uniform
distribution on the (L-l)-dimensional simplex.
Zigliavski (1985) estimates a global minimum by the well-known, see
Gnedenko (1943), asymptotic expression of extremal statistics. So the problem of
distribution function can be reduced to a simpler problem of estimation of a single
parameter a which shows the asymptotic rate of F(y) in the vicinity of the global
minimum. The parameter a can be estimated statistically from the sample. It can also
be estimated using some a priori knowledge about the behaviour of F(y) around the
global minimum, assuming that in this region F(y) can be represented as some
homogeneous function of degree b.
In both cases the theoretical framework is
acceptable only if at least some of the observations are in the area of global minimum.
However, in this case the usual stopping rules of local optimization can also be used.
If no sample point is near the global minimum then the exact meaning of the 'estimate'
of paramater a is not clearly defined, and so the corresponding estimate of the global
minimum remains without proper justification. The use of an asymptotic expression
for F(y) in the case of a finite number of observations also needs some additional
explanation.
Zilinskas (1986) estimates empirically the number of local minima.
Optimization is stopped if the estimated number of local minima is equal to some fixed
number L, 0 < L ~ 20; see section 9.10 (the description of algorithm UNT). The
second stopping condition of Zilinkas is M-multiply descent to the same local
minimum (in the case of UNT the number M is 3).
Mockus (1963) and (1967) assumed lognormal F(y) and estimated the
minimum by the method of maximum likelihood.
A brief survey of different assumptions used in the estimation of global
optimum is given by Zigliavski (1985).
Different authors support their assumptions by corresponding computer
simulation.
In all reported cases considerable improvement in the efficiency of
optimization was noticed. This means that for each assumption there exists a set of
functions for which the corresponding stopping rule works well.
Unfortunately we must not be too optimistic because here we deal with the
problem of statistical extrapolation, namely the statistical estimation of the global
minimum which, by definition, is usually outside the area covered by the sample. This
means that the quality of estimation can depend more on assumptions than on the
sample data. It is the natural price to pay for extrapolation outside the sample region
when there is no certainty that the behaviour of F(y) will not change completely outside
the sampled area. The problem is made even more difficult by the high sensitivity of
estimates of global minimum to the unknown parameters which define the shape of the
'tail' of the distribution function F(y).

CHAPTER 6
THE ANALYSIS OF STRUCTURE AND THE
SIMPLIFICATION OF THE OPTIMIZATION PROBLEMS
6.1
Introduction
It is well known that the complexity of optimization problems (in the sense of the
difficulty of the solution) usually increases much faster than linearly with the number
of variables. This means that it is easier to solve, for example, a sequence of n
one-dimensional problems than one n-dimensional problem of optimization. The
difference is very great in multi-modal problems. It is usually impossible, or almost
impossible, to find the exact solution of multi-modal optimization. It is permissible
for the solution of the simplified problem to be not exactly the same as the solution of
the original one, if the difference does not exceed the error of the optimization. In the
case of the Bayesian approach it is natural to consider the average error of
simplification.
The most obvious way of simplifying the optimization problem is to fix the
values of some of the less 'influential' variables and to optimise the remaining
problem with the reduced number of variables, if the expected error of such
simplification does not exceed the permissible level.
The other way is to replace the n-dimensional problem by a sequence of
one-dimensional problems if the estimated influence of pairs of variables is not
significant. Many different ways of simplifying the optimization problem exist, but it
is important to estimate the expected error caused by the simplification.
It was shown by Shaltenis and Radvilavichute (1977) that under some
assumptions there exists a relation between the expected error of simplification and
the 'structural characteristics' which can be estimated using results of observations.
One of the interesting applications of structural characteristics is the optimal
enumeration of variables in the case of LP-search. It was shown by Shaltenis (1982)
that the efficiency of LP-search can be significantly increased if the enumeration of
variables corresponds to the highest structural characteristics D j•
6.2
Structural characteristics and the optimization problem
We shall consider the following orthogonal expansion of the functionf(x) defined on
the unit hypercube A
117

118
CHAPlER 6
n
f(x) = c +L J;(X) + ... +
i=l
(6.2.1)
where c is the mean value of the functionf(x) on the cube A under the assumption of
the uniform distribution of x E A, S = 2, ... , n - 1
(6.2.2)
The expansion (6.2.1) is unique if we demand that the mean values of the
components of the expansion should be equal to zero (with the exception, of course,
of the component c).
The expansion (6.2.1) exists for a wide class of functions which are
continuous at any point x E A with the exception of dyadic rational points, see
Shaltenis and Varnaite (1976).
The structural characteristics of the variables and their groups are defined by
Shaltenis and Varnaite (1976) as the variances of corresponding components of the
expansion (6.2.1), namely
D i
I'
= f
(f;1'
I'
(XI' , ... ,XI' )f dx l·
••• dx l· •
l"'s
A
l"'s
1
sIs
(6.2.3)
It is convenient to normalise the structural characteristics by the following
condition
D1•
I' = 1,
S = 1, ... , n.
1'" s
(6.2.4)
The variance off(x)
n
D = t ({(xl' ... , Xn) - c)2 dX1 ... dXn = t Di
+ L L
D i i + ... + D l2...n
(6 2 5)
1<'
. <
12
.•
_11< 12 _n

ANALYSIS OF SlRUCTURE
119
because the components of the expansion are orthogonal.
It was shown by Shaltenis and Radvilavichute (1977) that under the
independence conditions the mean error of simplification is proportional to the sum of
the structural characteristics of the variables or their groups, which are eliminated
from the process of optimization, for example, by fixing their values. This means
that to minimise the error of simplification we should optimise the variables with the
largest structural characteristics.
6.3
The estimation of structural characteristics
The algorithm of estimation of the structural characteristics Dil ...is is based on the
Fourier-Haar expansion of the components of the expression (6.2.1)
f.1•
I'
(XI' , ••• , XI' ) =
I'" sIs
(6.3.1)
il".is
where
Ck
k
are the Fourier-Haar coefficients.
I'" s
The Haar functions are the step functions
2(m-I)/2,
-2(m-l)n, 'f j - 1/2 <
j
l--_X<--
2m- I
2m- I
0,
in the other cases
(6.3.2)
where the integers m and j are defined by the conditions
k
2m-I.
1 2
.
1
2m- I
=
+ j, m = "...
j = , ... ,
and hI(x) = 1.
From (6.2.1) and (6.3.1) it follows that
I
n
f(x) =
L
[LI'=I C~I' Hkl.(x) + ... +
kl .....kn =1

120
CHAPTER 6
(6.3.3)
Here the sum of the indices kl , ... , kn has r components.
The functions Hix),
k = 2, ... , I are the Haar'functions, normalised by the following conditions
hk.(x)
I
2(m-l)/2
(6.3.4)
jl o•oj
and Ck1
.ook:
are the Fourier-Haar coefficients modified to satisfy (6.3.4), (6.3.3)
and H1(x) = 1.
The following algorithm of the estimation of structural characteristics considers
not all but only the largest components of the Fourier-Haar expansion.
Let us begin with the estimation of the coefficient C
j
ko , k j = 2, ... ,I; i =
I
l, ..., n.
The values of ciko are estimated by the average: values of f(x), and the
I
structural characteristics of the corresponding components are estimated by the mean
square of f(x) in the interval where Hk.(x) should not be zero in accordance with
I
condition (6.3.2). The estimate is denoted by D H . The largest D H is defined and
k
k
the estimated value of the corresponding component of the Pourier-Haar expansion is
subtracted fromf(x) and so the modified functionfl (x) is calculated.
The same process is repeated with the sequence of modified fuctions hex),
i = I, ... ,s. In such a way a fixed number of the largest structural characteristics of
the Fourier-Haar expansion are defined.
Because of the orthogonality of the Fourier-Haar expansion the structural
characteristics of variables D j , i = 1, ... , n can be defined simply by summing the
structural characteristics of the corresponding Fourier-Haar functions in accordance
with the expression (6.3.1).
A similar algorithm is used to define the structural characteristics of pairs of
variables as the sums of the structural characteristics of the two-dimensional
components of the Fourier-Haar expansion.

ANALYSIS OF STRUCTURE
121
The estimation of the structural characteristics of a group of more than two
variables can also be done in similar way, but it is much more complicated
computationally.
6.4
The estimation of a simplification error
We shall suppose that the vector of variables x is decomposed into two parts, xI and
x2' with the number of components m < nand n - m, respectively.
We shall
consider the simplification when
(6.4.1)
o
*
*
Here Xl E arg rninf(x l , x2 ) and x2 is fixed.
xl
It was suggested by Shaltenis et al (1976), (1977) that the average error of
simplification (6.4.1) can be estimated by the structural characteristics
o= D2
or by the relation
(6.4.2)
(6.4.3)
In the more general case (where not only two but more different groups of
variables are considered) the average error of simplification is estimated by Shaltenis
(1976) as
D. ,
k.
=
.....:..;1I=-_
I
D.+D.-;
I
II
Herer corresponds to all indices with the exception of the index i.
6.5
Examples of the estimates
(6.4.4)
Table 6.5.1 shows the estimates of the simplification error of different optimization
problems. The first row corresponds to the Steiner problem, see section 8.14, with
four variables.
The second row shows the coefficients ki from (6.4.4) of the

122
CHAPTER 6
electricity meter problem, see section 8.2, in the case where all except two variables
are fixed. The third row corresponds to the very simple test problem/ex) = xl X2'
No.
Problem
n
kl
k2
k3
k4
I
Steiner
4
0.65
0.65
0.84
0.84
2
Electricity meter
2
0.59
0.88
3
lex) = Xl x2
2
0.25
0.25
Table 6.5.1
The simplification error of different optimization problems
Table 6.5.2 shows the structural characteristics of the Steiner problem.
D I
= 17%
D12 = 7%
DB =8%
D2
= 17%
Dl4
8%
D 123 =
2%
D23
= 8%
D 1234 = 8%
D3
=6%
D4 =6%
D24 =8%
D34 =8%
D l24 = 2%
Table 6.5.2
The structural characteristics of the Steiner problem
Table 6.5.3 shows the structural characteristics of variables and their groups of
the well known test problem No. 11, see Himmelbau (1972):
Minimise the function of five variables
lex) = 5.3578547 x~ + 0.8356891xI • Xs + 37.293239xI - 40792.141
under the conditions that
o :::; 85.334407 + 0.0056858x2xS + 0.0006262xlx4 -- 0.0022053xJXs :::; 92
90
:::; 80.51249 + 0.0071317x2xS + 0.0029955xIX2 + 0.0021813xr :::; 110
20 :::; 9.300961 + 0.0047026xJXs + 0.0012547xlx3 + 0.0019085xJX4 :::; 25

ANALYSIS OF STRUCTURE
78
~ xl
~ 102
33 < x2
~
45
27
~ x3
~
45
27
~ X4
~
45
27
~ x5
~
45.
D2
D25
123
0.20
0.20
0.19
0.07
0.05
0.03
Table 6.5.3
The structural characteristics of the Himmelbau problem No. 11
We can see that the sum of only six of the structural characteristics is 82%.
Table 6.5.4 shows the difference between the estimate of simplification error
(6.4.2) and its actual value defined by numerical integration.
No.
Simplification
Average error
1
2
Elimination of x4
Elimination of Xl
Estimated
0.15
0.17
Table 6.5.4
Actual
0.11
0.14
The difference between the estimated error of simplification and its actual value
One of the possible applications of the structural characteristics is the 'optimal'
numeration of variables in the LP-search. The influence of the order of numeration
of variables was investigated using the well known Mandelshtarn problem, see
Shaltenis (1982).
min
(m ax
!f('0I)
o~k:521t
0:51j1 :521t
where
n
f(\Jj) = L Uk cos (k 'I' + Xk)'
k=l

124
CHAPTER 6
Table 6.5.5 shows the average efficiency ratio of LP-search depending on the
numeration order.
The efficiency ratio is defined as the relation
K = N*IN
where Nand N* satisfy the following condition
F(N) = F*(N*).
Here F(N) and F*(N*) show how the minimal value F(N) of the functionf(x) which
is obtained after N observations depends on the number of observations.
The
number N corresponds to the LP-search and the number N* to the Monte Carlo
search.
Numeration order
1
2
3
4
4
3
2
1
Table 6.5.5
K(%)
3.2
-2.4
The efficiency ratio of LP-search
The second row of the table shows that the efficiency of the LP-search can be
less than that of the Monte Carlo search if the order of numeration is opposite to the
order of decreasing structural characteristics.

CHAPTER 7
THE BAYESIAN APPROACH TO LOCAL OPTIMIZATION
7.1 Introduction
There are no practical reasons for using the Bayesian approach to optimize convex
functions without noise.
The well known methods of 'second order' based on a
quadratic approximation such as variable metrics or conjugate gradients are
apparently nearly optimal and usually ensure a superlinear convergence. However, it
is only when there is no noise. The presence of even a small amount of noise can
change the situation completely.
The methods of second order which are so good in the absence of noise are not
at all popular in stochastic programming. Here the methods of practical use are
mostly based on a linear approximation, hence they are of gradient type. An example
of this can be the method of a stochastic quasigradient, see Ermolyev (1976).
These methods are simple and perform reasonably well.
However, some
problems remain which can be considered most naturally in the Bayesian framework.
One of them is the problem of optimal step size.
The well known rules for controlling step size are derived from the
convergence conditions, see Ermolyev (1976) and Blum (1954). At best they ensure
only a sort of asymptotic optimality of a minimax type (see Wasan (1969)). So the
problem of an optimal step size when the number of iterations is not large remains
open and can be conveniently considered by the Bayesian approach, see Mockus
(1984).
The idea underlying the Bayesian approach is that the step size should
minimize the conditional expectation along the line of the stochastic gradient. This
idea was discussed in general terms by Urjasjev (1986) but the relation of the actual
Urjasjev's algorithm to the general idea was not made totally clear.
7.2
The one-dimensional Bayesian model
It is convenient to begin with consideration of the one-dimensional case.
The statistical model will be defined as follows: Let
f~ = d2f(x, 0))/dx2, f x = df(x,O))/dx
andfx = f(x,O)), x E A, 0) E Q.
125

126
CHAPTER?
Suppose that x = 0 is an initial point and thatf; andf x are stochastic functions
defined by some a priori distribution such that
E{ff~dx} = fElf~} dx ,
and there exists such positive a that
Elf~} = a.
Then from (7.2.1) and (7.2.2)
E {fx} = ax+d
and
Assume that the observation is made at the point x = O.
From (7.2.2) and (7.2.4) it follows that
ElfOl
= a,
(7.2.1)
(7.2.2)
(7.2.4)
(7.2.5)
(7.2.7)
E {fo}
= d.
(7.2.8)
The natural and convenient loss function is the linear one, see Theorem 3.2.1
l(x) = Ix - in! Ix.
(7.2.10)
xeA
The corresponding risk function
r~ = E{fx} -E{in!lx}'
xeA
From (7.2.11) and (7.2.5) it follows that
(7.2.11)
r'
-
x -
1/2 aX2 + dx + b - E {in!Ix }
xeA
(7.2.12)

BAYESIAN APPROACH TO LOCAL OPTIMIZATION
or omitting E{in! Ix }
xeA
127
(7.2.13)
If parameter a is positive then the Bayesian decision Xl can be defined by the
following equation (when the initial observation is at the point X = 0)
ax+d = O.
Hence the Bayesian decision
Xl = - dla, if a > 0
and
Xl = arg min 0/2 ax
2 + dx), if a ~ O.
xeA
(7.2.14)
Later, for simplicity (to avoid the calculation of the intersection of the line of
search with the border of area A which is not simple in the multi-dimensional case)
the condition (7.2.14a) will not be used. Instead we shall simply keep the estimate of
parameter a positive; see expressions (7.3.44) and (7.3.45).
The unknown parameters d, a in (7.2.14) are not directly observable.
Conditions (7.2.7) and (7.2.8) show that the derivatives fo and f'o can be used as
estimates of the unknown parameters a and d, unbiased in the a priori probability
space.
Expression (7.2.14) shows that the Newtonian method can be regarded as the
one-step Bayesian method which is optimal in the sense of an average deviation
under conditions (7.2.1) and (7.2.2). This conclusion remains true in the stochastic
case as well, when we observe only the sums
and
h~ = f~ + g~
(7.2.15)
(7.2.16)
(7.2.16.1)
Here g~. g ~ and gx are the independent stochastic variables defined by the noise
probability distributions Po with zero expectations and variances a,,2 a,2, a 2 ,
respectively.

128
CHAPTER 7
Conditions (7.2.15) and (7.2.16) along with (7.2.7) and (7.2.8) mean that h'O,
hoare unbiased estimates of a and d also in the more general probability space which
is a product of a priori P and noise PQprobability spaces.
By the use of the estimates h'o, h'O of d, a in (7.2.14) we have
Xl
= - h'o/h'O, if h'O > O.
(7.2.17)
In this book we are consistently following the assumption that only the values
of the function hx but not the values of the derivatives
h~, h'~ can be observed
directly. In such a case hoandh'O can be expressed only indirectly, for example, as
finite differences h' and h" respectively.
(7.2.18)
and
Suppose that
q2 = qQ.
Then by the substitution of h', h" for ho, h'O from (7.2.17)
where
and
(7.2.19)
(7.2.20)
(7.2.21)
(7.2.22)
(7.2.23)
Formula (7.2.21) defines the length of the next step of a local Bayesian
algorithm, assuming that the next observation is the last one. Expression (7.2.21)
gives the minimum of the risk function when parameters a and d are estimated by h"
> 0 and h 'from (7.2.18) and (7.2.19), respectively.
Suppose that we can 'remember' only the current values of the first and second
derivatives at the point xn or their estimates.
Then according to the one-step Bayesian approach from (7.2.14) we have

BAYESIAN APPROACH TO LOCAL OPTIMIZATION
if the derivativesIx ,I~
> 0 are known, or
n
n
129
(7.2.24)
(7.2.25)
if the estimates h~, h'~ > 0, where
h~ = h ~
and
h'~ = h'~
(see (7.2.15) and
n
n
(7.2.16» are known, or
(7.2.26)
if the estimates h', h" > 0 from (7.2.18) and (7.2.19) are known.
In (7.2.26)
!:J.n =h'2Qo and an =h"qrJco = 1/2.
Here the index n of the parameter kn shows that the step length may depend on
n. The dependence will be defined more precisely later in section 7.3 from the
convergence conditions.
The equalities (7.2.24) to (7.2.26) define the one-step Bayesian methods when
the search is performed along the line, for example along the stochastic estimate of
the gradient, without the comparison of functional values. It corresponds to the
classical methods of stochastic approximation (see Ermolyev (1976) and Wasan
(1969)).
In the Bayesian case it is reasonable to go from the current point to the next one
if the expected gain is non-negative
(7.2.27)
where En >0.
From (7.2.24)
From (7.2.25)
A
= 2k
h'
I h"
if h" > 0
tJn
n
rt
n'
n
and from (7.2.26)
(7.2.28)
(7.2.29)

130
CHAPTER 7
(7.2.30)
The number In shows how many times the lower inequality of condition
(7.2.27) has occurred.
Condition (7.2.27) means that we shall not move from the 'old' n-th
observation as long as it remains better than the new one by at least En' but not for
more than L repetitions.
The restriction to no more than L repetitions is because we want to keep the
asymptotic properties of the Bayesian methods similar to those of the usual methods
of stochastic approximation. It allows us to use the same convergence conditions.
The reason why En should be more than zero can be explained in the following
way.
Expression (7.2.27) shows that the current hx
is a minimum of several
n
stochastic variables while hx _A is a stochastic variable. So if En = 0, then the
n I'n
expected tendency is to remain at the current point. Equality (7.2.27) shows that this
tendency will be balanced if the following symmetry condition holds:
(7.2.31)
It was shown by Senkiene (1983) that if hx _A can be regarded as a Gaussian
n I'n
random variable ~j with zero expectation and standard deviation cr and if hx can be
n
considered as a minimum of n independent Gaussian random variables with the same
parameters, then El = 0, E2 = cr/-vrc.
From Senkiene (1986)
From a Monte Carlo simulation, n = 200
(7.2.32)
7.3
The convergence of the local Bayesian algorithm
Denote by p(Xj, x) the average distance between the two points Xj and Xj
(7.3.1)
where the expectation Eo is defined on the noise probability space. If Xj and Xj are
fixed, then

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
131
(7.3.2)
If the stochastic variables Xj = Xj(ro) and Xj = x/ro), ro E n are different only
on a subset ofn of zero probability Po, then we shall regard them as equal:
(7.3.3)
In such a case average distance can be regarded as usual distance defining some
metric space.
Let us denote transformations (7.2.24), (7.2.25), (7.2.26) and (7.2.27) as
T 1(x), Tz(x), T 3(x) and T4(x) respectively.
Denote the distance between the
transformations Tj and Tj as
From (7.2.18) and (7.2.19)
where
o· = I -Ixn
and
(7.3.4)
(7.3.5)
(7.3.6)
(7.3.7)
Here g' is a random variable with zero expectation and standard deviation
(7.3.8)
where l' is the number of observations performed at each of the two points xn + qo
andxn -qo·
Similarly
h" =r; + 0" + g"
n
where
(7.3.9)

132
and
0" = f' -f'Xn
f' = lfx +q - 21x +Ix -q)lq2
n
n
n
CHAPTER 7
(7.3.10)
(7.3.11)
(7.3.12)
Here gOO is a random variable with zero expectation and standard deviation
1/2
a" = --/2all (VI" + 211)
(7.3.13)
where I" is the number of observations performed at each of the points x = Xn + q and
x = xn- q and 1is the number of observations at the point xnu.
From (7.2.20)
1/2
a" = ...J2alqo(VI"+211)
(7.3.14)
It follows from (7.2.20), (7.3.5), (7.3.6), (7.3.10) and (7.3.11) that
deterministic errors of the approximations 0' and 0" will converge to zero only if
qo ~ O. Unfortunately in such a case the variances a'Z and cr"z of the corresponding
stochastic errors of approximation will increase indefinitely in accordance with
(7.3.8) and (7.3.14).
The square of the distance between the first and third transformations from
(7.2.24) and (7.2.26)
(7.3.15)
If there exists a Lipschitz constant 1- e, 0 < e ~ 1of transformation T 1 and
sup P13 = P < 00
then from (7.2.41) and Collatz (1964) the expression of the upper bound of error of
method (7.2.25) is as follows
*
p(xn, x )
~ pie
where x* is the point of the minimum.
(7.3.16)

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
133
In the general case it is difficult to calculate PI3 from (7.3.15). It is less
complicated, if the error of the estimation of the second derivative is small. It follows
from (7.3.10) and (7.3.14) that the error of the estimations of the second derivative
will be small if 0" ~ 0 and [" ~ I ~ 00.
LEMMA 7.3.1. Suppose that f is twice differentiable and there exist integrable
functions SI' s2 and a positive number 13 such that
and
infh
= 13 > O.
n
(7.3.17)
(7.3.18)
Then from I" ~ 00 and 0" ~ 0 it follows that in the case when the second
derivativer; is known
n
(7.3.19)
and in the case when the estimate h" ofthe second derivative is known
(7.3.20)
Proof. Let
From (7.3.4) and (7.3.9)
f '
f' + 0' + g'
2
2
(xn
xn
)
'Y = r - f" + 0" + g"
xn
xn
(7.3.21)
The expectation of g" is zero and the variance converges to zero with
probability Po.
From this and from the assumption that 0" ~ 0 it follows that if the second
derivativer; is known then

134
2
Y. ~ (0' + g')/f~)
(mod Po)
CHAPTER 7
(7.3.22)
and if the estimate h" is known then
2
Y. ~ (0' + g')lh")
(mod Po)
(7.3.23)
From (7.3.15), (7.3.16), (7.3.17), (7.3.22) and the Lebesgue theorem it
follows that
2
2
0' + g'
2
P13
= (2kn) Eo { ( ~) }
(7.3.24)
xn
0' is deterministic, the expectation of g' is zero and the variance is 0",2. Then
from (7.3.24)
(7.3.25)
In a similar way, from (7.2.23), it follows that
(7.3.26)
In the case of Lemma 7.3.1
(7.3.27)
and
(7.3.28)
where the supremum is defined with regard to all possible values of variables which
are present in the expressions.
From (7.3.16), (7.3.27) or (7.3.28) it follows that the error of the local
Bayesian method
(7.3.29)
and
(7.3.30)

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
135
Inequalities (7.3.29) and (7.3.30) mean that the local Bayesian method will not
necessarily converge even for the convex twice differentiable functions. In this sense
the special local Bayesian method may appear to be less good than the much more
general global Bayesian method which converges to a minimum of any continuous
function; see Theorems 4.2.9 and 4.2.10.
Inequalities (7.3.29) and (7.3.30) show that in order to keep the random part
cr' of the error small we have to use a large step size qo see (7.3.8). However, from
(7.3.5) and (7.3.6) it follows that the deterministic part of the error, especially for
non-symmetric functions, will then be increased.
This means that in order to
minimize the deterministic part of the error we should keep the step size qo as small
as possible. This contradiction is apparenrtly the most important negative factor
explaining the poor convergence inside the region defined by (7.3.29) and (7.3.30).
The r.h. sides of inequalities (7.3.29) and (7.3.30) define the radius of a
sphere (with the minimum at its centre) which will be reached by the method (7.2.26)
after n iterations. It is easy to see that in the Bayesian case, where 2kn should be
equal to 1, the radius will not converge to zero. This means that by the minimization
of the Bayesian risk function (7.2.13) we shall reach only some sphere around the
minimum. The behaviour of the Bayesian method inside the sphere remains unclear.
To provide the convergence of the method to the exact minimum some correction
should be provided. The convenient way to do it is as follows. Outside the region
the parameter 2kn == 1. When the boundary of the sphere is reached the parameters kn
and qo are changed in accordance with the usual rules of stochastic approximation to
ensure the convergence to the exact minimum with probability 1, namely
r 1, if n
~ n' ,
2k
== 1
n
(n _ n,)-(l-(l(,-V), 'f
('
,
)
1 n>max n,n max
IX + V < 0.5, v - IX > 0, 'Yo > O.
(7.3.31)
Here n' is the first n when the boundary of region (7.3.29) or (7.3.30) is
reached.
The maximal number of iterations is restricted by n:nax to meet the
convergence conditions of stochastic approximation.
The condition (7.3.31) means that outside the region (7.3.29) or (7.3.30) we
are using a strictly Bayesian method in the sense that the risk function (7.2.13) is
minimal.
Inside the region the step length should be reduced following the
convergence conditions of stochastic approximation.

136
CHAPTER 7
In a stochastic approximation it is well known, see Wasan (1965), that for
continuously differentiable functions the asymptotically optimal a and v in the
minimax sense are
a = 0,
v = 1/4.
However, from (7.3.8) it follows that small qo means a large random
component of the error a' and a correspondingly low efficiency of search. So in the
local Bayesian methods we shall use much smaller v.
For example, v = 0.01,
a = 0.09 and Yo = 0.2.
Usually we do not know the distance p(xn, x*). The absolute value of the gradientfx
or its estimate h' can be regarded as a reasonable estimate of p(xn, x*), because for
convex functions the value of !fxl is a monotonic function of the distance from the
minimum. If the noise is large we can ignore the deterministic component 8'. In
such a case the boundary of the regions (7.3.29) and (7.3.30) can be estimated from
the inequalities
and
Ih'l ::; 2kn a'/(ef'x )
n
Ih'l ::; 2kn a'/(eh")
The parameter n' in (7.3.31) will be defined as the first n when
Ih'l ::; a'/(eh")
(7.3.32)
(7.3.33)
(7.3.34)
Here 1 - e is a Lipschitz constant of transformation T1 which depends on the
function to be minimized.
If (7.3.34) does not occur before n =n~ax then we shall assume that n =n~ax'
because otherwise the convergence conditions will not be satisfied.
EXAMPLE 7.3.1. Suppose that
Ix = Xl, l'
= 1, L" = 1.
Then

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
and
From (7.3.8), (7.3.27) and (7.3.35)
137
(7.3.35)
(7.3.36)
(7.3.37)
If kn = k then the Lipschitz constant 1 - £ of transfonnation T1 can be defined
from (7.2.24) by the condition
lx.- 2kx. - (x. - 2kx.)1
sup
I
I
)
}
xjER
lxj -x)
x.ER
}
From here
£ = 2k
1-£
(7.3.38)
(7.3.39)
From (7.3.16), (7.3.37) and (7.3.39) the error of the Bayesian method
(7.3.39.1)
If the upper bound of the error does not exceed, for example 0.1, then from
(7.3.39.1)
qo
~ 5/ cr.
(7.3.40)
From (7.3.8) (7.3.34), (7.3.39) and 2k = 1 it follows that n' is the first such n
where
(7.3.41)
In the progam LBAYES implementing the local Bayesian method, see section 9.19,
the expression (7.3.41) is used to optimize not only quadratic but other functions as
well, as an approximation of the inequality (7.3.16) which strictly speaking should
define the switching moment n'. The reason is that usually the exact definition of the

138
CHAPTER 7
Lifshitz constant 1- £ and the distance p(xn, x*), see expression (7.3.16), is a
problem at least as difficult as the calculation of the optimal point x*.
It is easy to see that the local Bayesian method defined by the expressions
(7.2.24) to (7.2.30) can be considered as a version of the usual Newtonian method
when the step length is reduced by the factor kn.
It is well known that the
convergence of the Newtonian method depends very strongly on the second
derivative. So we must take special care with its estimation. The estimate of the
second derivative should be positive, otherwise condition (7.2.14) will correspond to
the maximum of the risk function (7.2.12) rather than the minimum.
Some stability
of the estimate is also desirable in the sense that the deviation from the mean values
should be restricted in some way. To satisfy these conditions we shall define the
estimates a~ as a weighted sum of the past estimates ai' i == 1, ... , n
Lo(l-V)
n
a' =
L ai i V
n
I-v
(7.3.44)
n
i=1
where
a·
if 10-6 ~ ai ~ 106
I
10-6 if ai ~ 10-6
ai =
(7.3.45)
1
if 0.1
~ 10-2
106 if ai ~ 106
The third condition in (7.3.45) provides a reasonably good initial estimate 0.1'
We shall assign La = 1. Here
Condition (7.2.27) implies that the decision whether to go to the next point or
not depends only on the results of the comparison of the observations at points xn
and xn- Pn respectively. The probability of a wrong decision can be reduced if the
function is observed at each point not only once but, say, I and I~ times respectively.
In the case where In > 1
where 10 is the number of repetitions in one iteration and In is the number of iterations
when the observations are performed at the same point xn.

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
139
FOImula (7.3.44) was derived from the following considerations. The average
of differences (7.2.19) can be expressed in the following way
n
jill = lin L h"(i)
i= 1
where h"(i) is the observed value of h" at the iteration i.
From (7.3.46), (7.2.19), (7.2.20) and (7.2.23)
jill = lin f
~
i=1 %
From (7.3.31) and (7.3.47) assuming Yo = 1
n
ji" = lin L iii i v
.
i= I
Since the average of an may be expressed as
whereq0 is the average of qo.
From (7.3.49) and (7.3.47) the average value
n
a~
= lI(nC/o) L iii i
V
i= I
We shall estimate the average qo as
-
(1
)-I-V
qo =
-v
n
(7.3.46)
(7.3.47)
(7.3.48)
(7.3.49)
(7.3.50)
(7.3.51)
and then from (7.3.51) and (7.3.50) the average of Ui which we shall denote as
n
I-v L-
a'
= --
a.i V •
n
I-v
I
n
i=1
(7.3.52)
Suppose that in the expression (7.3.31) the indices n denote only such
iterations where xn+1
::1= x n.
Then the local Bayesian method defined by the
expressions (7.2.29), (7.2.30), (7.3.31), (7.3.43) to (7.3.45) can be reduced to the

140
CHAPTER 7
usual method of a stochastic approximation and so will converge to the minimum
under the same conditions.
7.4
Generalization of a multi-dimensional case
As usual different ways exist to generalize from the one-dimensional case to the case
where x = (Xl, ... , xn). A direct one is to regard the parameters d, a of the Bayesian
statistical models (7.2.4) and (7.2.2) as the multi-dimensional vectors and matrices
respectively. However such a model will contain too many unknown parameters
such as the partial derivatives of the first and second order which must be estimated
from a relatively small number of observations. Also, in this case we shall lose the
simplicity which is the main advantage of the local Bayesian methods when
comparing them with the global ones.
Another way to generalize is to use the same direction of search as in the usual
methods of stochastic approximation and to apply the Bayesian approach only to
optimize the step size.
Here we use the Bayesian methods only to consider the
problem of an optimal step size, which is less conveniently considered in the usual
framework of the stochastic approximation. In this case we need to estimate only the
partial derivatives of the first order to get the direction of search.
The second
derivative along the line of search can be estimated directly using some additional
observations performed on this line.
When the direction S = sn is fixed then the multi-dimensional search is reduced
to the one-dimensional search. The only variable is the distance from the initial point
x n·
Put
(7.4.1)
and
where
Sn = fx / l!fx II
n
n
(7.4.2)
(7.4.3)
f'xn
(7.4.4)
Then from (7.2.28) the optimal length of step

BAYESIAN APPROACH TO LOCAL OPTIMIZATION
where
Is (0) = dis (O)/dp
n
n
and
141
(7,4.5)
Here dliO)/dp means the derivative ofliP) at the point P= O. The gradient
along the fixed direction sn = (s~, ... , s:) can be expressed as a sum
m
f~(O) = L (dl(xn)/()vi) dV/dp
i=l
where
From here
and
From (7.4.6) to (7.4.9) the gradient along the direction s is
m
f~(O) = - L (dl(xJ/dx! )si
i=l
Suppose that the direction s is the direction of an anti-gradient
Si =
s~ = - dl(xn)ldx! / lif~II, i = 1, ... , m .
From (7.4.10) and (7.4.11)
I~ (0) =
lifx II.
n
n
(7.4.6)
(7.4.7)
(7.4.8)
(7.4.9)
(7.4.10)
(7.4.11)
(7.4.12)

142
CHAPlER 7
From (7.4.5) and (7.4.12)
~n = 2k
l!fx 11/ t; .
n
n
n
(7.4.13)
(7.4.14)
(
(0)
n
Ai
i
tJ
=~S
=2k
n
n n
n
Denote the i-th co-ordinate of the step length ~n along the direction sn as ~~.
Then from (7.4.13) and (7.4.5)
df(x )jdxi
n
Denote hx = fx + gx' where gx is a noise with zero expectation and standard
deviation 0" and x = (xl • ... ?).
Since the partial derivatives are unknown we shall use their estimates
h' = (h'} • .... h'",)
where
(7.4.15)
(7.4.16)
and
(7.4.17)
where
(7.4.18)
Here
The second derivativet; along the direction Sn will be estimated by the
corresponding difference of the second order calculated using the results of the
special observations made at the initial points xn and also at two other points located
on the line defined by the direction h' and placed symmetrically in relation to xn.

BAYESIAN APPROACH TO LOCAL OPTIMIZATION
143
In such a case the estimate of the second derivative along the direction h' can be
expressed as
where
q = -vqo
and
Sn = h'/lIh'lI.
By the substitution of h' forfx and h" for f~ from (7.4.14)
n
n
Suppose that l
= qo. Then from (7.4.21) it follows that
where
and
an = h"qo
(7.4.19)
(7.4.20)
(7.4.21)
(7.4.22)
(7.4.23)
(7.4.24)
Parameter kn can be calculated as in the one-dimensional case from the
expressions
r 1
if n
~ n'
2/kn = l (n - nT(l~v) if n > max (n', nmax)
(7.4.25)
where aVare the same as in (7.3.31) and n' is the first n when the boundary of the
region of slow convergence is crossed. This region in the multi-dimensional case
will be defined in the next section, considering the convergence, see inequality
(7.5.32).

144
CHAPTER 7
Expressions (7.4.21) and (7.4.22) are the direct extensions to the
multi-dimensional case of the corresponding one-dimensional expressions (7.2.29)
and (7.2.30). So, the multi-dimensional version of the local Bayesian algorithm is
the sequence
where
rXn-~n if hx _"
::; hx +en
n
I-'n
n
= l Xn
if hx _"
> hx + en and in < L
n
I.ln
n
~n =
(~~, ... , ~:').
(7.4.26)
(7.4.27)
From (7.4.22)
From (7.2.32)
en = 0.9 cr/-V(rr.i).
(7.4.28)
(7.4.29)
in shows how many times the lower inequality in condition (7.4.26) has occurred, i
is the number of observations at the point xn.
7.5
Convergence in the multi-dimensional case
Put
If Xi' Xj are fixed
p2(Xi' x) = Ilxi - x)12 .
We shall regard
if
(7.5.1)
(7.5.2)
(7.5.3)

BAYESIAN APPROACH TO LOCAL OPTIMIZATION
From (7.4.15)
where
and
145
(7.5.4)
(7.5.5)
f.'I
lim
l i m
f(xn ' ..• ,Xn + q0' ... ,Xn ) - f(xn ' ...
,Xn - q0 ' ... , Xn )
2QO
(7.5.6)
g lim -g
1
i
m
(xn •...•xn +qO··..·xn )
(xn .....xn -qO·..··xn )
2QO
(7.5.7)
Here gi is a random variable with zero expectation and standard deviation
(7.5.8)
The second derivativef;
along the direction h' = (h'I' ... , h'm), its estimate and,
n
also, the deterministic and the random errors 0" and gOO, respectively, are defined by
the same expressions (7.3.9) to (7.3.14) as in the one-dimensional case.
The distance between the transformations corresponding to (7.4.14) and
(7.4.21) can be defined as
2
m
P
LP~
i=I
where
PI
(2kn)2 E {--n }
and
l= (ii' _ hi )2
I
It
hit
fXn
(7.5.9)
(7.5.10)
(7.5.11)

146
CHAPTER 7
LEMMA 7.5.1.
Suppose that / is twice differentiable and that there exist the
integrable/unctions Sj, s and the positive number 13 such that
Igil
~ Sj, i = 1, ... , m
inff'x
=
13 > o.
n
(mod Po)
(mod Po)
(7.5.12)
(7.5.13)
(7.5.14)
Then/rom l" ~ 00 and 8" ~ 0 it/ollows that
m
2
p2 = (2k /1/f."
(mcr 2 +"8. )
n
x
£..
I
n
j=l
assuming that the second derivative f'x is known, and
n
assuming that the estimate h" 0/the second derivative is known.
Proof From (7.5.11), (7.3.9) and (7.5.4)
From (7.5.17) and from 8" ~ 0, (J" ~ 0
(7.5.15)
(7.5.16)
(7.5.17)
(mod Po)
(7.5.18)
and replacing the second derivative by its estimate h"
(mod Po)
(7.5.19)
From (7.5.10) to (7.5,13), (7.5.18) and from the Lebesgue theorem it follows
that
(7.5.20)

BAYESIAN APPROACH TO LOCAL OPTIMIZATION
147
Since 0; is detenninistic, the expectation of gi is zero and the variance of gi is
cr,2, then from (7.5.20)
From here and from (7.5.9)
m
2
p2 = (2k)2 1//"2 (m d 2 + "" 0',
)
n
x
k.J
I
n
i=l
In a similar way
2
m
2
p2 = (2k )2 1/h" (md + "" O~ )
n
"-'
I
i=l
(7.5.21)
(7.5.22)
(7.5.23)
From (7.3.16), (7.5.22) and (7.5.23) the square of the error of a local
Bayesian method is
(7.5.24)
and
(7.5.25)
By the substitution of IIh'1I2 for p2(xn, X*) and neglecting the deterministic part
of error oj, i = 1, ... , m from (7.5.25) we have
(7.5.26)
Since outside the region (7.5.26) parameter 2kn is supposed to be equal to 1,
then from (7.5.26)
(7.5.27)

148
EXAMPLE 7.5.1. Suppose that
m
2
Ix = L \ ' l' = 1, l" = 1, kn = k.
i=l
Then
oi = 0 and 0'; = O.
In a way similar to that in example 7.3.1 we have
£ = 2k.
Then from (7.5.27) and (7.5.28) assuming 2k = 1
CHAPTER 7
(7.5.28)
ma,2
-;:r
(7.5.29)
and
Ilh'lI
~
..Jm a'/h".
(7.5.30)
We shall use this definition of the region of slow convergence when the
Lipschitz constant 1 - £ is not known.
From (7.5.8), (7.5.30), (7.4.24) and (7.3.44)
IIh'lI
~
..J(m /(2l') a/a;""
(7.5.31)
Here l' is the number of observations made at each of the points (x~, ... , x ~ +
m)
d ( 1
i
m)
.
1
qo, ... 'Xn
an
Xn, ..·, x n - qo, ... ,xn
,
I =
, ... , m.
From (7.4.23) and (7.5.31)
(7.5.32)
Suppose that in the expression (7.4.25)
the index n denotes only those
iterations where xn+l ::I- x n. Then the local Bayesian method defined by expressions
(7.4.25) to (7.4.29) and (7.5.32) can be reduced to the usual method of a
multi-dimensional stochastic approximation considered by Blum (1954).

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
149
Consequently the local Bayesian method will converge with probability 1 under the
same conditions which are:
ASSUMPTION 7.5.33.
The function Ix is continuous with the continuous
derivatives of the fIrst and second order.
ASSUMPTION 7.5.34. The derivatives of the second order are bounded.
ASSUMPTION 7.5.35. The variance 0" is bounded.
ASSUMPTION 7.5.36. Suppose (without loss of generality) thatlx = 0 if x = 0 and
Ix > 0 if x ::F- O. Then for any positive e there exists the positive p(e) such that from
l!xll ;?; e it follows that Ix;?; p(e) and lID (x) II ;?; p(e) where D(x) is the matrix of
derivatives of the second order.
The multi-dimensional stochastic approximation method is usually defIned as
the sequence
where
lim c
= 0
n.......
n
00Lan =
00
n=1
00
~ a c
<
00
£..
n
n
n=1
f- (a Ie )2 < 00
£..
n
n
n=1
Denote
and
(7.5.37)
(7.5.38)
(7.5.39)
(7.5.40)
(7.5.41)
(7.5.42)
(7.5.43)
(7.5.44)

150
CHAPTER 7
Suppose that the index n denotes only those iterations where xn+l "# xn-
Consider the case when n ~ n:nax' Neither of these assumptions are important in the
asymptotic sense, because they exclude only a finite number of iterations.
From (7.4.2), (7.4.22), (7.4.25) and (7.5.37)
a,jcn = (n - n,)--(l-<Xr-v) la' n'
From (7.3.31) and (7.5.43)
Cn = 'Yo n-v, v > 0, a ~ 0, a + v < 1/2, v - a> 0, 'Yo> 0.
From (7.3.44) nd (7.3.45) there exist a' and a" such that
°< a'
S;
a~ S; a" .
Then conditions (7.5.38) to (7.5.41) hold, because from (7.5.46)
lim C = lim
'\10 n-v =°if v >°'\10 >°
h~OlI
n
:n......
II
,
'II'
From (7.5.45) and (7.5.57)
-v
'Yon
+ C
(
,)l-a-v,
n-n
an
~ f
'Yol (n
1
- a a') =
00 if a
~ 0.
n=l
From (7.5.45), (7.5.46) and (7.5.47)
2 -2v
2(k
,)-2v
00
00
'Yon
roo
'Yo
+ n
" a C = c' +"
-~,...-- = C' +
£.J
n n
£.J
l-a-v
1 a v
n=l
n=n'+1 (n- n')
k=1
k - -
S;
CO' + 'Y~ f. 1/k
l -c.+ v <
00,
if a < v; k =n - n',
k=1
and
00
00
1
2
00
1
2
r (a Ie )2 = C +r (
1
) = c' +r (--)
<
00
n=l
n
n
n=1
(n _ n') -v-o.
k=1
kl-v-c.
if a + v < 1/2.
(7.5.45)
(7.5.46)
(7.5.47)
(7.5.48)
(7.5.49)
(7.5.50)

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
151
This means that under conditions (7.5.33) to (7.5.36) the local Bayesian
method will converge to the minimum with probability 1.
The convergence of a method is, of course, a desirable property. However, if
the number of iterations is small, the minimization of the maximal deviation p2 as
defined by (7.5.16) may be interesting.
Suppose that
From (7.5.8)
cr' = cr/..J2 qQ.
From here and (7.5.16)
where
The minimum of p2 is at the point
7.6
The local Bayesian algorithm
(7.5.51)
(7.5.52)
(7.5.53)
(7.5.54)
It is convenient to write all the expressions which define the local Bayesian algorithm
in one place.
From (7.4.26)
rxn -
~n if hx -p
::; hx + En
Xn+1 = lXn
if hx
n
_1I
n
> hx
n
+Enandln <L
n
Pn
n
where, from (7.4.27)
~n =
(~~, ... , ~:).
From (7.4.28) substituting a~ for an
(7.6.1)

152
From (7.4.29)
£n = 0.9 <J£oI(V1tl).
Usually I =2m and to is the correction parameter, usually £0 = 1.
From (7.4.25)
( 1
if n
~ n'
21k
= i
n
l (n - nT(l--<Xr-V) if n > max (n', nmax)
Here n' is the first n which satisfies the condition
CHAPTER 7
(7.6.2)
(7.6.3)
(7.6.4)
(7.6.5)
It is obvious that the point xn will not necessarily remain inside the region of
slow convergence estimated by the inequality (7.6.5).
It can move out at any
iteration.
As a result the step size will be decreasing not only inside, but sometimes also
outside, the region of slow convergence, which is defined by the following relation:
(7.6.6)
This relation can be derived from (7.5.31) by the substitution of the derivatives
f'
and f~
for their estimates h' and a~/qo·
xn
n
There are several ways of correcting the estimates (7.6.5) or (7.6.6) of the
region. One of them is simply to multiply the r.h.s of (7.6.5) or (7.6.6) by the factor
k' < 1. Then from (7.6.5)
Another way is to allow the possibility of stopping the decrease of kn if we are
clearly outside the region of slow convergence
where k" > k', for example k" =0.5 and k' =0.25.

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
From (7.3.44)
n
a'
= I-v
"
a. i V
n
I-v
£...
I
n
i=1
From (7.3.45)
ai
if 10-6 ~ ai ~ 106
10-6 if ai ~ 10-6
1
if 0.1
~ 10-2
106 if ai ~ 106
From (7.4.23) and (7.4.15)
From (7.4.24), (7.4.19) and (7.4.20)
153
(7.6.7)
(7.6.8)
(7.6.9)
a =
n
hx + qs
- 2hx + hx - qs
'
n
n
n
n
n
(7.6.10)
q = ...Jqo
and
Here the result of the observation at the point xn is denoted by hx .
n
We can observe only the sum of the functionfx and the noise gx so
n
n
where the expectation of gx
is zero and the standard deviation is cr.
n
If ~ is not known, its estimate cr5 is used
(7.6.11)
(7.6.12)
(7.6.13)

154
2
AK
K
.
2
K
.
2
aO = K
0 1 (11K L (fx + g~ ) - (11K L (fx + g: ) ») .
-
;=1
n
n
;=1
n
n
CHAPTER 7
(7.6.13.1)
Here Ao> 0 is the correction parameter, g~ is the i-th sample of noise and K is the
n
number of samples. Since the variance of noise is assumed to be independent ofxn'
the samples at different xn are combined.
From (7.3.31)
qo = 'Yo n-v, 'Yo > 0
where
v > 0,
v + a < 112, v - a > 0, a ~ O.
(7.6.14)
(7.6.15)
In the case of linear constraints the projection operation PA should be applied in
the expression (7.6.1), see Ermoljev (1976)
r PA (Xn - Pn ), if hx _ '7l
~ hx + en
n
I"'n
n
1xn
, if hx _'7l
> hx + en
n
I"'n
n
7.7
Results of computer simulation
(7.6.16)
(7.7.1)
The following unimodal convex test function was considered by Zukauskaite (1987)
3
2
~ (x.
X,)
f(x) = L
"":"+_1
;=1
6
2
where x; e [- 1, 1].
Table 7.7.1 shows the results of computer simulation with different
parameters.

BAYESIAN APPROACH TO LOCAL OPTIMIZAnON
155
Row
Colunm number
No.
1
2
3
4
5
6
7
1
i
m
2
2
5
5
lO
lO
20
2
0
0.05
0
0.05
0
0.05
0
3
Para-
a
0
0.05
0
0.05
0
0.05
0
4
met-
Eo
1
1
1
1
1
1
1
5
ers
Ao
1
1
1
1
1
1
1
6
a'
B
B
B
B
B
B
B
n
7
.L
(Step
B
B
B
B
B
B
B
reduction)
8
i
(Optimum 3.66
3.48
12.32
20.15
41.17
64.20
178.15
Ave.
point)
error
(in lO-3
9
units)
(Last
2.09
2.52
9.35
15.57
41.33
64.15
175.77
.L
point)
Row
Colunm number
No.
8
9
lO
11
12
13
14
15
16
1
20
2
2
2
2
2
2
2
2
2
0.05
0.25
0.05
0.25
0.05
0.05
0.05
0.05
0.25
3
0.05
0.25
0.05
0.05
0.05
0.05
0.05
0.05
0.25
4
1
lO6
lO6
106
1.0
lO6
lO6
2.0
lO6
5
1
lO6
lO6
lO6
1.0
106
1.0
2.0
lO6
6
B
1.0
1.0
B
B
B
B
B
0.4
7
B
S.A.
S.A.
S.A.
S.A.
S.A.
B
B
B
8
231.01
52.24
70.44
6.98
16.32
5.74
6.77
5.93
lO.50
9
231.98
45.89
64.31
24.15
13.61
3.93
7.90
4.40
7.13
Table 7.7.1
Relationship of average error and parameters of the method

156
CHAPTER 7
The best results were obtained by the local Bayesian algorithm defined in
section 7.6 with parameters v =a =0, Eo =Ao= 1.0 (see columns 1, 3, 5, 7).
Column 9 corresponds to the classical algorithm of a stochastic approximation.
Columns 10 to 16 show the results of gradual change from the Bayesian algorithm
(Column 2) to a stochastic approximation procedure of usual type.
The noise corruptingf(x) was Gaussian with zero expectation and the standard
deviation was defined by the expression cr = 0.046..J(m/2) to keep the signal/noise
ratio approximately constant.
The average deviation from the minimum was obtained from twenty random
runs.
The last row corresponds to the points obtained in the last iterations. The
second row from the bottom shows the average value of the functionf(x) at the point
where the minimal function value is observed. The last iteration was usually a better
one.
Judging from the results of simulation the best algorithm is the local Bayesian
one with parameters corresponding to columns 1, 3, 5, 7 derived ignoring
convergence conditions. The best algorithm with convergence conditions is shown
in columns 2, 4, 6, 8.
The Bayesian algorithm (see column 2) was about twenty times better than the
usual algorithms of stochastic approximation (see column 9). This can hardly be
explained by random factors.
The condition Eo = 106, see (7.6.3), means that there will be no repetition of
iterations at the same point. The condition Ao= 106 , see (7.6.13.1), means that the
step length will be reduced after each iteration as it is in the usual methods of
stochastic approximation. The letters S.A. in the 7-th row means the same, only
without the change of the estimate of variance, which follows from (7.6.13.1). The
letter B in the 6-th and 7-th rows means that the Bayesian espressions were used for
the estimation of the second derivative and for the reduction of step size.
The number of iterations in all cases was twenty. The number of function
evaluations was correspondingly 20(4m + 2), because 2m evaluations were used for
the gradient estimation, 2m for the function evaluation and 2 for the estimation of the
second order derivative.
The final form of the Bayesian algorithm as presented in section 7.6 was
derived as a result of theoretical considerations and the extensive computer simulation
using different test functions, see Mockus et al (1987).

CHAPTER 8
THE APPLICATION OF BAYESIAN METHODS
8.1
Introduction
It often happens that the easiest way to explain the possibilities and the area of
application of some mathematical methods is to show how they work in some real life
examples. The investigation of such examples is also useful as an extension of the
set of special test problems which are usually more simple but not representative as
real engineering problems.
The method can perform reasonably well on some
textbook problem and fail on practical tasks. It is not unexpected, because numerical
methods are sometimes tailored to fit the well know test problems. To tailor the
methods to fit the more complicated problems is more difficult especially when the
values of function cannot be expressed explicitly and may only be calculated
algorithmically with possibly some errors.
Thus the investigation of real life problems is useful for both the users and the
developers of a method. To the users it helps to understand the possibilities and
limitations of the methods, and to the developers it shows the strong and weak points
of the methods. In this chapter some practical examples using the methods of this
book will be described. In some cases the analytical expression of the functions and
constraints will be given. In more complicated cases the behaviour of functions will
be only briefly outlined, referring the reader to the original papers for more details.
Since the examples represent a very wide area of apparently disconnected fields
of application, the order of examples is more or less arbitrary.
8.2
The optimization of an electricity meter
This is the first example of the practical application of the Bayesian approach to a real
problem of engineering design. The optimization was done in the early seventies (see
Mockus et al (1962» but the meter is still in production without any significant
change in its basic configuration. The task was to design a more accurate electricity
meter using the open configuration of the magnetic circuit which was less sensitive to
deviations of the technological conditions. It was supposed, at the time, that only the
closed magnetic circuit could provide the high acuracy of the meter. Unfortunately
the closed circuit design is too sensitive to deviations of the technological conditions.
Such deviations were, and still are, common in the factory environments. As a result
157

158
CHAPTER 8
the closed circuit configurations which were sufficiently accurate when produced
under laboratory conditions were not good at all when produced on the production
line.
The objective function was the maximal value of error. The nonlinearity of the
magnetic circuit made the objective function multimodal. Figure 8.2.1 shows how
the cost function depends on two parameters, because at the first stage of
optimization the cost was the objective. Later the cost was considered as a restriction
and the maximal error was minimized
Figure 8.2.1
The cost function ofan electricity meter as a function of two parameters
The multimodality problem was made easier using the parameters of the
existing meter CO-444 as a starting point for the local search using a version of the
gradient method. The Bayesian approach was used to test the hypothesis that the
minimum found is a the global one. The idea of using the Bayesian approach to the

APPLICAnON OF BAYESIAN METHODS
159
optimization of the deterministic function was suggested by the unexpected empirical
observation that the distribution of objective function values is surprisingly close to
the lognonnal distribution when the parameters of the electricity meter are unifonnly
distributed. It was shown by Mockus (1967) that the distribution will be close to
lognonnal if the objective function can be approximately represented as a product of
functions which depend on a relatively small number of variables, when the total
number of variables is large. In the case of the electricity meter, the number of
variables was thirty.
So it was assumed that the a priori distribution of the objective function is
lognonnal and, under this assumption, the hypothesis that the global minimum is in
the vicinity of the local minimum found using the parameters of the existing electricity
meter CO-444 as the starting point, was tested.
Figure 8.2.2 shows the empirical (dotted line) and lognonnal (continuous line)
distributions when the parameters were estimated by the maximum likelihood
method.
(lL)
9
5
/"
./.
0
~
JJ'
0
.",
.Y"
D
~
./
0
.L,
0
~
5
~
/
f
,
112
1005
0.8
0.6
0.4
0.2
o.t
0.0
0.0
0.0
0.0
0.9
F
0.9
-f
a
1
2
$
(n(U-W)
Figure 8.2.2
The distribution of the cost function of an electricity meter

160
CHAPTER 8
The additional test of globality of the results was the repetition of the local
minimization from different starting points. No better local minimum was found.
8.3
The optimization of vibromotors
The efficiency of vibromotors depends on the transfer of energy during the diagonal
impact of the rigid bodies. To describe the process of diagonal impact the so called
stereomechanical model can be used, see Ragulskiene (1974). We shall consider the
special case of a mechanical model where the vibrating body 1 is moving the other
body 2 in a straight line (see Didzgalvis et al.(1976)).
m1Y'i + v3f(y'l - Y3 - Yi) = 0
(mI + m3) v'i + v3 = 0
- v3 f(y't - Y3 - Yi) + u3 + m3Y'3
m2Y'z + Kyi - u3 = 0
o
(8.3.1)
Here
mI and m2 are the masses of the bodies 1 and 2,
VI is the normal displacement of the bodies,
Y'I and Y2 are the tangential velocities of bodies 1 and 2,
Y3 is the tangential deformation of body 2,
v3 and u3 are the normal and tangential reactions of the body 2,
where
v3=H Iv'I-CIVI' u3=H3Y'3+ C3Y3,
cI' c3 are the rigidities, HI' H3 are the coefficients of viscous friction,
f( • ) is the characteristic of dry friction and
K is the coefficient of rolling friction.
The system of equations can be reduced to the normalized form if the surface of
body 2 is described not only by its elasticity but also by its 'mass' m3'
The characteristic of dry friction is approximately expressed as
f(v) = fo 2/n arctg (sv),
where s is a sufficiently large number.

APPLICATION OF BAYESIAN METHODS
161
The initial conditions are defined by the momentary impulse on body 1 under
the angle a
V '1(0) = cos a, y'1(0) = sin a,
The end of the process T is the moment of separation of the masses. In the
design of vibromotors the main variables are the angle of the impact a and the
parameters of the materials.
The angle a defines the initial conditions and the
materials define the parameters hI' h3,fo, Yl' Y2 of the system (8.3.1), where
The quality of a vibromotor can be expressed using the following functions:
a) the loss function in the contact in the normal direction
b) the loss function of friction in the contact
c) the function of useful work
d) the efficiency
e) the velocity of body 2 at the end of the process
Fs = Y'z(T)/p

162
1) the displacement of body 2 at the end of the process
F6 = Y2(T)
g) the defonnation of body 2 in the nonnal direction
The set of feasible points was the rectangular one:
CHAPTER 8
0.2
~ Yl
~ 10,
0.1
~ Y2
~ 0.5,
a
< a. < 1t/2,
0.1
~ hl
~ 0.8
0.1
~ h3
~ 0.8
0.2
~ fo
~ 1.
The functions F l , F7 can be expressed in the analytical fonn and depend on
only two parameters hI and a. where the E-optimal angle is a. = 1t/2 - E, E> O. So
one-dimensional optimization can be used to define the optimal values of parameter
hl which minimize the loss functions F 1 or F7.
To define the other functions F2, ... , F6 numerical integration of the system of
differential equations is necessary.
To perfonn it the well known method of
prediction and correction was used.
Table 8.3.1 shows how the time of numerical integration of the system (8.3.1)
depends on the error of integration R and the 'accuracy' of the mechanical model
l = mllm3' where m3 is the 'mass' of surface. The accuracy of the model is highest
when m3 ~O.
R \ l
10
0.01
0.05
10
1.5
8.0
Table 8.3.1
100
25.0
500
114
The relation of the C.P.V. time in seconds on the accuracy I of the mechanical model
and the error R of numerical integration
Sectional views of functions F2' ... , F6 are unimodal or at least 'bimodal', so
it seems that local methods could be used to optimize functions F 2' ... , F 6'
However the presence of errors of numerical integration can transfonn even the

APPLICATION OF BAYESIAN METHODS
163
unimodal function to the 'multimodal' one unless the accuracy of numerical
integration and, consequently, the time of integration is very high.
The best results were achieved using the global methods and relatively low
accuracy.
Parameters
Objective functions
F2
F3
F4
Fs
F6
hI
global search
0.10
0.10
0.10
0.10
0.10
local search
0.10
0.10
0.10
0.10
0.10
h3
global search
0.10
0.10
0.10
0.10
0.10
local search
0.38
0.10
0.10
0.10
0.10
Yl
global search
0.88
1.52
0.93
0.93
1.53
local search
0.41
1.05
0.73
0.74
1.12
Y2
global search
0.50
0.50
0.50
0.50
0.50
local search
0.50
0.50
0.50
0.50
0.50
global search
10-10
0.92
0.82
0.99
0.91
local search
10-10
0.90
0.94
0.97
0.87
Obj.funct.
global search
10-12
0.05
0.33
0.39
0.74
local search
0.01
0.04
0.35
0.34
0.69
CPU time
global search
32.34
32.34
32.34
32.34
32.32
BESM-6 (min) local search
150
78
92
100
86
Table 8.3.2
The results of the optimization
The co-ordinate optimization
was done using the one-dimensional global
method of Zilinskas (1975), see section 9.15. The results of global optimization are
shown in Table 8.3.2. The local correction of the results was done by the variable
metrics method (see Tieshis (1975)) in three stages: the fIrst with R = 0.01, 1= 10,
the second with R = 0.05, I = 100 and the third with R = 0.05, 1=500.
The results of the last stage of local correction are also shown in Table 8.3.2.

164
8.4
The optimization of a shock-absorber
CHAPTER 8
The mechanical object of two masses is considered. It is supposed that the shock is
an instantaneous impulse and that the object can be represented by a system of linear
differential equations. The shock-absorber contains damping and elasticity so it can
be described as a linear function of deviation and velocity. The parameters of the
shock-absorber should minimize the maximal deviation during the transitional
process.
The mechanical model of the system, see Didzgalvis et al. (1978), is shown in
Figure 8.4.1 where m 1is the first mass, m2 the second mass, HI and H 2 are two
dampers, C1 and C2 are two elasticities.
H,
Figure 8.4.1
The mechanical model of a linear shock-absorber
The differential equations of the mechanical model:

APPLICATION OF BAYESIAN METHODS
165
(8.4.1)
where VI, Vz are the co-ordinates of masses and p(v'z, vz) is the linear action of the
shock- absorber
The shock defines the initial conditions
V1(0) = vz(O) = v'z(O), vi(O) = V = cos a, 0 < a < 1t/2
The end of the transitional process is defined by the condition
There are four parameters of the shock-absorber that can be optimized
Xz = hz = HzI(2mzp),
where
(8.4.2)
(8.4.3)
The area of admissible values ofx is defined as the intersection of the sets:
(8.4.4)
where
Xl = {x:0.l$h 1 $0.8,
0.1$hz $0.8, 0.2$1'1$10, 2$I'z$10}
(8.4.5)
Xz = {x: max I2hzlp v'z + 1'1vzl $
Ul}
O$~T
(8.4.6)

166
where ul and ul are given constants, and x = (Xl' Xl, X3, X4)'
We should minimize the maximal deviation
F(x) =
max Ivi't)I .
O::;«-T
CHAPTER 8
(8.4.7)
(8.4.8)
To calculate the values of function F(x) we must maximize the one-dimensional
multimodal function vl('t). The convenient way to do it is by the one-dimensional
global optimization method, see Zilinskas (1976).
Since the function F(x) is not unimodal, and the observations are expensive, it
is natural to use the global Bayesian method (see Mockus (1984a» after the reduction
of the original problem with nonlinear constraints (8.4.4), (8.4.7) to the more
convenient problem with rectangular constraints
(8.4.9)
where
are the penalty functions, i = I, 2.

APPLICATION OF BAYESIAN METHODS
167
The results of the optimization are given in Table 8,4.1 for two sets of ul and
UI
u2
Optimal F(x)
Optimalx
xl
x2
x3
x4
0.15
8
0.0174
0.566
0.800
7.280
10.0
0.08
2
0.0312
0.140
0.681
0,452
10.0
Table 8,4.1
Results of optimization in the linear case
The case of a nonlinear shock-absorber can be considered in a similar way.
The main difference in this case is that numerical instead of analytical integrationof
differential equations (8.4.1) should be used. The following nonlinear action of the
shock-absorber was considered:
(8.4.10)
The numerical integration of the corresponding differential equations was done
using the standard FORTRAN routines, with step length 0.005, because with longer
steps noticeable deviation from the analytical results was observed.
The results are shown in Table 8,4.2.
ul
u2
Optimal F(x)
Optimal x
xl
x2
x3
X4
Xs
0.02
0.7
0.14
0.20
0.10
0.20
2.09
180
0.02
2.4
0.017
0.163
0.146
0.44
10.0
10000
0.08
2.0
0.017
0.18
0.76
0.50
7.49
10000
Table 8,4.2
Results of optimization in the nonlinear case

168
In the nonlinear case the fIfth variable
was included because the additional parameter C3 appeared.
8.5
The optimization of a magnetic beam deflection system
CHAPTER 8
The function to be minimizedf(x) represents the aberration of the electron beam in a
TV tube, see Grigas et al. (1980). The aberration depends on the ampere turns Xj of
different sections of the beam deflection system, where 0 :s; Xj :s; 200, i = 1, ... , 13.
Aberration is the diameter of the light spot on the screen which defInes the
resolution of the tube.
The aberration was estimated as the maximum of the
deviations of the traces offour electron beams from the trace of the fIfth central beam.
The paths of electrons of all five beams were calculated using the following
differential equations.
dx/dz = u,
dy/dz = v,
(8.5.1)
Here ko= -V(e/2meu), and e, me are the charge and mass of the electron, u is the
anode voltage, 110 is the magnetic permeability and Hx' Hy, Hz are the components of
magnetic fIeld strength (magnetic intensity). An effIcient method of integration of the
differential equations based on cubic splines was developed.
Since the coil consists of many sections the calculation of the magnetic strength
H by the direct summing of the magnetic strengths of all sections is too complicated.
So the coil was represented as a system of distributed three-dimensional currents.
The optimization was done using the fIve algorithms of global optimization. In
global optimization it is reasonable to use different algorithms based on different
ideas and developed by different authors. In such a way we can obtain a deeper

APPLICATION OF BAYESIAN METHODS
169
understanding of the problem and also compare the efficiency of the algorithms under
consideration. Table 8.5.1 shows the corresponding results.
Algorithm No.
1
2
3
4
5
f g
0.51
0.41
0.44
0.46
0.21
fi
0.28
0.29
0.31
0.26
N
403
399
380
308
233
Table 8.5.1
The results of minimization of the aberration of a TV tube using five different
algorithms of global optimization
Algorithm 1 is the uniform deterministic search of LP type, by Sobol (1969),
see section 9.11.
Algorithm 2 is the clustering algorithm by Tom (1978) with the number of
initial points 10, see section 9.12.
Algorithm 3 is the adaptive Bayesian, by Mockus (1984) with the number of
initial points 25, see section 9.9.
Algorithm 4 is the multi-dimensional algorithm by Zilinskas (1981) with
parameters K = 30 and KL = 5, see section 9.10.
Algorithm 5 is the co-ordinate Bayesian by Zilinskas with parameters K = 6,
N =20, £1 =£2 =0.001, i = 1, ... , 13 and initial point x =35, see section
9.15.
fg is the result of global search,
fi is the result of local search from the best point of global search,
N is the total number of observations, including global and local search.

170
CHAPlER 8
The local search was done using the simplex method of NeIder and Mead, see
Himmelblau (1972), with the initial length of the edge of the simplex equal to 40, see
section 9.18.
The number of observations was divided between the global and the local
search by the condition of equal sharing of CPU time.
The exception was the
co-ordinate optimization Algorithm 5, where no additional local optimization was
needed because Algorithm 5 also provides the local minimum. The equal sharing of
the CPU time means that the more complicated global algorithms such as adaptive
Bayesian 3 were using a much smaller number of observations than the simpler
algorithms such as the uniform search 1 or clustering 2. It explains why Algorithms
3 and 4 which are usually more efficient in the sense of numbers of observations did
not behave much better that the simpler Algorithms 1 and 2.
The unexpected result was the success of the co-ordinate optimization
Algorithm 5. To explain it the analysis of the structural characteristics of the function
was carried out by the Shaltenis (1980) method, see section 9.20. The results are
shown in Table 8.5.2.
Variable No.
13
12
11
1
2
3
4
5
Structural
characteristics
20.8
15.8
9.1
6.9
6.7
5.1
4.5
2.9
Table 8.5.2
Structural characteristics of the variables
The analysis was based on the results of 150 observations by the LP grid by
Sobolj (1969), see section 9.11.
The results of Table 8.5.2 show that following Shaltenis and Radvilavichute
(1980) the 13-dimensional problem of optimization can be approximately reduced to
eight problems of one-dimensional optimization, because the combined 'influence'
(variance) of the remaining five variables and all possible combinations of variables
does not exceed 30%. In such a case it is natural to expect that the co-ordinate
optimization of the eight most 'influential' variables will be the most efficient
algorithm.

APPLICATION OF BAYESIAN METHODS
171
8.6
The optimization of small aperture coupling between a rectangular
waveguide and a microstrip line
It is well known, see Mashkovtsev et aI (1966), that if the diameter of apertures
coupling two lines is small in comparison with the wavelength then the coupling
coefficient of the j-th aperture can be expressed as follows
(8.6.1)
where the sign '-' corresponds to the return direction and the sign '+' to the straight
direction, 0> is the radial frequency, Xj is the co-ordinate of the j-th aperture, nj is the
normal to the j-th aperture and £1, Ht and E;+, H; are the normalized wave fields in
the first and second lines respectively. 112, ~ are environmental parameters of the
second line, Y1' Yz are the specific admittances of the first and second lines, Pj is the
coefficient of electrical polarization and Mj is the tensor of magnetic polarization of
the aperture j.
The coupling system of N apertures can be characterized by the direct coupling
factor S+, the return coupling factor S- and directivity Dfwhich are defined by the
formulae
N
S} = - 20 Ig IL
c~ I
.
J
J=1
(8.6.2)
(8.6.3)
It was assumed that the number of apertures N was fixed, and that we should
find such co-ordinates of apertures Xj and such coefficients Pj , Mj , of polarization
which minimize the deviation from the desirable values of the characteristics S+ and S-
andD.
We shall consider the case of four rectangular apertures, see Nikolaev et al
(1984), and will use the well known (see Rao et al (1981» expressions to define how
the values of H, E, P and M depend on the geometrical parameters of the coupling
such as the angle 'Y of waveguide slot, the length of the j-th slot Lj, the width of the
i-th slot dj and the distance between the centres of the j-th slot and the first slot zj-

172
CHAPTER 8
The objective function was defined as the maximal distance of the coupling
factor Sf from the fixed value So:
firx) =
max
IS+ - S+I
6
,
f
0
(8. .5)
f<!.f$f'
The feasible set was defined by the condition that the minimal directivity should
not be less than the prescribed value Do:
(8.6.6)
Here/is the frequency andf andf' are the minimal and maximal frequencies,
respectively.
The angle yand the widths of the waveguide slots dj = d were fixed. To keep
the apertures apart and to eliminate the dependence on the numbering of the apertures
the following conditions were included
ZI = 0,
Zj+l
~ Zj + d/cos y, j = 1, ... ,N - 1,
The lengths of the wave slots were restricted by the condition
L' < £. < L"
-
:J-
(8.6.7)
(8.6.8)
where L', L" are minimal and maximal lengths.
We should minimize the multimodal function (8.6.5) with one convex
constraint
(8.6.6) and
three linear constraints
(8.6.7)
in the rectangular area
defined by (8.6.8).
The variables x = (Xl' ... , x7) where Xi = L i, i = 1, ... ,4,
Xi+4 = Zi+l -Xi, i = 1,2,3,4.
To reduce the problem to minization in the rectangular area a penalty function
of a special kind was introduced in the following way:
The minimization with
constraints
min /(x),
xeA
A = {x: y(x)
~ O} c Rm
was reduced to the unconstrained minimization min /o(x) where
x
(8.6.9)

APPLICATION OF BAYESIAN METHODS
if x EA.
173
(8.6.10)
Here xA is a mapping of x on A and h(x, XA) is an increasing function of the distance
between x andxA'
The function h is better than the usual penalty function in the sense that under
some conditions function!o(x) will have no local minima outside the area A. This is
a desirable property if we wish to find the global minimum by using some local
optimization methods many times from different, not necessarily feasible, starting
points.
In the case of linear constraints it is convenient to define the mapping x on A as
the intersection of the border line of the inequality and the line connecting the point x
m
and some feasible point. In this case for the constraint L
C(ii = b we have the
i=l
following mapping
m
m
xiA = (Xi - ai) (b - L cp)/L ai(xi - a).
i=l
i=l
Here
ai = d/cosy, i=I, ... ,m.
This penalty function was used for the last constraint from (8.6.7)
'IN-l
zN
= '" x. :s;
Z
•
£..
I
max
i=N-l
The optimization was performed in the following way:
(8.6.11)
Step 1: The maximization of the constraint function D under the conditions (8.6.7)
and (8.6.8) by the method of global optimization UNT, see section 9.10.
The
number of initial points was 100, the total number of observations was 500, which is
the maximum for UNT. The method located 16 local maxima not one of which was
considered as satisfactory because the value of the function D was less then Do. So
local optimization was performed from the best points using the variable metrics
procedure MIVAR4, see section 9.16. In this way several different feasible starting
points were found and the local optimization of the objective function (8.6.5) was

174
CHAPTER 8
carried out using all of them as starting points. In this case the nonlinear constraint
(8.6.6) was eliminated using the usual quadratic penalty function:
r[max (0, e + Do - D)]2 where r is large and e >°
is small.
The maximization of lSi - Sol and the minimization of Dfwhere done simply
by comparing the values of lSi - Sol and Df for some fixed number of frequencies
f. This number was smaller for the global optimization and larger for the local one
because the procedures of variable metrics type are rather sensitive to even small
errors of calculation.
Figures 8.6.1 and 8.6.2 show how functions Sf and Df
depend on the frequencyf.
OJ
30
25
/5
Figure 8.6.1
Relation of directivity Df to normalized frequency F = if- f)/(j" -f)
flO
o LO-O-----'-0.2--.....0-4----:0'~6--0~8:----~
Figure 8.6.2
Relation of direct coupling factors Si to normalized frequency F

APPLICATION OF BAYESIAN METHODS
175
The continuous line corresponds to the parameters x fixed by experienced
designers as an initial guess. The dotted line corresponds to the optimized parameters
x. The horizontal lines correspond to the acceptable levels ofSj and Dr-
8.7
The maximization of LSI yield by optimization of parameters of
differential amplifier functional blocks
The deviation from the ratings of parameters which are set by the designer is the
source of rejection of a substantial proportion of LSI because they do not meet the
standards. One way of increasing the yield of LSI is to make the deviation as small
as possible by using better and more expensive technologies. The other way is to
optimize the ratings to reduce the percentage of rejects. Change of ratings during
production is highly undesirable, so the convenient approach is Monte Carlo
simulation when it is assumed that the deviations of parameters from their nominal
values correspond to the same probability distributions, for example, the multivariate
Gaussian one. In this case the objective function is the yield of LSI and it can be
calculated only with some 'noise'.
This noise can be decreased by numerous
repetitions of the simulation process which is usually rather expensive.
Here, we shall consider the simple case of the optimization of only two
parameters of the DA (differential amplifier) shown in Figure 8.7.1 (see Bashkis et
al (1982)).
Figure 8.7.1
The differential amplifier; RI, .., , Rs are resistors and VI' .,. , V4 transistors
It was supposed that the resistors could be subdivided into two parts, one with
width Xl and the other with width x2' The fitness of the DA block was defined as a
function of two parameters: the bias of zero Uo and the lower level of the output
voltage UO. The block DA is considered fit if the following conditions hold

176
and
-2.10-3 $ Uo $ 2.10-3
4.23
$ uO $ 4.37
CHAPTER 8
(8.7.1)
where the units of Uoand uO are volts. Both parameters Uoand uO are defined
using the simplified model of transistors, the so called transconde model which,
according to Bashkis et al (1984) provides sufficient accuracy. (The maximal
deviation from the actual transfer characteristics was 3-4% at 60 times less CPU time
in comparison with the well known transistor model of Ebers and Moll.)
( R 1
'YI
0.1
)
]
x
-
--+--1
+'1' +'1'
R
'V
a.
1
2
2
'2
2
uO = E _
RIa. a. [
Rs + 'Y4
]
R
1 3
R
R
(E - '1'4) - '1'3 + '1'4)
3 + 'Y3
4 +
S+ 'Y4
(8.7.2)
(8.7.3)
Here 'Yi, 'l'i, i =1, ... ,4 are the parameters of the transconde representation of
transistors VI' ... V4 respectively. The dimension 'Yi is Q, the dimension of 'I' is V
and a.i is a non-dimensional parameter, namely the coefficient of current transfer.
The Gaussian statistical model was used to describe the parameters of resistors
Rj and the transistors Yj.
The mean value of the resistance of the resistor Rj was defined as
and standard deviation as
a(R) = 0.33 hldj,
(8.7.4)
(8.7.5)
where Cj is the number of squares laid in a row to make the resistor, R is the sheet
resistivity (ohms per square), dj and h are the nominal values and the standard
deviation of the resistors width.
The mean values and the standard deviations of the transistor parameters are
shown in Table 8.7.1.

APPLICATION OF BAYESIAN METHODS
177
The correlation coefficients of the parameters of resistors are shown in Table
8.7.2.
The violation of conditions (8.7.1) is not the only source of rejects. Another is
defect of the silicon crystal.
Rejects due to the silicon defects will be called
'catastrophic' rejects.
Transistor
Parameter
Mean
Standard deviation
'I'
Y
a
cr('I')
cr(Y)
cr(a)
0.74
23
0.992
8.10-3
0.1
13.10-4
0.76
15
0.992
8.10-3
0.1
13.10-4
0.72
30
8.10-3
0.1
Table 8.7.1
Means and standard deviations of the transistor parameters
Ri
Yi
'l'i
a·I
R-
0.95
0.95
0
0
J
'Yj
0.95
0.95
0
0
'II;
0
0
0.8
0
aj
0
0
0
0.7
Table 8.7.2
The correlation coefficients of the resistor and transistor parameters
The following formula, Valiev (1969), was used to estimate the influence of
catastrophic defects on the yield
K = exp (- O.4gS)
(8.7.6)
Here g is the density of the defects, S is the area of the silicon crystal, K is the
proportion of fit circuits.

178
CHAPTER 8
The area of the silicon crystal of a DA integrated circuit was calculated by the
following fonnula
5
2
S = SA + L [2T1T.(cd. + 2r. + d.) + cd.]
j=l
J J
J J
J
J
J J
(8.7.7)
where S is the area of the resistors together with the area between resistors and
surrounding elements of the integrated circuit, SA is the auxiliary area, Tlj is the layout
coefficient, j is the number of the resistor and rj is the distance between the resistor j
and other elements.
The objective function is the expected number N of good IC from a silicon
wafer of area So:
f(x) = E(N) = SolS exp (- OAgS) M(S)
(8.7.8)
Here M(S) is the proportion of IC which satisfies the conditions (8.7.1).
The widths of the resistors Rl , R2, R3 were denoted by Xl and the widths of
the resistors R4 and R5 were denoted by x2' where
o ::; Xi ::; 2001l.
The optimization was carried out for two levels of technology. The lower level
was described by the density of defects g = 1.0 mm-2 and the standard deviation of
resistor widths h = I.SIl. The higher level was characterized by g = 0.3mm-2 and
h = O.61l. The other parameters were as follows: SA = 0.2mm2, TI = 0.8, rj = 20Il.
cl' c2 = 2.3,
c3 = 1.3,
c4 = 32.7 and C5 = 4.7.
The sheet resistance was
R = 200 QlO and the area of wafer was So = 4.S.103mm2.
The Monte Carlo simulation of the differential amplifier was done using a
multi-dimensional Gaussian random number generator with the mean values,
standard deviations and correlation coefficients of transistor and resistor parameters
shown in Tables 8.7.1 and 8.7.2.
The results of the Monte Carlo simulation are shown in Figure 8.7.2 for the
special case when Xl =x2 =x.
The simulation was repeated 100 times and the
average values plotted. The upper line corresponds to the higher technology and the
lower line describes the lower technology. It is easy to see that the errors of the
Monte Carlo simulation make the lower line 'multimodal'. It was shown by Bashkis
(1984) that unimodality of the lower line can be provided by increasing the number of
repetitions from 100 to 1000 which means 10 times more CPU time. This can be too
much for the statistical optimization if the number of variables is large. It seems that

APPLICAnON OF BAYESIAN METHODS
179
a more efficient way is not to increase the repetitions but to regard the objective
function as the multimodal one and to use the methods of global optimization In this
case the adaptive Bayesian method BAYES1, see section 9.9, was used.
This
provided the optimal widths for the lower technology x = (22, 45) and for the higher
technology x = (10, 33).
The corresponding widths of resistors are given in
microns.
Figure 8.7.2
LSI yield as a function of resistor width
It is not unusual that in planning the production of IC for the lower level of
technology the same parameters which were optimal for the higher technological level
are fixed. This is a very simple but very inefficient way.
For example if, following such an approach, for the lower technology the
widths x = (l0, 33) were chosen then the estimated yield would be 5500 acceptable
IC.
The optimal widths for the lower technology are x = (22, 45) and the
corresponding yield is 8400.
8.8
Optimization of technology to avoid waste in the wet-etching of
printed circuit boards in iron-copper-chloride solutions
The processing plant for the electrochemical regeneration of iron-copper-chloride
solution is considered. The idea is to get a dense sedimentation of copper on the
cathode. However the recycling procedure cannot eliminate all waste: for example,
inevitable entrainment of solution during the etching, the accumulation of excess

180
CHAPTER 8
copper chloride and the evaporation of water and hydrochloric acid.
So it is
important to set such parameters of the plant which minimize the waste and make the
technology as clean as possible. The plant which we shall consider is shown in
Figure 8.8.1 where ES is the etching set, IR is the intermediate reservoir, RS is the
regeneration set, CS is the correction set for the etching solution, BS is the boiler and
WS is the washing set to wash printed circuits (PC).
RS
PC
ES
I
___ J
i
%
<.J......
---,
I
Figure 8.8.1
Block diagram of plant for printed circuit board production
It was proposed by Praparov et al (1967) to consider the problem of reducing
the waste as the minimization of the cost function.
The cost function is defined as a result of the solution of equations of material
balance of the plant for 20000m2 PC per year and includes the cost of materials and
electrical power.
To keep the cathode sedimentation of copper dense during the process of
electrochemical regeneration we should satisfy the following seven inequalities:
1) 0.016
~ Xl ~ 0.035, where Xl is iron chloride, kg r l .
2) 0.08
~ x2 ~ 0.165, where x2 is copper chloride, kg r l .
3) 0.003
~ x3 ~ 0.0069, where x3 is the copper etched from PC, kg r l .

APPLICATION OF BAYESIAN METHODS
181
4) 0.04
::;; x4
::;; 0.07, where x4 is ammonium chloride, kg r l.
5) 0.03
::;; Xs ::;; 0.06, where Xs is hydrochloric acid, kg r l.
6) 1.0 ::;; x6
::;; 2.0, where x6 is the velocity of the flow of electrolyte in the
space between the electrodes, em sec-l.
7) 0.005
::;; xl - 2x3 Ml/Mz ::;; 0.025, where Ml and Mz are the molecular
weight of iron chloride and copper respectively.
The last condition was considered using the penalty function. The minimal
cost of mZ of PC is 0.93 roubles. The optimal parameters are shown in Table 8.8.1.
0.032
0.080
0.003
0.070
0.049
1.40
Table 8.8.1
Optimal parameters of PC technology
The global optimization was carried out by the uniform deterministic search of
LP type by Sobolj (1968) and Dzemyda (1983), see section 9.11, using the analysis
of structure by Shaltenis and Dzemyda (1982) and the grouping of variables by
Dzemyda (1982).
The local optimization was done using the FLEXI method by Himmelblau
(1972), see section 9.18. Fifty observations were made for the analysis of structure
and 500 observations for LP optimization (Dzemyda et al (1984)).
8.9
The optimization of pigment compounds
The problem is to minimize the deviation of the colour of the pigment compound
from some standard colour. The deviation of the compound from the standard can be
defined in many different ways.
We shall consider the two simplest.
The first
objective is the mean square difference of spectral reflectance coefficients
corresponding to thirty-six wavelengths. The second is the difference in colours for a
fixed light source.
It is well known that the difference of spectra can be calculated using the
following formulae
where

182
CHAPTER 8
n
LXS·kA·k
i=1
I
I
I
n
LXS'k
i=1
I
I
m
Here xi is the density of the pigment i, 0::;; xi::;; 1, L
xi = 1, m = 9, Rik is the
i=1
reflectance coefficient of the spectrum for pigment i at wavelength Lk. Coefficient
Rik is usually defined in the corresponding tables, see Barauskas et al. (1980).
Sik is the diffusion of pigment at wavelength L",
Qk is the reflectance coefficient of the standard of wavelength L", defined by
the tables, see Barauskas et al. (1980).
The difference of colours for the fixed source of light with the co-ordinates
z =(zl' z2' z3) where zl =96.8696, Z2 = 99.9994 , Z3 = 112.1363 was defined by
the following formulae
(
3
2)1/2
= L (w.(r(x) - w.(Q»)
j=1
J
J
where
r(x) = (rl (x), ... , r36(x»
Q (Ql' ... , Q36)
wl(r) = 25(100 Y2(r)/z2)113 - 16
w2(r)
13wl(r) (uY(r» - u(z»
w3(r) = 13wl(r) (uY(r» - v(z»
36
Y.(r) = L \jI'k rk,
J
k=1
J

APPLICATION OF BAYESIAN METHODS
Nine pigments were considered:
1. Zinc oxide
2. Red iron oxide
3. Yellow iron oxide
4. Chromium oxide
5. Smoke-black
6. Orange lead glass
7. Dark green cobalt
8. Blue manganese
9. Ultramarine
The different standards for the colour were investigated.
183
m
The condition LXi = 1 was eliminated using the multiplicative penalty function
i=l
F(x) = lCi) exp IlX -xII
wherexi =
X.
I
mLx.
j=l
J
and IlX -xII
1
2m
2
= (-m- -1) LXi
~
i=l
£.JX.
i=l
I
The results ofoptimization by four different methods are shown in Table 8.9.1.
In Table 8.9.1 the following algorithms were considered.
1. The uniform deterministic of Sobolj (1969), see section 9.11, with 3000
observations.
2. The clustering algorithm of Tom (1978), see section 9.12, with 10 initial
points.
3. The adaptive Bayesian by Mockus (1984), see section 9.9, with 25 initial
points and 500 observations.
4. The extrapolation algorithm of Zilinskas (1980), see section 9.10, with
parameters LT = 30 and ML = 3.

fois
Algorithm No.
opt. value
1
2
3
4
Standard
Nis
Objective No.
Objective No.
Objective No.
Objective No.
No.
no. of obs.
1
2
1
2
1
2
1
2
fo
0.048
1.34
0.0046
4.79
0.019
1.07
0.0076
0.0006
N
3596
3439
6298
9042
1150
1934
2765
3128
2
fo
7.54
11.8
0.051
11.8
0.051
11.8
0.051
11.8
N
3508
3328
4330
8007
1065
910
3770
1966
3
fo
0.032
7.54
0.035
2.78
0.026
4.21
0.017
0.00004
N
3651
3508
6462
9826
1145
1324
4075
3839
Table 8.9.1
Results of minimization of spectral and colour differences by four global algorithms for three standard samples and a set of
nine pigments
-
~
()
~@
:;Q
00

APPLICATION OF BAYESIAN METHODS
185
The result of global optimization was corrected using the version of the variable
metrics algorithm by Tieshis (1975), see section 9.16, with the following parameters:
initial step of numerical differentiation 10-4
tolerance of the step length 10-3
tolerance of the norm of gradient 10-4
tolerance of the decreasing function during one iteration 10-4.
Table 8.9.1 shows that methods 3 and 4 are clearly more efficient in the sense
that they provide better results than methods 1 and 2 with less observations.
Comparison of methods 3 and 4 is not so easy because method 4 gives better
function values than method 3, but method 3 needs less observations than method 4.
To arrange an equal number of observations for both methods is difficult
because method 4 stops by its own stopping rule and the number of observations of
method 3 is fixed.
It is possible to force method 4 to stop at the fixed number of observations.
However, in this case, the efficiency of the method can be reduced since a good
stopping rule is one of the advantages of method 4.
Figures 8.9.1 and 8.9.2 show the goodness of fit of the optimized (broken
lines) spectra to the standard spectra 1 and 2, respectively.
0.6
os
02
OJ
/
/.
1\
I.
I.
800
700
600
500
a I.
----'-
~
_'___
_
400
Figure 8.9.1
Spectra of the standard (continuous line) and the composition corresponding to
minimal mean square deviation (dotted line)

186
0.'1
0,/
,00
100
600
700
CHAPTER 8
Figure 8.9.2
Spectra of the standard No.2 (continuous line) and of the compositions
corresponding to minimal mean square deviation (broken line with dots) and to the
minimal difference of colours (dashed line)
The worst fit was in case No.2 which represents an organic dye. However, even in
this case the difference appeared, visually, to be only a tint of the same colour.
The broken line with dots (_._._) corresponds to the minimum of function! 1(x).
The dashed line ( - - -) corresponds to the minimum ofl,(x).
8.10
The least square estimation of electrochemical adsorption using
observations of the magnitude of electrode impedance
The process of inhibited adsorption of an active material in the absence of density
restrictions can be simulated by the elctrical circuit shown in Figure 8.10.1, see
Dzemyda et a1 (1984).
Denote the impedance of the circuit as

APPLICATION OF BAYESIAN METHODS
C2
r----II~----__,
Figure 8.10.1
The electrical circuit
187
To make the observations of electrode parameters more accurate the resistance
R1 is balanced. Then the observed impedance is the difference Zb = Z - Rb, where
Rb is the balancing resistance.
We shall express the magnitude of the impedance as
IZbl = A(C, K, y, R, ro)
where
R = R1-Rb,
C = C1 + C2,
K = R2 C2,
Y = C1/(C1+ C0,
ro = 2rtrf,
Ra
::;; R ::;; Rd,
Ca ::;; C ::;; Cd'
Ka ::;; K ::;; Kd,
Ya
::;; Y ::;; Yd,
and!o is the frequency; the index a denotes the lower limit and the index d indicates
the upper limit of the correponding parameter.
The empirical values of the magnitude of impedance at fixed roj are denoted by
A (roj).
Then the least square estimate of the parameters can be defined by the
following condition
min !(x 1' •.• ,xm )
x1·····xm
where

188
CHAPTER 8
n
!(X1, ... ,Xm) = lin L [A(oo) - A(C, K, y, R, oo)f
i=l
and
Xj
E
[0, 1], j = 1, ... ,m, m =4,
_
K -Ka
_
R -Ra
x2 -
K -K
'
x4
-
R -R
dad
a
The global optimization was done by the uniform deterministic method of LP
type by Sobolj (1969), Dzemyda (1983) and Shaltenis and Dzemyda (1982) with the
ordering of variables by the methods of Dzemyda (1982), using the routine LPTAU,
see seeton 9.11. The number of observations for the analysis of structure was 40
and for the LP optimization was 300.
The local optimization was carried out by Barauskas version of the variable
metrics method, see Barauskas (1984) with parameters as recommended by the
author.
First to estimate the error of optimization, the circuit in Figure 8.10.1 with
fixed parameters was considered. Table 8.10.1 shows the difference between the
actual values of parameters and their estimates.
Parameter
actual value
estimated value
error ofestimation %
C,j.1F
K
Y
R,n
20.90
140.50
0.048
-4.53
21.60
142.00
0.044
-4.41
Table 8.10.1
3.2
1.0
8.3
2.6
Difference between actual and estimated values of the parameters of the electrical
circuit shown in Figure 8.10.1
The maximal error was 8.3% which was considered acceptable and therefore
the method was used in the real problem.
The least square estimates of the

APPLICAnON OF BAYESIAN METHODS
189
parameters C, K, y, R which define the adsorption of atomic hydrogen on the
platinum electrode in solutions 1 N H2S04 and 1 N H2S04 + 2.5.10-3 N Zn2+ are
shown in Table 8.10.2.
Since the adsorption of Zn2+is slow the process was
approximately described by the electrical circuit shown in Figure 8.10.1. (See
Joshida et al (1978).)
Solution
1 N H2S04
+ 2.5.10-3 N Zn2+
E,V
Parameters
C,JlF
K
Y
R,n
Ep =0.12
671
280
0.02
-0.2
Em =0.19
315
180
0.02
- 0.2
Ep =0.16
404
240
0.05
-0.2
Em =0.21
349
240
0.05
-0.2
Table 8.10.2
Estimated parameters of adsorption for two solutions
In Table 8.10.2 the potential Em means the beginning of the adsorption of Hm
and potential Ep defines the peak of the internal transition HI ¢::> Hmo see Hochshtein
(1976).
The results for the solution 1 N H2S04 correspond to similar results by
Hochshtein (1976). The only difference is that r
l in Table 8.10.2 was smaller. In
the presence of Zn2+the specific potential of adsorption is biased towards the anode;
the capacity, which corresponds to the peak of internal transition, is much smaller
and the resistance R is greater.
8.11 Estimation of parameters of the immunological model
The simplest mathematical model of an immune response suggested by Marchuk in
1975, see Marchuk (1980), is the system of nonlinear differential equations
dV/dt = -yFV
dF/dt = pC - TlyFV -IlIF
dC/dt = aFVlt_'I" -1l2(C - Co)
V(O) = Vo, F(O) = Fo = pC011ll> C(O) = Co
(8.11.1)

190
CHAPTER 8
where
v = V(t) is the the density of antigen,
F = F(t) is the density of specific antibodies,
C = C(t)
is the density of plasma cells of mature antibody producers,
Y,P, 11,111,112' a are the unknown parameters of the model, and
't is the delay time.
Zuev (1982) suggested estimating the unknown parameters by maximization of
the likelihood function using the experimental data. The deterministic model (8.11.1)
was extended to the stochastic one, so that the maximum likelihood method could be
used. The stochastic model of Zuev involves some additional parameters so that the
total number of parameters to be estimated is nine; three parameters of the stochastic
part and six parameters of the deterministic part, similar to (8.11.1). The relation
between the parameters of the model and the corresponding values of V(t), F(t) and
C(t) at the points tj , i = 1, ... , K are defined using numerical methods for the
integration of systems of ordinary differential equations with constant time delay
developed by Belykh (1982).
The likelihood function was not convex so the global Bayesian method, see
section 9.9, was used to locate the vicinity of the minimum. In Figure 8.11.1 the
broken line shows how the expected density of plasma cells and its variance depend
on time.
k
~
z
••
/ \
" \
,
\
,
.\
,
'\
I I
I I
\
~I
\
"
oo
600
700
400
zoo
100
100
~
"
I \
\
I
... ,
,
'\
I
\\
/1
~
-::;.~
I~
o o
lO
20
ro
15
Figure 8.11.1
Mean value 11k and variance crfof plasma cell density during immunological reaction

APPLICATION OF BAYESIAN METHODS
191
The continuous line shows the experimental results (average from 10 samples).
The experiments were performed by Asachenkov and Stepanenko. The experimental
results correspond to the reaction of a homogeneous sample of mice to the inoculation
of a nonpathogenic antigen.
8.12
The optimization of nonstationary queuing systems
The simple version of the nonstationary queuing system is considered when the flow
of events is deterministic, with the density of events
(8.12.1)
and the service time is uniformly distributed in the intervals [0, 1!xd and [0, 1!x2]
depending on t, hence the density of the service time
r xl, 0
~ t ~ x3
b(t) = il ~,~
~ t ~ T
The objective function is assumed to be the sum
f(x) = L qj + Xl~ + ~(T -~)
j
(8.12.2)
(8.12.3)
whereL qj is the queuing cost, qj is a queuing time, Xl, ~ are the operational costs
j
per time unit.
The last column of Table 8.12.1 shows the difference between the results of
the corresponding method and the optimal decision. The differences are calculated
using the following formula
o = lx1- 2.301 + ~ - 3.501 +
min
lx~ - 5 - vi
~~
(8.12.4)
The last component of formula (8.12.4) means that the variable ~ is nearly optimal
in the interval [5.0, 9.0]. In (8.12.4) the deviation is calculated using the absolute
values of differences with unit weights, which is assumed to be natural in the
circumstances.

192
No. Method
Start
point
N
CHAPTER 8
T
1
2
3
4
5
6
7
8
9
10
11
12
1 BAYES1
3.23 8.39 9.56 1000
179.4 5.82
2 LBAYES 3.23 8.39 5.56 From no. 1
2.40 3.70 8.31 11699 3.1
0.30
3 BAYES1
2.66 3.51 8.60 11738 2.37
4.01
4 LBAYES 2.66 6.70 4.52 From no. 3
2.39 3.51 8.60 11738 2.56
0.10
5 LBAYES 7.20 6.30 2.94
Random
2.09 3.57 5.10 11699 2.51
0.28
6
5.25 1.75 8.93
2.34 3.70 7.53
0.24
7
2.66 9.24 4.11
2.10 3.51 5.02
0.21
8
4.80 9.65 6.01
2.49 3.92 9.90
0.61
9
8.92 6.69 8.91
2.18 2.72 0.08
5.0
10
6.53 2.48 1.34
2.05 2.89 1.42
4.34
11
7.91 1.15 2.76
5.88 2.79 0.10
9.19
12
4.97 4.84 7.25
2.39 2.71 0.15
5.63
13
5.33 3.09 8.67
2.19 3.64 .5.29
0.24
14
15
16
5.88 2.79 0.10 From no. 11 2.20 2.72 0.63
2.20 2.72 6.31 From no. 14 1.91 2.94 2.21
1.91 2.94 2.21 From no. 15 2.26 3.48 5.67
Table 8.12.1
Results of optimization of a queuing system
6.11
3.74
0.06

APPLICAnON OF BAYESIAN METHODS
193
Three types of method were used. The fIrst type was the sequence of global
and local search, see Nos. land 2 and Nos. 3 and 4. In the case of No.1 BAYES 1
was used with the number of uniform observations LT = 5; in case No.3 the same
global method was used with LT = M = 1000 which means the uniform LP-search.
In cases 1 and 2 the final deviation was 0.30, in cases 3 and 4 it was 0.10. As the
second type, we considered local search with randomly distributed starting points,
see Nos. 5 to 13. The minimal error from all cases was 0.21, the average deviation
was 2.86.
The third type was the local search from a random point represented as a
sequence of three local methods (Nos. 14 to 16).
The best deviation was 0.06.
Column 11 shows the CPU time for the
BESM-6 computer.
We can see that the function is obviously unimodal. In terms of the best result
the deviations of global plus local search (corresponding to Nos. 1 and 2 and Nos. 3
and 4) are similar to the final deviation of the sequence of three local search
procedures (Nos. 14 to 16), or the best of local search procedure repeated nine times
(Nos. 5 to 13).
In terms of numbers of observations the global-local approach (Nos. 1 and 2
and Nos. 3 and 4) was almost three times more economical when compared with the
local-local approach (Nos. 14 to 16).
In terms of CPU time the global-local search NOs. 3 and 4 was best. In this
case the global-local method corresponded to uniform LP-search.
8.13
The analysis of structure of the Steiner problem
The Steiner problem is how to connect a given set of N ~ 3 points by a graph of
minimal length. The Steiner problem is combinatorial because there exists a fInite
number of possible ways of connecting the fIxed points using additional points. This
problem can be reduced to the continuous but multimodal problem of how to defIne
such co-ordinates of n :s;; N - 2 additional points which minimize the sum of the
length of arcs of the minimal connecting graph, see Shaltenis (1976). Such a graph
can easily be found using the well known algorithm of Primm if the co-ordinates of
all points are fixed. The diffIcult problem is to defIne the co-ordinates of n:S;; N - 2
additional points, when the number N of fIxed points is large.
The algorithm of Shaltenis (1975) was used to minimize the length of the
network. The idea of the algorithm is similar to that of the Bayesian algorithm.
The main difference between the Shaltenis algorithm and the regular Bayesian
one as defined by condition (5.1.1) can be described in the following way.
Algorithm (5.1.1), at each
step, defInes a point of the next observation which

194
CHAPTER 8
minimizes the risk function (5.1.1). The Shaltenis algorithm defines not the next
point of observation but the next 'strategy' of search which minimizes the risk
function.
There are n + 1 strategies available: one is the n-dimensional Monte Carlo
search, the other n strategies correspond to one-dimensional uniform random search
along each co-ordinate.
The conditional expectations and conditional variances are defined
approximately by some simple formulae, using the results of observations. The
choice of the descibed algorithm can be explained in two ways:
1. Observations are not expensive, so the simple method should be used.
2. Interdependence of variables is not expected to be be very strong, so the
co-ordinate optimization is reasonable.
The results are shown in Figures 8.13.1 and 8.13.2. The continuous line in
Figure 8.13.1 corresponds to the result of the algorithm after 1225 observations.
The dotted line corresponds to the optimal decision. Figure 8.13.1 shows that the
algorithm found the decision which is near to the global minimum. To fix the exact
minimum it is better to use some procedure of local optimization rather than to try to
do it by increasing the number of observations of the global method.
Figure 8.13.1
Result of minimization ofconnecting graph
Figure 8.13.2 shows how the length of the network depends on the number of
observations. The figure corresponds to the Steiner problem with 12 fixed points (20

APPLICATION OF BAYESIAN METHODS
195
variables). The dotted lines correspond to the usual Monte Carlo procedure, see
section 9.13.
n
50
100
200
500
IOIX! 2000
20
~
!
I:
\',
!
I
\
,,
..
\
,
~
''"
\
........
"-
\
~
3.ZIj
10
HO
135
340
345
3.50
F"
3.55
Figure 8.13.2
The relationship of the length of the minimized graph to the number ofobservations
We can see that the comparative efficiency of the Shaltenis (1975) algorithm increases
with the dimensionality of the problem and with the number of observations.
8.14
The estimation of decision making by intuition on the example of
the Steiner problem
The Steiner problem is a convenient test problem to estimate the errors of decisions
made by intuition. The estimation is interesting because many of the decisions in the
design of large engineering systems are made without any formal optimization
procedures. So it is important to see how muchfcan be gained when the regular
optimization methods are applied. A good point of the Steiner problem is that it is
easy to understand and difficult to solve because the number of local minima is very
large. For example, in the case of ten fixed points, the number of local minima is
more than 2.106.
The usual regression analysis was done using the results of 1500 test problems
under different conditions, see Mockus (1967).
As expected it shows a positive

196
CHAPTER 8
relation between the mean error and such factors as the complexity of the test problem
(number of fixed points), and negative relation of the mean error and the time which
was available to make the decision, the level of education (estimated by years of
education) and the academic grades (in the five grade system).
Unexpectedly it was found that the mean error monotonically depends on the
level of experience (the number of Steiner problems already solved).
The minimal error corresponds to the third problem in the sequence of eight
Steiner problems. The mean error decreased sharply until the third problem and then
increased slowly.
The most obvious explanation of this phenomenon is the
decreasing interest after the consideration of three similar test problems.
The general average was 12% and the minimal error of the best intuitive
decision was 0.2%. This is rather surprising since the problem is very difficult
indeed.

CHAPTER 9
PORTABLE FORTRAN SOFTWARE FOR GLOBAL
OPTIMIZATION
9.1
Introduction
The purpose is to minimize a continuous function
f(x), x
= (xl> ... , x,J
(9.1.1)
wherexE A eRn.
It is assumed for most methods that the set A is a rectangular parallelepiped
A = {x: Qj
:;;
Xj
:;; bj , i = 1, ... , n}
(9.1.2)
because the more general case can be approximately reduced to (9.1.2) using the
penalty function techniques. The general idea is to implement the methods which can
be regarded as optimal in the sense of average deviation. In defining the average
optimality the number of observations is usually taken into account. The procedures
which minimize the risk function should be as simple as possible but some natural
limits exist. For example, in the case of global optimization of continuous functions,
in order to minimize the average deviation the risk function should be minimized. It
cannot be reduced to the unimodal one if the convergence to a global minimum of any
continuous function is to be provided. So it seems that the global Bayesian method
described by Mockus (1984a) is possibly the simplest one which minimizes the
average deviation and converges to a minimum. If the functionf(x) is simple enough
then it can be that a better policy is not to minimize the risk function at all but to take
more observations, which need not be planned optimally.
In such a case it is a good idea to use uniform search, for example the LP type,
see Sobolj (1969).
In this case we lose the average optimality but still have the
convergence. Even the LP-search can be too expensive if the observations are very
cheap. Then we can use the uniform random Monte Carlo search which is very
simple indeed, but in this case we shall have convergence only in the probabilistic
sense. For these reasons both the LP search and the uniform random search are
included in this package. The method of clustering by Tom (1978) can be regarded
as something between the LP search and Monte Carlo.
197

198
CHAPTER 9
For local optimization of continuously differentiabk functions without noise
the methods of variable metrics type seem to be the best. Different versions of those
methods are included: one is for rectangular constraints, the other is for nonlinear
constraints.
For local optimization of nondifferentiable functions with nonlinear constraints
the simplex type method is used, see Himmelblau (1972). If there are some reasons
to expect that the influence of some variables and their groups is considerably greater
than that of others then the method of analysis of structure should be used before the
usual optimization, see Shaltenis and Dzemyda (1982).
For the local optimization of unimodal functions with noise a good compromise
between simplicity and optimality is the stochastic approximation type of methods
with Bayesian step length, see Mockus (1984b).
By adjusting machine dependant constants, the software can be adapted to any
computer with a standard FORTRAN compiler. No machine dependent routines are
used.
9.2
Parameters
The parameters X, A, B, N, FM, IPAR, PAR, IPA, IPAA are used in all
subroutines.
X is an array of length N which defines the co-ordinates of a point being considered
(initial, optimal or current).
A is an array of length N which defines the lower bounds of X.
B is an array of length N which defines the upper bounds of X
N is the number of variables (dimension of X) usually N ~ 20.
FM is the value of function FI(X, N) at the point X.
IPAR is the array of length 30 which defines the integer control parameters.
PAR is an array of length 30 which defines the real control parameters.
IPA is the shift of integer control parameters.
IPAA is the shift of real control parameters.

FORmAN SOFIWARE
If only one method is used then both shifts are zero: IPA = 0 and IPAA = O.
199
If several methods are used sequentially then the shift for the next method must be
equal to the sum of numbers of control parameters used before by other methods.
The number of control parameters of different methods are given in Table 9.3.1. For
all the methods the fIrst integer control parameter is the printing parameter:
IPAR(IPA + 1) = IPR
(IPA = 0 if only one method is used)
IfIPR < 0
then only diagnostic messages are printed,
ifIPR =0
then the initial data, the fmal results and the diagnostic messages are printed,
ifIPR >0
then not only those but also the results of each IPR-th iteration are printed.
The meaning of other control parameters will be explained later when describing
corresponding subroutines.

200
CHAPTER 9
9.3
Methods available
No.
Name
Method
No.of control parameters
Integer IFAR Real PAR
Global QPtimization with rectangular constraints
1
BAYES1
Bayesian, see Mockus (1984a)
3
0
2
UNT
Extrapolation, see Zilinskas (1982)
4
0
3
LPMIN
Uniform deterministic, see Shaltenis
and Dzemyda (1982) and Sobolj
(1969)
N+3
0
4
GLOPT
Clustering, see Tom (1978)
3
0
5
MIGI,MIG2
Uniform random
2
0
6
EXTR
Bayesian one-dimensional, see
Zilinskas (l978b)
3
2
Local optimization
7
MNAR4
Variable metrics with rectangular
constraints, see Tieshis (1975)
4
4
8
REQP
Variable metrics with nonlinear
constraints, see Biggs (1974)
4
4
9
FLEXI
Simple with nonlinear constraints,
see Himmelblau (1972)
4
2
Local optimization with noise
10
LBAYES
Stochastic approximation with
Bayesian step length and
rectangular constraints, see Mockus
(I984b)
3
2
Analysis
of structure
11
ANAL1
Estimation of influence of variables
and their pairs, see Shaltenis and
Radvilavichiute (1976)
5
0
Table 9.3.1

FORlRAN SOFlWARE
9.4
Common blocks
201
/BS1/ Y(1000) are the values of function FI(X, N) at the points fonn the array XN of
length MN = N * M which contains co-ordinates of M points of function evaluations
/STATIS/ IFAIL, IT, 1M, M
Here
IFAIL is the control indicator if the initial data is not correct
then
IFAIL = 10 and return to the main program,
if the initial data is correct then IFAIL* 10 and shows the number of the termination
criterion
IT is the number of iterations,
1M is the number of the optional iteration (where the best point was found),
M is the number of function evaluations (observations).
9.5
The function
The function to be minimized should be represented as real function FI(X, N)
In most methods only the lower and upper bounds should be fixed by arrays A and B
In methods with nonlinear constraints the subroutine
CONSTR (X, N, G, MC)
should be used, where
G is a one-dimensional array of length MC which defines the constraints at the
point X
MC is the number of constraints

202
CHAPTER 9
It is well known that the local methods of optimization generally are sensitive
to the scales of variables. The parameters of local methods in this package usually are
adjustedto the case when
A(l) = -1 and B(l) = 1, I = 1, N. So it can be useful
to reduce the rectangular constraints A ::;; X ::;; B to the N-dimensional hypercube
[-1, I]N, which can be arranged using the reduction formulae (in the case of
LBAYES those formulae are included in the algorithm, so here no additional reduction
is needed).
The reduction formulae are as follows
X(l)
2
B(l) +A(l)
= B(l) -A(l) XO(l) - B(l) -A(l) ,I = 1, N
where XO are the original variables and X are the variables scaled to fit into [-1, I]N.
EXAMPLE.
In most of the following examples of methods, the following test
functionf(x) is used
f(x)
(9.5.1)
with N = 2, xl E [- 0.25; 0.5], x2 E [- 0.125; 0.625]
which is represented by subroutine function FURASN:
FUNCTION FURASN (X, N)
DIMENSION X(N)
F=O
DO 10 1= 1, N
XI=X(I)
10 F=F + XI * XI - cos(l8 * XI)
FURASN = F*(2./FLOAT(N))
RETURN
END

FORTRAN SOFIWARE
9.6 The main program
203
The main program defines the input data and the sequence of methods.
At the
beginning we should choose, from Table 9.3.1, the desirable sequence of methods of
optimization and analysis. Then the function FI(X, N) is prepared which evaluates
the objective function at a fixed point X.
If necessary the subroutine
CONSTR (X, N, G, MC) is included which evaluates the constraints at the point X.
The length of arrays usually depends on the subroutines which are used. The length
of arrays IPAR and PAR is always 30. The parameters of methods are included in
the arrays IPAR, PAR in accordance with the given sequence of methods.
The
formal parameters IPA, IPAA are fixed using the rules given in the previous section.
In the case when only one method is used IPA = IPAA = O.
9.7
The example of the main program
The following test problem is considered. The global minimum of test function
(9.5.1) should be defined using the global Bayesian method BAYES I, then the
results of global search should be corrected by the local method of variable metrics
MIVAR4. The test function is represented as the function FURASN (X, N).
The arrays are: X, A, B, XN, HES, IPAR, PAR.
It follows from Table 9.3.1 that in the subroutine BAYES 1 three integer
parameters, and in subroutine MIVAR4, four integer parameters are used.
In
MIVAR4 four real parameters should be defined. This means that seven elements of
IPAR and four elements of PAR should be fixed.
The main program:
DIMENSION X(2), A(2), B(2), XN(200), HES(3), IPAR(30), PAR(30)
DATA N, NM, NH, IPA, IPAAl2, 200, 3,0,01, AI -0.25, - 0.125/, B/O.5,
0.6251
DATA IPAR/O,IOO, 0, 100,2, 100,23*01, PAR/IOO., 3*l.E-4, 26*0./
CALL BAYES1 (X, A, B, N, XN, NM, FM, IPAR, IPA)
IPA=3
CALL MIVAR4 (X, A, B, N, HES, NH, FM, IPAR, PAR, IPA, IPAA)
STOP
END
FUNCTION FI(X, N)
DIMENSION X(N)
FI=FURASN (X, N)
RETURN
END

204
9.8 Description of routines
CHAPTER 9
In this chapter the general description of routines corresponding to different methods
of global and local optimization will be given. The general description of routines
includes the name and purpose of the routine, the restrictions and the accuracy. It
also shows how to use the routine. A simple example is provided.
The FORTRAN codes are given separately in the diskette, because the
complete listings are needed only for advanced users who want to check or to change
the parameters and procedures of optimization.
In the general description of
algorithms and programs only the most important information is provided.
9.9
BAYES1: the global Bayesian method by Mockus
PURPOSE.
To find the global minimum of a continuous function (9.1.1) of N
variables defIned on the rectangular parallelepiped (9.1.2).
RESTRICTIONS.
In terms of efficiency this program becomes increasingly less
successful as the dimensions of the parallelepiped increase. So the dimensions must
be as small as possible
The global Bayesian method uses a considerable amount of auxiliary
calculation.
As a result no more than 1000 function evaluations can be performed.
This means that BAYES1 can be efficiently used only when the function f(x) is
difficult - takes more CPU time, than the calculation of the co-ordinates of the next
point. The global method does the search in the whole area. It can find the point in
the neighbourhood of a global minimum but cannot always fIx the point of minimum
with suffIcient accuracy. So some local methods should be used to carry out the local
minimization.
ACCURACY.
The global method provides the minimal average deviation in
accordance with a given statistical model, see Mockus (l984a) and the convergence to
a global minimum for any continuous function. This means that if we solve many
problems the average error will be as small as possible. However, for some fIxed
samples it can be large if the iteration number is limited.

FORTRAN SOFfWARE
HOW TO USE THE METHOD
CALL BAYESI (X, A, B, N, XN, NM, FM, IPAR, IPA)
where the input is: A, B, N, NM, IPAR,IPA
and the output is X, XN, FM.
205
XN is an array of length NM = N * M which contains co-ordinates of M points of
function evaluation.
In the main program the following arrays should be described:
A(N), B(N), X(N), XN(NM), IPAR(3O)
N~20
IPAR(I) = IPR is printing parameter
IPAR(2) = M is number of function evaluation M ~ 1000.
IPAR(3) = LT is number of initial points which are uniformly distributed by the LP
sequences of Sobolj (1969)
O<LT~M.
EXAMPLE. The program locates the minimum of the multimodal function (9.5.1).
IPR = 0, M =100, LT =5. The initial information is fixed by DATA.
DIMENSION X(2), A(2), B(2), XN(200), IPAR(30),
DATA N, NM, IPA/2, 200, 01, AI - 0.25, - 0.125/, B/O.5, 0.6251
DATA IPAR/O, 100,5,27*01
CALL BAYESI (X, A, B, N, XN, NM, FM, IPAR, IPA)
STOP
END
FUNCTION FI(X, N)
DIMENSION X(N)
F!=FURASN (X, N)
RETURN
END

206
BAYES1
INITIAL DATA
NUMBER OF VARIABLES
PRINTING PARAMETER
NUMBER OF FUNCTION EVALUATIONS
NUMBER OF INITIAL POINTS
VECfOR OF LOWER BOUNDS (A) FOR X
- 0.2500000E 00
- 0.12500000E 00
VECTOR OF UPPER BOUNDS (B) FOR X
0.5000000E 00
0.62500000E 00
RESULTS
N=2
IPR=O
M= 100
LT=5
CHAPTER 9
OPTIMAL FUNCTION VALUE FM = -0.19982195E 01 OBTAINED IN NR = 45
OPTIMAL POINT
0.10454655E-02 - 0.31354427E-02
NUMBER OF FUNCfION EVALUATIONS
L = 100
BAYES1TERMINATED

FORTRAN SOFTWARE
9.10 UNT : The global method of extrapolation type by Zilinskas
207
PURPOSE.
To find the global minimum of a continuous function (9.1.1) of N
variables defined on the rectangular parallelepiped (9.1.2).
RESTRICTIONS.
The restrictions are the same as in the BAYESI method except
that if the function is differentiable then the local search of variable metrics type can
be directly incorporated in UNT.
ACCURACY. The method provides the minimal average deviation in accordance
with the set of assumptions given by Zilinskas (1982).
All other accuracy
considerations are similar to those in the BAYES 1 method.
HOW TO USE THE METHOD.
CALL UNT (X, A, B, N, XN, NM, FM, IPAR, IPA)
where the input is: A, B, N, NM, IPAR,IPA
and the output is X, XN, FM.
XN is an array of length NM = N * M which contains co-ordinates of M points of
function evaluation.
In the main program the following arrays should be described:
A(N), B(N), X(N), XN(NM), IPAR(30)
N:::;20
IPAR(1) = IPR is printing parameter
IPAR(2) = M is the maximal number of function evaluation, M :::; 500.
IPAR(3) = LT is number of RANDOM uniformly distributed initial points, LT ~ 30
IPAR(4) = ML is the maximal number of local minima, 0 < ML :::; 20
EXAMPLE. The program locates the global minimum of the multimodal function
(9.5.1).
IPR =0, M =500, LT =30, ML =5.
DIMENSION X(2), A(2), B(2), XN(1000), IPAR(30),
DATA N, NM, IPN2, 1000,01, N - 0.25, - 0.1251, B/O.5, 0.6251
DATA IPARlO,500, 30, 5, 26*01

208
CALL UNT (X, A, B, N, XN, NM, FM, IPAR, IPA)
STOP
END
FUNCTION Fl(X, N)
DIMENSION X(N)
FI=FURASN (X, N)
RETURN
END
UNT
INITIAL DATA
NUMBER OF VARIABLES
PRINTING PARAMETER
MAXIMUM NUMBER OF FUNCTION EVALUATIONS
NUMBER OF INITIAL POINTS
MAXIMUM NUMBER OF LOCAL MINIMA
VECTOR OF LOWER BOUNDS (A) FOR X
- 0.2500000E 00
- 0.12500000E 00
VECTOR OF UPPER BOUNDS (B) FOR X
0.5000000E 00
0.62500000E 00
RESULTS
CHAPTER 9
N=2
IPR=O
M=500
LT=30
ML=5
POINT
0.15230108E-Ol
- 0.13205975E4>1
0.34698546E 00
0.34251302E 00
OPTIMAL FUNCTION VALUE FM = - 0.19621372E 01
OPTIMAL POINT
0.15230108E4>21
0.13288877E4>2
LOCAL OPTIMA
FUNCTION VALUE
- 0.19621372E 01
-0.18478394E 01
- 0.18367290E 01
4>.17412872E 01
0.13288877E-02
0.34279919E 00
O.16140953E-Ol
0.33785129E 00

FORlRANSOF1WARE
NUMBER OF FUNCTION EVALUATIONS
L= 142
209
IFAIL = 1. TERMINATION CRITERION: DENSITY OF POINTS IN LOCAL
MINIMUM AREA EQUALS 3
UNT TERMINATED
9.11
LPMIN:
The global
method of uniform search
by Sobolj,
ShaItenis and Dzemyda
PURPOSE. To locate the global minimum of a continuous function (9.1.1) of N
variables defined on the rectangular parallelepiped (9.1.2).
RESTRICTIONS.
The restrictions are the similar to those in the BAYES 1 method
with the exception that LPMIN is using less auxilliary calculations and therefore it
can be recommended for minimising simpler functions than BAYES1 or UNT.
ACCURACY.
The method provides convergence to a minimum.
The average
deviation is usually considerably greater than in the methods BAYES 1 and UNT.
HOW TO USE THE METHOD.
CALL LPMIN (X, A, B, N, XN, NM, FM, IPAR, IPA)
where the input is: A, B, N, NM, IPAR,IPA
and the output is X, XN, FM.
XN is an array of length NM = N * M which contains co-ordinates of M points of
function evaluation.
In the main program the following arrays should be described:
A(N), B(N), X(N), XN(NM), IPAR(30)
N~20

210
CHAPTER 9
IPAR(l) = IPR is printing parameter
IPAR(2) = M is the indicator of analysis of structure. IF M < 0 then no analysis of
structure is performed. If 10::;; M::;; 300 then the results of M observations are used
to number the variables in order of decreasing importance. If M = 0 then the order of
variables should be fixed by the user in accordance with his opinion about the
decreasing importance
IPAR(3) = ML is number of steps of LP search
IPAR(4)
}
_ _ _
are the number of variables in order of decreasing
_ _ _
importance which should be fixed when IPAR(2) = M = 0
IPAR(N+3)
EXAMPLE. The program locates the global minimum and performs the analysis of
structure of the multimodal function (9.5.1).
IPR = 0, M = 50, ML = 1000.
DIMENSION X(2), A(2), B(2), XN(100), IPAR(30),
DATA N, NM, IPA/2, 100,0/, AI - 0.25, - 0.125/, B/0.5, 0.625/
DATA IPAR/O, 50,1000,27*0/
CALL LPMIN (X, A, B, N, XN, NM, FM, IPAR, IPA)
STOP
END
FUNCTION FI(X, N)
DIMENSION X(N)
FI=FURASN (X, N)
RETURN
END
LPMIN
INITIAL DATA
NUMBER OF VARIABLES
N = 2
PRINTING PARAMETER
IPR = 0
NUMBER OF FUNCTION EVALUATIONS FOR ANALYSIS
M = 50
NUMBER OF FUNCTION EVALUATIONS FOR LP-SEARCH ML = 1000

FORlRAN SOFTWARE
VECTOR OF LOWER BOUNDS (A) FOR X
- 0.2500000E 00
- 0.12500000E 00
VECTOR OF UPPER BOUNDS (B) FOR X
0.5000000E 00
0.62500000E 00
LP-SEARCH WITH ANALYSIS
RESULTS OF ANALYSIS
VARIABLES BY DECREASING INFLUENCE
2
1
211
OPTIMAL FUNCTION VALUE FM
=
- 0.19209299E 01 OBTAINED IN
NR= 10
OPTIMAL POINT
-0.15625000E-01
0.15625000E-01
RESULTS OF LP-SEARCH
OPTIMAL FUNCTION VALUE FM = - 0.19915352E 01 OBTAINED IN
NR= 404
OPTIMAL POINT
0.63476563E-02
- 0.34179688E-02
RESULTS
OPTIMAL FUNCTION VALUE FM =-0.19915352E 01
OPTIMAL POINT
0.63476563E-02
- 0.34179688E-02
NUMBER OF FUNCTION EVALUATIONS
LPMIN TERMINATED
L = 1050

212
9.12
GLOPT: The global method of clustering type by Torn
CHAPTER 9
PURPOSE. To find the global minimum of a continuous function (9.1.1) of N
variables defined on the rectangular parallelepiped (9.1.2).
RESTRICfIONS.
The restrictions are the same as in the methods BAYES1, UNT,
LPMIN with the exception
that GLOPT uses a smaller number of auxilliary
calculations so it can be recommended for minimising simpler functions when
compared with all previous methods if convergence is not necessary.
ACCURACY. The convergence to a minimum is not provided but the accuracy
usually satisfies the practical needs.
HOW TO USE THE METHOD.
CALL GLOPT (X, A, B, N, FM, IPAR, IPA)
where the input is: A, B, N, IPAR, IPA
and the output is X, FM.
In the main program the following arrays should be described:
A(N), B(N), X(N), IPAR(30)
N::S;20
IPAR(l) = IPR is printing parameter
IPAR(2) = M is the maximal number of function evaluations, recommended
M = 10000
IPAR(3) = LT is number of random uniformly distributed initial points, LT ::s; 150,
recommended LT is about double the number of an expected number of local minima.
EXAMPLE. The program locates the global minimum of the multimodal function
(9.5.1).
IPR =0, M = 10000, LT = 10.
DIMENSION X(2), A(2), B(2), IPAR(30),
DATA N, IPA/2, 01, AI - 0.25, - 0.125/, B/O.5, 0.6251
DATA IPAR/0,10000, 10,27*01
CALL GLOPT (X, A, B, N, FM, IPAR, IPA)
STOP

FORlRAN SOFIWARE
END
FUNCTION FI(X. N)
DIMENSION X(N)
FI=FURASN (X. N)
RETURN
END
GLOPT
INITIAL DATA
NUMBER OF VARIABLES
PRINTING PARAMETER
MAXIMUM NUMBER OF FUNCTION EVALUATIONS
NUMBER OF INITIAL POINTS
VECTOR OF LOWER BOUNDS (A) FOR X
- 0.2500000E 00
- 0.12500000E 00
VECTOR OF UPPER BOUNDS (B) FOR X
0.5000000E 00
0.62500000E 00
RESULTS
OPTIMAL FUNCTION VALUE FM =-0.19999999E 01
OPTIMAL POINT
- 033581266E-D4
0.37407226E-D4
N=2
IPR=O
M = 10000
LT= 10
213
NUMBER OF FUNCTION EVALUATIONS
IFAIL = O. TERMINATION CRITERION:
NUMBER OF ITERATIONS EQUALS 20
GLOPT TERMINATED
L = 1591

214
CHAPlER 9
9.13 MIG!: The global method of Monte Carlo (uniform random
search)
PURPOSE.
To find the global minimum of a continuous function (9.1.1) of N
variables defined on the rectangular parallelepiped (9.1.2).
RESTRICTIONS.
The restrictions are similar to those in all other global methods
except that in the case of MIG1 the amount of auxilliary calculation is minimal, so the
method can be recommended to minimize very simple functions, say less than 1 sec.
of CPU time, when the convergence in probability is sufficient.
ACCURACY.
The method converges in probability to the global minimum of
continuous functions. The average deviation is considerably greater compared with
global methods with the same number of function evaluations.
HOW TO USE THE METHOD.
CALL MIG1 (X, A, B, N, FM, IPAR, IPA)
where the input is: A, B, N, IPAR,IPA
and the output is X, FM.
In the main program the following arrays should be described:
A(N), B(N), IPAR(30), X(N)
N::;; 100
IPAR(l) = IPR is printing parameter
IPAR(2) = M is the number of function evaluations.
EXAMPLE. The program locates the global minimum of the multimodal function
(9.5.1).
IPR =0, M = 10000.
DIMENSION X(2), A(2), B(2), IPAR(30),
DATA N, IPA/2, 0/, N - 0.25, - 0.125/, B/0.5, 0.625/
DATA IPAR/0,10000, 28*0/
CALL MIG1 (X, A, B, N, FM, IPAR, IPA)
STOP
END

FORTRAN SOFTWARE
FUNCfION FI(X, N)
DIMENSION X(N)
FI=FURASN (X, N)
RETURN
END
MIGI
INITIAL DATA
NUMBER OF VARIABLES
PRINTING PARAMETER
NUMBER OF FUNCfION EVALUATIONS
VECfOR OF LOWER BOUNDS (A) FOR X
- 0.2500000E 00
- 0.12500000E 00
VECTOR OF UPPER BOUNDS (B) FOR X
0.5000000E 00
0.62500000E 00
RESULTS
N=2
IPR=O
M = 10000
215
OPTIMAL FUNCTION VALUE FM = - 0.19982195E 01 OBTAINED IN
NR= 1947
OPTIMAL POINT
0.10454655E--02
- 0.31354427E--02
NUMBER OF FUNCfION EVALUATIONS
MIG1TERMINATED
L = 10000

216
9.14 MIG2: The modified version of MIGI
CHAPTER 9
This is exactly the same method as MIGI except that the co-ordinates of the points of
all M function evaluations are placed in the array XN of length NM = N * M and,
consequently N ~ 20. The corresponding values of functions are placed into the
array /BSIIY(lOOO).
HOW TO USE THE METHOD.
CALL MIG2 (X, A, B, N, XN, NM, FM, IPAR, IPA)
where the input is: A, B, N, NM, IPAR, IPA
and the output is X, XN, FM.
In the main program the following arrays should be described:
A(N), B(N), XN(NM), IPAR(30), X(N)
N~20
IPAR(2) = M is the number of function evaluations, M ~ 1000.
9.15 EXTR: The global one-dimensional method by Zilinskas
PURPOSE. To locate the global minimum of a continuous function of one variable
on a closed interval.
RESTRICTIONS.
Restrictions are similar to those of multi-dimensional global
methods. The local search is included into EXTR.
ACCURACY.
The method provides the minimal average deviation from the
minimum under the assumption that the objective function can be regarded as a
sample of a Wiener process and converges to the minimum of continuous functions.
HOW TO USE THE METHOD.
CALL EXTR (X, A, B, FM, IPAR, PAR, IPA, IPAA)
where the input is: A, B, IPAR, PAR, IPA, IPAA
and the output is: FM, X

FORTRANSOF1WARE
217
IPAR(l) = IPR is printing parameter
IPAR(2) = M is the maximal number of function evaluations, M :s; 500 .
IPAR(3) = LT is the number of initial points which are random uniformly distributed
points, LT ;;:: 6, recommended LT = 6.
PAR(I) = EPSI is the accuracy of minimization,
PAR(2) = EPS2 is the accuracy of the point to be minimized.
In the main program the following arrays should be described:
IPAR(30), PAR(30).
EXAMPLE. The program locates the minimum of the multimodal function
5
f(x) = - L i sin «i + 1)x + i)
i=l
with XE [- 10, 10].
IPR = 0, M = 200, LT = 6, EPSI = 10-6, EPS2 = 10-6.
DIMENSION IPAR(30), PAR(30)
DATA IPA, IPANO, 0/, A, B/-IO., 10./
DATA IPAR/O, 200, 6,27*0/, PAR/2*1.E-6, 28*0./
CALL EXTR (X, A, B, FM, IPAR, PAR, IPA, IPAA)
STOP
END
FUNCTION FI(X, N)
A=O.
DO 2 I = 1,5
AI = FLOAT(I)
2 A = A - AI * SIN«AI + 1.) * X + AI)
FI=A
RETURN
END
EXTR
INITIAL DATA

218
CHAPTER 9
PRINTING PARAMETER
IPR = 0
MAXIMUM NUMBER OF FUNCTION EVALUATIONS
M = 200
NUMBER OF FUNCTION EVALUATIONS
FOR PARAMETER ESTIMATION
LT = 6
ACCURACY OF OPTIMAL FUNCTION VALUE EPS1 = 0.10000000E---D7
ACCURACY OF OPTIMAL POINT
EPS2 = 0.10000000E-07
LOWER BOUND (A) FOR X = -0.10000000E 02
UPPER BOUND (B) FOR X = 0.10000000E 02
RESULTS
OPTIMAL FUNCTION VALUE
FM = - 0.12031261E 02
OPTIMAL POINT
XM = - 0.67745743E 01
LOCAL OPTIMA
POINT
FUNCTION VALUE
- 0.10000000E 02
- 0.26305466E 01
- 0.67745743E 01
- 0.12031261E 02
-0.17255497E 01
-0.94947052E 01
-0.49139261E 00
-0.12031249E 02
0.45579252E 01
- 0.94947214E 01
0.57918062E 01
-0.12031260E 02
NUMBER OF FUNCTION EVALUATIONS
L = 157
IFAIL = O. TERMINATION CRITERION:
PROBABILITY OF FINDING THE GLOBAL OPTIMUM WITH GIVEN
ACCURACY IS MORE THAN 0.95
EXTR TERMINATED

FORTRAN SOFlWARE
9.16
MIVAR4: The local method of variable metrics by Tieshis
219
PURPOSE. To locate the local minimum of a differentiable function (9.1.1) defined
on the rectangular parallelepiped (9.1.2).
RESTRICfIONS. Only the local minimum of differentiable functions can be found.
Both numerical and analytical differentiation can be used. In the analytical case the
subroutine of differentiation should be provided.
ACCURACY. Arbitrarily close approaches to the minimum can be made depending
on parameters EPS.
HOW TO USE THE METHOD.
CALL MIVAR4 (X, A, B, N, HES, NH, FM, IPAR, PAR, IPA, IPAA)
where the input is: X, A, B, N, NH, IPAR, PAR, IPA, IPAA
and the output is X, FM,
HES is a working array of length NH which contains the elements of inverse
Hessian, where NH = N(N + 1)/2.
In the main program the following one-dimensional arrays should be described:
A(N), B(N), X(N), HES(NH), IPAR(30), PAR(30).
N:=; 100
IPAR(l) = IPR is printing parameter
IPAR(2) = M is the maximal number of function evaluations,
IPAR(3) = NSTOP is the stopping parameter if in the sequence of length NSTOP of
iterations the values of function are decreasing less than EPS 1 per iteration then the
procedure stops. Recommended NSTOP > 1
IPAR(4) = !MAX is the maximal number of iterations,
PAR(l) =XEPS is the step length tolerance,
PAR(2) = EPS is the norm of gradient tolerance,
PAR(3) = EPS 1 is the function decreasing tolerance,
PAR(4) = DELT is the length of initial step of numerical differentiation.
If the partial derivatives are defined analytically then the following suboutine is to be
used to define the gradient:
SUBROUTINE GRABP1(X, N, A, B)

220
DIMENSION X(N), A(N), B(N)
COMMON 1B3/GR(100)
GR(N) = 'djl'dxn
RETURN
END
CHAPTER 9
The values of gradient are put in the one-dimensional array GR of length 100
by the common block 1B3/.
EXAMPLE. The program locates the local minimum of the function (9.5.1).
IPR = 0,
M = 100, NSTOP = 2, IMAX = 100, XEPS = 100, EPS = 10-4 ,
EPS 1= 10-4, DELT = 10-4. Co-ordinates of initial point = (-0.1; 0.1)
DIMENSION X(2), A(2), B(2), HES(3),
IPAR(30), PAR(30)
DATA IPAR/O, 100,2, 100,26*01, PAR/100.,3*1.E-4, 26*0./,
XI -0,1.,0.11
DATA N, NH, IPA, IPAN2, 3, 0, 01, N - 0.25, - 0.125/, B/O.5, 0.6251
CALL MIVAR4 (X, A, B, N, HES, NH, FM, IPAR, PAR, IPA, IPAA)
STOP
END
FUNCTION FI(X, N)
DIMENSION X(N)
F!=FURASN (X, N)
RETURN
END
MIVAR4
INITIAL DATA
NUMBER OF VARIABLES
N = 2
P~GPARAMETER
IPR=O
MAXIMUM NUMBER OF FUNCTION EVALUATIONS
M = 100
NUMBER OF SMALL FUNCTION CHANGE RECURRENCE
NSTOP = 2
MAXIMUM NUMBER OF ITERATIONS
!MAX =100
SMALL STEP TOLERANCE
XEPS = 0.10000000E 03
GRADIENT NORM TOLERANCE
EPS = 0.10000000E-05
FUNCTION CHANGE TOLERANCE
EPS1 =0.10000000E-05

FORTRANSOFIWARE
DIFFERENTIATION STEP
DELT = 0.10000000E--05
VECTOR OF LOWER BOUNDS (A) FOR X
- 0.2500000E 00
- 0.12500000E 00
VECTOR OF UPPER BOUNDS (B) FOR X
0.5000000E 00
0.62500000E 00
STARTING POINT
221
- 0.99999999E--Ol
0.99999999E--Ol
FUNCTION VALUE F = 0.47440255E 00
RESULTS
OPTIMAL FUNCTION VALUE
FM = - 0.20000000E 01
NORM OF CONSTRAINED GRADIENT
=
0.37390131E--02
OPTIMAL POINT
- 0.48235106E--05
0.17049488E--05
NUMBER OF FUNCTION EVALUATIONS
NUMBER OF ITERATIONS
L=42
NR=6
IFAIL = 1. TERMINATION CRITERION: CHANGE OF FUNCTION,
LESS THAN EPS 1, OCCURED NSTOP TIMES
MIVAR4 TERMINATED
9.17
REQP: The local method of recursive quadratic programming by
Biggs
PURPOSE. To locate the local minimum of a differentiable function (9.1.1) with
nonlinear constraints
RESTRICTIONS.
Only the local minimum of a differentiable function with
nonlinear constraints can be found. Both numerical and analytical differentiation can

222
CHAPTER 9
be used. In the analytical case the subroutine of differentiation should be provided.
The user should also provide the subroutine of constraints.
ACCURACY. Arbitrarily close approaches to the minimum can be made depending
on parameters EPS.
HOW TO USE THE METHOD.
CALL REQP (X, H, Q, GC, N, FM, IPAR, PAR, IPA, IPAA)
where the input is: X, N, IPAR, PAR, IPA, IPAA
and the output is X, FM,
The working arrays are: H, Q, GC.
In the main program the following arrays should be described:
X(N), Q(N,N), H(N,N), GC(100, N), IPAR(30), PAR(30).
N~ 100
IPAR(1) = IPR is printing parameter
IPAR(2) = IMAX is the maximal number of iterations,
IPAR(3) = NC is the number of equality constraints,
IPAR(4) = NIC is the number of inequality constraints,
PAR(1) =Rl is the penalty parameter, recommended Rl =1.
PAR(2) = SCALE is the scale parameter of penalty function,
recommended 0.1 ~ SCALE ~ 0.75,
PAR(3) = DELTA is the step length of numerical differentiation,
recommended 10-2 :2: DELTA:2: 10-6
PAR(4) = EPS is the accuracy parameter, recommended 10-2:2: EPS :2: 10-6.
Constraints should be represented by the subroutine
CONSTR(X, N, G, Me)
where G is a one-dimensional array of length MC which contains the constraints at
the point X, MC is the number of constraints.
The equality constraints should be represented at the beginning of array G. In
the case of analytical differentiation the derivatives should be represented by the
subroutine

FORlRAN SOF1WARE
SUBROUTINE CALGRD (X, N, G, MC, GC)
COMMON /B3/GR(lOO)
DIMENSION X(N), GC(lOO,N), G(MC)
DO 1 1= 1, N
GR(I) = af/axj
DO 11= I,MC
GC(J, I) = ag/dXj
RETURN
END
223
The values of gradient are put in the one-dimensional array GR of length 100
by the common block !B3/. The values of gradients of constraints are put in the
two-dimensional array GC of dimension 100 * N in accordance with the following
formula
GC(J, I) = ag/aXj
where gj is the constraintj.
EXAMPLE. The program locates the local minimum of the function
f(x)
=
4Xl -xi -12
with constraints
25 -xi -X~ = 0
[PR = 0,
IMAX = 50, RI = 1, SCALE = 0.25,
DELTA = 10-4, EPS = 10-4,
NC = 1, NIC = 3. The initial point is (1, 1)

224
CHAPTER 9
DIMENSION X(2), H(2, 2), Q(2, 2), GC(100, 2), IPAR(30), PAR(30)
DATA N, IPA, IPAA/2, 0, 0/, X/I.,I./
DATA IPAR/O, 50, 1,3,26*0/, PAR/I., 0.25, 2*I.E-4, 26*0./
CALL REQP (X, H, Q, GC, N, FM, IPAR, PAR, IPA, IPAA)
STOP
END
FUNCTION FI(X, N)
DIMENSION X(N)
FI=4.*X(I) - X(2)**2 - 12.
RETURN
END
SUBROUTINE CONSTR (X, N, G, M)
DIMENSION X(N), G(M)
G(l) = 25. - X(l)**2 - X(2)**2
G(2) = 10. *X(I) - X(l)**2 + 10.*X(2) - X(2)**2 - 4.
G(3) = X(I)
G(4) = X(2)
RETURN
END
REQP
INITIAL DATA
NUMBER OF VARIABLES
N = 2
PRINTING PARAMETER
IPR = 0
MAXIMUM NUMBER OF ITERATIONS
!MAX = 50
NUMBER OF EQUALITY CONSTRAINTS
NC = 1
NUMBER OF INEQUALITY CONSTRAINTS
NIC = 3
PENALTY PARAMETER
RI
= O.lOOOOOOOE 01
SCALING PARAMETER
SCALE = 0.25000000E 00
DIFFERENTIATION STEP
DELTA = 0.10000000E-0S
TOLERANCE LEVEL
EPS
= 0.10000000E-0S
STARTING POINT = INFEASffiLE
0.10000000E
01
0.10000000E
01

FORmAN SOFfWARE
225
FUNCTION VALUE F = - 0.90000000E 01
CONSTRAINTS
0.23000000E
02
-O.16000000E 02
0.10000000E
01
0.10000000E
01
RESULTS
OPTIMAL FUNCTION VALUE
OPTIMAL POINT
0.10012760E 01
0.48987226E 01
CONSTRAINTS
FM = - 0.31992371E 01
- 0.45776367E-04 - 0.45776367E-04
0.1001277E 01
0.48987236E 01
LAGRANGE MULTIPLIERS
0.10003557E
01
0.74965036E 00
- 0.46047888E
01
0.0
NUMBER OF ITERATIONS
NUMBER OF FUNCTION EVALUATIONS
NUMBER OF GRADIENT EVALUATIONS
NUMBEROFACTIVECONS~NTS
NUMBERS OF ACTIVE CONSTRAINTS
1
2
K
= 11
L
=45
LG= 11
MA=2
IFAIL = O. TERMINATION CRITERION: NORMS OF GRADIENTS
LESS THAN EPS
REQPTERMINATED

226
9.18
FLEXI: The local simplex method by Neider and Mead
CHAPTER 9
PURPOSE. To locate the local minimum of a nondifferentiable function (9.1.1) with
nonlinear constraints.
RESTRICTIONS. Only the local minimum of a function with constraints can be
found. The user should provide the subroutine of constraints.
ACCURACY. Convergence to the minimum is not provided but usually the accuracy
satisfies the practical needs if the number of iterations is large enough.
HOW TO USE THE METHOD.
CALL FLEXI (X, N, FM, IPAR, PAR, IPA, IPAA)
where the input is: X, N, IPAR, PAR, IPA, IPAA,
and the output is X, FM.
In the main program the following arrays should be described:
X(N), IPAR(30), PAR(30).
N::;;20
IPAR(l) = IPR is printing parameter,
IPAR(2) = M is the maximal number of function evaluations,
IPAR(3) = NC is the number of equality constraints,
IPAR(4) = NIC is the number of inequality constraints, NC + NIC::;; 100.
PAR(l) = DELTA is the dimension of the initial simplex.
Recommended DELTA = 0.2 min (B( I) - A(I))
PAR(2) = EPS is the stopping accuracy, recommended EPS = 10-5 or EPS = 10-6.
Constraints should be represented by the subroutine
CONSTR(X, N, G, MC)
where G is the one-dimensional array of length MC which contains the values of
constraints at the point X and MC is the number of constraints.
The equality constraints should be represented at the beginning of array G.
EXAMPLE. The program locates the local minimum of the function

FORTRAN SOFIWARE
!(x) = 4Xl -xi - 12
with constraints
25-xi-xi = 0
IPR = 0, M = 200, NC = 1, NIC = 3.
DELTA= 0.3, EPS = 10-5.
The initial point is (1, 1)
DIMENSION X(2), IPAR(30), PAR(30)
DATA N, IPA, IPAA/2, 0,0/, X/I., 1.1
DATA IPAR!O, 200, 1,3,26*0/, PAR! 0.3, I.E-5, 28*0./
CALL FLEXI (X, N, FM, IPAR, PAR, IPA, IPAA)
STOP
END
FUNCTION FI(X, N)
DIMENSION X(N)
FI=4.*X(l) - X(2)**2 - 12.
RETURN
END
SUBROUTINE CONSTR (X, N, G, M)
DIMENSION X(N), G(M)
G(I) = 25. - X(I)**2 - X(2)**2
G(2) = 10. *X(l) - X(I)**2 + 1O.*X(2) - X(2)**2 - 34.
G(3) = X(l)
G(4) = X(2)
RETURN
END
FLEXI
227

228
INITIAL DATA
NUMBER OF VARIABLES
PRINTING PARAMETER
MAXIMUM NUMBER OF FUNCTION EVALUATrONS
NUMBER OF EQUALITY CONSTRAINTS
NUMBER OF INEQUALITY CONSTRAINTS
CHAPTER 9
N=2
IPR =0
M
=200
NC = 1
NrC=3
SIZE OF INITIAL POLYHEDRON
DESIRED CONVERGENCE
STARTING POINT
O.lOOOOOOOE
01
O.lOOOOOOOE
01
DELTA = 0.30000000E 00
EPS
= 0.10000000E-06
FUNCTION VALUE F = - 0.90000000E 01
CONSTRAINTS
0.23000000E
02
-O.16000000E
02
0.10000000E
01
O.lOOOOOOOE
01
STARTING POINT = INFEASIBLE
CALCULATED FEASIBLE STARTING POINT
0.25836763E
01
0.43556452E
01
FUNCTION VALUE F = - 0.206369170E 02
CONSTRAINTS
- 0.64701843E
00 0.97461853E
01
0.2583676E
01
0.43556452E
01
RESULTS
OPTIMAL FUNCTION VALUE
OPTIMAL POINT
0.10013027E
01
0.48987141E
01
CONSTRAINTS
FM = - 0.31992172E 02
0.0
0.15258789E-03
0.10013027E
01
0.48987141E 01

FORlRAN SOFIWARE
NUMBER OF FUNCTION EVALUATIONS
NUMBER OF ITERATIONS
L
=53
NR=24
229
IFAIL = O. TERMINATION CRITERION: TOLERANCE CRITERION
LESS THAN EPS
FLEX! TERMINATED
9.19
LBAYES: The local Bayesian method by Mockus
PURPOSE.
To locate the minimum of a unimodal function with noise on the
rectangular parallelepiped (9.1.2).
RESTRICTIONS. Only the minimum of a unimodal function is found
ACCURACY.
Arbitrarily close approaches to the minimum can be made with
probability 1 when the number of iterations is large enough.
The Bayesian step
length provides the minimal average deviation in accordance with a given statistical
model, see Mockus (1984a).
The number of iterations should be increased sharply if we wish to make the
average error considerably less than the level of noise.
HOW TO USE THE METHOD.
CALL LBAYES (X, A, B, N, F, IPAR, PAR, IPA, IPAA)
where the input is: A, B, N, IPAR, PAR, IPA, IPAA,
and the output is: X, F, XM, FM
where
X is the last point,
F is the value of the function at point X,

230
CHAPTER 9
XM is an array of length N which defines the point of minimum of the function,
FM is the minimum
Array XM and FM are defined by the common block COMMON/LAIK/FM,
XM(100).
In the main program the following arrays should be defined:
A(N), B(N), IPAR(30), PAR(30), X(N),
N S; 100
IPAR(l) = IPR is printing parameter,
IPAR(2) = M is the number of iterations,
IPAR(3) = NIPA is the number of integer variables, they should be at the beginning
of the array X,
PAR(1) = ANIU is the rate of decreasing of the differentation step,
PAR(2) = BETA is the rate of decreasing of the iteration step,
recommended BETA =1. - 2*ANIU, ANIU =0.01 to 0.1
In terms of expression (7.3.31) ANIU = v, BETA =1 - v - ex, to provide the
convergence ex ~ 0, v > 0, ex + v < 0.5, v - ex > O.
EXAMPLE. The program locates the local minimum of the following function with
noise
n
3
2
f(x) = ~ (x./6000 + x. /200) + ~
"'-'
I
I
j=l
with n = 2, x E [- 10, 10].
Here IPR =0, M =20, NIP = 1, ANIU =0.05, BETA =0.9, and ~ is the random
variable uniformly distributed in the interval [ - 0.5, 0.5] * 0.046 -V(n/2), by the real
function ATS(l) from this package. The initial point is (5, 5).
DIMENSION X(2), A(2), B(2), IPAR(30), PAR (30)
DATA N, IPA,
IPAAl2, 0, 0/, AI - 10., - 10./, B/2*10./, X/2*5.)
DATA IPAR/O, 20,1,27*0/, PAR/0.05, 0.9,28*0./
CALL LBAYES (X, A, B, N, F, IPAR, PAR, IPA, IPAA)
STOP
END

FORlRAN SOFIWARE
FUNCTION FI(X, N)
DIMENSION X(N)
Y=O.
DO 101 = I, N
10 y = Y+X(I)**3/6.E + 3 + X(I)**2/2.E + 2
A = ATS(l) -0.5
y = Y + 0.046*A*SQRT(N/2.)
F!=Y
RETURN
END
LBAYES
INITIAL DATA
NUMBER OF VARIABLES
PRINTING PARAMETER
NUMBER OF ITERATIONS
NUMBER OF INTEGER VARIABLES
RATE OF TRIAL STEP DECREASING
RATE OF ITERATION STEP DECREASING
VECTOR OF LOWER BOUNDS (A) FOR X
- 0.1000000E 02
- 0.10000000E 02
VECTOR OF UPPER BOUNDS (B) FOR X
0.1000000E 02
0.10000000E 02
STARTING POINT
0.50000000E 01
0.50000000E 01
FRUNCTION VALUE F = 0.28995705E 00
RESULTS
N
=2
IPR
=0
M
=20
NIPA = 1
ANIU = 0.50000000E-Ol
BETA = 0.90000000E 00
231
LAST FUNCTION VALUE F = - 0.38817651E-D2
LAST POINT
- 0.95811367E- 01
-.24840391E 00

232
CHAPTER 9
OPTIMAL FUNCTION VALUE FM =- 0.83632320E-02 OBTAINED IN NR =9
OPTIMAL POINT
- 0.10349190E 02
- 0.17454523E 00
NUMBER OF FUNCTION EVALUATIONS
L = 406
LBAYESTERMINATED
9.20
ANALl: The method of analysis of structure by Shaltenis
PURPOSE. To define the variables or pairs of variables which have the greatest
influence on the accuracy of optimization.
RESTRICTIONS.
The assumption is made that the search procedure is nearly
uniform.
The program was also successfully used for nonuniform optimization
procedures. No special assumptions are made about the function except that it is
continuous and satisfies some general conditions concerning average behaviour.
ACCURACY. Arbitrarily close estimation of the structural characteristics can be
made depending on the results of function evaluation.
HOW TO USE THE METHOD.
CALL ANAL! (A, B, N, XN, XM, NM, IPAR, IPA)
where the input is: A, B, N, XN, NM, IPAR, IPA.
The working array is XM
In the main program the following arrays should be described:
A(N),B(N), XN(NM), XM(NM), IPAR(30)
N~20
IPAR(I) = IPR is printing parameter,
IPAR(2) = M is the number offunction evaluations, 10 ~ M ~ 300
IPAR(3) =NH is the number of harmonics, NH ~ 7, recommended NH =7,
IPAR(4) = NSF is the maximal number of variables to be defined, NSF ~ 30. NSF
depends on M. Larger M permits larger NSF.

FORTRANSOFlWARE
233
IPAR(5) = INP is the parameter of structural analysis:
if INP = 1 then only single variables are considered,
if INP = 2 then pairs of variables are also included into the analysis of
importance
The routine ANAL1 can be used if the number L(L ~ M) of evaluations of the
function are performed and the following arrays are defined:
/BSI/Y(lOOO) are values of the function,
XN(NM) are the co-ordinates of corresponding points of evaluation.
To define the arrays the routine MIG2 can be used.
EXAMPLE. The program performs the analysis of structure of the function (9.5.1).
IPR = 0, M = 200, NH = 7, NSF = 8, INP = 2.
DIMENSION X(2), A(2), B(2), XN(400), XM(400), IPAR(30)
DATA N, NM, IPAl2, 400, 01, AI - 0.25, - 0.125/, B/O.5, 0.6251
DATA IPAR/-1, 200, 0, 200, 7,8,2,23*01
CALL MIG2 (X, A, B, N, XN, NM, FM, IPAR, IPA)
IPA=2
CALL ANAL! (A, B, N, XN, XM, NM, IPAR, IPA)
STOP
END
FUNCTION FI(X, N)
DIMENSION X(N)
A=FURASN (X, N)
RETURN
END
ANAL1
INITIAL DATA
NUMBER OF VARIABLES
PRINTING PARAMETER
NUMBER OF FUNCTION EVALUATIONS
NUMBER OF HARMONICS
NUMBER OF SELECTED FACTORS
INTERACTION PARAMETER
N
=2
IPR
=0
M
=200
NH
=7
NSF = 8
INP
= 2

234
VECfOR OF LOWER BOUNDS (A) FOR X
- 0.2500000E 00
- 0.12500000E 00
VECTOR OF UPPER BOUNDS (B) FOR X
0.5000000E 00
0.62500000E 00
RESULTS
VARIABLES OR PAIRS OF VARIABLES
X2
Xl
ANAL1TERMINATED
CHAPTER 9
DEGREE OF INFLUENCE
OA029091OE 00
0.32305169E 00

FORlRAN SOFfWARE
9.21 Portability routines
235
IlMACH, RIMACH defines the machine constants. Those routines correspond to
the PORT subroutine library.
They are described in the BELL laboratories
computing science technical report 47 by P.A. Fox, A.D. Hall and N.L Schryer.
INTEGER FUNCTION IlMACH(I):
IlMACH(l)
IlMACH(2)
IlMACH(3)
IlMACH(4)
IlMACH(5)
IlMACH(6)
I/O unit numbers
is the standard input unit,
is the standard output unit,
is the standard punch unit,
is the standard error message unit,
Words
is the number of bits per integer
storage unit
is the number ofcharacters per
integer storage unit,
Machine constants for
the VAX-IT with
FORTRAN IV-PLUS
5
6
7
6
32
4
Integers
IlMACH(7) = A
is the base,
IlMACH(8) = S
is the number of the base A digits,
IlMACH(9) = A**S-1 is the largest magnitude,
2
31
2147483647
IlMACH(lO) = B
Floatin~ point numbers
is the base,
2
Single precision
IlMACH(II) = T
is the number of the base B digits,
24
IlMACH(l2) = EMIN is the smallest exponent E,
- 127
IlMACH(l3) = EMAX is the largest exponent E,
127
Double precision
IlMACH(l4) = T
is the number of the base B digits,
56
IlMACH(l5) = EMIN is the smallest exponent E,
- 127
IlMACH(l6) = EMAX is the largest exponent E,
127

236
REAL FUNCTIONS R1MACH<n:
Single precision machine constants
CHAPTER 9
RIMACH(I) = B**(EMIN - 1)
RIMACH(2)
= B**EMAX*(I- B**(-T))
RIMACH(3) = B**(- T)
RIMACH(4) = B**(1 - T)
RIMACH(5) = LOGlO(B)
is the smallest positive magnitude
is the largest magnitude
is the smallest relative spacing
is the largest relative spacing
Z00000080
ZFFFF7FFF
Z00003480
Z00003500
Z209B3F9A
Double precision machine constants
DIMACH(I) = B**(EMIN - 1) is the smallest positive magnitude
DIMACH(2)
= B**EMAX*(1 - B**(- T))
is the largest magnitude
DIMACH(3) = B**(- T)
is the smallest relative spacing
DIMACH(4) = B**(l- T)
DIMACH(5) = LOGlO(B)
is the largest relative spacing
Z00000080
ZOOOOOOOO
ZFFFF7FFF
ZFFFFFFFF
Z00002480
ZOOOOOOOO
Z00002500
ZOOOOOOOO
Z209A3F9A
ZCFFA84FB
The list of machine constants should be fIxed by operator DATA in the same order as
shown here.

References
Aczel, J. (1966) Lectures on Functional Equations and their Applications, Academic
Press, New York.
Anderson, T.W. (1958) An Introduction to Multivariate Statistical Analysis, 2nd.
ed., Wiley, New York.
Archetti, F. (1975) 'A sampling technique for global optimization'. In: Towards
Global Optimization I, ed. Dixon, L.C.W. and Szego, G.P., North-Holland,
158-165.
Barauskas, A., Zilinskas, A., Piliavskij, V., Shulman, V., Jushkene, E. (1980)
'Investigation of the optimization problems of the synthesis of pigmental
composisitions'. In: Optimal Decision Theory, Inst. of Math. and Cybernetics,
Vilnius, 6,57-74 (in Russian).
Barauskas, A. (1984) 'Linear constraints in the problem of multiextremal
optimization'. In: Optimal Decision Theory, Inst. of Math. and Cybernetics,
Vilnius, 10, 22-33 (in Russian).
Barauskas, A. (1984) 'Package of applied software for OPTIMUM to solve
multimodal problems of design'. Information leaflet on scientific-technical
achievement, No. 84-60 Series 50, Lith. MTII. (in Russian).
Barbee, H.C.P., Boender, C.G.E.,
Rinnoy Kan, A.H.G., Smith, R.I., TeIgen, J.
(in print) 'Hit-and-run Algorithm for the indication and identification of
nonredundant linear constraint inequalities'.
Bashkis, A., Zanevicius, D., Kostetskij, Ch., (1981) The analysis of integrated
circuits in nonisothermic conditions using the transconde models of transistors.
Preprint No. 10. Inst. of semiconductor physics of the Academy of Sciences of
the Lithuanian S.S.R., Vilnius (in Russian).
Bashkis, A., Zanevicius, D.,
Mockus, J.B., Valevichene, J.P., Dailydenas, V.I.
(1982) 'The calculation of the relation of the yield of integrated circuits on the
widths of diffused resistors'.
Proc. of High Schools of Lithuanian S.S.R.,
Radioelectronics, 18, 98 (in Russian).
Bashkis, A. (1984) 'The optimization of the design of integrated circuits to increase
the yield'. In :Mathematical and computer simulation in microelectronics, Vilnius,
17-24 (in Russian).
237

238
REFERENCES
Betro, B., De Biase, L. (1976)
'A recursive spline technique for uniform
approximation of sampled data'. Quaderni del Dipartamento di Ricerca Operativa
e Scienze Statistiche, A31, Universita di Pisa.
Betro, B. (1981) 'Bayesian testing of nonparametric hypotheses and its application
to global optimization'. Technical Report, CNR-IAMI, Italy.
De Biase, L., Frontini, F. (1978) 'A stochastic method for global optimization: its
structure and numerical performance'. In: Towards Global Optimization 2, ed.
Dixon, L.C.W. and Szego, G.P., North-Holland, 85-102.
Biggs, M.C. (1974) 'Constrained minimization using recursive quadratic
programming: some alternative subproblem formulations'.
Numerical
Optimization Center. Technical Report No. 51.
Biggs, M.C. (1975) 'Constrained minimization using recursive quadratic
programming: some alternative subproblem formulations'. In: Towards Global
Optimization 1, ed. Dixon, L.C.W. and Szego, G.P., North-Holland, 341-349.
Blum, J.R. (1954) 'Multi-dimensional stochastic approximation method', Ann.
Math. Stat. 25, 737-744.
Boender, C.G.E., Rinnooy Kan (1983) 'A Bayesian analysis of the number of cells
of a multinomial distribution', The Statistician 32,240-248.
Chichinadze, V.K (1967) 'Random search to determine the extremum of functions
of several variables', Engineering cybernetics (Technicheskaya kibernetika), No.
1 , 115-123 (in Russian).
Collatz, L. (1964) Funktionanalysis und numerische mathematik, Springer-Verlag,
Berlin.
De Groot, M. (1970) Optimal Statistical Decisions, McGraw-Hill, New York.
Didzgalvis, R., Zilinskas, A., Ragulskis, K, Tieshis, V. (1975) 'Optimal synthesis
of a linear shock absorber'. In: Optimal Decision Theory, Inst. of Math. and
Cybernetics, Vilnius, 4, 13-26 (in Russian).
Didzgalvis, R., Zilinskas, A., Ragulskis, K, Tieshis, V. (1976) 'On optimal energy
transmission through skew impact'. In: Optimal Descision Theory, Inst. of Math.
and Cybernetics, Vilnius, 2, 9-27 (in Russian).

REFERENCES
239
Dixon, L.C.W. and Szego, G.P. (1978) 'Global optimization: an introduction'. In:
Towards Global Optimization 2, ed. Dixon, L.C.W. and Szego, G.P.,
North-Holland, 1-15.
Dixon, L.C.W. and Szego, G.P. (1978) ed. Towards Global Optimization 2,
North-Holland.
Dvoretzky, A. (1956) 'On stochastic approximation', Proc. Third Berkeley Symp.
on Math. Stat. and Prob., 1, 39-55.
Dzemyda, G. (1981) 'Portability of program libraries'. In: Optimal Descision
Theory, Inst. of Math. and Cybernetics, Vilnius, 7, 41-48 (in Russian).
Dzemyda, G. (1982) 'On an extremal grouping'. In: Optimal Decision Theory, Inst.
of Math. and Cybernetics, Vilnius, 8, 46-54 (in Russian).
Dzemyda, G. (1983) 'LP-search, taking into account the structure of an extremal
problem'. In: Optimal Decision Theory, Inst. of Math. and Cybernetics, Vilnius,
9, 39-44 (in Russian).
Dzemyda, G., Vaitekunas, G., Vyshniauskas, J., Juzefovich, D., Kucherenko, V.,
Kuziakin, 0., Filatov, N. (1984) 'Solution of the problems of optimal design and
selection of model parameter values using the package of applied programs
MINIMUM'. In: Optimal Decision Theory, Inst. of Math. and Cybernetics,
Vilnius, 10, 77-98 (in Russian).
Ermolyev, Yu.M. (1976) Methods ofStochastic Programming, Nauka, Moscow (in
Russian).
Everitt, B.S. (1978) Graphical techniques for Multivariate Data, Heinemann
Educational Books, London.
Fine, T.L. (1973) Theories ofProbability, Academic Press, New York.
Gantmacher, F.R. (1967) Theory ofMatrices, Nauka, Moscow (in Russian).
Gemulka, J.A. (1978) 'Users experience with Torn's clustering algorithm'.
In:
Towards Global Optimization 2, ed. Dixon, L.C.W. and Szego, G.P.,
North-Holland, 63-70.
Gemulka, J.A. (1978) 'Two implementations of Branin's method: numerical
experience'.
In: Towards Global Optimization 2, ed. Dixon, L.C.W. and Szego,
G.P., North-Holland, 151-164.

240
REFERENCES
Gnedenko, B.V. (1943) 'Sur la distribution limite du terrne maximum d'une serie
d'eatore, Ann. Math. 44, Nr. 2, 423-453.
Gnedenko, B.V. (1965) Course of Theory of Probability, Nauka, Moscow (in
Russian).
Grigas, F.J., Gudanavichute, V.V. (1980) 'The calculation of distribution of
ampere-turns of magnetic deflection systems'.
Proc. of High Schools of
Lithuanian S.S.R., Radioelectronics, 16, No.2, 81 (in Russian).
Grishagin, V.A. ( 1978) 'Operative charateristics of some algorithms of global
search'. In: Problems of Random Search,7,198-206 ed. Rastrigin, L.A.,
Zinatne, Riga,
(in Russian).
Herstein, LN. and Milnor, J. (1953) 'An axiomatic approach to measurable utility',
Econometrica, 21, 291-297.
Himmelblau, D.M. (1972) Applied nonlinear programming, McGraw-Hill, New
York.
Hochshtein, A. Ya. (1976) The surface tension of rigid bodies and adsorption,
Nauka, Moscow, (in Russian).
Joshida, T., Osaka, T. (1978) 'The investigation of adsorbtion of hydrogen on a
platinum electrode using dynamic measurement of impedance', Electrochemistry,
14, 692-694 (in Russian).
Juzefovich, D., Naumov, Yu., Bereshnov, N., Radvilavichute, J., Shaltenis V.,
Kuchorenko, V. (1984) 'The investigation of conditions for the regeneration of
ferro-copper chloride solutions for etching using the essential variable selection
algorithm'.
In: Optimal Decision Theory, Inst. of Math. and Cybernetics,
Vilnius, 10, 144-154 (in Russian).
Katkauskaite, A.J. (1972) 'Random Fields with independent increments', Lithuanian
Math. Collection XII, No.4, 75-85 (in Russian).
Katkauskaite, A., Zilinskas, A., (1977) 'On the construction of statistical models of
functions under uncertainty'. In: Optimal Decision Theory, Inst. of Math. and
Cybernetics, Vilnius, 3, 19-29 (in Russian).
Kramer, H. (1946) Mathematical Methods ofStatistics, Princeton University Press.
Kuratovski, K. (1966) Topology 1, Academic Press, New York, London and
Pan.Wyd.Nauk., Warsaw.

REFERENCES
241
Kuratovski, K. (1968) TopoLogy 2, Academic Press, New York, London and
Pan.Wyd.Nauk., Warsaw.
Kushner, H. (1964) 'A new method of locating the maximum point of an arbitrary
multipeak curve in the presence of noise', Trans. ASME, series C, 86, 97-105.
Loeve, M. (1960) Probability Theory, D. Van Nostrand Co. Inc. Princeton, New
York.
Marchuk, GJ. (1980) MathematicaL Models in ImmunoLogy, Nauka, Moscow (in
Russian).
Mashkovtsev, V.M., Tsibizov, K.N., Jemelin, V.F. (1966) Theory of Waveguides,
Nauka, Moscow (in Russian).
MINIMUM (1986) The software system for the interactive optimization of
multimodal problems 'Algorithms and Programs', No.6, Register No.
50860000112, GOSFAP, Smolnaia St., 14, Moscow (in Russian).
Mockus, J.B. (1963) 'On an application of the Monte Carlo method in multiextremal
and combinatorial problems', Conference Proc., Lectures, Vol IV, GeneraL
ProbLems ofthe AppLication ofProbabilistic and StatisticaL Methods, State Pub!.
House of Techn. Lit, Ukrainian S.S.R, Kiev, 30-41 (in Russian).
Mockus, J.B. (1964) 'On a method of distribution of trial points in multimodal
problems', JournaL vychisLiteLnoj matematiki i matematicheskoj fiziki 4, No.2,
380-385 (in Russian).
Mockus, J.B. (1965) 'On a sequential procedure for statistical decisions in the
extremal problems'. In: Automat. i VycisL. Techn. 10, Riga, 'Zinatne', 78-101
(in Russian).
Mockus, J.B. (1967) MuLtiextremaL ProbLems in Design, Nauka, Moscow
(in
Russian).
Mockus, J.B. (1969) 'On a problem of optimal search for an extremum, Abst. Nth
Symposium of ExtremaL ProbLems, Press of Physical-Technical problems of
Energetics, Kaunas, p. 5 (in Russian) .
Mockus, J.B. (1972) 'On Bayesian methods of search for an extremum', Automat.
i VycisL. Techn. 3, 53-62 (in Russian).

242
REFERENCES
Mockus, J.B. (1977) 'On Bayesian methods for seeking the extremum and their
applications'. In: Information Processing 77, ed. Gilchrist, B., North-Holland,
195-200.
Mockus, J.B., Tieshis, V., Zilinskas, A. (1978) 'The application of Bayesian
methods for seeking the extremum'. In: Towards Global Optimization 2, ed.
Dixon, L.C.W. and Szego, G.P., North-Holland, 117-130.
Mockus, J.B. (1978) 'The sufficient conditions for convergence of Bayesian
methods to a global minimum for any continuous function'. In: Optimal Decision
Theory, Inst. of Math. and Cybernetics, Vilnius, 4,67-89 (in Russian).
Mockus, J., Senkiene, E. (1979) 'On the estimate of the random Gaussian field mean
from the observation of dependant random points'. In: Optimal Decision Theory,
Inst. of Math. and Cybernetics, Vilnius, 4,27-38 (in Russian).
Mockus, J. (1980) 'Sufficient conditions for the convergence of the one-dimensional
Bayesian method to the global minimum for any continuous function'.
In:
Optimal Decision Theory, Inst. of Math. and Cybernetics, Vilnius, 6,9-17 (in
Russian).
Mockus, J. (1983) 'The Bayesian approach to global optimization', 2nd Int. Meeting
on Bayesian Statistics, Valencia, Spain, 6-10 September.
Mockus, J.B. (1984) 'On Bayesian approach to stochastic programming', Abst. Int.
Conf. on Stochastic Optimization, Kiev, 9-16 September, 165-167.
Mockus, J.B. (1984b) 'On Bayesian methods in nondifferential and stochastic
programming', Abst. IIASA Workshop on Nondifferential Optimization, Sopron,
Hungary, 17-22 September, 112-117.
Mockus, J. B. (1984
C
) 'The Bayesian approach to global optimization', Proc. Indian
Stat. Inst. Golden Jubilee Conf. on Statistics: Applications ofNew Directions,
Calcutta 16 Dec. 1981,405-430.
Mockus, J. B. (1984d) 'The Bayesian approach to global optimization', Preprint No.
176, Free University, Berlin, May.
Mockus, J. B. (l984e) 'The Bayesian approach to global optimization', Preprint No.
175, Free University, Berlin, May.
Mockus, J. B., Zukauskaite, L., Lideikis, T. (1987) 'The Bayesian approach to
stochastic approximation procedures and their applications'. In: Optimal Decision
Theory, Inst. of Math. and Cybernetics, Vilnius, 2, 71-77 (in Russian).

REFERENCES
243
Mockus, J. B., Mockus, L. B. (1987) 'Some algorithms of global and multiobjective
optimization and their computer implementation'. In: Optimal Decision Theory,
Inst. of Math. and Cybernetics, Vilnius, 2, 54-70 (in Russian).
Neveu, J. (1964) Bases matMmatique de calcul des probabilites, Masson et Cie,
Paris.
Nikolajev P., Pochnikaev G., Tieshis, V. (1984) 'Modelling and optimization of
waveguide to microstrip line directional couplers'. In: Optimal Decision Theory,
Inst. of Math. and Cybernetics, Vilnius, 10, 117-126 (in Russian).
Praporov, A.M., Naumov, Yu.I., Juzefovich, D.K., Kucherenko, V.I., Flerov,
V.N. (1979) 'The calculations of the productive cost of the etching of printed
circuits with recycling and regeneration'. In: The Exchange ofExperience in the
Radio Industry, 10, 61-63 (in Russian).
Price, L.W. (1978) 'A controlled random search procedure for global optimization'.
In: Towards Global Optimization 2, ed. Dixon, L.C.W. and Szego, G.P.,
North-Holland, 71-84.
Ragulskiene, V.L. (1974) Vibroshock Systems, Mintis, Vilnius (in Russian).
Rao, J.S., Joshi, K.K., Das, B.N. (1981) 'Analysis of small aperture coupling
between a rectangular waveguide and
a microstrip line', IEEE Trans. on
Microwave Theory and Techn., MTT-29, No.2, p. 150.
Rastrigin, L.A. (1968) The stochastic methods of search, Nauka, Moscow (in
Russian).
Savage, L.I. (1954) Foundations ofStatistics, Wiley, New York.
Senkiene E. (1980) 'Properties of the conditional means and the variance of the
Wiener process in the presence of noise and the convergence of the Bayesian
optimization algorithms'.
In: Optimal Decision Theory, Inst. of Math. and
Cybernetics, Vilnius, 6, 18-40 (in Russian).
Shaltenis, V.R., Mockus, J.B. (1963) 'The choice of the optimal development of
distribution networks defining the reasonable zone'. In:
Conference Proc.,
Lectures, Problems ofthe applications ofProbabilistic and Statistical Methods,
State Pub!. House of Techn. Lit. Ukrainian S.S.R., Kiev, 80-85 (in Russian).
Shaltenis, V., Vamaite, A. (1975) 'On the method of reducing dimensionality in
multiextremal problems'.
In: Theory of Optimal Design, Inst. of Math. and
Cybernetics, Vilnius, 1, 23-42 (in Russian).

244
REFERENCES
Shaltenis, V., Varnaite, A. (1976) 'Structure of multiextremal problems'. In: Theory
of Optimal Design, Inst. of Math. and Cybernetics, Vilnius, 2, 67-78 (in
Russian).
Shaltenis, V. (1976) 'The investigation of the efficiency of the LP-search in some
multimodal problems'. In: Optimal Decision Theory, Inst. of Math. and
Cybernetics, Vilnius, 2, 59-66 (in Russian).
Shaltenis, V.R., Radvilavichute, I. (1977) 'On the separation of main variables in
extremal problems'.
In: Optimal Decision Theory, Inst. of Math. and
Cybernetics, Vilnius, 3, 57-71 (in Russian).
Shaltenis, V.R. (1980) 'The analysis of problems in interactive systems of
optimization'. Proc. Conf. on the Application of Random Search Methods in
CAD. Tallin, Valchus, 118-123 (in Russian).
Shaltenis, V.R., Radvilavichute, I. (1980) 'Investigation of the algorithm for the
separation of main variables'. In Optimal Decision Theory, Inst. of Math. and
Cybernetics, Vilnius, 6, 41-48 (in Russian).
Shaltenis, V.R., Dzemyda, G. (1982) 'The structure analysis of extremal problems
using some approximation of characteristics'. In: Optimal Decision Theory, Inst.
of Math. and Cybernetics, Vilnius, 8, 124-140 (in Russian).
Shaltenis, V.R., (1982) 'The efficiency of LP-search and the structure of
optimization problems'.
In: Optimal Decision Theory, Inst. of Math. and
Cybernetics, Vilnius, 8, 115-123 (in Russian).
Shepard, D. (1965) 'A two-dimensional interpolation function for irregularly-spaced
data'. In: Proc. 23rdNationai Conf. ACM, New York, .517-524.
Sobolj, I.M. (1968) Multi-dimensional numerical quadrature formulae and Haar
functions, Nauka, Moscow (in Russian).
Sobolj, I.M., Statnikov, R.B. (1981) The choice ofoptimal parameters in problems
with many objectivefunctions. Nauka, Moscow (in Russian).
Sobolj, I.M. (1985) 'Points of uniform filling of the multi-dimensional cube'.
In:
Mathematics and Cybernetics, 2, Znanie Moscow, 1-32 (in Russian).
Strongin, R.G. (1978) Numerical Methods in Multiextremal Problems. Nauka,
Moscow (in Russian).

REFERENCES
245
Tieshis, V.A. (1975) 'The method of variable metrics for local optimization of
functions of many variables with rectangular constraints'. In: Proc. Con! on
Computers, Kaunas, 111-114 (in Russian).
Tieshis, V.A. (1979) 'The structure of the package for nonlinear programming'.
In
Optimal Decision Theory, Inst. of Math. and Cybernetics, Vilnius, 5, 95-102 (in
Russian).
Tom, A.A. (1978) 'A search-clustering approach to global optimisation'.
In:
Towards Global Optimization 2, ed. Dixon, L.C.W. and Szego, G.P.,
North-Holland, 42-69.
Urjasjev, S.P. (1986) 'On adaptive parameter control in stochastic gradient
algorithms'.
In: Preprints of 2nd. IFAC Symposium on stochastic control.
Vilnius, Part 11, Moscow, 83-87 (in Russian).
Wasan, M.T. (1969) Stochastic Approximation, Cambridge University Press.
Zanevichus, D.l. (1984) 'The nonlinear simulation of integrated circuits'.
In:
Mathematical and computer simulation in microelectronics, Vilnius, 3-16 (in
Russian).
Zigliavski, A. (1985) Mathematical Theory of Global Random Search, Leningrad
University Publishing House, Leningrad (in Russian).
Zilinskas, A. (1978a) 'Investigation of multi-dimensional extrapolation under
uncertainty'.
In: Optimal Decision Theory, Inst. of Math. and Cybernetics,
Vilnius, 4, 27-44 (in Russian).
Zilinskas, A. (1978b) 'On one-dimensional multimodal minimization', Trans. 8-th
Prague Con! on Inform. Theory, Stat. Dec. Funct., Proc. B, Academia, Prague,
397-488.
Zilinskas, A. (1978c) 'On statistical models for multimodal optimiztion', Mat.
Operationsforsch. Statist., Ser. Statistics, 9, No.2, 255-266.
Zilinskas, A. (1979) 'An axiomatic approach to extrapolation under uncertainty',
Automatika i Telemechanika, 12, 66-70 (in Russian).
Zilinskas, A. (1980) 'The use of statistical models for construction of multimodal
optimization algorithms'. In: 3rd Czechoslovak-Soviet-Hungarian Seminar on
Information Theory, Czechoslovak Academy of Sciences, Prague, 219-224.

246
REFERENCES
Zilinskas, A. (1981) 'The software for the development of specifications for the
central sample of a colour picture tube'. In: Interactive Technology in CAD,
Tallin, the Kalinin Institute, p. 69.
Zilinskas, A. (1983) 'Axiomatic approach to statistical models and their use in
multimodal optimization theory, Mathematical Programming 22, 104-116.
Zilinskas, A. (1985) 'Axiomatic characteristics of a global optimization algorithm and
investigation of its search strategy', Operations Research Letters 4, No, 1,
35-39.
Zilinskas, A. (1986) Global Optimization., "Mokslas", Vilni.us (in Russian).
Zuev, G.M. (1984) Mathematical models ofdiseases and the analysis ofexperimental
data,
Dept. of Computational Mathematics, U.S.S.R. Academy of Sciences,
Moscow (in Russian).

SUBJECf INDEX
A priori distribution, xi, 2, 3, 20
Adaptive Bayesian methods, 20,21,
82-85,93,99, 168, 179, 183,
204
Algorithms of global optimization,
16-21,79-115,204-218
Average case,
xi, 22-25, 35, 36,
125-128
Bayesian approach, 1-6,20,21,
125, 158
Bayesian method
local optimization, xi, 3, 6, 11,
12, 16-18,64,79-85, 108-115,
163, 166, 168, 179, 183-184,
190, 193, 194
local optimization, 125-130,
151-155, 163, 192, 193
co-ordinate optimization, 169,
194
Bayesian risk, 5,21,36, 84, 95,
108, 109
Beam-deflection, 167
Clustering method, 100, 101, 105,
168, 183,200,212
Conditional expectation, 6-17, 36,
41, 52, 65, 66, 79, 82-85, 93
Consistency conditions, xi, 3, 21,
32,39,81-84,93
Convergence conditions
global optimization, 40,49,51,
52, 83, 84
local optimization, 130, 136-151
247
Decision function,
4-7, 21
Decision theory, 3,35
Dynamic programming, 6, 83
Electricity meter, 157
Expectation, see conditional
expectation
Extrapolation models, 85, 183,200,
207
Final decision, 5, 10
Gaussian field, 65-67
Homogeneity, xi, 3, 19,67-69
Heuristic, 3,93
Interactive Procedures, 98,99, 113,
114
Independence, 3,40,68,69, 71,
127
Likelihood, 25,28,40,94,95,97,
98
Linear constraints, 107, 172
Loss function, 5, 22, 23, 25, 36-38,
100, 126
Multi-objective optimization, 110,
113,114
Monte Carlo method, 99, 194, 195,
197,214,216
Noise, xii, 40, 43, 44, 52, 126, 154,
229

248
Nonlinear constraints, 109, 200,
221,226
Observations, 4,5, 11, 14, 16, 17,
20, 21, 40, 42, 63, 72
One-step approximation, xi, 16, 17,
4~ 51, 80, 83, 97,99,100
Partial differences, xi, 3, 68-70
Penalty function, 109, 172-174, 198
Probability denstity function
conditional, 39,41,68, 83
non-consistent conditional, 84
Shock-absorber, 171
Simplex method, 98, 169, 198,200,
226
Stochastic models, 21,39,81,83,
85,94,
SUBJECT INDEX
Structural characteristics, 118-124,
169, 232
Subjective preferences, xi, 25
Test-functions, 96,97,99, 100,
154, 202
Uniform search, 64,97,99, 168,
181, 183, 188,209
Variable metrics, 174, 188,200,
219
Variance, 3,41,65-71,76,77,84,
89, 91-93, 118, 127
Vibromotors, 160
Waveguide, 172
Wiener field, 52, 55, 68-70
Worst case, 1

APPENDIX 1
THE SOFTWARE FOR GLOBAL OPTIMIZATION FOR IBM
PC/XT/AT AND COMPATIBLES
Since the software for global optimization is in portable FORTRAN it can be used in
personal computers with corresponding operating systems. However, FORTRAN is
not the best language for personal computing where interactive procedures are
essential. So another version of the software was designed for the IBM compatible
personal computers.
The PC version of the global optimization software was implemented using the
programming language 'C', see Mockus (1987). The PC version implements most
of the methods of global optimization described in this book, namely BAYES l,
UNT, LPMIN, MIGl, MIG2, EXTR, LBAYES, ANAL!.
In addition, it
implements the methods of global optimization with nonlinear constraints and the
method for the multi-objective global optimization, see Mockus (1987). Naturally, in
the case of personal computing, the interactive possibilities are provided but users
who do not wish to influence the process of optimization interactively can use it
completely automatically.
The PC version of the software is a multi-level interactive system. On each
level the corresponding 'menu' is presented to the user, who can see and change the
parameters of method and input-output data, interactively.
The output can be graphical. At any moment the user can see the process of
optimization, and can watch the moving point Xn+l on the central two-dimensional
projection of the objective functionf(x), see Figure A.I.
The FORTRAN version is provided on the disc (inside back cover).
To obtain the PC and updated versions, you should get in touch directly with
the author:
Prof. J. B. Mockus,
Institute of Mathematics and Cybernetics,
Academy of Sciences of the Lithuanian SSR,
232600 VILNIUS,
USSR.
249

250
APPENDIX 1
G OBAL
MIN MUM
Figure A.l
The graphical output: the central projection of the objective functionf(x) as a function
of two variables with fixed values of remaining variables.
One of the first examples of global optimization - the common electric meter,
designed in 1962, see section 8.2 - is still competing successfully in the world market
without major changes in the original configuration.

APPENDIX 2
HOW THE GLOBAL OPTIMIZATION SOFTWARE CAN
IMPROVE THE PERFORMANCE OF YOUR CAD SYSTEM
All well known CAD packages have GRAPHICS
Most of them have DATA BASES
Some of them have LINEAR or NONLINEAR PROGRAMMING Procedures
Very few have good software for GLOBAL OPTIMIZATION
WHAT CAN GLOBAL OPTIMIZATION DO FOR YOU?
When you are designing a complicated system you are confronted with the problem
of how to choose the values of tens or even hundreds of parameters in order to
optimize the system. Good interactive graphics can help a great deal. The usual
linear and nonlinear programming software can also be useful if your system can be
represented by linear or unimodal functions but this is seldom the case.
So what is the result?
The usual result is that you get a design which looks reasonably good, but it
can happen that it is a long way from the best possible decision both in terms of
money and in the quality of the product that you are designing.
If your CAD has a properly tuned Global Optimization Package, you can get
the design which is really GLOBALLY OPTIMAL. This means that it cannot be
significantly improved in terms of the objective which you wish to optimize. It can
save you millions of dollars and will give you the edge over your competitors.
The global optimization procedures can work automatically or interactively
depending on your problems and preferences.
HOW TO INCLUDE THE GLOBAL OPTIMIZATION INTO YOUR CAD
SOFTWARE
There are two basic versions of the global optimization software.
The first is in portable FORTRAN
which means that it can run on any
computer with standard FORTRAN. It was extensively tested on PDP, VAX and
IBM mainframe computers and on personal computers. The second version is in C
and is adjusted to IBM PC/Xf/AT compatible portable computers.
There are several ways to include the Global optimization software into your
CAD software.
251

252
APPENDIX 2
The best way naturally is by co-operation during the development of the CAD
software. The other way is to include the Global Optimization package as an addition
to the existing CAD software.
In both cases the authors of Global Optimization are ready to help you
promptly in every possible way.

APPENDIX 3
MACHINE DEPENDENT CONSTANTS OF PORTABLE
FORTRAN
In the package all the dependent constants are fixed because all of them could be
useful during extensions in the future.
For this version of the software no
double-precision constants are used so these are omitted.
The constants are given in Table 3, where columns represent different
computers and rows correspond to different single-precision constants. The longer
constants are written in two rows.
The integer N which is repeated L times is
denoted as N(Lt).
253

VAX-11
BURROUGHS
CD
CRAY-1
HONEY-
IBM
UNIVAC
NVI
WELL
.I>-
No.
Constant
FORTRAN
1700
5700/6700/
6000/
600/
360/
1100
IV-PLUS
7700
7000
6000
370
1
IlMACH(l)
5
7
5
5
100
5
5
5
2
IlMACH(2)
6
2
6
6
101
6
6
6
3
IlMACH(3)
7
2
7
7
102
43
7
7
4
IlMACH(4)
6
2
6
6
101
6
6
6
5
IlMACH(5)
32
36
48
60
64
36
32
36
6
IlMACH(6)
4
4
6
10
8
6
4
6
7
IlMACH(7)
2
2
2
2
2
2
2
2
8
IlMACH(8)
31
33
39
48
63
35
31
35
9
IlMACH(9)
214748
ZlFFF
0000
0000
7(2lt)B
037(llt)
Z7F(7t) 037(llt)
3647
FFFFF
7(13t)
7(16t)B
10
IlMACH(l0)
2
2
8
2
2
2
16
2
11
IlMACH(ll)
24
24
13
48
47
27
6
27
12
IlMACH(l2)
-127
-256
-50
-974
-8192
-127
-6
-128
13
IlMACH(13)
127
255
76
1070
8190
127
63
127
14
R1MACH(l)
ZOOOO
Z4OO8
0177
00014
200004
04024
ZOO1
00004
0080
0ססoo
0(l2t)
0(l5t)B
0(l5t)B
0(8t)
0000
0(8t)
15
R1MACH(2)
ZFFFF
Z5FFF
oo7(l5t)
3776
57776
0376
Z7FF
037(llt)
7FFF
FFFFF
7(l6t)B
7(l5t)6B
7(9t)
FFFFF
16
R1MACH(3)
ZOOOO
Z4E98
01311
16404
377224
07144
Z3B
01464
3480
0ססoo
0(l2t)
0(l5t)B
0(l5t)B
0(8t)
00000
0(8t)
17
R1MACH(4)
ZOOOO
Z4EA8
01301
16414
377234
07164
Z3C1
01474
3500
00000
0(l2t)
0(15t)B
0(l5t)B
0(8t)
0ססoo
0(8t)
18
R1MACH(5)
Z209B
Z500E
01157163
171646420
377774642
0207764642 Z411
0177464
3F9A
730E8
034761675 23241175720B 3241175720B 02324
34413
202324
~
tI1
Table A.3
8-
><
w
Machine dependent constants of portable FORTRAN

