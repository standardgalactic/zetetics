


Chapman & Hall/CRC
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2010 by Taylor and Francis Group, LLC
Chapman & Hall/CRC is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Printed in the United States of America on acid-free paper
10 9 8 7 6 5 4 3 2 1
International Standard Book Number: 978-1-58488-720-1 (Hardback)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts 
have been made to publish reliable data and information, but the author and publisher cannot assume 
responsibility for the validity of all materials or the consequences of their use. The authors and publishers 
have attempted to trace the copyright holders of all material reproduced in this publication and apologize to 
copyright holders if permission to publish in this form has not been obtained. If any copyright material has 
not been acknowledged please write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmit-
ted, or utilized in any form by any electronic, mechanical, or other means, now known or hereafter invented, 
including photocopying, microfilming, and recording, or in any information storage or retrieval system, 
without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.
com (http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood 
Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that provides licenses and 
registration for a variety of users. For organizations that have been granted a photocopy license by the CCC, 
a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used 
only for identification and explanation without intent to infringe.
Library of Congress Cataloging-in-Publication Data
Congdon, P.
Applied Bayesian hierarchical methods / Peter D. Congdon.
p. cm.
Includes bibliographical references and index.
ISBN 978-1-58488-720-1 (hardcover : alk. paper)
1.  Multilevel models (Statistics) 2.  Bayesian statistical decision theory.  I. Title.
QA279.5.C66 2010
519.5’42--dc22 
2010008252
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com 

Contents
Preface
xi
Author
xiii
1
Bayesian Methods for Complex Data: Estimation
and Inference
1
1.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Posterior Inference from Bayes Formula
. . . . . . . . . . . .
3
1.3
Markov Chain Monte Carlo Sampling in Relation to
Monte Carlo Methods: Obtaining Posterior Inferences
. . . .
4
1.4
Hierarchical Bayes Applications
. . . . . . . . . . . . . . . .
6
1.5
Metropolis Sampling . . . . . . . . . . . . . . . . . . . . . . .
9
1.6
Choice of Proposal Density
. . . . . . . . . . . . . . . . . . .
11
1.7
Obtaining Full Conditional Densities
. . . . . . . . . . . . .
12
1.8
Metropolis–Hastings Sampling
. . . . . . . . . . . . . . . . .
15
1.9
Gibbs Sampling
. . . . . . . . . . . . . . . . . . . . . . . . .
19
1.10 Assessing Eﬃciency and Convergence:
Ways of Improving Convergence
. . . . . . . . . . . . . . . .
20
1.10.1 Hierarchical model parameterization
to improve convergence
. . . . . . . . . . . . . . . . .
23
1.10.2 Multiple chain methods . . . . . . . . . . . . . . . . .
24
1.11 Choice of Prior Density
. . . . . . . . . . . . . . . . . . . . .
26
1.11.1 Including evidence . . . . . . . . . . . . . . . . . . . .
27
1.11.2 Assessing posterior sensitivity: Robust priors
. . . . .
28
1.11.3 Problems in prior selection in hierarchical
Bayes models . . . . . . . . . . . . . . . . . . . . . . .
31
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . . .
34
2
Model Fit, Comparison, and Checking
43
2.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
43
2.2
Formal Methods: Approximating Marginal Likelihoods
. . .
45
2.2.1
Importance and bridge sampling estimates . . . . . . .
47
2.2.2
Path sampling
. . . . . . . . . . . . . . . . . . . . . .
49
2.2.3
Marginal likelihood for hierarchical models
. . . . . .
50
2.3
Eﬀective Model Dimension and Deviance
Information Criterion
. . . . . . . . . . . . . . . . . . . . . .
54
2.4
Variance Component Choice and Model Averaging . . . . . .
60
v

vi
Contents
2.5
Predictive Methods for Model Choice and Checking
. . . . .
67
2.5.1
Predictive model checking and choice . . . . . . . . . .
67
2.5.2
Posterior predictive model checks . . . . . . . . . . . .
70
2.5.3
Mixed predictive checks . . . . . . . . . . . . . . . . .
72
2.6
Estimating Posterior Model Probabilities
. . . . . . . . . . .
76
2.6.1
Random eﬀects models . . . . . . . . . . . . . . . . . .
80
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . . .
81
3
Hierarchical Estimation for Exchangeable Units:
Continuous and Discrete Mixture Approaches
89
3.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
89
3.2
Hierarchical Priors for Ensemble Estimation using
Continuous Mixtures
. . . . . . . . . . . . . . . . . . . . . .
91
3.3
The Normal-Normal Hierarchical Model and Its
Applications
. . . . . . . . . . . . . . . . . . . . . . . . . . .
93
3.4
Prior for Second Stage Variance
. . . . . . . . . . . . . . . .
97
3.4.1
Nonconjugate priors . . . . . . . . . . . . . . . . . . .
99
3.5
Multivariate Meta-Analysis . . . . . . . . . . . . . . . . . . .
100
3.6
Heterogeneity in Count Data: Hierarchical
Poisson Models . . . . . . . . . . . . . . . . . . . . . . . . . .
104
3.6.1
Nonconjugate Poisson mixing . . . . . . . . . . . . . .
107
3.7
Binomial and Multinomial Heterogeneity
. . . . . . . . . . .
109
3.7.1
Nonconjugate priors for binomial mixing . . . . . . . .
111
3.7.2
Multinomial mixtures
. . . . . . . . . . . . . . . . . .
113
3.7.3
Ecological inference using mixture models . . . . . . .
114
3.8
Discrete Mixtures and Nonparametric
Smoothing Methods
. . . . . . . . . . . . . . . . . . . . . . .
116
3.8.1
Finite mixtures of parametric densities . . . . . . . . .
117
3.8.2
Finite mixtures of standard densities . . . . . . . . . .
118
3.8.3
Inference in mixture models . . . . . . . . . . . . . . .
119
3.8.4
Particular types of discrete mixture model . . . . . . .
121
3.8.5
The logistic-normal alternative to the
Dirichlet prior
. . . . . . . . . . . . . . . . . . . . . .
123
3.9
Nonparametric Mixing via Dirichlet Process
and Polya Tree Priors
. . . . . . . . . . . . . . . . . . . . . .
124
3.9.1
Specifying the baseline density
. . . . . . . . . . . . .
127
3.9.2
Truncated Dirichlet processes and
stick-breaking priors . . . . . . . . . . . . . . . . . . .
128
3.9.3
Polya Tree priors . . . . . . . . . . . . . . . . . . . . .
129
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . . .
133
4
Structured Priors Recognizing Similarity
over Time and Space
141
4.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
141
4.2
Modeling Temporal Structure: Autoregressive Models
. . . .
144

Contents
vii
4.2.1
Random coeﬃcient autoregressive models . . . . . . .
145
4.2.2
Low order autoregressive models . . . . . . . . . . . .
146
4.2.3
Antedependence models . . . . . . . . . . . . . . . . .
148
4.3
State–Space Priors for Metric Data
. . . . . . . . . . . . . .
149
4.3.1
Simple signal models . . . . . . . . . . . . . . . . . . .
150
4.3.2
Sampling schemes
. . . . . . . . . . . . . . . . . . . .
152
4.3.3
Basic structural model . . . . . . . . . . . . . . . . . .
154
4.3.4
Identiﬁcation questions
. . . . . . . . . . . . . . . . .
155
4.4
Time Series for Discrete Responses: State–Space Priors
and Alternatives
. . . . . . . . . . . . . . . . . . . . . . . . .
160
4.4.1
Other approaches . . . . . . . . . . . . . . . . . . . . .
163
4.5
Stochastic Variances . . . . . . . . . . . . . . . . . . . . . . .
167
4.6
Modeling Discontinuities in Time
. . . . . . . . . . . . . . .
171
4.7
Spatial Smoothing and Prediction for Area Data . . . . . . .
176
4.8
Conditional Autoregressive Priors
. . . . . . . . . . . . . . .
179
4.8.1
Linking conditional and joint speciﬁcations
. . . . . .
180
4.8.2
Alternative conditional priors . . . . . . . . . . . . . .
181
4.8.3
ICAR(1) and convolution priors . . . . . . . . . . . . .
183
4.9
Priors on Variances in Conditional Spatial Models
. . . . . .
185
4.10 Spatial Discontinuity and Robust Smoothing
. . . . . . . . .
187
4.11 Models for Point Processes
. . . . . . . . . . . . . . . . . . .
192
4.11.1 Discrete convolution models . . . . . . . . . . . . . . .
195
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . . .
200
5
Regression Techniques Using Hierarchical Priors
207
5.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
207
5.2
Regression for Overdispersed Discrete Data . . . . . . . . . .
209
5.2.1
Overdispersed binomial and
multinomial regression . . . . . . . . . . . . . . . . . .
211
5.3
Latent Scales for Binary and Categorical Data
. . . . . . . .
215
5.3.1
Augmentation for ordinal responses
. . . . . . . . . .
219
5.4
Nonconstant Regression Relationships and
Variance Heterogeneity
. . . . . . . . . . . . . . . . . . . . .
221
5.5
Heterogenous Regression and Discrete Mixture
Regressions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
222
5.5.1
Discrete mixture regressions . . . . . . . . . . . . . . .
223
5.5.2
Zero-inﬂated mixture regression . . . . . . . . . . . . .
226
5.6
Time Series Regression: Correlated Errors and
Time-Varying Regression Eﬀects
. . . . . . . . . . . . . . . .
231
5.7
Time-Varying Regression Eﬀects
. . . . . . . . . . . . . . . .
234
5.8
Spatial Correlation in Regression Residuals
. . . . . . . . . .
240
5.8.1
Spatial lag and spatial error models
. . . . . . . . . .
241
5.9
Spatially Varying Regression Eﬀects: Geographically
Weighted Linear Regression and Bayesian Spatially
Varying Coeﬃcient Models
. . . . . . . . . . . . . . . . . . .
244

viii
Contents
5.9.1
Bayesian spatially varying coeﬃcient models
. . . . .
246
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . . .
250
6
Bayesian Multilevel Models
257
6.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
257
6.2
The Normal Linear Mixed Model for Hierarchical Data
. . .
258
6.2.1
The Lindley–Smith model format . . . . . . . . . . . .
261
6.3
Discrete Responses: General Linear Mixed Model,
Conjugate, and Augmented Data Models
. . . . . . . . . . .
262
6.3.1
Augmented data multilevel models . . . . . . . . . . .
264
6.3.2
Conjugate cluster eﬀects . . . . . . . . . . . . . . . . .
265
6.4
Crossed and Multiple Membership
Random Eﬀects
. . . . . . . . . . . . . . . . . . . . . . . . .
270
6.5
Robust Multilevel Models . . . . . . . . . . . . . . . . . . . .
273
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . . .
277
7
Multivariate Priors, with a Focus on Factor
and Structural Equation Models
281
7.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
281
7.2
The Normal Linear SEM and Factor Models
. . . . . . . . .
283
7.2.1
Forms of model . . . . . . . . . . . . . . . . . . . . . .
284
7.2.2
Marginal and complete data likelihoods, and
Markov Chain Monte Carlo sampling . . . . . . . . . .
285
7.3
Identiﬁability and Priors on Loadings
. . . . . . . . . . . . .
287
7.3.1
An illustration of identiﬁability issues
. . . . . . . . .
289
7.4
Multivariate Exponential Family Outcomes
and General Linear Factor Models
. . . . . . . . . . . . . . .
292
7.4.1
Multivariate Poisson data . . . . . . . . . . . . . . . .
293
7.4.2
Multivariate binary data and item response models . .
295
7.4.3
Latent scale binary models
. . . . . . . . . . . . . . .
297
7.4.4
Categorical data
. . . . . . . . . . . . . . . . . . . . .
298
7.5
Robust Options in Multivariate and Factor Analysis . . . . .
303
7.5.1
Discrete mixture multivariate models . . . . . . . . . .
303
7.5.2
Discrete mixtures in SEM and factor models
. . . . .
304
7.5.3
Robust density assumptions in factor models
. . . . .
307
7.6
Multivariate Spatial Priors for Discrete Area Frameworks
. .
311
7.7
Spatial Factor Models
. . . . . . . . . . . . . . . . . . . . . .
315
7.8
Multivariate Time Series
. . . . . . . . . . . . . . . . . . . .
318
7.8.1
Multivariate dynamic linear models
. . . . . . . . . .
319
7.8.2
Dynamic factor analysis . . . . . . . . . . . . . . . . .
321
7.8.3
Multivariate stochastic volatility . . . . . . . . . . . .
323
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . . .
332
8
Hierarchical Models for Panel Data
337
8.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
337

Contents
ix
8.2
General Linear Mixed Models for Panel Data . . . . . . . . .
338
8.2.1
Centered or noncentered priors . . . . . . . . . . . . .
341
8.2.2
Priors on permanent random eﬀects
. . . . . . . . . .
343
8.2.3
Priors for random covariance matrix and random
eﬀect selection
. . . . . . . . . . . . . . . . . . . . . .
345
8.2.4
Priors for multiple sources of error variation . . . . . .
348
8.3
Temporal Correlation and Autocorrelated
Residuals
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
351
8.3.1
Explicit temporal schemes for errors . . . . . . . . . .
352
8.4
Panel Categorical Choice Data
. . . . . . . . . . . . . . . . .
357
8.5
Observation-Driven Autocorrelation:
Dynamic Panel Models
. . . . . . . . . . . . . . . . . . . . .
362
8.5.1
Dynamic panel models for discrete data . . . . . . . .
364
8.6
Robust Panel Models: Heteroscedasticity, Generalized
Error Densities, and Discrete Mixtures
. . . . . . . . . . . .
370
8.6.1
Robust panel data models:
discrete mixture models . . . . . . . . . . . . . . . . .
373
8.7
Multilevel, Multivariate, and Multiple Time Scale
Longitudinal Data
. . . . . . . . . . . . . . . . . . . . . . . .
380
8.7.1
Latent trait longitudinal models
. . . . . . . . . . . .
384
8.7.2
Multiple scale panel data
. . . . . . . . . . . . . . . .
386
8.8
Missing Data in Panel Models
. . . . . . . . . . . . . . . . .
393
8.8.1
Forms of missingness regression (selection
approach) . . . . . . . . . . . . . . . . . . . . . . . . .
396
8.8.2
Common factor models
. . . . . . . . . . . . . . . . .
397
8.8.3
Missing predictor data . . . . . . . . . . . . . . . . . .
399
8.8.4
Pattern mixture models . . . . . . . . . . . . . . . . .
401
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . . .
406
9
Survival and Event History Models
413
9.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
413
9.2
Survival Analysis in Continous Time
. . . . . . . . . . . . .
414
9.2.1
Counting process functions
. . . . . . . . . . . . . . .
416
9.2.2
Parametric hazards . . . . . . . . . . . . . . . . . . . .
417
9.2.3
Accelerated hazards
. . . . . . . . . . . . . . . . . . .
419
9.3
Semi-Parametric Hazards
. . . . . . . . . . . . . . . . . . . .
423
9.3.1
Cumulative hazard speciﬁcations . . . . . . . . . . . .
425
9.4
Including Frailty . . . . . . . . . . . . . . . . . . . . . . . . .
428
9.4.1
Cure rate models . . . . . . . . . . . . . . . . . . . . .
430
9.5
Discrete Time Hazard Models
. . . . . . . . . . . . . . . . .
435
9.5.1
Life tables . . . . . . . . . . . . . . . . . . . . . . . . .
437
9.6
Dependent Survival Times: Multivariate and Nested
Survival Times . . . . . . . . . . . . . . . . . . . . . . . . . .
441
9.7
Competing Risks . . . . . . . . . . . . . . . . . . . . . . . . .
447
9.7.1
Modeling frailty
. . . . . . . . . . . . . . . . . . . . .
449

x
Contents
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . .
451
10 Hierarchical Methods for Nonlinear Regression
459
10.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . .
459
10.2
Nonparametric Basis Function Models
for the Regression Mean
. . . . . . . . . . . . . . . . . . .
460
10.2.1
Mixed model splines
. . . . . . . . . . . . . . . . .
462
10.2.2
Model selection . . . . . . . . . . . . . . . . . . . .
464
10.2.3
Basis functions other than truncated
polynomials . . . . . . . . . . . . . . . . . . . . . .
465
10.3
Multivariate Basis Function Regression
. . . . . . . . . . .
468
10.4
Heteroscedasticity via Adaptive Nonparametric
Regression
. . . . . . . . . . . . . . . . . . . . . . . . . . .
476
10.5
General Additive Methods
. . . . . . . . . . . . . . . . . .
479
10.6
Nonparametric Regression Methods
for Longitudinal Analysis . . . . . . . . . . . . . . . . . . .
483
Appendix: Computational Notes
. . . . . . . . . . . . . . . . . .
491
Appendix 1: Using WinBUGS and BayesX
495
A1.1
WinBUGS: Compiling, Initializing,
and Running Programs . . . . . . . . . . . . . . . .
495
A1.2
WinBUGS Steps in Program Checking
and Execution . . . . . . . . . . . . . . . . . . . . .
495
A1.3
Using BayesX . . . . . . . . . . . . . . . . . . . . .
498
References
501
Index
565

Preface
The use of Markov Chain Monte Carlo (MCMC) methods for estimating
hierarchical models, often involving complex data structures, is sometimes
described as a revolutionary development, and has arguably facilitated the
ﬁtting of such models. This book is intended to provide an intermediate level
treatment of Bayesian hierarchical models and their applications. In a sense,
all Bayesian models are hierarchical but the present volume seeks to demon-
strate the advantages of a Bayesian approach to datasets involving inferences
for collections of related units or variables, or in methods (e.g., nonlinear re-
gression) for which parameters can be treated as random collections. It is in
such applications that the Bayesian approach based on MCMC techniques has
provided particular beneﬁts.
Examples of the application settings that occur are provided by meta-
analysis, data structured in space or time, multilevel and longitudinal data,
multivariate data, and survival time data. Such settings form the subject
matter of diﬀerent chapters in the book and an applied focus, with attention
to computational issues, is uppermost. The main package used for worked
examples is WinBUGS, which allows the analyst to explore alternative like-
lihood assumptions, regression structures or assumptions on prior densities,
while parameter sampling mechanisms rely on the package’s inbuilt updat-
ing schemes. WinBUGS can be obtained from http://www.mrc-bsu.cam.
ac.uk/bugs and its successor, OpenBUGS, is available at http://mathstat.
helsinki.ﬁ/openbugs/. The same ﬂexibility, though in a narrower range of
modeling settings, applies to the BayesX package. BayesX can be obtained
at www.stat.uni-muenchen.de/˜bayesx, and is particularly useful in non-
linear regression, as shown in Chapter 10. To demonstrate MCMC sam-
pling from ﬁrst principles, Chapter 1 also includes worked examples using the
R package.
My acknowledgments are ﬁrst to Chapman & Hall/CRC for giving me the
opportunity to develop the book and for their encouragement in progressing it
to ﬁnality. Particular thanks are due to Sarah Morris at C&H/CRC. For com-
ments on particular chapters or advice on methods used in particular sections
of the book, my thanks are due to Sid Chib, Valen Johnson, Kalyan Das, and
Peter Hooper. A set of programs linked to the worked examples in the book is
available from “Downloads and Updates” at the CRC Web site for this book,
xi

xii
Preface
namely, http://www.crcpress.com/product/isbn/9781584887201. Comments
on the book’s content, or on these programs, would be appreciated and can
be sent to me at p.congdon@qmul.ac.uk.
Peter Congdon
Geography & Centre for Statistics, QMUL

Author
Peter Congdon is a health statistician, originally qualiﬁed at the London
School of Economics, with particular interest in spatial variations in health,
spatial statistical techniques and Bayesian methods in general. He is aﬃli-
ated with the QMUL Centre for Statistics and the QMUL Department of
Geography, and since 2001 has been a research professor at QMUL. He is the
author of a wide range of articles and books, in both statistics and applica-
tions areas, and is an elected member of the International Statistical Institute
and a Chartered Statistician.
xiii

1
Bayesian Methods for Complex Data:
Estimation and Inference
1.1
Introduction
The Bayesian approach to inference focuses on updating knowledge about
the unknowns, θ, in a statistical model on the basis of observations y, with
revised knowledge expressed in the posterior density, p(θ|y). The sample of
observations y being analyzed provides new information about the unknowns,
while the prior density p(θ) of the unknowns represents accumulated knowl-
edge about them before observing or analyzing the data y. Hypotheses on
parameters are similarly based on posterior probabilities conditional on the
observed data.
Compared to frequentist approaches, there is considerable ﬂexibility with
which prior evidence about parameters can be incorporated in an analysis,
and use of informative priors (to express accumulated knowledge) can reduce
the possibility of confounding and provides a natural basis for evidence syn-
thesis (Dunson, 2001; Shoemaker et al., 1999). The Bayes approach provides
uncertainty intervals on parameters that are consonant with everyday inter-
pretations (Willink and Lira, 2005), and has no problems in comparing the ﬁt
of non-nested models, such as a nonlinear model and its linearized version.
Furthermore, Bayesian estimation and inference has a number of advan-
tages in terms of its relevance to the types of data and problems tackled by
modern scientiﬁc research. These are a primary focus later in the book. For ex-
ample, much of the data in social and health research has a complex structure,
involving hierarchical nesting of subjects (e.g., pupils within schools), crossed
classiﬁcations (e.g., pupils classiﬁed by school and by homeplace), spatially
conﬁgured data, or repeated measures on subjects (MacNab et al., 2004).
The Bayesian approach naturally adapts to hierarchically or spatio-temporally
correlated eﬀects via conditionally speciﬁed hierarchical priors under a three-
stage prior (Gustafson et al., 2006; Lindley and Smith, 1972), with the ﬁrst
stage specifying the likelihood of the data given unknown random individual
or cluster eﬀects, the second stage specifying the density of the population
of random eﬀects, and the third stage providing priors (or hyperpriors) on
the parameters of the population density. Bayesian estimation via repeated
sampling from posterior densities facilitates modeling of complex data with
1

2
Applied Bayesian Hierarchical Methods
random eﬀects treated as unknowns, and not integrated out as often in fre-
quentist approaches (Davidian and Giltinan, 2003). The integrated likelihood
approach may become infeasible or unreliable in complex varying coeﬃcient
models (Tutz and Kauermann, 2003), and diﬀerent parameter estimates may
be obtained according to the maximization methods used (Molenberghs and
Verbeke, 2004).
While Bayesian inference may have beneﬁts, until relatively recently its
practical implementation was impeded by computational restrictions. The
increased application of Bayesian methods has owed much to the development
of Markov Chain Monte Carlo (MCMC) algorithms for estimation (Gelfand
and Smith, 1990; Gilks et al., 1996), which draw repeated parameter sam-
ples from the posterior distributions of statistical models, including complex
models (e.g., models with multiple or nested random eﬀects). Sampling-based
parameter estimation via MCMC provides a full posterior density of a para-
meter so that any clear non-normality is apparent (Dellaportas and Smith,
1993), and hypotheses about parameters or interval estimates can be assessed
from the MCMC samples without assumptions of asymptotic normality that
typically underlie frequentist estimation.
As mentioned in the preface, a substantial emphasis in the book is on
practical implementation for tutorial purposes, via illustrative data analysis
and attention to statistical computing. Accordingly, the worked examples in
the rest of the chapter illustrate MCMC sampling and Bayesian posterior
inference from ﬁrst principles, mostly using R code. In subsequent chapters,
WinBUGS (which incorporates inbuilt MCMC algorithms) and to a lesser
extent BayesX are used for computation. To retain some of the advantages of
working in R (e.g., graphical presentations) and to access already developed
inference tools, one may use1 the R2WinBUGS facility (Sturtz et al., 2005),
which links R to WinBUGS1.4.
As just mentioned, Bayesian modeling of hierarchical and random eﬀect
models via MCMC techniques has extended the scope for modern data analy-
sis. Despite this, application of Bayesian techniques in such models also raises
particular issues, discussed below or in later chapters. These include:
1.
propriety and identiﬁability issues when diﬀuse priors are applied to
variance or dispersion parameters for collections of random eﬀects
(Hadjicostas and Berry, 1999; Hobert and Casella, 1996; Palmer and
Pettit, 1996);
2.
selecting the most suitable form of prior for variance or dispersion
parameters, such as inverse gamma, lognormal, or uniform priors
on variances (Gelman, 2006a);
3.
appropriate priors for models with several sources of random vari-
ation, e.g., separate conjugate priors, as against shrinkage priors,
which ensure propriety and express each variance as a component
of total random variation (Daniels, 1999; Natarajan and Kass, 2000;
Wakeﬁeld, 2007);

Bayesian Methods for Complex Data: Estimation and Inference
3
4.
potential bias in shrinkage estimation, such as oversmoothing in
the presence of genuine outliers in spatial applications (Conlon and
Louis, 1999);
5.
the scope for speciﬁcation bias in hierarchical models for complex
data structures where a range of plausible model structures are
possible (Chiang et al., 1999).
1.2
Posterior Inference from Bayes Formula
Statistical analysis uses probability models to summarize a set of observations,
y = (y1, . . . , yn), by a collection of unknown parameters of a particular dimen-
sion (say d), θ = (θ1, . . . , θd). Consider the joint density p(y, θ) = p(y|θ)p(θ),
where p(y|θ) is the sampling model or likelihood, and p(θ) deﬁnes existing
knowledge, or expresses assumptions regarding the unknowns that can be jus-
tiﬁed by the nature of the application (e.g., that random eﬀects are spatially
distributed in an area application). The analysis seeks to update knowledge
about the unknowns, θ, using the data, y, and so interest focuses on the poste-
rior density p(θ|y) of the unknowns. Since p(y, θ) also equals p(y)p(θ|y), where
p(y) is the unconditional density of the data (also known as the marginal
likelihood), one may obtain,
p(y, θ) = p(y|θ)p(θ) = p(y)p(θ|y).
(1.1)
This can be rearranged to provide the required posterior density as,
p(θ|y) = p(y|θ)p(θ)
p(y)
.
(1.2)
The marginal likelihood p(y) may be obtained by integrating the numera-
tor on the right side of Equation 1.2 over the support for θ, namely,
p(y) =

p(y|θ)p(θ)dθ.
From Equation 1.2, the term p(y) acts as a normalizing constant necessary
to ensure p(θ|y) integrates to 1, and so one may write,
p(θ|y) ∝p(y|θ)p(θ),
(1.3)
namely, that the posterior density (updated evidence) is proportional to the
likelihood (data evidence) times the prior (historic evidence or elicited model
assumptions).
In some cases when the prior on θ is conjugate with the posterior on θ (i.e.,
has the same density form), the posterior density and marginal likelihood can

4
Applied Bayesian Hierarchical Methods
be obtained analytically. When θ is low-dimensional, numerical integration
is an alternative, and approximations to the required integrals can be used,
such as the Laplace approximation (Raftery, 1996). In more complex appli-
cations, such approximations are not feasible and the integration to obtain
p(y) is intractable, so that direct sampling from p(θ|y) is not feasible. In such
situations, MCMC methods provide a way to sample from p(θ|y) without
necessarily knowing its analytic form. They create a Markov chain of sam-
pled values, θ(1), . . . , θ(T ), with transition kernel, K(θcand|θcurr), which have
p(θ|y) as their limiting distribution. Using the large samples from the poste-
rior distribution obtained by MCMC, one can estimate posterior quantities of
interest, such as posterior means, medians, and highest density regions (Chen
and Shao, 1999; Hyndman, 1996).
1.3
Markov Chain Monte Carlo Sampling
in Relation to Monte Carlo Methods:
Obtaining Posterior Inferences
MCMC methods are iterative sampling methods that can be encompassed
within the broad class of Monte Carlo methods. However, MCMC methods
must be distinguished from conventional Monte Carlo methods that generate
independent simulations,

u(1), u(2), . . . , u(T )
, from a target density, π(u).
From such simulations the expectation of a function g(u) under π(u), namely,
Eπ[g(u)] =

g(u)π(u)du,
is estimated as,
¯g =
T

t=1
g

u(t)
,
and, under independent sampling from π(u), ¯g tends to Eπ[g(u)] as T →∞.
However, independent sampling from the posterior density, p(θ|y), is not usu-
ally feasible.
When suitably implemented, MCMC methods oﬀer an eﬀective alternative
way to generate samples from the joint posterior distribution, p(θ|y), but diﬀer
from conventional Monte Carlo methods in that successive sampled parame-
ters are dependent or autocorrelated. The target density for MCMC samples
is therefore the posterior density, π(θ) = p(θ|y), and MCMC sampling is espe-
cially relevant when the posterior cannot be stated exactly in analytic form,
e.g., when the prior density assumed for θ is not conjugate with the likelihood
p(y|θ). The fact that successive sampled values are dependent means that
larger samples are needed for equivalent precision, and the eﬀective number

Bayesian Methods for Complex Data: Estimation and Inference
5
of samples is less than the nominal number. MCMC techniques can also be
used to generate random samples from particular statistical distributions, so
oﬀering an alternative to techniques such as rejection sampling and inverse
transform sampling.
For the parameter sampling case, assume a preset initial parameter value,
θ(0). Then MCMC methods involve generating a correlated sequence of sam-
pled values, θ(t) (t = 1, 2, 3, . . .), where updated values, θ(t), are drawn from
a transition distribution,
K

θ(t)|θ(0), . . . , θ(t−1)
= K

θ(t)|θ(t−1)
,
that is Markovian in the sense of depending only on θ(t−1). The transition
distribution, K(θ(t)|θ(t−1)), is chosen to satisfy additional conditions, ensur-
ing that the sequence has the joint posterior density, p(θ|y), as its stationary
distribution. These conditions typically reduce to requirements on the pro-
posal and acceptance procedure used to generate new parameter samples. The
proposal density and acceptance rule must be speciﬁed in a way that guar-
antees irreducibility and positive recurrence; see, e.g., Andrieu and Moulines
(2006). Under such conditions, the sampled parameters, θ(t) {t = B, B +
1, . . . , T}, beyond a certain burn-in phase in the sampling (of length B) can
be viewed as a random sample from p(θ|y) (Roberts and Rosenthal, 2004).
In practice, MCMC methods are applied separately to individual param-
eters or groups (“blocks”) of more than one parameter (Roberts and Sahu,
1997). In fact, diﬀerent MCMC methods may be applied to diﬀerent parame-
ters. So, assuming θ contains more than one parameter, and consists of C com-
ponents or “blocks,” {θ1, . . . , θC}, diﬀerent updating methods may be used for
each component. If there are d parameters, the number of blocks may well be
less than d, since several parameters in a single block may be updated jointly
(a so-called “block update”). Note that for simplicity, we will often represent
the MCMC algorithms as involving a generic parameter θ.
There is no limit to the number of samples T of θ that may be taken from
the posterior density p(θ|y). Estimates of the marginal posterior densities for
each parameter can be made from the MCMC samples, including estimates of
location parameters (e.g., posterior means, modes or medians), together with
the estimated certainty or precision of these parameters in terms of posterior
standard deviations, credible intervals, or highest posterior density intervals.
Such samples can also be used to provide probabilities on hypotheses relating
to the parameters (Smith and Gelfand, 1992). For example, one form of 95%
credible interval for θh may be estimated using the 0.025 and 0.975 quantiles
of the sampled output {θ(t)
h , t = B + 1, . . . , T}. To reduce irregularities in the
histogram of sampled values for a particular parameter, a smooth form of the
posterior density can be approximated by applying kernel density methods to
the sampled values.
Monte Carlo posterior summaries typically include estimated posterior
means and variances of the parameters, obtainable as moment estimates from
the MCMC output, namely,

6
Applied Bayesian Hierarchical Methods
ˆE(θh) = ¯θh =
T

t=B+1
θ(t)
h /(T −B),
ˆV (θh) =
T

t=B+1

θ(t)
h −¯θh
2
/(T −B).
This is equivalent to estimating the integrals,
E(θh|y) =

θhp(θh|y)dθh,
V (θh|y) =

θ2
hp(θh|y)dθh −[E(θh|y)]2 = E(θ2
h|y) −[E(θh|y)]2.
One may also use the MCMC output to obtain posterior means, variances,
and credible intervals for functions, ∆= ∆(θ), of the parameters (van Dyk,
2003, 150). These are estimates of the integrals,
E[∆(θ)|y] =

∆(θ)p(θ|y)dθ,
V [∆(θ)|y] =

∆2p(θ|y)dθ −[E(∆|y)]2 = E(∆2|y) −[E(∆|y)]2.
For ∆(θ), its posterior mean is obtained by calculating ∆(t) at every
MCMC iteration from the sampled values θ(t). The theoretical justiﬁcation
for such estimates is provided by the MCMC version of the law of large num-
bers (Tierney, 1994), namely, that,
T

t=B+1
∆[θ(t)]
T −B →Eπ[∆(θ)],
as T →∞, provided that the expectation of ∆(θ) under π(θ) = p(θ|y), denoted
Eπ[∆(θ)], exists. MCMC methods also allow inferences on parameter compar-
isons (e.g., ranks of parameters or contrasts between them) (Marshall and
Spiegelhalter, 1998).
1.4
Hierarchical Bayes Applications
The paradigm in Section 1.2 is appropriate to many problems, where uncer-
tainty is limited to a few fundamental parameters, the number of which is
independent of the sample size n—this is the case, for example, in a normal
linear regression when the independent variables are known without error and
the units are not hierarchically structured. However, in more complex data

Bayesian Methods for Complex Data: Estimation and Inference
7
sets or with more complex forms of model or response, a more general per-
spective than that implied by Equations 1.1 through 1.3 is available and also
implementable using MCMC methods.
Thus, a class of hierarchical Bayesian models are deﬁned by latent data
(Paap, 2002) intermediate between the observed data and the underlying pa-
rameters driving the process. A terminology useful for relating hierarchical
models to substantive issues is proposed by Wikle (2003) in which y deﬁnes
the data stage, latent eﬀects b deﬁnes the process stage, and θ deﬁnes the pa-
rameter stage. For example, the observations, i = 1, . . . , n, may be arranged
in clusters, j = 1, . . . , J, so that the observations can no longer be regarded
as independent. Rather, subjects from the same cluster will tend to be more
alike than individuals from diﬀerent clusters, reﬂecting latent variables that
induce dependence within clusters.
Modeling such dependencies involves a three stage hierarchical Bayes (HB)
prior set up for the joint density,
p(y, b, θ) = p(y|b, θ)p(b|θ)p(θ),
(1.4)
with a ﬁrst stage likelihood, p(y|b, θ), and second stage density, p(b|θ), for
the latent data conditional on the higher stage parameters θ. The ﬁrst stage
density, p(y|b, θ), in Equation 1.4 is a conditional likelihood, conditioning on b
as well as θ, sometimes also called the complete data or augmented data
likelihood. The application of Bayes theorem now speciﬁes,
p(θ, b|y) = p(y|b, θ)p(b|θ)p(θ)
p(y)
,
and the marginal posterior for θ may now be represented as,
p(θ|y) = p(θ)p(y|θ)
p(y)
= p(θ)
	
p(y|b, θ)p(b|θ)db
p(y)
.
where
p(y|θ) =

p(y, b|θ)db =

p(y|b, θ)p(b|θ)db,
is the observed data likelihood, namely, the complete data likelihood with b
integrated out; p(y|θ) is sometimes also known as the integrated likelihood.
Often the latent data exist for every observation, or they may exist for
each cluster in which the observations are structured (e.g., a school-speciﬁc
eﬀect, bj, for multilevel data, yij, on pupils i nested in schools j). Let
θ = [θL, θb] consist of parameter subsets relevant to the likelihood and to
the latent data density, respectively. Then the data are generally taken as
independent of θb given b, so that Equation 1.4 becomes
p(y, b, θ) = p(y|b, θL)p(b|θb)p(θb, θL).

8
Applied Bayesian Hierarchical Methods
The latent variables b can be seen as a population of values from an under-
lying density (e.g., varying log odds of disease) and the θb are then population
hyperparameters (e.g., mean and variance of the log odds) (Dunson, 2001).
As examples, Paap (2002) mentions unobserved states describing the busi-
ness cycle, Johannes and Polson (2006) mention unobserved volatilities in
stochastic volatility models, while Albert and Chib (1993) consider the miss-
ing or latent continuous data {b1, . . . , bn}, which underlie binary observations
{y1, . . . , yn}. The subject-speciﬁc latent traits in psychometric or educational
item analysis can also be considered this way (Johnson and Albert, 1999), as
can the variance scaling factors in the robust Student t errors version of lin-
ear regression (Geweke, 1993), or the subject-speciﬁc slopes in a growth curve
analysis of panel data on a collection of subjects (Lindstrom and Bates, 1990).
Typically, the integrated likelihood, p(y|θ), cannot be stated in closed form
and classical likelihood estimation relies on numerical integration or simula-
tion (Paap, 2002, 15). By contrast, MCMC methods can be used generate ran-
dom samples indirectly from the posterior distribution p(θ, b|y) of parameters
and latent data given the observations. This requires only that the augmented
data likelihood be known in closed form, without needing to obtain the inte-
grated likelihood p(y|θ). To see why, note that the marginal posterior of the
parameter set, θ, may alternatively be derived as,
p(θ|y) =

p(θ, b|y)db =

p(θ|y, b)p(b|y)db,
with marginal densities for component parameters θh of the form (Paap,
2002, 5),
p(θh|y) =

θ[h]

b
p(θ, b|y)dbdθ[h],
∝

θ[h]
p(θ|y)p(θ)dθ[h] =

θ[h]

b
p(θ)p(y|b, θ)p(b|θ)dbdθ[h],
where θ[h] consists of all parameters in θ with the exception of θh. The deriva-
tion of suitable MCMC algorithms to sample from p(θ, b|y) is based on the
Cliﬀord–Hammersley theorem, namely, that any joint distribution can be fully
characterized by its complete conditional distributions. In the HB context,
this implies that the conditionals p(b|θ, y) and p(θ|b, y) characterize the joint
distribution p(θ, b|y) from which samples are sought, and so MCMC sampling
can alternate between updates p(b(t)|θ(t−1), y) and p(θ(t)|b(t), y) on conditional
densities, which are usually of a simpler form than p(θ, b|y). The imputation
of latent data in this way is sometimes known as data augmentation (van Dyk,
2003).
To illustrate application of MCMC methods to parameter comparisons and
hypothesis tests in a HB setting, Shen and Louis (1998) consider hierarchical
models with unit or cluster speciﬁc parameters, bj, and show that if such
parameters are the focus of interest, their posterior means are the optimal

Bayesian Methods for Complex Data: Estimation and Inference
9
estimates. Suppose instead that the ranks of the unit or cluster parameters,
namely,
Rj = rank(bj) =

k
1(bj ≥bk),
(where 1(A) is an indicator function that equals 1 when A is true, 0 otherwise)
are required for deriving “league tables.” Then the conditional expected ranks
are optimal, and obtained by ranking bj at each MCMC iteration and tak-
ing their means over all samples. By contrast, ranking posterior means of bj
themselves can perform poorly (Goldstein and Spiegelhalter, 1996; Laird and
Louis, 1989). Similarly, when the empirical distribution function (EDF) of the
unit parameters (e.g., to be used to obtain the fraction of parameters above
a threshold) is required, the conditional expected EDF is optimal.
A posterior probability estimate that a particular bj exceeds a threshold τ,
namely, of the integral Pr(bj > τ|y) =
	 ∞
τ
p(bj|y)dbj, is provided by the
proportion of iterations where b(t)
j
exceeds τ, namely,
Pr(bj > τ|y) =
T

t=B+1
1

b(t)
j
> τ

/(T −B).
Thus, one might in an epidemiological application wish to obtain the pos-
terior probability that an area’s smoothed relative mortality risk, bj, exceeds
unity, and so count iterations where this condition holds. If this probability
exceeds .95 then a signiﬁcant excess risk is indicated, whereas a low probabil-
ity (the sampled relative risk rarely exceeds 1) would indicate a signiﬁcantly
low mortality level in the area.
In fact the signiﬁcance of individual random eﬀects is one aspect in assess-
ing the gain of a random eﬀects model over a model involving only ﬁxed eﬀects,
or of assessing whether a more complex random eﬀects model oﬀers a beneﬁt
over a simpler one (Knorr-Held and Rainer, 2001, 116). Since the variance can
be deﬁned in terms of diﬀerences between elements of the vector (b1, . . . , bJ) as
opposed to deviations from a central value (Kendall, 1943, 47), one may also
consider which contrasts between pairs of b values are signiﬁcant. Thus, Deely
and Smith (1998) suggest evaluating probabilities, Pr(bj ≤τbk|k ̸= j, y),
where 0 < τ ≤1, namely, the posterior probability that any one hierarchical
eﬀect is smaller by a factor τ than all the others.
1.5
Metropolis Sampling
The earliest scheme for posterior density estimation using a variant of MCMC
was developed by Metropolis et al. (1953). The Metropolis sampling algorithm
is a special case of Metropolis–Hastings considered in Section 1.8. Reverting

10
Applied Bayesian Hierarchical Methods
to the canonical framework in Section 1.2, let p(y|θ) denote the likelihood,
and p(θ) denote the prior density for θ, or more speciﬁcally the prior densi-
ties p(θ1), . . . , p(θC) on the components of θ. Then the Metropolis algorithm
involves a symmetric proposal density (e.g., a normal, Student t, or uniform
density) q(θcand|θ(t)) for generating candidate parameter values, θcand.
Under the Metropolis algorithm, the acceptance probability for potential
candidate values may be obtained as,
α = min

1, π(θcand)
π(θ(t))

= min

1, p(θcand|y)
p(θ(t)|y)

= min

1, p(y|θcand)p(θcand)
p(y|θ(t))p(θ(t))

.
(1.5)
So one compares the (likelihood * prior), namely, p(y|θ)p(θ), for the can-
didate and existing parameter values. If the (likelihood * prior) is higher for
the candidate value, it is automatically accepted and θ(t+1) = θcand. However,
even if the (likelihood * prior) is lower for the candidate value, such that
α is less than 1, the candidate value may still be accepted. This is decided
by random sampling from a uniform density, U (t), and the candidate value is
accepted if α ≥U (t).
The third equality in Equation 1.5 follows because the marginal likelihood,
1/M = p(y), in the Bayesian formula,
p(θ|y) = p(y|θ)p(θ)/p(y) = Mp(y|θ)p(θ),
cancels out, as it is a constant. Stated more completely, to sample parameters
under the Metropolis algorithm, it is not necessary to know the normalized
target distribution, namely, the posterior density, π(θ|y); it is enough to know
it up to a constant factor.
So the Metropolis algorithm can be implemented by using the full posterior
distribution,
π(θ) = p(θ|y) = Mp(y|θ)p(θ),
as the target distribution—which in practice involves comparisons of the
un-normalized posterior, p(y|θ)p(θ). However, for updating values on a par-
ticular parameter, θh, it is not just M that cancels out in the ratio,
π(θcand)/π(θ(t)) = p(y|θcand)p(θcand)
p(y|θ(t))p(θ(t))
,
but any parts of the likelihood or prior not involving θh (these parts can be
viewed as constant when θh is being updated).
When those parts of the likelihood or prior not relevant to θh are ab-
stracted out, the remaining part of p(θ|y) = Mp(y|θ)p(θ), the part relevant to
updating θh, is known as the full conditional density for θh (Gilks, 1996). One
may denote the full conditional density for θh as,
πh(θh|θ[h]) ∝p(y|θh)p(θh),

Bayesian Methods for Complex Data: Estimation and Inference
11
where θ[h] denotes the parameter set excluding θh. So the probability for
updating θh can be obtained either by comparing the full posterior (known
up to a constant M), namely,
α = min

1, π (θh,cand)
π

θ(t)
h


= min

1, p(y|θh,cand)p(θh,cand)
p

y|θ(t)
h

p

θ(t)
h


,
or by using the full conditional for the hth parameter, namely,
α = min

1,
πh

θh,cand|θ(t)
[h]

πh

θ(t)
h |θ(t)
[h]


.
Then, one sets θ(t+1)
h
= θh,cand with probability α, and θ(t+1)
h
= θ(t)
h otherwise.
1.6
Choice of Proposal Density
There is some ﬂexibility in the choice of proposal density q for generating can-
didate values in the Metropolis and other MCMC algorithms, but the chosen
density and the parameters incorporated in it are relevant to successful MCMC
updating and convergence (Altaleb and Chauveau, 2002). A standard recom-
mendation is that the proposal density for a particular parameter, θh, should
approximate the posterior density p(θh|y) of that parameter. In some cases,
one may have an idea (e.g., from a classical analysis) of what the posterior den-
sity is, or what its main deﬁning parameters are. A normal proposal is often
justiﬁed as many posterior densities do approximate normality. For example,
Albert (2007) applies a Laplace approximation technique to estimate the pos-
terior mode, and uses the mean and variance parameters to deﬁne the proposal
densities used in a subsequent stage of Metropolis–Hastings sampling.
The rate at which a proposal generated by q is accepted (the acceptance
rate) depends on how close θcand is to θ(t), and this in turn depends on the
variance, σ2
q, of the proposal density. A higher acceptance rate would typically
follow from reducing σ2
q, but with the risk that the posterior density will take
longer to explore. If the acceptance rate is too high, then autocorrelation in
sampled values will be excessive (since the chain tends to move in a restricted
space), while a too low acceptance rate leads to the same problem, since
the chain then gets locked at particular values. One possibility is to use a
variance or dispersion estimate, σ2
m or Σm, from a maximum likelihood or
other mode ﬁnding analysis (which approximates the posterior variance) and
then scale this by a constant, c > 1, so that the proposal density variance is
σ2
q = cσ2
m. Values of c in the range 2–10 are typical. For θh of dimension dh
with covariance Σm, a proposal density dispersion 2.382 Σm/dh is shown as
optimal in random walk schemes (Roberts et al., 1997). Working rules are for

12
Applied Bayesian Hierarchical Methods
an acceptance rate of 0.4 when a parameter is updated singly (e.g., by separate
univariate normal proposals), and 0.2 when a group of parameters are updated
simultaneously as a block (e.g., by a multivariate normal proposal). Geyer and
Thompson (1995) suggest acceptance rates should be between 0.2 and 0.4.
Typical Metropolis updating schemes use uniform, standard normal, or
standard Student t variables Wt. A normal proposal density q(θcand|θ(t))
involves samples Wt ∼N(0, 1), with candidate values,
θcand = θ(t) + σqWt,
where σq determines the size of the jump (and the acceptance rate). A uniform
random walk samples Wt ∼Unif(−1, 1) and scales this to form a proposal,
θcand = θ(t) + κWt, with the value of κ determining the acceptance rate. As
noted above, it is desirable that the proposal density approximately matches
the shape of the target density, p(θ|y). The Langevin random walk scheme is
an example of a scheme including information about the shape of p(θ|y) in the
proposal, namely, θcand = θ(t) + σq[Wt + 0.5∇log(p(θ(t)|y)], where ∇denotes
the gradient function (Roberts and Tweedie, 1996).
Sometimes candidate parameter values are sampled using a transformed
version of a parameter, for example, normal sampling of a log variance rather
than sampling of a variance (which has to be restricted to positive values).
In this case an appropriate Jacobean adjustment must be included in the
likelihood. Example 1.2 illustrates this.
1.7
Obtaining Full Conditional Densities
As noted above, Metropolis sampling may be based on the full conditional den-
sity when a particular parameter, θh, is being updated. These full conditionals
are particularly central in Gibbs sampling (see below). The full conditional
densities may be obtained from the joint density, p(θ, y) = p(y|θ)p(θ), and in
many cases reduce to standard densities (normal, exponential, gamma, etc.)
from which direct sampling is straightforward. Full conditional densities are
derived by abstracting out from the joint model density, p(y|θ)p(θ) (likelihood
times prior), only those elements including θh and treating other components
as constants (George et al., 1993; Gilks, 1996).
Consider a conjugate model for Poisson count data, yi, with means, µi,
that are themselves gamma distributed; this is a model appropriate for overdis-
persed count data with actual variability, var(y), exceeding that under the
Poisson model (Molenberghs et al., 2007). Suppose the second stage prior is
µi ∼Ga(α, β), namely,
p(µi|α, β) = µα−1
i
e−βµiβα/Γ(α),

Bayesian Methods for Complex Data: Estimation and Inference
13
and further that α ∼E(A) (namely α is exponential with parameter A), and
β ∼Ga(B, C), where A, B, and C are preset constants. So the posterior
density, p(θ|y) of θ = (µ1, . . . , µn, α, β), given y is proportional to,
e−AαβB−1e−Cβ

i
e−µiµyi
i

[βα/Γ(α)]n

i
µα−1
i
e−βµi

,
(1.6)
where all constants (such as the denominator yi! in the Poisson likelihood, as
well as the inverse marginal likelihood M) are combined in the proportionality
constant.
It is apparent from inspecting Equation 1.6 that the full conditional den-
sities of µi and β are also gamma, namely,
µi ∼Ga(yi + α, β + 1),
and
β ∼Ga(B + nα, C +

i
µi),
respectively. The full conditional density of α, also obtained from inspecting
Equation 1.6, is
p(α|y, β, µ) ∝e−Aα[βα/Γ(α)]n

i
µα−1
i

.
This density is nonstandard and cannot be sampled directly (as can the
gamma densities for µi and β). Hence, a Metropolis or Metropolis–Hastings
step can be used for updating it.
Example 1.1. Estimating Normal Parameters via Metropolis
To ill-
ustrate Metropolis sampling in practice using symmetric proposal densities,
consider n = 1000 values yi generated randomly from a N(3, 25) distribu-
tion, namely, a normal with mean µ = 3 and variance σ2 = 25. Note that the
average sampled yi is 3.13. Using the generated y, we seek to estimate the mean
and variance, now treating them as unknowns. Setting θ = (µ, σ2), the likeli-
hood is
p(y|θ) =
n

i=1
1
σ
√
2π exp

−(yi −µ)2
2σ2

.
Assume a ﬂat prior for µ, and a prior, p(σ) ∝1/σ, on σ; this is a form
of noninformative prior (see Albert, 2007, 109). Then the posterior density,
p(θ|y) = Mp(y|θ)p(θ), is proportional to,
1
σn+1
n

i=1
exp

−(yi −µ)2
2σ2

,
with the marginal likelihood and other constants incorporated in the propor-
tionality constant.

14
Applied Bayesian Hierarchical Methods
Parameter sampling via Metropolis involves σ rather than σ2, and uniform
proposals. Thus, assume uniform U(−κ, κ) proposal densities around the cur-
rent parameter values µ(t) and σ(t), with κ = 0.5 for both parameters. The
absolute value of σ(t) + U(−κ, κ) is used to generate σcand. Note that vary-
ing the lower and upper limit of the uniform sampling (e.g., taking κ = 1 or
κ = 0.25) may considerably aﬀect the acceptance rates.
An R code for κ = 0.5 is presented in the Appendix to this chapter2,
and uses the full posterior density (rather than the full conditional for each
parameter) as the target density for assessing candidate values. In the accep-
tance step, the log of the ratio p(y|θcand)p(θcand)/p(y|θ(t))p(θ(t)) is compared
to the log of a random uniform value to avoid computer over/underﬂow. With
T = 10,000, acceptance rates for the proposals of µ and σ are 48 and 34%,
respectively, with posterior means 3.13 and 4.99. Other posterior summary
tools (e.g., kernel density plots, eﬀective sample sizes) are included in the R
code. Also included is a posterior probability calculation to assess Pr(µ < 3|y),
with a result of 0.18, and a command for a plot of the changing posterior
expectation for µ over the iterations. The code uses the full normal likelihood,
via the dnorm function in R; a suggested exercise is to recode in terms of the
log of un-normalized posterior density (1/σn+1)n
i=1 exp(−(yi −µ)2/2σ2).
Example 1.2. Extended Logistic with Metropolis Sampling
Follow-
ing Morgan (1988) and Carlin & Louis (2000), consider an extended logistic
model for the Bliss mortality data, involving death rates, pi, at dose, wi. Thus,
for deaths, yi, at six dose points, one has
yi ∼Bin(ni, pi),
pi = h(wi) = [exp(zi)/(1 + exp(zi))]m,
zi = (wi −µ)/σ,
where m and σ are both positive. To simplify notation, write V = σ2.
Consider Metropolis sampling involving log transforms of m and V, and
separate univariate normal proposals in a Metropolis scheme. Jacobian adjust-
ments are needed in the posterior density to account for the two transformed
parameters. The full posterior, p(µ, m, V |y), is proportional to,
p(m)p(µ)p(V )

i
[h(wi)]yi[1 −h(wi)]ni−yi,
where p(µ), p(m), and p(V ) are priors for µ, m, and V . Suppose the priors
p(m) and p(µ) are as follows:
m ∼Ga(a0, b0),
µ ∼N(c0, d2
0),

Bayesian Methods for Complex Data: Estimation and Inference
15
where the gamma has the form, Ga(x|α, β) = (βα/Γ(α))xα−1e−βx. Also for
p(V ) assume,
V ∼IG(e0, f0),
where the inverse gamma has the form, IG(x|α, β) = (βα/Γ(α))x−(α+1)e−β/x.
The parameters (a0, b0, c0, d0, e0, f0) are preset. The posterior is then propor-
tional to

ma0−1e−b0m
exp

−0.5
µ −c0
d0
2
V −(e0+1)e−f0/V
×

i
[h(wi)]yi[1 −h(wi)]ni−yi.
Suppose the likelihood is respeciﬁed in terms of parameters, θ1 = µ, θ2 =
log(m), and θ3 = log(V ). Then the full posterior in terms of the transformed
parameters is proportional to,

∂m
∂θ2
 
 ∂V
∂θ3

p(µ)p(m)p(V )

i
[h(wi)]yi[1 −h(wi)]ni−yi.
One has (∂m/∂θ2) = eθ2 = m and (∂V /∂θ3) = eθ3 = V . So taking account
of the parameterization (θ1, θ2, θ3), the posterior density is proportional to,

ma0e−b0m
exp

−0.5
µ −c0
d0
2
V −e0e−f0/V 
i
[h(wi)]yi[1 −h(wi)]ni−yi.
The R code3 assumes initial values for µ = θ1 of 1.8, for θ2 = log(m) of 0, and
for θ3 = log(V ) of 1. Assume preset parameters (a0 = 0.25, b0 = 0.25, c0 = 2,
d0 = 10, e0 = 2.000004, f0 = 0.001), number of iterations, T = 50,000, and
standard deviations in the respective normal proposal densities of 0.01, 0.1,
and 0.1. Metropolis updates involve comparisons of the log (un-normalized)
posterior and logs of uniform random variables {U (t)
h , h = 1, . . . , 3}. Posterior
medians (and 95% intervals) for {µ, m, V } are obtained as 1.81 (1.79, 1.83),
0.36 (0.20, 0.73), 0.00033 (0.00017, 0.00072) with acceptance rates of 0.41,
0.65, and 0.81. A suggested exercise is to calibrate the standard deviations in
the proposal densities so that the acceptance rates for log(m) and log(V ) are
reduced to around 0.4.
1.8
Metropolis–Hastings Sampling
The Metropolis–Hastings (M–H) algorithm is the overarching algorithm for
MCMC schemes that simulate a Markov chain, θ(t), with p(θ|y) as its station-
ary distribution. Following Hastings (1970), the chain is updated from θ(t) to
θcand with probability,

16
Applied Bayesian Hierarchical Methods
α(θcand|θ(t)) = min

1, p(θcand|y)q(θ(t)|θcand)
p(θ(t)|y)q(θcand|θ(t))

,
where the proposal density q (Chib and Greenberg, 1995) may be nonsym-
metric, so that q(θcand|θ(t)) does not equal q(θ(t)|θcand). q(θcand|θ(t)) is the
probability (or density ordinate) of θcand for a density centered at θ(t), while
q(θ(t)|θcand) is the probability of moving back from θcand to the current value.
If the proposal density is symmetric, with q(θcand|θ(t)) = q(θ(t)|θcand), then
the M–H algorithm reduces to the Metropolis algorithm discussed above. The
M–H transition kernel is
K(θcand|θ(t)) = α(θcand|θ(t))q(θcand|θ(t)),
for θcand ̸= θ(t), with a nonzero probability of staying in the current state,
namely,
K(θ(t)|θ(t)) = 1 −

α(θcand|θ(t))q(θcand|θ(t))dθcand.
Conformity of M–H sampling to the requirement that the Markov chain even-
tually samples from π(θ) is considered by Mengersen and Tweedie (1996) and
Roberts and Rosenthal (2004).
If the proposed new value, θcand, is accepted, then θ(t+1) = θcand, while if
it is rejected the next state is the same as the current state, i.e., θ(t+1) = θ(t).
As mentioned above, since the target density p(θ|y) appears in ratio form, it
is not necessary to know the normalizing constant, M = 1/p(y).
If the proposal density has the form,
q(θcand|θ(t)) = q(θ(t) −θcand),
then a random walk Metropolis scheme is obtained (Albert, 2007, 105; Gelman
et al., 2004). Another option is independence sampling, when the density
q(θcand) for sampling candidate values is independent of the current value θ(t).
While it is possible for the target density to relate to the entire parameter
set, it is typically computationally simpler in multiparameter problems to
divide θ into C blocks or components, and use the full conditional densities
in componentwise updating. Consider the update for the hth parameter or
parameter block. At step h of iteration t + 1, the preceding h −1 parameter
blocks are already updated via the M–H algorithm, while θh+1, . . . , θC are
still at their iteration t values (Chib and Greenberg, 1995). Let the vector of
partially updated parameters apart from θh be denoted,
θ(t)
[h] =

θ(t+1)
1
, θ(t+1)
2
, . . . , θ(t+1)
h−1 , θ(t)
h+1, . . . , θ(t)
C

.
The candidate value for θh is generated from the hth proposal density,
denoted qh(θh,cand|θ(t)
h ). Also governing the acceptance of a proposal are full

Bayesian Methods for Complex Data: Estimation and Inference
17
conditional densities, πh(θ(t)
h |θ(t)
[h]) ∝p(y|θ(t)
h )p(θ(t)
h ), specifying the density
of θh conditional on known values of other parameters, θ[h]. The candidate
value θh,cand is then accepted with probability,
α = min

1, p(y|θh,cand)p(θcand)q(θ(t)
h |θcand)
p(y|θ(t)
h )p(θ(t)
h )q(θcand|θ(t)
h )

.
(1.7)
Example 1.3. Extended Logistic with Metropolis–Hastings Sam-
pling (continued)
We again consider an extended logistic model for the
Bliss mortality data. However, the analysis now involves a gamma M–H pro-
posal scheme for the positive parameters m and σ2, so that there is no need
for a Jacobian adjustments in the posterior density. Speciﬁcally, the proposal,
q(y|x) = Ga(κ, κ/x) =
κκ
xκΓ(κ)yκ−1e−κy/x,
is used. Note that κ has a role as a precision parameter that can be tuned to
provide improved acceptance rates: larger values of κ mean that the sampled
candidate values,
xcand ∼Ga(κ, κ/xcurr),
will be more closely clustered about the current parameter value, xcurr. Here
κ is set to 10 for sampling candidate values of m and σ2. The last 49,000
iterations of an MCMC chain4 of T = 50,000 iterations give acceptance rates
for µ, m, and σ2 of 0.41, 0.30, and 0.50. The posterior medians (and 95%
credible intervals) for µ, m, and σ are, respectively, 1.81 (1.79, 1.83), 0.36 (0.20,
0.70), and 0.0186 (0.013, 0.027). A suggested exercise is to adopt diﬀerent κ
values for m and σ2 to achieve acceptance rates closer to 0.4.
Example 1.4. Normal Random Eﬀects in a Hierarchical Binary Re-
gression
To exemplify a HB model involving a three stage prior, consider
binary data, yi ∼Bern(pi), from Sinharay and Stern (2005) on the survival or
otherwise of n = 244 newborn turtles arranged in J = 31 clutches, numbered
in increasing order of the average birthweight of the turtles. A known predic-
tor is turtle birthweight, xi. Let Ci denote the clutch that turtle i belongs to.
Then to allow for varying clutch eﬀects, one may specify, for cluster j = Ci,
a probit regression with
pi|bj = Φ(β1 + β2xi + bj),
where {bj ∽N(0, 1/τb), j = 1, . . . , J}. It is assumed that βk ∼N(0, 10) and
τb ∼Ga(1, 0.001).
An M–H step involving a gamma proposal is used for τb, and Metropolis
updates for other parameters.5 Trial runs suggest τb is approximately between

18
Applied Bayesian Hierarchical Methods
5 and 10, and a gamma proposal, Gam(κ, κ/τb,curr), with κ = 100 is adopted.
A run of T = 5000, iterations with B = 500 provides posterior medians (95%
intervals) for {β1, β2, σb = 1/√τb} of −2.66 (−3.80, −1.27), 0.36 (0.15, 0.54),
and 0.24 (0.15, 0.46), and acceptance rates for {β1, β2, τb} of 0.31, 0.44, and
0.25. Acceptance rates for the clutch random eﬀects (using normal proposals
with standard deviation 0.5) are between 0.42 and 0.51. However, none of
the clutch eﬀects appear to be signiﬁcant, in the sense of entirely positive
or negative 95% credible intervals (see Table 1.1). The ﬁrst eﬀect b1 (for the
clutch with lowest average birth-weight) has median and 95% interval, 0.35
(−0.07, 0.97), and is the closest to being signiﬁcant, while for bJ the median
is −0.28 (−0.83, 0.14).
TABLE 1.1
Random eﬀects posterior summary.
Clutch
2.5%
Median
97.5%
1
−0.07
0.35
0.97
2
−0.69
−0.12
0.43
3
−0.52
−0.01
0.54
4
−0.68
−0.15
0.32
5
−0.55
−0.06
0.43
6
−0.43
0.07
0.59
7
−0.60
−0.10
0.40
8
−0.58
−0.05
0.38
9
−0.21
0.25
0.82
10
−0.50
−0.02
0.42
11
−0.21
0.22
0.78
12
−0.36
0.14
0.80
13
−0.56
−0.01
0.55
14
−0.66
−0.06
0.46
15
−0.33
0.16
0.83
16
−0.68
−0.05
0.50
17
−0.47
−0.04
0.36
18
−0.60
−0.07
0.39
19
−0.57
−0.10
0.32
20
−0.39
0.09
0.74
21
−0.39
0.08
0.59
22
−0.45
0.04
0.54
23
−0.58
−0.12
0.35
24
−0.69
−0.07
0.47
25
−0.71
−0.15
0.28
26
−0.52
−0.04
0.50
27
−0.47
0.05
0.57
28
−0.58
−0.07
0.42
29
−0.30
0.16
0.72
30
−0.58
−0.09
0.32
31
−0.83
−0.28
0.14

Bayesian Methods for Complex Data: Estimation and Inference
19
1.9
Gibbs Sampling
The Gibbs sampler (Casella and George, 1992; Gelfand and Smith, 1990; Gilks
et al., 1993) is a special componentwise M–H algorithm, whereby the pro-
posal density, q, for updating θh equals the full conditional πh(θh|θ[h]) ∝
p(y|θh)p(θh). It follows from Equation 1.7 that proposals are accepted with
probability 1. If it is possible to update all blocks this way, then the
Gibbs sampler involves parameter block by parameter block updating, which
when completed forms the transition from θ(t) = (θ(t)
1 , . . . , θ(t)
C ) to θ(t+1) =
(θ(t+1)
1
, . . . , θ(t+1)
C
). The most common sequence used is
1.
θ(t+1)
1
∼f1

θ1|θ(t)
2 , θ(t)
3 , . . . , θ(t)
C

;
2.
θ(t+1)
2
∼f2

θ2|θ(t+1)
1
, θ(t)
3 , . . . , θ(t)
C

;
3.
θ(t+1)
C
∼fC

θC|θ(t+1)
1
, θ(t+1)
2
, . . . , θ(t+1)
C−1

.
While this scanning scheme is the usual one for Gibbs sampling, there are other
options, such as the random permutation scan (Roberts and Sahu, 1997) and
the reversible Gibbs sampler, which updates blocks 1 to C and then updates
in reverse order.
Example 1.5. Gibbs Sampling Example: Schools Data Meta Anal-
ysis
Consider the schools data from Gelman et al. (2004, 138), consisting
of point estimates yj (j = 1, . . . , J) of unknown eﬀects θj, where each yj has
a known design variance σ2
j (though the listed data provides σj not σ2
j). The
ﬁrst stage of a hierarchical normal model assumes,
yj ∼N(θj, σ2
j),
and the second stage speciﬁes a normal model for the latent θj,
θj ∼N(µ, τ2).
The full conditionals for the latent eﬀects, θj, namely, p(θj|y, µ, τ2) are as
speciﬁed by Gelman et al. (2004, 135). Assuming a ﬂat prior on µ, and that
the precision 1/τ2 has a Ga(a, b) gamma prior, the full conditional for µ is
N(¯θ, τ2/J), and that for 1/τ2 is gamma with parameters (J/2+a, 0.5
j(θj −
µ)2 + b).
For the R application, the setting a = b = 0.1 is used in the prior for 1/τ2.
Starting values for µ and τ2 in the MCMC analysis are provided by the mean
of the yj and the median of the σ2
j. A single run in R of T = 20,000 samples6
provides the posterior means and standard deviations shown in Table 1.2.

20
Applied Bayesian Hierarchical Methods
TABLE 1.2
Schools normal meta-analysis posterior summary.
µ
τ
θ1
θ2
θ3
θ4
θ5
θ6
θ7
θ8
Mean
8.0
2.5
9.0
8.0
7.6
8.0
7.1
7.5
8.8
8.1
Standard deviation
4.4
2.8
5.6
4.9
5.4
5.1
5.0
5.2
5.2
5.4
1.10
Assessing Eﬃciency and Convergence:
Ways of Improving Convergence
It is necessary to decide how many iterations to use to accurately represent
the posterior density and to ensure that the sampling process has converged.
Nonvanishing autocorrelations at high lags mean that less information about
the posterior distribution is provided by each iterate and a higher sample size
is necessary to cover the parameter space. Autocorrelation will be reduced
by “thinning,” namely, retaining only samples that are S > 1 steps apart

θ(t)
h , θ(t+S)
h
, θ(t+2S)
h
, . . . ,

that more closely approximate independent sam-
ples; however, this results in a loss of precision. The autocorrelation present in
MCMC samples may depend on the form of parameterization, the complexity
of the model, and the form of sampling (e.g., block or univariate sampling for
collections of random eﬀects). Autocorrelation will reduce the eﬀective sample
size, Teﬀ,h, for parameter samples

θ(t)
h , t = B + 1, . . . , B + T

below T. The
eﬀective number of samples (Kass et al., 1998) may be estimated7 as
Teﬀ,h = T

1 + 2
∞

k=0
ρhk

,
where,
ρhk = γhk/γh0,
is the kth lag autocorrelation, γh0 is the posterior variance V (θh|y), and γhk is
the kth lag autocovariance, cov[θ(t)
h , θ(t+k)
h
|y]. In practice, one may estimate
Teﬀ,h by dividing T by 1+2K∗
k=0 ρhk, where K∗is the ﬁrst lag value for which
ρhk < 0.1 or ρhk < 0.05 (Browne et al., 2009).
Also useful for assessing eﬃciency is the Monte Carlo standard error, which
is an estimate of the standard deviation of the diﬀerence between the true
posterior mean, E(θh|y) =
	
θhp(θh|y)dθh, and the simulation-based estimate,
¯θh = 1
T
T +B

t=B+1
θ(t)
h .

Bayesian Methods for Complex Data: Estimation and Inference
21
A simple estimator of the Monte Carlo variance is
1
T

1
T −1
T

t=1
(θ(t)
h −¯θh)2

,
though this may be distorted by extreme sampled values; an alternative batch
means method is described by Roberts (1996). The ratio of the posterior vari-
ance in a parameter to its Monte Carlo variance is a measure of the eﬃciency
of the Markov chain sampling (Roberts, 1996), and it is sometimes suggested
that the Monte Carlo standard error8 should be less than 5% of the posterior
standard deviation of a parameter (Toft et al., 2007).
The eﬀective sample size is mentioned above, while Raftery and Lewis
(1992, 1996) estimate the iterations required to estimate posterior summary
statistics to a given accuracy. Suppose the following posterior probability,
Pr[∆(θ|y) < b] = p,
is required. Raftery and Lewis seek estimates of the burn-in iterations, B, to
be discarded, and the required further iterations, Treq, in order to estimate p to
within r with probability s; typical quantities might be p = 0.025, r = 0.005,
and s = 0.95. The selected values of {p, r, s} can also be used to derive an
estimate of the required minimum iterations, Tmin, if autocorrelation were
absent, with the ratio,
I = Treq/Tmin,
providing a measure of additional sampling required due to autocorrelation.
Use of the R gibbsit function (available from STATLIB) is illustrated for
obtaining these quantities in the Appendix to this chapter.
As to the second issue mentioned above, there is no guarantee that sam-
pling from an MCMC algorithm will converge to the posterior distribution,
despite obtaining a high number of iterations. Convergence can be informally
assessed by examining the time series or trace plots of parameters. Ideally,
the MCMC sampling is exploring the posterior distribution quickly enough to
produce good estimates (this property is often called “good mixing”). Some
techniques for assessing convergence (as against estimates of required sample
sizes) consider samples θ(t) from only a single long chain, possibly after exclud-
ing initial t = 1, . . . , B burn-in iterations. These include the spectral density
diagnostic of Geweke (1992), the CUSUM method of Yu and Mykland (1998),
and a quantitative measure of the “hairiness” of the CUSUM plot (Brooks
and Roberts, 1998).
Slow convergence (usually combined with poor mixing and high autocorre-
lation in sampled values) will show in trace plots that wander, and that exhibit
short-term trends, rather than ﬂuctuating rapidly around a stable mean. Fail-
ure to converge is typically a feature of only some model parameters; for

22
Applied Bayesian Hierarchical Methods
example, ﬁxed regression eﬀects in a general linear mixed model may show
convergence, but not the parameters relating to the random components.
Often measures of overall ﬁt (e.g., model deviance) converge, while component
parameters do not.
Problems of convergence in MCMC sampling may reﬂect problems in
model identiﬁability, either formal nonidentiﬁcation as in multiple random ef-
fects models, or poor empirical identiﬁability when an overly complex model
is applied to a small sample (“overﬁtting”). Choice of diﬀuse priors tends to
increase the chance that models are poorly identiﬁed, especially in complex
hierarchical models for small data samples (Gelfand and Sahu, 1999). Elici-
tation of more informative priors and/or application of parameter constraints
may assist identiﬁcation and convergence.
Alternatively, a parameter expansion strategy may also improve MCMC
performance (Browne et al., 2009; Gelman et al., 2008; Ghosh, 2008). For
example, in a normal meta-analysis model (Chapter 3) with
yj ∼N(µ + θj, σ2
y);
θj ∼N(0, σ2
θ),
j = 1, . . . , J,
conventional sampling approaches may become trapped near σθ = 0, whereas
improved convergence and eﬀective sample sizes may be achieved by introduc-
ing a redundant scale parameter, λ ∼N(0, Vλ),
yj ∼N(µ + λξj, σ2
y);
ξj ∼N(0, σ2
ξ).
The expanded model priors induce priors on the original model parameters,
namely,
θj = λξj;
σθ = |λ|σξ.
The setting for Vλ is important: too much diﬀuseness may lead to eﬀective
impropriety.
Another source of poor convergence is suboptimal parameterization or data
form; for example, convergence is improved by centering independent variables
in regression applications (Roberts and Sahu, 2001; Zuur et al., 2002). Simi-
larly, delayed convergence in random eﬀects models may be lessened by sum
to zero or corner constraints (Clayton, 1996; Vines et al., 1996), or by a cen-
tered hierarchical prior (Gelfand et al., 1995, 1996), in which the prior on
each stochastic variable is centered at a higher level stochastic mean—see the
next section. However, the most eﬀective parameterization may also depend
on the balance in the data between diﬀerent sources of variation. In fact,
noncentered parameterizations, with latent data independent from hyperpa-
rameters, may be preferable in terms of MCMC convergence in some settings
(Papaspiliopoulos et al., 2003).

Bayesian Methods for Complex Data: Estimation and Inference
23
1.10.1
Hierarchical model parameterization
to improve convergence
While priors for unstructured random eﬀects may include a nominal mean of
zero, in practice a posterior mean of zero for such a set of eﬀects may not
be achieved during MCMC sampling. For example, the mean of the random
eﬀects can be confounded with the intercept. One may apply a corner con-
straint by setting a particular random eﬀect (say the ﬁrst) to a known value,
usually zero (Scollnik, 2002). An empirical sum to zero constraint may be
achieved by centering the sampled random eﬀects, say,
ui ∼N(0, σ2
u),
i = 1, . . . , n,
at each iteration (sometimes known as “centering on the ﬂy”), so that,
u∗
i = ui −¯u,
and inserting u∗
i rather than ui in the model deﬁning the likelihood. Another
option (Scollink, 2002; Vines et al., 1996) is to deﬁne an auxiliary eﬀect,
ua
i ∼N(0, σ2
u), and obtain ui, following the same prior N(0, σ2
u), but now
with a guaranteed mean of zero, by the transformation,9
ui =

n
n −1(ua
i −¯ua).
To illustrate a centered hierarchical prior (Gelfand et al., 1995; Browne
et al., 2009), consider two-way nested data, with j = 1, . . . , J repetitions over
subjects i = 1, . . . , n,
yij = µ + αi + uij,
with αi ∽N(0, σ2
α) and uij ∽N(0, σ2
u). The centered version deﬁnes κi =
µ + αi with yij = κi + uij, so that,
yij ∽N(κi, σ2
u),
κi ∽N(µ, σ2
α).
For three-way nested data, the standard model form is
yijk = µ + αi + βij + uijk,
with αi ∽N(0, σ2
α) and βij ∽N(0, σ2
β). The hierarchically centered version
deﬁnes ζij = µ + αi + βij and κi = µ + αi, so that,
yijk ∽N(ζij, σ2
u),
ζij ∽N(κi, σ2
β),
and
κi ∽N(µ, σ2
α).

24
Applied Bayesian Hierarchical Methods
Roberts and Sahu (1997, 309) set out the contrasting sets of full conditional
densities under the standard and centered representations, and compare Gibbs
sampling scanning schemes.
Papaspiliopoulos et al. (2003) compare MCMC convergence for centered,
noncentered, and partially noncentered hierarchical model parameterizations
according to the amount of information the data contain about the latent
eﬀects, κi = µ + αi. Thus for two-way nested data, the (fully) noncentered
parameterization (NCP), involves new random eﬀects, κi, with,
yij = κi + µ + σueij,
κi = σαzi,
where eij and zi are standard normal variables. In this form, the latent data,
κi, and hyperparameter, µ, are independent a priori, and so the NCP may give
better convergence when the latent eﬀects, κi, are not well identiﬁed by the
observed data, y. A partially noncentered form is obtained using a number,
w ϵ [0, 1], and
yij = κw
i + wµ + uij,
κw
i = (1 −w)µ + σαzi,
or equivalently,
κw
i = (1 −w)κi + wκi.
Thus, w = 0 gives the centered representation and w = 1 gives the noncentered
parameterization. The optimal w for convergence depends on the ratio σu/σα.
The centered representation performs best when σu/σα tends to zero, while
the noncentered representation is optimal when σu/σα is large.
1.10.2
Multiple chain methods
Many practitioners prefer to use two or more parallel chains with diverse
starting values to ensure full coverage of the sample space of the parame-
ters (Gelman and Rubin, 1996; Toft et al., 2007). Diverse starting values may
be based on default values for parameters (e.g., precisions set at diﬀerent
default values such as 1, 5, 10 and regression coeﬃcients set at zero), or on
the extreme quantiles of posterior densities from exploratory model runs. On-
line monitoring of sampled parameter values, {θ(t)
k , t = 1, . . . , T}, from mul-
tiple chains, k = 1, . . . , K, assists in diagnosing lack of model identiﬁability.
Examples might be models with multiple random eﬀects, or when the mean
of the random eﬀects is not speciﬁed within the prior, as under diﬀerence pri-
ors over time or space that are considered in Chapter 4 (Besag et al., 1995).
Another example is factor and structural equation models where the loadings
are not speciﬁed so as to anchor the factor scores in a consistent direction, so
that the “name” of the common factor may switch during MCMC updating

Bayesian Methods for Complex Data: Estimation and Inference
25
(Congdon, 2003). Single runs may still be adequate for straightforward prob-
lems, and single chain convergence diagnostics (Geweke, 1992) may be applied
in this case. Single runs are often useful for exploring the posterior density
and as a preliminary to obtain inputs to multiple chains.
Convergence for multiple chains may be assessed using Gelman–Rubin
scale reduction factors that measure the convergence of the between-chain
variance in θ(t)
k
=

θ(t)
1k , . . . , θ(t)
dk

to the variance over all chains. These fac-
tors converge to 1 if all chains are sampling identical distributions, whereas
for poorly identiﬁed models, variability of sampled parameter values between
chains will considerably exceed the variability within any one chain. To apply
these criteria, one typically allows a burn in of B samples while the sampling
moves away from the initial values to the region of the posterior. For iterations,
t = B+1, . . . , T +B, a pooled estimate of the posterior variance, σ2
θh|y, of θh is
σθh|y = Vh/T + TW h/(T −1),
where variability within chains Wh is deﬁned as,
Wh =
1
(T −1)K
K

k=1
B+T

t=B+1

θ(t)
hk −¯θhk
2
,
with ¯θhk being the posterior mean of θh in samples from the kth chain, and
where,
Vh =
T
K −1
K

k=1
(¯θhk −¯θh.)2,
denotes between-chain variability in θh, with ¯θh. denoting the pooled aver-
age of the ¯θhk. The potential scale reduction factor (PSRF) compares σ2
θh|y
with the within-sample estimate, Wh. Speciﬁcally, the scale factor is Rh =
(σ2
θh|y/Wh)0.5 with values under 1.2 indicating convergence. A multivariate
version of the PSRF for vector θ mentioned by Brooks and Gelman (1998) and
Brooks and Roberts (1998) involves between- and within-chain covariances Vθ
and Wθ, and pooled posterior covariance Σθ|y. The scale factor is deﬁned by,
Rθ = max
b
b′Σθ|yb
b′Wθb = T −1
T
+

1 + 1
K

λ1,
where λ1 is the maximum eigenvalue of W −1
θ
Vθ/T.
An alternative multiple chain convergence criterion, also proposed by
Brooks and Gelman (1998), avoids reliance on the implicit normality assump-
tions in the Gelman–Rubin scale reduction factors based on analysis of vari-
ance over chains. Normality approximation may be improved by parameter
transformation (e.g., log or logit), but problems may still be encountered when
posterior densities are skewed or possibly multimodal (Toft et al., 2007).

26
Applied Bayesian Hierarchical Methods
The alternative criterion uses a ratio of parameter interval lengths: for
each chain the length of the 100(1 −α)% interval for a parameter is obtained,
namely, the gap between 0.5α and (1 −0.5α) points from T simulated values.
This provides K within-chain interval lengths, with mean LU. From the pooled
output of TK samples, an analogous interval, LP , is also obtained. The ratio,
LP /LU, should converge to 1 if there is convergent mixing over the K chains.
The corresponding ˆR statistics are available both in WinBUGS and as part
of the R2WinBUGS output (see note 1 in the Appendix).
1.11
Choice of Prior Density
Choice of an appropriate prior density, and preferably a sensitivity analysis
over alternative priors, is fundamental in the Bayesian approach; for exam-
ple, see Daniels (1999), Gelman (2006), and Gustafson et al. (2006) on priors
for random eﬀect variances. Before the advent of MCMC methods, conjugate
priors were often used in order to reduce the burden of numeric integration.
Now nonconjugate priors (e.g., ﬁnite range uniform priors on standard devi-
ation parameters) are widely used. There may be questions of sensitivity of
posterior inference to the choice of prior, especially for smaller datasets, or for
certain forms of models; examples are the priors used for variance components
in random eﬀects models, the priors used for collections of correlated eﬀects,
for example, in hierarchical spatial models (Bernardinelli et al., 1995), pri-
ors in nonlinear models (Millar, 2004), and priors in discrete mixture models
(Green and Richardson, 1997).
In many situations, existing knowledge may be diﬃcult to summarize
or elicit in the form of an “informative prior” and to express prior igno-
rance one may use “default” or “noninformative” priors. This is typically
less problematic—in terms of posterior sensitivity—for ﬁxed eﬀects, such as
regression coeﬃcients (when taken to be homogenous over cases) than for vari-
ance parameters. Since the classical maximum likelihood estimate is obtained
without considering priors on the parameters, a possible heuristic is that a
noninformative prior leads to a Bayesian posterior estimate close to the maxi-
mum likelihood estimate. It might appear that a maximum likelihood analysis
would therefore necessarily be approximated by ﬂat or improper priors, but
such priors may actually be unexpectedly informative about diﬀerent param-
eter values (Zhu and Lu, 2004).
A ﬂat or uniform prior distribution on θ, expressible as p(θ) = 1, is often
adopted on ﬁxed regression eﬀects, but is not invariant under reparameteri-
zation. For example, it is not true for φ = 1/θ that p(φ) = 1, as the prior for
a function φ = g(θ), namely,
p(φ) =

d
dφg−1(φ)
 ,

Bayesian Methods for Complex Data: Estimation and Inference
27
demonstrates. By contrast, on invariance grounds, Jeﬀreys (1961) recom-
mended the prior, p(σ) = (1/σ), for a standard deviation, as for φ =
g(σ) = σ2, one obtains p(φ) = (1/φ). More general analytic rules for deriving
noninformative priors include reference prior schemes (Berger and Bernardo,
1992), and Jeﬀreys prior,
p(θ) ∝|I(θ)|0.5,
where I(θ) is the information matrix, namely, I(θ) = −E

∂2l(θ)/∂l(θg)∂l(θh)

,
and l(θ) = log(L(θ|y)) is the log-likelihood. Unlike uniform priors, a Jeﬀreys
prior is invariant under transformation of scale since I(θ) = I(g(θ))(g′(θ))2
and p(θ) ∝I(g(θ))0.5g′(θ) = p(g(θ))g′(θ) (Kass and Wasserman, 1996, 1345).
1.11.1
Including evidence
Especially for establishing the intercept (e.g., the average level of a disease),
or regression eﬀects (e.g., the impact of risk factors on disease), or variability
in such impacts, it may be possible to base the prior density on cumulative
evidence via meta-analysis of existing studies, or via elicitation techniques
aimed at developing informative priors. This is well established in engineering
risk and reliability assessment, where systematic elicitation approaches, such
as maximum-entropy priors, are used (Hodge et al., 2001; Siu and Kelly, 1998).
Thus, known constraints for a variable identify a class of possible distributions,
and the distribution with the greatest Shannon–Weaver entropy is selected as
the prior. Examples are θ ∽N(m, V ) if estimates m and V of the mean and
variance are available, or an exponential with parameter −q/ log(1 −p) if a
positive variable has an estimated pth quantile of q.
Simple approximate elicitation methods include the histogram technique,
which divides the domain of an unknown θ into a set of bins and elicits prior
probabilities that θ is located in each bin; then p(θ) may be represented as
a discrete prior or converted to a smooth density. Prior elicitation may be
aided if a prior is reparameterized in the form of a mean and prior sample
size; for example, beta priors, Be(a, b), for probabilities can be expressed as
Be(mτ, (1 −m)τ), where m = a/(a + b) and τ = a + b are elicited estimates
of the mean probability and prior sample size. This principle is extended in
data augmentation priors (Greenland and Christensen, 2001), while Greenland
(2007) uses the device of a prior data stratum (equivalent to data augmen-
tation) to represent the eﬀect of binary risk factors in logistic regressions in
epidemiology.
If a set of existing studies is available, providing evidence on the likely
density of a parameter, these may be used in a form of preliminary meta-
analysis to set up an informative prior for the current study. However, there
may be limits to the applicability of existing studies to the current data,
and so pooled information from previous studies may be down-weighted. For
example, the precision of the pooled estimate from previous studies may be
scaled downwards, with the scaling factor possibly an extra unknown. When

28
Applied Bayesian Hierarchical Methods
a maximum likelihood (ML) analysis is simple to apply, one option is to adopt
the ML mean as a prior mean, but with the ML precision matrix downweighted
(Birkes and Dodge, 1993).
More comprehensive ways of downweighting historical/prior evidence have
been proposed, such as power prior models (Chen et al., 2000; Ibrahim and
Chen, 2000). Let 0 ≤δ ≤1 be a scale parameter with beta prior that weights
the likelihood of historical data, yh, relative to the likelihood of the current
study data, y. Following Chen et al. (2000, 124), a power prior has the form,
p(θ, δ|yh) ∝[p(yh|θ)]δ[δaδ−1(1 −δ)bδ−1]p(θ),
where p(yh|θ) is the likelihood for the historical data, and (aδ, bδ) are prespec-
iﬁed beta density hyperparameters. The joint posterior density for (θ, δ) is
then,
p(θ, δ|y, yh) ∝p(y|θ)[p(yh|θ)]δ[δaδ−1(1 −δ)bδ−1]p(θ).
Chen and Ibrahim (2006) demonstrate connections between the power
prior and conventional priors for hierarchical models.
1.11.2
Assessing posterior sensitivity: Robust priors
To assess sensitivity to prior assumptions, the analysis may be repeated over
a limited range of alternative priors. Thus, Sargent (1997) and Fahrmeir and
Knorr-Held (1997) suggest a gamma prior on inverse precisions, 1/τ2, gov-
erning random walk eﬀects (e.g., baseline hazard rates in survival analysis),
namely, 1/τ2 ∼Ga(a, b), where a is set at 1, but b is varied over choices
such as 0.05 or 0.0005. One possible strategy involves a consideration of both
optimistic and conservative priors, with regard, say, to a treatment eﬀect or
the presence of signiﬁcant random eﬀect variation (Gustafson et al., 2006;
Spiegelhalter, 2004).
Another relevant principle in multiple eﬀect models is that of uniform
shrinkage governing the proportion of total random variation to be assigned
to each source of variation (Daniels, 1999; Natarajan and Kass, 2000). So for
a two level normal linear model with,
yij = xijβ + ηj + eij,
with eij ∼N(0, σ2) and ηj ∼N(0, τ2), one prior (e.g., inverse gamma) might
relate to the residual variance, σ2, and a second conditional U(0, 1) prior
relates to the ratio (τ2/τ2 + σ2) of cluster to total variance. A similar eﬀect
is achieved in structural time series models (Harvey, 1989) by considering
diﬀerent forms of signal to noise ratios in state–space models, including several
forms of random eﬀect (e.g., changing levels and slopes, as well as season
eﬀects). Gustafson et al. (2006) propose a conservative prior for the one level
linear mixed model,

Bayesian Methods for Complex Data: Estimation and Inference
29
yi ∼N(ηi, σ2),
ηi ∼N(µ, τ2),
namely, a conditional prior, p(τ2|σ2), aiming to prevent overestimation of τ2.
Thus in full,
p(σ2, τ2) = p(σ2)p(τ2|σ2),
where σ2 ∼IG(e, e) for some small e > 0, and
p(τ2|σ2) = a
σ2 [1 + τ2/σ2]−(a+1).
The case, a = 1, corresponds to the uniform shrinkage prior of Daniels
(1999), where,
p(τ2|σ2) =
σ2
[σ2 + τ2]2 ,
while larger values of a (e.g., a = 5) are found to be relatively conservative.
For covariance matrices, Σ, between random eﬀects of dimension k, the
emphasis in recent research has been on more ﬂexible priors than aﬀorded by
the inverse Wishart (or Wishart priors for precision matrices). Barnard et al.
(2000) and Liechty et al. (2004) consider a separation strategy whereby,
Σ = diag(S).R.diag(S),
where S is a k × 1 vector of standard deviations, and R is a k × k correla-
tion matrix. With the prior sequence, p(R, S) = p(R|S)p(S), Barnard et al.
suggest log(S) ∼Nk(ξ, Λ) where Λ is usually diagonal. For the elements
rij of R, constrained beta sampling on [−1, 1] can be used subject to positive
deﬁnitiveness constraints on Σ. Daniels and Kass (1999) consider the transfor-
mation, ηij = 0.5 log (1−rij/1+rij), and suggest an exchangeable hierarchical
shrinkage prior, ηij ∼N(0, τ2), where,
p(τ2) ∝(c + τ2)−2;
c = 1/(k −3).
This is an example of an exchangeable hierarchical prior considered more
fully in Chapter 3. Daniels and Kass (2001) consider other options for hier-
archical modeling of the correlations in Σ. While a full covariance prior (e.g.,
assuming random slopes on all k predictors in a multilevel model) can be ap-
plied from the outset, MacNab et al. (2004) propose an incremental model
strategy, starting with random intercepts and slopes but without covariation
between them, in order to assess for which predictors there is signiﬁcant slope
variation. The next step applies a full covariance model only for the predictors
showing signiﬁcant slope variation.

30
Applied Bayesian Hierarchical Methods
Formal approaches to prior robustness may be based on “contamina-
tion” priors. For instance, one might assume a two group mixture with
larger probability 1 −r on the “main” prior, p1(θ), and a smaller proba-
bility, such as r = 0.1, on a contaminating density, p2(θ), which may be any
density (Gustafson, 1996). More generally, a sensitivity analysis may involve
some form of mixture of priors, for example a discrete mixture over a few
alternatives, a fully nonparametric approach (see Chapter 3), or a Dirichlet
weight mixture over a small range of alternatives (e.g., Jullion and Lambert,
2007). For an example of such an analysis for a random eﬀect variance, see
Example 1.11.6.
A mixture prior can include the option that the parameter is not present
(e.g., that a variance or regression eﬀect is zero). A mixture prior method-
ology of this kind for regression eﬀects is presented by George and McCul-
loch (1993). Increasingly also random eﬀects models are selective, including a
default allowing for random eﬀects to be unnecessary (Albert and Chib, 1997;
Cai and Dunson, 2006; Fruhwirth-Schnatter and Tuchler, 2008).
In hierarchical models the prior speciﬁes both the form of the random
eﬀects (fully exchangeable over units or spatially/temporally structured), the
density of the random eﬀects (normal, mixture of normals, etc.), and the third
stage hyperparameters. The form of the second stage prior p(b|θb) amounts
to a hypothesis about the nature and form of the random eﬀects. Thus, a
hierarchical model for small area mortality may include spatially structured
random eﬀects, exchangeable random eﬀects with no spatial pattern, or both,
as under the convolution prior of Besag et al. (1991); it also may assume
normality in the diﬀerent random eﬀects, as against heavier-tailed alternatives.
A prior specifying the errors as spatially correlated and normal is likely to be a
working model assumption, rather than a true cumulation of knowledge, and
one may have several models for p(b|θb) being compared (Disease Mapping
Collaborative Group, 2000), with sensitivity not just being assessed on the
hyperparameters.
Random eﬀect models often start with a normal hyperdensity, and so pos-
terior inferences may be sensitive to outliers or multiple modes, as well as
to the prior used on the hyperparameters. Indications of lack of ﬁt (e.g., low
conditional predictive ordinates for particular cases) may suggest robustiﬁ-
cation of the random eﬀects prior. Robust hierarchical models are adapted
to pooling inferences and/or smoothing in data subject to outliers or other
irregularities; for example, Jonsen et al. (2006) consider robust space-time
state–space models with Student t rather than normal errors in an analysis
of travel rates of migrating leatherback turtles. Other forms of robust analy-
sis involve discrete mixtures of random eﬀects (e.g., Lenk and Desarbo, 2000),
possibly under Dirichlet or Polya process models (e.g., Kleinman and Ibrahim,
1998). Robustiﬁcation of hierarchical models reduces the chance of incorrect
inferences on individual eﬀects, important when random eﬀects approaches
are used to identify excess risk or poor outcomes (Conlon and Louis, 1999;
Marshall et al., 2004).

Bayesian Methods for Complex Data: Estimation and Inference
31
1.11.3
Problems in prior selection in hierarchical
Bayes models
For the third stage parameters (the hyperparameters) in hierarchical models,
choice of a diﬀuse noninformative prior may be problematic as improper priors
may induce improper posteriors that prevent MCMC convergence, since con-
ditions necessary for convergence (e.g., positive recurrence) may be violated
(Berger et al., 2005). This may apply even if conditional densities are proper,
and Gibbs or other MCMC sampling proceeds apparently straightforwardly.
A simple example is provided by the normal two level model with subjects,
i = 1, . . . , n, nested in clusters, j = 1, . . . , J,
yij = µ + θj + uij,
where θj ∽N(0, τ2) and uij ∽N(0, σ2). Hobert and Casella (1996) show that
the posterior distribution is improper under the prior p(µ, τ, σ) = (1/σ2τ2),
even though the full conditionals have standard forms, namely,
p

θj|y, µ, σ2, τ2
= N

n(¯yj −µ)
n + σ2
τ2
,
1
n
σ2 + 1
τ2

,
p

µ|y, σ2, τ2, θ

= N

¯y −¯θ, σ2
nJ

,
p

1/τ2|y, µ, σ2, θ

= Ga

J
2 , 0.5

j
θ2
j

,
p

1/σ2|y, µ, τ2, θ

= Ga

nJ
2 , 0.5

ij
(yij −µ −θj)2

,
so that Gibbs sampling could in principle proceed.
Whether posterior propriety holds may also depend on the level of infor-
mation in the data, whether additional constraints are applied to parameters
in MCMC updating, and the nature of the improper prior used. For example,
Rodrigues and Assuncao (2008) demonstrate propriety in the posterior of spa-
tially varying regression parameter models under a class of improper priors.
More generally, Markov random ﬁeld (MRF) priors, such as random walks in
time or spatial conditional autoregressive priors (Chapter 4), may have joint
forms that are improper, with a singular covariance matrix—see for example,
the discussion by Sun et al. (2000, 28–30). The joint prior only identiﬁes dif-
ferences between pairs of eﬀects and unless additional constraints are applied
to the random eﬀects, this may cause issues with posterior propriety.
It is possible to deﬁne proper priors in these cases by introducing autore-
gression parameters (Sun et al., 1999), but Besag et al. (1995, 11) mention
that “the sole impropriety in such [MRF] priors is that of an arbitrary level
and is removed from the corresponding posterior distribution by the presence
of any informative data.” The indeterminacy in the level is usually resolved by

32
Applied Bayesian Hierarchical Methods
applying “centering on the ﬂy” (at each MCMC iteration) within each set of
random eﬀects and under such a linear constraint, MRF priors become proper
(Rodrigues and Assun¸c˜ao, 2008, 2409). Alternatively, “corner” constraints on
particular eﬀects, namely, setting them to ﬁxed values (usually zero), may be
applied (Clayton, 1996; Koop, 2003, 248), while Chib and Jeliazkov (2006)
suggest an approach to obtaining propriety in random walk priors.
Datta and Smith (2003) consider propriety in multilevel normal linear
models,
yij = xijβ + zijbj + uij,
with repetitions i = 1, . . . , nj in clusters j = 1, . . . , J and demonstrate propri-
ety in terms of the ranks of the predictor matrices Z and X as compared to J
and n =  nj. For example, consider the Fay–Herriott small income model
with,
yi = xiβ + bi + ui,
where bi ∽N(0, ψb), but variances, var(ui) = Di, are known (as in meta-
regressions discussed in Chapter 3). Then, in the case Di = D and under the
Jeﬀreys prior,
p(β, ψb) ∝
1
D + ψb
,
the posterior is proper if J ≥rank(X) + 3. Similarly, Hadjicostas and Berry
(1999) consider a conjugate hierarchical model with yj ∽Po(ojλj) and λj ∽
Ga(α, β) along with the prior,
p(α, β) ∝αk1(α + s1)k2βk3(β + s2)k4,
where {s1, s2} are positive leading to a joint posterior,
p(λ1, . . . , λJ, α, β|y)
∝
1
[Γ(α)βα′]J
J

j=1

λα+yj−1
j
e−λj(oj+1/β) 
αk1(α + s1)k2βk3(β + s2)k4.
The prior is improper for certain k values, but proper posteriors can still be
obtained provided certain conditions are satisﬁed by the data.
Priors that are just proper mathematically (e.g., gamma priors on 1/τ2
with small scale and shape parameters) are often used on the grounds of ex-
pediency, and justiﬁed as letting the data speak for themselves. However, such
priors may cause identiﬁability problems as the posteriors are close to being
empirically improper. This impedes MCMC convergence (Gelfand and Sahu,
1999; Kass and Wasserman, 1996, 1361). Furthermore, just proper priors on
variance parameters in fact favour particular values, despite being supposedly
only weakly informative. Gelman (2006a) suggests possible (less problematic)
options including a ﬁnite range uniform prior on the standard deviation (rather
than variance), and a positive truncated t density.

Bayesian Methods for Complex Data: Estimation and Inference
33
Example 1.6. Seeds Data: Mixture Prior for Random Eﬀects Vari-
ance
To illustrate a simple discrete mixture to the prior for a random eﬀects
variance, consider the seeds data from Crowder (1978), with model,
yi ∼Binomial(Si, pi),
logit(pi) = β1 + β2x1i + β3x2i + β4x1ix2i + ui,
ui ∼N(0, σ2
u).
The program in the WinBUGS14 examples (Volume I) considers two
mutually exclusive alternatives for the random eﬀects variance, σ2
u, a uniform
U(0, 1000) prior on σu, and a gamma Ga(0.001, 0.001) prior on the precision
τ = 1/σ2
u.
However, instead of a single form of prior for σ2
u, one may instead average
over two or more plausible alternatives, either plausible mathematically, or in
terms of the level of evidence they include (their informativeness using, say,
previous studies). For example, one may use a discrete mixture10 with equal
prior probabilities for,
M1: σ1u ∽U(0, 100), η1 = 1/σ2
1u,
and
M2: η2 = 1/σ2
2u ∽Ga(0.1, 0.1).
The latter option is slightly less diﬀuse than the 1/σ2
u ∽Ga(0.001, 0.001)
option used in the WinBUGS14 examples. Thus, with π = (π1, π2) =
(0.5, 0.5), the realized precision is
τu = ηδ,
δ ∼Mult(1, π),
σ1u ∼U(0, 100);
η1 = 1/σ2
1u,
η2 ∼Ga(0.1, 0.1).
A two chain run of this model (B = 1000, T = 10,000) provides a posterior
median (with 95% interval) for συ of 0.37 (0.21, 0.67), higher than the median
of 0.27 obtained under 1/σ2
u ∽Ga(0.001, 0.001). The uniform option is chosen
in under 2% of iterations.
The Dirichlet weight approach of Jullion and Lambert (2007) is here
applied to average the precision over two priors. Again, the ﬁrst is σ1u ∽
U(0, 100), with precision η1 = 1/σ2
1u, and the second is η2 ∽Ga(0.1, 0.1).
Thus, with τu denoting the overall weighted precision obtained by averaging
over the two options, one has,
τu|w = w1η1 + w2η2,
w ∼Dirichlet(φ),
where (φ1, φ2) are prior weights, each set to 0.5. This approach is less likely
than the one just considered to be heavily weighted to one or other option.

34
Applied Bayesian Hierarchical Methods
This approach produces a posterior median for σu of 0.39 (0.20, 0.71) with
posterior weights (w1, w2) of 0.27 and 0.73 on the two alternative priors.
It is also possible to include an option σ2
u = 0 in the mixture prior, via the
model,
yi ∼Binomial(Si, pi),
logit(pi) = β1 + β2x1i + β3x2i + β4x1ix2i + κσmu∗
i ,
u∗
i ∼N(0, 1),
where κ ∼Bern(πκ) is a binary inclusion indicator, and πk can be taken
as known or assigned a beta prior. Here we take πκ ∼Be(1, 1). Addition-
ally, when κ = 1, a discrete mixture prior, as in the ﬁrst model, is adopted
with equal prior probabilities for the two nonzero options, σ1m ∽U(0, 100),
η1 = 1/σ2
1m and η2 = 1/σ2
2m ∽Ga(0.1, 0.1). In eﬀect, there is averaging over
three models, with the realized standard deviation, σu = κσm, averaging over
iterations when κ = 0 as well as when κ = 1. A two chain run of 100,000
iterations (with 10,000 burn in) shows that, in fact, the posterior probability
that κ = 1 is below 0.5, namely, 0.32. The posterior mean for the realized
random eﬀect standard deviation, namely, κσm, is 0.13, with the density now
showing a spike at zero.
Appendix: Computational Notes
1. The interface to WinBUGS from R involves specifying data, inits, param-
eters, and model, as well as number of chains, total iterations, and burn-in.
One option is to save the WinBUGS code and data (with extensions .bug and
.dat, respectively) to the R working directory. Another option is to specify
the WinBUGS code in R using the cat command (see below for an exam-
ple). For guidance, one may refer to http://www.stat.columbia.edu/∼gelman/
bugsR/runningbugs.html.
To illustrate, consider data relating male life expectancy yi (in 2003–2005)
to a health and disability score, xi, for 353 English local authorities. The ex-
pectancy data are from http://www.nchod.nhs.uk/ and the health scores are
from http://www.communities.gov.uk/communities/neighbourhoodrenewal/
deprivation/deprivation07. Consider the quadratic model, yi ∼N(µi, 1/τ),
µi = b1 + b2xi + b3x2
i , with N(0, 1000) priors for bj and τ ∼Ga(1, 0.01). One
may specify initial values by generating them randomly or by presetting them.
Using the cat function, and with three chains, a possible command se-
quence is
library(R2WinBUGS)
expecs <- read.table (“c:\\Rdata\\Ch1 expecs.txt”, header=TRUE)
y <- expecs$y; x <- expecs$x
data <- list(“x”,“y”)

Bayesian Methods for Complex Data: Estimation and Inference
35
cat(“model { for (i in 1:353) {y[i] ∼dnorm(mu[i],tau)
mu[i] <- b[1]+b[2]*x[i]+b[3]*x[i]*x[i]}
for (j in 1:3) {b[j] ∼dnorm(0,0.001)}
tau ∼dgamma(1,0.01)}”, ﬁle=“expecs.bug”)
# initialise unknowns randomly
# inits <- function(){list(b = rnorm(3, 0, 100), tau=rgamma(1,1)) }
# initialise unknowns via preset values
inits1 <- list(b=c(70,0,0),tau=1); inits2 <- list(b=c(80,0,0),tau=2)
inits3 <- list(b=c(90,0,0),tau=3); inits <- list(inits1, inits2,inits3)
# name parameters
parameters=c(“b”,“tau”); T <- 10000; B <- 1000
# interface to bugs
expecs.sim <- bugs(data,inits, parameters,
model=“expecs.bug”,n.chains=3,n.iter=T,n.burnin=B,n.thin=1)
# posterior summary
expecs.sim
# plots, etc
attach.all(expecs.sim$sims.list)
summary(b[,1]); summary(b[,2]); summary(b[,3])
# graphical summary of convergence and posterior density
plot(expecs.sim)
2. In Example 1.1, the data are generated (n = 1000 values) and then the
underlying parameters are estimated as follows:
# generate data
y = rnorm(1000,3,5);
# initial vector setting and parameter values
mu <- sig <- numeric(T); mu[1] <- 3; sig[1] <- 5
T <- 10000; B <- T/10; u.mu <- runif(T); u.sig <- runif(T)
REJmu <- 0; REJsig <- 0
# log posterior density (up to a constant)
logpost = function(mu,sig){
loglike = sum(dnorm(y,mu,sig,log=TRUE))
return(loglike - log(sig))}
# MCMC sampling loop
for (t in 2:T) { print(t)
mut <- mu[t-1]; sigt <- sig[t-1]
# uniform proposals with kappa=0.5
mucand <- mut + runif(1,−0.5,0.5)
sigcand <- abs(sigt + runif(1,−0.5,0.5))
alph.mu = logpost(mucand,sigt)-logpost(mut,sigt)
if (log(u.mu[t]) <= alph.mu) mu[t] <- mucand
else { mu[t] <- mut; REJmu <- REJmu+1 }
alph.sig = logpost(mu[t],sigcand)-logpost(mu[t],sigt)
if (log(u.sig[t]) <= alph.sig) sig[t] <- sigcand

36
Applied Bayesian Hierarchical Methods
else { sig[t] <- sigt; REJsig <- REJsig+1 }}
# MCMC Rejection rates
REJratemu <- REJmu/T; REJratesig <- REJsig/T;
# posterior plots and summaries
hist(mu,50) # mu posterior marginal
plot(mu) # mu sequence of sampled values
plot(mu,sig) # covariance plot of sampled values
cat(“mubar = ”,mean(mu),”\n”)
cat(“sdbar = ”,mean(sig),”\n”)
cat(“Rejection Rate mu = “,REJratemu,”\n”)
cat(“Rejection Rate sigma = “,REJratesig,”\n”)
# Kernel density plots
plot(density(mu),main=“Density plot for mu posterior”)
plot(density(sig),main=“Density plot for sigma posterior”)
# Monte Carlo Standard Errors
source(“http://www.stat.psu.edu/∼mharan/batchmeans.R”)
bm1 <- bm(mu); bm2 <- bm(sig)
# Eﬀective sample sizes and ACF plots
library(R2WinBUGS); eﬀectiveSize(mu); eﬀectiveSize(sig)
acf(mu,main=“acf plot, mu”); acf(sig,main=“acf plot, sig”)
# posterior probability on hypothesis µ < 3
sum(mu < 3)/T
# evolution plot for posterior mean estimate over iterations
estvssamp(mu)
# Raftery-Lewis required iterations
source(“C:\\Documents and Settings\\peter congdon\\gibbsit.R”)
gibbsit(cbind(mu,sig),q=0.025,r=0.005,s=0.95)
Taking T = 10, 000 leads to acceptance rates of 48% and 34% on µ and σ,
respectively.
3. An R code for Metropolis sampling of the extended logistic model is
f = function(mu,th2,th3) {V <- exp(th3); m1 <- exp(th2); sig <- sqrt(V)
x <- (w-mu)/sig; xt <- exp(x)/(1+exp(x)); h <- xtˆm1;
loglike <- y*log(h)+(n-y)*log(1-h)
logpriorm1 <- a0*th2-m1*b0
logpriorV <- -e0*th3-f0/V
logpriormu <- -0.5*((mu-c0)/d0)ˆ2-log(d0)
logprior <- logpriormu+logpriorV+logpriorm1
f <- sum(loglike)+logprior}
# Read in data and set initial values and vectors
w = c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)
n = c(59, 60, 62, 56, 63, 59, 62, 60); y = c(6, 13, 18, 28, 52, 53, 61, 60)
T = 50000; mu <- numeric(T); th3 <- numeric(T); th2 <- numeric(T);
V<- numeric(T); m1<- numeric(T); samp<- matrix(0, nrow=T, ncol=3);
pm <- numeric(3)

Bayesian Methods for Complex Data: Estimation and Inference
37
MCMCsamp <- matrix(0, nrow=T, ncol=3)
# initial parameter values
mu[1] <- 1.8; th2[1] <- 0; th3[1] <- 1;
k1 = 0; k2 = 0; k3 = 0; u1 <- runif(T); u2 <- runif(T); u3 <- runif(T)
a0=0.25; b0=0.25; c0=2; d0=10; e0=2.004; f0=0.001
# metropolis proposal standard devn’s
sd1 <- 0.01; sd2 <- 0.1; sd3 <- 0.1
# main MCMC loop
for (i in 2:T) {mucand <- mu[i-1]+sd1*rnorm(1,0,1)
tcand <- f(mucand,th2[i-1],th3[i-1])
tcurr <- f(mu[i-1],th2[i-1],th3[i-1])
if (log(u1[i]) <= tcand-tcurr) mu[i] <- mucand else
{mu[i] <- mu[i-1]; k1 <- k1+1 }
th2cand <- th2[i-1]+sd2*rnorm(1,0,1)
tcand <- f(mu[i],th2cand,th3[i-1])
tcurr <- f(mu[i],th2[i-1],th3[i-1])
if (log(u2[i]) <= tcand-tcurr) th2[i] <- th2cand else
{th2[i] <- th2[i-1]; k2 <- k2+1 }
m1[i] <- exp(th2[i])
th3cand <- th3[i-1]+sd3*rnorm(1,0,1)
tcand <- f(mu[i],th2[i],th3cand)
tcurr <- f(mu[i],th2[i],th3[i-1])
if (log(u3[i]) <= tcand-tcurr) th3[i] <- th3cand else
{th3[i] <- th3[i-1]; k3 <- k3+1}
V[i] <- exp(th3[i])
samp[i-1,1] <- mu[i]; samp[i-1,2] <- m1[i]; samp[i-1,3] <- V[i]}
# output for posterior data analysis
write.table(samp, ﬁle=“MCMCsamp.txt”)
# posterior summary (iterations 1000 to T=50,000)
quantile(mu[1000:T], probs=c(.025,0.5,0.975))
quantile(m1[1000:T], probs=c(.025,0.5,0.975))
quantile(V[1000:T], probs=c(.025,0.5,0.975))
# acceptance rates
1-k1/T; 1-k2/T; 1-k3/T
4. An R code for M–H estimation of the extended logistic for the Bliss mor-
tality analysis is
f = function(mu,m1,sig2) { x <- (w-mu)/sqrt(sig2); xt <- exp(x)/(1+exp(x))
h <- xtˆm1; loglike <- y*log(h)+(n-y)*log(1-h)
logpriorm1 <- (a0-1)*log(m1)-m1/b0
logpriorsig2 <- -(e0+1)*log(sig2)-1/(f0*sig2)
logpriormu <- -0.5*((mu-c0)/d0)ˆ2-log(d0)
logprior <- logpriormu+logpriorsig2+logpriorm1
f <- sum(loglike)+logprior}
w = c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839)

38
Applied Bayesian Hierarchical Methods
n = c(59, 60, 62, 56, 63, 59, 62, 60); y = c(6, 13, 18, 28, 52, 53, 61, 60)
k = 8; T = 50000
mu <- numeric(T); sig2 <- numeric(T); m1 <- numeric(T);
sig <- numeric(T); pm <- numeric(3)
mu[1] <- 1.8; m1[1] <- 0.5; sig2[1] <- 0.001
k1 = 0; k2 = 0; k3 = 0; u1 <- runif(T); u2 <- runif(T); u3 <- runif(T)
a0=0.25; b0=4; c0=2; d0=10; e0=2.004; f0=1000
kapm1=10; kapsig2=10
# Main MCMC loop
for (t in 2:T) { mu.n <- mu[t-1]+0.01*rnorm(1,0,1)
tn <- f(mu.n,m1[t-1],sig2[t-1])
tc <- f(mu[t-1],m1[t-1],sig2[t-1])
if (log(u1[t]) <= tn-tc) mu[t] <- mu.n else
{mu[t] <- mu[t-1]; k1 <- k1+1 }
m1.n <- rgamma(1,kapm1,kapm1/m1[t-1])
fn <- f(mu[t],m1.n,sig2[t-1])
fc <- f(mu[t],m1[t-1],sig2[t-1])
tn <- fn+log(dgamma(m1[t-1],kapm1,kapm1/m1.n))
tc <- fc+log(dgamma(m1.n,kapm1,kapm1/m1[t-1]))
if (log(u2[t]) <= tn-tc) m1[t] <- m1.n else
{m1[t] <- m1[t-1]; k2 <- k2+1 }
sig2.n <- rgamma(1,kapsig2, kapsig2/sig2[t-1]);
fn <- f(mu[t],m1[t],sig2.n)
fc <- f(mu[t],m1[t],sig2[t-1])
tn <- fn+log(dgamma(sig2[t-1], kapsig2,kapsig2/sig2.n))
tc <- fc+log(dgamma(sig2.n, kapsig2,kapsig2/sig2[t-1]))
if (log(u3[t]) <= tn-tc) sig2[t] <- sig2.n else
{sig2[t] <- sig2[t-1]; k3 <- k3+1 }
sig[t] <- sqrt(sig2[t]) }
# posterior quantiles
quantile(mu[1000:T], probs=c(.025,0.5,0.975))
quantile(m1[1000:T], probs=c(.025,0.5,0.975))
quantile(sig[1000:T], probs=c(.025,0.5,0.975))
# acceptance rates
1-k1/T; 1-k2/T; 1-k3/T
5. An R code for the turtle survival data is
# un-normalized posterior density
f = function(b,a,tau,e) { sig <- 1/sqrt(tau)
for (i in 1:N){ p[i] <- pnorm(a+b*x[i]+e[C[i]])
LL[i] <- y[i]*log(p[i])+(1-y[i])*log(1-p[i])}
logpr[1] <- -0.5*aˆ2/10
logpr[2] <- -0.5*bˆ2/10
logpr[3] <- -0.001*tau
for (j in 1:J){ LLr[j] <- -0.5*e[j]ˆ2/sigˆ2-log(sig)}

Bayesian Methods for Complex Data: Estimation and Inference
39
f <- sum(LL[1:N])+sum(LLr[1:J])+sum(logpr[1:3])}
# settings
T = 5000; B =T/10; N <- 244; J <- 31; k1 = 0; k2 = 0; k3 =0; kap=100
U1 <- log(runif(T)); U2 <- log(runif(T)); U3 <- log(runif(T))
a <- numeric(T); b <- numeric(T); tau <- numeric(T); logpr <- numeric(3)
s <- numeric(T); p <- numeric(N); e <- numeric(J); LL <- numeric(N);
LLr <- numeric(J); ec <- matrix(0,T,J); en <- matrix(0,T,J); kran <-
numeric(J)
# initial values
b[1] <- 0.35; a[1] <- -2.6; tau[1] <- 5; for (j in 1:J) {ec[1,j] <- 0; kran[j] <- 0}
# Main loop
for (t in 2:T) { print (t)
bn <- b[t-1]+0.05*rnorm(1,0,1)
tn <- f(bn,a[t-1],tau[t-1],ec[t-1,]); tf <- f(b[t-1],a[t-1],tau[t-1],ec[t-1,])
if (U1[t] <= tn-tf) b[t] <- bn
else {b[t] <- b[t-1]; k1 <- k1+1 }
# update intercept
an <- a[t-1]+0.2*rnorm(1,0,1)
tn <- f(b[t],an,tau[t-1],ec[t-1,]); tf <- f(b[t],a[t-1],tau[t-1] ,ec[t-1,])
if (U2[t] <= tn-tf) a[t] <- an
else {a[t] <- a[t-1]; k2 <- k2+1}
# update precision
taun <- rgamma(1,kap,kap/tau[t-1])
s[t-1] <- 1/sqrt(tau[t-1])
tn <- f(b[t],a[t],taun,ec[t-1,])+log(dgamma(tau[t-1],kap,kap/taun))
tc <- f(b[t],a[t],tau[t-1],ec[t-1,])+log(dgamma(taun,kap,kap/tau[t-1]))
if (U3[t] <= tn-tf) tau[t] <- taun
else {tau[t] <- tau[t-1]; k3 <- k3+1}
# update cluster eﬀects
for (j in 1:J) { en[j] <- ec[t-1,j]; ec[t,j] <- ec[t-1,j]}
for (j in 1:J) { en[j] <- ec[t-1,j]+0.5*rnorm(1,0,1)
tn <- f(b[t],a[t],tau[t],en[]); tf <- f(b[t],a[t],tau[t],ec[t,])
if (log(runif(1)) <= tn-tf) ec[t,j] <- en[j]
else { en[j] <- ec[t-1,j]
kran[j] <- kran[j]+1}}}
# summaries
quantile(a[B:T], probs=c(.025,0.5,0.975))
quantile(b[B:T], probs=c(.025,0.5,0.975))
quantile(tau[B:T], probs=c(.025,0.5,0.975))
quantile(s[B:T], probs=c(.025,0.5,0.975))
for (j in 1:J) {print(quantile(ec[B:T,j], probs=c(.025,0.5,0.975)))}
# acceptance rates
1-k1/T; 1-k2/T; 1-k3/T
for (j in 1:J) {print(1-kran[j]/T)}

40
Applied Bayesian Hierarchical Methods
6. There are J + 2 unknowns in the R code (NB the σ2
j are not unknowns)
for implementing these Gibbs updates. There are T = 20,000 MCMC samples
to be accumulated in the array MCMCsamp. With a = b = 0.1 in the prior
for 1/τ2, and remembering that the normal density in R uses the standard
deviation, one then has
y=c(28,8,-3,7,-1,1,18,12); sigma=c(15,10,16,11,9,11,10,18)
J <- 8; T <- 20000; sigma2 <- sigmaˆ2
MCMCsamp <- matrix(0, nrow=T, ncol=J+2)
# starting values
mu=mean(y); tau2=median(sigma2)
# main sampling loop
for (t in 1:T) {th.mean=(y/sigma2+mu/tau2)/(1/sigma2+1/tau2)
th.sd=sqrt(1/(1/sigma2+1/tau2))
theta=rnorm(J,th.mean,th.sd)
mu=rnorm(1,mean(theta),sqrt(tau2/J))
invtau2=rgamma(1,J/2+0.1,sum((theta-mu)ˆ2)/2+0.1)
tau2 <- 1/invtau2; tau <- sqrt(tau2)
MCMCsamp[t,3:(2+J)] = theta;
MCMCsamp[t,1] =mu; MCMCsamp[t,2] =tau}
write.table(MCMCsamp, ﬁle=“MCMCsamp.txt”)
7. The eﬀective sample size can be obtained in R by loading the R2WinBUGS
library (Sturtz et al., 2005), and then using the eﬀectiveSize(theta.h) command,
where theta.h is the name for the sampled values of a particular parameter.
8. In the R program, one may use a program developed by Jones et al. (2006)
for estimating the MC standard error, which can be downloaded via the com-
mand
source(“http://www.stat.psu.edu/∼mharan/batchmeans.R”)
and then simply specifying
bmse <- bm(theta.h).
9. For example, consider a random eﬀects logistic model (one allowing for
overdispersion) for seeds, yi, germinating among a total, Si, on plate, i, as in
Crowder (1978). Denote the probability of germination by pi, yi ∼Binomial
(Si, pi), with,
logit(pi) = β1 + β2x1i + β3x2i + β4x1ix2i + ui,
ui ∼N(0, σ2
u),
where x1i and x2i are, respectively, the seed type and root extract of plate i.
Adopting priors σu ∼U(0, 10), and {βh ∼N(0, 1000), h = 1, 4}, the auxiliary
eﬀect method may be coded in WinBUGS as
model { for( i in 1 : n ) {y[i] ∼dbin(p[i],S[i])
u.a[i] ∼dnorm(0,inv.sig2.u); u[i] <- sqrt(n/(n-1))*(u.a[i]-mean(u.a[]))
logit(p[i]) <- beta[1]+beta[2]*x1[i]+beta[3]*x2[i]+beta[4]*x1[i]*x2[i]+u[i]}

Bayesian Methods for Complex Data: Estimation and Inference
41
for (h in 1:4) {beta[h]∼dnorm(0,1.0E-3)}
sig.u∼dunif(0,10);inv.sig2.u <-1/(sig.u*sig.u)}
10. For the discrete mixture over two options for the variance, the relevant
WinBUGS code is
model {for( i in 1 : n ) {r[i] ∼dbin(p[i],S[i]); u[i] ∼dnorm(0,tau)
logit(p[i]) <- beta[1]+beta[2]*x1[i]+beta[3]*x2[i]+beta[4]*x1[i]*x2[i]+u[i]}
for (j in 1:4) {beta[j]∼dnorm(0,1.0E-3)}
# mixture over priors and selected precision and s.d. of random eﬀects
tau <- taumx[del]; sig <- 1/sqrt(tau); del ∼dcat(pi[1:2])
# Prior 1: uniform on SD
sig1 ∼dunif(0,100); taumx[1] <- 1/(sig1*sig1)
#Prior 2: gamma on precision
taumx[2] ∼dgamma(0.1, 0.1)}
For the Dirchlet weight mixture, a sequence of gamma priors is used to repro-
duce the Dirichlet. Thus
model { for( i in 1 : n) {r[i] ∼dbin(p[i],S[i]); u[i] ∼dnorm(0,tau)
logit(p[i]) <- beta[1]+beta[2]*x1[i]+beta[3]*x2[i]+beta[4]*x1[i]*x2[i]+u[i]}
for (j in 1:4) {beta[j]∼dnorm(0,1.0E-3)}
# precision and s.d. of random eﬀects
tau <- w[1]*taumx[1]+w[2]*taumx[2];
sig <- 1/sqrt(tau)
for (k in 1:2) {w[k] <- W[k]/sum(W[]); W[k] ∼dgamma(phi[k],1)}
# Prior 1: uniform on SD
sig1 ∼dunif(0,100); taumx[1] <- 1/(sig1*sig1)
#Prior 2: gamma on precision
taumx[2] ∼dgamma(0.1, 0.1)}
When the option of a zero variance is added, the code is
model {for( i in 1 : n) {r[i] ∼dbin(p[i],S[i])
ustar[i] ∼dnorm(0,1)
logit(p[i]) <- beta[1]+beta[2]*x1[i]+beta[3]*x2[i]+beta[4]*x1[i]*x2[i]
+kap*sigm*ustar[i]}
for (j in 1:4) {beta[j]∼dnorm(0,1.0E-3)}
kap ∼dbern(pi.kap); pi.kap ∼dbeta(1,1)
sig <- kap*sigm
del ∼dcat(pi.m[1:2]); taum <- taumx[del]; sigm <- 1/sqrt(taum)
# Prior 1: uniform on SD
sig1 ∼dunif(0,100); taumx[1] <- 1/(sig1*sig1)
#Prior 2: gamma on precision
taumx[2] ∼dgamma(0.1, 0.1)}

2
Model Fit, Comparison, and Checking
2.1
Introduction
Model assessment involves both choice between competing models in terms
of best ﬁt, and checks to ensure model adequacy. For example, even if one
model has superior ﬁt, it still needs to be established whether predictions
from the model check with, namely, reproduce satisfactorily, the observed
data. Checking may also seek to establish whether model assumptions (e.g.,
normality of random eﬀects) are justiﬁed, and whether particular observations
are poorly ﬁt (Berkhof et al., 2000; Sinharay and Stern, 2003).
Once adequacy is established for a set of candidate models, one may seek to
choose a particular best ﬁtting model to base inferences on, or average over two
or more adequate models with closely competing ﬁt. This chapter focuses on
three main strategies to assessing model ﬁt and carrying out model checks, the
formal approach, approaches based on posterior analysis of the deviance, and
predictive methods based on samples of replicate data. Particular emphasis is
placed on their application in hierarchical models.
What is termed the formal approach to Bayes model selection is based
on integration over the model parameter space to estimate marginal likeli-
hoods and posterior model probabilities, leading to possible model averaging.
The canonical situation is provided by a “model closed” or M-closed scenario
(Bernardo and Smith, 1994; Key et al., 1999) where the set of models under
consideration are judged to include the correct model. Then formal model
choice strategies are directed toward ﬁnding which model is most likely given
the data.
Let prior model probabilities be denoted p(m = k), where m ∈(1, . . . , K)
is a model indicator. Then posterior model probabilities are obtained as,
p(m = k|y) = p(y|m = k)p(k)
p(y)
,
where,
p(y|m = k) =

p(y|θk)p(θk)dθk,
is the marginal likelihood for model k, with parameter θk of dimension dk.
Section 2.2 considers approximations to the marginal likelihood and to Bayes
43

44
Applied Bayesian Hierarchical Methods
factors that compare such likelihoods. In simple models, such as normal linear
regressions with regression coeﬃcients and the residual variance the only un-
knowns, the formal approach is relatively simple to implement, and marginal
likelihoods are available analytically under certain priors (Bos, 2002).
Approximate methods (Tierney and Kadane, 1986) for obtaining sum-
mary ﬁt measures (e.g., marginal likelihoods) or posterior densities of param-
eters are also reliable in simple models. A large sample approximation for
the log marginal likelihood is provided by the Bayesian Information Criterion
(Schwarz, 1978) deﬁned as,
BIC = log[p(y|ˆθk)] −0.5dk log(n),
where ˆθk is the maximum likelihood estimator.
Posterior model probabilities on nested models are also obtainable by
adding model selection indicators, as illustrated by Bayesian variable selec-
tion algorithms (Fernandez et al., 2001; Mitchell and Beauchamp, 1988) for
choosing predictors in regression. Such selection has recently been extended to
variance hyperparameters in hierarchical models (e.g., Cai and Dunson, 2006;
Chen and Dunson, 2003; Fruhwirth-Schnatter and Tuchler, 2008; Kinney and
Dunson, 2008) and avoids the sometimes complex issues involved in estimat-
ing marginal likelihoods of diﬀerent models. Section 2.4 considers variance
selection in hierarchical models.
However, in more complex random eﬀect applications with discrete res-
ponses or hierarchically structured data, there remain issues that impede
straightforward application of the formal approach (Han and Carlin, 2001).
For example, in approximating marginal likelihoods, there is a choice whether
or not to integrate over random eﬀects (Sinharay and Stern, 2005). The more
commonly advocated approach of integrating out random eﬀects becomes
impractical when there are multiple possibly correlated random eﬀects. The
formal approach is also sensitive to priors adopted on parameters, which in the
case of random eﬀect models include the form of prior on variance components
(e.g., inverse gamma or uniform) as well as the degree of prior informativeness.
As priors become more diﬀuse, the formal approach tends to select the sim-
plest least parameterized models, in line with the so-called Lindley or Bartlett
paradox (Bartlett, 1957). Finally, the formal approach to model averaging re-
quires both posterior densities, p(θk|y, m = k), and posterior model proba-
bilities, p(m = k|y). Estimates of posterior densities, p(θk|y, m = k), may be
diﬃcult to obtain in complex random eﬀects models with large numbers of
parameters.
However, straightforward and pragmatic approaches to model compari-
son, applicable to complex hierarchical models, are available as alternatives
to formal methods. The two main approaches are based on posterior densities
of ﬁt measures (e.g., log-likelihood, deviance) and on predictive asssessment
using samples of replicate data. Section 2.4 considers the posterior deviance as
a ﬁt measure, and the related measure of model complexity (eﬀective dimen-
sion) that is of considerable utility in comparing hierarchical models. Bayesian

Model Fit, Comparison, and Checking
45
ﬁt measures such as the deviance information criterion (DIC) are analogous
to information theoretic approaches in frequentist statistics (Burnham and
Anderson, 2002), but more widely applicable (e.g., to non-nested models).
The components of the overall ﬁt deriving from each observation (e.g., the
deviance contributions from particular observations) may be used in model
checking (Plummer, 2008).
The predictive approach to model choice and diagnosis (Section 2.5) has
also been simpliﬁed by Markov Chain Monte Carlo (MCMC) (Gelfand, 1996).
Predictive methods shift the focus onto observables away from parameters
(Geisser and Eddy, 1979) and seek to alleviate the impact on model com-
parison of factors such as speciﬁcation of priors. The predictive approach is
particularly advantageous in model checking, namely, ensuring that a model
actually reproduces the data satisfactorily (e.g., Kacker et al., 2008), but is
also applied to model choice, for example under posterior predictive loss cri-
teria (Gelfand and Ghosh, 1998).
Predictive model checking typically involves repeated sampling of replicate
data, ynew, from a model’s parameters at each MCMC iteration (Gelfand et al.,
1992). For a satisfactory model, this process generates data like the observed
data such that (y, ynew) are exchangeable draws from the joint density (Stern
and Sinharay, 2005, 176–77),
p(ynew, y, θ) = p(ynew|θ, y)p(y|θ)p(θ) = p(ynew|θ)p(y|θ)p(θ).
When all the data are used in model estimation, such sampling provides esti-
mates of the posterior predictive density of model k, p(ynew|y, m = k). How-
ever, predictive comparisons based on models using all the data in estimation
may be overly favorable to the model being ﬁtted (i.e., be conservative in
terms of detecting model discrepancies) (Bayarri and Berger, 1999). An al-
ternative involves cross-validation (Alqalaﬀand Gutafson, 2001), where the
model predicts values for certain observations (the test sample) on the basis
of a model estimated using the remaining observations (the learning sample).
Key et al. (1999) argue that cross-validation is approximately optimal in an
M-open scenario, where none of the models being considered is believed to be
the true model.
2.2
Formal Methods: Approximating
Marginal Likelihoods
As mentioned above, the global ﬁt of a model with parameter vector θ under
the formal Bayes paradigm is provided by the marginal likelihood, p(y|m = k),
obtained by integrating the likelihood,
p(y) =

p(y|θ)p(θ)dθ.

46
Applied Bayesian Hierarchical Methods
The marginal likelihood is also a component in Bayes formula, such that
at any parameter value θ,
p(θ|y) = p(y|θ)p(θ)
p(y)
.
Consider models 1 and 2 with equal prior model probabilities, p(m = 1) =
p(m = 2) = 0.5. Then the ratio of posterior model probabilities is obtained as,
p(m = 2|y)
p(m = 1|y) = p(y|m = 2)
p(y|m = 1) = B21,
where B21 is the Bayes factor. Kass and Raftery (1995) provide guidelines
for interpreting B21. If 2 loge B21 is larger than 10 the evidence for model
2 is very strong, while values of 2 loge B21 < 2 are inconclusive as evidence
in favor of one or other model. Note that such criteria are inﬂuenced by the
prior adopted. In general, diﬀuse priors (whether on ﬁxed eﬀect parameters or
variances) are to be avoided as they tend to favor the selection of the simpler
model.
Estimating the marginal likelihood by direct integration is generally infea-
sible in multiparameter applications. Hence, a range of approximations have
been proposed for estimating marginal likelihoods or associated model choice
criteria, such as the Bayes factor. For example, on suitable rearrangement, the
Bayes formula implies that the marginal likelihood may be approximated by
estimating the posterior ordinate, p(θ|y), in the relation,
log[p(y)] = log[p(y|θh)] + log[p(θh)] −log[p(θh|y)],
where θh is a point with high posterior density (e.g., posterior mean or me-
dian). One may estimate p(θ|y) by kernel density methods or by moment
approximations based on MCMC output—see Lenk and DeSarbo (2000) for
a discussion of such estimates. Let g(θ) denote an estimated density that ap-
proximates p(θ|y). One may then evaluate g(θ) at θh (Bos, 2002; Sinharay and
Stern, 2005), so providing an estimate of the log marginal likelihood as,
log[p(y|θh)] + log[p(θh)] −log[g(θh)].
The relation, log[p(y)] = log[p(y|θh)]+log[p(θh)]−log[p(θh|y)], also implies
a sampling-based estimator of the log marginal likelihood. Since this relation
applies for all samples, θ(r), one may average over values,
H(r) = log
!
p

y|θ(r)"
+ log
!
p

θ(r)"
−log
!
g

θ(r)"
,
to estimate the log of the marginal likelihood, log[p(y)]. This is likely to be
the most suitable approach for larger samples, to avoid numeric overﬂow. For
small samples, one may set L(r) = p(y|θ(r)), π(r) = p(θ(r)), and g(r) = g(θ(r)).
Then an estimator of the marginal likelihood is provided by the simple average
of the ratios (L(r)π(r)/g(r)).

Model Fit, Comparison, and Checking
47
Alternatively, suppose θ contains B parameter sub-blocks. When the full
conditionals of each sub-block are available in closed form, Chib (1995) con-
siders a marginal/conditional decomposition of p(θh|y) as follows,
p(θh|y) = p(θ1h|y)p(θ2h|θ1h, y)p(θ3h|θ1h, θ2h, y), . . . , p(θBh|θ1h, . . . , θB−1,h, y),
with p(θh|y), and thus p(y), estimated by using B −1 sampling sequences
subsidiary to the main scheme. If B = 2, namely, θh = (θ1h, θ2h), the posterior
ordinate p(θh|y) is then p(θ1h|y)p(θ2h|y, θ1h), where p(θ1h|y) is estimated from
the output of the main sample, e.g., as,
p(θ1h|y) =
R

r=1
p

θ1h|y, θ(r)
2

,
or by an approximation technique (e.g., assuming univariate/multivariate pos-
terior normality of θ1 or a kernel method). The second ordinate is available
by inserting θ1h and θ2h in the relevant full conditional density. Chib and
Jeliazkov (2001) extend this method to cases where full conditionals do not
have a known normalizing constant and have to be updated by Metropolis–
Hastings steps.
2.2.1
Importance and bridge sampling estimates
Let θk be the parameter vector for model k and the marginal likelihoods,
p(y|m = k), be denoted Mk, and let,
p∗(θk|y, m = k) = p(y|θk, m = k)p(θk|m = k),
denote the un-normalized posterior density of θk with,
p∗(θk|y, m = k)/ck = p(θk|y).
Then by deﬁnition,
p(y|m = k) =

p∗(θk|y, m = k)dθ.
Consider a function g(θ) with known normalizing constants, often termed
an importance function, and one that should ideally approximate the posterior
p(θ|y). Then one has,
p(y|m = k) =

p∗(θk|y, m = k)dθ =
 p∗(θk|y, m = k)
g(θk)
g(θk)dθk.
This suggests that an estimator for the marginal likelihood may be ob-
tained using samples ˜θ(r)
k (r = 1, . . . , R) from g(θk), namely,
Mk =

r
p∗˜θ(r)
k |y, m = k

g
˜θ(r)
k

.

48
Applied Bayesian Hierarchical Methods
Let ˜L(r)
k
= p

y|˜θ(r)
k

, ˜π(r)
k
= p
˜θ(r)
k

, and ˜g(r)
k
= g
˜θ(r)
k

. Then the impor-
tance sample estimator may be written in terms of weights, w(r)
k
= ˜π(r)
k /˜g(r)
k ,
comparing the prior and importance function, namely,
Mk =

r
˜L(r)
k w(r)
k .
Bridge sampling estimators of marginal likelihoods use the fact that the
marginal likelihood of model k is the normalizing constant, ck = p(y|m = k),
in the relation,
p(θk|y, m = k) = p(y|θk, m = k)p(θk|m = k)
p(y|m = k)
= p∗(θk|y, m = k)
ck
.
The Bayes factor, Bjk = (p(y|m = j)/p(y|m = k)), is then a ratio, cj/ck,
of normalizing constants. Let g(θ) be an approximation to p(θ|y) with known
normalizing constant (e.g., suppose g consists of a multivariate normal density
and a gamma density). Then one has
1 =
	
α(θk)p(θk|y)g(θk)dθk
	
α(θk)g(θk)p(θk|y)dθk
= Eg[α(θk)p(θk|y)]
Ep[α(θk)g(θk)] ,
where α(θ) is a bridge function linking the densities g(θ) and p(θ|y) (see Meng
and Wong, 1996), Eg[] denotes expectation with regard to the density g(θ),
and Ep[] denotes expectation with regard to the density p(θ|y). Substituting
p∗(θk|y, m = k)/ck for p(θ|y) in 1 = Eg[α(θk)p(θk|y)]/Ep[α(θk)g(θk)] gives the
result,
ck = Eg[α(θk)p∗(θk|y, m = k)]
Ep[α(θk)g(θk)]
.
For simplicitly omit conditioning on model k. Then with samples θ(r)(r =
1, . . . , S) and ˜θ(r)(r = 1, . . . , R) from p(θ|y) and g(θ), respectively, one may
estimate the marginal likelihood p(y) of a particular model as,

1
R
R

r=1

α
˜θ(r)
p∗˜θ(r)|y
  
1
S
S

r=1

α

θ(r)
g

θ(r) 
.
Setting α(θ) = 1/g(θ) then gives a marginal likelihood estimator,
M = 1
R
R

r=1
p∗˜θ(r)|y

g
˜θ(r) ,
that uses only samples from the approximate posterior (or importance) den-
sity g(θ).

Model Fit, Comparison, and Checking
49
Setting α(θ) = (1/p∗(θ|y)) gives an estimator based on the harmonic mean
of the ratios (p∗(θ(r)|y)/g(θ(r))), and using parameters sampled from p(θ|y)
rather than g(θ) (Gelfand and Dey, 1994). So
1
M = 1
S
S

r=1
g

θ(r)
p∗
θ(r)|y
.
The choice, α(θ) = (1/g(θ)p∗(θ|y)), leads to the geometric estimator of
Lopes and West (2004), namely,
M =
1
R
R
r=1

p∗˜θ(r)|y

/g
˜θ(r)|y
 0.5
1
S
S
r=1
!
g

θ(r)|y

/p∗
θ(r)|y
"0.5 .
A recursive scheme for obtaining an optimal estimate of α(θ) is also avail-
able, and mentioned by Lopes and West (2004, 54) and Fr¨uhwirth-Schnatter
(2004, equation 8). This simpliﬁes if R = S, as in the ﬁrst illustrative worked
application below. With R ̸= S, s1 = S/(S + R), and s2 = 1 −s1, one has an
updated estimate for M at recursion j,
Mj = A(Mj−1)/B(Mj−1),
where,
A(u) =

r
W2r/(s1W2r + s2u),
B(u) =

s
1/(s1W1s + s2u),
W2r = p

y|˜θ(r)
p
˜θ(r)
/g
˜θ(r)
,
and
W1s = p

y|θ(s)
p

θ(s)
/g

θ(s)
.
2.2.2
Path sampling
Another approximation may be obtained by a technique known as path sam-
pling (Gelman and Meng, 1998). Consider a path variable t ranging from 0
to 1, and deﬁne the power posterior based on various levels of weighted like-
lihood, namely,
pt(θ|y) ∝[p(y|θ)]tp(θ).
Deﬁne the posterior expectation,
z(y|t) =

[p(y|θ)]tp(θ)dθ,

50
Applied Bayesian Hierarchical Methods
so that z(y|t = 0) is the integral of the prior, namely, 1 for proper priors, while
z(y|t = 1) is the marginal likelihood, p(y) =
	
p(y|θ)p(θ)dθ.
To derive an estimate of z(y|t = 1), one may use the identity,
log(p(y)) = log

z(y|t = 1)
z(y|t = 0)

=
1

0
Eθ|y,t log[p(y|θ)]dt,
which states that the log marginal likelihood is the expected log likelihood
with respect to the power posterior at temperature t, with t ranging from 0
to 1. This follows (Friel and Pettitt, 2008) because,
d
dt log[z(y|t)] =
1
z(y|t)
d
dt z(y|t) =
1
z(y|t)
d
dt

{p(y|θ)}tp(θ)dθ

=
1
z(y|t)

{p(y|θ)}t log[p(y|θ)]p(θ)dθ
=
 {p(y|θ)}tp(θ)
z(y|t)
log[p(y|θ)]dθ
= Eθ|y,t log[p(y|θ)].
One may numerically evaluate the integral over t using the trapezoid rule
over T intervals deﬁned using T + 1 temperature functions, qs = ac
s, deﬁned
at cutpoints {a0, . . . , aL} in [0,1], where c is a speciﬁed positive power. So
the estimate log(Mc) of the log marginal likelihood at that power is obtained
by summing over T grid points that combine information from successive
expected log likelihoods,
log(Mc) =
T −1

s=0
(qs+1 −qs)1
2
!
Eθ|y,qs+1 log[p(y|θ)] + Eθ|y,qs log[p(y|θ)]
"
.
Friel and Pettitt (2008) take c = 4, while Song and Lee (2004) take c = 1.
So with T = 40 intervals, equally spaced cutpoints {a0 = 0, a1 = 0.025, a2 =
0.05, . . . , a40 = 1}, and setting c = 4, one has q0 = 0, q1 = (0.025)4, . . . , q39 =
0.9754, q40 = 1. The Monte Carlo standard error of log(Mc) is obtained as the
square root of the summed variances of the contributions to log(Mc) at each
of T grid points. Thus, let δs = 1/2(qs+1 −qs) and let νs be the Monte Carlo
variance of Eθ|y,qs+1 log[p(y|θ)]. Then the variance at each grid point is δ2
sνs
and the Monte Carlo variance of log(Mc) is T −1
s=0 δ2
sνs.
2.2.3
Marginal likelihood for hierarchical models
For conjugate hierarchical models (e.g., Poisson-gamma mixtures), the margi-
nal likelihood can be obtained analytically (Albert, 1999). However, general
linear mixed models (Clayton, 1996) are widely used for handling multiple
random eﬀects, with regression terms,
ηi = Xiβ + Wibi,

Model Fit, Comparison, and Checking
51
where Xi and Wi are predictors, and bi are latent data. For such nonconjugate
schemes, the marginal likelihood is not obtainable analytically, and one possi-
ble approach to evaluating marginal likelihoods is to work with the integrated
likelihood,
p(y|θ) =

p(y, b|θ)db =

p(y|b, θ)p(b|θ)db,
where the random eﬀects or latent data have been integrated out, and where θ
includes hyperparameters ψ (e.g., covariances) governing b, as well as param-
eters ϕ (e.g., ﬁxed regression eﬀects) not relevant to the random eﬀect hyper-
density (Fruhwirth-Schnatter, 1999; Sinharay and Stern, 2005). This can be
done in practice in MCMC sampling by applying importance sampling, the
Laplace approximation, or numeric integration methods to the complete data
likelihood, p(y, b|θ).
However, it may be argued that under a Bayesian approach the distinction
between ﬁxed and random regression coeﬃcients is less relevant, and so use of
the integrated likelihood and implied numerical complexity may be avoided.
For example, one may (e.g., Clayton, 1996) adopt a uniﬁed perspective on the
parameters in the joint precision matrix for the ﬁxed eﬀects (and other param-
eters not in the hyperdensity) ϕ, and the random eﬀects hyperparameters, ψ.
Sinharay and Stern (2005) also mention obtaining the marginal likelihood by
considering the expanded parameter set, ω = (b, ϕ, ψ), so that,
p(y) =

p(y|ϕ, ψ)p(ϕ, ψ)dϕdψ,
=

p(y|ϕ, b)p(b|ψ)p(ψ, ϕ)dbdψdϕ.
The advantage of working with the expanded likelihood, p(y|b, ϕ), is the
avoidance of repeated integration, but this comes at the expense of an of-
ten considerably increased dimension of the parameter space (namely, by the
number of components in b). Marginal likelihood approximation retaining the
expanded likelihood is considered in real examples by Nandram and Kim
(2002) and Gelfand and Vlachos (2003).
Let g(θ|b) be a density subject to
	
g(θ|b)dθ = 1, where θ = (ψ, ϕ), and
let θ∗be an appropriate ﬁxed point (e.g., a posterior mean). Chen (2005) men-
tions an estimator for the log marginal likelihood, M = p(y), in a hierarchical
modeling situation based on the identity,
p(y|θ∗) =

p(y|θ∗, b)p(b|θ∗)g(θ|b)dθdb,
=
 g(θ|b)
p(θ)
p(y|θ∗, b)p(b|θ∗)
p(y|θ, b)p(b|θ) p(y|θ, b)p(b|θ)p(θ)dθdb,
= p(y)E
g(θ|b)
p(θ)
p(y|θ∗, b)p(b|θ∗)
p(y|θ, b)p(b|θ)
 y

,

52
Applied Bayesian Hierarchical Methods
where the expectation is over samples from p(θ, b|y). Taking logarithms
provides,
log[M] = log[p(y|θ∗)] −log

E
g(θ|b)
p(θ)
p(y|θ∗, b)p(b|θ∗)
p(y|θ, b)p(b|θ)
 y

.
So with samples {θ(r), b(r)} from p(θ, b|y), an estimator for log[M] is
log[M] = log[p(y|θ∗)] −log

1
R
R

r=1
g

θ(r)|b(r)
p

θ(r)
p

y|θ∗, b(r)
p

b(r)|θ∗
p

y|θ(r), b(r)
p

b(r)|θ(r)

.
One option is then to set g(θ|b) = p(θ), leading to,
log[M] = log[p(y|θ∗)] −log

1
R
R

r=1
p

y|θ∗, b(r)
p

b(r)|θ∗
p

y|θ(r), b(r)
p

b(r)|θ(r)

,
The component, log[p(y|θ∗)] = log(L∗), may be estimated from the Monte
Carlo average,
L∗= 1
R
R

r=1
p

y|θ∗, b(r)
.
Chen (2005) shows that a variance minimizing estimator is, however, ob-
tained by setting g(θ|b) = p(θ|b, y), namely, the conditional posterior density
of θ given b.
Example 2.1. Marginal Likelihood Estimates for Turtle Mortality
Data
This example uses approximations to the marginal likelihood in data
from Sinharay and Stern (2005) under the complete likelihood perspective
just mentioned. It compares a simple ﬁxed eﬀect model against a random
eﬀects alternative for nested binary data, yij, on n = 244 newborn turtles,
i = 1, . . . , mj, clustered into clutches, j = 1, . . . , J, with responses yij =
1 or 0 according to survival or death. The known predictor is turtle birth-
weight, xij, so there are p = 2 regression parameters including an intercept.
The J = 31 clutches are numbered in increasing order of the average birth-
weight of the turtles in the clutch. Graphical analysis suggests that heavier
turtles have better survival chances, but also suggests extraneous variability
in survival rates across clutches.
Two alternative models are to be evaluated for the probability, πij =
Pr(yij = 1). One involves a ﬁxed eﬀects only regression on birthweight with
a probit link. The other assumes additional random eﬀects based on clutch
membership. So, model 1 speciﬁes πij1 = Φ(β1 + β2xij), while model 2 has
πij2 = Φ(β1 + β2xij + bj),
where bj ∽N(0, σ2
b). Sinharay and Stern (2005) compare several methods
of deriving formal model ﬁt measures, namely, marginal likelihoods or Bayes

Model Fit, Comparison, and Checking
53
factors. Here the marginal likelihood of the alternative models is initially es-
timated using the temperature path approach of Friel and Pettitt (2008), and
with N(0, 10) priors on ﬁxed eﬀects {β1, β2} as in Sinharay and Stern (2005).
There are several possible sources of sensitivity. The formal model mea-
sures will depend not only on the degree of informativeness in the priors (e.g.,
the prior variance on the ﬁxed eﬀects), but may depend on the form of prior,
for example, the prior density adopted on the random eﬀects variance, σ2
b,
or precision, τb = 1/σ2
b. Possibilities include gamma, lognormal, or uniform
priors. Sinharay and Stern (2005) consider a form of shrinkage prior,
p

σ2
b

∝
1
1 + σ2
b
,
that tends to downweight larger values of σ2
b. For example, the value σ2
b = 1
has half the prior weight of σ2
b = 0. With this prior, Sinharay and Stern obtain
an inconclusive Bayes factor of 1.31 in favor of the simpler ﬁxed eﬀects only
model.
To illustrate sensitivity to the prior on the variance, a gamma prior on
τb is initially assumed, namely, τb ∼Ga(1, 1). The path sampling approach1
of Friel and Pettitt (2008) and Song and Lee (2004) is applied, with qs = a
4
s
and T = 20, and with {a0, . . . , aT +1} then having elements {0.00001, 0.05,
0.10, . . . , 0.95, 1}. For numeric stability, the ﬁrst element in as is taken as
0.00001 rather than 0, so that q0 = 1E −20. This device could possibly be
avoided with more informative priors, e.g., a N(0, 1) prior on β2. Although
formally the estimate of log[p(y)] is obtained by piecing together the sepa-
rate posterior estimates, Eθk|y,tsp(y|θk), an essentially identical estimate is
obtained by applying the trapezoid rule at each iteration and monitoring the
composite log marginal likelihood node.
The marginal likelihood estimate for model 1 is obtained as −155.29 com-
pared to −155.53 for the random eﬀects extension giving B12 = 1.27. These
estimates are based on the last 90,000 iterations of single chain runs of 100,000
iterations2, and have respective Monte Carlo standard errors of 0.030 and
0.117. Relatively large clutch eﬀects (mean with posterior sd) are obtained
under model 2 for clutches 1, 9, and 11, namely, 0.82 (0.34), 0.65 (0.42),
and 0.60 (0.39). Posterior plots of the eﬀects indicate normality, so the ﬁrst
eﬀect might be judged signiﬁcant or necessary. To assess signiﬁcance, an al-
ternative device, namely, monitoring the probability that bj is positive, may
be applied—see Example 2.2, also using the turtles mortality data. With a
slightly more diﬀuse Ga(0.1, 0.1) prior on τb, the marginal likelihood for the
random eﬀects model is raised to −155.15 and B12 reduced to 0.8.
The bridge sampling method is also applied under the prior τb ∼Ga(1, 1),
and with importance sample estimates of {β1, β2, τb, b1, . . . , bJ} based on
a preliminary run. A gamma approximation is used for p(τb|y) and nor-
mal approximations for the remaining parameters. Thus the preliminary run
provided a posterior mean and standard deviation for τb of 3.74 and 1.45
and this translates to a gamma Ga(6.65, 1.78) approximation for p(τb|y).

54
Applied Bayesian Hierarchical Methods
A WinBUGS code3 to provide the quantities required for the iterative
scheme (in MATLAB r
⃝) to obtain the optimal α function involves sampling
{β1, β2, τb, b1, . . . , bJ} both from the posterior and the importance functions;
this is followed (for both sets of parameter samples) by log likelihood calcu-
lations, and by normal and gamma function evaluations over both log prior
and log importance densities.
R = 5000 samples of the four required statistics under the prior, τb ∼
Ga(1, 1), are obtained and the recursions run 500 times. The bridge samp-
ing method gives an estimate for log(M) of −156.5 for the ﬁxed eﬀects model,
and −160.2 for the random eﬀects model; so B12 = 46.5. Although both path
and bridge sampling reach the same conclusion regarding the better model,
the variation in marginal likelihood estimates between them reﬂects features
of the approximations used, such as the arbitrariness of the power in the
temperature function (path method), and imperfections in the importance
sample densities as approximations to the posterior density (bridge method).
2.3
Eﬀective Model Dimension and Deviance
Information Criterion
Classical approaches to model choice methods are frequently based on pe-
nalized likelihood criteria, such as the Akaike information criterion (AIC)
(Akaike, 1973), and the Bayesian information criterion (BIC) (Schwarz, 1978).
Such criteria are applicable in comparing ﬁxed eﬀects models with known
dimension d, and with models assumed nested within one another. With L de-
noting a log likelihood, and D = −2L denoting the deviance, log likelihood
ratio tests comparing maximized log likelihoods of models 1 and 2 are ob-
tained with,
C = −2(log L1 −log L2) = D1 −D2,
where C is approximately chi-square, with degrees of freedom d2 −d1 equal to
the number of additional parameters in the more complex model 2. The AIC
is deﬁned as 2d −2L = D + 2d and the diﬀerence in AICs between models 1
and 2 is ∆AIC = C + 2(d1 −d2). However, classical likelihood ratio testing is
not possible in random eﬀects models or models with parameter constraints
(e.g., order of size constraints) that make the eﬀective number of estimated
parameters itself a random variable so that the asymptotic distribution of the
log likelihood ratio is unknown.
Spiegelhalter et al. (2002) provide a penalized ﬁt criterion analogous to
the AIC and BIC, called the deviance information criterion (DIC). This is
applicable to comparing non-nested models and also to models including ran-
dom eﬀects where the true model dimension is another unknown. The DIC is
based on the posterior distribution of the deviance statistic,

Model Fit, Comparison, and Checking
55
D(θ|y) = −2 log[p(y|θ)] + 2 log[h(y)],
where p(y|θ) is the likelihood of data y given parameters θ, and h(y) is a
standardizing function of the data only (and so does not aﬀect model choice).
Suppose the deviance is monitored as an extra node in an MCMC run,
providing samples {D(1), . . . , D(R)}. The overall ﬁt of a model is measured
by the posterior expected deviance obtained by averaging over the posterior
density of the parameters,
¯D = Eθ|y[D],
while the eﬀective model dimension, de, is estimated as,
de = Eθ|y[D] −D(Eθ|y[θ]) = ¯D −D(¯θ),
namely, the expected deviance minus the deviance at the posterior means of
the parameters; the latter is also known as the plug-in deviance (Plummer,
2008). In hierarchical random eﬀects models, the eﬀective number of param-
eters total is typically lower than the nominal number of parameters, due to
borrowing of strength under the hyperdensity (e.g., Buenconsejo et al., 2008;
Zhu et al., 2006).
The DIC is then obtainable as the expected deviance plus the eﬀective
model dimension,
DIC = ¯D + de = D(¯θ) + 2de.
So the DIC will prefer models with lower values of ¯D, combined with small
values of de (which indicate a relatively parsimonious model). A possible dis-
advantage with the DIC is that it can be aﬀected by reparameterization of θ,
or by the form of link in general linear models, with this applying in particu-
lar to the “plug-in” deviance, D(¯θ); hence the value of de may be sensitive to
parameterization.
The DIC and de can be disaggregated to individual observations, and pro-
vide a measure of local complexity, namely, of observations that are more
problematic under the model relative to others. Spiegelhalter et al. (2002, 602)
mention that the local complexity measures,
dei = ¯
Di −Di(¯θ),
measure the leverage of observation i, deﬁned as the relative inﬂuence that
each observation has on its own ﬁtted value. Unusually large observation-
speciﬁc DIC measures, namely,
DICi = ¯
Di + dei,
are used by Spiegelhalter et al. (2002) as indicators of outlier status—
observations inconsistent with the model.

56
Applied Bayesian Hierarchical Methods
The DIC can be seen as a Bayesian version of AIC and may underpenalize
model complexity, as pointed out by discussants to Spiegelhalter et al. (2002).
Plummer (2008) conﬁrms that the DIC underpenalizes complex models, par-
ticularly when the ratio of the sample size to the eﬀective number of pa-
rameters is relatively low. By contrast, it is well established (Burnham and
Anderson, 2002) that the BIC tends to select overly parsimonious models.
A ﬁt criterion analogous to the BIC may be deﬁned as,
DIC
∗= D(¯θ) + de log(n),
and was used by Pourahmadi and Daniels (2002, 228) for panel data with
repeated observations over n subjects. Note that the model with the lowest
DIC or DIC
∗will not necessarily be a suitable model if it does not reproduce
the data adequately. Hence, model checks are required to assess consistency
of predictions from the model with the actual observations.
Just as there are alternative approaches to marginal likelihood derivation
in hierarchical models, Spiegelhalter et al. (2002) point out that for such mod-
els, one cannot uniquely deﬁne the likelihood or model complexity without
specifying the level of the hierarchy that is the model focus. Thus, one might
analyze count data using a complete data likelihood (with unknown latent data
b as well as hyperparameters θ) using a Poisson-gamma or Poisson-lognormal
model, or alternatively apply a negative binomial likelihood with the random
eﬀects integrated out (Fahrmeir and Osuna, 2003), and the complexity mea-
sures will obviously diﬀer. Model choice may be aﬀected by the focus, as shown
by Plummer (2008, 530) in an analysis of a discrete mixture model, with one
approach considering a complete data likelihood, pC(y|b, θ) (with the param-
eters including missing component indicators), and the other considering the
integrated likelihood, pI(y|θ). Ando (2007) considered DICs based on both
conditional and integrated likelihoods, namely, DICC and DICI, and showed
that both tend to select overﬁtted (i.e., nonparsimonious) models.
Issues of focus as well as the derivation of the complexity measure, de, are
considered by Celeux et al. (2006). In general terms, a complexity measure
or eﬀective parameter count is obtained by comparing the mean deviance
with the deviance at the pseudo-true parameter values θt (Spiegelhalter et al.,
2002, Section 2.2). There are various possible estimators, ˜θ, of the pseudo-true
parameter values, θt, apart from the elementwise posterior means. Another
possibility is to consider the posterior mode value, ˆθ, which generates the
maximum posterior density, p(θ|y) ∝p(y|θ)p(θ) (Celeux et al., 2006, 654),
namely,
ˆθ = arg max
θ
p(θ|y).
In missing data applications (e.g., discrete mixture models and random ef-
fect models) with missing data b, this extends to considering the pair (ˆθ,ˆb) that
generates the maximum posterior density (Celeux et al., 2006, 656). Celeux
et al. (2006) mention other possibilities for ˜θ, such as the EM (expectation-
maximization) maximum likelihood estimate.

Model Fit, Comparison, and Checking
57
Celeux et al. state diﬀerent DIC deﬁnitions under three alternative foci (ob-
served data likelihood, complete data likelihood, and conditional likelihood)
and under diﬀerent options for ˜θ. For the observed data focus with likelihood
p(y|θ), obtained possibly after integrating out random eﬀects, one has,
DIC = ¯D+de = D(˜θ)+2de = 2 ¯D−D(˜θ) = −4Eθ[log{p(y|θ)}|y]+2 log[p(y|˜θ)].
It can be seen that taking θ as the posterior mean amounts to assuming,
DIC = −4Eθ[log{p(y|θ)}|y] + 2 log[p{y|Eθ(θ|y)}],
whereas taking ˜θ as the posterior mode ˆθ amounts to an alternative DIC
deﬁnition, denoted DIC2 by Celeux et al., namely,
DIC = −4Eθ[log{p(y|θ)}|y] + 2 log[p(y|ˆθ)].
For a complete data focus, with likelihood p(y, b|θ) = p(y|b, θ)p(b|θ) in-
cluding the second stage likelihood model, p(b|θ), for the missing data (e.g.,
Kuhn and Lavielle, 2005), one obtains,
¯D = −2Eθ,b[log{p(y, b|θ)}|y].
Taking b as additional parameters, one may deﬁne ˜θ on the basis of joint
modal or maximum a posteriori parameters, (ˆθ,ˆb), so that de is obtained by
comparing the average deviance ¯D with,
D(˜θ) = −2 log[p(y,ˆb|ˆθ)].
The joint mode (ˆθ,ˆb) may be estimated by monitoring the posterior density
over an MCMC sequence, and ﬁnding that set of values {θ(r), b(r)} associated
with the maximum value, pmax(θ|y), of the posterior density. The DIC may
then be deﬁned as,
DIC = −4Eθ,b[log{p(y, b|θ)}|y] + 2 log[p(y,ˆb|ˆθ)],
with complexity estimated as,
de = −2Eθ,b[log{p(y, b|θ)}|y] + 2 log[p(y,ˆb|ˆθ)].
This procedure has the disadvantage that ordinates of prior densities (in-
cluding densities for random eﬀects) have to be evaluated at each iteration.
To ensure satisfactory estimation of log[p(y,ˆb|ˆθ)], one may consider values
obtained from diﬀerent batches of MCMC sequences and/or diﬀerent chains,
and ensure that they show consistency in the estimated log[p(y,ˆb|ˆθ)]. Similarly,
under a conditional likelihood approach, the DIC may be deﬁned as,
DIC = −4Eθ,b[log{p(y|θ, b)}|y] + 2 log[p(y|ˆb,ˆθ)],

58
Applied Bayesian Hierarchical Methods
with complexity estimated as,
de = −2Eθ,b[log{p(y|b, θ)}|y] + 2 log[p(y|ˆb,ˆθ)].
The deviance D(¯θ|y) at the posterior mean ¯θ of the parameters may also
be estimated using posterior means of quantities involved in deﬁning the
deviance, such as case means (Poisson likelihood), means and overdisper-
sion parameter (negative binomial likelihood), means and variance (normal
likelihood), and so on (Spiegelhalter et al., 2002, 596). Thus, let µi denote
case-speciﬁc means and ξ denote any another parameters needed to derive
the deviance. Then the estimate, D(¯µ, ¯ξ|y), may be more easily obtainable
than D(¯θ|y) in complex (e.g., discrete mixture) models, or in models with
many random eﬀects, where the number of nominal parameters may consid-
erably exceed the number of cases. For an illustration, see an application of
the Potts spatial model in Chapter 4 (Example 4.9). This type of procedure
is also mentioned by Spiegelhalter (2006) in terms of monitoring the “direct
parameters” that appear in the distributional syntax and plugging these into
the deviance; it was adopted in the paper by Ohlssen et al. (2006, Section 2).
Example 2.2. Turtle Survival
This example seeks to demonstrate pos-
sible issues in establishing whether one model improves over another under
the posterior deviance approach, and how inferences may be aﬀected by alter-
native priors on hyperparameters. Simulations are also used to show how the
eﬀective parameter count reﬂects the amount of random heterogeneity in the
data.
As in Example 2.1, two models are considered for the observed survival
data. Normal N(0, 10) priors are adopted on the ﬁxed eﬀects and as the ﬁrst
of three options, a Ga(0.1, 0.1) prior is initially assumed on the random eﬀects
precision, τb = 1/σ2
b, in model 2 that includes clutch eﬀects. The ﬁxed eﬀects
priors follow Sinharay and Stern (2005), whereas the prior on the precision
follows the commonly adopted diﬀuse setting, Ga(ε, ε), with ε small (e.g.,
Green and Richardson, 2000; Lambert et al., 2005). A possible alternative is
Ga(1, ε) as in Besag et al. (1995) and Fahrmeir and Lang (1997). These options
correspond in the limit as ε →0 to p(τb) ∝1/τb and to a ﬂat prior on τb.
With two chain runs4 involving R = 10,000 iterations (B = 1000 itera-
tions for burn in), the DICs of models 1 and 2 are obtained as 301.6 and 298.1,
with de1 = 1.98, de2 = 12.8, D(¯θ1) = 299.7, and D(¯θ2) = 272.5. The eﬀective
parameter total, de2, for model 2 is about 11 higher than model 1, whereas
there are 32 extra nominal parameters (the random eﬀects variance and each
of the 31 cluster eﬀects), illustrating the impact of borrowing strength on the
parameter total.
Comparing the DICs suggests a small advantage for the random eﬀects
model, though the small DIC diﬀerence might not be judged signiﬁcant ac-
cording to the rule of thumb in Spiegelhalter et al. (2002, Section 9.2.4).
A more speciﬁc focus on the parameter estimates from model 2 shows the
density of σb to be relatively symmetric and to have its mass away from zero

Model Fit, Comparison, and Checking
59
0.2
0.4
0.6
0.8
1.0
N = 9000 bandwidth = 0.02
Density
3
2
1
0
FIGURE 2.1
Kernel density clutch eﬀects standard deviation.
(Figure 2.1), supporting the preference by the DIC for this model. In this con-
nection, McNab et al. (2004) illustrate how—when a form of random variation
is not supported by the data—the density of the random eﬀects standard de-
viation can be heavily skewed to the left or “spiked,” with the posterior mass
piled up against zero.
It is also relevant to consider the signiﬁcance of individual random eﬀects.
In fact, only the ﬁrst cluster eﬀect seems to be clearly signiﬁcant (with a .97
chance of exceeding zero), but the last has a posterior probability of .06 of
exceeding 0, so it is close to signiﬁcance. It is also relevant (in assessing the
gain from adding random eﬀects) to consider eﬀect contrasts {bi −bj} and
whether these are signiﬁcantly diﬀerent from zero.
Note that BIC analogues DIC∗for models 1 and 2 are obtained as 310.7
and 316.5, with implicit marginal likelihood approximations of −155.3 and
−158.2. This is calculated—in line with Pourahmadi and Daniels (2002)—
by taking the number of observations as the cluster total of J = 31, so that
DIC∗= D(¯θ)+de log(J). So the BIC analog, like the formal criteria considered
in Example 2.1, tend to ﬁnd evidence against the more heavily parameterized
model 2, in contrast to the DIC.
The alternative Ga(1, 1) prior for τb = 1/σ2
b used in Example 2.1 is also
applied. This prior is less likely to generate very small near zero precisions
(i.e., less likely to generate large random eﬀect variances). By contrast, small
ε values in the Ga(ε, ε) prior may lead to a spike at (virtually) zero values
(Lambert, 2006). The DIC for model 2 is then 299.7, with the eﬀective pa-
rameter count about 4 higher, namely, de2 = 17.1, and D(¯θ2) = 282.6. It is
apparent that the eﬀective parameter count, de, may be sensitive to the prior
adopted for the inverse variance. Unlike the formal ﬁt criteria in Example 2.1,
the DIC still prefers the random eﬀect model.
A further option is a bounded uniform prior on the standard deviation
of the clutch eﬀects, for example, σb ∼U(0, 10). This provides DIC2 = 299,
with de2 lower at 11.8, but the deviance at the parameter means higher at

60
Applied Bayesian Hierarchical Methods
D(¯θ2) = 287.3. The mean for σb is 0.33, with a posterior density bounded away
from zero. This option again conﬁrms that the eﬀective parameter count, de,
may be sensitive to the prior adopted for the variance or precision, and the
number of individually signiﬁcant random eﬀects may also be sensitive to
variance priors. Under this bounded uniform prior on σb, no clutch eﬀects are
signiﬁcant in the sense of Pr(bj > 0|y) being over 0.95 or under 0.05, whereas
with τb ∼Ga(0.1, 0.1) there were signiﬁcant eﬀects.
To illustrate the impact of the level of random variation in the data on
the eﬀective parameter estimate, the birthweight and clutch membership data
are retained, but survival indicators, yij, are simulated5 under various preset
levels of σ2
b. Three diﬀerent preset values σ2
b, namely, σ2
b = 1, σ2
b = 0.01, and
σ2
b = 0.001 are considered.
One may then estimate de for the values of y sampled under the three
options on σ2
b. The prior, σb ∼U(0, 10), is adopted. With a high level of
random variation (σ2
b = 1), we obtain de = 24.7, while low random varia-
tion (σ2
b = 0.01) gives de = 6.9, and a situation with limited random vari-
ation (σ2
b = 0.001) leads to de = 6.3. Therefore, the eﬀective parameters
associated with a random eﬀects density increase with the level of heterogene-
ity present. The analysis is complicated by overestimation of σ2
b against its
true value (i.e., the one on which the simulated y are based), with posterior
means of 1.55, 0.06, and 0.04 under the three scenarios.
2.4
Variance Component Choice and Model Averaging
A considerable amount of research has been devoted to MCMC selection of sig-
niﬁcant ﬁxed eﬀects, namely, signiﬁcant predictors in regression—sometimes
called Bayesian “variable selection” or predictor selection. Such techniques
are consistent with a formal Bayes approach, but less constrained by the
complex integration issues that may be involved in obtaining marginal likeli-
hoods. Diﬀerent possible approaches to predictor selection are considered by
Fernandez et al. (2001), George and McCulloch (1997), and Sala-i-Martin et al.
(2004). Let Jj be a binary indicator for retaining or excluding the jth regres-
sion coeﬃcient βj, George and McCullough (1993, 1997) develop stochastic
search variable selection (SSVS) using a mixture prior,
p(βj|Jj) = 1(Jj = 1)p(βj|Jj = 1) + 1(Jj = 0)p(βj|Jj = 0),
in which the “inclusion prior,” p(βj|Jj = 1), is a diﬀuse or possibly informative
prior, but one that allows realistic search for the parameter value. By contrast,
the “exclusion prior,” p(βj|Jj = 0), is centered at zero with high precision.
For example, one might have,
p(βj|Jj = 1) ∼N(0, Vj),

Model Fit, Comparison, and Checking
61
with Vj large, but,
p(βj|Jj = 0) ∼N(0, Vj/Kj)
Kj ≫1,
with Kj chosen so that the sampling from the prior is constrained to values
around zero, that is, to substantively insigniﬁcant values. If all p predictors
apart from the intercept are open to inclusion or exclusion, then MCMC sam-
pling over parameters βj and indicators Jj is averaging over 2
p possible models
(Fernandez et al., 2001).
By contrast, Kuo and Mallick (1998) and Smith and Kohn (1996) take the
selection indicators, Jj, and coeﬃcients, βj, to be independent rather than
being governed by mixture priors. Assuming normal priors, one has βj = 0 if
Jj = 0, but p(βj) ∼N(0, Vj) if Jj = 1. Following Zellner (1986), the prior on
(β0, β1, . . . , βp) when Jj = 1 may be speciﬁed as a g-prior, namely,
(β0, β1, . . . , βp|σ2) ∼Np+1(B, gσ2(XX )−1),
where g is a known constant and B is typically a vector of zeroes (Vannucci,
2000).
Model indicator selection ideas has also been applied to the parameters
governing random eﬀects so that only genuine sources of heterogeneity are re-
tained. Such covariance selection helps ensure sparse structure in the covari-
ance matrix of the selected (retained) random eﬀects (Fr¨uhwirth-Schnatter
and T¨uchler, 2008). Selection may relate to the retention or otherwise of uni-
variate random eﬀects—for example, a multilevel model with a random inter-
cept (as in the turtle survival analysis) or the convolution model of Besag et al.
(1991) for area count data. For multivariate random eﬀects, such as random
cluster intercepts, b0j, and slopes {b1j, . . . , bpj} in a multilevel analysis,
yij = b0j + b1jx1ij + · · · + bpjxpij + uij,
one can consider retaining covariances, Σbgh, subject to variances in both ef-
fects, bgj and bhj, being retained. Thus, Smith and Kohn (2002) identify zero
oﬀ-diagonal elements in the inverse, Πb = Σ−1
b , of the variance–covariance
matrix. Alternatively, one may allow exclusion also of variance components
(diagonal terms in Σb), which necessarily leads to exclusion of associated
covariances.
Shively et al. (1999) suggest variance component selection based on infor-
mative priors in the sense of using an exploratory run of the data to provide
a sensible prior on the variance component. In general, noninformative priors
are to be avoided in model selection applications as they bias selection toward
null models (Ghosh and Dunson, 2008). Shively et al. (1999) suggest initial
runs of random eﬀects models based on the usual choice for variances, such
as a diﬀuse inverse gamma or uniform over a wide interval (Yau and Kohn,
2003, 193), or an inverse Wishart prior for covariance matrices. Suppose σ2
b
is a single variance component (e.g., an intercept variance) as in the turtle

62
Applied Bayesian Hierarchical Methods
data example above. Long run of samples of h(r) = log(σ2(r)
b
) would then be
obtained in a ﬁrst stage analysis using standard diﬀuse priors, providing the
basis for lognormal priors on σ2
b,
σ2
b ∼LN (Mσ, Vσ),
at the second stage. Speciﬁcally, as in Yau et al. (2003, 34), the median of
h(r) provides the mean, Mσ, for a second stage lognormal prior, while the
variance, Vσ, is provided by n times the variance, Vh = var(h(r)), where n is
the total sample size, or the number of units involved in deﬁning the particular
random eﬀect. Shively et al. (1999, 779–80) argue that scaling the variance in
this way leads to model selection that approximately replicates selection via
the BIC. Variance inﬂation by a factor of n is a particular setting in a g-prior
adjustment as discussed by Liang et al. (2008, 413), and one might instead
choose a data-based approach with Vσ = gVh involving a uniform prior on the
shrinkage factor g/(1 + g).
Consider a model with K variance components. For example, the convolu-
tion model of Besag et al. (1991) widely used in disease mapping has K = 2
components. Then the variance component selection at the second stage in-
volves binary indicators, Jk ∼Bern(πk), where (at any particular MCMC
iteration) a sampled value, Jk = 1, corresponds to retaining the random ef-
fects bkj (for areas j) with a nonzero variance, while Jk = 0 corresponds to
σ2
bk = 0, and amounts to setting all bkj = 0. The πk could be preset or taken
as extra unknowns. If πk are preset (e.g., πk = 0.5), then the posterior prob-
ability, Pr(Jk = 1|y), would be obtained from the MCMC run, and the odds
ratio Pr(Jk = 1|y)/[1−Pr(Jk = 1|y)], compared to its prior value (which is 1
when πk = 0.5).
One may also follow an analog to the George and McCulloch (1997)
approach in predictor selection, whereby Jk = 1 corresponds to a realistic
variance prior, while Jk = 0 corresponds to choosing an informative prior
giving a very low variance, which is substantively negligible. The setting for
the latter would typically be context speciﬁc and depend on the scale of the
predictors (including intercepts) to which random eﬀects are applied. For ex-
ample, if bj were random cluster eﬀects (variable intercepts) in a two level
normal model for responses yij,
yij = bj + Xiβ + eij,
with intercept variance anticipated to be around 5, then the “no eﬀective
variance” option could be centered at a variance of 0.05, for instance via an
informative Ga(20, 1) prior on the precision.
Selection schemes applicable to both diagonal and oﬀ-diagonal elements in
covariance matrices for random eﬀects have been developed by Cai and Dun-
son (2006), Chen and Dunson (2003), and Fruhwirth-Schnatter and Tuchler
(2008). Thus consider a general linear mixed model for nested responses yij
(as in longitudinal data with repetitions i over subjects j) with means µij.

Model Fit, Comparison, and Checking
63
These means are linked to a P × 1 vector of regressors, Xij, and Q × 1 vector
of regressors, Zij, via the model,
g(µij) = X′
ijβ + Z′
ijbj,
where g is an appropriate link, β = (β1, . . . , βQ)′ denotes the central ﬁxed
eﬀects, and bj = (bj1, . . . , bjQ)′ are zero mean random eﬀects with covari-
ance 
b = {σbkl}. For continuous data—and discrete outcomes subject to
overdispersion—an observation level residual is also present, so that,
g(µij) = X′
ijβ + Z′
ijbj + uij,
with uij usually taken as i.i.d. errors.
Following Cai and Dunson (2006), one possible Cholesky decomposition of
the covariance matrix for bj = (bj1, . . . , bjQ)′ has the form,
Σb = ΛΓΓ′Λ,
where Λ = diag(λ1, . . . , λQ) and Γ is a lower triangular matrix,
Γ =





1
0
· · ·
0
γ21
1
· · ·
0
· · ·
· · ·
...
0
γQ1
γQ2
· · ·
1




,
implying,
σbkl = λkλl

γr2r1 +
r1−1

s=1
γksγls

,
where r2 = max(k, l), r1 = min(k, l). Then one has,
g(µij) = X′
ijβ + Z′
ijΛΓcj + uij,
where {cjq ∼N(0, 1), q = 1, . . . , Q} are uncorrelated standard normal
variables.
The selection indicators for retaining variances and covariances are Jq ∼
Bern(πΛ), governing the diagonal terms in Λ, and Hkl ∼Bern(πΓ) governing
the terms in Γ. Note that retaining γkl requires not only Hkl = 1, but Jk =
Jl = 1. If either Jk or Jl is zero then γkl is necessarily excluded. Cai and
Dunson (2006) suggest positive truncated normal priors with variance 10 for
the diagonal terms λq, namely,
λq ∼N(0, 10)I(0, )
if
Jq = 1,
λq = 0
if
Jq = 0,

64
Applied Bayesian Hierarchical Methods
but one may also use the data-based approach of Shively et al. (1999). Diﬀuse
priors are not recommended (Cai and Dunson, 2008, 72) as they may favor
the null model. There may also be a case for interlinked priors for λq and the
variances of the uij eﬀects (if present).
Smith and Kohn (2002) parameterize the covariance matrix through a
Cholesky decomposition of its inverse. Thus,
Σ−1
b
= HDH ′,
where H is lower triangular with ones on the diagonal, while D is diagonal,
D = diag(d1, . . . , dQ). So for Q = 2, one obtains,
Σ−1
b
=

h1
d1h21
d1h21
h2
21d1 + d2

,
and for Q = 3,
Σ−1
b
=


d1
d1h21
d1h31
d1h21
h2
21d1 + d2
h21h31d1 + h32d2
d1h31
h21h31d1 + h32d2
h2
31d1 + h2
32d2 + d3

.
Kohn and Smith apply selection to the elements of H, so that, potentially,
H could be reduced to an identity matrix. They take Jh
jk ∼Bern(πH), where
πH is an extra unknown and,
hjk ̸= 0 if Jh
jk = 1, j ≥k,
hjk = 0 if Jh
jk = 0.
If all selection indicators are zero, Σb is shrunk toward the diagonal ma-
trix D−1.
Selection can be extended to the diagonal terms in D also, with the “vari-
ance absent” option corresponding to inﬁnite precision, dq →∞. The George–
McCulloch strategy of eﬀectively zero variance would correspond to a very
high precision chosen for each variation source, q, according to context. Thus,
Jd
q = 1 corresponds to selecting dq from priors that allow realistic exploration,
while Jd
q = 0 corresponds to setting dq to large values, taken so large as to be
eﬀectively equivalent to random variation being negligible.
Fruhwirth-Schnatter and Tuchler (2008) consider the covariance matrix
decomposition,
Σb = CC ′,
with C a lower triangular matrix of dimension Q including unknown diagonal
terms Cqq. To illustrate the resulting covariance selection procedure, a hierar-
chical linear normal model with varying cluster regression eﬀects, βj = β + bj,
of dimension Q, would be reframed as,
yij = Xij(β + bj) + uij = Xijβ + XijCzj + uij,

Model Fit, Comparison, and Checking
65
where uij ∼N(0, 1/τu) and zj = (zj1, zj2, . . . , zjQ)′ is a Q × 1 vector dis-
tributed as NQ(0, I). Consider binary indicators, Jkl, for retention or other-
wise of each of the Q(Q + 1)/2 elements of C. Then,
Ckl ̸= 0 if Jkl = 1
(for k ≥l),
Ckl = 0 if Jkl = 0,
and bjk is 0 at a particular iteration if all Ckl in the kth row of C are zero.
A possible prior for the Jkl indicators is Bernoulli with probability πJ, where
πJ follows a beta density,
πJ ∼Be(TJ + 1, Q(Q + 1)/2 −TJ + 1),
based on the total free covariance parameters and the number TJ of Jkl taking
the value 1. For Q = 1 in a model where a cluster level random intercept is to
be tested for inclusion, one would have,
µij = β0 + Xijβ + bj + uij = β0 + Xijβ + czj + uij,
where zj ∽N(0, 1), and c ̸= 0 if J = 1 and c = 0 if J = 0. The (model aver-
aged) estimate of the covariance matrix, Σb, of bj over r = 1, . . . , R iterations
of a chain is obtained as,
Σb = 1
R
R

r=1
C(r)(C′)(r).
Example 2.3. Hypertension Trial
To illustrate covariance selection for
potentially correlated multiple random eﬀects, this example considers clini-
cial trial data from Brown and Prescott (1999). In the trial concerned, 288
patients are randomly assigned to one of three drug treatments for hyperten-
sion, 1 = Carvedilol, 2 = Nifedipine, and 3 = Atenolol. The data consist of
a baseline reading, BS i, of diastolic blood pressure, and four post-treatment
blood pressure readings, yit, at two weekly intervals (weeks 3, 5, 7, and 9 after
treatment). Some patients are lost to follow up (there are 1092 observations
rather than 4 × 288 = 1152), but for simplicity their means are modeled for
all T = 4 periods.
The baseline analysis (model 1) includes random patient intercepts and
random slopes on the baseline reading. Additionally, the new treatment,
Carvelidol, is referenced in the ﬁxed eﬀects comparison vector, η = (η1, η2, η3),
leading to the corner constraint, η1 = 0. Then for patients, i = 1, . . . , 288, with
treatments, Tri, and waves t = 1, . . . , 4,
yit = β1 + b1i + (β2 + b2i)BS i + ηTr i + uit,
with uit ∼N(0, 1/τu) taken to be uncorrelated through time. In line with
a commonly adopted methodology, the bqi are taken to be bivariate normal
with mean zero and covariance Σb. The precision matrix, Σ−1
b , is assumed

66
Applied Bayesian Hierarchical Methods
to be Wishart with 2 degrees of freedom and identity scale matrix, S. The
observation level precision is taken to have a gamma prior, τu ∽Ga(1, 0.001).
The last 4500 iterations from a two chain run of 5000 iterations give pos-
terior means (and 95% intervals) for β = (β1, β2) of 52.8 (43.6, 75.2) and
0.39 (0.09, 0.48). Posterior means (and 95% intervals) for the random eﬀect
standard deviations, σbj = )Σbjj , of {b1i, b2i} are 0.98 (0.37, 2.7) and 0.094
(0.084, 0.103). Although the posterior density of σb1 is bounded away from
zero, none of the ratios |b1i/sd(b1i)| of posterior means to standard deviations
of the varying intercepts exceed 0.04. By contrast, 74 of 288 ratios |b2i/sd(b2i)|
exceed 2. Correlation between the eﬀects does not seem to be apparent, with
σb12 having a 95% interval straddling zero.
So, absence of signiﬁcant intercept eﬀects at the individual patient level
contrasts with widely signiﬁcant slope variations. This suggests possible re-
dundancy in the full bivariate random eﬀects approach. To implement the
Shively et al. (1999) method, the logs of the variances Σbjj are monitored and
have posterior medians (−0.35, −4.8) and variances (0.94, 0.0084). Following
Yau et al. (2003, 567), these variances are multiplied by the number of patients
(288). This procedure provides parameters for lognormal priors on σ2
bj which
are those used for covariance selection. Independent rather than correlated
eﬀects {b1i, b2i} are now assumed.
Following the principle suggested by George and McCulloch (1993), an
alternative to the “variance present” option (where the variances are those of
the random intercepts and slopes) is not to set the variance to zero, but to
a variance that is inconsequential in the application. These are set here6 at
σ2
b1 = 0.001 and σ2
b2 = 0.0001, so that the precisions τb1 and τb2 are 1000 and
10,000; this speciﬁcation forms model 2.
After 10,000 iterations in a two chain run of 50,000, both chains over-
whelmingly choose to exclude the ﬁrst variance component, namely, the one
associated with variations b1i around the intercept β1. Prior probabilities for
retaining each component are set at 0.5, but the posterior probability for re-
taining σ2
b1 is under 0.01, while the second component (for varying slopes on
baseline blood pressure) has a posterior retention probability of 1.
Finally in model 3, full covariance selection is considered via the ap-
proach of Fruhwirth-Schnatter and Tuchler (2008). Context-based informa-
tive priors for the diagonal elements of C are assumed, namely, C11∼E(1)
and C22∼E(10), based on the posterior means 0.98 and 0.09 for the random
eﬀects standard deviations from the baseline analysis. For the lower diagonal
term a normal prior, C21∼N(0, 1), is assumed. These options are preferred
to, say, adopting diﬀuse priors on the Cjk terms, in order to stabilize the co-
variance selection analysis. Such a strategy may be compared to the Shively
et al. (1999) use of lognormal priors for variances based on results of earlier
analysis. Note that the covariance term, Σ21, is nonzero only when both C11
and C21 are retained7.
The last 9000 iterations of a two chain run of 10,000 iterations give a
posterior probability of 1 for retaining slope variation, while the posterior

Model Fit, Comparison, and Checking
67
probability for intercept variation is 0.6. Posterior means (and 95% intervals)
for the random eﬀect standard deviations σbj = )Σbjj
of {b1i, b2i} are 0.68
(0, 3.8), and 0.065 (0.050, 0.097), with a clear spike at zero in the density
for σb1. Analogous posterior results for βq (q = 1, 2) are 49.2 (43.2, 55.1) and
0.43 (0.37, 0.49), so that the average baseline eﬀect, β2, is both higher and
more precisely identiﬁed than in the conventional bivariate random eﬀects
model (model 1).
Finally, it may be noted that using diﬀuse Ga(1, 0.001) priors on C11 and
C22, and a N(0, 1000) prior on C12, did not produce a posterior analysis re-
sembling the one using more informative priors. A 20,000 iteration two chain
run in fact shows a zero posterior probability for retaining varying slopes. This
is in line with a general principle that model selection tends to choose the null
model if diﬀuse priors are taken on the parameter(s) subject to inclusion or
rejection (Cai and Dunson, 2008).
2.5
Predictive Methods for Model Choice
and Checking
A number of studies have pointed to drawbacks in focusing solely on the
marginal likelihood or Bayes factor as a single global assessment measure of
the performance of complex models, and also mentioned computational and
inferential diﬃculties with the Bayes factor when priors are diﬀuse, as well
as the need to examine ﬁt for individual observations to make sense of global
criteria (e.g., Gelfand, 1996; Johnson, 2004). While formal Bayes methods
can be extended to assessing the ﬁt of single observations (Pettit and Young,
1990), it may be argued that predictive likelihood methods oﬀer a more ﬂexible
approach to assessing the role of individual observations. In fact, predictive
methods have a role both in model choice and model checking.
2.5.1
Predictive model checking and choice
The formal predictive likelihood approach assumes only part of the obser-
vations are used in estimating a model. On this basis, one may obtain
cross-validation predictive densities (Vehtari and Lampinen, 2002), p(ys|y[s]),
where ys denotes a subset of y (the “validation data”), and y[s] is the comple-
mentary “test data” formed by excluding ys from y. If [i] is deﬁned to contain
all the data {y1, . . . , yi−1, yi+1, . . . , yn} except for a single observation i, then
the densities,
p(yi|y[i]) =

p(yi|θ, y[i])p(θ|y[i])dθ,
are called conditional predictive ordinates (CPOs) (e.g., Chaloner and Brant,
1988; Geisser and Eddy, 1979), and sampling from them shows what values

68
Applied Bayesian Hierarchical Methods
of yi are likely when a model is applied to all the data points except the
ith, namely, to the data y[i]. The predictive distribution, p(yi|y[i]), can be
compared to the actual observation in various ways (Gelfand et al., 1992).
For example, to assess whether the observation is extreme (not well ﬁtted)
in terms of the model being applied, replicate data, yi,rep, may be sampled
from p(yi|y[i]) and their concordance with the data may be represented by
probabilities (Marshall and Spiegelhalter, 2003),
Pr(yi,rep ≤yi|y[i]).
These are estimated in practice by counting iterations r where the con-
straint y(r)
i,rep ≤yi holds. For discrete data, this assessment is based on the
probability,
Pr(yi,rep < yi|y[i]) + 0.5Pr(yi,rep = yi|y[i]).
Gelfand (1996) recommends assessing concordance between predictions
and actual data by a tally of how many actual observations, yi, are located
within the 95% interval of the corresponding model prediction, yi,rep. For
example, if 95% or more of all the observations are within 95% posterior in-
tervals of the predictions yi,rep, then the model is judged to be reproducing
the observations satisfactorily.
The collection of predictive ordinates {p(yi|y[i]), i = 1, n} is equivalent
to the marginal likelihood p(y) when p(y) is proper, in that each uniquely
determines the other. A pseudo Bayes factor is obtained as a ratio of products
of leave one out cross-validation predictive densities (Vehtari and Lampinen,
2002) under models M1 and M2, namely,
PsBF(M1, M2) =
n

i=1
{p(yi|y[i], M1)/p(yi|y[i], M2)}.
In practical data analysis, one typically uses logs of CPO estimates and
totals the log(CPO) to derive log pseudo marginal likelihoods and log pseudo
Bayes factors (Sinha et al., 1999, 588).
Monte Carlo estimates of conditional predictive ordinates, p(yi|y[i]), may
be obtained without actually omitting cases, so formal cross validation based
on n separate estimations (the ﬁrst omitting case 1, the second omitting case 2,
etc.) may be approximated by using a single estimation run. For parameter
samples {θ(1), . . . , θ(R)} from an MCMC chain, an estimator for the CPO,
p(yi|y[i]), is
1
p(yi|y[i]) = 1
R
R

r=1
1
p(yi|θ(r)),
namely, the harmonic mean of the likelihoods for each observation (Aslanidou
et al., 1998; Silva et al., 2006). In computing terms, an inverse likelihood
needs to be calculated for each case at each iteration, the posterior means
of these inverse likelihoods obtained, and the CPOs are the inverse of those

Model Fit, Comparison, and Checking
69
posterior mean inverse likelihoods. Denoting the inverse likelihoods as H(r)
i
=
(1/p(yi|θ(r))), one would in practice take minus the logarithms of the posterior
means of Hi, for example in a spreadsheet environment since small numbers
may be involved. The sum over all cases of these estimates of log(CPOi)
provides a simple estimate of the log pseudo marginal likelihood. In the turtle
data example, the ﬁxed eﬀects only model 1 has a PsBF of −151.8, while the
random eﬀects model 2 has a Pseudo Bayes Factor (PsBF) of −149.6 under
a Ga(0.1, 0.1) prior for τb, and under a Ga(1, 1) prior has a PsBF = −150.8.
So the pseudo Bayes factors tends to support the random eﬀects option.
Model ﬁt (and hence choice) may also be assessed by comparing samples
yrep from the posterior predictive density based on all observations, though
such procedures may be conservative since the presence of yi inﬂuences the
sampled yi,rep (Marshall and Spiegelhalter, 2003). Laud and Ibrahim (1995)
and Meyer and Laud (2002) propose model choice based on minimization of
the criterion,
C = E[c(yrep, y)|y] =
n

i=1
{var(yi,rep) + [yi −E(yi,rep)]2},
where for y continuous, c(yrep, y) is the predictive error sum of squares,
c(yrep, y) = (yrep −y)′(yrep −y).
The C measure can be obtained from the posterior means and variances of
sampled y(r)
i,rep or from the posterior average of n
i=1

y(r)
i,rep −yi
2. Carlin and
Louis (2000) and Buck and Sahu (2000) propose related model ﬁt criteria
appropriate to both metric and discrete outcomes.
Posterior predictive loss (PPL) model choice criteria allow varying trade-
oﬀs in the balance between bias in predictions and their precision (Gelfand
and Ghosh, 1998; Ibrahim et al., 2001). Thus, for k positive and y continuous,
one possible criterion has the form,
PPL(k) =
n

i=1
*
var(yi,rep) +

k
k + 1

[yi −E(yi,rep)]2
+
.
This criterion would be compared between models at selected values of k,
typical values being k = 0, k = 1, and k = 10, 000, where higher k values
put greater stress on accuracy in predictions and less on precision. One may
consider calibration of such measures, namely, expressing the uncertainty of C
or PPL in a variance measure (Ibrahim et al., 2001; Laud and Ibrahim, 1995).
De la Horra and Rodrıguez-Bernal (2005) suggest predictive model choice
based on measures of distance between the two densities that can potentially
be used for predicting future observations, namely, sampling densities and
posterior predictive densities.
To assess poorly ﬁtted cases, the CPO values may be scaled (dividing by
their maximum) and low values for particular observations (e.g., under 0.001)

70
Applied Bayesian Hierarchical Methods
will then show observations that the model does not reproduce eﬀectively
(Weiss, 1994). If there are no very small scaled CPOs then a relatively good
ﬁt of the model to all data points is suggested and is likely to be conﬁrmed by
other forms of predictive check. The ratio of extreme percentiles of the CPOs
is useful as an indicator of a good ﬁtting model, e.g., the ratio of the 99th to
the 1st percentile.
An improved estimate of the CPO may be obtained by weighted resampling
from p(θ|y) (Marshall and Spiegelhalter, 2003; Smith and Gelfand, 1992).
Samples θ(r) from p(θ|y) can be converted (approximately) to samples from
p(θ|y[i]) by resampling the θ(r) with weights,
w(r)
i
= G

yi|θ(r),
R

r=1
G

yi|θ(r)
,
where,
G

yi|θ(r)
= 1
-
p

yi|θ(r)
,
is the inverse likelihood of case i at iteration r. Using the resulting resampled
values, ˜θ(r), corresponding predictions, ˜yrep, can be obtained, which are a
sample from p(yi|y[i]).
2.5.2
Posterior predictive model checks
A range of model checks can also be applied using samples from the posterior
predictive density without actual case omission. To assess predictive perfor-
mance, samples of replicate data yrep from,
p(yrep|y) =

p(yrep|θ)p(θ|y)dθ,
may be taken, and checks made against the data, for example, whether the
actual observations y are within 95% credible intervals of yrep. Formally, such
samples are obtained by the method of composition (Chib, 2008), whereby if
θ(r) is a draw from p(θ|y), then y(r)
rep drawn from p(yrep|θ(r)) is a draw from
p(yrep|y). In a satisfactory model, namely, one that adequately reproduces
the data being modeled, predictive concordance (accurate reproduction of the
actual data by replicate data) is at least 95% (Gelfand, 1996, 158).
Other comparisons of actual and predicted data can be made, for example
by a chi-square comparison (Gosonuiou et al., 2006). Johnson (2004) proposes
a Bayesian chi-square approach based on partitioning the cumulative distri-
bution into K bins, usually of equal probability. Thus, one chooses quantiles,
0 ≡a0 < a1 < · · · < aK−1 < aK ≡1,
with corresponding bin probabilities
pk = ak −ak−1,
k = 1, . . . , K.

Model Fit, Comparison, and Checking
71
Then using model means µi for subject i ∈(1, . . . , n), one obtains the implied
cumulative density, qi, say ak∗−1 < qi < ak∗, and allocates the ﬁtted point
to a bin randomly chosen from bins 1, . . . , k∗. For example, under a Poisson
likelihood, suppose there are K = 5 equally probable intervals, with pk = 0.2.
If µi = 1.4, the probability assigned to an observation yi = 1 by the cu-
mulative density function falls in the interval (0.247, 0.592), which straddles
bins 2 and 3. To allocate a bin, a U(0.247, 0.592) variable is sampled, and
the predicted bin is 2 or 3 according to whether the sampled uniform variable
falls within (0.247, 0.4) or (0.4, 0.592). The totals so obtained accumulating
over all subjects deﬁne predicted counts, mk(˜θ), which are compared (at each
MCMC iteration) to actual counts, npk, as in formula (3) in Johnson (2004).
This provides the Bayesian chi-square criterion,
RB(˜θ) =
K

k=1
[mk(˜θ) −npk]2
npk
,
where RB(˜θ) is asymptotically χ2
K−1, regardless of the parameter dimension
of the model being ﬁtted8. One can assess the posterior probability that RB(˜θ)
exceeds the 95th percentile of the χ2
K−1 density. Poor ﬁt will show in proba-
bilities considerably exceeding 0.05.
Analogs of classical signiﬁcance tests are obtained using the posterior
predictive p value (Kato and Hoijtink, 2004). This was originally deﬁned
(Meng, 1994) as the probability that a test statistic, T(yrep), of future ob-
servations; yrep, is larger than or equal to the observed value of T(y), given
the adopted model M, the response data y and any ancilliary data x,
ppost = Pr[T(yrep, x) ≥T(y, x)|y, x, M],
where x would typically be predictors measured without error. The probability
is calculated over the posterior predictive distribution of yrep conditional on M
and x. By contrast, the classical p-test integrates over y, as in,
pc = Pr[T(yrep, x) ≥T(y, x)|x, M].
The formulation of Meng (1994) is extended by Gelman et al. (1996) to
apply to discrepancy criteria, D(y, θ), based on data and parameters, as well
as to observation-based functions T(y). So,
ppost = Pr[D(yrep, x, θ) ≥D(y, x, θ)|y, x, M],
where the probability is taken over the joint posterior distribution of yrep and
θ given M and x. In estimating the corresponding ppost, the discrepancy is
calculated at each MCMC iteration. This is done both for the observations,
giving a value D(y, x, θ(r)), and for the replicate data, y(r)
rep, sampled from
p(y(r)
rep|θ(r), x), resulting in a value D(y(r)
rep, x, θ(r)) for each sampled parame-
ter θ(r). The proportion of samples where D(y(r)
rep, x, θ(r)) exceeds D(y, x, θ(r))

72
Applied Bayesian Hierarchical Methods
is then the Monte Carlo estimate of ppost. For example, Kato and Hoijtink
(2004) show good performance of ppost using both statistics T and discrepan-
cies D in a normal multilevel model context with subjects i = 1, . . . , mj in
clusters j = 1, . . . , J,
yij = b1j + b2jxij + uij,
where uij ∽N(0, σ2
j). The hypotheses considered (i.e., in the form of reduced
models) are bkj = βk and σ2
j = σ2.
Posterior predictive checks may be used to assess model assumptions. For
instance, in multilevel and general linear mixed models, assumptions of nor-
mality regarding random eﬀects are often made by default, and a posterior
check against such assumptions is sensible. A number of classical tests have
been proposed, such as the Shapiro–Wilk W statistic (Royston, 1993) and
the Jarque–Bera test (Bera and Jarque, 1980). These statistics can be de-
rived at each iteration for actual and replicate data, and the comparison,
D(yrep, x, θ) ≥D(y, x, θ), applied over MCMC iterations to provide a poste-
rior predictive p value.
2.5.3
Mixed predictive checks
The posterior predictive check makes double use of the data and so may be
conservative as a test (Bayarri and Berger, 1999, 2000), since the observa-
tion yi has a strong inﬂuence on the replicate yi,rep. For example, Sinharay
and Stern (2003) show that posterior predictive checks may fail to detect de-
partures from normality in random eﬀects models. However, also in the context
of random eﬀects and hierarchical models, Marshall and Spiegelhalter (2003,
2007) mention a mixed predictive scheme, which uses a predictive prior distri-
bution, p(yi,rep|bi,rep, θ), for a new set of random eﬀects. The associated model
check is called a mixed predictive p test, whereas the (conservative) option of
sampling from p(yi,rep|bi, θ) results in what Marshall and Spiegelhalter (2007,
424) term full-data posterior predictive p values. Mixed predictive replicates
for each case seek to reduce dependence on the observation for that case,
as the replicate data is sampled conditional only on global hyperparameters.
Therefore, mixed predictive p values are expected to be less conservative than
posterior predictive p values.
Let b denote random eﬀects for cases i = 1, . . . , n, or for clusters j in
which individual cases are nested. To generate a replicate yi,rep for the ith
case under the mixed scheme involves sampling (θ, b) from the usual posterior
p(θ, b|y) conditional on all observations, but the sampled b are ignored and in-
stead replicate brep values taken. A fully cross-validatory method would require
that bi,rep be obtained by sampling from p(bi,rep|y[i]), or bj,rep sampled from
p(bj,rep|y[j]); in fact, Green et al. (2009) compare mixed predictive assessment
schemes with full cross-validation based on omitting single observations.
As full cross-validation is computationally demanding when using MCMC
methods, approximate cross-validatory procedures are proposed by Marshall

Model Fit, Comparison, and Checking
73
and Spiegelhalter (2007), in which the replicate random eﬀect is sampled from
p(bi,rep|y), followed by a step sampling yi,rep from p(yi,rep|bi,rep, θ). A discrep-
ancy measure T obs based on the observed data is then compared to its refer-
ence distribution,
p(T|y) =

p(T|b)pM(b|y)db,
where pM(b|y) =
	
p(b|θ)p(θ|y)dθ may be termed the “predictive prior” for b
(Marshall and Spiegelhalter, 2007, 413). This contrasts with more conservative
posterior predictive checks based on replicate sampling from p(yi,rep|bi, θ),
under which T obs is compared to the reference distribution,
p(T|y) =

p(T|b)p(b|y)dθ.
Marshall and Spiegelhalter (2003) conﬁrm that a mixed predictive pro-
cedure reduces the conservatism of posterior predictive checks in relatively
simple random eﬀects models, and is more eﬀective in reproducing p(yi|y[i])
than weighted importance sampling. However, this procedure may be inﬂu-
enced by the informativeness of the priors on the hyperparameters θ, and also
by the presence of multiple random eﬀects.
Marshall and Spiegelhalter (2007) also consider full cross-validatory mixed
predictive checks to assess conﬂict in evidence regarding random eﬀects b
between the likelihood and the second stage prior; see also Bayarri and
Castellanos (2007). Consider nested data {yij, i = 1, . . . , nj; j = 1, . . . , J}
with likelihood,
yij ∼N(bj, σ2),
and second stage prior on random cluster eﬀects,
bj ∼N(µ, τ2).
Under a cross-validatory approach the discrepancy measure T obs
j
for cluster
j would be based on the remaining data y[j] with cluster j excluded, and its
reference distribution is then,
p(T rep
j
|y[j]) =

p(T rep
j
|bj, σ2)p(bj|µ, τ2)p(σ2, τ2, µ|y[j])dbjdσ2dτ2dµ.
Marshall and Spiegelhalter (2007) also propose a conﬂict p test based on
comparing a predictive prior replicate, bj,rep|y[j], with a ﬁxed eﬀect estimate or
“likelihood replicate” bj,ﬁx for bj based only on the data. The latter is obtained
using a highly diﬀuse ﬁxed eﬀects prior on the bj, rather than a borrowing
strength hierarchical prior, for example bj ∼Be(1, 1) or bj ∼Be(0.5, 0.5).
Deﬁning,
bj,diﬀ= bj,rep −bj,ﬁx,

74
Applied Bayesian Hierarchical Methods
the conﬂict p value for cluster j is obtained as,
pj,conf = Pr(bj,diﬀ≤0|y).
This can be compared to a mixed predictive p value, based on sam-
pling yj,rep from a cross-validatory model using only the remaining cases
y[j] to estimate parameters, and then comparing yj,rep, or some function
T rep
j
= T(yj,rep), with yj,obs or with T obs
j
= T(yj,obs). Thus, depending on the
substantive application, one may deﬁne lower or upper tail mixed p values,
pj,mix = Pr

T rep
j
≤T obs
j
|y

,
or
pj,mix = Pr

T rep
j
≥T obs
j
|y

,
with the latter being relevant in (say) assessing outliers in hospital mortality
comparisons. If T(y) = y and y is a count, then a mid p value is relevant
instead with the upper tail test being,
pj,mix = Pr(yj,rep > yj,obs|y[j]) + 0.5Pr(yj,rep = yj,obs|y[j]).
Example 2.4. Regional Mortality in China
This
example
considers
predictive checks in a model for mortality contrasts between the 31 provinces
of China. Regional life table analysis often proceeds by using a ﬁxed ef-
fects model independently in each region, which takes no account of spatial
structure in mortality risk, and also does not model correlation in mortal-
ity between adjacent age groups. Here a random eﬀects model pools strength
over ages and regions. The analysis relates to deaths in 2000 in i = 1, . . . , n
Chinese provinces with n = 31, with deaths also diﬀerentiated by age x (for
X = 21 groups from 0 to 4, 5 to 9 through to 100+), by gender s, and by an
urban–rural subdivision r within each province (r = 1 for urban, r = 2 for
rural). Populations are from the 2000 China Census. Whereas a ﬁxed eﬀects
model involves 31 × 21 × 2 × 2 = 2604 parameters, the approach developed
here is expected to be more parsimonious while also reproducing the data
satisfactorily. A Bayesian approach enables stochastic variation in life table
parameters to be fully assessed (e.g., via posterior densities for province life
expectancies).
The deaths data, yrisx, collected in conjunction with the 2000 China Cen-
sus, are subject to undercounting. Bannister and Hill (2004) obtain correction
factors using the general growth balance method, and here these factors
are applied to correct for mortality under-recording. Speciﬁcally, popula-
tions at risk, Prisx, are reduced to account for deﬂation in the death record-
ing; the male mortality adjustment factor was 1.113, so recorded deaths are
retained as the response variables, but analyzed in relation to populations
scaled by 1/1.113=0.898; for females the adjustment factor is 1.181, so female

Model Fit, Comparison, and Checking
75
populations are scaled by 0.847. Due to relatively large death counts, the yrisx
are assumed to follow a negative binomial density, namely,
p(yrisx|ξrisx, α) =
Γ(α + yrisx)
Γ(α)Γ(yrisx + 1)

α
α + ξrisx
α 
ξrisx
α + ξrisx
yrisx
,
with means ξrisx. Equivalently, yrisx ∽Po(µrisx), with gamma means,
µrisx ∽G(α, α/ξrisx),
whereby E(µrisx) = ξrisx, Var(µrisx) = ξ2
risx/α, and,
Var(yrisx) = E[Var(yrisx|µrisx)] + Var[E(yrisx|µrisx)] = ξrisx + ξ2
risx/α.
A multiplicative model for mortality parameters, ξrisx, involves:
1. a population at risk (Prisx) oﬀset;
2. overall mortality level (ﬁxed eﬀect) parameters by gender s, κs;
3. parameters ηxs to represent age-sex mortality diﬀerentials and fol-
lowing a ﬁrst order random walk prior reﬂecting correlation in rates
between successive ages. These age parameters are taken to apply
uniformly across all provinces in line with the multiplicative model,
though in fact, regional variation in age eﬀects may be present in
the Chinese mortality data;
4. ﬁxed eﬀect parameters, γs, to represent a gender-speciﬁc rural mor-
tality diﬀerential and present only in the model for ξ2isx;
5. division eﬀects, λis, reﬂecting unmeasured risks likely to be spa-
tially patterned (e.g., diﬀerences in environment, health care). They
are assigned a multivariate conditional autoregressive prior (see
Chapters 4 and 7) with Wishart distributed precision matrix.
Then the multiplicative model under (1)–(5) is
log(ξ1isx) = log(P1isx) + κs + ηxs + λis,
log(ξ2isx) = log(P2isx) + κs + γs + ηxs + λis,
with model checks based on full data posterior replicates and on mixed predic-
tions using replicate samples from the random eﬀects {ηxs, λis}. The analysis9
also includes derivation of Monte Carlo estimates of log(CPOrisx) statistics.
The second half of a two chain run of 3000 iterations shows that just
over 5% of the cases are not included in the 95% intervals of full data
posterior predictive data, yrep,risx. These condition on random eﬀects sam-
pled from the posterior rather than on replicate random eﬀects. Using this
potentially conservative method suggests that in overall terms the model’s
predictions seem broadly concordant with the data. However, examination of

76
Applied Bayesian Hierarchical Methods
0
10
20
30
40
50
60
70
80
90
100
0–4
5–9
10–14
15–19
20–24
25–29
30–34
35–39
40–44
45–49
50–54
55–59
60–64
65–69
70–74
75–79
80–84
85–89
90–94
95–99
100+
% of counts y within 95% credible intervals of yrep
% of mixed predictions in tails
FIGURE 2.2
Predictive discrepancies by age band.
model discrepancies at the age group level shows a relatively high number of
death counts for ages 0–4 and the oldest ages are not predicted satisfacto-
rily. There are 2604/21 = 124 observations in each age group, and 39 of the
124 death counts in the age group 0–4 are not satisfactorily predicted (see
Figure 2.2). The log(CPO) statistics also show deﬁcient ﬁt for the youngest
age group. The mixed predictions are assessed by sampling {ηrep, λrep} and
{yrep|ηrep, λrep, κ, γ} and deriving p values
Pr[yh,rep < yh|y) + 0.5Pr[yh,rep = yh|y),
where h = (r, i, s, x). These mixed p tests show a broadly similar pattern (also
in Figure 2.2), with high probabilities at the oldest ages, though they also
highlight discrepancies in the model for young adult mortality. An alternative
approach is therefore indicated, such as to allow spatially varying age eﬀects,
for at least some age groups.
2.6
Estimating Posterior Model Probabilities
A Monte Carlo method for estimating posterior model probabilities based on
independent MCMC sampling of two or more diﬀerent models is presented
in Congdon (2007a), building on work by Carlin and Chib (1995), and Scott

Model Fit, Comparison, and Checking
77
(2002). This method allows iteration-speciﬁc model averaging as compared
to approaches that undertake averaging over posterior parameter densities.
Let θ = (θ1, . . . , θK) be parameters for models (1, . . . , K), with dimension
(d1, . . . , dK), and deﬁne a model indicator m ∈(1, . . . , K). Conditional on the
model m = j, the parameter vector, θj, deﬁnes the likelihood for y, and y is
independent of parameters in other models, θk, k ̸= j. As above, the marginal
likelihood given m = j is (Carlin and Chib, 1995),
p(y|m = j) =

p(y|θ, m = j)p(θ|m = j)dθ
=

p(y|θj, m = j)p(θ|m = j)dθj.
The term p(θ|m = j) includes an “own model” prior p(θj|m = j), and K−1
“cross-model” priors p(θk|m = j, k ̸= j); the latter are termed pseudo priors
by Carlin and Chib (1995). Proper densities are required for the cross-model
priors, p(θk|m = j, k ̸= j), in order that p(θ|m = j) integrate to 1. With sam-
ples from the own model prior, cross-model priors, and posterior densities,
p(θj|y, m = j), of all K models, one may estimate model weights at each iter-
ation and so form model averaged parameters at each iteration. The posterior
average of the weights may be used to derive posterior probabilities for each
model.
From the posterior model probability formula,
p(m = j|y) =

p(m = j, θ|y)dθ =

p(m = j|y, θ)p(θ|y)dθ,
it is apparent that a Monte Carlo estimate of Pr(m = j|y) over T samples is
provided by,
¯wj =
T

t=1
p

m = j|y, θ(t)
/T,
where

θ(t) = (θ(t)
1 , . . . , θ(t)
2 , . . . , θ(t)
K ), t = 1, T

are samples of parameters
from the K posterior densities. The weights for model j at iteration t are,
w(t)
j
= p(m = j|y, θ(t)) = p(m = j, y, θ(t))
p(y, θ(t))
= p(y|m = j, θ(t))p(θ(t)|m = j)p(m = j)
p(y, θ(t))
.
The numerator in the preceding equation contains the term p(θ(t)|m = j)
involving a mix of own model and cross-model priors, namely,
p(θ|m = j) = p(θ1|m = j)p(θ2|m = j) · · · p(θj|m = j) · · · p(θK|m = j).

78
Applied Bayesian Hierarchical Methods
The choice for the cross-model prior is arbitrary though a proper prior is
preferred (Carlin and Chib, 1995). The simpliﬁcation,
p(θk|m = j) = gk
(all j when k ̸= j),
is therefore admissible, with gk a proper density. So,
p(θk|m = 1) = · · · = p(θk|m = k −1) = p(θk|m = k + 1)
= · · · = p(θk|m = K) = gk,
and there are K cross-model priors {g1, . . . , gK}. For example, one may set
gk to be an estimate of p(θk|m = k, y), namely, the “own model” posterior
density of θk given y and m = k.
One then has,
p(θ|m = j) = p(θj|m = j)
K

k̸=j
p(θk|m = j)
= p(θj|m = j)g1g2 · · · gj−1gj+1 · · · gK.
The model weights at each iteration become,
w(t)
j
=
p

y|m = j, θ(t)
j

p

θ(t)
j |m = j
 
h̸=j g(t)
h
 
p(m = j)
p(y, θ(t))
,
where the denominator is,
p

y, θ(t)
=
K

k=1
p

y, θ(t), m = k

=
K

k=1


p

y|θ(t), m = k

p

θ(t)
k |m = k



h̸=k
g(t)
h

p(m = k)



=
K

k=1
p

y|θ(t)
k , m = k

p

θ(t)
k |m = k



h̸=k
g(t)
h

p(m = k).
Then
w(t)
j
=
p(y|m = j, θ(t)
j )p(θ(t)
j |m = j)[Πh̸=jg(t)
h ]p(m = j)
K
k=1 p(y|θ(t)
k , m = k)p(θ(t)
k |m = k)[Πh̸=kg(t)
h ]p(m = k)
,
and dividing through by the product of the K cross-model priors (g1g2 · · · gK)
gives
w(t)
j
=
4 p(y|m=j,θ(t)
j
)p(θ(t)
j
|m=j)p(m=j)
g(t)
j
5
K
k=1
4 p(y|θ(t)
k ,m=k)p(θ(t)
k |m=k)p(m=k)
g(t)
k
5.

Model Fit, Comparison, and Checking
79
For the common case when K = 2, one has,
w(t)
1
=
p(y|θ(t)
k ,m=1)p(θ(t)
k |m=1)p(m=1)
g(t)
1
p(y|θ(t)
k ,m=1)p(θ(t)
k |m=1)p(m=1)
g(t)
1
+ p(y|θ(t)
k ,m=2)p(θ(t)
k |m=2)p(m=2)
g(t)
2
.
(2.1)
Letting H(t)
j
=

P

y|m = j, θ(t)
j

P

θ(t)
j |m = j

/g(t)
j

, one has,
w(t)
j
=
H(t)
j P(m = j)
K
k=1[H(t)
k P(m = k)]
.
In the H(t)
j
term, gj have a role parallel to that of an importance function
(Geweke, 1989), and so densities, gj, which are heavy tailed relative to the
posterior may be preferred in order to minimize the variance of the components
H(t)
j
of w(t)
j
(Yuan and Druzdzel, 2005). This might mean, for example, using a
heavy tail modiﬁcation Student gj = t(mj, s2
j, ν) with low degrees of freedom ν,
even if the own model posterior density for θj with mean and variance (mj, s2
j)
is approximately normal (Congdon, 2007a).
This approach to posterior model probability estimation avoids problems
involved in tuning or “jump” proposal densities to ensure that models are
visited suﬃciently often (Friel and Pettitt, 2008; Green and O’Hagan, 1998).
Moreover, model averaging is on the basis of continuous quantities, namely,
the w(t)
k
obtained for all models and so is more eﬃcient. It is convenient to
work in the log scale and deﬁne the quantities,
q(t)
k
= log


p

y|θ(t)
k , m = k

p

θ(t)
k |m = k



a̸=k
ga

p(m = k)


,
calculate deviations ∆q(t)
k
= q(t)
k
−maxk(q(t)
k ), with w(t)
k
then obtained by
exponentiating,
w(t)
k
=
exp

∆q(t)
k


k exp

∆q(t)
k
.
As a toy example∗, consider comparing two beta priors, π ∼Be(α, β), for
a binomial probability, when the data are x = 1 sucesses in n = 10 trials.
Two models are compared, diﬀering in the priors adopted for the unknown
probability, namely, a diﬀuse prior,
M1 : x ∼Bin(n, π); π ∼Be(1, 1),
∗This example is based on discussion with Samu M¨antyniemi [samu.mantyniemi@
helsinki.ﬁ].

80
Applied Bayesian Hierarchical Methods
and an informative prior,
M2 : x ∼Bin(n, π); π ∼Be(30, 30).
This choice can be solved analytically to give P(M1|x) = 0.8634. In partic-
ular, integrating π out from the binomial-beta mixture model, x ∽Bin(n, π),
π ∽Be(α, β), gives a beta-binomial distribution, x ∼Beta −Bin(n, α, β), with
density,
p(x|n, α, β) = Be(x + α, n −x + β)
Be(α, β)
n!
(n −x!)x!,
which can be evaluated at p(x|10, 1, 1) and p(x|10, 30, 30).
To apply the method in Congdon (2007a), as in Equation 2.1 particularly,
the posterior densities of π under the two models (which may be taken to
provide cross-model priors g1 and g2) are obtainable analytically as Be(2, 10)
and Be(31, 39), because π|x ∼Be(α+x; β+n−x). Alternatively, an initial run
provides posterior means (sd) for π, denoted mj(sj), under the two models of
0.1656 (0.1025), and 0.4427 (0.0586), respectively. One may then use the fact
that beta density, Be(α, β), parameters α and β are obtainable as,
α = −m(m2 −m + s2)/s2, β = (m −1)(m2 −m + s2)/s2.
Using the latter results provides beta cross-model priors with parameters
(2, 10.1) and (31.3, 39.5). A subsequent MCMC run of 100,000 iterations
assumes equal prior model probabilities Pr(M1) = Pr(M2) = 0.5. This run10
obtains likelihoods, prior ordinates, and importance sample ordinates at each
iteration, giving iteration-speciﬁc weights, and a posterior mean weight for
model 1 equal to the analytic probability to four signiﬁcant places, namely
0.8634, with a Monte Carlo standard error of 7.5E-6.
2.6.1
Random eﬀects models
For highly parameterized random eﬀect models, or models with multiple ran-
dom eﬀects, the same principle applies except that posterior densities are
usually not available analytically. There is also an issue of “focus” to consider
for such models (Spiegelhalter et al., 2002). Model selection for random eﬀects
models may be based on integrated likelihoods, with random eﬀects integrated
out analytically or numerically—see Congdon (2007a). However, an alterna-
tive focus is to retain random eﬀects b(t)
j
in model j in an expanded parameter
collection (Spiegelhalter et al., 2002). Then the numerator in w(t)
j
becomes,
p

y|m = j, b(t)
j , θ(t)
j

p

b(t)
j |θ(t)
j ,m = j

p

θ(t)
j |m = j



h̸=j
g(t)
h

p(m = j).
Additionally the cross-model prior gh becomes p(bh|θh,m = j)p(θh|m = j).
Choice of gh is again arbitrary, but a reasonable default is an estimate of the

Model Fit, Comparison, and Checking
81
own model posterior density for the parameters, namely,
p(bh|θh, m = h, y)p(θh|m = h, y),
the density of {bh, θh} given y and m = h.
Example 2.5. Turtle Mortality
This example reworks the turtle mor-
tality model comparison, with a lognormal option for the precisions τb in the
random eﬀects model 2, namely, τb ∼LN(0, 10), but with N(0, 10) priors
retained on the ﬁxed eﬀects {β1, β2}. According to the method of Friel and
Pettitt (2008), this model has a log marginal likelihood of −155.03 compared
to −155.29 for the ﬁxed eﬀects model 1 (from iterations 5,000 to 50,000 of
single chain runs using OpenBUGS version 2.2). This leads to respective pos-
terior probabilities of 0.443 (model 1) and 0.557 (model 2)11.
To apply the method of Congdon (2007a), separate exploratory runs of
models 1 and 2 are taken to provide estimates of the components of the
cross-model priors g1 and g2, namely, 34 parameters in model 2, and two
in model 1. For the random eﬀects model 2, the cross-model prior compo-
nent for τb, namely, log(τb), is monitored in this exploratory run and log(τb)
is found to have a posterior mean and standard deviation of 2.8 and 1.27,
respectively. This provides parameters for a lognormal density on τb in the
cross-model prior g2. Normal densities for the random eﬀects bj and regres-
sion parameters {β1, β2} are assumed for the remaining components of g2, and
in g1 also. From iterations 5000 to 50,000 of a single chain run, respective pos-
terior probabilities12 on the two models are obtained. Like those derived from
the marginal likelihood estimates, these are inconclusive for model choice, but
very similar numerically, namely, 0.57 for the hierarchical model 2 and 0.43
for the simpler model.
Appendix: Computational Notes
1. A WinBUGS code is based on a stacked rather than nested form of input
data, so that h = 1, . . . , m1 for cases in the 1st cluster, h = m1 +1, . . . , m2 for
cases in the 2nd cluster, and so on. A code with each temperature point, qs,
taken singly uses synthetic data wh = 1 to deﬁne a nonstandard likelihood
and adopts the device suggested by Barry (2006). Thus,
model {for (h in 1:n) {w[h] <- 1; L.tem[h] <- pow(L[h],q.s)
w[h]∼dunif(a1[h],b1[h]); a1[h] <- -1/L.tem[h]; b1[h] <- 1/L.tem[h]
LL[h] <- log(L[h]); pi[h] <- phi(beta[1]+beta[2]*x[h]+b[clutch[h]])
log(L[h]) <- y[h]*log(pi[h])+(1-y[h])*log(1-pi[h])}
for (j in 1:p) { beta[j]∼dnorm(0,0.1)}
for (j in 1:J) { b[j] ∼dnorm(0,tau)}
tau ∼dgamma(1,1); tLL <- sum(LL[1:n])}.

82
Applied Bayesian Hierarchical Methods
The marginal likelihood is obtained by piecing together the separate posterior
likelihood estimates at each grid point (tLL in the above code, obtained with
q.s=a4
s) according to their individual Monte Carlo variances.
Alternatively an inclusive code spanning all T + 1 cutpoints is as follows
model {for (h in 1:n) {for (s in 1:T+1) {w[h,s] <- 1; L.tem[h,s] <- pow
(L[h,s],q[s])
w[h,s] ∼dunif(a1[h,s],b1[h,s])
a1[h,s] <- -1/L.tem[h,s]; b1[h,s] <- 1/L.tem[h,s]
LL[h,s] <- log(L[h,s])
pi[h,s] <- phi(beta[1,s]+beta[2,s]*x[h]+b[clutch[h],s])
log(L[h,s]) <- y[h]*log(pi[h,s])+(1-y[h])*log(1-pi[h,s])}}
for (s in 1:T+1) { for (j in 1:p) { beta[j,s] ∼dnorm(0,0.1)}
for (j in 1:J) { b[j,s] ∼dnorm(0,tau.b[s])}
tau.b[s] ∼dgamma(1,1); q[s] <- pow(a[s],4)
tLL[s] <- sum(LL[1:n,s]) }
a[1] <- 0.00001; for (s in 1:T) {a[s+1] <- s/T}
for (s in 1:T) {mc[s] <- (q[s+1]-q[s])*(tLL[s+1]+tLL[s])*0.5 }
logML <- sum(mc[])}
where the tLL[1 : T] correspond to Eθk|y,tsp(y|θk).
2. Slightly diﬀerent results for the posterior mean log marginal likelihood
are obtained using WinBUGS14 and OpenBUGS. The mean of −155.53 for
the random eﬀects model is obtained using WinBUGS14.
3. The four relevant series are monitored in the following WinBUGS code
and then input to a matlab program, which is also listed. Thus, the random
eﬀects model code in WinBUGS is
model {for (h in 1:n) { y[h] ∼dbern(pi[h]); pi[h] <- phi(nu[h])
nu[h] <- beta[1] + beta[2]*x[h] + b[Clutch[h]]
nu.g[h] <- beta.g[1] + beta.g[2]*x[h] + b.g[Clutch[h]]
# log-likelihoods, posterior and importance sampled parameters
LL[h] <- y[h]*log(phi(nu[h])) + (1-y[h])*log(1-phi(nu[h]))
LL.g[h] <- y[h]*log(phi(nu.g[h])) + (1-y[h])*log(1-phi(nu.g[h]))}
# quantities for calculating optimal function
log.pstar <- sum(LL[])+sum(pr[]); log.imp <- sum(imp[])
log.pstar.g <- sum(LL.g[])+sum(pr.g[]); log.imp.g <- sum(imp.g[])
# matlab inputs
mon[1] <- log.pstar;
mon[2] <- log.imp;
mon[3] <- log.pstar.g;
mon[4] <- log.imp.g;
# sample beta[1:p] from posterior and imp densities, and obtain
# prior and importance ordinates for both samples
for (j in 1:p) {beta[j] ∼dnorm(M[j],P[j]);
beta.g[j] ∼dnorm(beta.m[j],beta.pr[j]); beta.pr[j] <- 1/pow(beta.se[j],2)
pr.g[j] <- 0.5*log(P[j]/6.28)-0.5*P[j]*pow(beta.g[j]-M[j],2)
imp.g[j] <- 0.5*log(beta.pr[j]/6.28)

Model Fit, Comparison, and Checking
83
-0.5*beta.pr[j]*pow(beta.g[j]-beta.m[j],2)
pr[j] <- 0.5*log(P[j]/6.28)-0.5*P[j]*pow(beta[j]-M[j],2)
imp[j] <- 0.5*log(beta.pr[j]/6.28)-0.5*beta.pr[j]*pow(beta[j]-beta.m[j],2)}
# sample b[1:J] from posterior and imp densities
for (j in 1:J) {b[j] ∼dnorm(0,tau); b.g[j] ∼dnorm(b.m[j],b.pr[j])
b.pr[j] <- 1/(b.sd[j]*b.sd[j])
pr.g[p+j] <- 0.5*log(tau/6.28)-0.5*tau*b.g[j]*b.g[j]
imp.g[p+j] <- 0.5*log(b.pr[j]/6.28)-0.5*b.pr[j]*pow(b.g[j]-b.m[j],2)
pr[p+j] <- 0.5*log(tau/6.28)-0.5*tau*b[j]*b[j]
imp[p+j] <- 0.5*log(b.pr[j]/6.28)-0.5*b.pr[j]*pow(b[j]-b.m[j],2)}
# importance and posterior samples of precision
tau.g ∼dgamma(r.m,s.m); tau ∼dgamma(r,s)
pr.g[p+J+1] <- (r-1)* log(tau.g)-s*tau.g +r*log(s.m)-loggam(r.m)
imp.g[p+J+1] <- (r.m-1)*log(tau.g)-s.m*tau.g+r.m*log(s.m)-loggam(r.m)
pr[p+J+1] <- (r-1)*log(tau) - s*tau + r*log(s) - loggam(r)
imp[p+J+1] <- (r.m-1)*log(tau) - s.m*tau+ r.m*log(s.m) - loggam(r.m)}
The subsequent matlab function code carries out Nrecurse recursions to ob-
tain the Meng-Wong optimal estimator for R=S samples from posterior and
importance densities. It also obtains the simple importance sample estimator.
function [logML]=MLrecurse(Nrecurse,R,log pstar, log imp, log pstar g,
log imp g)
% initial estimate of Marg LKD
r(1) = 1;
for t=1:R W1(t) = exp(log pstar(t)-log imp(t));
W2(t) = exp(log pstar g(t)-log imp g(t));
ISratio(t)=exp(log pstar g(t)-log imp g(t));
end
logML IS=log(mean(ISratio(1:R)))
% revised estimates of optimal marg LKD estimator
for j=2:Nrecurse A(j)=0; B(j)=0;
for t=1:R A(j)=A(j)+W2(t)/(0.5*W2(t)+0.5*r(j-1));
B(j)=B(j)+1/(0.5*W1(t)+0.5*r(j-1));
end
% revised estimate of marg LKD and log ML at recursion j
r(j) = A(j)/B(j); logML= log(r(j));
end
4. The WinBUGS coding of the random eﬀects option (model 2) is again based
on a stacked rather than nested form of input data, so that h = 1, . . . , m1 for
cases in the 1st cluster, h = m1 + 1, . . . , m2 for cases in the 2nd cluster, and
so on. Thus,
model {for (h in 1:n) {y[h]∽dbern(pi[h]);
pi[i] <- phi(beta[1] + beta[2]*x[h] + b[Clutch[h]])
# log-likelihood
LL[h] <- y[i]*log(pi[h]) + (1-y[i])*log(1-pi[h])

84
Applied Bayesian Hierarchical Methods
# CPO estimate is inverse of posterior mean of g[h] (section 2.5)
g[h] <- 1/exp(LL[h])}
# deviance node
Dv <- -2*sum(LL[])
for (j in 1:p) {beta[j] ∼dnorm(M[j],P[j])}
# alternative prior on random eﬀects precision/variance
tau∽dgamma(r,s); sig2 <- 1/tau
# sig2∽dunif(r,s); tau <- 1/sig2
for (j in 1:J) { b[j] ∼dnorm(0,tau.b); p.sig[j] <- step(b[j])}}
5. This is achieved with the WinBUGS code (for stacked data)
model {for (i in 1:n) { y[i] ∼dbern(pi[i]);
pi[i] <- phi(-2.9 + 0.4*x[i] + b[Clutch[i]])}
tau.b <- 1/sig2b
for (j in 1:J) { b[j]∼dnorm(0,tau.b)}}
with the input data containing the preset σ2
b, together with clutch and predic-
tor values, but not the actually observed y values. Instead, simulated yij are
obtained by using the “gen inits” and “info/node” commands.
6. In Example 2.3, the WinBUGS code uses normal priors on log(σ2
bj ), equiv-
alent to lognormal priors on σ2
bj . Additionally, the code assumes y in stacked
form indexed by patient and reading, so that
model {for (i in 1:1092) {y[i] ∼dnorm(mu[pat[i],rdg[i]],tau.u) }
for (j in 1:N) {for (q in 1:q) {b[q,j] ∼dnorm(0,tau.b[q])}
for (t in 1:T) {mu[j,t]<- beta[1]+b[1,j]+(beta[2]+b[2,j])*Bs[j] + eta[Tr[j]]}}
# variance component selection
for (q in 1:2) {J[q] ∼dbern(0.5); sig2b[q] <- exp(logsig2b[q])
sigb[q] <- sqrt(1/tau.b[q])}
tau.b[1] <- 1000*(1-J[1])+J[1]/sig2b[1]
tau.b[2] <- 10000*(1-J[2])+J[2]/sig2b[2]
logsig2b[1]∼dnorm(-0.35,0.0035); logsig2b[2]∼dnorm(-4.8,0.4)
# other priors
for (q in 1:Q) {beta[q] ∼dnorm(M.beta[q],T.beta[q])}
tau.u ∼dgamma(1,0.001); eta[1] <- 0; for (k in 2:3) {eta[k] ∼dnorm
(0,0.001)}}
7. The distinctive code elements governing the random eﬀects, and their re-
tention or otherwise under a selection mechanism, are
for (i in 1:N) {for (j in 1:Q){z[i,j] ∼dnorm(0,1)}
b[1,i] <- J[1,1]*C[1,1]*z[i,1];
b[2,i] <- J[2,1]*C[2,1]*z[i,1]+J[2,2]*C[2,2]*z[i,2]}
Retain[1] <- J[1,1]; Retain[2] <- max(equals(J[2,1],1),equals(J[2,2],1))
C[1,1] ∼dexp(1);C[1,2] <- 0; J[1,2] <- 0
C[2,1] ∼dnorm(0,1); C[2,2] ∼dexp(10)

Model Fit, Comparison, and Checking
85
for (j in 1:2) { sd.b[j] <- sqrt(Sig.b[j,j]); for (k in 1:2) {Csamp[j,k] <-
J[j,k]*C[j,k]
Ctran[j,k] <- Csamp[k,j]; Sig.b[j,k] <- inprod(Csamp[j,], Ctran[,k])}}
Qr <- Q*(Q+1)/2; aJ <- T.J+1; bJ <- Qr-T.J+1;
T.J <- sum(tJ[]); p.J∼dbeta(aJ,bJ)
for (j in 1:Q) { tJ[j] <- sum(J[j,1:j]); for (k in 1:j) {J[j,k] ∼dbern(p.J)}}
8. The Bayesian chi-square method is illustrated using model 5 for the Scot-
tish lip cancer incidence, also considered in Johnson (2004, 2374–76). Thus,
with Ei denoting expected incidence counts,
yi ∽Po(Eiρi)
where ρi are modeled as diﬀuse ﬁxed eﬀects. The code is as follows:
model { for (i in 1:n) {y[i] ∼dpois(mu[i]);
log(mu[i]) <- log(E[i]) + b[i]; b[i] ∼dnorm(0,0.001)
# Poisson probs (up to maximum count 50), ym[i]=y[i]-1 unless y=0
for (j in 1:51) {cdf[i,j] <- exp(-mu[i])*pow(mu[i],j-1)/exp(logfact(j-1))
*step(y[i]-j+1)}
for (j in 1:51) {cdfm[i,j] <- exp(-mu[i])*pow(mu[i],j-1)/exp(logfact(j-1))
*step(ym[i]-j+1)}
# cdf probs for y[i] and (y[i]-1)
t[i] <- sum(cdf[i,1:51]); tm[i] <- sum(cdfm[i,1:51])
# lower limit of interval from which bin randomly chosen
s[i] <- (1-equals(y[i],0))*tm[i]
u[i] ∼dunif(0,1); a[i] <- s[i]+u[i]*(t[i]-s[i])
ybin[i,1] <- step(0.2-a[i]); ybin[i,5] <- step(a[i]-0.8)
ybin[i,2] <- step(a[i]-0.2)*step(0.4-a[i])
ybin[i,3] <- step(a[i]-0.4)*step(0.6-a[i])
ybin[i,4] <- step(a[i]-0.6)*step(0.8-a[i])}
for (k in 1:K) {mhat[k] <- sum(ybin[,k]); m[k] <- n*p[k]
r.B[k] <- pow(mhat[k]-m[k],2)/m[k]}
# compare R.B with 95th quantile of the chi2 distribution for K-1 df
R.B <- sum(r.B[]); P <- step(R.B-9.49)}
From iterations 5–100 thousand of a single chain run the probability that RB
exceeds the 95% point of a χ2
4 is 0.157 and the posterior means of the number
(mhat[] in the code) of the n = 56 counts assigned to the ﬁve bins are (8.6,
9.9, 10.9, 12.1, 14.5)
9. The WinBUGS code for Example 2.4 is
model { for (i in 1:n) { for (s in 1:2) { for (x in 1:X) {
for (r in 1:2) {y[r,i,s,x] ∼dnegbin(pi[r,i,s,x],alp)
yrep[r,i,s,x] ∼dnegbin(pi[r,i,s,x],alp)
yrep.mx[r,i,s,x] ∼dnegbin(pi.rep[r,i,s,x],alp)
pi[r,i,s,x] <- alp/(alp+xi[r,i,s,x])
pi.rep[r,i,s,x] <- alp/(alp+xi.rep[r,i,s,x])

86
Applied Bayesian Hierarchical Methods
d.extreme[r,i,s,x] <- step(y[r,i,s,x]-yrep.mx[r,i,s,x]-0.001)
+0.5*equals(y[r,i,s,x],yrep.mx[r,i,s,x])
log(xi[r,i,s,x]) <- log(P[r,i,s,x])+gm[r,s]+eta[s,x]+lam[s,i]
log(xi.rep[r,i,s,x]) <- log(P[r,i,s,x])+gm[r,s]+eta.rep[s,x]+lam.rep[s,i]
LL[r,i,s,x] <- loggam(a1[r,i,s,x])-logfact(y[r,i,s,x])-loggam(alp)
+alp*log(pi[r,i,s,x])+y[r,i,s,x]*log(pi.m[r,i,s,x])
# log(CPO) are minus log(posterior mean G)
G[r,i,s,x] <- 1/exp(LL[r,i,s,x])
a1[r,i,s,x] <- y[r,i,s,x]+alp; pi.m[r,i,s,x] <- 1-pi[r,i,s,x]}}}}
for (j in 1:2) { for (k in 1:2) {gm[j,k]∼dnorm(-5,0.001)}}
alp∼dunif(0,1000);
# age-sex RW component
w[1] <- 1;
adj[1] <- 2;
num[1] <- 1
w[(X-2)*2 + 2] <- 1;
adj[(X-2)*2 + 2] <- X-1;
num[X] <- 1
for (x in 2:X-1) {w[2+(x-2)*2] <- 1; adj[2+(x-2)*2] <- x-1
w[3+(x-2)*2] <- 1;adj[3+(x-2)*2] <- x+1;num[x] <- 2}
for (j in 1:2) {tau[j] ∼dgamma(1,0.001)
eta[j,1:X] ∼car.normal(adj[],w[],num[],tau[j])
eta.rep[j,1:X] ∼car.normal(adj[],w[],num[],tau[j])}
# spatial component
lam[1:2,1:n] ∼mv.car(mapnei[], wnei[], numnei[], omeg.lam[,])
lam.rep[1:2,1:n] ∼mv.car(mapnei[], wnei[], numnei[], omeg.lam[,])
omeg.lam[1:2, 1:2] ∼dwish(Q[ , ], 2)
Sig2.lam[1:2,1:2] <- inverse(omeg.lam[,])
corr.lam <- Sig2.lam[1,2]/sqrt(Sig2.lam[1,1]*Sig2.lam[2,2])
for (i in 1 : Nnei) { wnei[i] <- 1}}
10. The code for the beta-binomial toy example, with the mean of w[1:2]
being the relevant output, and with the same data for both models, namely,
list(x=c(1,1)), is
model {x[1]∼dbin(p[1],10); p[1]∼dbeta(1,1)
x[2]∼dbin(p[2],10); p[2]∼dbeta(30,30)
# Likelihood terms for models
LL[1]<-logfact(10)-logfact(10-x[1])-logfact(x[1])+x[1]*log(p[1])+(10-x[1])
*log(1-p[1])
LL[2]<-logfact(10)-logfact(10-x[2])-logfact(x[2])+x[2]*log(p[2])+(10-x[2])
*log(1-p[2])
# prior ordinates for models
LP[1]<-loggam(2)-loggam(1)-loggam(1)+0*log(p[1])+0*log(1-p[1])
LP[2]<-loggam(60)-loggam(30)-loggam(30)+29*log(p[2])+29*log(1-p[2])
# importance sample ordinates for models
g[1]<-loggam(12.1)-loggam(2)-loggam(10.1)+1*log(p[1])+9.1*log(1-p[1])
g[2]<-loggam(70.8)-loggam(31.3)-loggam(39.5)+30.3*log(p[2])+38.5*log(1-
p[2])
# Combining likelihoods, priors and importance samples

Model Fit, Comparison, and Checking
87
L[1]<-LL[1]+LP[1]+log(0.5)-g[1]; L[2]<-LL[2]+LP[2]+log(0.5)-g[2]
# Scaling with the largest likelihood, and protecting for underﬂow
maxL<-ranked(L[],2); SL[1]<-max(L[1]-maxL,-700); SL[2]<-max(L[2]-maxL,-
700)
# exponentiating and normalizing
expSL[1]<- exp(SL[1]); expSL[2]<- exp(SL[2]);
# model weights
w[1]<-expSL[1]/sum(expSL[]); w[2]<-expSL[2]/sum(expSL[])}.
11. The coding of the Friel and Pettitt method for model 2 in Example 2.5 is
(with T=20 grid points)
model {for (h in 1:n) {for (s in 1:T+1) { w[h,s] <- 1; L.tem[h,s] <-
pow(L[h,s],q[s])
w[h,s] ∼dunif(a1[h,s],b1[h,s])
a1[h,s] <- -1/L.tem[h,s]; b1[h,s] <- 1/L.tem[h,s]
LL[h,s] <- log(L[h,s])
pi[h,s] <- phi(beta[1,s]+beta[2,s]*x[h]+b[clutch[h],s])
log(L[h,s]) <- y[h]*log(pi[h,s])+(1-y[h])*log(1-pi[h,s])}}
for (s in 1:T+1) { for (j in 1:p) { beta[j,s] ∼dnorm(0,0.1)}
for (j in 1:J) { b[j,s] ∼dnorm(0,tau.b[s])}
log.tau.b[s] ∼dnorm(0,0.1);
tau.b[s] <- exp(log.tau.b[s])
q[s] <- pow(a[s],4); expLL[s] <- sum(LL[1:n,s]) }
a[1] <- 0.01; for (s in 1:T) {a[s+1] <- s/T}
for (s in 1:T) {mc[s] <- (q[s+1]-q[s])*(expLL[s+1]+expLL[s])*0.5 }
logML <- sum(mc[])}
12. The code for the method of Congdon (2007a) applied in Example 2.5
with a lognormal prior on τb is
model {for (i in 1:N){Y1[i] ∼dbern(p1[i]); Y2[i] ∼dbern(p2[i])
Y1[i] <- y[i]; Y2[i] <- y[i]
p1[i] <- phi(b1[1]+b1[2]*x[i])
p2[i] <- phi(b2[1]+b2[2]*x[i]+e[clutch[i]])
LL[i,2] <- y[i]*log(p2[i])+(1-y[i])*log(1-p2[i])
LL[i,1] <- y[i]*log(p1[i])+(1-y[i])*log(1-p1[i])}
# priors
for (j in 1:J) {e[j] ∼dnorm(0,tau)}
tau ∼dlnorm(0,pr.tau); log.tau <- log(tau)
for (j in 1:p) { b2[j] ∼dnorm(M,T); b1[j] ∼dnorm(M,T)}
# prior ordinates, reg coeﬀs
for (j in 1:p) {prior1[j] <- 0.5*log(T/6.28)-0.5*T*pow(b1[j]-M,2)
prior2[j] <- 0.5*log(T/6.28)-0.5*T*pow(b2[j]-M,2)}
# cross prior ordinates, reg coeﬀs
for (j in 1:p) { pr.b2[j] <- 1/(psd.b2[j]*psd.b2[j]);
pr.b1[j] <- 1/(psd.b1[j]*psd.b1[j])

88
Applied Bayesian Hierarchical Methods
g1[j] <- 0.5*log(pr.b2[j]/6.28)-0.5*pr.b2[j]*pow(b2[j]-pm.b2[j],2)
g2[j] <- 0.5*log(pr.b1[j]/6.28)-0.5*pr.b1[j]*pow(b1[j]-pm.b1[j],2)}
# prior ordinate precision (tau) model 2
pr.logtau <- 1/(psd.logtau*psd.logtau)
prior2[p+J+1] <- 0.5*log(pr.tau/6.28)-log.tau-0.5*log.tau*log.tau
# cross prior ordinate, precision
g2[p+J+1] <- 0.5*log(pr.logtau/6.28)-log.tau
-0.5*pr.logtau*pow(log.tau-pm.logtau,2)
# prior ordinates, random eﬀects model 2
for (j in 1:J) { prior2[p+j] <- 0.5*log(tau/6.28)-0.5*tau*e[j]*e[j]}
for (j in 1:J) {pr.e[j] <- 1/(psd.e[j]*psd.e[j])
# cross prior ordinates, random eﬀects model 2
g2[p+j] <- 0.5*log(pr.e[j]/6.28)-0.5*pr.e[j]*pow(e[j]-pm.e[j],2)}
# model comparison
for (j in 1:2) { TL[j] <- sum(LL[,j]); H[j] <- exp(q[j])
q[j] <- max(logh[j]-maxh,-500)
# model probability
w[j] <- H[j]/sum(H[1:2])}
logh[2] <- TL[2]+sum(prior2[1:34])-sum(g2[1:34])
logh[1] <- TL[1]+sum(prior1[1:2])-sum(g1[1:2])
maxh <- ranked(logh[1:2],2) }

3
Hierarchical Estimation for
Exchangeable Units: Continuous and
Discrete Mixture Approaches
3.1
Introduction
What is sometimes termed ensemble estimation or “borrowing strength from
the ensemble” refers to inferences for collections of similar units, i = 1, . . . , n
(schools, health agencies, etc.) (Burr and Doss, 2005; George et al., 1993;
Morris, 1983; Rao, 1975). Among possible examples are collections of clinical
trials, surgical death rates for hospitals, exam pass rates for schools, goal aver-
ages for basketball players (Hsiao, 1997), or teenage pregnancy rates in health
areas (Deely and Smith, 1998). Fixed eﬀects models for such collections are
problematic (Marshall and Spiegelhalter, 1998), whereas hierarchical random
eﬀects approaches pool information across units to obtain more reliable esti-
mates for each unit, and help identify units with unusually high or low values.
Bayesian hierarchical models for modeling collections of similar units typ-
ically adopt unit or cluster-speciﬁc models with conditional means, {yi|bi},
depending on unobserved eﬀects, bi, with density, p(bi|ψ), known variously as
the mixing distribution, hyperdensity, or higher stage density with hyperpa-
rameter(s) ψ. To reﬂect the conditioning on this density, estimation for sets of
similar units is known as hierarchical modeling (Kass and Steﬀey, 1989; Lee,
2004). For instance, in the ﬁrst stage of the conjugate Poisson-gamma model
considered below, the observed counts are conditionally independent given the
unknown means that are taken to have generated them. At the second stage,
these means are themselves determined by the gamma density parameters,
while the density for the gamma parameters forms the third stage. The goals
of such analysis may vary (Shen and Louis, 1998), but often the aim is to pro-
vide conditional estimates of outcome rates or eﬀects in each unit given the
parameters ψ of the common density. Alternatively, rankings of the units may
be required or probabilities of signiﬁcant diﬀerence between units or against
a threshold (Deely and Smith, 1998).
The procedures considered in this chapter are typically based on an ex-
changeability principle—that units are similar enough to justify being mod-
eled by a common density and that the units are not conﬁgured in ways
89

90
Applied Bayesian Hierarchical Methods
(e.g., over time or space) that imply higher correlations between some units
than others (Lindley and Smith, 1972, 4; Spiegelhalter et al., 2004). Struc-
turing of units in space, time, or other forms of nonexchangeability does not
preclude borrowing strength, but a prior relating to that structuring is re-
quired (see Chapter 4). Exchangeability means that there is no prior basis
for supposing some units have higher true eﬀects than others, or that certain
subgroups of units are more similar between themselves than other subgroups
(e.g., that mortality in hospitals i and j is more similar than between hospi-
tals i and k). For units of the same type and observations generated under
similar conditions, exchangeability means all possible permutations of the se-
quence of units have the same probability: random variables {y1, . . . , yn} are
exchangeable if their joint distribution P(y1, . . . , yn) is invariant under per-
mutation of its arguments, so that,
P(y∗
1, . . . , y∗
n) = P(y1, . . . , yn),
where {y∗
1, . . . , y∗
n} is any permutation of {y1, . . . , yn} (Greenland and Draper,
1998).
Sometimes units are better considered exchangeable within subgroups of
the data. A UK example relates to mortality in cardiac surgery units, with
exchangeability within “closed” procedures involving no use of heart bypass
during anesthesia, and “open” procedures where the heart is stopped and
a heart bypass is needed (Spiegelhalter, 1999). Sometimes exchangeability
can only be supported for “residual eﬀects,” bi, obtained after controlling for
known diﬀerences in the denominator population (e.g., the patient casemix
underlying diﬀerent hospital death rates).
Hierarchical smoothing methods result in shrinkage of estimates for each
unit toward the average outcome rate in the population within which ex-
changeability is assumed; shrinkage will be greater for units with observations
based on small samples. When the single population hierarchical model is
appropriate, pooling of strength results in more precise estimates, and may
provide better out-of-sample predictive performance—see Deely and Smith
(1998) for an application of such predictions to “performance indicators.”
The estimated locations of individual units are typically pulled toward the
population average, so that pooling strength may increase the risk of bias, as
compared to unadjusted ﬁxed eﬀect estimates. The increase in precision but
possible bias inherent in hierarchical estimation provides a dilemma known
as the bias-variance trade-oﬀ. In some applications, inferences are over more
than one variable as well as over a collection of similar units (Everson and
Morris, 2000; van Houwelingen et al., 2002). Inferences will typically be im-
proved for related outcomes over similar units (e.g., exam success rates in
diﬀerent pupils, or surgical and nonsurgical mortality in diﬀerent hospitals).
While smoothing is the leading motivation for hierarchical models, a re-
lated theme is to achieve smoothed estimates that allow appropriately for
heterogeneity between sample units—that is, they do not “oversmooth” and
show some robustness or ﬂexibility to individual units, or to clusters of units,

Hierarchical Estimation for Exchangeable Units
91
which are somewhat discrepant or outlying from the rest of the population.
Such heterogeneity will often be associated with overdispersion in Poisson or
binomial data, or with heavy-tailed data in the case of symmetric departures
from normality in continuous variables. One way to modify the standard densi-
ties (e.g., binomial, Poisson, normal) to take account of heterogeneity greater
than postulated under that density is to allow adaptive continuous mixing
at unit level. Examples of such mixing are the scale mixture approach to
the t-density discussed in Section 3.2, or in the Poisson-gamma mixture—see
Hsiao (1997) for a binomial-beta example. Another option is discrete mixing
(see Sections 3.6 et seq), in which a single population assumption is replaced
by an assumption of two or more latent subpopulations. Shrinkage will then be
toward the subgroup characteristics that each unit has the highest posterior
probability of belonging to.
Undershrinkage (undersmoothing) also raises issues: this will lead to over-
estimation of random eﬀect variability and is to be avoided when a type I error
has worse consequences than a type II error (Gustafson et al., 2006). Simi-
larly, Spiegelhalter (2005) points out that there is a danger in performance
indicator analysis that the units (e.g., institutions) that one is trying to detect
could be “accommodated” by a random eﬀects approach, and it is therefore
important that robust methods are used to estimate the standard deviation
of the random eﬀects distribution.
3.2
Hierarchical Priors for Ensemble Estimation using
Continuous Mixtures
Observations for related units are often available in aggregate form, such as
means, yi, for a metric variable or numbers of successes for a binomial variable,
though originally collected in disaggregated form for repetitions, j, within each
unit of observation i. Consider the ﬁrst stage sampling density, p(y|b), for a
set of n observations, {yi, i = 1, . . . , n}, conditional on the parameter vector,
b = {b1, . . . , bn}. For example, consider a Poisson model, yi ∽Po(bi), where yi
is the number of accidents at diﬀerent road sites in a ﬁxed period (e.g., a year),
and bi is a measure of accident proneness. Instead of assuming all units have
the same proneness, it may be more realistic to allow bi to vary over units
according to a stage 2 density, p(bi|ψ), for instance a gamma density to allow
for positive skew in proneness. Then at stage 3 the population parameters
ψ = (ψ1, . . . , ψQ) (hyperparameters) that generate bi are speciﬁed.
Of central interest are the posterior densities, p(bi|y), and p(ψ|y), and the
probabilities under these densities that bi and ψ are in speciﬁed intervals,
such as the probability of an overall positive eﬀect, Pr(ψ > 0|y), when yi are
measures of (say) a clinical treatment beneﬁt. One may also be interested in
predictions for hypothetical future units (e.g., for a new clinical trial or for the

92
Applied Bayesian Hierarchical Methods
next year in a performance ranking application), p(ynew|y). If p(ψ|y) can be
obtained analytically, or samples ψ(1), ψ(2), . . . , ψ(t) obtained directly, then
the posteriors p(bi|y), p(ψ|y), and p(ynew|y) can be obtained by Monte Carlo
simulation, as in,
p(bi|y) =

p(bi|y, ψ)p(ψ|y)dψ,
leading to the estimate p(bi|y) = T
t=1 p

bi|y, ψ(t)
.
An alternative to direct simulation is to simulate the full posterior
p(ψ, b|y) using Markov Chain Monte Carlo (MCMC) methods (Marshall and
Spiegelhalter, 1998), for example by obtaining samples {b(t), ψ(t)} from the
full conditional posteriors p(bi|b[i], ψ, y) and p(ψq|ψ[q], b, y). Often the ﬁrst
stage density, p(y|b), is in the full exponential family, so that,
p(yi|bi) = exp

yibi −B(bi)
A(φi)
+ C(yi, φi)

,
(3.1)
where φi is a scale parameter. Assuming a conjugate second stage prior, the
conditional posterior of each bi follows the same density. For example, as-
sume (Das and Dey, 2006, 2007; Diaconis and Ylvisaker, 1979; Ferreira and
Gamerman, 2000; Frees, 2004) that,
p(bi|ψ) = k1 exp(big1(ψ) −B(bi)g2(ψ)),
(3.2)
where k1 is a normalizing constant. Then the posterior density of bi and ψ
given y is of exponential form,
p(bi, ψ|y) = k2 exp


g1(ψ) +
yi
A(φi)

bi −B(bi)

g2(ψ) +
1
A(φi)

.
(3.3)
With proper log-concave priors, p(ψ), the full conditionals, p(ψq|ψ[q], b, y),
are log-concave and can be sampled using methods such as those of Gilks and
Wild (1992) and a convergent MCMC sequence generally obtained.
By contrast, if improper priors are assumed on {ψ1, . . . , ψQ}, then the
full posterior, p(b, ψ|y), is not necessarily proper (Browne and Draper, 2006;
George and Zhang, 2001; George et al., 1993), and empirical convergence of
the MCMC sequence, {b(t), ψ(t)}, may be problematic even if the posterior
is proper analytically. George and Zhang (2001) consider posterior propriety
results for the Poisson-gamma, the binomial-beta, and multinomial-Dirichlet
models in terms of conditions on the hyperparameter prior tail behavior. For
the latter two hierarchical model schemes, no improper prior can guarantee
a proper posterior. Similar convergence and identiﬁcation issues apply to the
general linear mixed model formulation.

Hierarchical Estimation for Exchangeable Units
93
3.3
The Normal-Normal Hierarchical Model
and Its Applications
A widely applied conjugate hierarchical scheme assumes normal sampling and
normally distributed latent eﬀects. A typical borrowing strength template is
for continuous observations for unit level eﬀects, yi, and intra-unit variation,
a(φi) = s 2
i , even though the underlying data might have involved two-way
nesting with j = 1, . . . , Ji replications for units i = 1, . . . , n. This is often
the case in clinical meta-analysis where patient-level results are summarized
as treatment or risk factor eﬀect measures (e.g., change in a clinical measure
between treatment and control groups, or the slope of a dose-response curve)
along with moment estimates of sampling variances. Assuming the observed
summary measures are exchangeable in terms of being obtained from sim-
ilar study designs and relating to similar types of unit (Spiegelhalter et al.,
2004, 92), they may be regarded as draws from an underlying common density
for the unknown true means, bi.
Often the normal-normal model is applied to ostensibly binomial data us-
ing normal approximations for the eﬀect measures (e.g., Albert, 1996a; Carlin,
1992). Suppose riT of NiT treated subjects in trial i exhibit a particular re-
sponse (e.g., disease or death) as compared to riC of NiC control subjects.
Deﬁne log odds,
ωiT = log(riT/(NiT −riT) ,
and
ωiC = log(riC/(NiC −riC) ,
in the treated and control arms in each trial. Then the log of the odds ratio
forms the unit level response,
yi = ωiT −ωiC,
assumed approximately normal with variance,
s2
i =
1
riT
+
1
NiT −riT
+ 1
riC
+
1
NiC −riC
,
(see Example 3.1). It is also possible to take yi as a log relative risk between
treatment and control groups, namely,
yi = log

 riT
NiT

−log

 riC
NiC

,
with variance,
1
riT
+ 1
riT
−
1
NiT
−
1
NiC
.

94
Applied Bayesian Hierarchical Methods
Another option is to take the risk diﬀerence,
yi = riT
NiT
−riC
NiC
,
as approximately normal with variance,
riT(NiT −riT)
N 3
iT
+ riC(NiC −riC)
N 3
iC
.
Unless heavy tails, skewness, or multiple modes are suspected, an appro-
priate hierarchical model then has a ﬁrst stage specifying a normal density
for the observations yi (with variances allowed to diﬀer by units) and a sec-
ond stage normal density for the bi with variance constant over groups. So for
a univariate outcome,
yi ∼N(bi, s 2
i ),
(3.4)
and
bi ∼N(µ, τ2).
(3.5)
Integrating out the bi, the marginal likelihood for yi is then,
yi|µ, τ2 ∼N

µ, s 2
i + τ2
.
Often the summary measures are unit or trial means and diﬀerent observa-
tional variances are associated with diﬀering sample sizes, Ni, so that s 2
i =
σ2/Ni, where σ2 is an additional unknown. While clinical meta-analysis appli-
cations are common, a similar scenario occurs in small area estimation from
multiple surveys where s 2
i are sampling variances obtained according to the
survey design.
More complex situations can be ﬁtted into this framework. For example,
Abrams et al. (2000) consider the eﬀect of testing positive or negative in a
screening test on subsequent levels of anxiety; see also Abrams et al. (2005).
Let xik be baseline anxiety in study i, with k = 1 (tested positive) and k = 2
(tested negative), and with Ni1 and Ni2 subjects in diﬀerent arms. Let zik be
follow-up anxiety according to screening result, and let dik = zik −xik denote
change in anxiety. Then the measure of interest is the contrast between anxiety
growth according to screening result, namely, yi = di1 −di2, with variance
s 2
i = (Ni1 −1)V (di1) + (Ni2 −1)V (di2)
(Ni1 + Ni2 −2)
,
where
V (dik) = V (xik) + V (zik) −2ρ
)
V (xik)V (zik),

Hierarchical Estimation for Exchangeable Units
95
and ρ is a within-subject correlation taken constant across studies and arms.
Studies may not report all the relevant statistics: they may report the dik
and their variances, or the separate baseline and follow-up measures in each
arm, {xik, zik}, and their variances. In either case, meta-analysis requires a
prior on ρ.
In Equation 3.4, assume independent priors on the hyperparameters,
p(τ2, µ) = p(τ2)p(µ),
with a commonly adopted option being,
τ2 ∼IG

ν
2, νλ
2

,
µ ∼N (mµ, Vµ) ,
where ν, λ, mµ, Vµ are known. The full posterior conditional for bi is then
(Browne and Draper, 2006; George et al., 1993; Silliman, 1997, 927),
p(bi|b[i], µ, τ, y) = p(bi|µ, τ, y) = N([1 −wi]yi + wiµ, Di),
where
Di =

 1
S2
i
+ 1
τ2
−1
=
τ2S2
i
τ2 + S2
i
,
wi =
s 2
i
s 2
i + τ2 ,
and the ﬁrst equality is by virtue of conditional independence of bi. The full
conditional for τ2 is
τ2 ∽IG

0.5[n + ν], 0.5

νλ +
n

i=1
(yi −µ)2

,
while that for µ involves a precision weighted average of mµ, and the average
of bi, namely,
µ ∽N

¯b

nV µ
nV µ + τ2

+ mµ

τ2
nV µ + τ2

,
τ2Vµ
nV µ + τ2

.
Allowing interrelatedness between units leads to inferences about under-
lying unit means that are diﬀerent from those obtained under alternative
scenarios sometimes used, namely, (a) the “independent units” case, with bi
taken as unknown and mutually unrelated ﬁxed eﬀects, with τ2 →∞; and (b)
the complete pooling model of classical meta-analysis where the studies are
regarded as eﬀectively interchangeable and τ2 = 0.
By contrast, the intermediate “exchangeable units” Bayes model leads to
a posterior mean for bi,
E[bi|y] = wiµ + [1 −wi]yi,

96
Applied Bayesian Hierarchical Methods
that averages over the prior mean µ and the data mean yi with weights
wi = (s 2
i /s 2
i + τ2) and 1 −wi = (τ2/s 2
i + τ2), respectively, as is apparent
from the Gibbs sampling full conditionals. The bi under an exchangeability
scenario have narrower posterior intervals than under an independent units
assumption, with precision related to the conﬁdence about the prior mean
and the prior assumed for τ2 (see also Section 3.4). Assume the intra-study
variances can be expressed as s 2
i = σ2/Ni and then set τ2 = σ2/Nµ, where Nµ
is the sample size assigned to the prior mean. Then the weights, wi, become
Nµ/(Ni + Nµ), demonstrating that shrinkage to the prior mean increases as
the conﬁdence about the prior mean increases.
Sometimes it is necessary to control explicitly for trial design, study loca-
tion, and other design features in order to justify an exchangeability assump-
tion (Marshall and Spiegelhalter, 1998; Pauler and Wakeﬁeld, 2000; Prevost
et al., 2000). Similarly, in survey-based small area estimation, the estimate
of bi may incorporate information from administrative area data Xi (Fay and
Herriott, 1979; Rao, 2003). So with centered predictors Xi of dimension p
(excluding a constant term) the above model becomes,
yi ∼N(bi, s 2
i ),
bi ∼N(µ + Xiβ, τ2),
with marginal likelihood then (DuMouchel, 1996),
yi|β, τ2 ∼N(µ + Xiβ, s 2
i + τ2).
This is sometimes known as meta-regression, with recent Bayesian applica-
tions including Levy et al. (2005) and Batterham (2005). Writing the model as
yi = µ + Xiβ + δi + εi,
δi ∼N(0, τ2),
εi ∼N(0, s 2
i ),
the true eﬀect for unit i is then µ + Xiβ + δi.
The normal-normal model may be robustiﬁed against skewness or heavy
tails in either the sampling density or the latent eﬀects density. If non-
normality is suspected at the second stage, a heavy-tailed prior can be used to
accommodate possibly outlying studies. This may be achieved by introducing
study-speciﬁc scale parameters at the second stage (West, 1984), discounting
the inﬂuence of atypical studies on posterior estimates of the overall eﬀect µ,
and avoiding overshrinkage of individual study eﬀects bi. These scale factors
are positive and most commonly taken as gamma with scale and shape ν/2,
providing a scale mixture version of the Student t density. So,
bi ∽N(µ, τ2/λi),
λi ∽Ga
ν
2, ν
2

.

Hierarchical Estimation for Exchangeable Units
97
Skewness in the observed data can often be reduced or eliminated by trans-
formation. However, continuous data (e.g., cost data or data resulting from
psychometric tests) will sometimes have more unusual departures from nor-
mality that render transformation inapplicable, such as clumping of zero val-
ues as well as positive skewness in positive responses (Delucchi and Bostrom,
2004). Skewness in the latent eﬀects, bi, may also be handled by more speciﬁc
parametric adaptations (e.g., Fernandez and Steele, 1998; Sahu et al., 2003),
multivariate versions of which are considered in Section 3.5. Another robust
option adapted to skewness and/or multiple modes is a discrete mixture over
two or more normal densities (Marshall and Spiegelhalter, 1998).
3.4
Prior for Second Stage Variance
The prior assumed for τ2 plays an important role in governing the degree
of shrinkage or pooling strength (Lambert et al., 2005), with diﬀuse priors
leading to lesser shrinkage (Conlon et al., 2007). As discussed in Chapter 1,
improper or highly diﬀuse priors may also lead to identiﬁcation or propriety
problems. For example, the prior
p(τ2) ∝1
τ2 ,
equivalent to taking τ2 ∽IG(0, 0) and to a ﬂat prior on log(τ) over (0, ∞),
can lead to improper posteriors in random eﬀects models (DuMouchel and
Waternaux, 1992). A just proper alternative, such as τ2 ∽IG(c, c) with c small
is often used. However, this prior has a spike near zero (Browne and Draper,
2006), and diﬀerent values of c can inﬂuence posterior inﬂuences despite the
supposedly diﬀuse nature of the prior (Gelman, 2006a).
One might carry out a sensitivity analysis over a range of proper but
diﬀuse Ga(c, d) priors for 1/τ2, such as {c = 0.1, d = 0.001} or c = d = 0.0001
(Fahrmeir and Lang, 2001; van Dongen, 2006). An alternative scheme is to
compare alternative values of c in Ga(1, c) priors for 1/τ2 (Besag et al., 1995),
possibly using a mixture prior over M possible values for cm in the prior
1/τ2 ∼Ga(1, cm), such as cm = 1, 0.1, 0.01, and 0.001 (Jullion and Lambert,
2007). Then for c = (c1, . . . , cm), and p = (p1, . . . , pm),
c|p ∼
M

m=1
pmGa(1, cm),
p ∼Dirichlet(ω),
where (ω1, . . . , ωM) are prior weights.
Introducing some degree of prior information may be relevant, and is natu-
ral under the inverse chi-squared density (sometimes called the scaled inverse
chi-squared) with parameters {ν, λ}. For τ2 a variance, taking

98
Applied Bayesian Hierarchical Methods
τ2 ∽χ−2(ν, λ),
is equivalent to assuming τ2 ∼IG(ν/2, νλ/2), where λ is a prior guess at the
mean variance and ν is a prior sample size (or level of conﬁdence) parameter.
Conlon et al. (2007) consider informative inverse gamma priors on τ2 for
interstudy variability in log-expression ratios in a microarray data application;
for example, they use relatively large prior sample sizes ν.
Smith et al. (1995) discuss elicitation of informative inverse gamma priors
for τ2 based on anticipated variation in the underlying rates bi, and the fact
that assuming normality, 95% of bi will lie between µ −1.96τ and µ + 1.96τ.
Assume bi are measured on a log scale (e.g., log relative risks or log odds) and
suppose the expected ratio of the 97.5th and 2.5th percentiles of risks (or odds)
between centers or studies is 5, then the gap between the 97.5th and 2.5th
percentiles for bi is log(5) = 1.61. For normal bi, the prior mean for τ2 is then
(0.5 × 1.61/1.96)2 = 0.17, and the prior mean for 1/τ2 is 5.93. If the upper
limit for the ratio of the 97.5th and 2.5th percentile of risks or odds is set at 10,
this deﬁnes the 97.5th percentile of τ2, namely, (0.5 × 2.3/1.96)2 = 0.34. The
expectation and variability is then used to deﬁne an inverse gamma prior on τ2
or a gamma prior on 1/τ2. Another procedure based on expected contrasts
in relative risk (RR) or relative odds (ROs) is mentioned by Marshall and
Spiegelhalter (2007, 422): 95% of units will have RRs or ROs in the range
exp(±1.96τ), and an expectation of reasonable homogeneity might correspond
to values of τ less than τh = 0.2. Setting ψ = 0.5τh = 0.1, these expectations
are expressed via a half normal prior on τ, with τ = |T| where,
T ∼N(0, ψ2),
with prior 95% point at 1.96 × ψ = 0.2.
As another way to use prior evidence on variability, Marshall and Spiegel-
halter (1998) mention a hyperprior for the scale parameter, φ, in a gamma
prior for 1/τ2, namely,
1/τ2 ∼Ga(γ, φ),
φ ∼Ga(c, d),
where d is a small multiple of 1/R2 and R is the range of the observed cen-
ter eﬀects, with γ and c constrained according to γ > 1 > c.
When the
ﬁrst stage sampling density involves an unknown variance, Gustafson et al.
(2006) suggest a conditional prior sequence adapted to avoiding undersmooth-
ing, namely,
p

σ2, τ2
= p

σ2
p

τ2|σ2
,
where σ2 ∼IG(e, e) for some small e > 0, and
p

τ2|σ2
∝

1
τ2 + σ2
a+1
exp

−
b
τ2 + σ2

.

Hierarchical Estimation for Exchangeable Units
99
This corresponds to a truncated inverse Gaussian prior on τ2, with Z ∼
IG(a, b) or 1/Z ∼Ga(a, b), where Z = τ2 + σ2. The case {a = 1, b = 0}
corresponds to the uniform shrinkage prior, while larger values of a (e.g.,
a = 5) are “conservative” in the sense of guarding against overestimation of τ2.
3.4.1
Nonconjugate priors
Among nonconjugate strategies (for normal-normal meta-analysis) an eﬀec-
tive choice in terms of being genuinely noninformative (Gelman, 2006a) is a
bounded uniform prior on the random eﬀects standard deviation, τ ∼U(0, H),
with H large. However, this prior may be biased toward relatively large vari-
ances when the number of units (trials, studies, etc.) is small (van Dongen,
2006, 92).
Variations on the uniform shrinkage prior, suggested by Christiansen and
Morris (1997) and Daniels (1999), may also be used. One is a uniform prior
on the shrinkage weights, wi = (s 2
i /s 2
i + τ2), or on the shrinkage weight, w =
(σ2/σ2 + τ2), when σ2 is unknown. Alternatively, one might represent diﬀerent
shades of opinion (sceptical, neutral, enthusiastic with regard to meta-analytic
shrinkage) via the shrinkage weight. One might set a prior probability of 1/3
on the value w = 0.9, or on values w > 0.9, corresponding to nearly complete
shrinkage to µ as under classical meta-analysis. A prior probability of 1/3
would also be set on w = 0.1 or values w < 0.1, corresponding to a sceptical
view on exchangeability. Finally, a prior probability of 1/3 could be set on
neutral values, w ∼U(0.1, 0.9).
Another possibility when the s 2
i are provided as part of study summaries,
is a uniform prior on the average shrinkage (Spiegelhalter et al., 2004, Chap-
ter 5), namely,
w =
s 2
0
s 2
0 + τ2 ,
where
1
s 2
0
= 1
n
n

i=1
1
s 2
i
,
is the harmonic mean of the study sampling variances. DuMouchel (1996) pro-
poses a uniform prior on s0/(s0+τ) that is equivalent to a Pareto prior, namely,
p(τ) =
s0
(s0 + τ)2 .
This prior is proper but with E(τ) = ∞, and with (0.01, 0.25, 0.5, 0.75,
0.99) percentile points at (s0/99, s0/3, s0, 3s0, 99s0). Note that the Pareto can
also be parameterized as
p(u) = bs b
0u−b−1,
with τ = u −s0 when b = 1.

100
Applied Bayesian Hierarchical Methods
An increasingly popular option is half-normal, half-Student t, or half-
Cauchy priors on the second stage standard deviation τ. If T ∼N(0, V ) and
τ = |T|, then τ is half-normal with variance V (Spiegelhalter et al., 2004).
One then has E(τ|V ) =
)
2V/π and var(τ|V ) = V (1 −2/π). If τU represents
a likely upper value for τ, then one may take V = (τU/1.96)2 as in Pauler and
Wakeﬁeld (2000). Note that if T ∼N(m, V ) (i.e., the normal has an unknown
mean), then τ = |T| is folded-normal with
E(τ|V ) =
)
2V/π exp(−m2/2V ) −m[1 −2Φ(m/V 0.5)],
and variance m2 + V. Gelman (2006a) and Zhao et al. (2006) adopt folded
noncentral t-densities for τ, obtained by dividing the absolute value of a normal
variable by the square root of a gamma variable. If the normal variable has
mean zero then the folded noncentral t becomes a half-t variable.
In particular, half-t and half-Cauchy priors for the second stage parame-
ter τ may be achieved by a reparameterization of the second stage prior on
the latent trial means that strictly involves parameter redundancy. Such over-
parameterization may improve MCMC convergence (Gelman, 2006a). With
preset parameters ν and A (degrees of freedom and prior scale, respectively)
one has,
bi = µ + ξηi,
ξ ∼N(0, A),
ηi ∼N

0, σ2
η

,
1/σ2
η ∼χ2
ν,
with the standard deviation of bi then obtained as τ = |ξ|ση; see van Dongen
(2006) for an application. Setting ν = 1 leads to a half-Cauchy prior,
p(σb) ∝(τ2 + A)−1,
where Gelman (2006a, 524) uses a value A = 25 in a meta-analysis with
small n, based on a prior belief that τ was well below 100.
3.5
Multivariate Meta-Analysis
A multivariate analysis for metric outcomes may arise in two main ways.
The ﬁrst occurs in clinical applications involving treatment and control arms.
Often the event rate in the control arm is taken as indicating the baseline risk
in the patient population being studied and there is interest in whether the
treatment eﬀect is related in any way to baseline risk (Arends, 2006). Sup-
pose riT of NiT treated subjects in trial i exhibit a particular response (e.g.,
disease or death) as compared to riC of NiC control subjects; also deﬁne log
odds yiT = log(riT/(NiT −riT)) and yiC = log(riC/(NiC −riC)). Often the

Hierarchical Estimation for Exchangeable Units
101
analysis focuses on the log of the odds ratio obtained as yiT −yiC, and treats
it as approximately normal (see Example 3.1).
However, to separate out baseline risk, one may model {yiT, yiC} as
(approximately) bivariate normal. If the trial is randomized it is legitimate
to assume that {yiT, yiC} are independent at the ﬁrst stage (van Houwelin-
gen et al., 2002). So,

yiT
yiC

∽N


biT
biC

,

s2
iT
0
0
s2
iC

,

biT
biC

∽N


µT
µC

, Υ

,
where Υ =

τ2
T
τTC
τTC
τ2
C

, with diagonal terms τ2
T and τ2
C representing variability
in the true treatment and control event rates, and with γ = µT −µC deﬁning
the underlying treatment eﬀect with variance τ2
T +τ2
C −2τTC. The conditional
variance of the treatment eﬀect given the true control group rate is τ2
T −
(τ2
TC/τ2
C). So baseline risk explains a portion τ2
C −2τTC +(τ2
TC/τ2
C)/τ2
T +τ2
C −
2τTC of the treatment eﬀect variance.
It is also possible, of course, to have a multivariate analysis generated when
more than one outcome is associated with a speciﬁc unit, such as surgical and
nonsurgical mortality in each hospital in the case study of Everson and Morris
(2000). In this case, suppose there are K outcomes, then,




yi1
yi2
·
yiK



∽N








bi1
bi2
·
biK



, Si



,
where
Si =




s2
i1
si12
·
si1K
si21
s2
i2
·
si2K
·
·
·
·
siK1
siK2
·
s2
iK



,
is the known covariance matrix between outcomes for trial i. A multivariate
normal second level prior for (bi1, . . . , biK) involves means {µ1, . . . , µK} and
K × K covariance matrix Υ.
Multivariate normality is often a simpliﬁcation and one may wish to allow
both for heavier tails, skewness, or multimodality; see Genton (2004) and Lee
and Thompson (2008) for reviews of recent developments in skew-elliptical
densities, which are one possible avenue to greater robustness in these di-
rections. These models build on the principle suggested by Azzalini (1985)
that if f and g are symmetric densities with parameters µ and σ, with G the
cumulative density corresponding to g, then the new density deﬁned by,

102
Applied Bayesian Hierarchical Methods
h(x|µ, σ, δ) = 2
σf

x −µ
σ

G

δx −µ
σ

,
is skew for nonzero δ.
Following Sahu et al. (2003), a multivariate skew-normal model is a partic-
ular type of skew-elliptical model (of dimension K) obtained by considering
errors εK×1 ∽NK(0, Σ), positive variables ZK×1 ∽NK(0, I), and taking
y = DZ + ε where D is a diagonal matrix, diag(δ1, . . . , δK). In a regression
setting with a K dimensional mean µ, one has,
y|Z = z ∽NK(µ + Dz, Σ).
Values δk > 0 correspond to positive skew in the kth outcome, while a negative
δk arises from negative skew. A multivariate skew-t model (allowing for both
heavier tails than the normal, and also for skewness) is obtained by sampling
ZK×1 ∽tK,ν(0, I), where ν is a degrees of freedom parameter, then,
y|Z = z ∽tK,ν+K

µ + Dz, ν + zT z
ν + K Σ

.
Example 3.1. Nicotine Replacement Therapies
To illustrate approx-
imately normal responses based on discrete (binomial) data, this example con-
siders n = 90 studies1 of the beneﬁts of nicotine replacement therapy (NRT)
(Cepeda-Benito et al., 2004). The data are supplied as the numbers, riT, quit-
ting smoking among those under therapy, NiT, and numbers of quitters, riC,
in control or placebo groups of size NiC. Then the empirical log odds ratios
measuring treatment eﬀects, namely,
yi = log

riT
NiT −riT

−log

riC
NiC −riC

,
are approximately normal with variances,
s2
i =
1
riT
+
1
NiT −riT
+ 1
yiC
+
1
NiC −riC
.
A normal higher stage is assumed with yi ∽N(bi, s2
i ) and bi ∽N(µ, τ2).
A uniform shrinkage prior on
w =
s 2
0
s 2
0 + τ2 ,
as considered above, is assumed for the second stage variance. Additionally a
N(0, 100) prior on µ is adopted. Various kinds of predictions may be consid-
ered. Here the predicted treatment eﬀect in a new trial is sampled according to,
bnew ∽N(µ, τ2),
ynew ∽N(bnew, s2
0).

Hierarchical Estimation for Exchangeable Units
103
–2
0
1
2
–1
0.2
0.6
1.0
Theoretical quantiles
Sample quantiles
FIGURE 3.1
Normal Q-Q plot.
Early convergence in a two chain run of 5000 iterations is obtained. Using
the last 4000 for inference, a clear beneﬁt of NRT is indicated, with the odds
ratio exp(µ) having a posterior mean (and 95% credible interval) of 1.92 (1.73,
2.14). τ2 is estimated as 0.082 (mean) and 0.076 (median). A Q-Q plot for the
posterior mean, bi, does not suggest marked departures from normality2 except
possibly in the more extreme bi (Figure 3.1), while a Shapiro–Wilk normality
test has a p-value just over 0.05. However, a Jarque–Bera test (Jarque and
Bera, 1980) suggests a signiﬁcant departure from normality, with p-value of
0.0018. Although the analysis would appear conclusive in terms of treatment
beneﬁt, the predicted odds ratio for a new trial includes null values for the
beneﬁt from NRT, having mean (95% CI) of 2.16 (0.7, 5.1).
To allow for possibly outlying trials and downweight their eﬀect, an alter-
native analysis adopts a second stage Student density with,
bi ∽N(µ, τ2/λi),
λi ∽G
ν
2, ν
2

.
Less typical trial results will have values of λi considerably under 1 and a
test for the posterior probability that λi is less than 1 can be included. The
prior on ν is speciﬁed in two steps as ν ∽E(κ) and κ ∽U(0.01, 0.5). Evidence
in support of a heavy-tailed second stage is equivocal. From the last 9000 of a
two chain run of 10,000 iterations, ν is estimated at 9.5, suggesting departure
from normality. The posterior mean and median for τ2 are reduced to 0.051
and 0.046, respectively. On the other hand, only two trials (4 and 36) have
posterior probability that λi < 1 in excess of 0.7, namely 0.87 for trial 4 and
0.83 for trial 36. Trial 4 has an exceptionally high empirical log odds ratio in
support of NRT.
Example 3.2. Bacillus Calmette–Gu´erin Vaccine Trials: Bivariate
Model
Following van Houwelingen et al. (2002), an example of a bivariate
meta-analysis involves data from 13 trials regarding the eﬀectiveness of Bacil-
lus Calmette–Gu´erin (BCG) vaccine against tuberculosis. Each trial compares

104
Applied Bayesian Hierarchical Methods
vaccinated and nonvaccinated groups of size {NT, NC} with the outcome being
counts of tuberculosis {rT, rC}, and with the infection rate in the control arm
taken as indicating the baseline risk. The response variables are the log odds
in each trial arm, yiT = log(riT/(NiT −riT)) and yiC = log(riC/(NiC −riC)).
Here the analysis assumes normality at both levels3, with

yiT
yiC

∽N


biT
biC

,

s2
iT
0
0
s2
iC

,

biT
biC

∽N


µT
µC

, Σb

,
where s2
iT = 1/riT+1/(NiT −riT), s2
iC = 1/riC+1/(NiC −riC). It is assumed
that the precision matrix Σ−1
b
of the latent eﬀects is Wishart with identity
scale matrix and 2 degrees of freedom, while the {µT, µC} parameters have
N(0, 1000) priors.
Posterior means for (µT, µC) are estimated as (−4.83, −4.02), with mean
vaccination eﬀect of −0.80 (−1.3, −0.3), slightly more negative than the esti-
mate of −0.74 found by van Houwelingen et al. (2002) using classical methods
(in the SAS package). The posterior mean for Σb is ( 1.86 2.24
2.24 3.32 ), with correlation
between treatment and control eﬀects (where eﬀects are log odds) obtained
from monitoring the components of Σb as 0.90. Similarly, the slope of the re-
gression to predict the vaccination group log odds from the control group
log odds, obtained by averaging Σ(t)
b12/Σ(t)
b22 over iterations t, is 0.67. The
variance of the true treatment eﬀects, biT −biC, is obtained by monitoring
Vt = Σb,11 + Σb,22 −2Σb,12, while the conditional variance of the vaccination
log odds eﬀects biT given biC (and hence the variance of biT −biC given biC)
is obtained by monitoring Vc = Σb,11 −Σ2
b,12/Σb,22. Finally, the proportion of
treatment eﬀect variation explained by baseline risk (i.e., the true log odds in
the control group), obtained by monitoring 1 −Vc/Vt, has a posterior mean
of 0.51.
3.6
Heterogeneity in Count Data:
Hierarchical Poisson Models
The adoption of higher stage densities for count data is often linked to appar-
ent departures from the Poisson mean-variance assumption. The most com-
mon departure is that count data show more variability than expected under
the Poisson, so that the coeﬃcient of variation, (V (y)/¯y), exceeds 1. Overdis-
persion may reﬂect unobserved subject frailties, multiple modes, nonrandom
sampling (Efron, 1986), or widely diﬀerent exposures, oi (e.g., when a count
outcome yi is surgical deaths for hospitals, with means µioi where oi are
patient totals). The conjugate continuous mixture models in the presence of

Hierarchical Estimation for Exchangeable Units
105
excess heterogeneity is the Poisson-gamma, though greater ﬂexibility in more
complex models (e.g., multilevel or multivariate) is generally obtained by mix-
ing with nonconjugate links.
The Poisson-gamma model allows for unit mean rates, µi, to vary accord-
ing to a gamma density, µi ∽Ga(α, β), which is unimodal but ﬂexibly shaped.
Thus for count data yi assumed Poisson with means µi, set,
B(bi) = ebi,
in Equation 3.1, where µi = ebi, a(φi) = 1, and c(yi, φi) = log yi! Then
Equation 3.2 has the form,
p(bi|ψ) = k1 exp

big1(ψ) −ebig2(ψ)

= k1

ebig1(ψ) exp

−ebig2(ψ)

,
namely, a gamma density for µi = ebi with parameters α = g1(ψ) + 1 and
β = g2(ψ). The conditional posterior is
p(bi|y, α, β) = k2

ebiα+yi exp

−ebi[β + 1]

,
namely, a gamma for µi with parameters α+yi and β+1. Denoting the mean
of the µi as ξ = α/β, one obtains V (µi) = α/β2 = ξ2/α. Then,
V (yi) = E[V (yi|µi)] + V [E(yi|µi)] = ξ + ξ2/α,
so that overdispersion is present when φ > 0, where φ = 1/α.
Diﬀerent parameterizations of the Poisson-gamma mixture can be used.
For example, one may set µi = ξωi, with overall mean parameter ξ, and
multiplicative random eﬀects, ωi, having mean 1 for identiﬁability, namely,
ωi ∽G(α, α) with V (ωi) = 1/α. Integrating the ωi out, as in
p(yi|ξ, α) =

p(yi|ωi, ξ)p(ωi|α)dωi,
leads to a marginal negative binomial density for the yi, namely,
p(yi|ξ, α) =
Γ(α + yi)
Γ(α)Γ(yi + 1)

α
α + ξ
α 
ξ
α + ξ
yi
.
If predictors Xi are present, negative binomial regression is obtained with
ξi = exp(Xiβ) (see Chapter 5). Note that in many applications there may be
forms of truncation, as when zero counts do not enter the analysis (Eaton,
1974; Larson and Soule, 2006). So a zero truncated negative binomial has
p(yi|ξ, α, yi > 0) =
Γ(α+yi)
Γ(α)Γ(yi+1)

α
α+ξ
α 
ξ
α+ξ
yi
1 −

α
α+ξ
α
.

106
Applied Bayesian Hierarchical Methods
Alternatively, one may assume yi ∽Po(µi), µi ∽G(α, β), with E(µi) = m =
α/β and var(µi) = Vµ = α/β2 (e.g., Clayton and Kaldor, 1987). When this pa-
rameterization includes oﬀsets, oi, the posterior p(µi, α, β|y) is proportional to,
L(α, β, µ|y)p(α, β) =
 n

i=1
exp(−µioi)(µioi)yi
yi!



 βα
Γ(α)
n  n

i=1
µi
α−1
exp

−β
n

i=1
µi

p(α, β),
with conditional posterior for µi now G(α + yi, β + oi). Hence the posterior
mean is
E(µi|yi, α, β) = yi + α
oi + β.
The conditional likelihoods (George et al., 1993, 191) for α and β under
this structure are obtained from L(α, β, µ|y), namely,
L(α|β, µ) = kα

 βα
Γ(α)
n  n

i=1
µi
α−1
,
and
L(β|α, µ) = kββnα exp

−β
n

i=1
µi

,
where kα and kβ are normalizing constants. Hence L(β|α, µ) is gamma with
parameters nα + 1 and n
i=1 µi. The conditional posteriors, p(α|β, µ) =
L(α|β, µ)p(α) and p(β|α, µ) = L(β|α, µ)p(β), are log-concave when the pri-
ors p(α) and p(β) are log-concave. Assuming a gamma prior, p(β) = G(c, d),
the full conditional for β is G(nα + 1 + c, n
i=1 µi + d). However, the full
conditional for α is nonstandard whatever form for p(α) is adopted.
Another Poisson-gamma mixture formulation (e.g., Albert, 1999; Chris-
tiansen and Morris, 1996) assumes,
yi|λi ∽Po(oiλi),
λi ∽Ga

ζ, ζ
µi

,
where V (λi) = µ2
i /ζ and the Poisson corresponds to ζ →∞. If µi = µ and
a gamma prior is assumed for µ, then the posterior mean for λi conditional
on µ and ζ is
E(λi|y, ζ, µ) =
yi + ζ
oi + ζ/µ = Biµ + (1 −Bi)yi
oi
,
where
Bi =
ζ
ζ + oiµ,

Hierarchical Estimation for Exchangeable Units
107
measures the level of shrinkage toward the overall mean µ. Thus, shrinkage will
be greater when oi (e.g., the population at risk in a mortality application) is
small, or when ζ is large. As for the second stage variance in the normal-normal
model, the prior on ζ inﬂuences the degree of shrinkage that is obtained. Let
ri = yi/oi. Then Christiansen and Morris (1996) suggest a uniform prior based
on the average shrinkage factor,
B0 =
ζ
ζ + min(oi)¯r ∼U(0, 1),
with the prior value of ζ then obtained as B0 min(oi)¯r/(1 −B0).
Extended parameterizations of the negative binomial have been suggested
(Liu and Dey, 2007). Winkelmann and Zimmermann (1991) suggest a variance
function,
V (yi) = E[V (yi|µi)] + V [E(yi|µi)] = ξ + φξk+1,
with k ≥−1, and obtained by taking µi ∽G(ξ1−k/φ, ξ−k/φ). Setting k = 0
and k = 1 leads to what are called NB1 and NB2 forms of the negative
binomial, under which the variances are linear and quadratic in ξ, namely,
V (yi) = ξ + φξ and V (yi) = ξ + φξ2, respectively.
3.6.1
Nonconjugate Poisson mixing
Alternatives to the conjugate model are the Poisson lognormal model, and
models such as the generalized Poisson density, zero inﬂated Poisson (ZIP),
and hurdle model adapted to diﬀerent types of departure from the typical
Poisson frequency pattern. The Poisson lognormal model has been suggested
as a more appropriate model, than the conjugate mixture in certain applica-
tions such as species abundance—see Bulmer (1974) and Diserud and Engen
(2000). It is obtained for yi ∼Po(µi) when µi are lognormally distributed,
or equivalently when the logarithms wi = log(µi) of the Poisson means are
assumed normal with mean M and variance V (Aitchison and Ho, 1989).
The marginal density under lognormal mixing is obtained by integrating the
sampling density over the domain of the log mean, namely,
p(yi|M, V ) = (2πV )−0.5
yi!
 ∞
0
µyi−1
i
e−µi exp
−(log µi −M)2
2V

dµi,
with marginal mean and variance, respectively, eM+V/2 and e2M+V [eV −1].
As V →0, this reduces to a Poisson density. An alternative parameterization
(Weems and Smith, 2004) has yi ∼Po(µiUi) with log(µi) = β0 +β1x1i +· · ·+
βpxpi, and log(Ui) ∼N(1, V ).
The Poisson-lognormal generalizes readily to multivariate count data (Chib
and Winkelmann, 2001) or to mixing with heavier tails than available under
the lognormal; for example, the log Student t with a low degrees of freedom
parameter for a heavy-tailed albeit symmetric mixing density. Skew normal

108
Applied Bayesian Hierarchical Methods
and skew Student t mixing can also be used since in some applications ex-
tremes of frailty tend to be above rather than below the center of density
(Sahu et al., 2003).
The exchangeable Poisson lognormal model is quite widely applied to pool-
ing inferences over sets of units (e.g., hospitals) when health event totals, yi,
such as surgical deaths are obtained and there are oi expected events; the
Poisson lognormal is also widely applied in modeling for spatially structured
disease count data (Chapter 4). The oi might be based on multiplying the
patient total for hospital i by an average event rate and are usually assumed
known (i.e., not to be subject to measurement error). If the average rate is
based on the total set of n hospitals, then one has Σyi = Σoi, and with
µi = oiρi one has,
yi ∽Po(oiρi),
with the ρi interpretable as relative risks averaging 1 over all units. However,
this feature is not always present, and allowing for mean risk other than 1 (e.g.,
if a national surgical mortality rate is applied to a particular set of hospitals)
the Poisson-lognormal then assumes,
log(ρi) = β0 + wi,
where wi ∽N(0, Vw) are exchangeable normal random eﬀects, with relative
risks, ρi, pooled toward a global average rate, exp(β0), according to the size
of Vw. Equivalently, vi = exp(wi) are lognormal with mean µ = exp(0.5 Vw)
and variance µ2(expVw −1).
Generalized Poisson and Poisson process models are also often useful in
particular settings, including underdispersion (Consul, 1989; Podlich et al.,
2004; Scollnik, 1995). The generalized Poisson density (Consul, 1989) speciﬁes4
p(y|λ, ρ) = λ(λ + yρ)y−1
y!
e−λ−ρy,
with mean λ/(1 −ρ), variance λ/(1 −ρ)3, and hence coeﬃcient of variation
1/(1 −ρ)2 ≥1. This reduces to a Poisson density as ρ →0.
Example 3.3. Hospital Mortality
To exemplify the Poisson-gamma me-
thodology, consider counts of patient deaths following heart transplant
surgery in 131 hospitals in the United States between October 1987 and
December 1989. These were analyzed by Christiansen and Morris (1996, 1997).
Let oi be expected deaths (calculated by a logit regression on patient charac-
teristics). Then,
yi|λi ∽Po(oiλi),
λi ∽Ga

ζ, ζ
µ

,

Hierarchical Estimation for Exchangeable Units
109
with shrinkage factors,
Bi =
ζ
ζ + oiµ.
The prior on ζ is indirect, via a uniform prior on B0 = ζ/(ζ + min(oi)¯r).
A two chain run of 10,000 iterations5 provides a deviance information
criterion (DIC) of 456 (de = 32) and high values for both B0 and ζ, namely,
0.987 and 10.9. This might be taken as possibly indicating that a Poisson-
gamma mixture is not needed (see Albert, 1999). A possible predictive check
is that the 95% intervals of yrep,i include at least 95% of the data points yi
(Gelfand, 1996). In fact, all the observations meet this criterion.
Christiansen and Morris (1996) argue that exchangeability between all 131
units might not be applicable since hospitals with larger patient totals have
lower crude death rates. As one remedy for such a pattern, one might take
yi ∽Po(νi), νi ∽Ga(ζ, ζ/µi) where,
log(µi) = β1 + β2 log(oi),
now includes a regression on log(oi). So expected deaths is no longer an oﬀset
with implicit coeﬃcient β2 = 1. Here we instead split the hospitals into two
groups with indicator Gi, one group (with Gi = 1) containing 37 hospitals
with under 10 patients, the other (with Gi = 2) containing the remaining
94 hospitals. Diﬀerent means and variance parameters are assumed in the two
groups. So,
yi|λi ∽Po(oiλi),
λi ∽Ga

ζGi, ζGi
µGi

,
with uniform priors on group-speciﬁc average shrinkage factors (k = 1, 2),
B0k =
ζk
ζk + min(oi; Gi = k)¯rk
.
This extension to partial exchangeability produces a deviance reduction to
447 with the eﬀective dimension still about 32. The mean mortality RR (with
95% interval) is found to be 2.1 (1.4, 2.9) in the low workload hospitals, but
lower, namely, 0.95 (0.82, 1.1), in the higher workload hospitals. The variance
factor, ζk, is higher in the low workload hospitals, but the average shrinkages,
B0k, are similar, at 0.95 and 0.93, respectively.
3.7
Binomial and Multinomial Heterogeneity
Heterogeneity in binary and categoric outcomes is commonly found in con-
sumer and demographic data. Among possible approaches are the beta-
binomial, the logistic-normal, and generalizations of the binomial (e.g., Alanko

110
Applied Bayesian Hierarchical Methods
and Duﬀy, 1996); analogous methods apply for categoric data with the con-
jugate model being the multinomial-Dirichlet. Although the Poisson-gamma
mixture is widely applied to health and disease events, the beta-binomial
may also be used if populations are relatively small, and has diﬀerent impli-
cations for shrinkage: shrinkage is greater under the Poisson-gamma (Howley
and Gibberd, 2003). Binomial and multinomial mixture methods have recently
become popular in the analysis of ecologic problems where marginals of a con-
tingency table are available, often from diﬀerent sources, such as census and
voting data, but the internal cells are unobserved (King, 1997; King et al.,
2004).
For binomial data, yi ∽Bin(Ni, πi), i = 1, . . . , n, the exponential family
parameterization sets,
B(bi) = Ni log(1 + ebi),
in Equation 3.1, where πi = ebi/(1 + ebi), a(φi) = 1, and c(yi, φi) = log
 Ni
yi

.
Then Equation (3.2) has the form,
p(bi|ψ) = k1 exp(big1(ψ) −Ni log(1 + ebi)g2(ψ))
= k1

ebi
1 + ebi
g1(ψ)
(1 + ebi)−Nig2(ψ)+g1(ψ),
namely, a beta density for πi with parameters g1(ψ) and Nig2(ψ) −g1(ψ).
The conditional posterior of πi is then also a beta density with parameters
g1(ψ) + yi and Ni[g2(ψ) + 1] −g1(ψ) −yi. The marginal density is known as
the beta-binomial with,
p(yi|g1, g2) =

Ni
yi
Be(g1 + yi, Ni(g2 + 1) −(g1 + yi))
Be(g1, Nig2 −g1)
.
Shrinkage eﬀects are apparent under the beta mixing parameterization,
πi ∽Be(γρ, γ(1 −ρ)),
where ρ ∈(0, 1), and where γ > 0, termed the spread parameter by Howley
and Gibberd (2003), is inversely related to the prior variance of the proportions
ρ(1 −ρ)/(1 + γ). The conditional posterior for πi is πi ∽Be(γρ + yi, γ(1 −
ρ) + Ni −yi), and the posterior mean is
E(πi|y, γ, ρ) =
γ
γ + Ni
ρ +
Ni
γ + Ni

 yi
Ni

,
namely, a weighted average of the observed rate and the prior mean rate.
Shrinkage to the prior mean is greater when γ is large and for small popula-
tions, Ni. The marginal density is
p(yi|γ, ρ) =

Ni
yi
Be(γρ + yi, γ(1 −ρ) + Ni −yi)
Be(γρ, γ(1 −ρ))
=

Ni
yi
Γ(γρ + yi)Γ(γ(1 −ρ) + Ni −yi)Γ(γ)
Γ(γρ)Γ(γ(1 −ρ))Γ(γ + Ni)
,

Hierarchical Estimation for Exchangeable Units
111
with expectation E(yi) = E[E(yi|πi)] = E(Niπi) = Niρ, and variance,
V (yi) = V [E(yi|πi)] + E[V (yi|πi)] = ρ(1 −ρ)

γ + Ni
γ + 1

,
so that γ →∞corresponds to the binomial density.
Quintana and Tam (1996) consider both marginal and conditional likeli-
hood MCMC estimation approaches to the beta-binomial. With beta mixing
according to πi ∽Be(a, b), and prior p(a, b), they apply Hastings sampling to
the joint marginal likelihood (with πi integrated out)
L(a, b, y) ∝
 Γ(a + b)
Γ(a)Γ(b)
n 
i
Γ(a + yi)Γ(b + Ni −yi)
Γ(a + b + Ni)

p(a, b),
and mixed Gibbs–Hastings sampling to the joint conditional likelihood,
L(a, b, π, y) ∝
 Γ(a + b)
Γ(a)Γ(b)
n 
i
πa+yi−1
i
(1 −πi)b+Ni−yi+1

p(a, b).
They also consider implications for posterior parameter correlation of the
reparameterization (Lee and Sabavala, 1987),
πi ∼Be(µ, η),
µ = a/(a + b); η = 1/(1 + a + b),
where η is a measure of heterogeneity.
3.7.1
Nonconjugate priors for binomial mixing
Alternatives to conjugate beta mixing are the binomial with normal errors
in the link, generalized binomial models (Makuch et al., 1989), generalized
beta-binomial models (Rodriguez-Avi et al., 2007), and models adapted to
departures from the typical binomial frequency pattern, such as zero-inﬂated
binomial models. The logistic-normal model with normal random eﬀects in
the logit link speciﬁes,
yi|πi ∽Bin(Ni, πi),
logit(πi) = bi,
bi|µ, τ ∽N(µ, τ2).
Here, πi then follows a logistic-normal density,
p(πi|µ, τ2) =
1
τ
√
2π exp

−1
2τ2

log
πi
1 −πi
−µ
2
1
πi(1 −πi).
The logistic-normal prior with τ = 2.67 and µ = 0 matches a Jeﬀreys prior
on πi in the ﬁrst two moments, and setting τ = 1.69 matches the uniform prior

112
Applied Bayesian Hierarchical Methods
in the ﬁrst two moments (Agresti and Hitchcock, 2005). As for the Poisson-
lognormal, one may generalize to heavier tailed or skewed mixing densities.
Teather (1984) proposes a family of symmetric prior densities for logit(πi)
that includes the normal and double exponential as special cases. Alternative
links (e.g., probit) or mixing over links are possible.
In many applications (e.g., studies with patients allocated to multiple
treatment), the random eﬀect variation represents diﬀerential frailty in the
patient population of the study, so that for studies, i = 1, . . . , n with
k = 1, . . . , K treatment categories,
yik ∽Bin(Nik, πik),
logit(πik) = bi + βk,
bi ∽N(0, τ2),
where βk are ﬁxed treatment eﬀects, while bi can be interpreted as between
study variation in treatment eﬀects. For example, Gao (2004) considers this
structure for data on a meta-analysis of eight randomized clinical trials com-
paring healing rates in duodenal ulcer patients. For trials with treatment and
control arms only, with patient totals {NiT, NiC}, the logistic-normal model is
often applied in meta-analysis when trial totals are small, rather than adopt-
ing a normal approximation (Parmigiani, 2002; Warn et al., 2002). In fact,
other links (combined with binomial sampling) may be more useful in clinical
interpretability.
The prior structure often focuses on the control arm probabilities, πiC, and
on diﬀerences between trial and control group probabilities. Thus, assume,
yiT ∽Bin(NiT, πiT),
yiC ∽Bin(NiC, πiC).
Then analysis of treatment–control diﬀerences, δi, on the log odds ratio
scale would involve transforms ωiT = logit(πiT), and ωiC = logit(πiC), and
taking,
δi = ωiT −ωiC,
one might assume,
δi ∼N(∆, σ2
δ).
For the πiC, random eﬀect options might be to take ωiC ∽N(µC, τ2
C),
with {µC, τ2
C} as additional unknowns, or πiC ∽Be(aC, bC) with {aC, bC}
additional unknowns.
Consider instead a log link, so that ωiT = log(πiT), and ωiC = log(πiC),
again with δi ∽N(∆, σ2
δ). The δi now measure log relative risks, which are
often more clinically useful than log odds ratios, and exp(∆) will measure the
RR of (say) recurrence or mortality under the treatment. In practice, sampling
has to be constrained to ensure δi is less than −log(πiC), so that,

Hierarchical Estimation for Exchangeable Units
113
ωiT = ωiC + min(δi, −log(πiC)),
δi ∽N(∆, σ2
δ).
Similarly, for a risk diﬀerence analysis, ωiC = πiC, πiT = ωiT = δi + ωiC,
with δi ∽N(∆, σ2
δ), but sampling has to be constrained to ensure that πiT ∈
[0, 1]. This involves conﬁning δi to the interval [−πiC, 1−πiC] with the actually
sampled model specifying,
ωiT = ωiC + min(max(δi, −πiC), 1 −πiC).
If the control group probabilities are regarded as proxies for the underlying
risk of subjects in a study, then the model involves a regression on centered
control group eﬀects, namely,
ωiT = ωiC + δi + β(ωiC −¯ωC),
δi ∽N(∆, σ2
δ),
where ¯ωC is the average of the control arm eﬀects (calculated at each itera-
tion), and β is an extra unknown.
3.7.2
Multinomial mixtures
For representing overdispersion in multinomial data with M categories,
(yi1, . . . , yiM ) ∽Mult(Ni, [πi1, . . . , πiM ]),
Ni =

m
yim,
the beta prior generalizes to a Dirichlet prior with parameters (αi1, . . . , αiM ).
With πi = [πi1, . . . , πiM ], αim = αm, and A = 
m αm, one has,
p(πi|α) =
Γ(A)
M
m=1 Γ(αm)
M

m=1
παm−1
im
,
so that prior means for πim are αm/A, with variances αm(K −αm)/A2(A + 1).
The posterior density for [πi1, . . . , πiM ] is Dirichlet with parameters (yi1 +
α1, . . . , yiM + αM). Assuming equal prior mass is assigned to all categories,
namely, α1 = α2 = · · · = αM, there is greater shrinkage or ﬂattening toward
an equal prior cell probability across the M categories as A increases.
Greater ﬂexibility may be provided by a multivariate generalization of
the logistic-normal prior (Aitchison and Shen, 1980; Hoﬀ, 2003). Thus, with
(yi1, . . . , yiM ) ∽Mult(Ni, [πi1, . . . , πiM ]),
πij =
exp(bij)
M
m=1 exp(bim)
,

114
Applied Bayesian Hierarchical Methods
where the vector (bi1, . . . , bi,M−1) of the ﬁrst M −1 eﬀects is multivariate
normal with mean µi = (µi1, . . . , µi,M−1) and covariance matrix Σ of dimen-
sion M −1. For the reference category, one sets biM = 0. If the categories
are ordered and similarity of probabilities in adjacent categories is expected
on substantive grounds, the covariance matrix or its inverse may be stipu-
lated in line with a low order autoregressive form; this is known as histogram
smoothing (Leonard, 1973).
Another generalization is to add a higher stage prior on the Dirichlet pa-
rameters, for example on the total mass A. Thus, Albert and Gupta (1982)
consider a two-stage prior in multinomial-Dirichlet analysis of contingency
tables. With the reparameterization, αi = Aρi, where 
m ρm = 1, one possi-
ble hierarchical prior generalizes the binomial-beta with,
πi = [πi1, . . . , πiM ] ∽Dir(Aρ1, . . . , AρM),
A ∽Ga(aA, bA),
(ρ1, . . . , ρM) ∽Dir(w1, . . . , wM),
where wm and {aA, bA} are known.
3.7.3
Ecological inference using mixture models
Binomial-beta and multinomial-Dirichlet models (or nonconjugate alterna-
tives) have recently found wide application in ecological inference. Much of
the impetus for this research has come from political science, and may involve
counts of a behavior or event for unit i (e.g., constituency) with M outcomes
(e.g., party voting aﬃliation) by demographic attribute with c levels (e.g.,
social class, ethnic group). The underlying data are the totals Nimc. What is
observed in practice are the marginals Nim+ (e.g., constituency voting data
by party voted for), and information from another source (e.g., from the cen-
sus) on the relative distribution of the voting age population across levels
of the demographic attribute. This is proxy information regarding the ratios
xic = Ni+c/Ni++ (which might be census-based percentages of the voting
population in diﬀerent ethnic groups).
Consider the simplest case, ecological inference in 2×2 tables. Suppose the
observations are the total electorate, Ni, the number who turn out, Vi, and
(from census data) the proportion, xi, of the voting age population who are
black. Given this information, the goal of ecological inference is to estimate
parameters governing the internal table cells, namely, the proportions, ri1
and ri2, of black and white voters who turned out. Since M = 2, the data are
binomial, and the overall turnout rate in area i is modeled as Vi ∼Bin(Ni, pi).
Modeling of the turnout rates in terms of ethnic-speciﬁc voting rates proceeds
using the probabilistic statement,
Pr(Turnout) = Pr(Turnout|Black)Pr(Black)
+ Pr(Turnout|White)Pr(White),

Hierarchical Estimation for Exchangeable Units
115
with the corresponding relation in area i being,
pi = ri1xi + ri2(1 −xi).
Among possible priors for the unknown ri1 and ri2 in a 2 × 2 ecological
problem are:
1.
independent beta densities ri1 ∼Be(a1, b1), ri2 ∼Be(a2, b2);
2.
a bivariate normal for wij = logit(rij), with mean µ = (µ1, µ2) and
covariance Σ, allowing {ri1, ri2} to be correlated;
3.
a trivariate normal for wi1 = logit(ri1), wi2 = logit(ri2), and wi3 =
logit(xi).
Imai et al. (2010) typify ecological missing data as data “coarsening” and
the ﬁrst two priors above are consistent with coarsening at random. By con-
trast, the ﬁnal option amounts to modeling the joint density p(x, r) of racial
composition x and turnout behavior r = (r1, r2) via the sequence p(x|r)p(r).
This is similar to joint modeling of missingness and observed data in non-
random models for missing data (Pastor, 2003) and hence may be termed
coarsening not at random. If predictors of turnout rates are available, then
the means µi1 and µi2 include regression terms.
Example 3.4. Breast Cancer Recurrence: Binomial Meta-Analysis
under Diﬀerent Treatment Scales
Parmigiani (2002, 127) considers
14 trials concerning the impact of tamoxifen on breast cancer recurrence rates.
The trials are mostly large and a normal approximation might well be applied,
though one trial involved only 20 patients. A binomial analysis is adopted with
yiT ∽Bin(NiT, πiT), and yiC ∽Bin(NiC, πiC). Deﬁning ωiT = logit(πiT),
ωiC = logit(πiC), and δi = ωiT −ωiC, the logit scale treatment eﬀects are
assumed normal,
δi ∽N(∆, σ2
δ),
with diﬀuse normal and inverse gamma priors on ∆and σ2
δ, respectively. A
random eﬀects beta density is assumed for the control group rates, namely,
πiC ∽Be(aC, bC) with uniform priors on the unknowns, aC ∽U(1, 100) and
bC ∽U(1, 100). To provide a summary index of treatment beneﬁt, the treat-
ment gain, δnew, for a hypothetical new trial is sampled and added to a pre-
dicted baseline recurrence rate, πnew,C (transformed on the appropriate scale)
to give a predicted new trial treatment rate, πnew,T. Then the probability that
the predictive relative risk, RRnew = (πnew,T/πnew,C), exceeds 1 is obtained.
Treatment and placebo groups are compared on three diﬀerent eﬀect scales,
namely, the log-odds ratio (LOR), the log-relative risk (LRR), and the ab-
solute risk diﬀerence (ARD). On the LRR scale, the predictive density6 for
RRnew has 95% interval (0.78, 1.01) with a 3.5% chance that RRnew exceeds 1.
The ARD scale admits a larger element of doubt, with a 95% interval

116
Applied Bayesian Hierarchical Methods
(0.64, 1.05) and Pr(RRnew > 1|y) = 0.075. By contrast, under an LOR scale,
RRnew has 95% interval (0.78, 0.98) with only a 1% chance of exceeding 1.
Example 3.5. Voter Registration
This example considers the race and
literacy data from King (1997) for 1040 US counties. For county i, xi is the
county proportion of blacks, and pi is the overall literacy rate in a binomial
model, Li ∼Bin(Ni, pi), with literate and population totals, Li and Ni. Then,
pi = ri1xi + ri2(1 −xi),
where ri1 and ri2 are the literacy rates of blacks and whites, respectively, taken
to be unknown for modeling purposes. In fact, the true values of ri1 and ri2 are
known (denoted r∗
i1 and r∗
i2), so that the performance of alternative models
can be assessed. The ﬁrst model applied is the “coarsening at random” model
of Imai et al. (2010) with a bivariate normal on the logits of ri1 and ri2, with
N(0, 1) priors on µi, and a Wishart prior on Σ with identity scale matrix. An
absolute error performance measure, Er = ΣiΣj|rij −r∗
ij |, is applied. In a two
chain run7 in OpenBUGS, using initial values based on exploratory analysis,
convergence is obtained by iteration 10,000 in a 20,000 iteration two-chain run.
With inferences based on the remaining iterations, the correlation ρ between
logits of black and white literacy rates has a mean (95% interval) of 0.66 (0.53,
0.78), a value higher than the 0.27 in a frequentist analysis reported by Imai
et al. (2010) in the manual for the R package eco (for ecological inference in
2 × 2 tables). Other parameter means are µ = (0.49, 3.0), σ11 = 0.17, and
σ22 = 0.95, with mean Er = 113.8.
Taking a trivariate normal for wi1 = logit(ri1), wi2 = logit(ri2), and wi3 =
logit(xi) involves a diﬀerent data input scheme, with logit(xi) as the third
column in a 1040 × 3 matrix, with the ﬁrst two columns containing missing
data. The Wishart scale matrix has degrees of freedom, ν = 3, and scale ma-
trix with diagonal elements equal to νVii, where Vii (i = 1, 2) are based on the
preceding model and V33 is based on the empirical variance of wi3. From the
second half of a two-chain run of 50,000 iterations, the absolute error criterion
now averages 104, thereby assuming nonrandom data coarsening improves ﬁt.
The correlation between logit literacy rates is lower than under the bivariate
model (and more precisely estimated) at 0.17 (0.13, 0.21). The element σ31
of the covariance matrix is signiﬁcantly negative, so that the registration rate
for blacks is inversely related to the percent of voters who are black.
3.8
Discrete Mixtures and Nonparametric
Smoothing Methods
Hierarchical models for pooled inferences or density estimation based on a
single underlying population with a speciﬁc parametric form are often a

Hierarchical Estimation for Exchangeable Units
117
simpliﬁcation. Pooling strength applications such as meta-analysis and density
estimation are often seeking to identify the main features of the data, or to
predict further observations ynew via the predictive distribution p(ynew|y), and
a single population model may not be appropriate for data exhibiting asymme-
try, multiple modes, isolated outliers, or outlier clusters (Mohr, 2006). While
the standard densities can be extended (e.g., to reﬂect asymmetry), mixtures
of standard densities (normal and t densities) can be used to represent a wide
variety of density shapes (Everitt and Hand, 1981). Use of a single population
density model in such circumstances will provide improper pooling and poor
predictions for a new unit (Hoﬀ, 2003). For example, a normal random-eﬀects
analysis of hospital mortality rates may shrink extreme rates considerably,
and this might mask potentially unusual results for units with smaller totals
of patients at risk (Ohlssen et al., 2007).
Among the principles that govern robust smoothing and regression meth-
ods for nonstandard densities are discrete mixing of densities over K > 1 sub-
populations (Bohning, 1999) and various types of local regression based on
kernel or smoothness priors (Muller et al., 1996). In this chapter, the focus is
on discrete mixture modeling, where the Bayesian approach has been coupled
with many recent advances. These include the Bayesian analogue to nonpara-
metric maximum likelihood estimation, with MCMC implementation as set
out by Diebolt and Robert (1994), Richardson and Green (1997), and Robert
(1996) and numerous developments of the Dirichlet process (DP) methodol-
ogy as reviewed by Hanson et al. (2005). The Bayesian approach is ﬂexible in
terms of prior structures that can be imposed in estimation, either grounded
in substantive theory, or to improve deﬁnition of the subgroups (e.g., Robert
and Mengersen, 1999). On the other hand, repeated sampling without ap-
propriate parameter constraints is subject to “label switching,” since label-
ing of the subgroups is arbitrary (Chung et al., 2004; Fruhwirth-Schattner,
2001).
3.8.1
Finite mixtures of parametric densities
In a discrete parametric mixture model, a single parametric density is typi-
cally assumed in each subpopulation, k ∈(1, . . . , K), but a diﬀerent hyper-
parameter, ψk, so that within this subpopulation, y ∽p(y|ψk). Unobserved
subgroup or allocation indicators Si ∈(1, . . . , K) describe how the units are
distributed over subpopulations. These are also known as conﬁguration indi-
cators (Gopalan and Berry, 1998). The joint or complete data density p(y, S)
can be written,
p(yi, Si) = p(yi|Si)p(Si) = p(yi|ψSi)πSi,
where p(y|S)
=
p(y|ψS) is the density for yi conditional on Si, and
{π1, . . . , πK} are the prior subgroup probabilities, with K
k=1 πk = 1. The
unconditional or marginal density for a single yi is

118
Applied Bayesian Hierarchical Methods
p(yi|π1, . . . , πK, ψ1, . . . , ψK) =
K

k=1
πkp(yi|ψk),
with the total likelihood (Diebolt and Robert, 1994) being
p(y|π, ψ) =
n

i=1
K

k=1
πkp(yi|ψk).
Classical analysis via nonparametric maximum likelihood estimation
involves maximization of the log of this marginal density—for example, see
Rattanasiri et al. (2004) for a disease mapping application, where yi are
malaria counts and p(y|ψ) is a Poisson density.
In MCMC applications, discrete mixture models can be represented hi-
erarchically using the latent subpopulation indicators (Marin et al., 2005,
462). Thus at the highest stage or level are the parameters ϕ = (π1, . . . , πK,
ψ1, . . . , ψK), then the missing conﬁguration data, the distribution of which
depends on ϕ,
Si ∼P(Si|ϕ),
and at the lowest (ﬁrst) stage the distribution of the observations p(y|ϕ, S)
depends on both ϕ and S = (S1, . . . , Sn). The joint distribution is therefore,
p(y, S, ϕ) = p(y|S, ϕ)p(S|ϕ)p(ϕ).
3.8.2
Finite mixtures of standard densities
There is a considerable literature on univariate and multivariate normal mix-
tures for continuous data, and on Poisson and binomial mixtures for discrete
data, with Bayesian references including Hurn et al. (2003), Militino et al.
(2001), Richardson and Green (1997), and Roberts et al. (1998). Overdis-
persed or skew alternatives to the major densities can be used in discrete
mixtures instead: for continuous data, the Student t distribution involves an
additional tuning parameter useful for outlier accommodation, and greater
robustness to such points may be obtained by discrete mixtures over univari-
ate and multivariate Student t densities with varying degrees of freedom (Lin
et al., 2004). Discrete mixtures of skew normal and skew Student t densities are
considered by Lin et al. (2007a, 2007b). Lin et al. (2007a) argue that a simple
normal discrete mixture model tends to overﬁt when additional components
are added to capture skewness in continuous data.
Parameter sampling via MCMC is facilitated by conjugate prior choices
for the mixing density. For example, consider a univariate normal mixture
with ψk = (µk, σ2
k), and
p(y|π, µ, σ) =
K

k=1
πkφ(y|µk, σk),

Hierarchical Estimation for Exchangeable Units
119
where φ(y|µ, σ) is the normal density, N(µ, σ2). The conjugate prior for ψk =
(µk, σk) takes σ2
k ∽IG(νk/2, Vk/2), namely,
p(σ 2
k) ∝σ−νk−1
k
exp

−Vk/2σ2
k

,
and
p

µk|σ2
k

= N

ξk, σ2
k
κk

.
Also assume a Dirichlet prior for the unknown mixture probabilities
(π1, . . . , πK) ∽Dir(α, . . . , α), with α preset or possibly an extra unknown.
Gibbs sampling then samples the missing data (the allocation indicators)
according to a multinomial density with probabilities at iteration t,
p

S(t)
i
= k|π(t), µ(t), σ(t)
= ρ(t)
ik =
π(t)
k φ(yi|µ(t)
k , σ(t)
k )
K
k=1 π(t)
k φ(yi|µ(t)
k , σ(t)
k )
.
Let d(t)
ik = 1 if S(t)
i
= k and d(t)
ik = 0 otherwise. Suppose N (t)
k
= #{S(t)
i
= k}
is the total number of cases with S(t)
i
= k, that m(t)
k
=  d(t)
ik yi/N (t)
k
is the
average response for these cases, and that E(t)
k
=  d(t)
ik (yi −m(t)
k )2 is the sum
of squared errors for this subgroup. Then, with conditioning on remaining
parameters understood, the πk are updated according to a Dirichlet with

π(t)
1 , π(t)
2 , . . . , π(t)
K

∽D

α + N (t)
k , α + N (t)
2 , . . . , α + N (t)
K

,
the subgroup variances are sampled from an updated inverse gamma,
σ2(t)
k
∽IG

0.5

νk + N (t)
k
 
, 0.5

Vk + E(t)
k
+
N (t)
k κk
κk + N (t)
k

ξk −m(t)
k

,
and the subgroup means are updated according to
µ(t)
k
∽N

κkξk + N (t)
k m(t)
k
κk + N (t)
k
,
σ2(t)
k
κk + N (t)
k

.
Diebolt and Robert (1994) suggest stabilizing adjustments to these updates
to improve convergence. A reﬁnement is to take the mixture proportions as
subject-speciﬁc as in (πi1, . . . , πiK) ∽Dir(α, . . . , α), and in the updates for
π(t)
ik , the N (t)
k
are replaced by binary indicators according to which class sub-
ject i is allocated to at a particular iteration.
3.8.3
Inference in mixture models
Parametric mixture models such as the univariate normal just considered are
subject to identiﬁcation issues due to the arbitrariness of the subpopulation

120
Applied Bayesian Hierarchical Methods
labels. Another form of identiﬁability relates to potential overﬁtting (e.g.,
K taken too large) (Fr¨uhwirth-Schnatter, 2006, 107). To illustrate label iden-
tiﬁability, in the absence of parameter constraints or other prior information
to distinguish the components, the likelihood is invariant under permutation
of the components and there are K! possible labeling schemes. It is essential
to produce MCMC draws with a unique labeling if interest lies in the estima-
tion of group-speciﬁc parameters or classiﬁcation probabilities, πk (Fr¨uhwirth-
Schnatter et al., 2004). Note though that inferences on some aspects of the
model are unaﬀected by group labeling—for example, the unit means that pool
over the population-wide category means. Cluster labeling issues are also not
generally considered in the Dirichlet process approach (Section 3.9), where
the emphasis is on the smoothed unit means.
Identifying (usually ordering) constraints may be imposed on parameters
to avoid label switching (Richardson and Green, 1997; Roeder and Wasserman,
1997). Label switching refers to permuting the mixture component subscripts
without altering the likelihood (Redner and Walker, 1984). However, Celeux
et al. (2000), Geweke (2007), and Marin et al. (2005) consider drawbacks to
such identiﬁability constraints (e.g., distortions of the posterior distribution
of the parameters). For example, in a normal mixture, constraints may be im-
posed on prior masses, πk (e.g., π1 > π2 > · · · > πK), or on the subpopulation
parameters, µk, or on the scale parameters, σk. A preliminary MCMC sam-
pling analysis without parameter constraints may be used to assess the most
suitable form of constraint (Fruhwirth-Schattner, 2001). Another possibility
is to use maximum likelihood solutions (e.g., using the R package ﬂexmix) to
set constraints and/or relatively informative priors that are sensible for the
dataset. Reanalysis of the posterior output to impose a consistent labeling is
another possibility (Fr¨uhwirth-Schnatter, 2001), as are data-based priors, al-
beit not fully Bayesian (Wasserman, 2000). For example, in a two group model
without regression on predictors, the unit with the maximum y value could
be prelabeled as belonging to one or other subpopulation. Diebolt and Robert
(1994) suggest excluding MCMC samples where the conﬁguration indicators
all fall into one group.
Particular types of parameterization may be used to improve identiﬁca-
tion. Robert (1996) and Robert and Mengersen (1999) suggest introducing
dependence between the parameters, ψk, in diﬀerent components such that
they are perturbations of one another. For example, a normal mixture model
with ψk = (µk, σ2
k) would be based on taking {θ1, σ2
1} as reference parameters
and adopting the parameterization,
σ2 = σ1ω1,
σ3 = σ2ω2,
σ4 = σ3ω3,
· · ·
σK = σK−1ωK−1 = σ1ω1ω2 · · · ωK−1,

Hierarchical Estimation for Exchangeable Units
121
where ωk ∽U(0, 1). With θ1 = µ1, the prior on the series of normal means
takes a perturbation form,
µ2 = θ1 + σ1θ2,
µ3 = θ1 + σ1θ2 + σ1σ2θ3,
· · ·
µK = θ1 + σ1θ2 + σ1σ2θ3 + · · · + (σ1σ2 · · · σK−1)θK.
The mixture weights have the form,
π1 = p1,
π2 = (1 −p1)p2,
π3 = (1 −p1)(1 −p2)p3,
· · ·
πK−1 = (1 −p1)(1 −p2) . . . (1 −pK−2)pK−1,
πK = (1 −p1)(1 −p2) . . . (1 −pK−1),
with pk ∽U(0, 1). This prior is still invariant under permutation of the clus-
ter indices and an indentifying constraint is placed on the variances by taking
1 ≥ω1 ≥· · · ≥ωK−1. An advantage of this representation is that an im-
proper prior on {µ1, σ2
1} can be used (Robert and Titterington, 1998). For
the two group case, Basu (1996) presents the parameterization ν = σ2
1/σ2
2 and
∆= (µ2 −µ1/σ1) to test for normal or Student t unimodality as against bi-
modality; posterior probabilities of unimodality are obtained using the results
of Robertson and Fryer (1968).
Celeux et al. (2000) and others apply postprocessing to the MCMC output
resulting from a discrete mixture analysis without parameter constraints; the
goal is to reconﬁgure the output with a consistent labeling. Suppose there are
p parameters in any subpopulation. If MCMC convergence is assumed, one
may select a short run of iterations (say S = 100 iterations) where there is no
label switching to provide a reference labeling. The initial run of parameter
samples provides a base reference label sequence, 1, 2, . . . , K (one among the
K! possible), and K means of dimension, p, ¯θk = {¯θ1k,¯θ2k, . . . ,¯θpK}, that can
be permuted to include all other remaining K!−1 possible labeling schemes. In
a subsequent run of R iterations where label switching might occur, iteration
r is assigned to that scheme (among the K!) closest to it in distance terms and
a relabeling applied if there has been a switch away from the base reference
label. Additionally, the means under the schemes are recalculated at each
iteration, S + r (Celeux et al., 2000, 965).
3.8.4
Particular types of discrete mixture model
Heterogeneity within classes can be accommodated using discrete mixtures
for unit level conjugate or nonconjugate random eﬀects (Fruhwirth-Schnatter

122
Applied Bayesian Hierarchical Methods
et al., 2004; Lenk and DeSarbo, 2000). For example, the standard discrete mix-
ture to account for heterogeneity in count data involves K < n homogenous
subpopulations with means µ1, . . . , µK,
yi ∼
K

k=1
πkPo(µk),
where πk is the prior probability that a unit belongs to subpopulation k, with
K
k=1πk = 1. Alternatively, accounting for heterogeneity within subpopula-
tions would involve K Poisson-gamma subgroups,
yi ∼Po(µi),
µi ∼
K

k=1
πkGa(ak, bk),
or K Poisson-lognormal subgroups,
yi ∼Po(µi),
µi ∼
K

k=1
πkLN (µk, σ2
k),
where LN (m, V ) denotes a lognormal density with mean m and variance V .
Discrete mixtures can also be used to modify the shape of standard den-
sities such as the Poisson or binomial. For example, a manufacturing process
may move between diﬀerent regimes, one where faults are essentially unknown
and another where they occur according to a Poisson process. This will gen-
erate excess zeroes as compared to the standard Poisson, leading to a zero
inﬂated Poisson (ZIP). One may introduce a binary regime indicator, Si, with
marginal probability π = Pr(Si = 1) that the fault-free regime applies, and
(1−π) that sampling is from a Poisson density with mean µ. In more general-
ity, with p(y|ψ) as a density for count data (e.g., Poisson, negative binomial,
binomial), the corresponding zero-inﬂated density is
p(y = 0|π, ψ) = π + (1 −π)p(y = 0|ψ)
y = 0,
p(y|π, ψ) = (1 −π)p(y|ψ)
y > 0.
Conditionally, Pr(Si = 1|y > 0) = 0, while
Pr(Si = 1|y = 0) =
π
π + (1 −π)p(y = 0|ψ).
The process generating the Si needs only to be considered for zero obser-
vations, yi = 0, and the complete data likelihood (assuming Si to be given) is
L(π, ψ|y, S) =

yi>0
(1 −πi)p(yi|ψ)

yi=0
πSi
i [(1 −πi)p(0|ψi)]1−Si.

Hierarchical Estimation for Exchangeable Units
123
For example, if p(y|ψ) is taken to be Poisson with mean ψ = µ, then E(y|
π, µ) = (1 −π)µ and
V (y|π, µ) = (1 −π)µ(1 + πµ) > E(y|π, µ),
so that the ZIP model is necessarily overdispersed8.
3.8.5
The logistic-normal alternative to the Dirichlet prior
A generalization of the logistic-normal to multivariate contexts has been ap-
plied to nonparametric analysis and by authors such as Aitchison and Shen
(1980), Hoﬀ(2003), and Lenk (1988). The goal is to replace the restrictive
Dirichlet prior for the unknown mixture probabilities, πk, with a multino-
mial logistic framework. Consider the case where units are exchangeable, and
there are no covariates relevant to allocation between subpopulations. Then
for subjects or units i = 1, . . . , n, and assuming,
yi ∽
K

k=1
πikpk(yi|ψk),
the mixing probabilities are obtained as,
πik =
ezik
1 + K
k=1ezik ,
k = 1, . . . , K −1,
πiK =
1
1 + K
k=1ezik ,
where the {zik, k = 1, . . . , K −1} are multivariate normal with mean ν and
variance Σz. For example, Hoﬀ(2003) argues for the use of normal mixtures in
density smoothing and in this case the pk(y|ψk) would be univariate or mul-
tivariate normal themselves. This approach generalizes to multivariate skew
normal or multivariate Student t densities, and can be adapted to allow nonex-
changeable mixture priors, as in histogram smoothing (Leonard, 1973).
Instead of subject-speciﬁc zik, one may also assume a single vector
{z1, . . . , zK−1} to be multivariate normal. For unique identiﬁcation of the sub-
groups, one may impose order constraints on the parameters in ψk or on those
underlying {z1, . . . , zK−1}. In the univariate normal case with ψk = {µk, σ2
k},
one might assume an ordering either on the means µk, or on the means νk of
the zik.
Example 3.6. Galaxy Data
The number of clusters detected in the much
analysed galaxy data has varied over diﬀerent studies, under the model,
yi ∽
K

k=1
πkN

µk, σ2
k

,
and y being measured in thousands of kilometers per second. A classical anal-
ysis using the ﬂexmix package (Leisch, 2004) in R shows no gain in moving

124
Applied Bayesian Hierarchical Methods
beyond four clusters, whereas Ishwaran and James (2002) ﬁnd at least ﬁve to
six clusters with a Dirichlet process approach and under an inverse gamma
prior for the σ2
k. They do, however, ﬁnd only four clusters when a uniform
prior U(0, 20.83) is used for σ2
k with 20.83 being the observed variance, V (y).
Ando (2007) reports six clusters (assuming a monotonic constraint on the µk)
via several model ﬁt criteria.
Here, K is taken to be 6 with an identiﬁability constraint on the normal
means applied, together with additional data-based features to ensure sensible
inferences. Thus, µ1 is taken to be normal with a minimum of 9.176, namely,
to be at least as large as the minimum y value. Then µk = µk−1+δk, where the
increments are distributed Ga(1, 0.001) with a maximum of 20. Without the
latter constraint, implausibly large µ6 values were sometimes sampled. Diﬀuse
Ga(1, 0.001) priors are assumed on 1/σ2
k. Initial values for a two chain run
were based on an initial single chain run with trial values for parameters.
Using these initial values, convergence9 is attained by iteration 2,000 in a
run of 10,000 iterations and the clusters means (with their posterior standard
deviations) are obtained as {9.7 (0.16), 16.1 (0.05), 19.8 (0.17), 22.7 (0.43),
28.2 (2.5), 33.9 (3.0)}, while the mean cluster probabilities are {0.092, 0.034,
0.34, 0.46, 0.034, 0.04}. The mean BIC is 461, obtained using the posterior
mean of minus twice the likelihood of the marginal density,
p(y|π, µ, σ) =
K

k=1
πkφ(y|µk, σk),
and adding a penalty based on the known parameter total. While an appar-
ently sensible model, replicate samples ynew for some data points are biased
away from the observations; for example, both y6 = 10.23 and y7 = 10.41
have posterior predictive means and 95% intervals of 9.7 {8.7, 10.6}, while
observations y48 to y77 vary from 21.8 to 25.6, but have posterior predicted
means between 22.5 and 22.8.
To illustrate the logistic-normal approach, the same number of subgroups
is assumed, with the same priors on the component group normal parameters
{µk, σ2
k}. N(0, 1000) priors are adopted on the νk parameters and a Wishart
with 5 degrees of freedom and identity scale matrix assumed for Σ−1
z . The ﬁt
obtained is very similar to that under a Dirichlet prior. Replicate data, ynew,
sampled from the model still do not reproduce observations y6 and y7 very
closely, and show a ﬂat proﬁle for observations 48 to 77, with ynew around 22.6.
3.9
Nonparametric Mixing via Dirichlet Process
and Polya Tree Priors
In applications of hierarchical models, inferences may depend on the assumed
forms (e.g., normal, gamma) for higher stage priors, and will be distorted

Hierarchical Estimation for Exchangeable Units
125
if there are unrecognized features such as multiple modes in the underlying
second stage eﬀects. Instead of assuming a known prior distribution, G, for
second stage latent eﬀects, such as bi in the normal-normal model of Sec-
tion 3.3, the Dirichlet process (DP) prior involves a distribution on G itself,
so acknowledging uncertainty about its form (Gill and Casella, 2009). The DP
prior involves a baseline or base prior G0, the expectation of G, and a precision
or mass parameter, α, governing the concentration of the prior for G about
its mean G0. For any partition A1, . . . , AM on the support of G0, the vector
{G(A1), . . . , G(AM)} of probabilities G(Am) contained in the set {Am, m =
1, . . . , M} follows a Dirichlet distribution D(αG0(A1), . . . , αGM(AM)).
Original forms of the DP prior assumed G0 to be known (ﬁxed). One
problem with a DP when G0 is known is that it assigns a probability of 1
to the space of discrete probability measures (Hanson et al., 2005, 249). An
alternative is to take the parameters in G0 to be unknown, and to follow
a set of parametric distributions, with possibly unknown hyperparameters,
resulting in a mixture of Dirichlet process or MDP model (Walker et al.,
1999, 489). General computational procedures for such models are discussed
by Jara (2007) and Ohlssen et al. (2007).
Following West et al. (1994), assume conventional ﬁrst stage sampling
densities yi ∽p(yi|bi, ψ), with distributions P(yi|bi, ψ). The uncertainty about
the appropriate form of prior arises about the distribution G for the latent
eﬀects bi. Under a DP prior, any set of unit-speciﬁc parameters {b1, . . . , bn}
generated from G lies in a set of K ≤n distinct values {ζ1, . . . , ζK}, which are
sampled from G0. The concentration parameter α governing the closeness of
G to G0 can be taken as an unknown, or assigned a preset value (e.g., α = 1).
The number of distinct values or clusters K is stochastic, with an implicit prior
determined by α, with limiting mean α log(1 + n/α). Note that the posterior
mean of K is not necessarily a reliable guide to the number of components in
the data or eﬀects (e.g., components with substantive meaning), though it can
be interpreted as an upper bound on the number of components (Ishwaran and
Zarepour, 2000, 381–82). Related algorithms include the Chinese Restaurant
process (Ishwaran and James, 2003), a method for randomly assigning objects
to groups that results in samples having the equivalent sampling distribution
as that obtained by the Dirichlet Process.
Given the realised number of clusters K (at any particular MCMC iter-
ation), bi are sampled from the set {ζ1, . . . , ζK} according to a multinomial
distribution. Deﬁne cluster indicators S = {S1, . . . , Sn}, where Si = k if
bi = ζk and denote Nk = #{Si = k} as the total number of units with Si = k
(i.e., units in the same cluster with a common value ζk for the second stage
latent eﬀect). If α is taken as unknown, its prior is important in determining
the number of clusters. Taking α ∽Ga(η1, η2) where η1 and η2 are relatively
large will tend to discourage unduly small or large values for α. Typical values
are η1 = η2 = 1 or η1 = η2 = 2, though taking η2 > η1 as in {η1 = 2, η2 = 4}
tends to encourage repetitions in ζk, and can be used to assess the number
of components present in the data (Ishwaran and Zarepour, 2000, 377). It is
clear that the parameters used in the prior for α may aﬀect the number of

126
Applied Bayesian Hierarchical Methods
components, but typically there is less concern with this aspect in nonpara-
metric mixture modeling (Leslie et al., 2007).
Consider the assignment of a latent eﬀect bi to a particular unit, given
that the remaining n −1 latent eﬀects b[i] = {b1, . . . , bi−1, bi+1, . . . , bn} are
already assigned. Also let S[i] be a particular conﬁguration of the remaining
n −1 eﬀects in b[i] into K[i] distinct values, with N[i]k = #{Si = k, k ̸= i}
denoting the total of those n −1 units having a common value ζ[i]k. Then the
conditional prior for bi follows a Polya urn scheme (Dunson et al., 2007, 165;
Hanson et al., 2005, 252; West et al., 1994),

bi|b[i], S[i], K[i], α

∽
α
α + n −1G0 +
1
α + n −1

k̸=i
δ(bk)
∽
α
α + n −1G0 +
1
α + n −1
K[i]

k=1
N[i]kδ(ζ[i]k),
(3.5)
where δ(u) denotes a degenerate distribution having a single value at u. So
bi is distinct from the remaining latent values with probability (α/α + n −1),
in which case it is drawn from the base prior G0. Alternatively it is selected
from the existing distinct eﬀects, ζ[i]k, according to a multinomial with prob-
abilities proportional to (N[i]k/α + n −1). This selection scheme extends to
the predictive scenario, i.e., to the latent eﬀect for a hypothetical new unit
n + 1, with
(bn+1|b, S, K, α) ∽
α
α + nG0 +
1
α + n
K

k=1
Nkδ(ζk).
Predictions of the ﬁrst stage response for unit n + 1 are obtained as,
(yn+1|b, S, K, α) ∽
α
α + nPn+1(|ζn+1) +
1
α + n
K

k=1
NkPn+1(|ζk),
where ζn+1 is an extra draw from G0. Predictions beyond n+1 may be relevant
in panel or time series applications (Hirano, 1998).
In terms of Gibbs sampling, Equation 3.5 implies conditional posteriors
(Ishwaran and James, 2001, 166; Neal, 2000; West et al., 1994, 367),
(bi|y, b[i], S[i], K[i], α) ∽αqi0g0(bi|y)p(yi|bi) +
K[i]

k=1
qikδ(ζ[i]k),
where g0(bi|y) is the density corresponding to G0 evaluated at bi, and where
qi0 =

p(yi|bi)g0(bi)dbi
qik = N[i]kp(yi|ζ[i]k)
k > 0.
(3.6)

Hierarchical Estimation for Exchangeable Units
127
Normalizing the values αqi0 and qik to probabilities {ri0, ri1, . . . , riK[i]}
summing to 1, the conditional posteriors for the subgroup indicators are then,
Pr

Si = k|y, b[i], S[i], K[i]

= rik,
where Si = 0 corresponds to drawing a new sample from G0 under the Polya
urn scheme.
3.9.1
Specifying the baseline density
An important aspect of the MDP framework is the speciﬁcation of G0. Assume
there are p parameters, (ψ1, . . . , ψp), in G0, then one has
yi|bi ∽p(yi|bi),
b1, . . . , bn|G,
G|α, G0 ∽DP(αG0),
G0 = {p01(ψ1|ξ1), . . . , p0p(ψp|ξp)},
where ψ1, . . . , ψp are unknown, and also possibly some of the deﬁning ξ pa-
rameters. Consider a normal mixture with both means and variances possibly
diﬀering for each unit (Cao and West, 1996; Hirano, 2002), namely,
yi ∽N(µi, σ2
i ).
The appropriate prior G for bi = (µi, σ2
i ) is not certain, therefore,
(µi, σ2
i ) ∽G,
G ∽DP(αG0),
where G0 involves the priors µi ∽p01(µi|ξ1), σ2
i ∽p02(σ2
i |ξ2), with ξ1 and ξ2
possibly including further unknowns. For example, Hirano (2002) takes,
1/σ2
i ∼χ2(s)/(sQ),
and
µi ∼N

m, cσ2
i

,
where s, Q, m, and c are speciﬁed but may be varied in a sensitivity analysis.
The marginal distribution of yi (averaged over all possible G) in this case is
a mixture of normal distributions, with the number of subgroups, K, randomly
varying between 1 and n. The n unit-speciﬁc parameter pairs, bi = (µi, σ2
i ),
are selected under G from the set of K[i] possible values, ζk = (µk, σ2
k), already
drawn from G0, or by fresh sampling from G0. The qih in Equation 3.6 are
then obtained as
qi0 =

1
σi
√
2πe−(yi−µi)2/2σ2
i g0(µi, σ2
i )dµidσ2
i ,
qik = N[i]k
1
σk
√
2πe−(yi−µk)2/2σ2
k
k > 0.

128
Applied Bayesian Hierarchical Methods
As another example, Kleinman and Ibrahim (1998) consider Gibbs updates in
an MDP framework for parameters in general linear mixed models for nested
data. For example, let Xi and Zi be predictors of dimension q and r (possibly
overlapping) and consider repeated data, yit, over subjects i, with observation
vectors yi = (yi1, . . . , yiT) and ﬁrst stage model,
yi ∼N

Xiβ + Zibi, σ2
,
where one may assume conventional normal and inverse gamma priors for
β and σ2. However, for bi = (bi1, . . . , bir), greater ﬂexibility is obtained by
taking,
bi ∽G,
G ∽DP(α, G0),
where G0 is the multivariate normal of dimension r, with mean 0 but unknown
covariance D. The Wishart distribution in the Gibbs update for D−1 is mod-
iﬁed for clustering of values among the sampled bi (Kleinman and Ibrahim,
1998, 94).
3.9.2
Truncated Dirichlet processes
and stick-breaking priors
Implementation may be simpliﬁed if an alternative way to generate the DP
prior is adopted. The basis of this alternative scheme is to regard the density
of the unit level eﬀects, bi, as an inﬁnite mixture of point masses or continuous
densities (Hirano, 1998; Ohlssen et al., 2007), with
bi ∼
∞

k=1
πkh(bi|ψk).
This approach is called a Dirichlet process mixture by Hanson et al. (2005,
250) and a dependent Dirichlet process by Dunson et al. (2007, 164). For
practical application, Ishwaran and James (2002) and Ishwaran and Zarepour
(2000) suggest the inﬁnite representation be approximated by one truncated
at M ≤n components with
g(b) =
M

m=1
πmh(b|ψm),
where πm are sampled by introducing M −1 beta distributed random vari-
ables,
Vm ∽Be(cm, dm),
with VM = 1 to ensure the random weights, πm, sum to 1 (Ishwaran and
James, 2001; Sethuraman, 1994). Then π1 = V1 and
πm = (1 −V1)(1 −V2) · · · (1 −Vm−1)Vm
m > 1.

Hierarchical Estimation for Exchangeable Units
129
This method of generation is known as stick breaking, since at each stage,
the procedure randomly breaks what is left of a stick of unit length and assigns
the length of the break to the current πm.
Following Pitman and Yor (1997), the beta parameters {cm, dm} in the
prior for Vm can be written as cm = 1 −c, dm = d + mc, where c ∈[0, 1) and
d > −c. For an inﬁnite dimensional mixture, the Dirichlet process is obtained
by taking c = 0 and d = α, so that Vm ∽Be(1, α). When a ﬁnite (truncated)
mixture is used, setting cm = 1 + c/M and dm = α −mα/M = α(1 −m/M)
is asymptotically equivalent to the DP process (Ishwaran and James, 2001;
Ishwaran and Zarepour, 2002).
However, using an approximate DP scheme with Vm ∽Be(1, α) and M
large is equivalent to the inﬁnite DP process for practical purposes (Ishwaran
and James, 2002; Ishwaran and Zarepour, 2000, 383). If a Ga(η1, η2) prior is
used for α, its full conditional is α ∽Ga(M + η1 −1, η2 −log(πM)) (Ishwaran
and Zarepour, 2000, 387). The realized number of clusters is K ≤M as above,
and Ishwaran and James (2002) suggest AIC and BIC penalties based on K
that can be used for model selection.
Taking Vm ∽Be(α, 1) rather than Vm ∽Be(1, α) in the truncated stick-
breaking scheme means that larger values of α now imply greater clustering
into a few subpopulations. This is an example of the beta process priors con-
sidered by Ishwaran and Zarepour (2000). Other truncated mixture sampling
schemes that start with a prior on α to give an implicit prior on a stochas-
tic K are available. For example, Ishwaran and Zarepour (2000, 376) consider
taking α as an unknown in,
(π1, . . . , πM) ∽D
 α
M , α
M , . . . , α
M

.
Alternatively, Green and Richardson (2001, 357) start oﬀwith a prior
on K and then select the cluster indicators from a multinomial vector with
probabilities p(Si = k) = πi, where (π1, . . . , πK) follow a Dirichlet density
D(δ, . . . , δ). They refer to this as an explicit allocation prior and show how the
DP prior is obtained as K →∞and δ →0 in such a way that Kδ →α > 0.
3.9.3
Polya Tree priors
The Polya Tree (PT) is a more general class than the Dirichlet process and
has the beneﬁt that it can place probability 1 on the space of continuous
densities (Hanson et al., 2005; Walker et al., 1999). In essence, if the support
of a parameter ω is denoted Γ then the PT prior chooses the most appropriate
value for ω by successive binary partitioning of Γ. The ﬁrst partition splits
Γ into two disjoint sets {B0, B1}; the probabilities of moving into B0 and B1
are C00 and C01 = 1 −C00, with C00 set to 0.5. At the second partition, B0 is
split into {B00, B01} and B1 is split into {B10, B11}, so there are 22 sets. At
the third partition, B00 is split into {B000, B001}, B01 into {B010, B011}, B10
into {B100, B101}, and B11 into {B110, B111}, so there are 23 sets. Generally,
the number of sets at the mth partition is 2m.

130
Applied Bayesian Hierarchical Methods
The partition probabilities at second and subsequent stages are unknown.
Let ε denote a sequence of 0s and 1s. For example, suppose B1 is selected at
step 1 and B11 is selected at step 2, then ε = [1, 1]. The choice at the next
stage between sets Bε0 and Bε1 (i.e., between B110 and B111) is governed by
probabilities (Cε0, Cε1), with a beta prior for Cε0, and Cε1 = 1 −Cε0. The
canonical form for the prior on the partition probabilities at partition m is
Cε0 ∽Be(cm, cm),
cm = dm2,
where d may be taken as an extra unknown. The Dirichlet process occurs
when cm = d/2m, so that cm →0 as m →∞, whereas cm →∞as m →∞is
appropriate if the underlying distribution G is expected to be continuous.
While, theoretically, the completely continuous case corresponds to
m →∞, in practice the partitioning is truncated at a ﬁnite value M. Hanson
and Johnson recommend M = log2(n), where n is the sample size. The parti-
tions can be taken to coincide with percentiles of G0, so for example,
B0 =

−∞, G−1
0 (0.5)],
B1 = [G−1
0 (0.5), ∞

;
B00 =

−∞, G−1
0 (0.25)],
B01 = [G−1
0 (0.25), G−1
0 (0.5)],
B10 = [G−1
0 (0.5), G−1
0 (0.75)],
B11 = [G−1
0 (0.75), ∞

;
and so on. Let dki at partition k and option i be a re-expression of the Bε
(e.g., for k = 3, d31 = B000, d32 = B001, d33 = B010, d34 = B011, d35 = B100,
d36 = B101, d37 = B110, d38 = B111). Then at partition k, for i = 1, . . . , 2k,
the interval boundaries are
dki =

G−1
0

i −1
2k

, G−1
0

 i
2k

,
with appropriate modiﬁcations for the extreme tails.
For example, consider a PT prior on unstructured errors in a Poisson
lognormal mixture, with
yi ∽Po(µi),
log(µi) = β + σbi.
Then G0 for vi = σbi is a N(0, σ2) density, with G0 for bi being a N(0, 1)
density. So with M = 3 levels, the relevant ordinates from G0 for deﬁning the
eight intervals are (−1.15, −0.67, −0.32, 0, 0.32, 0.67, 1.15).
Example 3.7. Nicotine Replacement Therapy
Xia et al. (2005) ana-
lyzed the NRT trials data of Example 3.1 and detected K = 2 subpopulations
using a discrete mixture of normals model with
yi ∼N(bi, s 2
i ), with s 2
i
known, and
bi ∼
K

k=1
πkN

µk, τ2
k

.

Hierarchical Estimation for Exchangeable Units
131
They found one subgroup to have a nonsigniﬁcant treatment eﬀect, with
its µ parameter straddling zero. Here we consider both a conventional dis-
crete normal mixture with K = 2, and a DP-based mixture. In the former,
a monotonicity constraint is applied to the µk. The mean likelihood of this
model was improved by taking relatively informative N(0, 1) priors on µk and
Ga(1, 1) priors on 1/τ2
k; these may be judged reasonable in terms of the likely
range of treatment-control log odds ratios typically encountered in trials.
With inferences based on the second half of a two chain run of 10,000 iter-
ations, the average likelihood stands at −56 compared to −62 for a standard
normal-normal model with K = 1. Posterior means for µk (and 95% credi-
ble intervals) are found to be 0.38 (−0.83, 0.76) and 0.93 (0.55, 2.19), with
respective component probabilities 0.48 and 0.52. Sampling replicate data,
yrep,i, shows the observations to be reproduced eﬀectively with no posterior
probabilities, Pr(yrep,i > yi|y), exceeding 0.05 or 0.95, and in fact varying
between 0.11 and 0.88.
In the DP model, conventional priors for {bi, µk, τ2
k} are replaced by a
DPM structure (Section 3.9) with bi = ζk when Si = k and where the realised
number of clusters is K ≤M, where a maximum of M = 20 possible clus-
ters is assumed. The M potential values {µm, τ2
m} are sampled from normal
densities with means µm ∽N(mµ, 1), where mµ is itself unknown, and with
1/τ2
m ∽G(1, 1). A Ga(3, 3) prior is assumed on the Dirichlet concentration
parameter α.
A two chain run10 of 5000 iterations shows convergence in α, K, and the
latent eﬀects b after around 1000 iterations. The posterior mean and median
of K are, respectively, 3.5 and 3, supporting a relatively small number of
components in the second stage prior of NRT eﬀects; α has a posterior mean
of 0.78. A plot of the posterior means of the bi does not show sharply distinct
subgroups (Figure 3.2), though outliers can be seen, such as trial 36, a trial
with a relatively large number of subjects in the “women, long term follow-
up category” in Cepeda-Benito et al. (2004). However, the eﬀects show more
peakedness than under a normal density (superimposed plot).
Sampling replicate data, yrep,i, shows the observations to be reproduced
eﬀectively with no posterior probabilities, Pr(yrep,i > yi|y), exceeding 0.05 or
0.95, and in fact varying between 0.09 and 0.93. The latter value for Pr(yrep,i >
yi|y) is for trial 66 where rT is only 2 (from NT = 86 in the treatment group).
Example 3.8. Eye-Tracking Data
Escobar and West (1998) present
count data on eye-tracking anomalies in schizophrenic patients (n = 101). The
data are overdispersed and the ﬁrst analysis assumes a DP Poisson-gamma
mixture with G0 being a gamma density with unknown shape and scale pa-
rameters. So,
yi ∽Po(bi),
bi ∽G,
G ∽DP(αG0),
G0 = Ga(cg, dg).

132
Applied Bayesian Hierarchical Methods
Smoothed trial effects
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
0
10
20
30
40
50
60
Frequency
FIGURE 3.2
Histogram of smoothed trial eﬀects.
Taking cg and dg to be unknowns results in an MDP prior, which is imple-
mented using the Polya urn prior (Equation 3.5). A Ga(1, 1) prior is assumed
on α, and exponential E(1) priors on the parameters (cg, dg) with a minimum
of 0.5 on cg for numerical stability.
In line with Marshall and Spiegelhalter (2003), the observed yi are com-
pared with replicates sampled from the predictive distribution p(yrep|y) to see
if yi are at odds with the model. Discrepancies could be due to genuine outlier
status, or to model failures. For discrete data, the relevant p-value is
Pr(yrep,i < yi) + 0.5Pr(yrep,i = yi).
A related check is whether the 95% intervals for yrep,i include yi (Gelfand,
1996).
From the last 4000 iterations of a two chain run11 of 5000 iterations in
OpenBUGS, an average of K = 12 distinct clusters is obtained, with poste-
rior mean (sd) for α, cg, and dg of 2.86 (1.5), 0.77 (0.27), and 0.13 (0.06).
Figure 3.3 shows the prediction ynew for a new case, and demonstrates that
the main source of overdispersion is skewness in the latent frailties, bi, rather
than multiple modes. The predictive checks based on replicate samples are

Hierarchical Estimation for Exchangeable Units
133
ynew
0
10
20
30
P (ynew)
0.0
0.2
0.4
0.6
FIGURE 3.3
Prediction for new case.
satisfactory. Note that the same does not apply if the gamma mixing density
parameters are set, e.g., cg = dg = 1. In this case, bimodal posteriors are
obtained on some bi (e.g., b92) and predictive checks for y101 = 34 suggest it
to be an extreme observation.
A second analysis involves a Polya Tree prior in a Poisson-lognormal model,
namely, yi ∽Po(µi) with
log(µi) = β + σbi,
where G0 for vi = σbi is an N(0, σ2) density. The number of stages is set
at M = 4 and a Ga(1, 1) prior is assumed on 1/σ2. Once an interval, Bεm,
is selected, uniform sampling to generate bi takes place within the interval
deﬁned by G0, except in the tails where the sampling is from a N(0, 1).
As for the Polya urn model (with the same MCMC details), both types of
predictive check indicate no major discrepancies. σ has posterior mean (and
95% interval) 2.0 (1.6, 2.5). If σ is taken to equal 1 so that G0 is assumed
known, then predictive discrepancies do occur. Taking σ = 1 also leads to
bimodal posteriors for individual bi indicating a clash between prior and data,
such that the prior cannot accommodate certain values.
Appendix: Computational Notes
1. The code for the nicotine replacement example is
model {# predictions
ynew ∽dnorm(b.new,inv.s20); b.new ∽dnorm(mu,inv.tau2); OR.new <-
exp(ynew)

134
Applied Bayesian Hierarchical Methods
for (i in 1:n) {# empirical logits and sampling variances
y[i] <- log(rT[i]/(nT[i]-rT[i]))-log(rC[i]/(nC[i]-rC[i]))
s2[i] <- 1/rT[i] + 1/(nT[i]-rT[i]) + 1/rC[i] + 1/(nC[i]-rC[i]); inv.s2[i] <-
1/s2[i]
# observation model
y[i] ∽dnorm(b[i],inv.s2[i])
# second stage
b[i] ∽dnorm(mu,inv.tau2)}
inv.tau2 <- 1/tau2; s2.0 <- n/sum(inv.s2[]); inv.s20 <- 1/s2.0;
# uniform for average shrinkage
w ∽dunif(0,1); tau2 <- (s2.0-s2.0*w)/w
# posterior mean of NRTpos estimates probability of treatment beneﬁt
NRTpos <- step(mu);mu ∽dnorm(0,0.01);
# overall odds-ratio
OR.NRT <- exp(mu)}
Under the second stage t-prior the code for the latent eﬀects becomes
b[i] ∼dnorm(mu,prec[i]);
prec[i] <- inv.tau2*lam[i]
lam[i] ∼dgamma(nu.2,nu.2); step.lam[i] <- step(1-lam[i])}
2. A Q-Q plot may be obtained in R by pasting in the b[1:90] posterior means
in Example 3.1, naming the vector b, and then using the commands
> qqnorm(b)
> qqline(b)
The Shapiro-Wilk test may be obtained by loading the stats package, and then
using the command shapiro.test(b). The Jarque-Bera test may be obtained by
loading the tseries package, and then using the command jarque.bera.test(b).
3. The WinBUGS code for this model is
model {for (i in 1:n) {# deﬁne response
y[i,1] <- log(rT[i]/(nT[i]-rT[i])); y[i,2] <- log(rC[i]/(nC[i]-rC[i]))
S2[i,1,1] <- 1/rT[i] + 1/(nT[i]-rT[i]); S2[i,1,2] <- 0;
S2[i,2,1] <- 0; S2[i,2,2] <- 1/rC[i] + 1/(nC[i]-rC[i]);
# deﬁne hierarchical model
y[i,1:2] ∽dmnorm(b[i,1:2],Precy[i,1:2,1:2])
Precy[i,1:2,1:2] <- inverse(S2[i,1:2,1:2])
ynew[i,1:2] ∽dmnorm(b[i,1:2],Precy[i,1:2,1:2])
b[i,1:2] ∽dmnorm(mu[1:2],Precb[1:2,1:2])}
Sigma.b[1:2,1:2] <- inverse(Precb[,]);Precb[1:2,1:2] ∼dwish(Q[,],2)
V.t <- Sigma.b[1,1]+Sigma.b[2,2]-2*Sigma.b[1,2]
V.c <- Sigma.b[1,1]-pow(Sigma.b[1,2],2)/Sigma.b[2,2]
# variation in treatment eﬀects due to baseline risk
r2.base <- 1-V.c/V.t
corr.TC <- Sigma.b[1,2]/sqrt(Sigma.b[1,1]*Sigma.b[2,2]);
b.TC <- Sigma.b[1,2]/Sigma.b[2,2]

Hierarchical Estimation for Exchangeable Units
135
# gam is population wide vaccine eﬀect
gam <- mu[1]-mu[2]; for (i in 1:2) {mu[i] ∼dnorm(0,0.001)}}
4. As an illustration of applying these extended models, and to provide a tem-
plate for assessing overdispersion in other count datasets, consider data on the
distribution of 402 sow bugs beneath 122 boards from Scollnik (1995). The
observed frequencies are for 0.1, . . . , 17 bugs found. The vector of predicted
probabilities under the generalized Poisson density is contained in prob[1:n]
in the following code, where prob[1] is the probability of a board having zero
bugs, etc. So with n=122, the code is
model {for (i in 1:n) {log(p[i]) <-
log(lam)+(y[i]-1)*log(lam+y[i]*rho)-(lam+y[i]*rho)-loggam(y[i]+1)
z[i] <- 1; z[i] ∼dunif(a[i],b[i]); a[i] <- -1/p[i]; b[i] <- 1/p[i]}
for (i in 1:n) {log(prob[i]) <- log(lam)+(i-2)*log(lam+(i-1)*rho)
-(lam+(i-1)*rho)-loggam(i); yhat[i] <- n*prob[i]}
lam ∽dgamma(2,0.25); rho <- rho.val[k.rho]; k.rho ∽dcat(p.rho[1:101])
for (i in 1:101){p.rho[i] <- 1/101; rho.val[i] <- (i-1)*0.01}}
The sample variance for these data is considerably in excess of the sample
mean and counts of one are deﬂated by social behavior among the bugs. Be-
cause of the discrete prior on ρ, a Bayes factor on the generalized Poisson
as against the usual Poisson model can in principle be obtained. In fact, the
posterior mean (sd) of ρ is 0.56 (0.05), and values of ρ under 0.4 have zero pos-
terior probability (in a two chain run of 10,000 iterations with 1,000 burn in).
5. The WinBUGS code for the hospital mortality example (exchangeable
model) is
model { for (i in 1:131) {# checks using replicate samples
yrep[i] ∼dpois(nu[i]); ch[i] <- step(y[i]-yrep[i]-0.001)+0.5*equals(yrep[i],y[i])
y[i] ∽dpois(nu[i]); nu[i] <- o[i]*lam[i]; r[i] <- y[i]/o[i]
lam[i] ∽dgamma(zeta,b)}
B0 ∽dunif(0,1); zeta <- B0*ranked(o[],1)*mean(r[])/(1-B0)
b <- zeta/mu; mu ∼dexp(1)}
while the two group model has code
model { for (i in 1:131) {# checks using replicate samples
yrep[i] ∽dpois(m[i]); ch[i] <- step(y[i]-yrep[i]-0.001)+0.5*equals(yrep[i],y[i])
y[i] ∽dpois(nu[i]); nu[i] <- o[i]*lam[i]; r[i] <- y[i]/o[i]
lam[i] ∽dgamma(zeta[G[i]],b[G[i]])}
z0[1] <- ranked(o[1:37],1)*mean(r[1:37])
z0[2] <- ranked(o[38:131],1)*mean(r[38:131])
for (k in 1:2) {B0[k] ∼dunif(0,1); zeta[k] <- B0[k]*z0[k]/(1-B0[k])
b[k] <- zeta[k]/mu[k]; mu[k] ∼dexp(1)}}
6. The code used in Example 3.4 (cancer recurrence) is as follows:
model { for (i in 1:n) { rT[i]∼dbin(pT[i],nT[i]); rC[i] ∼dbin(pC[i],nC[i]);
pC[i] ∼dbeta(a.C,b.C); del[i] ∼dnorm(mu.del,tau.del)}

136
Applied Bayesian Hierarchical Methods
# alternative scales
# log OR scale
# for (i in 1:n) {logit(pT[i]) <- logit(pC[i])+del[i]}
# logit(pT.new) <- logit(pC.new)+del.new
# log RR scale
# for (i in 1:n) {log(pT[i]) <- log(pC[i])+min(del[i],-log(pC[i]))}
# log(pT.new) <- log(pC.new)+del.new
# absolute risk diﬀerence scale
for (i in 1:n) {pT[i] <- pC[i]+min(max(del[i],-pC[i]),(1-pC[i]))}
pT.new <- pC.new+del.new
# predictive relative risk (all models)
del.new ∼dnorm(mu.del,tau.del); pC.new ∼dbeta(a.C,b.C);
RRnew <- pT.new/pC.new; RRnew.above.1 <- step(RRnew-1)
# hyperpriors
a.C ∼dunif(1,100); b.C ∼dunif(1,100)
mu.del ∼dnorm(0,0.001); tau.del ∼dgamma(1,0.001)}
7. The code for the bivariate normal model is
model {for (i in 1:1040){ L[i] ∼dbin(p[i], N[i])
p[i] <- x[i]*r[1,i]+(1-x[i])*r[2,i]
for (j in 1:2) {r[j,i] <- 1/(1+exp(-w[i,j])); e[i,j] <- abs(r[j,i]-rstar[i,j])}
w[i,1:2] ∼dmnorm(mu[1:2],T.w[,])}
T.w[1:2,1:2] ∼dwish(Q[,],2); Sig[1:2,1:2] <- inverse(T.w[,])
rho <- Sig[1,2]/sqrt(Sig[1,1]*Sig[2,2])
for (j in 1:2) { mu[j] ∼dnorm(0,1)
for (k in 1:2) {Q[j,k] <- equals(j,k)}}
E.r <- sum(e[,])}
with initial value ﬁles list(T.w = structure(.Data = c(5,-0.8,-0.8,1),.Dim =
c(2,2)),mu = c(0.5,3)) and list(T.w = structure(.Data = c(4,-1,-1,0.9),.Dim =
c(2,2)),mu = c(0.55,3.1)).
For the trivariate model the code is
model {for (i in 1:1040){ L[i] ∼dbin(p[i], N[i])
# literacy rate
p[i] <- x[i]*r[1,i]+(1-x[i])*r[2,i]
for (j in 1:2) {r[j,i] <- 1/(1+exp(-w[i,j])); e[i,j] <- abs(r[j,i]-rstar[i,j])}
x[i] <- 1/(1+exp(-w[i,3]))
w[i,1:3] ∼dmnorm(mu[1:3],T.w[,])}
T.w[1:3,1:3] ∼dwish(Q[,],3); E.r <- sum(e[,])
Sig[1:3,1:3] <- inverse(T.w[,]); rho <- Sig[1,2]/sqrt(Sig[1,1]*Sig[2,2])
for (j in 1:3) { mu[j] ∼dnorm(0,1)
for (k in 1:3) {Q[j,k] <- 3*V[j]*equals(j,k)}}}
with initial value ﬁles list(T.w = structure(.Data = c(6.9,-1.7,8.1,-1.7,1.3,
-2.5,8.1,-2.5,13.7),.Dim = c(3,3)),mu = c(0.8,3.5,-0.4)) and list(T.w = struc-
ture(.Data = c(5.1,-2.7,5.7,-2.7,0.8,-3.9,5.7,-3.9,10.3),.Dim = c(3,3)),mu =
c(0.7,3.8,-0.4)).

Hierarchical Estimation for Exchangeable Units
137
8. A BUGS implementation for a ZIP model may use the associated full condi-
tionals for π and µ. With data arranged so that the n0 subjects with yi = 0 are
placed ﬁrst, and assuming priors π ∽Be(1, 1), µ ∽Ga(1, 0.001) the code is
model {for (i in 1:n0) {S0[i]∼dbern(p.S)}
p.S <- pi/(pi + (1 - pi) * exp(-mu))
for (i in n0+1:n) { y[i]∼dpois(mu)}
s0 <- sum(S0[]); pi∼dbeta(aw,bw);
aw <- s0 + 1; bw <- n - s0 + 1
mu ∼dgamma(a.mu,b.mu);
a.mu <- sum(y[]) + 1; b.mu <- n - s0 + 0.001}
For example, applying this code to the hard disk read-write error data from
Xie et al. (2001) gives π = 0.862 and µ = 8.66, close to the maximum likeli-
hood estimates, namely, π = 0.865 and µ = 8.64.
9. A code including both the conjugate and logistic-normal priors (with
KM=K-1 and n=82) follows. One or other prior will need to be commented
out in practice.
model { for (i in 1:n) {y[i] <- Y[i]/1000; y[i] ∼dnorm(mu[G[i]],tau[G[i]])
ynew[i] ∼dnorm(mu[G[i]],tau[G[i]]); ML[i] <- log(sum(c[i,]))}
for (k in 1:K) {tau[k] ∼dgamma(1,0.001)}
# constrained prior on latent means
mu[1] ∼dnorm(10,0.001) I(9.176,)
for (k in 1:KM) {del[k] ∼dgamma(1,0.001) I(,20); mu[k+1] <- mu[k]
+del[k]}
# Fit
TLL <- sum(ML[]); pars <- (K-1)+2*K; BIC <- -2*TLL+pars*log(n)
#
# Mixing Prior 1
#
for (i in 1:n) {G[i] ∼dcat(pi[1:K])
for (k in 1:K) {c[i,k] <- pi[k]*exp(0.5*log(tau[k]/6.28)
-0.5*tau[k]*pow(y[i]-mu[k],2))}}
pi[1:K] ∼ddirch(alph[1:K]); for (k in 1:K) {alph[k] <- 1}
#
# Mixing Prior 2
#
for (i in 1:n) {z[i,1:KM] ∼dmnorm(nu[1:KM],T.z[1:KM,1:KM])
G[i]∼dcat(p.z[i,1:K]); p.z[i,K] <- 1/(1+sum(exz[i,1:KM]))
for (k in 1:K) {c[i,k] <- p.z[i,k]*exp(0.5*log(tau[k]/6.28)
-0.5*tau[k]*pow(y[i]-mu[k],2))}
for (k in 1:KM) {exz[i,k] <- exp(z[i,k])
p.z[i,k] <- exz[i,k]/(1+sum(exz[i,1:KM]))}}
for (k in 1:KM) {nu[k] ∼dnorm(0,0.001);
for (m in 1:KM) {Q[k,m] <- equals(k,m)}}
T.z[1:KM,1:KM] ∼dwish(Q[,],KM)}

138
Applied Bayesian Hierarchical Methods
10. The code for the NRT analysis is
model {for (i in 1:n) { y[i] <- log(rT[i]/(nT[i]-rT[i]))-log(rC[i]/(nC[i]-rC[i]))
s2[i] <- 1/rT[i] + 1/(nT[i]-rT[i]) + 1/rC[i] + 1/(nC[i]-rC[i]);
y[i] ∼dnorm(b[i],inv.s2[i]); inv.s2[i] <- 1/s2[i]
yrep[i] ∼dnorm(b[i],inv.s2[i]); testrep[i] <- step(yrep[i]-y[i])
# subgroup indicator
S[i] ∼dcat(p[1:M]); b[i] <- phi[S[i]];
# log-likelihood
LL[i] <- 0.5*log(inv.s2[i]/6.28)-0.5*inv.s2[i]*pow(y[i]-b[i],2)
for (m in 1:M) {memb[i,m] <- equals(S[i],m)}}
TL <- sum(LL[])
# base prior
for (m in 1:M) { phi[m] ∼dnorm(mu[m],inv.tau2[m])
realclus[m] <- step(sum(memb[,m])-1)
inv.tau2[m] ∼dgamma(1,1); mu[m] ∼dnorm(m.mu,1)}
m.mu ∼dnorm(0,1)
# treatment beneﬁt
p.ben <- step(mean(b[]))
# truncated Dirichlet process
alpha ∼dgamma(a0,b0) I(0.1,); V[M] <- 1; p[1] <- V[1]
for (m in 1:M-1){
# c[m] <- 1+alpha/M; d[m] <- alpha*(1-m/M)
c[m] <- 1; d[m] <- alpha
V[m] ∼dbeta(c[m],d[m]); p[m+1] <- V[m+1]*(1-V[m])*p[m]/V[m]}
# total clusters
K <- sum(realclus[])}
11. The code for the Polya urn scheme for the DP Poisson-gamma model
(with nP=n+1) is
model { # prediction
pnew[1] <- alph/(alph+n); bnew[1] ˜dgamma(c.g,d.g)
for (k in 2:nP) {pnew[k] <- 1/(alph+n); bnew[k] <- b[k-1]}
Snew ˜dcat(pnew[1:nP]); b.new <- bnew[Snew]
ynew ˜dpois(b.new)
for (i in 1:n) {y[i] ˜dpois(b[i]); yrep[i] ˜dpois(b[i]);
# checks using replicate samples
ch1[i] <- step(y[i]-yrep[i]-0.001); ch2[i] <- equals(yrep[i],y[i])
ch[i] <- ch1[i]+0.5*ch2[i]}
# urn prior
b[1] ˜dgamma(c.g,d.g); newclus[1] <- 1
for (i in 2:n) {bstar[i,1] ˜dgamma(c.g,d.g)
p[i,1] <- alph/(alph+i-1); S[i] ˜dcat(p[i,1:n])
newclus[i] <- equals(S[i],1); b[i] <- bstar[i,S[i]]
for (k in 1:i-1) {bstar[i,k+1] <- b[k]; p[i,k+1] <- 1/(alph+i-1)}
for (k in i:n-1) {bstar[i,k+1] <- 0; p[i,k+1] <- 0}}

Hierarchical Estimation for Exchangeable Units
139
K <- sum(newclus[]); alph ˜dgamma(1,1); c.g ˜dexp(1) I(0.5,); d.g
˜dexp(1)}
The code for the Polya Tree prior in this data analysis is
model {for (i in 1:n) {y[i] ∼dpois(mu[i]); log(mu[i]) <- beta+sig*b[i];
b[i] <- bstar[B[M,i]]
yrep[i] ∼dpois(mu[i]); ch1[i] <- step(y[i]-yrep[i]-0.001);
ch2[i] <- equals(yrep[i],y[i]); ch[i] <- ch1[i]+0.5*ch2[i]}
beta ∼dnorm(0,0.01); tau ∼dgamma(1,1); sig <- 1/sqrt(tau)
# Polya Tree Process for b[]
for (m in 2:M) { c[m] <- 0.1*pow(m,2)}
for (i in 1:n) { V[1,i] ∼dbern(0.5)
for (m in 2:M) { p[m,i] ∼dbeta(c[m],c[m]); V[m,i] ∼dbern(p[m,i])}
# level 1 choice (convert V=0,1 to B=1,2)
B[1,i] <- V[1,i]+1
# choices at level 2 and above
for (m in 2:M) { B[m,i] <- sum(BC[m,i,1:m-1])+V[m,i]+1
for (k in 1:m-1) {BC[m,i,k] <- V[m-k,i]*pow(2,k)}}}
# Sample within ordinates of base distribution
bstar[1] ∼dnorm(0,1) I(,U[1]); bstar[M2] ∼dnorm(0,1) I(L[M2],)
for (i in 2:M2-1) {w[i] ∼dbeta(1,1); bstar[i] <- (1-w[i])*L[i]+w[i]*U[i]}}

4
Structured Priors Recognizing Similarity over
Time and Space
4.1
Introduction
In the analysis of data over time or space, one often expects positive
covariation between units that are close to each other in those domains, so that
exchangeable priors are not necessarily appropriate. Consider health event
counts for small geographical areas, or relatively rare diseases, when small
event totals or small populations at risk lead to unstable estimates of rates
or relative risks. One is then led to hierarchical methods for pooling strength
over sets of areas to achieve more stable estimates (Riggan et al., 1991; Waller,
2002). An assumption of exchangeable random eﬀects then implies global
smoothing, with area rates or risks smoothed toward the overall mean. If
there is spatial covariation (when contiguous areas have similar disease levels),
a more appropriate smoothing mechanism would incorporate local smoothing
toward the mean of adjacent areas (Clayton and Kaldor, 1987).
Related ideas in time series are the extraction of relatively smooth trends
or regular seasonal eﬀects from time series subject to random variation.
For example, modern state–space models recognize the presence of multiple
underlying components in time series (West and Harrison, 1997), with the
priors governing the evolution of the components emphasizing an expectation
of smoothness. An example of such smoothness priors involves kth order dif-
ferences in successive latent parameters, θt, as in ∆kθt ∼N(0, W) for times
t = k + 1, . . . , T (Kashiwagi and Yanagimoto, 1992; Kitagawa and Gersch,
1996). While time series are sometimes analyzed exchangeably, at least within
subgroups of the data, as in change point models (Mira and Petrone, 1996),
in most applications there is a gain from modeling temporal covariation.
Priors for time or space covariance modeling are structured in the sense
of explicitly recognizing adjacency or proximity, and use this structure as
the basis for smoothing or prediction. Often, smoothing of a time series or
of rates in small areas is an end in itself; for example, spatial smoothing of
health data for administrative areas to reﬂect similarity of disease risks in
nearby areas is a more reliable guide for health interventions (e.g., Zhu et al.,
2006, 3). Similarly, Berzuini and Clayton (1994, 828) mention use of state–
space priors for pooling strength in problems with several time scales (e.g.,
141

142
Applied Bayesian Hierarchical Methods
age, time, cohort), whereby random time parameters depend on each other in
a way that reﬂects their proximity on each scale.
However, structured priors may also be more suitable when the goals
of analysis include out-of-sample prediction in addition to description. For
example, time series forecasts place higher weight on recent observations, as
in ﬁrst order autoregressions or Markov random walks, but the parameters for
the second stage model use all the data. In spatial applications, such as geo-
statistics, a frequent goal is interpolation of a modeled surface to unsampled
locations based on proximity to observed locations (Gotway and Wolﬁnger,
2003; Jiruse et al., 2004; Webster et al., 1994).
While there may be beneﬁts from borrowing strength methods that take
account of correlations between units, the use of multiple random eﬀects to
represent unobserved components in time or spatial series raises potential
identiﬁcation issues. For example, priors for correlated unit eﬀects in time or
space may consider diﬀerences between adjacent units without specifying the
mean level of the eﬀects. Markov Chain Monte Carlo (MCMC) methods may
then require centering of the eﬀects during sampling to ensure identiﬁcation
of other parameters. Methods for smoothing or interpolation in space or time
may also need to retain robustness to take account of regime shifts, or to
accommodate temporal or spatial outliers. Structured priors assume relatively
smooth variation over adjacent units, and their parameters may be distorted
if mechanisms are not incorporated for accommodating extreme points (see
Sections 4.6 and 4.10 relating to time and spatial series, respectively).
To illustrate commonality in structured priors for temporal and spatial
series, one may cite simultaneous and conditional autoregressive priors deﬁned
over observations, latent eﬀects, or both. In particular, the pairwise diﬀerence
or Markov random ﬁeld (MRF) prior may be speciﬁed via conditional densi-
ties, which are naturally suited for Gibbs sampling (Finley et al., 2006). For
univariate eﬀects, θ = (θ1, . . . , θn), the conditional MRF prior takes the form
(Besag et al., 1995, 11; Rue and Tjelmeland, 2002),
p(θi|θ[i]) ∝τ exp

−

j̸=i
wijΦ(τ[θi −θj])

,
where θ[i] denotes values for cases other than i, wij are weights specifying
dependence between units i and j, Φ(u) is an increasing function in u, subject
to Φ(u) = Φ(−u), and τ is a precision parameter. Under a neighborhood prior,
where wij = 1 when units i and j are neighbors and wij = 0 otherwise, an
equivalent representation is
p(θi|θ[i]) ∝τ exp

−

j∈∂i
Φ(τ[θi −θj])

,
where ∂i is the set of areas or times adjacent to area or time i. The case
wij = 1 if |i −j| = 1 and wij = 0 otherwise, leads to ﬁrst order random walk

Structured Priors Recognizing Similarity over Time and Space
143
priors relevant to modeling time ordered data. The MRF prior generalizes
to variables θij in two-dimensional lattices (e.g., areas i and times j), and a
neighborhood might then be deﬁned as ∂ij = [(i + 1, j), (i −1, j), (i, j + 1),
(i, j −1)] (Lavine, 1999). Taking Φ(u) = u2/2 leads to a Gaussian or L2 norm
conditional prior for θi (Waller, 2002),
θi|θ[i] ∽N

j̸=i
wijθj
wi+
,
1
τwi+

,
whereas if φ(u) = |u|, then,
p(θi|θ[i]) ∝τ exp

−τ

j#i
wij|θi −θj|

,
known as the L1 norm prior (Richardson et al., 2004). To achieve robust
smoothing, the latter form may be better suited to spatial or temporal discon-
tinuities since its mode is at the median rather than the mean. Other methods
that reﬂect spatial or temporal outliers include convolution smoothing (Besag
et al., 1991; Knorr-Held, 2000), based on an equal mixture of global and local
smoothing, or discrete mixtures of spatially or temporally structured priors
(Sections 4.8 and 4.10).
While the MRF prior can be used for simple time series model, a more
general scheme for specifying priors for modeling time series data is provided
by the state–space approach, considered in Sections 4.3 and 4.4 (Harvey et al.,
2006). A linear state–space (or dynamic linear model) speciﬁcation for the
changing level of a metric response, yt, has the form,
yt = βtXt + ut,
βt = βt−1Gt + wt,
where ut ∼N(0, Vt) and wt ∼N(0, Wt) are white noise (unstructured) ran-
dom variation, Xt is a predictor or design matrix, and Gt is a known ma-
trix governing the evolution of the state vector βt (Durbin, 2000; West and
Harrison, 1997). The time-structured latent eﬀects, βt, may include levels,
trends, seasonal, or cyclical eﬀects. Taking ut and wt to be normal leads to the
normal dynamic linear model (West, 1998), with extension to general linear
model forms for discrete data leading to dynamic general linear models. State–
space principles can also be applied to model stochastic variances, for example
in stochastic volatility models, as opposed to changing levels (Section 4.5).
In terms of Bayesian computing options for temporal and spatial series,
one may mention the development of conditional autoregression and spatial
functions in WinBUGS, such as the car.normal, mv.car, and spatial.exp func-
tions. As well as WinBUGS, a number of temporal and spatial analysis tools
and models are available in R. Spatial modules, some with Bayesian options,
include spdep (Bivand and Gebhardt, 2000), geoR and geoRglm (Ribeiro and

144
Applied Bayesian Hierarchical Methods
Diggle, 2001), and spBayes. Time series analysis functions in R are discussed
by Shumway and Stoﬀer (2006), while the MSBVAR package speciﬁcally
addresses Bayesian vector autoregressive models, with applications considered
by Brandt and Freeman (2006) and Brandt and Williams (2007).
This chapter ﬁrst considers schemes for modeling correlated observations
and latent eﬀects in time series. Sections 4.2 and 4.3 consider autoregressive
and state–space priors for time series analysis, with Section 4.4 considering
state–space methods for discrete time series, Section 4.5 considering Bayesian
approaches to stochastic volatility, and Section 4.6 considering models adap-
tive to temporal discontinuities. The last four sections consider error structures
for area and point data.
4.2
Modeling Temporal Structure:
Autoregressive Models
A time series is a sequence of stochastic observations that are ordered in
time, most often at equally spaced discrete times, t = 1, . . . , T, though ex-
tensions to unequally spaced intervals are relatively straightforward (Lee and
Nelder, 2001). Major goals of time series analysis include modeling the in-
terrelationship of variables evolving jointly through time, as in econometric
growth models (Paap and van Dijk, 2003), forecasting future values of time
series variables (Beck, 2004), and identifying the structural components of the
sequence of observations (Huerta and West, 1999). Areas where Bayesian per-
spectives have greatly inﬂuenced recent developments include dynamic general
linear models (Carter and Kohn, 1994), time series model selection (Troughton
and Godsill, 1998), and models with common latent variables such as fac-
tor stochastic volatility models. Below, several leading approaches to time
series modeling are reviewed, beginning with established methods (e.g., Box–
Jenkins), which help set a context for more recent techniques (e.g., for mod-
eling stochastic volatility).
Many time series show evidence of serial dependence in the observations
or error terms, leading to what are sometimes denoted as observation-and
parameter-driven models, respectively (Oh and Lim, 2001); an analogous dis-
tinction is often made in analyzing spatial series (Larch and Walde, 2008). A
widely used model for expressing such serial dependence is the lag p autore-
gressive or AR(p) model. An AR(p) scheme for dependent outcomes, yt, in a
normal linear framework is represented by
yt = φ0 + φ1yt−1 + φ2yt−2 + · · · + φpyt−p + ut,
where the innovation errors, ut ∼N(0, σ2), are homoscedastic white noise,
independent
of
each
other
and
lagged
y
values
{yt−1, · · · , yt−p}.
So
E(utut−s) = E(ut−jut−j−s) = 0 for all s and j. Note that a full likelihood

Structured Priors Recognizing Similarity over Time and Space
145
analysis will refer to p latent preseries values (Marriott et al., 1996), with
Marriott et al. (2003) suggesting preseries values follow a heavy-tailed version
of the density assumed for the observed series, for instance (y0, y−1, . . . , y1−p)
as Student t with variance σ2 and low degrees of freedom ν (e.g., ν = 2).
Autoregressive dependence may also be present in error terms, such that,
yt = φ0 + φ1yt−1 + φ2yt−2 + · · · + φp1yt−p1 + εt,
εt = ρ1εt−1 + ρ2εt−2 + · · · + ρp2εt−p2 + ut.
Furthermore, moving average eﬀects may occur in the white noise errors,
ut, with an impact on yt of lagged disturbances ut. A lag q moving average
eﬀect, combined with a lag p eﬀect in the yt series, provides the ARMA(p, q)
model,
yt = φ0 + φ1yt−1 + · · · + φpyt−p + ut + γ1ut−1 + γ2ut−2 + · · · + γqut−q.
Assuming the y-series is centered around its mean, and deﬁning Byt =
yt−yt−1, one has yt−φ1yt−1 −· · · φpyt−p = yt(1−φ1B−· · · φpBp) = Φ(B)yt,
and the ARMA(p, q) model can be written,
Φ(B)yt = Γ(B)ut.
Classical estimation methods typically require stationarity and constant
variances in estimating such models. Stationarity is equivalent to the roots of
Φ(B) = 1−B−B2 ..−Bp being outside the unit circle, and invertibility refers
to the same condition on the roots of Γ(B). This typically involves prelimi-
nary data diﬀerencing or transformation to gain stationarity, or regression to
remove trend (e.g., Abraham and Ledolter, 1983, 225), with the actual model
then applied to diﬀerenced data or to regression residuals. To assess whether
stationarity has been achieved, one can consider the autocorrelation sequence
of model residuals: a stationary process should show a sequence fading to zero
at high lags, whereas signiﬁcant values at high lags indicate nonstationarity.
In Bayesian analyzes, it is common to estimate parameters without presuming
stationarity (or invertibility), but obtain the posterior probabilities of station-
arity via monitoring the sampled parameters (Marriott et al., 1996; McCulloch
and Tsay, 1994).
4.2.1
Random coeﬃcient autoregressive models
A hierarchical generalization of the AR(p) prior allows the lag coeﬃcient to
vary over time, as in random coeﬃcient AR or RCAR models—see, e.g., Berkes
et al. (2009), Lee (1998), and Nicholls and Quinn (1980). These are also called
time-varying autoregressive or TVAR models. Thus, for a centered and uni-
variate y, an RCAR(p) model in the observations speciﬁes,
yt =

φtjyt−j + ut,
φt = µφ + Σ0.5
φ et,

146
Applied Bayesian Hierarchical Methods
where ut ∼N(0, σ2), et ∽Np(0, I), φt = (φt1, . . . , φtp), and µφ = (φ1, . . . , φp).
Instead of a multivariate normal prior for the φt, sequential updating of the
φt may be applied, for example via a multivariate random walk (Section 4.3),
with,
φt = φt−1 + wt
wt ∼Np(0, Wt).
Another possibility (Godsill et al., 2004) is to take both the AR coeﬃcient
vector and the innovation variance σ2 to be time varying, for example by set-
ting a random walk prior on ht = log(σt), or by a second stage autoregression,
such as,
ht ∼N(ρhht−1, σ2
h).
As in many Bayesian applications, typically, stationarity constraints are
not necessarily placed on the φtj at each t (Prado et al., 2000). However, if the
AR parameters lie in the stationary region then the series can be considered
locally stationary. For example, for an RCAR(1) model including a latent
preseries value, y0, a hierarchical scheme such as,
yt ∽N(φt1yt−1, σ2)
t > 1,
y0 ∽t2(m0, σ2),
φt1 ∽N(φ1, σ2
φ)
t > 1,
may be applied. For this model, stationarity holds if φ2
1 + σ2
φ < 1.
4.2.2
Low order autoregressive models
Simple dependence models for observations or latent eﬀects are obtained via
ﬁrst or second order autoregression. In the AR(1) observation model, one has,
yt −µ = φ(yt−1 −µ) + ut,
or
yt = φyt−1 + ut,
for centered data, where under stationarity, −1 < φ < 1, and yr and ys
for 1 ≤r ≤s ≤T are conditionally independent, given {yr+1, . . . , ys−1} if
r −s > 1 (Rue and Held, 2005). The AR(2) model has,
yt = φ1yt−1 + φ2yt−2 + ut,
where stationarity requires φ1 + φ2 < 1, φ2 −φ1 < 1, and |φ2| < 1. An AR(1)
error sequence, εt = ρεt−1 + ut with ut ∼N(0, σ2), similarly requires −1 < ρ < 1
for stationarity. The covariance for such a sequence has the form, Cov(ε) =
σ2C, with (s, t)th element in the correlation matrix, corr(εs, εt) = ρ|s−t|/
(1 −ρ2), so correlations decline as the gap between observations increases.

Structured Priors Recognizing Similarity over Time and Space
147
For the stationary AR(1) observation model, yt = φyt−1+ut, the marginal
density of the ﬁrst observation is y1 ∽N(0, σ2/(1 −φ2)), and the joint density
can also be obtained by density decomposition as,
p(y1, . . . , yT ) = p(y1)p(y2|y1)p(y3|y2) . . . p(yT |yT −1)
∝(1 −φ2)0.5σ−n exp[−0.5H/σ2],
where H = (1 −φ2)y2
1 + T
t=2(yt −φyt−1)2. The same sequence of marginal
and conditional densities applies for AR(1) autoregressive errors.
The precision (inverse covariance) matrix of autoregressive models has
interesting theoretical properties demonstrating how conditional independence
structures determine the precision matrix and vice versa (Rue and Held, 2005;
Speed and Kiiveri, 1986). Speciﬁcally, zeros in the precision matrix deﬁne,
and are deﬁned by, conditional independencies in the joint density. Thus, for
an AR(1) prior on eﬀects ε with lag coeﬃcient ρ, the precision matrix, Π,
is tridiagonal with (r, s)th cell equalling zero if, and only if, the complete
conditional distribution of εr does not depend on εs, namely,
Π = σ−2C−1 = σ−2


1
−ρ
0
−ρ
1 + ρ2
−ρ
0
−ρ
1 + ρ2
· · ·
· · ·
· · ·
−ρ
1 + ρ2
−ρ
0
−ρ
1


.
For an AR(2) error sequence with lag parameters {ρ1, ρ2}, the precision
matrix is
Π = σ−2


1
−ρ1
−ρ2
0
−ρ1
1 + ρ2
1
−ρ1(1 −ρ2)
−ρ2
−ρ2 −ρ1(1 −ρ2)
1 + ρ2
1+ρ2
2
−ρ1(1 −ρ2)
0
−ρ2
−ρ1(1 −ρ2)
1 + ρ2
1+ρ2
2
· · ·
· · ·
· · ·
−ρ1(1 −ρ2) 1 + ρ2
1 −ρ1
−ρ2
−ρ1
1


.
Such simpliﬁcations in structure are useful in multidimensional applica-
tions involving spatio-temporal or multiple time scale errors. For example, if
the covariance matrix of a spatio-temporal error, εst, is represented as a Kro-
necker product, Σt ⊗Σs, of a temporal covariance Σt and spatial covariance
Σs, then the corresponding precision matrix is Πt ⊗Πs (Bijma et al., 2005).
There is a considerable literature around the unit root and explosive root
solutions of the AR(1) model, yt = φyt−1 + ut. One may apply an autoregres-
sive prior not constrained to stationarity, and a substantial posterior probabil-
ity of nonstationarity would support using random walk priors (Section 4.3), as
a parsimonious autoregressive prior that allows for potential nonstationarity.
For example, Lubrano (1995) considers the alternative composite hypotheses,

148
Applied Bayesian Hierarchical Methods
H0 : φ < 1 and H1 : φ ≥1. Schotman and van Dijk (1991) consider the auto-
regression plus trend observation model, yt = φ0+φ1yt−1+δt+ut, and reframe
it in equivalent AR(1) error form as,
yt = δ0 + δ1t + εt,
εt = φεt−1 + ut,
while Chatuverdi and Kumar (2005) consider the unit root hypothesis under
a more general polynomial trend, yt = δ0 + Σjδjtj + εt.
4.2.3
Antedependence models
Structured antedependence models may oﬀer ﬂexibility in time series speciﬁ-
cation; they resemble autoregressions in entailing a regression over preceding
observations or latent eﬀects, but are speciﬁed in a way that avoids station-
arity constraints (Nunez-Anton and Zimmerman, 2000; Pourahmadi, 2002).
Observations {y1, . . . , yT } are antedependent of order s if yt depends only on
{yt−1, . . . , yt−s} for all t ≥s (Gabriel, 1962). For example, Jaﬀrezic et al.
(2003) consider a second order antedependence model for normal panel data
of the form yit = µit+git+uit, where µit models ﬁxed eﬀects, e.g., µit = xitβ,
uit are unstructured white noise errors with ﬁxed variance, and the genetic
component, git, follows a second-order structured antedependence or AD(2)
scheme. The essence of this scheme for a pure time series is
g1 = η1,
g2 = φ12g1 + η2,
gt = φ1tgt−1 + φ2tgt−2 + ηt
t > 2,
with ηt ∼N(0, ωt). Due to the initial condition, g1 = η1, the antedepen-
dence parameters, such as {φ1t, φ2t} in an AD(2) model, are unconstrained,
in contrast to the stationarity constraints needed for autoregressive models.
To reduce the number of parameters being estimated, changing vari-
ances, ωt, may be modeled via a parametric function of time, for example,
log(ωt) = α1 + α2t + α3t2,
while the antedependence parameters can also be modeled using time func-
tions. For example, a Box–Cox power law can be used to parameterize time-
varying AD coeﬃcients, φkt, namely,
φkt = φrt−rt−k
k
,
where {rt = t
λk−1/λk, rt−k = (t −k)
λk−1/λk} if λk ̸= 0, and {rt = log(t),
rt−k = log(t −k)} if λk = 0 (Nunez-Anton and Zimmerman, 2000). The
φ and ω parameters may be adjusted to account for unevenly spaced times

Structured Priors Recognizing Similarity over Time and Space
149
located at points {a1, . . . , aT }. For example, an exponential parameterization
is possible, such that an AD(2) model would specify,
φ1(at, at−1) = exp(−λ1(at −at−1)),
and
φ2(at, at−2) = exp(−λ2(at −at−2)),
with λj > 0 corresponding to positive temporal dependence (Jaﬀrezic et al.,
2004; Pourahmadi, 2002).
4.3
State–Space Priors for Metric Data
Nonstationary models based on state–space priors are widely used in appli-
cations where time series parameters are evolving through time, especially in
analyzing multiple unobserved components due to trend, cyclical, or seasonal
eﬀects. The idea that a time series may best be viewed as being composed of
several unobserved components contrasts with Box–Jenkins or ARMA meth-
ods that require diﬀerencing to eliminate trend or periodic eﬀects and achieve
stationary means and variances (Durbin, 2000, 2). ARMA models are selected
using autocorrelation and partial and autocorrelation functions that are sub-
ject to sampling variability, and quite diﬀerent models can provide similar ﬁts
for the same series. In fact, though ARMA sequences can be represented as
particular instances of state–space models with implicit components. Among
informative discussions on state–space vs. Box–Jenkins methods, see Durbin
and Koopman (2001, 51) and Harvey and Todd (1983).
The normal linear state–space speciﬁcation, or dynamic linear model, has
the form,
yt = βtXt + ut,
where evolution of the p dimensional signal, βt, is deﬁned by a state equation,
βt = βt−1Gt + wt,
with Xt being a p × 1 design matrix (typically including an intercept), and
Gt deﬁning a p × p state evolution matrix. The normal errors ut and wt
are independent of each other, with mean zero and variances Vt and Wt (or
covariances for multivariate y). The initial state vector or initial condition
has a separate (e.g., normal) prior such as β1 ∼N(m1, W1) (Strickland et al.,
2008). Often, Gt has a simple form such as an identity matrix. For the case
Gt = G, Gamerman (1998) mentions an inverse parameterization consequent
on taking,
δ1 = β1, δt = βt −Gβt−1,

150
Applied Bayesian Hierarchical Methods
so that
βt =
t

j=1
Gt−jδj.
Algorithms using normal distribution properties can be applied to se-
quential updating (ﬁltering), forward prediction, and retrospective smoothing
of the state vector in the normal dynamic linear model. Letting Dt = (yt,
yt−1, . . . , y1), the prior, predictive, and posterior distributions of βt are (Reis
et al., 2006),
p(βt|Dt−1) =

p(βt|βt−1)p(βt−1|Dt−1)dβt−1,
p(yt|Dt−1) =

p(yt|βt)p(βt|Dt−1)dβt,
p(βt|Dt) ∝p(βt|Dt−1)p(yt|Dt−1).
For the linear normal model with Vt = V , Wt = W, sequential updating
provides posteriors,
βt|Dt ∽N(mt, Ct),
where
at = Gtmt−1,
mt = at + Atet,
Ct = Rt−AtA′
tqt,
Rt = GtCt−1G′
t+W,
qt = X′
tRtXt + V,
with forecast errors,
et = yt −X′
tat.
The one step ahead state and observation predictive densities are normal
densities, namely,
(βt|Dt−1) ∽N(at, Rt),
(yt|Dt−1) ∽N(X′
tat, qt).
4.3.1
Simple signal models
As an illustration of a normal state–space or dynamic linear model, assume
that observations are obtained with measurement error and in fact generated
by a relatively smooth underlying signal, βt. This is a hierarchical model—
parallel to the normal-normal model of Chapter 3—with the ﬁrst level being

Structured Priors Recognizing Similarity over Time and Space
151
the observation equation, the second level being the state equation, and the
priors on the variances and initial conditions deﬁning hyperparameters at the
third stage (Berliner, 1996). Assuming unstructured measurement errors, ut,
one has an observation or measurement equation,
yt = βt + ut,
(4.1a)
for t = 1, . . . , T and a state equation deﬁning the evolution of the signal,
βt = βt−1 + wt,
(4.1b)
for t = 2, . . . , T. This is also known as a local level model (Durbin and
Koopman, 2001), or random walk plus noise model (Durbin, 2000), and the
second stage is a nonstationary ﬁrst order random walk or RW (1) prior, cor-
responding to the unit root case of an AR(1) prior.
As for the AR(1) prior, future values of the signal depend on (βt,
βt−1, . . . , β1) only through the current value βt. The conditional form of the
RW (1) prior is
p(βt|β[t], y) ∝



p(β2|β1)p(β1)p(y1|β1)
t = 1
p(βt+1|βt)p(βt|βt−1)p(yt|βt)
t = 2, . . . , T −1
p(βT |βT −1)p(yT |βT )
t = T


,
so that for times t = 2, . . . , T −1, there is averaging over preceding and
following states. The ﬁrst period signal (or “initial condition”) β1 is typi-
cally taken as an unknown ﬁxed eﬀect with large variance, while the obser-
vation error, ut, and state error, wt, are taken as, respectively, N(0, V ) and
N(0, W), and assumed uncorrelated in time, independent of one other, and
also independent of the signal βt. Assume β1 ∼N(b1, S1), 1/V ∼Ga(au, bu),
1/W ∼Ga(aw, bw), then the full conditionals are,
β1 ∼N
 β2
W + b1
S1 + y1
V
 1
W + 1
S1 + 1
V
−1
,
 1
W + 1
S1 + 1
V
−1
,
βt ∼N
(βt+1 + βt−1)
W
+ yt
V
 2
W + 1
V
−1
,
 2
W + 1
V
−1
t = 2, . . . , T −1,
βT ∼N
βT −1
W
+ yT
V
 1
W + 1
V
−1
,
 1
W + 1
V
−1
,
1/V ∼Ga

au + T
2 , bu + 0.5
T

t=1
(yt −βt)2

,
1/W ∼Ga

aw + (T −1)
2
, bw + 0.5
T

t=2
(βt −βt−1)2

.
Higher order random walks in the signal are another possibility, with a kth
order random walk having prior,
∆kβt ∽N(0, W),

152
Applied Bayesian Hierarchical Methods
(Berliner, 1996; Fahrmeir and Lang, 2001; Kitagawa and Gersch, 1996). For
example, a second diﬀerence random walk or RW(2) prior speciﬁes yt = βt+ut
and state equation ∆2βt = wt. Hence,
∆(∆βt) = ∆(βt −βt−1) = ∆βt −∆βt−1 = (βt −βt−1) −(βt−1 −βt−2) = wt,
and the RW(2) prior can be stated as,
βt ∼N(2βt−1 −βt−2, W).
Whereas ﬁrst order random walks penalize abrupt jumps between suc-
cessive values, the RW(2) prior penalizes deviations from a linear trend. The
RW(2) and higher order RW priors therefore lead to a smoother evolution of βt
through time. This is relevant not just to time series, but to processes operating
on other time scales (e.g., age, cohort), for example in survival analysis or in
graduating (smoothing) demographic schedules (Carlin and Klugman, 1993).
4.3.2
Sampling schemes
Diﬀerent MCMC sampling schemes have been proposed for state–space models
according to the form of outcome (e.g., metric or discrete) and the form of
observation-state equations (e.g., linear or nonlinear). Multistate or joint sam-
pling of the state vectors, βt, is generally more eﬃcient than single-state sam-
pling that updates one state parameter vector at a time (Knorr-Held, 1999).
Carlin et al. (1992) in the context of non-normal/nonlinear dynamic models
suggest single-state samples from (β1, . . . , βT ). Joint sampling for β when y
is metric is discussed by Carter and Kohn (1994) and Fruhwirth-Schnatter
(1994), while de Jong and Shephard (1995) focus on sampling the ut and wt
error series as opposed to the state eﬀects βt; a recent overview is provided by
Reis et al. (2006). Gamerman (1998) proposes updating via the δt rather than
the usually highly correlated βt using the reparameterization mentioned above.
Knorr-Held (1999), Rue (2001), and Rue and Held (2005) use properties
of the penalty (inverse covariance) matrix of the joint density for the state
vectors as a basis for sampling sub-blocks of the elements (β1, . . . , βT ). Thus,
Gaussian state–space priors can be written in joint form as,
p(β1, . . . , βT |W) ∝exp

−β′Kβ
2W

,
where the form of the penalty matrix K is determined by the form of au-
toregressive prior. For a ﬁrst order random walk with βt ∽N(βt−1, W), the
penalty matrix is
K =










1
−1
−1
2
−1
−1
2
−1
..
..
..
−1
2
−1
−1
2
−1
−1
1










,

Structured Priors Recognizing Similarity over Time and Space
153
while for a second order random walk with βt ∽N(2βt−1 −βt−2, W), one has,
K =














1
−2
1
−2
5
−4
1
1
−4
6
−4
1
1
−4
6
−4
1
..
..
..
..
1
−4
6
−4
1
1
−4
6
−4
1
1
−4
5
−2
1
−2
1














.
For an RW(p) prior at equally spaced time points, the elements of the
matrix K (apart from edge eﬀects) are expressible as,
kij = (−1)|i−j|

2p
p −|i −j|

if |i −j| ≤p,
and kij = 0 otherwise (Sun et al., 2006, Equation 10).
Let βab denote the subvector (βa, βa+1, . . . , βb) of state eﬀects, and Kab
denote the corresponding submatrix of K. Let K1,a−1 and Kb+1,T denote the
submatrices to the left and right of Kab, namely,
K =


K′
1,a−1
K1,a−1
Kab
Kb+1,T
K′
b+1,T

.
Then the conditional density for βab given β1,a−1, βb+1,T and W is normal,
βab ∽N(νab, WK−1
ab ), where
νab =
−K−1
ab Kb+1,T βb+1,T
−K−1
ab [K1,a−1β1,a−1 + Kb+1,T βb+1,T ]
−K−1
ab K1,a−1β1,a−1
a = 1
a > 1, b < T
b = T.
Using this density, a Metropolis–Hastings block sample may be used to
update the full conditional,
p(βab|) ∝
b

t=a
p(yt|βt)p(βab|βb+1,T , β1,a−1, W).
This involves drawing a proposal, βab, from N(νab, WK −1
ab ) with {νab, Kab}
evaluated at the current sampled values β and W in a chain, with the proposal
accepted or rejected according to a probability,
min

1,
b

t=a
p(yt|β∗
t )
 b

t=a
p(yt|βt)

,
which may be calculated by comparing likelihoods only (Knorr-Held, 1999,
134).

154
Applied Bayesian Hierarchical Methods
4.3.3
Basic structural model
To allow for a trend in the mean level or signal, one may extend the state
equation in Equation 4.1 to include a stochastic increment, so that,
yt = βt + ut,
βt = βt−1 + ∆t + w1t,
∆t = ∆t−1 + w2t,
where ∆t represent the changing slope of the trend. This provides the local
linear trend model or dynamic trend model (Fruhwirth-Schnatter, 1994). A
constant parameter, ∆, models a linear trend, as in the Carter–Lee mortal-
ity forecasting model considered by Pedroza (2006); this is sometimes known
as a random walk with drift. Other variations on the local linear model in
Equation 4.1 include autoregressive rather than random walk state equations,
such as,
βt = φβt−1 + wt,
as in Carlin et al. (1992, 496). An autoregression or random walk in y itself
might be added, as in Ghosh and Tiwari (2007), who assume a local linear
model for common cancer deaths of the form yt+1 ∽N(yt + βt, V ).
The basic structural model or unobserved components model (Koopman,
1993; Koopman et al., 1999) adds seasonal eﬀects, st, to the above local linear
trend model, so that with µt representing the level of the series, one has,
yt = µt + st + ut,
µt = µt−1 + ∆t + w1t,
∆t = ∆t−1 + w2t,
st + st−1 + · · · + st−S+1 = w3t,
where S is the number of seasons, and wjt ∼N(0, Wj). Fruhwirth-Schnatter
(1994) sets out the full conditionals for this model under gamma priors for
the precisions 1/Wj. The last equation provides the time domain prior for
seasonal eﬀects, whereas a frequency domain prior speciﬁes,
st =
[S/2]

j=1
sjt,
sjt = sj,t−1 cos (λj) + vj,t−1 sin (λj) + w3t,
vjt = −sj,t−1 sin(λj) + vj,t−1 cos(λj) + w4t,
where λj = 2πj/S and [S/2] denotes the integer part of S/2.
Certain series (e.g., natural phenomena) may show unknown periodicities,
so cyclical components are added as well as, or instead of, seasonal com-
ponents. For example, Piegorsch and Bailer (2005, 229) consider unknown
frequencies in carbon dioxide concentrations from Mauna Loa volcano in

Structured Priors Recognizing Similarity over Time and Space
155
Hawaii. So for a local linear trend model with a single unknown cycle,
yt = µt + ct + ut,
µt = µt−1 + ∆t + w1t,
∆t = ∆t−1 + w2t,
ct+1 = ct cos(λ) + dt sin(λ) + w3t,
dt+1 = −ct sin(λ) + dt cos(λ) + w4t,
where λ is an unknown frequency.
4.3.4
Identiﬁcation questions
Identiﬁcation issues in state–space random eﬀect models occur for two main
reasons. One is that the mean or level of the state eﬀects is not speciﬁed
(rather the mean of pairwise or higher diﬀerences is speciﬁed). The other is
the presence of multiple confounded sources of random variation, as in the
basic structural model with level and seasonal eﬀects, whereas the data can
only identify the sum of the random eﬀects, µt+st. These questions raise issues
in MCMC sampling because an intercept (if included) will be confounded with
the mean of at least one set of random eﬀects.
To exemplify issues occurring due to the mean of the latent series, consider
the measurement error with RW(1) signal model in Section 4.3.1. The state
equation can be stated as,
∆βt = βt −βt−1 ∽N(0, W),
so the prior only deﬁnes a level for diﬀerences in βt, but the level of (undif-
ferenced) βt is not deﬁned by the prior. If the model for yt does not have a
separate intercept parameter, the level of βt will be identiﬁed by the level of
yt. Suppose though that the observation equation includes a separate constant
with,
yt = µ + βt + ut.
Then µ and the mean of βt are confounded and for identiﬁcation, one may
apply a centering or corner constraint to βt. An identifying corner constraint
involves setting a single βt to a known value; taking the initial condition β1 to
have a known value, e.g., β1 = 0, is one option (Clayton, 1996). By contrast,
if the initial conditions (β1 in an RW(1) prior, β1 and β2 in an RW(2) prior,
etc.) are taken as unknowns, then a centering constraint may be applied at
each MCMC iteration, so that the centered βt satisfy T
t=1 βt = 0.
As in other models with multiple sources of random variation, priors on
the variance components in state–space models may aﬀect inferences. This
is not simply a matter of scale and shape options for inverse gamma priors,
but of how priors on variances (or precisions) inﬂuence the partitioning of
total random variation between diﬀerent sources (such as measurement error
and state error variation in the simple signal model). One may recognize the

156
Applied Bayesian Hierarchical Methods
interdependence between variance components using devices such as uniform
priors on shrinkage ratios, B = V/(V + W), combined with a prior on V
or V + W (Daniels, 1999). Alternatively, (V, W) may be reparameterized as
(V, qV ) where q is a signal to noise ratio. So with an inverse gamma prior
on V , the prior on q might be centered on 1, in line with a prior belief that
signal and observation variances are equal.
These approaches extend to models with competing sources of varia-
tion in the state equation. Consider the three errors, wjt (for levels, slopes,
and seasonals), in the basic structural model. Denoting Wj = Var(wjt) and
V = Var(ut), one may set Wj = qjV where qj are signal to noise ratios (Har-
vey, 1989, 33; Koopman, 1993). One may then set priors on the qj separately
(e.g., separate gammas), or jointly; for example, via a multivariate normal
on log(qj). Another option is a prior on V and uniform priors on the ratios
V/(V + Wj). Such devices amount to assuming prior correlation between the
respective variances.
An alternative approach to ensure stable identiﬁcation is to set informa-
tive priors on the variance of each random walk, possibly based on expected
stochastic variation around a deterministic trend. For example, following
Berzuini and Clayton (1994), for yt ∼Po(λt), consider a second order random
walk for βt = log(λt),
βt = 2βt−1 −βt−2 + wt,
then the value, W = 0, for Var(wt) corresponds to a log-linear deterministic
relationship between λt and time. To allow for stochastic variation, one may
assume,
νW ∗
W
∽χ2
ν,
or equivalently,
1/W ∼Ga

ν
2, W ∗ν
2

,
where W ∗is a prior guess at W, and higher values of ν represent stronger
degrees of belief in that guess. For example, taking W ∗= 0.01 corresponds
to assuming a 95% probability that λt will be within −18 and +22% of a
log-linear extrapolation from βt−1.
The single source of error approach (Ord et al., 2005) may also assist
in achieving parsimony, and in resolving the partitioning of variance between
multiple sources of variation in unobserved component models. Thus, the local
linear trend model in multiple source of error (MSOE) form is
yt = µt + ut,
µt = µt−1 + ∆t + w1t,
∆t = ∆t−1 + w2t,

Structured Priors Recognizing Similarity over Time and Space
157
but in single source of error form is
yt = µt + ut,
µt = µt−1 + ∆t + λ1ut,
∆t = ∆t−1 + λ2ut,
where λ1 and λ2 are loadings. In contrast to the MSOE scheme, the state and
observation errors are now correlated.
Example 4.1. Air Passenger Data
As an example of the kind of issues
that might occur in partitioning the sources of variation in a basic structural
model, consider air passenger data analyzed in West and Harrison (1997)
and elsewhere, namely, monthly totals of international airline passengers (for
1949–1961, so T = 144). A monthly seasonal eﬀect is assumed, so there are
S −1 = 11 initial conditions for the st sequence. Then,
yt = µt + st + ut,
µt = µt−1 + ∆t + w1t,
∆t = ∆t−1 + w2t,
st + st−1 + · · · + st−S+1 = w3t,
with wjt ∼N(0, Wj), ut ∼N(0, V ). A stable solution may depend on in-
troducing some context-speciﬁc information and also inspecting the data to
see what priors on hyperparameters are sensible, especially the variances
{V, W1, W2, W3}, without actually using data-based priors. Adopting vague
priors on variance parameters may mean the trend and level components are
not well identiﬁed empirically.
In this spirit, a diﬀuse Ga(1, 0.001) prior is assumed on 1/V , but priors
on {qj, j = 1, 3} where Wj = qjV, are set in line with contextual informa-
tion and a general belief that “level and slope both change slowly over time”
(Harvey and Todd, 1983, 300), such that the µt and ∆t sequences should not
show erratic ﬂuctuations. On the other hand, seasonal ﬂuctuations may be
pronounced, as a plot of the data suggests. So q3 ∼Ga(1, 0.001), while q1 and
q2 are assigned E(10) priors, implying that W1 and W2 are expected to be
small compared to V . N(0, 1000) initial condition priors are assumed for the
seasonal and growth eﬀects.
The second half of a two chain run of 20,000 iterations is used for
inferences1. Figure 4.1 shows a smoothly evolving mean and clear seasonal
variations. Underlying growth (shown by the posterior means of the ∆t param-
eters in the trend ﬁgure) is generally positive, though stalls between months
50–60 and 100–120. The posterior means (medians) of the Wj are 0.76 (0.74),
0.75 (0.70), and 172 (170), while those for qj are 0.15 (0.11), 0.23 (0.20), and
58 (46).
An alternative prior sets qj ∼N(0, 1) I(0, ), and also adopts less dif-
fuse N(0, 10) initial condition priors for the seasonal and growth eﬀects. This

158
Applied Bayesian Hierarchical Methods
Trend
–1 0
20
40
60
80
100
120
140
0
20
40
60
80
100
120
140
0
20
40
60
80
100 120
140
0
1
2
3
4
5
6
Month
Level
0
100
200
300
400
500
600
Seasonal
–150
–100
–50
0
50
100
150
200
Month
Month
Month
Trend (Truncated normal priors for variance scales)
1
1.5
2
2.5
3
3.5
4
0
20
40
60
80
100 120
140
FIGURE 4.1
Air passenger BSM.
achieves early convergence in a two chain run of 20,000 iterations (5000 burn
in). The posterior means on (q1, q2, q3) are 0.46, 0.0035, and 2.87, respectively.
There is a ﬂatter trend eﬀect (see Figure 4.1), though the level and seasonal
plots are very similar to those of the ﬁrst model.
Example 4.2. Global Sea Level Change
This example compares in-
sample predictions and out-of-sample forecasts from a local linear model with
linear trend, and a simple hierarchical model involving unit level linear trends.
A number of studies have analyzed local relative sea level records from tide
gauge observations, and considered broader inferences regarding global mean
sea level change. Local confounding factors may hinder quantifying a “global”
signal from such data. However, Patwardhad and Small (1992) consider a set
of stations from around the world with relatively long continuous records that
were representative of other stations in the same region, and seemed relatively
free of local confounding factors.
The analysis here follows them in using records for 1900–1980 from ﬁve sta-
tions, namely, San Francisco, Tonoura (Japan), Sydney, Bombay, and Cascais
(Portugal), with out-of-sample forecasts to 2000. The data are in millimeters
from the Permanent Service for Mean Sea Level website (http://www.pol.
ac.uk/psmsl). For station j at time t, the model used by Patwardhad and
Small (1992) involves a ﬁrst order random walk in the mean global sea level,
Mt, plus a homogenous linear trend (common coeﬃcient b across sites j). So
model 1 has,
yjt = Mt + bt + ujt,

Structured Priors Recognizing Similarity over Time and Space
159
with ujt ∽N(0, σ2), and Mt ∽N(Mt−1, σ2
M) for t > 1, and with the initial
condition M1 assigned a diﬀuse N(6,900, 10,000) prior. A gamma prior is
assumed for ς = (1/σ2) + (1/σ2
M) and with u ∽U(0, 1), one obtains (1/σ2) =
uς. Patwardhad and Small mention that compilations of trends in relative sea
level data suggest an upward trend of 0.5–3.0 mm/year, so a N(0, 1) prior
on b seems reasonable. An alternative model (model 2) allowing site-speciﬁc
linear trends is considered, namely,
yjt = Mt + bjt + ujt,
with ujt ∽N(0, σ2), bj ∽N(µb, σ2
b), Mt ∽N(Mt−1, σ2
M), and µb ∽N(0, 1).
For model 1, a two chain run of 25,000 iterations converges early, and the
last R = 20,000 iterations give a mean linear growth rate of 1.03 with 95%
interval 0.45 to 1.49. Variation around the evolving sea level, Mt, is compar-
atively small, with the posterior median of σ2
M standing at 4, compared to a
median 2010 for σ2. Figure 4.2 plots the smoothed series, Mt, through to 1980,
with forecasts thereafter. Let yrep,jt be replicate data from the model. Then
a posterior predictive loss (PPL) criterion is calculated (within the observed
data period to 1980) as,
PPL =
80

t=1
5

j=1
V (yrep,jt) + 1
R
k
k + 1
80

t=1
5

j=1
R

r=1
(y(r)
rep,jt −yjt)2,
and obtained (with k = 1) as 1830 in units of 1000. For model 2, a two chain
analysis with the same details gives a mean (95% interval) for µb of 0.82 (0.13,
1.47). Variation around the evolving sea level, Mt, is raised, with the posterior
median of σ2
M now 7.2, and the median σ2 reduced to 1378. The PPL is much
reduced, namely, 1273.
–20
0
20
40
60
80
100
120
140
160
1900
1910
1920
1930
1940
1950
1960
1970
1980
1990
2000
mm rise compared to 1900
Mean
2.5%
97.5%
FIGURE 4.2
Change in global sea level (in mm relative to 1900).

160
Applied Bayesian Hierarchical Methods
Example 4.3. Luteinizing
Hormone:
State–Space
Version
of
an
ARMA Model
Koopman et al. (1999) consider state–space versions of
the ARMA(p, q) model involving latent data, zt, whereby for (for p > q),
yt = zt + ut,
zt = φ0 + φ1zt−1 + · · · + φpzt−p + (γ1 + φ1)ut−1 + (γ2 + φ2)ut−2
+ · · · + (γq + φq)ut−q + φq+1ut−q−1 + · · · + φput−p,
with an analogous expression for p ≤q. For the ARMA(1, 1) model, one
obtains,
yt = zt + ut,
zt+1 = φ0 + φ1zt + (γ1 + φ1)ut,
that is zt+1 ∽N(φ0+φ1zt, (γ1+φ1)2σ2). Diﬀerent forms for stating the state–
space equivalent forms of an ARMA model for yt are considered by authors
such as De Jong and Penzer (2004) and Pearlman (1980).
Venables and Ripley (1994) analyze a series of 48 centered readings, yt,
of luteinizing hormone readings in a human female. They especially consider
AR(1), ARMA(1, 1), and AR(3) models. Here, a stationary ARMA(1,1) model
for centered data, namely,
yt = φyt−1 + ut + γut−1,
is estimated using the latent data approach, with,
yt ∽N(zt, σ2),
zt ∽N(φzt−1, (γ + φ)2σ2).
A two chain run2 of 10,000 iterations (1000 burn in) gives posterior means
(and 95% intervals) for φ and γ of 0.68 (0.44, 0.91) and 0.72 (0.16, 0.99). The
residual variance σ2 is estimated at 0.07, lower than reported by Venables and
Ripley. One step ahead forecasts are demonstrated in Figure 4.3.
4.4
Time Series for Discrete Responses:
State–Space Priors and Alternatives
Dynamic generalized linear models (DGLMs) extend the Gaussian state–space
representation to outcomes with density p(yt|ζt) belonging to the exponential
family of distributions, where ζt is the natural parameter. One may also con-
dition on the history of previous observations plus previous and current pre-
dictors, Dt−1 = (yt−1, yt−2, . . . , y1, Xt, . . . , X1) to allow for observation-driven
components in the model (Fahrmeier and Tutz, 2001, 242). So,
p(yt|ζt, Dt−1) = exp[φt{ytζt −b(ζt)}]c(yt, φt),

Structured Priors Recognizing Similarity over Time and Space
161
–1.25
–0.75
–0.25
0.25
0.75
1.25
0
5
10
15
20
25
30
35
40
45
50
Actual
One step ahead
FIGURE 4.3
Luteinizing hormone.
with µt = E(yt|ζt) = b′(ζt), and µt linked to a linear predictor, ηt, via a link
function, g, namely, g(µt) = ηt. Also, a known scale parameter, φt, deﬁnes the
conditional variance, Var(yt|ζt) = b′′(ζt)/φt. Then an observation equation for
design matrix, Xt, of dimension p would typically be of the form,
g(µt) = ηt = βtXt + ut,
with state or system equation,
βt = βt−1Gt + wt,
where wt ∼Np(0, W), and ut ∼N(0, V ) is not necessarily included for discrete
responses, but may be necessary to represent unstructured (or structured)
extra-variation.
An alternative state–space approach, sometimes termed a linear Bayes
approach, involves conjugate priors for the natural parameters and a guide
relationship,
h(ζt) = βtXt,
linking the natural parameters to the state vector (West et al., 1985, 74;
Ferreira and Gamerman, 2000, 60). So with time-speciﬁc parameters (gt, ht),
the prior for the natural parameter at time t is
p(ζt|Dt−1, gt, ht) = k(gt, ht) exp[gtζt −htb(ζt)],
while the updated natural parameters have density,
p(ζt|Dt, gt, ht) = k(gt, ht) exp[(gt + φtyt)ζt −(ht + φt)b(ζt)].

162
Applied Bayesian Hierarchical Methods
As for normal linear state–space models, the state vector may include level,
trend, and seasonal eﬀects. For an underlying signal model (Xt containing
only an intercept), the observation and state equations become (Kitagawa
and Gersch, 1996, Chapter 13),
g(µt) = βt + ut,
∆kβt = wt,
with ut ∼N(0, V ), wt ∼N(0, W). Thus, Kashiwagi and Yanagimoto (1992)
consider Poisson data on disease counts, yt ∼Po(µt), and take k = 1 in
the signal equation. For binary data with πt = Pr(yt = 1), a signal may
be combined with Markov dependence on lagged responses (Cox, 1970). For
example, a time-varying level and lag 1 eﬀect could specify,
g(πt) = ηt = β1t + β2tyt−1,
(β1t, β2t) ∼N2([β1,t−1, β2,t−1], W).
Time series of categorical data vectors, namely, yt = (yt1, yt2, . . . , ytJ) with
only a single ytj = 1 if (say) diagnosis j applies, or mutually exclusive choices
j made at time t, are multinomial according to,
yt = (yt1, yt2, . . . , ytJ) ∽Mult(1, [pt1, pt2, . . . , ptJ]).
Typically, a multiple logit link is assumed for the unknown probabilities
ptj (Cargnoni et al., 1997; Fahrmeier and Tutz, 2001). A signal model would
then involve a (J −1) dimensional state vector, though by analogy to binary
Markov dependence, the regression term, ηtj, for the jth choice may also
involve lags on both the same response, yt−k,j, and lagged cross-responses,
yt−k,m (m ̸= j). For a general predictor, possibly varying by category, Xtj,
one has,
ptj = exp(βtjXtj)
 J

j=1
exp(βtjXtj),
where βtJ = 0 for identiﬁability. Cross-series borrowing of strength via random
walk priors may be applied for the J −1 category-speciﬁc state vectors, βtj.
Thus for the coeﬃcient on predictor k, Xtjk, one might have,
βtk ∽NJ−1(βt−1,k, Σk),
where βtk = (βt1k, . . . , βt,J−1,k), and Σk is of dimension J −1.
An alternative with binary and multinomial responses is to introduce the
augmented metric data, y∗
t , which underlie the observed discrete responses.
Thus, for binary data, consider the scheme,
y∗
t = βtXt + ut,

Structured Priors Recognizing Similarity over Time and Space
163
where y∗
t is positive or negative according as yt = 1 or yt = 0, and the variance
of ut is assumed known for identiﬁability, usually with Var(ut) = 1. A simple
signal model with Xt = 1 may then be expressed (Carlin and Polson, 1992,
583) as,
y∗
t |W, yt, βt ∝N(βt, 1) I(0, ∞)
if
yt = 1,
y∗
t |W, yt, βt ∝N(βt, 1) I(−∞, 0)
if
yt = 0,
βt ∼N(βt−1, W).
4.4.1
Other approaches
Another general scheme for modeling time series of exponential family data
is the generalized autoregressive moving average (GARMA) representation
(Benjamin et al., 2000; Li, 1994). This implies models with conditional means,
µt, link function, g(µt) = ηt, and regression term in the form,
ηt = γtXt +
p

j=1
φj[g(yt−j) −γt−jXt−j] +
q

k=1
γk[g(yt−k) −ηt−k].
For example, for Poisson data, yt ∼Po(µt), and y∗
t = max(yt, m) for a
small positive constant m, one has,
log(µt) = γtXt +
p

j=1
φj[log(y∗
t−j) −γt−jXt−j] +
q

k=1
γk[log(y∗
t−k/µt−k)].
More general autoregression in the state vector (not limited to random
walks) may be adopted. Thus, Chan and Ledolter (1995) and Oh and Lim
(2001) adopt an autocorrelated error, θt, for count data with yt ∼Po(eηt),
such that,
ηt = θt + Xtγ,
θt = ρθt−1 + wt,
with ρ constrained to stationarity. Dependence on lagged counts can also be
achieved by binomial thinning, whereby,
ηt = γtXt + ρ ◦yt−1,
is equivalent to ηt = γtXt + ht, ht ∼Bin(yt−1, ρ).
Conjugate mixture schemes for time series counts are exempliﬁed by Bock-
enholt (1999), and Jowaheer and Sutradhar (2002), with for instance,
yt ∼Po(eηtγt),
γt ∼Ga

1
c , 1
c

,
where ηt may be speciﬁed in state–space form, ηt = βtXt, βt = Gβt−1 + ωt.
Marginally, Var(yt) = exp(ηt) + c exp(2ηt).

164
Applied Bayesian Hierarchical Methods
TABLE 4.1
Treated schizophrenia by age and sex.
Cases
Population
Age
M
F
M
F
0–15
0
0
123,512
117,775
16–24
75
25
62,808
59,439
25–34
235
93
90,722
89,149
35–44
299
186
90,625
87,755
45–54
298
238
84,956
82,847
55–64
171
217
63,229
62,147
65–74
129
207
47,180
53,337
75–84
58
119
25,762
39,653
85+
6
40
6,037
15,886
All
1271
1125
59,4831
607,988
Example 4.4. Treated Schizophrenia
To illustrate dynamic general lin-
ear model (DGLM) approaches, consider data on treated schizophrenia preva-
lence totals, yag, by gender g and age a (a = 1, . . . , A for A = 9 age groups,
0–15, 16–24, 25–34, . . . , 65–74, 85+) from the General Practice Research
Database for England and Wales. This database covers around 1 in 40 of
the population of England and Wales and includes totals of patients being
treated for major chronic disease. The counts are zero for under 16s since
schizophrenia is very rare at these ages (Table 4.1).
Under a state–space approach, ﬁrst order random walks are assumed to
pool strength in prevalence estimates over adjacent ages, a. So with a Poisson
observation equation, one has,
yag ∽Po(ragPag/1000),
where Pag denote populations at risk by age and sex, and division by 1000
means that the rag will be rates per 1000 population. Then,
log(rag) = δag,
with gender-speciﬁc RW(1) priors for δag,
δag ∼N(δa−1,g, 1/τg),
to model anticipated correlation in prevalence for neighboring age bands, and
uniform priors on the standard deviations 1/τ0.5
g . A ﬁrst order antedependence
(AD1) model (model 2) is also applied with,
log(rag) = λag,
where,
λ1g = ω1g,
λag = φgλa−1,g + ωag
a > 1,

Structured Priors Recognizing Similarity over Time and Space
165
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
16–24
25–34
35–44
45–54
55–64
65–74
75–84
85+
No per 1000
Male
2.5% (M)
97.5% (M)
Female
2.5% (F)
97.5% (F)
FIGURE 4.4
Fitted prevalence curves by age, antedependence model.
where ωag ∽N(0, 1/χa) and φg ∽N(0, 1). A quadratic function in age is
assumed for the precisions, χa.
Two chain runs of 100,000 iterations are applied3 in OpenBUGS with
inferences based on the second halves of the sampling. Both models provide
a satisfactory predictive check (95% or over of observed data within 95%
credible intervals of replicate data) and both models have a DIC around 144.6,
though the AD1 model has fewer eﬀective parameters (14.7 vs. 18.4). The φ
coeﬃcients in the latter have means (and 95% interval) of 0.82 (0.46, 0.93)
and 0.94 (0.77, 1.02). Figure 4.4 plots the model 2 estimates of the male and
female series, rag.
Example 4.5. Warwick Telephone Calls
This example applies a dy-
namic GLM to half-hourly counts, yt, of incoming telephone calls at the Uni-
versity of Warwick over a week (so T = 7 × 48 = 336) (West et al., 1985).
Assuming Poisson distributed counts, yt ∼Po(µt), a log link model assumes
evolving level and cyclical terms, the latter modeled using K = 5 harmonics
of a Fourier representation with period S = 48. Then with,
log(µt) = βtXt,
βt = βt−1Gt + wt,
one possible parameterization takes βt of length 11, Xt = (1, 1, 0, 1, 0, 1, 0, 1,
0, 1, 0)′, Gt = (H0, H1, . . . , H5)′, and H0 = 1, with,

166
Applied Bayesian Hierarchical Methods
Hk =

cos(ηk)
sin(ηk)
−sin(ηk)
cos(ηk)

,
for k = 1, . . . , K, and ηk = (2πk/S).
Here the parameterization adopted is
log(µt) = λt +
K

k=1
ckt,
λt = λt−1 + w1t,
ckt = ck,t−1 cos(ηk) + dk,t−1 sin(ηk) + w2t,
dkt = −ck,t−1 sin(ηk) + dk,t−1 cos(ηk) + w3t,
wjt ∼N(0, Wj).
To partition the variance among the components the square root of the
total variance, Z = 
j Wj, is assigned a U(0, 10) prior and the variances Wj
obtained as Wj = Zqj, where qj are assigned a Dirichlet prior.
Convergence in a two chain run4 with default starting values (Z0.5 = 1 in
one chain, Z0.5 = 0.25 in the other, with the c, d, and λ parameters all set
to 0) is obtained after 35,000 iterations, and a further 15,000 provide posterior
medians for {W1, W2, W3} of 0.057, 6.1E-4, and 1.6E-4. The plot of one step
ahead forecasts (Figure 4.5) matches the observations reasonably well: 80% of
the observations (269/335) are included in the 95% credible intervals of the
one step ahead predictions.
0
20
40
60
80
100
120
140
160
180
200
1
13
25
37
49
61
73
85
97
109
121
133
145
157
169
181
193
205
217
229
241
253
265
277
289
301
313
325
Time (half hours)
Number of calls
Actual
One step ahead
FIGURE 4.5
One step ahead predictions, telephone call data.

Structured Priors Recognizing Similarity over Time and Space
167
4.5
Stochastic Variances
Many state–space applications assume constant variances in the observation
and state equations, but there is often nonstationarity in such variances (Broto
and Ruiz, 2004). Certain types of data such as exchange rate and share price
series, rt, are particularly likely to demonstrate volatility clustering (Granger
and Machina, 2006), with ﬂuctuating variances, Var(rt). There are periods
when volatility is relatively high and periods when volatility is relatively
low, often with relatively smooth transition between high and low volatility
regimes. In many applications the series is transformed to have an eﬀectively
zero mean (Meyer and Yu, 2000, 200); for example, the ratio of successive ex-
change rates, rt/rt−1, has approximate average 1, so that a response obtained
as yt = log(rt/rt−1) can be taken to average zero. Hence, one may write a
model without intercept (or predictor eﬀects) as,
yt = V 0.5
t
ut,
where ut ∼N(0, 1), but the variances Vt are unknowns.
Stochastic volatility models may apply state–space techniques to model
changing variances. A widely used template model in this class involves a
stationary state equation (Harvey et al., 1994; Jacquier et al., 2004; Kim
et al., 1998; Meyer and Yu, 2000). With θt = log(Vt), one has,
yt =
)
Vtut = exp

θt
2

ut,
(4.2)
θt = µ + φ(θt−1 −µ) + W 0.5wt
t > 1,
θ1 ∼N

µ,
W
1 −φ2

,

ut
wt

∼N


0
0

,

1
0
0
1

,
where |φ| < 1 measures persistence in the volatility, but the ut and wt series
are uncorrelated. This scheme can be generalized to multivariate responses
subject to volatility, such as a set of exchange rates—see Chapter 7, and Yu
and Meyer (2006).
As a heavy-tailed alternative, one may consider a Student t for the y series
as a scale mixture of normals (Jacquier et al., 2004). With ν degrees of freedom,
one has,
yt =
√
λt
)
Vtut =
√
λt exp

θt
2

ut,
1/λt ∼Ga
ν
2, ν
2

,
and other aspects as above. Although a uniform prior on ν is possible, for a
recent alternative prior (applicable to other types of Student t regression) see

168
Applied Bayesian Hierarchical Methods
Fonseca et al. (2008). This model deals with isolated y outliers by introducing a
large λt, and it requires a sequence of large |yt| before Vt is increased (Jacquier
et al., 2004, 190).
By
contrast,
generalized
autoregressive
conditional
heteroscedastic
(GARCH) models involve autoregression in y2
t and/or Vt. A GARCH(p, q)
model speciﬁes,
Vt = γ +
p

j=1
αjy2
t−j +
q

j=1
βjVt−j,
where coeﬃcients {γ, αj, βj} are constrained to be positive, and setting q = 0
leads to the ARCH(p) model (Engle, 1982). Stationarity requires,
p

j=1
αj +
q

j=1
βj < 1,
though is not necessarily imposed a priori. Whichever approach is used, de-
partures from normality are frequently relevant, such that yt/√Vt is non-
Gaussian. Among heavy-tailed alternatives, one may consider a Student t,
either ut ∼t(0, 1, ν), or as a scale mixture of normals (Bauwens and Lubrano,
1998; Chib et al., 2002).
In case y has a nonzero mean or there are predictors, one may widen the
model for y. For example, a model with a zero mean y and lag 1 eﬀect in y
would be
yt = ρyt−1 +
)
Vtut.
One variant is the doubly autoregressive model (Ling, 2004),
yt = ρyt−1 + ut
8
γ + αy2
t−1,
which can be shown equivalent to the random coeﬃcient AR model,
yt = (ρ + at)yt−1 + ct,
where (at, ct) are bivariate normal with mean 0 and covariance matrix,
Diag(α, γ).
A generalization of the state–space approach is to introduce correlation
between the ut and wt terms, and so reﬂect leverage eﬀects. Positive and
negative shocks then have diﬀerent impacts on future volatility (Asai et al.,
2006; Jacquier et al., 2004; Meyer and Yu, 2000; Chen and So, 2006). So one
possible scheme has
yt =
)
Vtut = exp

θt
2

ut,
θt = µ + φ(θt−1 −µ) +
√
Wwt,

ut
wt

∼N


0
0

,

1
ϕ
ϕ
1

,

Structured Priors Recognizing Similarity over Time and Space
169
where ϕ is a correlation. A heavy-tailed version of the leverage model (Jacquier
et al., 2004) may be obtained with,
yt =
√
λt exp

θt
2

ut,
1/λt ∼Ga
ν
2, ν
2

.
A GARCH model including leverage is obtained by setting zt = √Vtut in
yt = µy +ρ(yt−1 −µy)+√Vtut. Leverage is then obtained under the following
asymmetric model (Glosten et al., 1993),
Vt = γ + α1z2
t−1 + α2z2
t−1I(zt−1 > 0) + βVt−1.
Under the model (Equation 4.2), assume priors µ ∼N(0, σ2
µ), (φ + 1)/2 ∼
Be(rφ, sφ), and W ∼IG(κW , λW ), where {σ2
µ, rφ, sφ, κW , λW } are known.
Then, with ψ = (µ, φ, W), the posterior is
p(ψ|y) ∝
 T

t=1
exp{−θt/2} exp
*−y2
t
2eθt
+
×

1 −φ2
W
0.5
exp
*1 −φ2
2W
(θ1 −µ)2
+
×
 T

t=2

 1
W
0.5
exp
*
−1
2W (θt −µ −φ(θt−1 −µ))2
+
p(µ)p(φ)p(W),
and Gibbs sampling from full conditionals is obtained (Kim et al., 1998). The
griddy-Gibbs technique may also enable Gibbs sampling of all parameters
in a GARCH (1, 1) model, with normal or Student distributed ut (Bauwens
and Lubrano, 1998). Chib et al. (2002) consider more general Metropolis–
Hastings techniques, including particle ﬁltering, to sample from models with
discontinuities in the observations.
Example 4.6. US 90-Day Treasury Bill Rate
Consider 350 observa-
tions, rt, of the US 90-day bill rate from July 1972 to August 2001. The data
are obtained as yt = log(rt/rt−1)—see Figure 4.6 for a plot of log(rt), which
shows several spells of high volatility. As one of several ways to represent the
data, the double autoregressive model (Ling, 2004), namely,
yt = ρyt−1 + ut
8
γ + αy2
t−1,
is applied5, with the constraint ρ2 + α < 1 suﬃcient to ensure E(y2
t < ∞).
The analysis conditions on the ﬁrst observation. A two chain run of 5000
iterations with 500 burn-in gives posterior means (sd) for ρ and α of 0.43

170
Applied Bayesian Hierarchical Methods
1.0
1.2
1.4
1.6
1.8
2.0
2.2
2.4
2.6
2.8
3.0
0
50
100
150
200
250
300
350
FIGURE 4.6
Treasury bill rate.
(0.07) and 0.50 (0.10), with γ estimated as 0.0018. Despite its low param-
eter count, sampling replicate data from this model provides 93.4% con-
cordance with the actual observations; i.e., 93.4% of the data points are
contained with 95% credible intervals of replicate data sampled from the
model. A PPL criterion deﬁned for iterations r = 1, . . . , R after the burn-in is
obtained as
PPL =
350

t=2
Var(yrep,t) +
1
4500
k
k + 1
349

t=2
R

r=1
(y(r)
rep,t −yt)2,
and for k = 1 and k = 100 has values 2.59 and 3.83.
A second approach is based on a stationary state–space stochastic volatility
model with,
yt =
)
Vtut = exp

θt
2

ut,
θt = µ + φ(θt−1 −µ) + W 0.5wt
t > 1,
where a Beta prior is adopted on φ∗, with φ obtained as 2φ∗−1 (Meyer
and Yu, 2000), and 1/W ∼Ga(2.5, 0.025). Starting values are important for
early convergence of this model and are based on exploratory analysis showing
µ ⋍−6. With inferences from the second half of a two chain run of 100,000
iterations, this model produces PPL values of 2.71 and 4.04 at k = 1 and
k = 100. Figure 4.7 plots the evolving variance, Vt = exp(θt), under this
model.

Structured Priors Recognizing Similarity over Time and Space
171
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0.016
0.018
0.02
0
50
100
150
200
250
300
350
FIGURE 4.7
Plot of variances under state–space volatility.
4.6
Modeling Discontinuities in Time
Aberrant observations or shifts in a series can bias parameter estimates and
other inferences in time series models (Chen and Liu, 1993; Hamilton, 2009;
Tsay, 1986), and a variety of methods exist for modeling shifts or outliers
in the observation, state, or error series. These extend to shifts in variance
parameters also.
Robust versions of the priors for the component errors ut and/or wjt in
dynamic models may be applied to allow ﬂexibility in response to disparate
observations. For example, a heavy-tailed alternative to Gaussian errors (Mar-
tin and Raftery, 1987) may be invoked by scale mixing at both levels in the
local level model,
yt = βt + ut, βt = βt−1 + wt,
with,
ut ∽N(0, V/λ1t), wt ∽N(0, W/λ2t),
λ1t ∽Ga
νu
2 , νu
2

, λ2t ∽Ga
νw
2 , νw
2

.
This generalization is adapted to detecting or accommodating additive
outliers (outliers in the observation equation errors) and innovation outliers
in the state equation errors. Geweke (1993) points out problems with adopting
diﬀuse priors for ν, and possibilities include an exponential density such as
ν ∼E(0.1) (Fernandez and Steel, 1998).

172
Applied Bayesian Hierarchical Methods
Many outlier mechanisms involve discrete mixing around default nor-
mal error assumptions, as in a contaminated normal density (Verdinelli and
Wasserman, 1991). Thus, let π be a given prior probability of an outlier (e.g.,
π = 0.05). Then the observation error in a state–space model can be modiﬁed
to allow innovation outliers,
ut ∽(1 −π)N(0, W1) + πN(0, W2),
where W2 = KW1 with K large. A comprehensive generalization of the normal
errors dynamic linear model is provided by taking yt and βt to follow the
univariate or multivariate exponential power distribution (Gomez et al., 2002).
More specialized binary switching in observation error or state error pro-
cesses may be applied (Diggle and Zeger, 1989), for example, adapted to
positive pulses (e.g., periods with abnormally heavy rainfall). To illustrate
switching in observation errors to accommodate positive pulses, consider the
AR(1) observation model,
yt = φyt−1 + ut,
such that usually ut = u1t, but exceptionally ut = u2t, where the latter error
is necessarily positive, namely,
u1t ∼N(0, σ2),
u2t ∼Ga(g1, g2),
where {g1, g2} are preset. Deﬁne latent allocation indicators, St ∈(1, 2), as in
Chapter 3. Then ut = u2t with probabilities πt = Pr(St = 2), which might
be deﬁned by a separate model such as,
logit(πt) = η0 + η1yt−1.
One may also distinguish innovation outliers from additive outliers cor-
responding to isolated shifts or “gross errors” in the observation series (Fox,
1972; Tsay, 1986). This involves separate binary indicators {SAt,SIt}, or a
single multinomial indicator, St. For example, let πA and πI be prior proba-
bilities of additive and innovative outliers, and consider an AR(1) observation
model with AR(1) errors,
yt = φ0 + φ1yt−1 + atSAt + εt,
εt = ρεt−1 + ut,
where SAt ∼Bern(πA), and at ∼N(0, σ2
a) represents the sizes of the additive
outliers (McCulloch and Tsay, 1994). Innovation outliers are encompassed by
a variance inﬂation mechanism with,
ut ∼(1 −πI)N(0, V ) + πIN(0, KV ),
with K > 1, as determined by latent indicators, SIt ∼Bern(πI).

Structured Priors Recognizing Similarity over Time and Space
173
The possibility of additive and innovative outliers coinciding at a single
point may be discounted (Barnett et al., 1996; Gerlach et al., 1999). So with
both additive and innovation outliers generated by variance inﬂation factors
(respectively, KA and KI), one may have a single trinomial indicator, St, gov-
erning outlier occurrence, with St = 1 if neither type of outlier is present
(KA = 0, KI = 1), St = 2 if an additive outlier is present (KA = 10,
KI = 0), and St = 3 if an innovation outlier is present (KA = 0, KI = 10).
Then,
St ∼Mult(1, [π1, π2, π3]),
where π2, and π3 may be assigned preset values (e.g., π2 = π3 = 0.025), and,
yt = φ0 + φ1yt−1 + atSt + εt,
εt = ρεt−1 + utSt,
where atSt ∼N(0, KAσ2), utSt ∼N(0, KIσ2).
Enduring rather than temporary shifts in the mean or variance of a series
require another approach. Models with a single or small number of enduring
changes in the level of the series may be handled by extending conventional
discrete mixture methods (e.g., Leonte et al., 2003; Mira and Petrone, 1996;
Perreault et al., 2000). To illustrate binary switching in both levels and vari-
ances in an autoregressive error model (McCulloch and Tsay, 1993), deter-
mined by binary pairs (S1t, S2t), consider,
yt = µt + εt,
where a change in level is accomplished by letting,
µt = µt−1 + S1t∆t,
when S1t = 1, with Pr(S1t = 1) = π1, and ∆t are random eﬀects representing
the shifts. The errors are AR(p),
εt = ρ1εt−1 + ρ2εt−2 + · · · + ρt−pεt−p + ut,
where shifts in the variance of ut ∼N(0, Vt) occur when S2t = 1 with Pr(S2t =
1) = π2. If there is conditioning on (y1, . . . , yp), then the variance sequence
commences with Vp+1 = σ2, and subsequently,
Vt = Vt−1
when
S2t = 0,
Vt = κt Vt−1
when
S2t = 1,
where κt are positive variables (e.g., gamma distributed) that model propor-
tional shifts in the error variance.
Shocks in diﬀerent components of the basic structural model can also be
considered (De Jong and Penzer, 1998; Penzer, 2006). For example, in a three

174
Applied Bayesian Hierarchical Methods
component local linear trend model, binary shock indicators (S1t, S2t, S3t) are
invoked such that,
yt = µt+S1t∆1t + ut,
µt = µt−1 + S2t∆2t + ∆t + w1t,
∆t = ∆t−1 + S3t∆3t + w2t,
where ∆1t represent temporary additive shocks that occur when S1t = 1, ∆2t
represent shifts in mean, and ∆3t represent shifts in the slope.
Regime switching models (Geweke and Terui, 1993; Lubrano, 1995) typi-
cally involve discrete switching between two or more levels, regression regimes,
or variances, though smooth transition mechanisms can also be used. The
choice between regimes is governed by a binary switching function, St, or a
continuous transition function, φt, with values between 0 and 1, such as the
logit (Bauwens et al., 2000). A binary function, St, might be deﬁned as 1 if
time t exceeds a threshold κ and zero otherwise, as in change point models for
the mean level of a series. In self-exciting threshold autoregressive (SETAR)
models, the mechanism involves a lag in y; for example, St = 1 if yt−1 > κ.
The continuous version in these two cases would be
φt =
exp(ω[t −κ])
1 + exp(ω[t −κ]),
φt =
exp(ω[yt−1 −κ])
1 + exp(ω[yt−1 −κ]),
where ω is an extra unknown. Additionally, the lag r in the comparison
yt−r > κ may be unknown (Geweke and Terui, 1993).
Example 4.7. Nile Discharges
Data on Nile discharges for 1871–1970
(T = 100) have been analyzed by a variety of ARMA and other methods
and illustrate possible identiﬁcation issues associated with outlier and shift
points. Balke (1993) compares an AR(2) model for these data to one allow-
ing for an intercept shift. To facilitate prior speciﬁcation for latent preseries
values, y0 and y−1, we center the original data, Yt, by subtracting Y1 from all
points. So yt = Yt−Y 1.
Firstly, an AR(2) model with no shift mechanism (and a heavy-tailed prior
for the preseries points) is applied, namely,
yt = φ0 + φ1yt−1+φ2yt−2 + ut
t = 1, . . . , T,
ut ∼N(0, σ2),
yt ∽t2(0, σ2)
t = −1, 0,
with N(0, 1) priors on {φ1, φ2} so that nonstationarity is allowed. A two chain
run6 of 10,000 iterations (with 1000 burn-in) provides a DIC (and eﬀective
parameters de) of 1282.5 (4.3). The posterior means (and 95% intervals) on the
AR parameters {φ1, φ2} are obtained as 0.40 (0.21, 0.59), and 0.21 (0.02, 0.40).

Structured Priors Recognizing Similarity over Time and Space
175
Suppose, however, a shift in the series level is allowed: a series plot sug-
gests such a shift around 1895. One may also allow for coeﬃcient selection
via binary variables, dj = 1, if φj is to be retained, with prior probabilities
Pr(dj = 1) = 0.5. So,
yt = φ01 + φ02I(t > κ) + d1φ1yt−1 + d2φ2yt−2 + ut,
where κ is taken to be uniform between 3 and T-3. Fitting this model indi-
cates that the lag in yt−2 is now in doubt, with Pr(d2 = 1|y) = 0.09, whereas
Pr(d1 = 1|y) = 0.25.
So an AR(1) model with shift mechanism is applied, namely,
yt = φ01 + φ02I(t > κ) + φ1yt−1 + ut
t = 1, . . . , T.
With a two chain run of 10,000 iterations (and 1000 burn-in), the DIC is
reduced to 1260.5 with de = 5.5, and κ is precisely identiﬁed with mean 28.2
(i.e., the year 1998) and 95% interval (26.1, 30.3). The lag 1 coeﬃcient esti-
mate is now in fact not strictly signiﬁcant in the sense that the 95% interval
(−0.04, 0.35) straddles zero. A suggested exercise is to ﬁt a SETAR model,
yt = φ01 + φ02I(yt−1 > κ) + φ1yt−1 + ut
t = 2, . . . , T,
and assess the impact on φ1.
Example 4.8. Box–Jenkins Series A
This example involves the Box–
Jenkins series A, and entails outlier modeling via variance inﬂation in the
observation component of an autoregressive state–space model (cf. Gerlach
et al., 1999). The observation model is
yt ∽N(β0 + θt, VSt),
where St is a trinomial indicator modeling the measurement error outlier
mechanism. The state equation is
θt = φθt−1 + wt,
where wt ∽N(0, W), and φ is constrained to stationarity.
As discussed above, outlier probabilities are often preset. However, if vari-
ance inﬂation factors are preset instead, then it is possible to take the outlier
probabilities as unknowns. Thus, assume π1 = Pr(St = 1) is the unknown
probability of a normal measurement error with variance V1, while π2 = π3
are unknown probabilities of moderate and extreme outliers with variances
10V1 and 32V1, respectively. It is assumed that V1 ∽Ga(1, 0.001), together
with the parameterization,
π1 = 1/(1 + r),
π2 = π3 = 0.5r/(1 + r),
where r ∽E(9). Additionally, the variances of the observation and state
equations are linked by taking W = qV 1 with an E(1) prior on q.

176
Applied Bayesian Hierarchical Methods
A two chain run7 of 20,000 iterations (and 2000 burn-in) in OpenBUGS
shows early convergence with estimated probability π1 = 0.93 (and 95%
interval from 0.77 to 0.99). The observation error variance, V1, has a pos-
terior mean of 0.031, while the state variance, W, has mean 0.036.
4.7
Spatial Smoothing and Prediction for Area Data
Whereas exchangeable hierarchical analysis is appropriate for independently
generated area or point data, such data often cannot be regarded as inde-
pendent because of the presence of similarities between neighboring areas or
points (Anselin and Bera, 1998). Modeling area diﬀerences or point patterns
with spatially structured eﬀects reﬂects the empirical regularity that neighbor-
ing areas or points tend to be similar, and that similarity typically diminishes
as distance increases. Even if some known predictors are available, it is likely
that other relevant inﬂuences on the underlying process cannot be identiﬁed
or measured, and this residual heterogeneity is likely (at least in part) to be
spatially structured (Lawson, 2008, 94); for example, Gelfand et al. (2005a)
consider spatial modeling of residuals in the analysis of species distributions,
both for areas and points as the units, where unobserved inﬂuences might in-
clude habitat and interspecies competition. Bayesian techniques have played a
central role in recent developments for analyzing spatial data, whether space
is viewed from a discrete or continuous perspective, e.g., Banerjee et al. (2004)
and Waller (2002).
In studies with a discrete framework, the data are typically aggregated,
with observations consisting of counts (e.g., of diseased subjects in spatial
epidemiology) or of regional indicators (e.g., average income per head or
house prices in spatial econometrics). By contrast, in geostatistical models
for geochemical readings, species distribution, or disease events in relation
to a pollution source, a continuous spatial framework is more relevant (Sec-
tion 4.11), allowing interpolation between observed point readings.
Consider metric responses yi for areas i, or at sites speciﬁed by grid
references gi = (g1i, g2i). To allow greater ﬂexibility, one may assume a “con-
volution” prior that compromises between structured and unstructured varia-
tion: so the model includes both a spatially structured random eﬀect, si, and
a fully exchangeable eﬀect, ui, with,
yi = α + ui + si,
where ui ∽N(0, σ2
u), but si is spatially correlated. Alternatively, suppose yi
are counts, and that Pi are populations at risk with yi ∽Bin(Pi, πi). Then,
one may specify,
logit(πi) = α + ui + si,

Structured Priors Recognizing Similarity over Time and Space
177
where πi are latent probabilities of the event. Alternatively, for rare events
in relation to the risk population, a Poisson assumption is relevant with yi ∽
Po(Piλi), and,
log(λi) = α + ui + si,
where λi are latent event rates per unit of Pi. If the oﬀsets to the Poisson mean
are expected health events, Ei, such that 
i yi = 
i Ei with yi ∽Po(Eiλi),
then λi are interpretable as latent relative risks (Wakeﬁeld, 2007, 160).
One way to model the correlation in the elements of the vector s =
(s1, . . . , sn) is to directly specify a joint multivariate prior with a covari-
ance matrix that expresses spatial correlation between areas i and j or sites
gi and gj (Richardson et al., 1992, 541; Wakeﬁeld, 2007). Typical assump-
tions in such models (also considered in Section 4.11) are of stationarity and
isotropy, with the latter meaning the correlation is the same in all directions.
For example, a multivariate normal prior would take,
(s1, . . . , sn) ∽Nn(0, Σs),
where,
Σs = σ2
sW = σ2
s


1
w12
·
w1n
w21
1
·
w2n
·
·
·
·
wn1
wn2
·
1

,
and wij = f(dij) are correlation functions that decline as the spatial separa-
tion, dij, between areas i and j (or sites gi and gj) increases. For this model,
one may decompose the total residual variation (metric response) or the total
residual relative risk (count models with oﬀset Ei) into spatial and nonspatial
components, σ2
s and σ2
u.
The correlation functions are deﬁned to ensure that W is always non-
negative deﬁnite (Mardia and Watkins, 1989). Cook and Pocock (1983)
suggest,
wij = exp(−δdij),
where δ > 0, while Cliﬀand Ord (1973) propose a function combining inter-
area distance, dij, and length bij of the common border between area i and j,
namely,
wij = [dij]β1[bij + c]β2,
where β1 is negative and β2 is positive. Another choice is the disc model with,
wij = 2
π

cos−1

dij
κ

−

dij
κ

1 −d2
ij
κ2
0.5

dij ≤κ,

178
Applied Bayesian Hierarchical Methods
with wij = 0 for dij > κ, so that κ controls the decline in correlation with
distance. Such choices are to some degree arbitrary, and inferences may be sen-
sitive to the choice of spatial weights (e.g., Bhattacharjee and Jensen-Butler,
2006).
Another widely used scheme speciﬁes the joint density via simultaneous
autoregressive or SAR eﬀects (Richardson et al., 1992). By analogy with
ARMA time series models, the autoregression may operate both for (met-
ric) responses, y = (y1, . . . , yn)′, and for the error vector, s = (s1, . . . , sn)′.
Let W = [wij] be a spatial dependence matrix as above, but with wii = 0
rather than wii = 1. One possible SAR scheme has the form,
yi = α + ρ1

h̸=i
wihyh + si,
si = ρ2

h̸=i
wihsh + ui,
where ρ1 and ρ2 are coeﬃcients of spatial autocorrelation, and u = (u1, . . . ,
un)′ are independently distributed, with diagonal covariance matrix, Σu. The
covariance matrix, for s = (s1, . . . , sn)′ is (I −ρ2W)−1Σu(I −ρ2W ′)−1. In
matrix form,
y = 1α + ρ1Wy + s,
s = ρ2Ws + u,
where 1 is a n × 1 vector of ones. The simultaneous autoregressive prior par-
allels autoregressive models in time, such as one with AR(1) dependence in
both y and the errors,
yt = α + ρ1yt−1 + εt,
εi = ρ2εt−1 + ut.
Wall (2004) points out that SAR priors (and also CAR priors, as considered
below) may generate implausible covariance patterns when considered in terms
of the joint priors.
The ρ coeﬃcients are constrained to lie between (1/ηmin) and (1/ηmax),
where {η1, . . . , ηn} are the eigenvalues of W, in order to ensure that (I −ρW)
is invertible. This restriction can be implemented by choosing unconstrained
priors for ρ1 and ρ2, but retaining only sampled values satisfying the criterion.
If the spatial lag matrix in a SAR model is standardized to have row sums
of unity, so that w∗
ij = wij/
h wih, then the maximum eigenvalue of W ∗is 1
and since negative spatial correlation is unlikely, one may specify uniform or
beta priors on ρ coeﬃcients in the interval [0, 1].
Metropolis–Hastings updates are generally needed for the correlation pa-
rameters. Consider the spatial autoregressive model with ρ2 = 0, namely,
y = 1α + ρWy + u.

Structured Priors Recognizing Similarity over Time and Space
179
Assuming Σu = σ2I, the likelihood is (Lesage, 1997),
L

α, ρ, σ2|y

∝1
σn |I −ρW| exp

−1
2σ2

i
u2
i

,
where ui = yi −α −ρ 
h̸=i wihyh. With normal and inverse gamma priors on
α and σ2, Gibbs updates may be used for these parameters, but Metropolis–
Hastings sampling must be used for ρ, which has conditional posterior,
p

ρ|α, σ2, y

∝|I −ρW| exp

−1
2σ2

i
u2
i

.
4.8
Conditional Autoregressive Priors
In contrast to simultaneous autoregressive spatial priors, conditional autore-
gressive priors for (s1, . . . , sn) have the advantage of facilitating random eﬀects
analysis under a MCMC sampling approach. Such priors are often applied to
discrete outcomes, such as health event counts, yi, taken to be Poisson or
binomial in relation to populations, Pi, or expected events, Ei (e.g., Besag
et al., 1991; Norton and Niu, 2009). If there are no measured risk factors and
the event is relatively infrequent (or populations at risk are small), one often
seeks to estimate an underlying smooth pattern of relative risk by “borrowing
strength” over areas taking account of spatial dependence (MacNab et al.,
2006, 3967). Simple maximum likelihood estimates of event rates, yi/Pi, or
relative risks (e.g., by ratios ri = yi/Ei of observed to expected events) assume
a binomial or Poisson density with disease risk constant over areas and indi-
viduals within areas. In practice, individual risks vary within areas, and risks
vary between areas, so that area counts are more variable than the standard
density stipulates.
The extra-variation can be modeled by including random eﬀects in a model
for disease rates or risks, whether by conjugate (e.g., Poisson-gamma) or non-
conjugate methods. Spatially correlated eﬀects that vary smoothly over space
may account for much extra-variation, and proxy unobserved risk factors that
are also spatially correlated (Richardson and Monfort, 2000). These might be
shared environmental or social capital factors in neighboring areas, or shared
factors operating at a more aggregated regional scale, such as regional varia-
tion in cardiovascular mortality associated with diﬀerences in water hardness.
While spatially correlated random eﬀects alone may be postulated, this is
an informative prior assumption. For health data, there may be outlier areas
(e.g., areas of deprived social renting surrounded by aﬄuent areas), or local-
ized policy interventions, or service variations, which aﬀect the health event
but cannot be regarded as spatially continuous. A more general and less in-
formative approach allows adaptive downweighting of a spatial prior to allow
the data to support an exchangeable unstructured prior for some areas.

180
Applied Bayesian Hierarchical Methods
4.8.1
Linking conditional and joint speciﬁcations
As discussed by Besag and Kooperberg (1995), one may use properties of
the multivariate normal to obtain the conditional autoregressive prior from a
joint spatial prior and vice versa. Thus consider the joint multivariate normal
density for the eﬀects, s = (s1, . . . , sn), with mean zero and covariance Σs,
p(s) =
1
(2π)n/2 |Σs|−0.5 exp

−0.5s′Σ−1
s s

.
Setting Q = [qij] = Σ−1
s
to be the precision matrix and s[i] = (s1, . . . ,
si−1, si+1, . . . , sn), the conditional distributions for each si take a univariate
normal form, corresponding to the pairwise interaction function, Φ(u) = u2/2
(Rue and Held, 2005, 22), namely,
si|s[i] ∽N
 
j̸=i

−qij
qii

sj, 1
qii

,
with corr(si, sj|s[i,j]) = (−qij/√qiiqjj). Following Besag and Kooperberg
(1995, 734), deﬁne hii = 0, and set,
hij = −qij/qii
(i ̸= j).
Also set qii = ai/δ with variance parameter δ, so that,
hij= −qijδ/ai.
(4.3)
The above conditional density is then in the conditional autoregressive form
speciﬁed by Besag (1974),
si|s[i] ∽N
 
j̸=i
hijsj, δ/ai

.
(4.4)
To obtain the joint density from the conditional one, symmetry of Q means
−Qij = −Qji, so that from Equation 4.3 the constraint,
hijai = hjiaj,
applies. Note that expressing δ/ai = τ2
i or ai = δ/τ2
i , this constraint can also
be stated (Cressie and Kapat, 2008) as,
hijτ2
j = hjiτ2
i .
Letting R = A(I −H), where A = diag(a1, . . . , an), one has that R is
symmetric with diagonal elements ai and oﬀ-diagonal elements −aihij. So the
joint density (Banerjee et al., 2004, 8; Besag and Green, 1993) implied by the
conditional priors is
(s1, . . . , sn) ∽Nn(0, δR−1),

Structured Priors Recognizing Similarity over Time and Space
181
where Q = δ−1R. If R is positive deﬁnite as well as symmetric, the joint
density of the spatial eﬀects is proper. Positive deﬁniteness of R holds under
diagonal dominance (Besag and Kooperberg, 1995, 734; Rue and Held, 2005,
20), namely, that in at least one row (or column) of R, the diagonal element,
rii, exceeds the absolute sum of the oﬀ-diagonal elements,
 
j̸=i rij
.
4.8.2
Alternative conditional priors
Various schemes for deﬁning the hij and ai in Equation 4.4 are possible,
including options where R is not positive deﬁnite. Setting,
hij = ρ
wij

k̸=i wik
, ai =

k̸=i
wik,
where 0 ≤ρ ≤1, and taking wij = wji, with wii = 0, ensures the symmetry
constraint is met, with hijai = ρwij = hjiaj. The most commonly applied
approach is to set wij = 1 for adjacent areas and wij = 0 otherwise, and let
ai = di = 
k̸=i wik, where di is then the number of areas adjacent to area i.
For example, when a region is partitioned into grid cells, then each grid cell
has eight (ﬁrst order) neighbors (Gelfand et al., 2005a). However, distance or
common boundary length-based forms for wij can be used.
In this case, R = A(I −H) has diagonal elements ai and oﬀ-diagonal
elements −ρwij. This provides the intrinsic conditional autoregression or
ICAR(ρ) prior, with,
si|s[i] ∽N

ρ ¯Ai, δ
di

,
where ¯Ai is the average of the sj in locality Li of area i, i.e.,
¯Ai =

j∈Li sj
di
.
Note that R = A(I −H) = D −ρW is positive deﬁnite, and the joint prior
on (s1, . . . , sn) is proper, only when |ρ| < 1. Lower values of ρ imply lesser
degrees of spatial dependence between si, though the limiting case when ρ = 0
has the disadvantage that the variance is not constant but depends on the
number of neighbors, di.
Alternatively, in a CAR(ρ) spatial prior, as distinct from the ICAR(ρ)
prior, one may set,
hij = ρwij, ai = 1,
so that
si|s[i] ∽N

ρ

j̸=i
wijsj, δ

,

182
Applied Bayesian Hierarchical Methods
with a homogenous conditional variance (Cressie and Kapat, 2008, 729). In
this case, R = I −ρW is positive deﬁnite, and so invertible (and the joint den-
sity is proper), when the correlation parameter is between 1/ηmin and 1/ηmax,
where η1, . . . , ηn are the eigenvalues of W (Bell and Broemeling, 2000).
A compromise scheme for the variance deﬂators, ai—see Leroux et al.
(1999) and MacNab et al. (2006)—sets,
ai = (1 −λ) + λ

j̸=i
wij,
with 0 ≤λ ≤1 subject to a prior such as λ ∼U(0, 1). The symmetry condi-
tion, hijai = hjiaj, is maintained by setting,
hij =
λwij
1 −λ + λ 
j̸=i wij
,
since hijai = λwij = λwji = hjiaj. So the joint density for (s1, . . . , sn) has
covariance δR−1 where,
R = λF + (1 −λ)I,
fii=

j̸=i
wij,
fij = −wij
i ̸= j.
The case λ = 0 corresponds to a lack of spatial interdependence, with
R then reducing to an identity matrix, and borrowing strength conﬁned to
“global smoothing.” By contrast, λ = 1 leads to the ICAR(1) model (see
Section 4.8.3). So,
si|s[i] ∽N


λ
1 −λ + λ 
j̸=i wij

j̸=i
wijsj,
δ
1 −λ + λ 
j̸=i wij

,
and when wij are deﬁned by contiguity, one obtains,
si|s[i] ∽N


λ
1 −λ + λdi

j∈Li
sj,
δ
1 −λ + λdi

.
The scheme of Leroux et al. (1999) can be generalized to allow greater
spatial adaptivity with varying λ (Congdon, 2008a). The symmetry condition,
hijai = hjiaj, is maintained by setting, ai = (1−λi) + λi

j̸=i wij, and taking,
hij =
λiλjwij
1 −λi + λi

j̸=i wij
,
since this ensures the constraint,
hijai = hjiaj = λiλjwij.

Structured Priors Recognizing Similarity over Time and Space
183
A possible borrowing strength prior for these parameters is
logit(λi) ∼N(λµ, 1/τλ),
where the average, λµ, and precision, τλ, are extra unknowns. Setting Λ =
diag(λ1, . . . , λn), the covariance in the joint prior is then,
δ[ΛF ∗+ (I −Λ)]−1,
where,
f ∗
ii =

j̸=i
wij,
f ∗
ij = −wijλj
i ̸= j.
Pettitt et al. (2002) propose a scheme with,
hij =
φwij
1 + |φ| 
j̸=i wij
,
and
ai = 1 + |φ|

j̸=i
wij,
where φ measures the strength of spatial dependency, and the case φ = 0
corresponds to an absence of spatial interdependence, such that R = I (see
also Gschl¨oßl and Czado, 2008). Gibbs updating for φ can be applied. So,
si|s[i] ∽N


φ
1 + |φ| 
j̸=i wij

j̸=i
wijsj,
δ
1 + |φ| 
j̸=i wij

.
Under both the McNab et al. (2005) and Pettitt et al. (2002) schemes, the
joint distribution of s is proper, ensuring a proper posterior when either is
taken as the prior distribution. Retaining hij = φwij/(1 + |φ| 
j̸=i wij), but
setting ai = (1 + |φ| 
j̸=i wij)/(1 + |φ|), means that φ →∞corresponds to
the ICAR(1) prior, with the conditional variance (1 + |φ|δ)/(1 + |φ| 
j̸=i wij)
tending to
δ

j̸=i wij .
4.8.3
ICAR(1) and convolution priors
The ICAR(ρ) prior, when ρ = 1, is sometimes known as the ICAR(1) model,
when one has,
hij =
wij

j̸=i wij
, ai =

j̸=i
wij,

184
Applied Bayesian Hierarchical Methods
and for counts yi ∼Po(λiPi), if one assumes,
log(λi) = α + si,
then borrowing of strength is purely spatial, with,
si|s[i] ∽N

¯Ai,
δ

j̸=i wij

,
where ¯Ai = (
j̸=i wijsj/ 
j̸=i wij). The precision matrix of the joint prior is
δ−1R where,
rii=

j̸=i
wij,
rij = −wij
i ̸= j.
When wij are binary indicators of adjacency (wij = 1 for areas i and j
contiguous, wij = 0 otherwise), then rii = di and the oﬀ-diagonal elements,
rij, are −1 if i and j are neighbors, but zero otherwise. This case demonstrates
most directly that conditional independence properties relating to the diﬀerent
spatial eﬀects are stipulated by the matrix R and vice versa (Rue and Held,
2005, 4). Despite the relative simplicity of this form and the wide use of the
ICAR(1) conditional prior, R is not invertible under this model, and the joint
prior is improper (Haran et al., 2003).
To see this in another way, consider the case where wij are binary, such
that the joint prior can be speciﬁed in terms of pairwise comparisons be-
tween si (Knorr-Held and Becker, 2000). Let i ∽j denote that areas i and j
are neighbors, then for a normal ICAR(1) model, the joint prior in terms of
diﬀerences, si −sj, is (Hodges et al., 2003),
p(s1, . . . , sn) ∝δ−0.5(n−1) exp

−1
2δ

i∽j
(si −sj)2

.
Thus, the prior only speciﬁes diﬀerences between spatial eﬀects and not
their overall level. However, all linear contrasts c′s with c′1 = 0 have proper
distributions (Besag and Kooperberg, 1995, 740).
To tie down the eﬀects and remove their locational invariance, one method
involves centering the sampled values at every iteration to have mean zero.
This is one form of linear constraint, and so the joint distribution becomes
integrable and propriety is obtained (Rodrigues and Assuncao, 2008). An-
other possibility is a corner constraint, i.e., setting a particular eﬀect to a
known value, such as s1 = 0 (Besag et al., 1995). Finally, one may omit
the intercept so that si model the level of the data (Reich and Hodges,
2008). In this case, yi ∽Po(Pi exp(si)) with si not constrained, rather than
yi ∽Po(Pi exp(α + si)).
As mentioned above, a spatial eﬀects only assumption is relatively infor-
mative, and the ICAR(1) spatial prior is often combined with an exchangeable
prior to form a convolution prior (Richardson et al., 2004). It may be argued

Structured Priors Recognizing Similarity over Time and Space
185
that an exchangeable i.i.d eﬀect should only be introduced in combination
with an ICAR(1) spatial prior, since conditional priors including a correlation
parameter, such as the ICAR(ρ), can adjust to varying mixtures of spatial and
unstructured variation by varying the ρ parameter (Wakeﬁeld, 2007). Thus for
a Poisson response, yi ∽Po(λiPi), one obtains the convolution prior of Besag
et al. (1991), namely,
log(λi) = α + si + ui,
with si|s[i] ∽N( ¯Ai, δs/di), and ui ∽N(0, δu) usually homoscedastic. However,
heteroscedasticity or heavier tails than under the normal might be represented
by taking ui ∽N(0, ψi) where,
ψi = δu/κi,
where κi are positive variables with mean 1 (Lesage, 1999a). Reich and Hodges
(2008) allow spatial adaptivity by making the variance δs speciﬁc to area-
pairs. While only the sum, zi = si + ui, is identiﬁable in this model, Norton
and Niu (2009) show that the precisions, δs and δu, are identiﬁable from the
distribution of zi.
4.9
Priors on Variances in Conditional Spatial Models
As in the exchangeable hierarchical models considered in Chapter 3, the prior
on δ, and on the pair {δs, δu} in a convolution model, is important in governing
the degree of smoothing toward the neighborhood or global mean. Although
some applications of conditional autoregressive priors use vague priors for δ
such as p(δ) ∝1/δ or just proper priors, with 1/δ ∽Ga(ε, ε) with ε small,
these may lead to eﬀective impropriety in the posterior such that MCMC
convergence is impeded (Besag and Kooperberg, 1995, 741). The prior 1/δ ∽
Ga(ε, ε) with ε small may also put undue weight on low variances.
Suppose the prior relates to a variance for unstructured eﬀects in a log-
linear model for relative risks, with yi ∽Po(Eiλi). Wakeﬁeld (2007) mentions
that a Ga(0.001, 0.001) prior on δu in the model, log(λi) = α+ui, is equivalent
to assuming that the relative risks, eα+ui, follow a log-t distribution with 0.002
degrees of freedom. To avoid such diﬀuse options, one may use a weakly data-
based prior (technically amounting to an Empirical Bayes method) for this
model (Mollie, 1996, 372). Thus, let H = 1/V (qi), where qi = log(yi/Ei)
or qi = log((yi + 0.5)/(Ei + 0.5)). Then in a convolution prior, one would
take 1/δs ∽Ga(0.5bH/ ¯d, b), and 1/δu ∽Ga(0.5bH, b), where ¯d is the average
number of neighbors, and b < 1 downweights information from the data.
Another option in the convolution prior is to link the two variances or
precisions. Adapting the uniform shrinkage prior of Natarajan and Kass (2000)
is not straighforward, since δs is a conditional variance, so that δs and δu
cannot be regarded as components of the total residual relative risk. Wakeﬁeld

186
Applied Bayesian Hierarchical Methods
(2007, 167) suggests an approximate strategy based on the marginal variance
of wi = si −sn. One may, however, monitor the ratio of spatial to total
residual variation by obtaining an empirical estimate, Vs = Var(s), of the
marginal spatial variance (e.g., Eksler, 2008). It is then possible to set up a
uniform prior on ratio, ru = (δu/Vs + δu) (see Example 4.9), resulting in a
form of joint prior for δs and δu. One might also use a scaling factor, q, such
that δu = qVs with q centered at 1.
Example 4.9. Blood Lead in Children, Virginia Counties
The data
here, considered by Schabenberger and Gotway (2004), relate to elevated blood
level readings, yi, among ni children (under 72 months) tested in the 133
counties of Virginia (including Independent Cities) in 2000. Recent data are
described at http://www.vahealth.org/leadsafe/dataclpp.htm.
Numbers sampled, ni, vary considerably (from 1 to 3808). Spatial proxim-
ity is binary, with wij= 1 for intercounty distances under 50 km and wij= 0
otherwise. Assuming binomial sampling with yi ∼Bin(ni, πi), one option
considered is the convolution model of Besag et al. (1991), namely,
logit(πi) = α + si + ui,
with conditional variance δs for ICAR(1) spatial eﬀect si, and variance δu for
the unstructured eﬀects. This is compared to the Leroux et al. (1999) model
with logit(πi) = α + si and,
si|s[i] ∽N


λ
1 −λ + λdi

j∽i
sj,
δ
1 −λ + λdi

.
For the convolution model, the priors on the precisions are
δ−1
s
∼Ga(1, 0.001),
ru = δu/(δu + Vs) ∼U(0, 1),
where Vs = Var(si) is the marginal variance of the spatial eﬀects calculated
at each iteration. The uniform prior on the share, ru, of unstructured in total
variation ties the unknown variances together and governs the extent of global
as against local shrinkage (cf Cohen et al., 1998; Daniels, 1999).
The posterior mean8 for ru based on iterations 1000–50,000 of a two chain
run is 0.42. Fifteen (from 133) of the si parameters are judged signiﬁcant
in terms of posterior probabilities over 0.95 or under 0.05 that si> 0. By
contrast, 40 composite terms, ui+si, are signiﬁcant. Such a pattern suggests
that there may be no great advantage (in terms of substantive interpretation
not just statistical terms) in having two distinct sets of eﬀects. The average
deviance, ¯D, is 501.4, and de is 77.6, giving a DIC of 579. The log pseudo
marginal likelihood is −315.4, with the lowest log(CPO) being for Winchester
(county 3), namely, −6.5.
Since the second model is less parameterized with a single set of eﬀects, one
might expect the average deviance to deteriorate. In fact, ¯D is unchanged at

Structured Priors Recognizing Similarity over Time and Space
187
501.4, though a lower de of 73.6 leads to a reduced DIC of 575. The log psML
is also slightly improved, at −313, giving a pseudo Bayes factor of 10; λ is
estimated at 0.63, albeit with a wide 95% interval from 0.25 to 0.97; 34 eﬀects
si are now signiﬁcant. One feature of note is the only slight increase in the
eﬀective parameter count in the convolution model as compared to this one;
this may in part reﬂect the lack of signiﬁcance of the majority of individual
spatial eﬀects in that model.
4.10
Spatial Discontinuity and Robust Smoothing
Spatial pooling assuming a smoothly varying outcome over contiguous areas
may not be appropriate when there are clear discontinuities in the spatial pat-
tern of events. For instance, a low mortality area surrounded by high mortality
areas will have a distorted smoothed rate when heterogeneity is assumed to be
entirely spatially structured. More generally, one may seek robustness against
mis-speciﬁcation of the distribution of latent event rates or risks; for example,
virtually all applications of spatial conditional autoregression models assume
normality by default. Finally, one may seek some degree of spatial adaptive-
ness. For example, under conditional autoregressive models, the conditional
variance, δ, is constant across the region, whereas one might expect spatial
correlation to be stronger in some subregions. In the convolution model, the
variances δs and δu are global parameters, so that the relative amount of spa-
tially structured and unstructured heterogeneity is constant across the study
region (Congdon, 2007b; Knorr-Held and Becker, 2000).
Robustness against spatial outliers or non-normality may be important
when event totals are small, since then the prior structure of the latent risks
has a greater eﬀect; this is the case with the much analyzed Scottish lip cancer
data, where certain areas have elevated standard mortality ratios (SMRs) but
small counts, y, and expected cases, E. A high relative risk apparent from a
crude or moment estimate not based on a large y or E may be shrunk con-
siderably under a spatial random eﬀects approach, particularly if surrounded
by lower morbidity areas, so that important excess risks may not be ﬂagged
up (Conlon and Louis, 1999).
Where extreme crude rates are observed, then a robust model is sug-
gested even though the crude rates are unreliable estimators. One might adopt
heavier-tailed alternatives such as the double exponential (Laplace) or L1-
norm version of the ICAR(1) prior, which Besag (1989, 399) mentions as
preferable when si have discontinuities. For a connected graph (i.e., with no
isolated areas in the region) this prior is
p(s1, . . . , sn) ∝
1
δn−1 exp

−0.51
δ

j̸=i
|si −sj|

,

188
Applied Bayesian Hierarchical Methods
and has its posterior mode at the median rather than mean of the neigh-
boring sj. One might also apply Student t versions of the ICAR(ρ), which if
applied using scale mixtures give a natural measure of outlier status. Thus,
si|s[i] ∽N

ρ ¯Ai,
δ
γidi

,
where γi ∽Ga(ν/2, ν/2), and very low values of γi correspond to spatial
outliers.
Forms of discrete mixture have been proposed as particularly appropri-
ate to modeling discontinuities in disease risk. Green and Richardson (2000)
distinguish between clustering models and allocation models, while Knorr-
Held and Rasser (2000) propose a scheme whereby at each MCMC iteration,
areas are allocated to clusters of mutually contiguous areas, with identical
risks within each cluster. Lawson and Clark (2002) propose a mixture of the
ICAR(1) and Laplace priors for the case yi ∼Po(Eiλi), with continuous
(beta) weights, ri, rather than binary mixture weights, namely,
log(λi) = α + ris1i + (1 −ri)s2i,
where ri ∽Be(c, c), with c known, s1i is an ICAR error, but s2i follows a
spatial Laplace prior. Other densities might be used for s2i (e.g., ones allow-
ing skewness). Following Congdon (2007b), analogous mixture forms can be
applied to the errors in the convolution model itself, giving more emphasis to
the unstructured term, ui, in outlier areas,
log(λi) = α + risi + (1 −ri)ui.
This type of representation may also be useful for modeling edge eﬀects,
with u eﬀects taking a greater role on the peripheral areas where neighbors
are fewer. Another possibility is a discrete mixture in a “spatial switching”
model (Congdon, 2007b), allowing an unstructured term only for areas where
the pure spatial eﬀects model is inappropriate. Thus for a count response,
yi ∽Po(EiλSi,i),
Si ∽Categoric(π1, π2),
(π1, π2) ∽Dirichlet(ξ1, ξ2),
log(λ1i) = α + si,
log(λ2i) = α + si + ui,
where ξj are extra unknowns, and si follow an ICAR(1) prior. The posterior
estimates for ξj provide overall weights of evidence in favor of a pure spatial
model as compared to a convolution model, while high posterior probabilities,
Pr(Si = 2|y), for particular areas indicate that pure spatial smoothing is
inappropriate for them.

Structured Priors Recognizing Similarity over Time and Space
189
Fernandez and Green (2002) use a discrete mixture model generated via
mixing over several spatial priors. Thus, for count data, assume K possible
components with area-speciﬁc probabilities, πik, on each component,
yi ∽
K

k=1
πikPo(Eiλik),
where log(λik) = αk for a model without predictors. Then K sets of underlying
spatial eﬀects {sik} are generated from separate conditional spatial priors, and
used to estimate area-speciﬁc mixture weights,
πik = exp(χsik)
 K

k=1
exp(χsik),
where χ > 0. As χ tends to 0, the πik tend to 1/K without spatial patterning,
whereas large χ reduce overshrinkage.
Another discrete mixture model for robust spatial dependence modeling
uses the Potts prior (Green and Richardson, 2002). Thus, let Si ∈1, . . . , K be
unknown allocation indicators with yi ∽Po(EiµSi) where {µ1, . . . , µK} are
distinct cluster means. Also let dik = 1 if Si = k. Then the joint prior for the
allocation indicators incorporates spatial dependence with,
Pr(Si = k) = exp

ω

j∼i
I(dik = djk)
  K

h=1
exp

ω

j∼i
I(dih = djh)

,
where ω > 0 multiplies the number of same label neighbor pairs, so that
lower values of ω indicate lesser spatial dependence. So pooling toward the
local neighborhood average will tend not to occur if an area’s latent risk is
discrepant with those of its neighbors. Richardson et al. (2004) compare this
model with the convolution model under various simulated scenarios for diﬀer-
entiated spatial risks. Additional eﬀects can be included by multiplying µSi;
for example, a spatially unstructured multiplicative eﬀect could be modeled
as νi ∽Ga(bν, bν), or a log-normal prior assumed with νi = exp(ui), and
ui ∽N(0, δu). Then yi ∽Po(EiµSiνi).
Assumptions such as normality in the spatial eﬀects can be avoided by
adapting the Dirichlet process stick-breaking prior of Sethuraman (1994) to
spatial settings. The stick-breaking prior speciﬁes an unknown distribution G
by a mixture,
G =
M

m=1
pmδ(ρm),
where M may in principle be inﬁnite, but in practical computing is taken
as ﬁnite, the mixing probabilities satisfy M
m=1 pm = 1, and δ(ρm) has a
point mass at ρm that may be scalar or vector values for areas (e.g., relative

190
Applied Bayesian Hierarchical Methods
risks) or at grid locations. For example, the ρm may be draws from a baseline
borrowing-strength prior G0 such as a stationary Gaussian process in the case
of continuous point-referenced spatial data, y(gi), at sites gi. One may incor-
porate spatial information into either ρm, as in Gelfand et al. (2005b), or into
the mixture probabilities, pm, as in Griﬃn and Steele (2006). Such formula-
tions are typically for point-referenced data, and allow for nonstationarity and
non-Gaussian features in the response when the stationary Gaussian process
(see Section 4.11) is not appropriate (Duan et al., 2007).
Example 4.10. Robust Priors for Attempted Suicides in NE London
This analysis compares the Potts prior and the convolution prior for model-
ing the distribution of attempted suicides in 133 wards (small administrative
areas) in NE London over the two ﬁnancial years 2002–2003 and 2003–2004.
Attempted suicide (also called parasuicide) is deliberate self-injury with a
nonfatal outcome where there is evidence that the patient intended to commit
suicide (external ICD10 codes X60-X84,Y10-Y34). Expected parasuicides, Ei,
are based on London as a whole, with the crude hospitalization risk ratios,
qi = yi/Ei, averaging 154 (i.e., parasuicide is higher in this part of London
than elsewhere).
A plot of qi (Figure 4.8) shows discontinuities in the spatial patterning
that may be linked to socioeconomic disparities between neighboring areas,
when relatively deprived areas (which tend to have higher parasuicide lev-
els) are surrounded by aﬄuent areas, and vice versa. Hence, adopting a pure
Crude RR
0.28 – 0.87
0.88 – 1.45
1.46 – 2.04
2.05 – 4.46
FIGURE 4.8
Unsmoothed curve relative risks.

Structured Priors Recognizing Similarity over Time and Space
191
spatial prior may be unduly informative and result in biased smoothing, as,
for example, taking yi ∽Po(Eiλi) with log(λi) = α + si, with si following an
ICAR(1) prior.
Instead, a Potts prior is applied with an exponential E(1) prior on ω and
with an ordering constraint on the latent cluster means, so µ1 ≤µ2 ≤· · · ≤
µK, where K is set at 10. An order constraint on the cluster means is applied
indirectly, so that for k > 1, µk = µk−1 + eηk, where ηk are taken as random
eﬀects. The second half of a two chain run9 of 10,000 iterations gives a mean
scaled deviance,
2

i
{yi log(yi/(Eiλi)) −(yi −Eiλi)} ,
of 158, and DIC of 185 (de = 26), where the latter is obtained using poste-
rior means of the Poisson parameters, νi = EiµSi. A predictive check using
replicate data, ynew,i, sampled from the model is satisfactory, with only one
of the observations, yi, not contained within 95% intervals of ynew,i. The pos-
terior mean (95% CI) of ω is 1.08 (0.85, 1.35) with K = 10 latent cluster
means ranging from µ1 = 0.52 to µK = 4.02, the latter being four times
the expected parasuicide count based on London-wide parasuicide rates. The
smoothed pattern (posterior means of λi = µSi in Figure 4.9) shows fewer
isolated high-risk areas than are apparent in the plot of unsmoothed risks.
The adaptive version of the convolution prior mentioned above, namely,
log(λi) = riui + (1 −ri)si,
Smoothed RR, potts model
0.55 – 1.12
1.13 – 1.46
1.47 – 2.19
2.20 – 4.38
FIGURE 4.9
Smoothed relative risks, Potts Model.

192
Applied Bayesian Hierarchical Methods
Smoothed RR, adaptive convolution
0.53 – 1.01
1.02 – 1.41
1.42 – 1.85
1.86 – 3.84
FIGURE 4.10
Smoothed relative risk, Adaptive Convolution Model.
is also run using the weakly data-based prior described above on the two pre-
cisions, and taking ri ∼Be(1, 1). For these data, one has H = Var(log[qi]) =
25.4 and ¯d = 5.3. Taking b = 0.01, one has 1/δs ∽Ga(0.024, 0.01) and
1/δu ∽Ga(0.127, 0.01). The intercept is excluded from the model for the
log relative risk, so si do not need to be centered at every MCMC iteration.
Considering again the second half of a two chain run of 10,000 iterations, this
option gives a lower mean deviance of 143.6 (comparing more closely to the
n = 133 data points), with complexity estimated at 10.6, and DIC of 154.2.
Compared to the Potts prior, the smoothed pattern is less dissimilar from that
evident in the crude relative risks (compare Figures 4.10 and 4.8).
4.11
Models for Point Processes
A continuous spatial framework is appropriate when point observations are
made. Nevertheless, a continuous framework is often applied to discrete area
or lattice data (Berke, 2004; Kelsall and Wakeﬁeld, 2002; Webster et al.,
1994; Yanli and Wall, 2004). Consider metric observations (y1, . . . , yn) =
(y1(g1), . . . , yn(gn)) at points {g1, g2, . . . , gn} in two-dimensional space G2.
To represent the spatially driven component in the variation of y, deﬁne

Structured Priors Recognizing Similarity over Time and Space
193
a Gaussian spatial process (s1, . . . , sn) = (s(g1), . . . , s(gn)) with covariance
matrix Σ(dij) = σ2
sC(dij), where the oﬀ-diagonal correlations depend on dis-
tances, dij = ∥gi −gj∥, between points gi and gj, and C(0) = 1.
Such a process is ergodic if the oﬀ-diagonal elements in Σ(d) tend to zero
as d →∞(so that covariance between values at two points vanishes for
large enough distances), and isotropic if Σ(d) depends only on the distance
between gi and gj, and not on other features such as the direction from gi
to gj or the coordinates of the gi. The process is intrinsically stationary if
E[y(g + d) −y(g)] = 0, namely, has a constant mean, and if the variance
depends only on the lag, not on the point locations, namely,
E[y(g + d) −y(g)]2 = V [y(g + d) −y(g)] = 2γ(d),
where γ(d) is the semiovariogram (Waller and Gotway, 2004, 274). The co-
variance Σ(d) and the semiovariogram are related via γ(d) = Σ(0) −Σ(d)
since,
2γ(d) = V [y(g + d) −y(g)]
= V [y(g + d)] + V [y(g)] −2Cov[y(g + d), y(g)]
= Σ(0) + Σ(0) −2Σ(d) = 2[Σ(0) −Σ(d)],
so that γ(0) = 0.
A Gaussian spatial error, possibly together with an unstructured random
eﬀect, ui ∽N(0, σ2
u), and regressor eﬀects may be used to deﬁne means,
µi = E(yi), in a normal linear model. However, this scheme generalizes to
discrete responses using an appropriate link function (Diggle et al., 1998;
Zhang, 2002). The variance parameter, σ2
u, is sometimes called a nugget ef-
fect or nugget variance, deﬁning measurement error or microscale spatial ef-
fects (spatial variation at lower scales than the smallest observed distance
between sampled points). In Bayesian modeling, it is possible to take account
of interplay between the nugget and the parameters of the spatial correlation
function (Gramacy and Lee, 2008). Regressor eﬀects might include a trend sur-
face, T(g1i, g2i), deﬁned by the coordinates of gi (Diggle and Ribeiro, 2002,
133; O’Sullivan and Unwin, 2002), such as a quadratic polynomial with terms

g1i, g2i, g2
1i, g2
2i, g1ig2i

. So for y continuous, one might have,
yi = α + β.T(g1i, g2i) + si + ui,
(s1, . . . , sn) ∽N n(0, σ2
sC),
ui ∽Nn

0, σ2
u

.
There are a number of isotropic schemes with C(dij), and hence γ(dij),
parameterized to reﬂect anticipated distance decay in the correlation between
points (e.g., Grunwald, 2005). For example, the exponential distance model
has
C(dij) = exp

−dij
φ

,

194
Applied Bayesian Hierarchical Methods
with range parameter φ > 0, and smaller values of φ leading to more
pronounced distance decay. The covariance function for (e1, . . . , en), where
ei = si + ui, is then,
Σ(dij) = σ2
uI(i = j) + σ2
s exp

−dij
φ

,
while the semivariogram is
γ(dij) = σ2
u + σ2
s

1 −exp

−dij
φ

.
As dij tends to inﬁnity, the semivariogram tends to an upper limit of
σ2
u + σ2
s, known as the sill. The powered exponential variant has
C(dij) = exp

−

dij
φ
κ
,
for φ > 0 and 0 < κ ≤2.
The spherical model (Zhang, 2002) has nonzero covariance only within a
certain range φ, namely,
C(dij) = 1 −3dij
2φ + d3
ij
2φ3 ,
for d < φ, whereas C(dij) = 0 for dij ≥φ. Hence, the spherical function has
covariance,
Σ(dij) = σ2
uI(i = j) + σ2
s

1 −3dij
2φ + d3
ij
2φ3

I(dij < φ),
and semivariogram,
γ(dij) = σ2
u + σ2

3dij
2φ −d3
ij
2φ3

for dij < φ,
γ(dij) = σ2
u + σ2
s for d ≥φ.
Finally, Matern functions (Diggle et al., 2003) set,
C(dij) = 21−κ
Γ(κ)

dij
φ
κ
Kκ

dij
φ

,
where Kκ(u) = 
i=0 (−1)i/i!Γ(κ + i + 1)(u/2)2i+κ is a Bessel function of
order κ.
Suppose continuous observations y = (y1, . . . , yn) = (y1(g1), . . . , yn(gn))
are made at locations g =(g1, . . . , gn), and that predictions y0 = (y01, . . . , y0k)
are required at k new locations g0 = (g01, . . . , g0k). These are based on the
posterior predictive density,
p(y0|y) =

p(y0, θ|y)dθ =

p(y0|y, θ)p(θ|y)dθ,

Structured Priors Recognizing Similarity over Time and Space
195
where θ is the vector of parameters involved in the model for y, namely, those
deﬁning its mean, and the covariance parameters for spatial and unstructured
errors (Banerjee et al., 2004, 132). For example, Diggle et al. (2003, 51) con-
sider a model, yi = µ+si+ui, with ui ∽Nn

0, σ2
u

, and spatial error process,
(s1, . . . , sn) ∽Nn(0, σ2
sC),
where prediction is required at a single new location, g0. With d0 denoting
a n × 1 vector of distances between g0 and g = (g1, . . . , gn), and with Q =
σ2
uI + σ2
sC, one has,
p(y0|θ, y) = N

µ + σ2
sd′
0Q−1(y −µ1n), σ2
s −σ2
sd′
0Q−1σ2
sd0

.
For k > 1, univariate predictions may be obtained at each new site, g01,
g02, . . . , g0k, though multivariate predictions may be more precise. For non-
normal z, one may apply the procedure of De Oliveira et al. (1997), where
y = G(z) is obtained by a normalizing transformation of z.
4.11.1
Discrete convolution models
Assuming a stationary Gaussian process described through its mean and
covariance structure may result in slow estimation when there are a large
number of points and is relatively inﬂexible when stationarity and isotropy
assumptions are violated. An alternative representation, based on the Gaus-
sian process but one that adapts to spatial nonstationarity and anisotropy is
the process convolution approach (Higdon, 1998, 2007; Lee et al., 2005). This
involves convolving a continuous white noise process, w(g), with a symmetric
smoothing kernel, K(g), with the spatial eﬀect obtained as,
s(g) =

G
K(g −u)w(u)du,
where G is the region of interest. The spatial process might be combined
with ﬁxed eﬀects deﬁning level or regression impacts and with appropriate
regression links for non-normal observations. For example, if y(g) were binary,
such as species presence or absence at site g (Gelfand et al., 2005a), then
y(g) ∼Bern(π(g)) and,
logit[π(g)] = β0 + s(g),
where β0 deﬁnes the average intensity.
In practice, the continuous underlying process can be approximated by
a discretized process (e.g., one deﬁned on a regular lattice over G) provided
the discretization is not too coarse relative to the smoothing kernel (Calder,
2003, 2007). So if there are i = 1, . . . , n observations at points g1, . . . , gn and
grid locations {tj, j = 1, . . . , m} with tj = (t1j, t2j), over the region, one may
deﬁne the discretized kernel smoother as,

196
Applied Bayesian Hierarchical Methods
s(gi) =
m

j=1
K(gi −tj)wj,
where for large m, the wj can be taken as a collection of random eﬀects
(Higdon, 2007, 245). Lee et al. (2005) consider options for representing the
kernel, possibly by a form with known variance (e.g., a standard normal), and
consequent ways for modeling wj. Note that if both the K function and w
series have unknown variances, then there is nonidentiﬁability. Options for
wj include exchangeable eﬀects or low order random walks, with unknown
precision, τw. Assuming K is a normal kernel, one can, by varying τw, mimic
the eﬀect of the range parameter in a conventional Gaussian process model
with a Gaussian variogram.
For example, Lee et al. (2005) consider n = 12 observations, yi, in G1 at
equally spaced locations, gi, between 0 and 10. These are generated according
to a Gaussian process, s(g), with mean 0 and covariance matrix,
C(dij) = exp(−d2
ij/25),
where dij relates to distances between points gi and gj on the line. A white
noise error, ui, with standard deviation 0.2 is also used to deﬁne yi, so that
yi = s(gi) + ui. They then ﬁt10 a discrete convolution model to yi so generated,
using a grid with m = 20 points, tj equally spaced between −2 and 12. They
assume wj follow a ﬁrst order random walk, and assume the kernel is a normal
density with standard deviation 0.6.
Best et al. (2000) consider a convolution model for health counts, yi ∼
Po(Piλi), observed for areas rather than points, where Pi are populations
and λi are latent rates. In this case, a rectangular grid is deﬁned over m
points in the region, and an additive (rather than log link) regression is used
for modeling the latent rates. So with a single predictor, xi, taking positive
values only, one has,
λi = β0 + β1xi + β2
m

j=1
K(gi −tj)wj,
where wj (and β parameters) are gamma distributed and the kernel func-
tion has a known variance. One can decompose the total risk parameter into
three sources: one due to the background rate, β0, one reﬂecting the known
predictor, and one the latent spatially conﬁgured risk over the region.
Semiparametric approaches to spatial modeling based on the stick-
breaking prior can also be related to this theme (Reich and Fuentes, 2007).
Thus, there are kernel functions for each of m potential clusters, with the ker-
nel centers, tj = (t1j, t2j), being unknowns, and the cluster allocation prob-
abilities for sites or areas i at location gi = (g1i, g2i) incorporating spatial
information. While the cluster eﬀects, wj ∼N(0, 1/τw), are unstructured, the
cluster for area or point i is chosen using indicators,
Si ∼Categorical(pi1, . . . , pim),

Structured Priors Recognizing Similarity over Time and Space
197
with pij determined both via beta distributed Vj ∽Be(c, d), and by cluster-
speciﬁc kernels, Kij, constrained to lie in [0, 1]. The realized spatial eﬀect for
area or point i is then wSi. Deﬁning Rij = KijVj, one has,
pi1 = Ri1,
pij = Rij(1 −Ri1) · · · (1 −Ri,j−1)
j = 2, . . . , m −1,
pim = (1 −Ri1) · · · (1 −Ri,m−1),
where (for example),
Kij = exp[−|gi −tj|/2γj],
deﬁnes a normal kernel with bandwidth γj. Bandwidths can be taken equal
across kernel functions or vary across kernel functions according to a positive
prior (e.g., inverse gamma).
Example 4.11. Trichloroethylene Groundwater Contamination
This
example considers spatial covariance modeling for continuous measures of
groundwater contamination. The particular contamination involves concentra-
tions (ppb) of trichloroethylene (TCE), a chemical used as a metal degreaser
and in cleaning ﬂuids that can enter ground and surface water from industrial
discharges or from landﬁll disposal of industrial waste. Data from Kitanidis
(1997, Table 2.2) relate to TCE readings in groundwater at 56 locations
with predictions required for k = 3 new points, namely, g01 = (50, −50),
g02 = (100, −50), and g03 = (170, −50).
Log transforms of the originally positive skewed readings are taken as the
responses. The eastings and northings are scaled to give kilometre distances, so
that the original four digit grid references are replaced by two digit grid refer-
ences. A powered exponential distance model11 is applied for spatial eﬀects si,
namely,
Cij(d) = exp

−

 d
φ
κ
,
with spatial error predictions (s01, . . . , s0k) for k = 3 new points. A nugget
term is included so that,
yi = α + si + ui,
and the interplay between variances governed by a uniform prior on,
ru =
σ2
s
σ2s + σ2u
,
with a Ga(1, 0.001) prior adopted on 1/σ2
s.
A two chain run with of 10,000 iterations (2,500 burn-in) shows the k = 3
predicted values close to the overall mean α = 4.3, and the spatial errors
(s01, s02, s03) at the new locations all having 95% credible intervals straddling

198
Applied Bayesian Hierarchical Methods
TABLE 4.2
Response variable and grid reference data.
x1
x2
y
E
Crude SMR
Barking and Dagenham
547.8
185.1
75
80.7
0.93
Barnet
524.3
191.7
145
169.8
0.85
Bexley
548.4
175.7
99
123.2
0.80
Brent
520.7
185.5
168
139.5
1.20
Bromley
541.8
167.6
152
169.1
0.90
Camden
527.9
184.3
173
107.2
1.61
Croydon
533.3
165.1
152
179.8
0.85
Ealing
515.9
181.4
169
160.4
1.05
Enﬁeld
533.1
195.3
130
147.5
0.88
Greenwich
542.8
176.8
117
116.8
1.00
Hackney
534.2
185.5
124
102.8
1.21
Hammersmith and Fulham
523.8
178.5
119
91.8
1.30
Haringey
531.5
189.6
134
119.6
1.12
Harrow
515
189.5
90
114.8
0.78
Havering
553.1
188.2
98
131.1
0.75
Hillingdon
508.6
183.8
89
136.1
0.65
Hounslow
514
175.8
128
116.6
1.10
Islington
531.1
185.1
145
98.5
1.47
Kensington and Chelsea
525.6
179.5
130
88.8
1.46
Kingston upon Thames
519.4
167.5
69
79.8
0.86
Lambeth
530.8
174.6
246
144.9
1.70
Lewisham
537.5
174
166
134.7
1.23
Merton
525.8
169.3
95
98.9
0.96
Newham
541.2
183.6
135
118.6
1.14
Redbridge
543.8
188.9
98
130.6
0.75
Richmond upon Thames
517
173.4
97
96.1
1.01
Southwark
526.6
164.5
202
127.1
1.59
Sutton
533.6
177.1
75
97.7
0.77
Tower Hamlets
536.1
181.8
100
88.5
1.13
Waltham Forest
526.4
173.9
100
121.4
0.82
Wandsworth
527.2
181.1
153
156.8
0.98
Westminster, City of
537.9
189.6
194
114
1.70
zero. The spatial process has a low φ value, with posterior mean (95% interval)
of 0.16 (0.1, 0.4), and so relatively strong distance decay, while κ has mean
1.3 (0.95, 1.6). Spatial variation outweighs nugget variation with respective
posterior medians on σ2
s and σ2
u of 8.3 and 0.4, respectively. The DIC (and de)
stands at 103 (22).
Example 4.12. Area Suicide Counts
This example relates to a discrete
area outcome, but subject to smoothing via geostatistical methods. Suicide
mortality totals, yi (male and female suicides combined over 1989–1993), in 32
London boroughs, expected deaths, Ei, and grid references (gi1, gi2) are shown
in Table 4.2. The grid references are deﬁned so that inter-area distances are

Structured Priors Recognizing Similarity over Time and Space
199
in kilometres. To apply kernel smoothing, a two-way grid enclosing London
is constructed; this has 13 equally spaced points (eastings from 500 to 560
at intervals of 5) on its east-west axis, and 11 north–south points (northings
from 160 to 210). So there are m = 143 interior points, tj = (tj1, tj2), deﬁning
the grid.
A discrete kernel approach is applied with a log link regression with yi ∼
Po(λi) where,
log(λi) = log(Ei) + β0 +

j
Kijwj,
and with a normal kernel,
Kij(dij) =
1
σk
√
2π exp

−d2
ij/2σ2
k

,
with distances dij =
!
(gi1 −tj1)2 + (gi2 −tj2)2"0.5, and standard deviation σk
preset at 8. This setting ensures a majority of Kij are negligible (e.g., only
17/143 of K1j are above 0.01, with 2 above 0.4). The wj are assumed to be
unstructured random eﬀects with zero mean, and with standard deviation, σw,
assigned a U(0, 100) prior.
The second half of a two chain run12 of 50,000 iterations gives a mean
scaled deviance of 67, with σw having posterior mean 0.85. Predictive perfor-
mance is satisfactory with observed counts for 31 of the 32 areas contained
within 95% intervals for replicate data. Analogues to area-speciﬁc spatial ef-
fects, si, are obtained by centering the terms,
Ai =
m

j=1
Kijwj,
around their means. Then 24 of the 32 centered spatial eﬀects, si = Ai−¯A, are
judged signiﬁcant in that the posterior probability they exceed zero is above
0.95 or below 0.05.
To achieve a match between average deviance and the number of obser-
vations, one might simply add an unstructured error. An alternative that
achieves the same goal of improved ﬁt but preserves the majority of signiﬁ-
cant spatial eﬀects is based on the switching spatial prior of Congdon (2007b).
Thus,
log(µi) = log(Ei) + β0 +
m

j=1
Kijwj + δiui,
where δi ∼Bern(0.05) and ui is a zero mean unstructured normal eﬀect.
Three areas (21, 31, 32) have posterior probabilities, Pr(δi = 1|y), exceed-
ing 0.9, but 16 of the si remain signiﬁcant. The average deviance is reduced
to 34.

200
Applied Bayesian Hierarchical Methods
Finally, a stick-breaking prior is applied with m = 8 potential clus-
ters, and cluster centers (eastings and northings) taken to be uniform t1j ∼
U(509, 533), t2j ∼U(165, 195). The {wj, j = 1, . . . , m} are normal with pre-
cision 1/σ2
w taken to be Ga(1, 0.01), while the mixture parameters, Vj, are
taken to be Be(1, 2). The kernels are normal in form,
Kij = exp[−|gi −tj|/2γj],
with bandwidths γj taken to be Ga(1.5, 40), and choice of scale parameter
based on the maximum possible distance between areas, as in Reich and
Fuentes (2007). Then,
log(µi) = log(Ei) + β0 + wSi.
A single chain run of 10,000 iterations produces an average deviance of
35.8, close to the number of areas, without a separate unstructured eﬀect,
ui, being needed. Monitoring the realized spatial eﬀects for borough i, namely
wSi, 19 of the 32 eﬀects are judged signiﬁcant in that the posterior probability
they exceed zero is above 0.95 or below 0.05.
Appendix: Computational Notes
1. In one chain the initial values for the µt are set equal to the yt, and the
ﬁrst inits ﬁle is
list(invV=1,q=c(1,1,1),delta1=5,s1=c(0,0,0,0,0,0,0,0,0,0,0),
mu1=112,mu=c(NA,118,. . . ,))
while the other inits ﬁle is based on an exploratory single chain run using
these initial values. The code for the air passenger data analysis is then
model {for (t in 1:T) { y[t]∼dnorm(m.y[t],invV); m.y[t] <- mu[t] +s[t]}
for (t in 2:T){ mu[t] ∼dnorm(m.mu[t],invW[1])
m.mu[t] <- mu[t-1]+del[t-1]; del[t] ∼dnorm(del[t-1],invW[2])}
for (t in 12:T) {s[t]∼dnorm(m.s[t],invW[3]);
m.s[t] <- -sum(s[t-S+1:t-1])}
# initial conditions
for (j in 1:11) {s[j] <- s1[j]; s1[j]∼dnorm(0,0.001)}
del[1] <- del1; mu[1] <- mu1
del1∼dnorm(0,0.001); mu1∼dnorm(0,0.00001)
# variances
invV∼dgamma(1,0.001); q[3]∼dgamma(1,0.001)
q[2]∼dexp(10); q[1]∼dexp(10)
for (j in 1:3) { invW[j] <- invV/q[j]; W[j] <- 1/invW[j]}}.
The code for the alternative prior is
model {for (t in 1:T) { y[t]∼dnorm(m.y[t],tau[1]); m.y[t] <- mu[t] +s[t]}

Structured Priors Recognizing Similarity over Time and Space
201
for (j in 1:3) {q[j]∼dnorm(0,1) I(0,); tau[j+1] <- tau[1]/q[j] }
for (t in 2:T){mu[t]∼dnorm(m.mu[t],tau[2])
m.mu[t] <- mu[t-1]+del[t-1];del[t]∼dnorm(del[t-1],tau[3])}
for (t in 12:T) {s[t]∼dnorm(m.s[t],tau[4]);
m.s[t] <- -sum(s[t-S+1:t-1])}
# initial conditions
for (j in 1:11) {s[j] <- s1[j]; s1[j]∼dnorm(0,0.1)}
del[1] <- del1; del1∼dnorm(0,0.1)
mu[1] <- mu1; mu1 ∼dnorm(0,0.00001); tau[1] ∼dgamma(1,0.01)}
with initial values list(del1=0,mu1=0,s1=c(0,0,0,. . . ,),tau=c(1,NA,NA,NA),
q=c(1,1,1)) and list(del1=0,mu1=0,s1=c(0,0,0,. . . ,),tau=c(10,NA,NA,NA),
q=c(0.1,0.1,0.1)).
2. The code in Example 4.3 is
model { tau∼dgamma(1,0.001); sig2 <- 1/tau
sig2z <- (gam+ph)*(gam+ph)*sig2; tau.z <- 1/sig2z
for (t in 1:T) { y[t] ∼dnorm(z[t],tau)}
for (t in 2:T) { mu.z[t] <- ph*z[t-1]
# one step ahead predictions
yp.one[t]∽dnorm(z[t-1],tau)
z[t] ∼dnorm(mu.z[t],tau.z)}
z1 ∼dnorm(0,0.001); z[1] <- z1
ph∼dunif(-1,1); gam∼dunif(-1,1)}
3. The codes for the two models in Example 4.4 are as follows
model { for (a in 1:9) {for (g in 1:2) {
y[a,g] ∼dpois(m[a,g]); ynew[a,g] ∼dpois(m[a,g])
m[a,g] <- r[a,g]*P[a,g]/1000; log(r[a,g]) <- del[g,a]}}
for(g in 1:2){del[g,1] ∼dﬂat(); sig[g] ∼dunif(0,100);
tau[g] <- pow(sig[g],-2)
for (a in 2:9){del[g,a] ∼dnorm(del[g,a-1],tau[g])}}}
and
model { for (a in 1:9) {for (g in 1:2) {
y[a,g] ∼dpois(m[a,g]); ynew[a,g] ∼dpois(m[a,g])
m[a,g] <- r[a,g]*P[a,g]/1000;
log(r[a,g]) <- lam[a,g]}}
for (g in 1:2) {ph[g] ∼dnorm(0,1); lam[1,g] <- omeg[1,g]
for (a in 1:9) {omeg[a,g] ∼dnorm(0,chi[a])}
for (a in 2:9) {lam[a,g] <- ph[g]*lam[a-1,g]+omeg[a,g]}}
for (a in 1:9) {log(chi[a]) <- b[1]+b[2]*a+b[3]*a*a}
for (j in 1:3) {b[j] ∼dnorm(0,1)}}.
4. The code for the telephone call data (Example 4.5) is
model { for (t in 1:T) {y[t] ∼dpois(mu[t])
log(mu[t]) <- lam[t] + sum(c[1:K,t])}

202
Applied Bayesian Hierarchical Methods
for (k in 1:K) {c[k,1] ∼dnorm(0,0.001); d[k,1] ∼dnorm(0,0.001)}
Zr ∼dunif(0,10); lam[1] ∼dnorm(0,0.001)
for (j in 1:3) {v[j] ∼dgamma(1,1); q[j] <- v[j]/sum(v[])
W[j] <- Zr*Zr*q[j]; tau[j] <- 1/W[j]}
for (t in 2:336) {yp[t] ∼dpois(mu[t-1])
lam[t] ∼dnorm(lam[t-1],tau[1])
for (k in 1:K) { c[k,t] ∼dnorm(C[k,t],tau[2])
d[k,t] ∼dnorm(D[k,t],tau[3])
C[k,t] <- c[k,t-1]*cos(2*k*pi/S)+d[k,t-1]*sin(2*k*pi/S)
D[k,t] <- -c[k,t-1]*sin(2*k*pi/S)+d[k,t-1]*cos(2*k*pi/S)}}}
5. The code for the double autoregression model of the treasury bill data,
with xt= log(rt), is
model { for (t in 1:349) {y[t] <- x[t+1]-x[t]}
for (t in 2:349) {y[t]∼dnorm(mu[t],tau[t]); mu[t] <- rho*y[t-1]
ynew[t] ∼dnorm(mu[t],tau[t]); dnew[t] <- pow(y[t]-ynew[t],2)
var[t] <- gam + alph*y[t-1]*y[t-1]; tau[t] <- 1/var[t]}
rho <- sqrt(rho2); gam ∼dgamma(1,1)
rho2 <- r[1]/sum(r[]); alph <- r[2]/sum(r[])
Dnew <- sum(dnew[2:349])
for (j in 1:3) {r[j]∼dgamma(1,1)}}
The state–space model has code
model { for (t in 1:349) {y[t] <- x[t+1]-x[t]}
for (t in 2:349) {y[t] ∼dnorm(m.y[t],tau[t]); ynew[t] ∼dnorm(m.y[t],tau[t]);
tau[t] <- 1/exp(th[t]); var[t] <- 1/tau[t]; m.y[t] <- rho*y[t-1]
th[t] ∼dnorm(m.th[t],invW); m.th[t] <- mu + ph*th[t-1]}
rho∼dnorm(0,1); ph∼dnorm(0,1); mu∼dnorm(0,0.001)
invW∼dgamma(1,0.001); th[1] <- 0}
6. The code for the ﬁrst Nile discharge analysis is
model { for (t in 1:T) {y[t] <- Y[t]-Y[1];
y[t] ∼dnorm(mu[t],tau)}
y0 ∼dt(0,tau,2); ym1 ∼dt(0,tau,2)
for (t in 3:T) {mu[t] <- ph0+ph[1]*y[t-1]+ph[2]*y[t-2]}
mu[2] <- ph0+ph[1]*y[1]+ph[2]*y0;
mu[1] <- ph0+ph[1]*y0+ph[2]*ym1
ph0 ∼dﬂat(); for (j in 1:2) {ph[j]∼dnorm(0,1)}
tau ∼dgamma(1,0.001); sig <- sqrt(1/tau)}.
The code for the AR(1) model with shift mechanism is
model { for (t in 1:T) {y[t] <- Y[t]-Y[1]; y[t]∼dnorm(mu[t],tau)}
y0 ∼dt(0,tau,2);
for (t in 2:T) {mu[t] <- ph0[2]*step(t-kap)+ph0[1]+ph*y[t-1]}
mu[1] <- ph0[1]+ph*y0
ph ∼dnorm(0,1); kap ∼dunif(3,97)
for (j in 1:2) {ph0[j] ∼dﬂat()}
tau ∼dgamma(1,0.001); sig <- sqrt(1/tau)}

Structured Priors Recognizing Similarity over Time and Space
203
7. The code for the Box–Jenkins series A data is
model { for (t in 1:T) {y[t] ∼dnorm(mu[t],tau[S[t]])
mu[t] <- beta0+th[t]; S[t] ∼dcat(p[1:3])}
r ∼dexp(9); p[1] <- 1/(1+r); p[2] <- 0.5*r/(1+r); p[3] <- 0.5*r/(1+r)
for (t in 2:T) {th[t] ∼dnorm(m.th[t],tau.th); m.th[t] <- phi*th[t-1]}
th[1] <- 0; beta0 ∼dnorm(0,0.00001)
tau.th <- tau[1]/q; tau[1] ∼dgamma(1,0.001)
tau[2] <- tau[1]/10; tau[3] <- tau[1]/32
q ∼dexp(1); phi ∼dunif(-1,1)
sig2[1] <- 1/tau[1]; sig2[2] <- 1/tau.th}
8. The code excluding model ﬁt elements for the blood lead example (Ex-
ample 4.10) is
model {for (i in 1:133) {y[i] ∼dbin(p[i],n[i])
u[i] ∼dnorm(0,inv.delta.u); p.sig[i] <- step(s[i])
logit(p[i]) <- alph+s[i]+u[i]}
s[1:133] ∼car.normal(map[],wei[],d[],inv.delta)
for (j in 1:1056) {wei[j] <- 1}
V.s <- pow(sd(s[]),2); r.u ∼dunif(0,1);
delta.u <- r.u*V.s/(1-r.u); inv.delta.u <- 1/delta.u
inv.delta ∼dgamma(1,0.001); alpha ∼dﬂat()}
The Leroux et al. model has code
model {for (i in 1:N) {y[i] ∼dbin(p[i],n[i])
p.sig[i] <- step(s[i]); logit(p[i]) <- alph+s[i]
s[i] ∼dnorm(S[i],tau[i]); tau[i] <- inv.delta * (1-lam+lam*d[i])
S[i] <- (lam/(1-lam+lam*d[i]))*sum(Ws[C[i]+1:C[i+1] ])}
# sum weighted errors over neighbors
for (i in 1:NN) { Ws[i] <- s[map[i]] }
inv.delta ∼dgamma(1,0.001); alph ∼dﬂat(); lam ∼dunif(0,1)}
9. The Potts prior model has code
model { for (i in 1:N) { y[i] ∼dpois(nu[i]); ynew[i] ∼dpois(nu[i])
nu[i] <- E[i]*lam[i]; lam[i] <- mu[S[i]]; S[i] ∼dcat(p[i,1:K])
dv[i] <- y[i]*log(y[i]/nu[i])-(y[i]-nu[i])
for (k in 1:K) {J[i,k] <- equals(S[i],k);
# allocation probabilities
p[i,k] <- U[i,k] /sum(U[i,])
log(U[i,k]) <- omega*sum(wJ[cumnei[i] + 1 : cumnei[i + 1],k ])}}
for (i in 1 : NN ) {for (k in 1:K) { wJ[i,k] <- J[map[i],k] }}
for (k in 2:K) {eta[k-1] ∼dnorm(0,tau.eta);
mu[k] <- mu[k-1]+exp(eta[k-1])}
D <- 2*sum(dv[]); mu1 ∼dgamma(1,1); mu[1] <- mu1;
# priors
omega ∼dexp(1); tau.eta ∼dgamma(1,1)}
The code for the adaptive convolution prior is
model {for (i in 1:N) { y[i] ∼dpois(nu[i]); ynew[i] ∼dpois(nu[i])

204
Applied Bayesian Hierarchical Methods
nu[i] <- E[i]*lam[i]; log(lam[i]) <- r[i]*u[i]+(1-r[i])*s[i];
r[i] ∼dbeta(1,1); u[i] ∼dnorm(0,inv.delta.u);
s[i] ∼dnorm(S[i],tau.s[i])
S[i] <- mean(Ws[ cumnei[i]+1 : cumnei[i+1] ])
tau.s[i] <- inv.delta.s*d[i]; d[i] <- cumnei[i+1]-cumnei[i]
dv[i] <- y[i]*log(y[i]/nu[i])-(y[i]-nu[i])}
for (i in 1 : NN ) {Ws[i] <- s[map[i]] }
D <- 2*sum(dv[]); h ∼dexp(1)
# priors
inv.delta.u ∼dgamma(0.127,0.01); inv.delta.s ∼dgamma(0.024,0.01)}
10. The code for the Lee et al. (2005) line example, with precision τw for
the wj assigned a Ga(1, 0.001) prior is
model { for (i in 1:n) {y[i] ∼dnorm(mu[i],tau[1])
mu[i] <- beta+sum(Kw[i,])
for (j in 1:m) {K[i,j] <- phi((x[i]-t[j])/sd.kern)
Kw[i,j] <- K[i,j]*w[j]}}
w[1] ∼dnorm(0,0.1); beta ∼dﬂat()
for (j in 2:m) {w[j] ∼dnorm(w[j-1],tau[2])}
for (j in 1:2) {tau[j] ∼dgamma(1,0.001)}}
with data input
list(sd.kern=0.6,n=12,m=20,x=c(0,0.91,1.82,2.73,3.64,4.55,5.45,
6.36,7.27,8.18,9.09,10),y=c(1.19,0.80,1.07,0.45,0.22,0.11,
-0.06,0.13,-0.25,0.47,0.36,0.46),t=c(-2,-1.26,-0.53,0.21,0.94,1.68,2.42,3.15,
3.89,4.63,5.36,6.1,6.84,7.57,8.31,9.05,9.79,10.53,11.26,12))
11. The WinBUGS code for the TCE data is
model { for (i in 1 : 56) { y[i] <- log(Y[i]+1); y[i] ∼dnorm(mu[i],tau.u)
X1[i] <- x1[i]/100; X2[i] <- x2[i]/100; nought[i] <- 0; mu[i] <- alpha+s[i]}
# structured errors
s[1:56] ∼spatial.exp(nought[],X1[],X2[],tau.s,phi.inv,kappa)
for(i in 1:k) { X0east[i] <- x0east[i]/100; X0north[i] <- x0north[i]/100
# single site prediction
s0[i] ∼spatial.unipred(0,X0east[i], X0north[i],s[])
y0[i] <- alpha+s0[i]}
# priors
alpha ∼dnorm(0,0.001); phi.inv ∼dunif(0,10); phi <- 1/phi.inv
kappa ∼dunif(0,2); r.u ∼dunif(0,1); sig2.s <- 1/tau.s; tau.s ∼dgamma
(1,0.001);
sig2.u <- sig2.s*(1-r.u)/r.u; tau.u <- 1/sig2.u}
12. The code for Example 4.13 is
model { for (i in 1:n) { y[i] ∼dpois(mu[i]); yrep[i] ∼dpois(mu[i])
log(mu[i]) <- log(E[i])+beta0+sum(Kw[i,])
tkw[i] <- sum(Kw[i,]); s[i] <- tkw[i]-mean(tkw[])

Structured Priors Recognizing Similarity over Time and Space
205
for (j in 1:m) {d[i,j] <- sqrt(pow(x1[i]-t1[j],2)+pow(x2[i]-t2[j],2))
K[i,j] <- phi(-pow(d[i,j]/sig.k,2));
Kw[i,j] <- K[i,j]*w[j]}}
beta0 ∼dﬂat()
for (j in 1:m) {w[j] ∼dnorm(0,tau)}
sd.w ∼dunif(0,100); tau <- pow(sd.w,-2)
for (i in 1 : n) { # probs of extreme values of s
p.sig[i] <- step(s[i])
# deviance
dev[i] <- y[i]*log(y[i]/mu[i])-(y[i]-mu[i])}
# Deviance
Dv <- 2*sum(dev[])}
The amended lines of code in the model extension are
log(mu[i]) <- log(E[i])+beta0+sum(Kw[i,])+del[i]*u[i]
u[i] ∼dnorm(0,tau.u); del[i] ∼dbern(0.05)
· · ·
sd.u ∼dunif(0,100); tau.u <- pow(sd.u,-2).
The code for the stick-breaking prior incorporating cluster speciﬁc kernels is
model {for(i in 1:n){y[i] ∼dpois(mu[i])
log(mu[i]) <- log(E[i])+beta0+w[S[i]]
# realized spatial eﬀect
s[i] <- w[S[i]]; pexc.s[i] <- step(s[i])
# deviance elements
dev[i] <- y[i]*log(y[i]/mu[i])-(y[i]-mu[i])
# cluster choice
S[i] ∼dcat(p[i,1:m])
g1[i] <- eas[i]/10; g2[i] <- nor[i]/10}
beta0 ∼dnorm(0,0.01); for (j in 1:m) {w[j] ∼dnorm(0,tauw)}
tauw ∼dgamma(1,0.01)
for (i in 1:n) {p[i,1] <- R[i,1]; R[i,m] <- 1
for (j in 2:m) {p[i,j] <- R[i,j]*prod(Rm[i,1:(j-1)])}}
for (j in 1:(m-1)) {v[j] ∼dbeta(1,2)
# centres of kernel functions
t1[j] ∼dunif(min1,max1); t2[j] ∼dunif(min2,max2)
# bandwidth params
gam[j] ∼dgamma(1.5,lambda)
for (i in 1:n) {d[i,j] <- pow(t1[j]-g1[i],2) + pow(t2[j]-g2[i],2)
R[i,j] <- exp(-0.5*d[i,j]/gam[j])*v[j]
Rm[i,j] <- 1-R[i,j]}}
# range parameter
lambda ∼dunif(0,40)
# Deviance
Dv <- 2*sum(dev[])}

5
Regression Techniques Using
Hierarchical Priors
5.1
Introduction
This chapter is concerned with the application of hierarchical priors to regres-
sion models for univariate metric and discrete responses, where the observation
units are non-nested but may be spatially or temporally conﬁgured. Nested
data applications are considered in Chapters 6 and 8. Particular applications
involving latent responses or random eﬀects are when such eﬀects are used:
1.
to improve model ﬁt in general linear models in line with distribu-
tional assumptions;
2.
to generate latent responses on a diﬀerent scale to the observations;
3.
to demonstrate heterogeneity in regression relationships or variance
parameters over exchangeable sample units;
4.
to represent random regression eﬀects and correlated regression
errors for responses structured in time or space.
Let {y1, . . . , yn} be observations from the exponential family density,
p(yi|θi, φ) = exp
yiθi −b(θi)
ai(φ)
+ c(yi, φ)

,
(5.1)
with canonical parameter, θi, dispersion function, ai(φ) = φ/wi, and wi
known. The mean of y is µi = E(yi|θi) = b′(θi), linked to predictors Xi
via a monotone link function, g(µi) = Xiβ, and the variance is
Var(yi|θi) = ai(φ)b′′(θi) = ai(φ)Var(µi).
The exponential family includes as special cases the binomial, Poisson,
exponential, gamma, and inverse Gaussian densities. The generalized linear
model (Dey et al., 2000; McCullagh and Nelder, 1989) scheme extends normal
linear regression concepts to such outcomes.
However, counts assumed to be Poisson or binomial often show a residual
variance larger than expected under the exponential family models, due to
unknown omitted covariates, clustering in the original units, or inter-subject
207

208
Applied Bayesian Hierarchical Methods
variations in propensity (Albert and Pepple, 1989; Dey and Ravishanker, 2000;
Gschl¨oßl and Czado, 2006). Unless such excess dispersion is allowed for, stan-
dard errors are likely to be understated. The solution involves regression with
conjugate or nonconjugate mixing for the residual variation (Section 5.2), and
the focus in Markov Chain Monte Carlo (MCMC) is often on the complete
data likelihood rather than the marginal model obtained by integrating over
the random eﬀects.
Binary and multinomial regression based on the generalized linear mod-
eling principles is widely applied, with Bayesian strategies described in Dey
et al. (2000). Sampling and inference in Bayesian general linear models is,
however, complicated to the extent that conjugate priors are only avail-
able for normal regression (Holmes and Held, 2006). The auxiliary variable
approach (Albert and Chib, 1993; van Dyk and Meng, 2001) circumvents
this by introducing latent continuous responses underlying the binary or
categorical observations, resulting in a speciﬁcation (including priors) that
eﬀectively replicates normal regression (Section 5.3). This provides simpli-
ﬁed MCMC sampling, improved residual tests, and facilitates multivariate
analysis involving mixtures of continuous and discrete responses, as in the
underlying variable approach in factor analysis (Bartholomew, 1987; Muthen,
1984).
For data assumed conditionally normal, one has θi = µi = Xiβ and
ai(φ) = σ2, and the canonical form of the normal linear regression model is
yi = Xiβ + εi,
(5.2)
where εi ∼N(0, σ2). However, the assumption of homoscedastic normal errors
in Equation 5.2 may be restrictive in many modeling situations due to the rel-
atively thin tails of the normal, particularly when unusual observations are
present. Geweke (1993), Lange et al. (1989), and West (1984) consider regres-
sion based on a wider class of scale mixtures of normals, which leads to a
varying scale parameter for each sample unit, and leads to heavier tails than
the normal. Qin et al. (2000) propose an alternative scale mixture of uniforms
method, which can lead to both heavier and lighter tails than the normal.
Other approaches to heteroscedasticity are possible, including variance trans-
formation and variance regression modeling (Cepeda and Gamerman, 2000);
see Section 5.4. The other main limitation of Equation 5.2 is the assumption
of identical regression eﬀects for all cases. Alternatives are discrete mixture
regressions, also known as regression regimes in time series applications (Hurn
et al., 2003), and random coeﬃcient models (Swamy and Mehta, 1975)—see
Section 5.5.
For structured data observed over neighboring areas or periods, or points
in time or space, a mis-speciﬁcation of regression is likely to be apparent in
correlated residuals. Either the error structure will need to accommodate such
correlation or the design component of the regression model will need to be
extended to reduce residual correlation. In time series regression, relatively
simple autoregressive or moving average error structures are often suﬃcient

Regression Techniques Using Hierarchical Priors
209
to remove residual correlation, though time-varying regression eﬀects are often
relevant in particular applications—see Sections 5.6 and 5.7.
In spatial data modeling, correlated residuals may be attributable to omit-
ted predictors, nonlinear eﬀects, and spatial heterogeneity—see Section 5.8.
In particular, varying regression eﬀects over space may be indicated for some
or all observed predictors and the prior governing the randomly varying coeﬃ-
cients will be spatially structured—see Section 5.9. While classical approaches
center on geographically weighted regression, random spatially varying coeﬃ-
cient models based on Bayesian principles (Assun¸c˜ao, 2003; Gamerman et al.,
2003) arguably provide greater inferential ﬂexibility.
5.2
Regression for Overdispersed Discrete Data
For discrete data (Poisson, binomial, multinomial), overdispersion is typically
due to unobserved variations between subjects (also called frailty eﬀects) that
are not represented by the observed covariates. For time series data, another
possibility is contagion, violating the Poisson assumption that events occur
randomly in time (Winkelmann and Zimmerman, 1995). Particular types of
response pattern (e.g., an excess proportion of zero counts as compared to
the expected Poisson frequency) may also cause overdispersion (Hall, 2000).
Without correction for such extra-variability, regression parameter estimates
may be biased, and their credible intervals will be too narrow, so that incorrect
inferences about signiﬁcance may be obtained (Cameron and Trivedi, 1998).
For example, the Poisson regression model for count data assumes that the
mean and variance are equal, but overdispersion as compared to the Poisson
assumption is routinely encountered. As discussed in Chapter 3, the conjugate
mixture model for count data is the Poisson-gamma with,
yi ∽Po(µi),
µi ∽Ga(αi, ηi).
Denoting the mean of µi as ξi = αi/ηi, one obtains Var(µi) = αi/η2
i =
ξ2
i /αi and
Var(yi) = E[Var(yi|µi)] + Var[E(yi|µi)] = ξi + ξ2
i /αi,
so providing overdispersion as αi becomes smaller. The mean is modeled by
regression, typically involving ﬁxed eﬀects only, with ξi = exp(β0+β1x1i+· · ·+
βpxpi). Identiﬁcation requires constraints on the gamma mixture parameters,
such as αi = α in the {ξi, αi} parameterization, namely, µi ∽Ga(α, α/ξi).
Then with φ = 1/α, one has a quadratic variance function, denoted as NB2
(e.g., Cameron and Trivedi, 1998, 71) with,
Var(yi) = E[Var(yi|µi)] + Var[E(yi|µi)] = ξi + φξ2
i .
(5.3)

210
Applied Bayesian Hierarchical Methods
Another possibility (Fahrmeir and Osuna, 2006; Greene, 2007) is to set
µi = ξiωi, where ωi ∽Ga(α, α) so that the frailties average 1, with variance
φ = 1/α. Integrating out ωi leads to a marginal negative binomial density
for yi, namely,
p(yi|β, α) =
Γ(α + yi)
Γ(α)Γ(yi + 1)

α
α + ξi
α 
ξ
α + ξi
yi
.
Bayesian approaches to the negative binomial include Bradlow et al.
(2002), Chun and Sumichrast (2007), and Dauxois et al. (2006). Dauxois
et al. (2006) adopt prior distributions on the variance function coeﬃcients to
encompass Poisson, binomial, and negative binomial models simultaneously
and decide which provides a better ﬁt. Fahrmeir and Osuna (2006) adopt
a Ga(a, b) prior for the overdispersion parameter α, with a = 1, and with
b ∼Ga(1, 0.005) taken as an extra unknown. They show that the full condi-
tional for this parameter then has no closed analytical form, so that a M-H
algorithm is required to sample values with a random walk proposal.
A more general NBk form is described by Winkelmann and Zimmermann
(1995), and involves a variance function,
Var(yi) = E[Var(yi|µi)] + Var[E(yi|µi)] = ξi + φξk+1
i
,
(5.4)
with k ≥−1. This is obtained by an extra parameter in the mixing prior,
namely,
µi ∽Ga

ξ1−k
i
φ
, ξ−k
i
φ

.
The values k = 0 and k = 1 lead to variance forms (NB1 and NB2) that
are linear and quadratic in ξi, namely, Var(yi) = ξi + φξi = (1 + φ)ξi and
Var(yi) = ξi + φξ2
i , respectively.
Nonconjugate random mixture models are often adopted for count data,
with normal or Student t errors in the log link (Kim et al., 2002). This is a
more common approach when multiple or multilevel random eﬀects are to be
considered, with an example being the convolution prior (Besag et al., 1991)
for area disease events, yi, in population totals, Pi. Thus, for rare events,
yi ∽Po(Piµi), where,
log(µi) = Xiβ + εi + si,
and both random eﬀects {εi, si} may account for overdispersion, but the εi
are unstructured (exchangeable with regard to area identiﬁers) while the si
are spatially structured. For count regressions only involving an unstructured
error, one may specify,
µi = E(yi|Xi, εi) = exp(Xiβ + σεi),

Regression Techniques Using Hierarchical Priors
211
with εi ∼N(0, 1). Denoting νi = exp(Xiβ), the unconditional mean (Greene,
2007) is
E(yi|Xi) = Eε[E(yi|Xi, εi)] = νi exp(σ2/2),
and the unconditional variance is
Var(yi|Xi) = Eε[Var(yi|Xi, εi)] + Varε[E(yi|Xi, εi)]
= νi exp(σ2/2){1 + νi exp(σ2/2)[exp(σ2) −1]}.
Taking φ = eσ2 −1,
Var(yi|Xi) = E(yi|Xi, εi)[1 + φE(yi|Xi, εi)],
showing that the variance has a quadratic form, as for the NB2 form of the
negative binomial.
5.2.1
Overdispersed binomial and multinomial regression
Binomial regression with excess variation may occur when responses are
arranged in clusters and responses from the same cluster are correlated: exam-
ples occur in teratological studies (e.g., when the observation unit is a litter
of animals, and litters diﬀer in terms of unknown genetic factors). Crowder
(1978) assumed a conjugate approach with a beta distributed success probabil-
ity, leading to a beta-binomial regression model—this form of overdispersion
model is considered in Bayesian terms by Kahn and Raftery (1997). Thus,
with yi ∼Bin(ni, pi), one assumes,
pi ∼Beta(γπi, (1 −πi)γ),
with mean πi and variance,
πi(1 −πi)/(γ + 1),
where γ ≥0. Regression on known predictors involves a logit or other link,
g(πi) = Xiβ.
Setting ϕ = (γ + 1)−1, the unconditional variance of a beta-binomial re-
sponse is of the form (Collett 2002, 201),
Var(yi) = nipi(1 −pi)[1 + (ni −1)ϕ].
Possible priors on the precision parameter γ include P(γ) ∝1/γ, and
(Albert, 1988),
P(γ) = 1/(1 + γ)2.

212
Applied Bayesian Hierarchical Methods
Nonconjugate random mixture models are often adopted for binomial data,
with normal or Student t errors in the regression link (whether logit, probit, or
complementary log-log). The presence of an error term permits regression vari-
able selection using a g-prior approach (Zellner, 1983), which avoids specifying
the prior covariances for the elements of β and instead assumes these covari-
ances are a multiplier of those provided by the observations. Thus, Gerlach
et al. (2002) and Kinney and Dunson (2007) propose variable and random
eﬀects selection in mixed logistic models, with g-priors on the ﬁxed eﬀects.
A logit link example is
logit(πi) = Xiβ + εi,
εi ∼N(0, σ2),
with g-prior (g > 1, typically large),
β ∼N(B, σ2g(X′X)−1).
For multinomial data (e.g., on voting patterns, yij, for parties, j, by con-
stituency, i) overdispersion may occur when choice probabilities vary between
Ni individuals in each observation unit, but clusters of individuals within
each unit have similar probabilities. The individual level factors associated
with such clustering are not observed, so a random eﬀect will proxy such
unobserved factors; for example, voters with diﬀerent education levels may
diﬀer in their voting preferences, but only the average education in each con-
stituency is observed. The raw percentages, yij/Ni, are also likely to show
erratic features, whereas hierarchical models for pooling strength over units
provide frequency smoothing and model interdependencies between categories.
This form of data may be modeled as a product multinomial likelihood
conditioning on known Ni = yi+. With probabilities, πij, of choices, j =
1, . . . , J, the sampling model is
yij ∼M(Ni, [πij, . . . , πiJ])
i = 1, . . . , n.
The conjugate approach for such heterogeneity is the multinomial-Dirichlet
mixture, where the Dirichlet is the multivariate generalization of the beta
density. However, the Dirichlet has a restricted covariance structure when
there are dependencies between the response categories, j, within units, i.
For example, for n constituencies and J political parties, one may expect both
negative and positive correlations between πij for diﬀerent parties. Greater
ﬂexibility is provided by modeling heterogeneity within the regression link, as
in random eﬀects multiple logit models (Hensher and Greene, 2003), or via
multinomial probit models (Hausman and Wise, 1978).
Under the multiple logit form, deﬁne a J −1 dimensional random eﬀect,
αi = (αi1, . . . , αi,J−1), representing subject or unit level intercepts; these might
be exchangeable or correlated (if, say, the units were areas and behaviors were
spatially clustered). Then with Xi excluding an intercept,

Regression Techniques Using Hierarchical Priors
213
πij = exp(αij + Xiβj)
 J

k=1
exp(αik + Xiβk),
with αiJ = βJ = 0 for identiﬁcation. For example, one may assume,
(αi1, . . . , αi,J−1) ∼NJ−1(A, D),
(5.5)
where D is an unknown covariance matrix, and A is the average intercept.
This model may also be ﬁtted by Poisson regression using the fact that the
multinomial is equivalent to a Poisson distribution conditional on a ﬁxed total;
this involves deﬁning n ﬁxed eﬀect predictors, ai, to ensure the unit totals, Ni,
are maintained. Thus, yij ∼Po(µij), with,
log(µij) = ai + αij + Xiβj,
for j = 1, . . . , J, where ai would typically be ﬁxed eﬀects assigned vague
priors, e.g., ai ∼N(0, 1000).
Example 5.1. Crab Data
This example considers Poisson overdispersion
in terms of diﬀerent negative binomial regression forms. The dataset is the
crab data from Agresti (1996) with n = 173 observations relating the number
of satellite males to the predictor x=carapace width. Overdispersion in the
data is apparent with variance of 9.9 exceeding the mean of 2.9. A simple
Poisson regression for these data assumes log(µi) = β1 + β2xi, and deviance
(minus twice the posterior mean likelihood) is 925.2. By contrast, under a
Poisson-gamma mixture with,
yi ∽Po(ξiωi),
ωi ∽Ga(α, α),
log(ξi) = β0 + β1xi,
the Poisson deviance is 539 with posterior mean and 95% CI for α of 0.95
(0.65, 1.35). This can be estimated using the marginal negative binomial
NB2 likelihood or the complete data Poisson-gamma likelihood, with the
latter approach having the beneﬁt of providing observation-speciﬁc frailties
(Fahrmeir and Osuna, 2006). The coeﬃcient β2 under the NB2 model has
mean 0.195 (0.10, 0.29), while φ is estimated as 1.1 (0.75, 1.55). This model
may also be estimated in BayesX1, under which the overdispersion param-
eter α has posterior mean 0.88, and mean deviance (minus twice the NB2
likelihood) of 754.4 and DIC of 757.4.
The suitability of the NB1 or NB2 form of negative binomial regression
may be assessed using the NBk model, whereby for yi ∼Po(µi) one has,
µi ∽Ga

ξ1−k
i
φ
, ξ−k
i
φ

,

214
Applied Bayesian Hierarchical Methods
and
Var(yi) = E[Var(yi|µi)] + Var[E(yi|µi)] = ξi + φξk+1
i
.
Gamma priors with scale and index parameters of 1 are adopted for φ
and k + 1. Since the predictor values are relatively large, a N(0, 1) prior is
adopted on its regression coeﬃcient to avoid numeric overﬂow. The second half
of a two chain run of 10,000 iterations gives posterior means (95% interval)
for k and φ of −0.39 (−0.93, 0.31) and 4.3 (2.0, 7.4). The posterior interval
for k excludes 1, and so does not favor the NB2 parameterization. In fact, the
overdispersion term in the variance function is close to involving a square root
in the mean ξi. The mean deviance is reduced to 527 under the NBk model,
and the coeﬃcient on x is more precisely identiﬁed with mean and 95% CI of
0.19 (0.13, 0.25).
Example 5.2. Voting in Florida, 2000: Multinomial Overdispersion
This example considers normal random eﬀects to model multinomial overdis-
persion via multiple logit links. The analysis relates to 2000 US presidential
election voting data, yij, for i = 1, . . . , 67 Florida polling districts and with
Ni denoting total votes (Mebane and Sekhon, 2004). There are J = 5 choices
(Buchanan, Nader, Gore, Bush, other) and three predictors:
1. x1, the proportion of each county’s votes for diﬀerent presidential
candidates in 1996;
2. x2, changes between 1996 and 2000 in party registration;
3. x3, percent of Census population Cuban in district i.
Speciﬁcation of x1 and x2 (predictors speciﬁc for area and candidate) fol-
lows Mebane and Sekhon (2004), but x3 diﬀers from their variable. Mebane
and Sekhon (2004) ﬁnd substantial overdispersion in these data.
The sampling model is
yij ∼Mult(Ni, [πi1, . . . , πi5])
i = 1, . . . , n,
πij = φij
, 
ij
φij,
and to account for overdispersion, normal eﬀects as in Equation 5.5 are in-
cluded in multiple logit links. These are denoted αij and are of dimension J −1
with nonzero means Aj, namely, the intercepts for the ﬁrst four choices. So,
log(φij) = αij + Xiβj,
(αi1, . . . , αi,J−1) ∼NJ−1(A, D),
log(φiJ) = 0,
with {βj,k; j = 1, 4, k = 1, 3} and Aj assigned ﬂat priors, and the precision
matrix, D−1, assigned a Wishart prior with identity scale matrix and J−1 = 4
degrees of freedom2.

Regression Techniques Using Hierarchical Priors
215
Despite centering of predictors and taking mean random eﬀects to be inter-
cepts, convergence is delayed to over 50,000 iterations in certain β coeﬃcients
when widely separated initial values (for two chains) are chosen. The scale of
the predictors is quite unusual in these data (evident in a very large coeﬃ-
cient for β2,2), and possibly standardizing predictors would improve MCMC
performance. Nevertheless, a posterior predictive check comparing chi-square
values for replicate and observed data (Gelman et al., 1996) is satisfactory at
around 0.30. This is not the case when a ﬁxed eﬀects only model is applied
with,
log(φij) = Aj + Xiβj
j = 1, . . . , J −1.
There is then zero posterior probability that χ2(yrep, θ) > χ2(y, θ).
Standard deviations of predictor eﬀects are also considerably understated if
allowance is not made for excess variation.
5.3
Latent Scales for Binary and Categorical Data
Prior speciﬁcation and sampling in binary and categorical regression is often
complicated by the nonconjugacy in the standard general linear model (GLM)
approach (Holmes and Held, 2006). For example, sampling strategies for the
logistic model include Metropolis–Hastings updates combined with an approx-
imate posterior density for the regression coeﬃcients obtained via iteratively
reweighted least squares (Gamerman, 1997), and adaptive rejection sampling
from the univariate conditional densities of the coeﬃcients (Dellaportas and
Smith, 1993). An alternative is to augment the observations with latent data
on a metric scale.
Consider ﬁrst binary responses. One may assume latent metric data, y∗,
such that y = 1 when y∗> 0 and y = 0 when y∗≤0 (Albert and Chib,
1993). In economic choice applications (e.g., regarding economic participation
or not), the latent scale y∗arises by comparing utilities U1i and U0i of options 1
and 0 with,
Uji = Vji + εji = Xiβ∗
j + εji,
y∗
i = U1i −U0i.
(5.6)
In other applications, y∗and U may be conceptualized diﬀerently; thus
Heringstad et al. (2001) consider a threshold-liability model for the analysis
of clinical mastitis as a binary response. Under the scheme (Equation 5.6) one
has,
Pr(yi = 1) = Pr(y∗
i > 0) = Pr(ε0i −ε1i < V1i −V0i) = Pr(ε0i −ε1i < Xiβ),
where β = β∗
1 −β∗
0. Alternative forms for ε lead to diﬀerent links: taking εji
to be normal with mean zero and variance σ2 leads to a probit link with

216
Applied Bayesian Hierarchical Methods
Pr(yi = 1) = Φ(Xiβ/σ). It is apparent that β and σ cannot be separately
identiﬁed, and the commonest identifying device takes σ2 = 1.
A probit regression with binary responses, yi, may therefore be obtained
by truncated normal sampling for y∗
i with the form of constraint determined
by the observed y. Thus, if yi = 1, y∗
i is constrained to be positive, and sampled
from a normal with mean Xiβ (including an intercept in p-dimensional Xi)
and variance 1. If yi = 0, y∗
i is sampled from the same density but constrained
to be negative. With a normal prior on the coeﬃcients β ∼Np(B0, V0), the
full conditional distribution of β is also normal, namely,
β|y∗∼N(B, V ),
B = V −1(V −1
0
B0 + X′y∗),
V = (V −1
0
+ X′X)−1.
Van Dyk and Meng (2001) use a “working parameter” sampling approach
that retains σ2 as an unknown, and amounts to the scheme,
y∗
i ∼N(Xiβσ, σ2)I(0, )
yi = 1,
y∗
i ∼N(Xiβσ, σ2)I(, 0)
yi = 0.
Holmes and Held (2006) propose an alternative strategy to reduce auto-
correlation and improve mixing in MCMC sampling by updating y∗and β
jointly, and justiﬁed by the factorization,
p(β, y∗|y) = p(y∗|y)p(β|y∗),
where updating of β is as above, but y∗is updated from its marginal distri-
bution integrated over β.
Heavier-tailed links are obtained by sampling y∗
i directly from a Student t
with ν degrees of freedom, or by using the scale mixture version of the Student t
density. This again involves constrained normal sampling but with gamma
distributed subject-speciﬁc precisions λi ∼Ga(ν/2, ν/2), so that,
y∗
i ∼N(Xiβ, 1/λi)I(0, ∞) when yi = 1,
y∗
i ∼N(Xiβ, 1/λi)I(−∞, 0) when yi = 0.
For example, Chang et al. (2006) consider binary mastistis data in cattle,
and argue that replacing a Gaussian model for the underlying liabilities with
a heavy-tailed distribution for the underlying liabilities is expected to lead to
more robust inferences. As well as a gamma density for λi, they consider a
slash density, p(λi|ν) = νλν−1
i
. Skew densities for ε in Equation 5.6 have also
been proposed. Thus, Bazan et al. (2006) mention a skew-probit link with
augmentation scheme,
y∗
i = Xiβ + εi,
εi = σ[−δVi −(1 −δ2)Wi],
(5.7)

Regression Techniques Using Hierarchical Priors
217
where Vi is half normal Vi ∼HN(0, 1), Wi ∼N(0, 1), δ ∼U(−1, 1), and σ = 1
for identiﬁability. In hierarchical form, one has,
y∗
i ∼N(Xiβ −δVi, 1 −δ2).
Taking ε to be logistic, a logit regression is obtainable (e.g., Kinney and
Dunson, 2007), by the augmentation scheme,
y∗
i ∼logistic(Xiβ, 1)I(0, ∞) when yi = 1,
y∗
i ∼logistic(Xiβ, 1)I(−∞, 0) when yi = 0,
where y ∼logistic(µ, τ), when,
p(y|τ, µ) = τ exp(τ[y −µ])/{1 + exp(τ[y −µ])}2,
with variance κ2/τ2, where κ2 = π2/3.
Several other approaches to generate the latent data underlying logit choice
model have been suggested. Thus, the logit link can be obtained approximately
by Student t sampling when ν = 8, or equivalently by scale mixture normal
sampling with λi ∼Ga(ν/2, ν/2) (Albert and Chib, 1993), combined with
constrained sampling according to the observed y values. Speciﬁcally, a t8
variable is approximately 0.634 times a logistic variable, so that,
y∗
i ∼t8

Xiβ,
1
0.6342

I(0, ∞) when yi = 1,
y∗
i ∼t8

Xiβ,
1
0.6342

I(−∞, 0) when yi = 0.
Equivalently with λi ∼Ga(4, 4),
y∗
i ∼N

Xiβ,
1
λi(0.634)2

I(0, ∞) when yi = 1,
y∗
i ∼N

Xiβ,
1
λi(0.634)2

I(−∞, 0) when yi = 0.
Kinney and Dunson (2007) mention a slightly diﬀerent approximation
whereby a t7.3 variable is approximately 0.647 times a logistic variable. So
with λi ∼Ga(ν/2, ν/2), where ν = 7.3, and σ2 = π2(ν −2)/3ν,
y∗
i ∼N

Xiβ, σ2/λi

I(0, ∞) when yi = 1,
y∗
i ∼N

Xiβ, σ2/λi

I(−∞, 0) when yi = 0.
Logit models relate responses yi = 0 or 1 to predictors Xi through pro-
portional exponential functions of regressors,
Pr(yi = k) ∝exp{ηk(Xi, β)}

218
Applied Bayesian Hierarchical Methods
where ηk is a linear or nonlinear function. With ηk(Xiβ) = Xiβ, a latent
exponential variable version (Scott, 2003) of the logit link involves sampling
{z0i, z1i} from exponential densities E(λ), with parameters λ0i = 1 and λ1i =
exp(Xiβ). If yi = argmin(z0i, z1i), then Pr(yi = k|Xi) ∝λki as under a
logit regression3. This principle extends to multiple logit regression with J
categories, implemented by sampling {z0i, z1i, . . . , zJ−1,i}.
In related work, Fruhwirth-Schnatter and Fruhwirth (2007) implement
augmented data sampling for the logit model by using a discrete mixture
approximation of the type 1 extreme value error in the McFadden (1974) for-
mulation of the logit model. Thus with U0i and U1i as utilities of category 0
and 1, and
U1i = Xiβ + εi,
the binary logit is obtained when U0i and εi follow type 1 extreme value
distributions. Using the relation between the exponential and type 1 extreme
distributions, and with νi = exp(Xiβ), one has,
exp(−U0i) ∼E(1), exp(−U1i) ∼E(νi),
with the minimum of these variables also exponential,
min[exp(−U0i), exp(−U1i)] ∼E(1 + νi).
(5.8)
When yi = 1, one has U1i > U0i, or equivalently exp(−U1i) < −exp(−U0i),
so that from Equation 5.8,
exp(−U1i) ∼E(1 + νi).
When yi = 0, one has U0i > U1i, or equivalently exp(−U0i) < −exp(−U1i),
so that,
exp(−U0i) ∼E(1 + νi),
exp(−U1i) = exp(−U0i) + δi,
where,
δi ∼E(νi).
A useful diagnostic feature resulting from the latent response approach is
that the residuals, y∗
i −Xiβ, are nominally a random sample from the assumed
cumulative distribution for ε (Johnson and Albert, 1999). So for the latent data
probit, the residual, εi = y∗
i −Xiβ, is approximately N(0, 1) if the model is
appropriate for case i, whereas if the posterior distribution of εi is signiﬁcantly
diﬀerent from N(0, 1), then the model conﬂicts with the observed y. So one
might obtain the probability Pr(|εi| > 2|y) and compare it to its prior value,
which is 0.045. For the latent data logit, one may obtain Pr(|εi|/κ > 2|y),
while for the logistic approximation, one monitors Pr(|εi|λi > 2|y).

Regression Techniques Using Hierarchical Priors
219
5.3.1
Augmentation for ordinal responses
Suppose that the categorical response, yi, has J categories, with the observa-
tions measuring a latent response, y∗, according to the model,
yi = j if αj−1 ≤y∗
i < αj.
The αj are cut points dividing the values of y∗according to the observed
y values. The model in the latent data (e.g., Spiess, 2006) is then,
y∗
i = Xiβj + εji,
where εji is usually either normally or logistically distributed. So P(ε) =
Φ(ε), where Φ is the cumulative normal function, or P(ε) = 1/(1 + exp(−ε)).
The corresponding model for cumulative probabilities is
Pr(y∗
i ≤αj) = Pr(Xiβj + εji ≤αj),
= Pr(εji ≤αj −Xiβj).
Thus,
Pr(y∗
i ≤αj) = Φ(αj −Xiβj),
or
Pr(y∗
i ≤αj) = 1/(1 + exp(−[αj −Xiβj])),
according to the assumed form for εji. Let γji = Pr(y∗
i ≤αj), then,
Pr(yi = j) = Pr(αj−1 ≤y∗
i < αj) = γji −γj−1,i.
The probability that yi = 1, namely,
Pr(yi = 1) = Pr(α0 ≤y∗
i < α1) = γ1i,
is obtained by setting α0 = −∞, while the probability that yi = J, namely,
Pr(yi = J) = Pr(αj−1 ≤y∗
i < αJ) = 1 −γJ−1,i,
is obtained by setting αJ = ∞.
Assuming Xi excludes an intercept, the remaining J −1 cut points
{α1, α2, . . . , αJ−1} are unknowns subject to an order constrained prior α1 ≤
α2 ≤· · · ≤αJ−1. By reparameterization,
αj = αj−1 + exp(∆j)
(J > j > 1),
α1 = ∆1,
one may, however, specify unconstrained normal priors such as ∆j ∽N(0, V∆),
where V∆is preset or possibly itself unknown.

220
Applied Bayesian Hierarchical Methods
An equivalent speciﬁcation of this model involves sets of J −1 binary
variables for each subject, namely, zji = 1 if yi ≤j, and zji = 0 otherwise
(e.g., Parsons et al., 2006, 512). So if J = 3, and if yi = 1, then z1i = 1,
z2i = 1; if y = 2, then z1i = 0, z2i = 1. So for ε normal,
Pr(yi ≤j) = Pr(y∗
i ≤αj) = Pr(zji = 1) = Φ(αj −Xiβj).
Example 5.3. Irish Education Attainment
This example involves a
probit regression model for education data from Raftery and Hout (1993)
relating to n = 500 Irish school pupils. A binary leaving certiﬁcate indicator
is the response variable and explanatory variables are the Student’s Verbal
Reasoning Test Score, the Student’s sex (1 = female, 0 = male), and father’s
occupational status. The third covariate has some missing values that are
treated as missing at random.
To account for possible skewness in residuals the approach of Bazan et al.
(2005) is applied, as in Equation 5.7, but modiﬁed to include a model selection
indicator applied to the skewness parameter δ. Thus4,
y∗
i ∼N

µi,
!
1 −k2
δ δ2"
I(Ai, Bi),
µi = Xiβ −kδδVi,
Vi ∼N(0, 1),
where the sampling intervals {Ai, Bi} depend on the observed leaving certiﬁ-
cate indicator, y. A uniform prior is adopted for the skew parameter δ, namely,
δ ∼U(−1, 1). The binary selection indicator has prior kδ ∼Bern(πδ), where
πδ = 0.5.
With inferences from iterations 5001 to 25,000 of a two chain run, all three
predictors emerge as signiﬁcant with means and 95% intervals of 0.034 (0.022,
0.044), 0.29 (0.05, 0.53), and 0.022 (0.013, 0.031). The posterior probability
that kδ = 1 is 0.44, compared to a prior probability of 0.5, so no signiﬁcant
residual skew seems present.
Example 5.4. Delegation of Discretion in Trade Policy
Epstein and
O’Halloran (1996, 388) apply an ordered probit model to analyze changes in
discretion in trade policy delegated to the US President by Congress between
1890 and 1990 (giving T = 99 observations). The response has J = 3 cate-
gories: 3 if the President’s discretion is increased between successive years, 2
if it stays the same, and 1 if it is reduced. They relate changes in discretion to
p = 4 predictors, namely, changes in log gross national product (x1), changes
in the log unemployment rate (x2), changes in the log of the producer price
index (x3), and to a variable measuring changes in government disunity (x4),
where disunity in a particular year is measured by a trichotomy according to
whether one or both chambers of Congress are in the same political party as
the President. So x4 can take values {−2, −1, 0, 1, 2}.
Following Epstein and O’Halloran, a proportional odds model5 over
responses j is assumed, namely, βjk = βk (k = 1, . . . , p). Order constrained

Regression Techniques Using Hierarchical Priors
221
N(0, 1) priors are assumed on the unknown cut points {α1, α2 ˙} and a mul-
tivariate normal (MVN) prior on {β1, . . . , β4} with mean zero and diagonal
precision matrix B0, with prior variances of 1000.
A two chain run of 5000 iterations (with the last 4000 for inference) gives a
nonsigniﬁcant posterior mean (95% CI) for the impact β1 of x1, namely, of 0.96
(−5.0, 7.1). The 95% intervals for the impacts of x2 and x3 are inconclusive,
though the posterior densities are biased to negative values. β4 has mean −0.42
(−0.82, −0.03), an estimate similar to the maximum likelihood estimate of
−0.46 reported by Epstein and O’Halloran. The percentage of years accurately
predicted by replicate responses is 62.6%. Similar coeﬃcients are obtained
from an augmented data approach5 involving binary responses, ztj = 1 if
yt ≤j, and ztj = 0 otherwise.
5.4
Nonconstant Regression Relationships
and Variance Heterogeneity
The canonical form of the linear normal regression model assumes constant
regression relationships and a constant residual variance over all units. How-
ever, heteroskedasticity and varying regression eﬀects over sample subsets are
well-known problems in the regression literature. Apparent heteroscedasticity
in residuals may in fact be due to varying eﬀects of predictors: consider a
linear model speciﬁed as yi = xiβ + wiγ + vi, when in fact the true model is
yi = xiβ + wi(γµ + ci) + ui with Var(ci) = σ2
c and Var(ui) = σ2
u. The error vi
will then have nonconstant variance, w2
i σ2
c + σ2
u. In many applications, het-
eroscedasticity is apparent also in increasing dispersion of the residuals at
higher ﬁtted values. Nonconstant variance may be reduced or eliminated by
making the variance a function of the predictors themselves, or by outcome
and predictor term transform (Carroll and Ruppert, 1984). Both options may
be combined with modeling of the variance.
Carroll and Ruppert (1982) consider the heteroscedastic linear model,
yi = ηi + σizi,
with ηi = Xiβ, z a zero mean symmetric density with known variance (e.g.,
normal with variance 1), and σi a possibly nonlinear function of ηi or Xi.
Possibilities might be simply σi = exp(Xiγ), or σ2
i = exp(Xiγ) as in Cepeda
and Gamerman (2000), where γ includes an intercept. This may be modiﬁed
to σi = exp(Wiγ), where Wi may contain some or all of the variables in Xi.
Alternatively, separate variance parameters may be speciﬁed, as in the forms,
σi = σ|ηi|λ,
σi = σ

1 + λη2
i
0.5 .

222
Applied Bayesian Hierarchical Methods
The approach of Geweke (1993) involving a scale mixture distribution for
regression errors can be used to deal with heteroscedasticity as well as with
outliers; see also Fonseca et al. (2008). The class of scale mixtures of normals
accommodates a wide variety of heavy-tailed distributions, as demonstrated
by Fernandez and Steele (2000). In the linear model, yi = ηi + σεi, a scale
mixture is generated by assuming the residuals are distributed as,
εi = zi/λ0.5
i
,
where zi are N(0, 1), and λi are independent positive random variables. The
tν distribution can be interpreted as a scale mixture of normal distributions by
taking λi to be gamma with scale and shape ν/2, with the Cauchy obtained by
taking ν = 1. Fonseca et al. (2008) consider alternative priors for ν, including
the Jeﬀreys prior.
In a related approach, Qin et al. (2000) consider variance regression in-
volving a scale mixture of uniforms. They show that yi ∼N(µi, σ2/λ) is
equivalent to,
yi|hi ∼U

µi −σ
)
hi, µi + σ
)
hi

,
hi ∼Ga(1.5, λ/2),
with hi ∼Ga(1.5, 0.5) leading to the baseline normal yi ∼N(µi, σ2). Taking,
hi ∼Ga(3λ/2, λ/2),
leads to alternative forms of kurtosis, namely, lighter tails than normal under
λ > 1, and heavier tails than normal under 1 > λ > 0. Variance regression
may be achieved by the parameterization,
yi|hi ∼U

µi −
√hi
Pi
, µi +
√hi
Pi

,
Pi =
K
k=0
γwki
k ,
where w0i = 1, Wi = (1, w1i, . . . , wKi) are positive covariates inﬂuencing the
variance, and γk are positive coeﬃcients. For example, one may adopt gamma
priors, γk ∼Ga(ak, ak), with ak small.
5.5
Heterogenous Regression and Discrete
Mixture Regressions
Heterogeneity in regression relationships is also a familiar question considered
under Bayesian random eﬀects perspectives (e.g., Smith, 1973a), following on
earlier classical work (e.g., Hildreth and Houck, 1968). Thus, for a normal

Regression Techniques Using Hierarchical Priors
223
linear regression and R predictors, xri, apart from the intercept, a random
regression eﬀects model speciﬁes,
yi = α +
R

r=1
xri(βr + vri) + ui,
where {v1i, . . . , vRi} are independent or jointly dependent zero mean random
eﬀects. This approach is relevant to exchangeable, non-nested responses with
metric predictors. Exchangeable random priors for eﬀects of categorical pre-
dictors, xri, as opposed to metric ones, have been employed in log-linear model
and analysis of variance applications. Smith (1973b) considers an analysis of
variance application—see McCarthy (2007) for a recent discussion of random
factors in analysis of variance—while Albert (1996b, 331) uses exchangeable
random eﬀect priors for interaction parameters in log-linear models.
A hierarchical regression approach especially relevant for metric predictors
involves the Gaussian process, whereby for a metric response y = (y1, . . . , yn)′,
and predictor matrix F = (1, X) of dimension n×(1+R), one has (Gramacy,
2007; Gramacy and Lee, 2008),
y ∼Nn(Fβ, σ2H),
β ∼NR+1(B, V ),
Hij = Kij + γI(i = j),
and the correlation matrix Kij between observations i and j is deﬁned in
geostatistical terms (see Chapter 4) by distance functions |xi−xj| involving the
R predictors, excluding the intercept6. For example, a separable exponential
power function speciﬁes,
Kij = exp

−
R

r=1
(xri −xrj)pr

dr

,
where dr is a range parameter, and 0 < pr ≤2.
Variation in regression regimes between groups of observations is often
approached using discrete regression mixtures (Section 5.5.1), while randomly
varying regression eﬀects applied to structured data (such as time series or
spatially conﬁgured data) have received considerable attention also (see Sec-
tions 5.7 and 5.9).
5.5.1
Discrete mixture regressions
Discrete mixtures of regressions take the form,
p(yi|x1i, . . . , xRi) =
K

k=1
πkfk(Xi, βk, φk),

224
Applied Bayesian Hierarchical Methods
where βk denote component regression eﬀects and φk any other parameters
involved in deﬁning densities fk. They have found wide application, with
Bayesian applications increasing with the advent of MCMC. An early example
is the work on switching regression in time series by Goldfeld and Quandt
(1975), with more recent applications including neural computing (Peng et al.,
1996), marketing (Andrews and Currim, 2003), and health research (Yau et al.,
2003). Examples of discrete mixture regressions include normal regression mix-
tures (Viele and Tong, 2002),
p(yi|x1i, . . . , xRi) =
K

k=1
πkN

αk +
R

r=1
xriβrk, σ2
k

,
Poisson regression mixtures (Wedel et al., 1993),
p(yi|x1i, . . . , xRi) =
K

k=1
πkPo

exp

αk +
R

r=1
xriβrk

,
and logit regression mixtures (Hurn et al., 2003) for binary or binomial data,
p(yi|x1i, . . . , xRi) =
K

k=1
πkBern


exp

αk + R
r=1 xriβrk

1 + exp

αk + R
r=1 xriβrk


.
The probabilities, πk, for the components may be predicted for each in-
dividual via regression (e.g., logit) also. In Bayesian applications, MCMC
sampling is facilitated by the introduction of latent allocation indicators,
Si ∈(1, . . . , K), for each case, which are sampled at each iteration from case-
speciﬁc multinomial full conditionals,
πkfk(Xi, βk, φk)
 K

k=1
πkfk(Xi, βk, φk).
Discrete regression mixtures are useful for detecting subpopulations with
diﬀerent behaviors, while accounting for excess heterogeneity in part related
to varying regression relationships (Wedel et al., 1993). They are also advo-
cated as a natural solution to masked outliers, with one widely reproduced
scenario (Rousseeuw, 1984) involving one subpopulation where a genuine re-
gression exists, but another with (yi, Xi) uncorrelated. A simple discrete mix-
ture underlies the outlier accommodation method of Verdinelli and Wasserman
(1991), which takes the form for normal data,
p(yi|x1i, . . . , xRi) =
2

k=1
πkN

α +
R

r=1
xriβr, σ2
k

,
where σ2
2 ≫σ2
1, and π2 is taken small (e.g., π2 = 0.05). This provides the scale
contamination or variance-inﬂation mechanism for regression outliers, where
outliers come from a normal distribution with the same mean as the remaining
cases, but a higher variance. The Huber-M estimate when applied to normal

Regression Techniques Using Hierarchical Priors
225
regression is also expressible as a discrete mixture (Rice and Spiegelhalter,
2006). Viele and Tong (2002) argue that a full discrete mixture (including
component varying regression eﬀects) is more suitable to identify masked out-
liers, while Mohr (2007) regards the variance-inﬂation mechanism as better
suited to modeling scattered outliers rather than outlier clusters.
Mohr (2007, 3958) advocates a two group model allowing for both clus-
tered outliers (with clustering deﬁned by similar values on predictors) and for
scattered outliers, generated by a variance inﬂation mechanism. Thus, allo-
cation indicators, S1i, are used to identify cluster outliers (in group 1) with
probability,
Pr(S1i = 1) = κ1 exp[−κ2(X∗
i −ψ)′(X∗
i −ψ)],
(5.9a)
where X∗
i is a subset of the full predictors (excluding the intercept), ψ is the
group 1 mean on X∗, 0 ≤κ1 ≤1, and κ2 > 0. For a normal regression, cases
in group 1 have density,
yi|S1i = 1 ∼N(Xiβ1, 1/τ1).
For cases not classiﬁed in the clustered outlier group, it is still possible to
be a scattered outlier. So for the (majority of) cases with S1i = 0, a second
allocation indicator, S2i ∼Bern(π), has a value of 1 for scattered outliers,
but is 0 for the main set of cases. For a normal regression, such cases have
density,
yi|S1i = 0 ∼(1 −π)N(Xiβ2, 1/τ2) + πN(Xiβ2, D/τ2),
(5.9b)
where D ≫1. The binary pair (S1i, S2i) can be replaced by a trinomial (see
Example 5.6).
Certain identiﬁcation and estimation issues apply to discrete regression
mixtures, and a variety of sampling and post-processing methods, and pri-
ors to gain or improve identiﬁability, have been proposed. Firstly, improper
priors are not suitable as they result in an improper posterior (Diebolt and
Robert, 1994). Even with proper priors, a major issue revolves around compo-
nent labeling, since diﬀerent component labels cannot be distinguished during
MCMC sampling unless some identiﬁability constraint is imposed a priori.
Another issue involves small components (those with relatively low probabil-
ities πk), especially when combined with small samples (Wasserman, 2000),
since at particular MCMC samples, no cases may be allocated to a partic-
ular group, k∗, so that the associated parameters are not updated. To deal
with this problem, Viele and Tong (2002, 320) suggest Metropolis sampling
of (β, σ2, π) without introducing latent allocation indicators.
Sampling and estimation methods for discrete regression mixtures diﬀer
in whether they impose identifying constraints or allow switching between
diﬀerent numbers of components. Hurn et al. (2003) exemplify approaches that
exclude identifying constraints on parameters, but rely on post-processing to
identify clusters; they also employ a birth–death process to switch between
diﬀerent numbers of components K.

226
Applied Bayesian Hierarchical Methods
By contrast, Viele and Tong (2002, 317) advocate identifying restrictions in
linear regression mixtures, for example on the variances of components, σ2
1 <
σ2
2 < · · · < σ2
K. Ordering of variances may work better when the variances
are well separated, whereas ordering of particular regression parameters works
well when subpopulations are distinct in substantive terms. Similarly, Geweke
and Keane (2000) consider a data augmented probit regression mixture and
impose identiﬁability either by ordered regression intercepts, αk−1 < αk, or by
ordered precisions, τk−1 < τk, with the latter option including the constraint
that τk∗= 1 for some k
∗∈(1, . . . , K). A ﬂexible error structure is then
achieved with,
p(y∗
i |x1i, . . . , xRi) =
K

k=1
πkN

αk +
R

r=1
xriβr, 1

τk

,
with straightforward extension to component-speciﬁc regression. Sampling
of y∗
i is truncated to negative or positive values according to the observed
binary response, yi.
5.5.2
Zero-inﬂated mixture regression
Zero-inﬂated regression is a form of mixture regression applied to overdis-
persed or underdispersed data from Poisson, binomial, or negative binomial
densities. For example, Poisson overdispersion may result from an excess num-
ber of zero counts, and this form of overdispersion occurs in applications in
veterinary science (Rodrigues-Motta et al., 2007), sociology (MacAdam and
Su, 2002), and quality control (Lambert, 1992). Under a zero inﬂated Poisson
(ZIP) model, zero counts may result from either of two mechanisms: they may
be true zeroes, as in quiescent periods for war protests (MacAdam and Su,
2002), or result from a stochastic mechanism, when the process is “active” but
sometimes produces zero events. A distinction is therefore often made between
structural and random zeroes (Martin et al., 2005).
The “active” stochastic mechanism, f(y), may be described by any discrete
density (Poisson, generalized Poisson, negative binomial, binomial, etc.). Let
di = 1 for true zeroes as against stochastic zeroes when di = 0, with Pr(di =
1) = ω. The inﬂation to the zero counts occurs under the degenerate option.
Then,
P(yi = 0) = Pr(di = 1) + f(yi = 0|di = 0)Pr(di = 0)
P(yi = j) = f(yi = j|di = 0)Pr(di = 0)
j = 1, 2, . . . ,
Regressors Xi may be relevant both to the binary inﬂation mechanism,
and to the parameters deﬁning the density f(yi = j) of the count data, such
as a Poisson or negative binomial (Czado et al., 2007; Hall, 2000). So, under
a zero-inﬂated Poisson regression, one might adopt a logit regression for the
inﬂation process with,

Regression Techniques Using Hierarchical Priors
227
ωi = Pr(di = 1|Xi) =
exp(Xiγ)
1 + exp(Xiγ),
and a log link model, µi = exp(Xiβ), for the Poisson mean in f(yi = j|Xi,
di = 0). The full ZIP model is
P(yi = 0|Xi) = ωi + (1 −ωi)e−µi,
P(yi = j|Xi) = (1 −ωi)e−µiµyi
i /yi!
j = 1, 2, . . . ,
with variance then,
Var(yi|ωi, µi) = (1 −ωi)
!
µi + ωiµ2
i
"
> µi(1 −ωi) = E(y|ωi, µi).
So modeling of excess zeros implies overdispersion. A useful representation
for programming the zero-inﬂated Poisson involves the mixed scheme (Ghosh
et al., 2006),
wi ∼dbern(ω),
yi ∼Po(µi(1 −wi)).
The zero adjustment approach is also applicable to underdispersion (Ghosh
and Kim, 2007). Czado et al. (2007) and Angers and Biswas (2003) consider
Bayesian approaches to zero adjusted modeling using the generalized Poisson
density (GPD), namely,
P(yi|Xi) =

µi
1 + αµi
yi (1 + αyi)yi−1
yi!
exp

−µi(1 + αyi)
1 + αµi

,
(5.10)
which implies overdispersion for α > 0, and underdispersion for α < 0.
A maximum likelihood GDP approach with adjustment for excess zeroes
is considered by Bae et al. (2005), including a generalization to Poisson k-
inﬂation (e.g., too many cases with yi = 1 as compared to the Poisson if
k = 1). For f a generalized Poisson (or any other relevant discrete density),
the k-inﬂated model has the form,
P(yi = k|Xi) = ωi + (1 −ωi)f(k; µi, α),
P(yi = j|Xi) = (1 −ωi)f(j; µi, α)
j ̸= k.
Example 5.5. Radioimmunoassay and Esterase
This example com-
pares three heteroscedastic models for continuous radioimmunoassay obser-
vations (y) in relation to a single predictor, namely, esterase (x), as in Carroll
and Ruppert (1982). A randomly varying coeﬃcient model is also considered.
Fit is based on sampling replicate data, with ﬁt and penalty criteria derived
as in Gelfand and Ghosh (1998).
So with,
yi = ηi = β0 + β1xi + σizi,

228
Applied Bayesian Hierarchical Methods
the ﬁrst model is a variance regression model with,
σ2
i = exp(γ0 + γ1xi).
This yields a signiﬁcant parameter, γ1, with mean (95% interval) of
0.068 (0.044, 0.094), and such a signiﬁcant relationship between the variance
and predictor supports heteroscedasticity, whereas homoscedastic regression
requires predictor eﬀects on the variance to be nonsigniﬁcant. The penalty
criterion, CP (obtained by summing the posterior variances of replicates), is
1.42E + 06, while the predictive ﬁt criterion, obtained as the posterior mean
of (yi −yrep,i)2, is CF = 2.63E + 06.
The variance model used by Carroll and Ruppert (1982) is a power model
in the absolute linear predictor, namely,
σi = σ(1 + |ηi|)λ.
This is applied7 with a U(−2, 2) prior on λ, and with a U(0, 250) prior
on σ, which includes the observed standard deviation of 213. This gives an
estimate (from OpenBUGS) for λ = 0.63(0.41, 0.85), and provides improved
ﬁt criteria (CP, CF) = (1.24E + 06, 2.44E + 06).
A Student t with ν degrees of freedom via normal scale mixing (centered on
a single variance parameter σ2) is then applied. A U(0.01, 1) prior is applied
on the inverse of the degrees of freedom 1/ν. This shows 17 data points with
scale factors λi below 0.5, and ν estimated at 2.8. Although such estimates
clearly show non-normality, the ﬁt criteria deteriorate to (CP, CF) = (1.72E +
06, 2.94E + 06).
Finally, a random regression coeﬃcient model is applied, with a variance
regression model additionally retained to see whether heteroscedasticity is
reduced or eliminated. So,
yi = α + βixi + σizi,
σ2
i = exp(γ0 + γ1xi),
βi ∼N(µβ, σ2
β),
with priors,
log(σb) ∼N(0, 1); µβ ∼N(0, 1000).
Two chains are run, with initial values for log(σb) of 1 and 2.
The second half of a run of 100,000 iterations shows a mean (95% interval)
for log(σb) of 1.58 (0.13, 1.80), with γ1 now having a 95% interval (−1.25,
0.55) straddling zero. The posterior means of the βi range from 6.7 to 38, but
with mean 17.1 close to that under other models. A histogram of the posterior
mean βi (in Figure 5.1, including a superimposed normal) shows more kurtosis
than under a normal, with a few extreme highly positive coeﬃcients. The ﬁt
criteria are markedly improved with (CP, CF) = (150620, 154600).

Regression Techniques Using Hierarchical Priors
229
0
0.05
0.1
Density
0
10
20
30
40
Coefficient
FIGURE 5.1
Varying esterase coeﬃcients.
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
x
y
FIGURE 5.2
Clustered outliers.
Example 5.6. Clustered Outlier Data
This example considers discrete
mixture regression applied to simulated data that follow the scenario of
Rousseeuw (1984). Thus, the ﬁrst 30 points (the “main regression compo-
nent”) are generated as yi = 2 + xi + ui, where ui have standard devia-
tion 0.2, while for cases 31–50, the bivariate pair (xi, yi), deﬁning the “masked
outlier component,” are generated from a bivariate normal with mean (7,2)
and diagonal covariance with diagonal terms 0.25—see Figure 5.2. To estimate
the underlying mixture, the Mohr (2007) method is used, as in Equation 5.9,
except that the cluster deﬁnition prior for the probability of belonging to
group 1 (the masked outlier group) is simpliﬁed to,
Pr(S1i = 1) = exp[−κ(xi −ψ)′(xi −ψ)] = exp(−hi),

230
Applied Bayesian Hierarchical Methods
where the group 1 regression is
yi|S1i = 1 ∼N(Xiβ1, 1/τ1),
where Xi = (1, xi) includes an intercept. A value of 10 is taken for the variance
inﬂation factor D in the mixture prior for the main observation group,
yi ∼(1 −π)N(Xiβ2, 1/τ2) + πN(Xiβ2, D/τ2).
Then the three possible groups have probabilities {e−hi, (1 −π)(1 −e−hi),
π(1 −e−hi)}.
A Be(1, 9) prior on π favors low probabilities for scattered outliers, while an
informative U(0.04, 8.09) prior for the univariate cluster center, ψ, reﬂects the
range of the observed (here simulated) covariate xi. More diﬀuse priors on ψ
were accompanied by failure to locate the regression parameters in the main
regression component. A 10,000 iteration run8 then shows early convergence
with cases 1–30 having zero or eﬀectively zero probabilities of belonging to
group 1, deﬁned by a posterior mean of 7.27 for ψ. The posterior mean for π
is 0.067, with case 14 having a posterior probability of 0.47 of belonging to
the scattered outlier group, but all other cases having posterior probabilities
under 0.10 of being a scattered outlier.
Example 5.7. ZIP Regression for Decayed, Missing, and Filled Teeth
This example involves zero inﬂated regression analysis of counts of teeth de-
cayed, missing, or ﬁlled (DMFT) from Bohning et al. (1999). Thus, 797 Brazil-
ian children in six schools were subject to a dental health prevention trial; the
school is in fact equivalent to a health prevention treatment type. The vari-
ables are as follows:
1. DMFT1—DMFT before intervention
2. DMFT2—DMFT at end of study
3. Gender (0—female ; 1—male )
4. Ethnicity: 1—dark ; 2—white ; 3—black )
5. School (kind of prevention):
1—oral health education; 2—all four methods together;
3—control school; 4—enriched diet with ricebran;
5—mouthrinse with 0.2% NaF-solution; 6—oral hygiene.
The response yi is DMFT2, with baseline DMFT scores included as a
measure of severity of dental problems, and with school 3 as the reference
prevention treatment.
As above, the model is
P(yi = 0) = ω + f(yi = 0|di = 0)(1 −ω),
P(yi = j) = f(yi = j|di = 0)(1 −ω),
j = 1, 2, . . .

Regression Techniques Using Hierarchical Priors
231
where f(yi = j|di = 0) is a Poisson likelihood with mean µi, and where log(µi)
is modeled as a function of gender, ethnicity, and school. Since the model is
Poisson,
f(yi = 0|di = 0) = exp(−µi).
One way of estimating the ZIP model involves a marginal rather than
complete data likelihood, with WinBUGS coded for a nonstandard density9.
A two chain run of 5000 iterations (convergent after 500) gives an estimate
for ω of 0.047, and insigniﬁcant regression coeﬃcients except for negative
eﬀects of schools (i.e., treatment types) 1, 2, and 5. The posterior means (sd)
of the relevant coeﬃcients are −0.24 (0.09), −0.33 (0.10), and −0.25 (0.08).
A pseudo marginal likelihood estimate of −1243 is obtained from the posterior
means of the inverse likelihoods. An alternative estimation method based on
the mixed Poisson scheme of Ghosh et al. (2006) yields the same estimate
of ω, and the same pattern of signiﬁcant school eﬀects.
For illustrative purposes, the zero inﬂated version of the generalized
Poisson density,
P(yi|Xi) =

µi
1 + αµi
yi (1 + αyi)yi−1
yi!
exp

−µi(1 + αyi)
1 + αµi

,
is also applied. A gamma prior is adopted on the overdispersion parameter,
namely, α ∼Ga(1, 0.01). This model produces an improved pseudo marginal
likelihood of −1229, with a lower posterior mean for ω of 0.017, but a posterior
density for α, which is not clearly bounded away from zero—there is a spike
at zero.
5.6
Time Series Regression: Correlated Errors
and Time-Varying Regression Eﬀects
The generalized linear model framework of Section 5.1 applies to time series
regressions where responses may be binary, counts, or metric. Such time series
regression may be characterized by serial correlation in regression residu-
als, overdispersion, or time-varying regression coeﬃcients (Jung et al., 2006;
Kedem and Fokianos, 2002). There may also be lagged dependence on ob-
served or latent responses, or on predictors, with such dependence varying
over time (Kitagawa and Gersch, 1985; Nicholls and Quinn, 1982). An au-
toregressive distributed lag or ADL(p, q) regression includes lagged eﬀects
{yt−1, . . . , yt−p; Xt−1, . . . , Xt−q} in both predictors and responses (Bauwens
et al., 1999, 136).
If autocorrelation in the regression errors is suspected or postulated, as
opposed to dependence on past responses or latent data, one option is param-
eter driven or latent process time series models involving autoregressive and

232
Applied Bayesian Hierarchical Methods
moving average random eﬀects (Chiogna and Gaetan, 2002; Cox, 1981). For y
metric, with,
yt = Xtβ + εt,
t = 1, . . . , T,
where Xt is of dimension R, an ARMA(p, q) error scheme speciﬁes (Chib and
Greenberg, 1994)
εt −ρ1εt−1 −ρ2εt−2 · · · −ρpεt−p = ut −θ1ut−1 −θ2ut−2 · · · −θqut−q,
or ρp(L)εt = θq(L)ut, where ut ∼N(0, σ2) are white noise errors.
For the normal linear regression case, yt = Xtβ + εt, where Xt does not
include lagged y values, Chib (1993) sets out Gibbs sampling for the AR(p)
error model,
ρp(L)εt = ut,
with ρ(L) = 1 −ρ1L −ρ2L2 · · · −ρpLp. Assume conditioning on the initial p
observations and priors,
σ2 ∼IG

ν0
2 , δ0
2

, ρ ∼Np

ρ0, R−1
0

, β|σ2 ∼N

β0, σ2B−1
0

.
Also, restate the model as ρ(L)yt = ρ(L)Xtβ + ut or equivalently as y∗
t =
X∗
t β + ut, where y∗
t = ρ(L)yt, and X∗
t = ρ(L)Xt. Finally, restate the error
scheme, εt = ρ1εt−1 + ρ2εt−2 + · · · + ρpεt−p + ut, as ε = Eρ + u, where E is a
(T −p) × p matrix with tth row (εt−1, . . . , εt−p). Then with τ = σ−2, the full
conditionals for the unknowns are
β|σ2, ρ ∼Nk(˜β, σ2 ˜B−1);
σ2|β, ρ ∼IG

n −p + ν0 + k
2
, δ0 + Qβ + dβ
2

;
ρ|β, σ2 ∼Np

˜R−1[R0ρ0 + τE′ε]−1, ˜R−1
,
where ˜β = (B0 + X∗′X∗)−1(B0β0 + X∗y∗), ˜B = (B0 + X∗′X∗), Qβ = (β −
β0)′B0(β −β0), dβ = (y∗−X∗β)′(y∗−X∗β), and ˜R = (R0 + τE′E). The
prior and posterior for ρ can be constrained to a stationary region, though
Chib (1993) suggests unconstrained sampling with draws in the nonstationary
region rejected.
Widely applied options in practice for ARMA error dependence in time
series models for metric and discrete data are the simple AR(1) and MA(1)
schemes. The AR(1) model with,
εt = ρεt−1 + ut,
(5.11a)
where ut ∼N(0, σ2) are unstructured and independent of εt, is an eﬀective
scheme for controlling for temporal error dependence if (as often) most cor-
relation from previous errors is transmitted through the impact of εt−1. This

Regression Techniques Using Hierarchical Priors
233
assumption is widely used in longitudinal models (e.g., Chi and Reinsel, 1989).
As discussed in Chapter 4 whether the prior on ρ speciﬁes stationarity is a cen-
tral feature; for example, Palmer and Pettitt (1996) discuss the requirement
for an informative prior on the regression intercept in an AR(1) error model
for a metric response, since in or near the unit root case (ρ = 1) the intercept
is not deﬁned. With σ2
ε = Var(εt), assuming stationarity with |ρ| < 1, AR(1)
error dependence means,
Var(εt) = ρ2Var(εt−1) + σ2 + 2ρcov(εt−1, ut) = ρ2σ2
ε + σ2,
so that σ2
ε = σ2/(1 −ρ2), and the initial condition for the stationary case is
ε1 ∽N

0,
σ2
1 −ρ2

.
(5.11b)
Also cov(εt, εt−1) = ρE(ε2
t−1) + E(εt−1, ut) = ρσ2
ε and cov(εt, εt−k) =
ρkρσ2
ε = ρkσ2/(1 −ρ2).
AR(1) error dependence for nonmetric responses is illustrated by the
Poisson count outcomes case, yt ∽Po(µt), with (Chan and Ledolter, 1995;
Nelson and Leroux, 2006),
log(µt) = Xtβ + εt,
εt = ρεt−1 + ut,
while the MA(1) error model (Baltagi and Li, 1995) speciﬁes εt = ut −θut−1.
Bayesian analysis of AR(1) errors for count data is exempliﬁed by Oh and Lim
(2001) and Jung et al. (2006), who also consider augmented data sampling for
count responses, while Chen and Ibrahim (2000) set out sampling algorithms
under a power prior approach (that assumes historic data with the same form
of design are available).
The Durbin–Watson statistic for AR(1) error dependence, namely,
DW =
(εt −εt−1)2
 ε2
t
= 2 −2
(εt −εt−1)
 ε2
t
 ε2
t−1
= 2 −2ρ,
is often used to test temporal autocorrelation (when predictors exclude lagged
responses), and in a Bayesian context can be applied in a posterior predic-
tive check. For example, Spiegelhalter (1998, 126) considers Poisson time series
modeling of cancer cases, yijt, in age groups i = 1, . . . , I, districts j = 1, . . . , J,
and years t = 1, . . . , T, with µijt being model means. At each iteration,
deviance residuals, dijt = −2 log{p(yijt|µijt)}, are obtained, and an average
DW statistic derived for each age and district, namely,
DWij =
T
t=2(dijt −dij,t−1)2
T
t=1(dijt −dij.)2
.
A summary statistic for autocorrelation is then DW =   DWij/IJ,
which can be obtained for both actual and replicate data and the procedure
of Gelman et al. (1996) applied.

234
Applied Bayesian Hierarchical Methods
An alternative observation-driven approach to dependent errors is the
generalized ARMA(p, q) or GARMA(p, q) scheme for discrete outcomes
(Benjamin et al., 2003), based on re-expressing lagged residuals as diﬀerences
between previous responses and regression terms. For count data with Pois-
son means, µt, an AR(p) analog is
log(µt) = Xtβ + ρ1(log y∗
t−1 −Xt−1β) + ρ2(log y∗
t−2 −Xt−2β)
+ · · · + ρp(log y∗
t−p −Xt−pβ),
where lagged zero responses are handled by setting,
y∗
t−k = max(c, yt−k),
with c ∈(0, 1]. Moving average analogs in a GARMA model compare log y∗
t−j
with log µt−j, so a GARMA(0, 1) model would be
log(µt) = Xtβ + θ
!
log

y∗
t−1/µt−1
"
.
Davis et al. (2003) also compare previous responses with predictions via
an observation-driven approach, namely,
log(µt) = Xtβ + Zt = Xtβ +
∞

k=1
γket−k = Xtβ +
∞

k=1
γk

yt−k −µt−k
µλ
t−k

,
where λ ∈(0, 1]. The inﬁnite moving average can be represented in the form,
Zt = φ1(Zt−1 + et−1) + · · · + φp(Zt−p + et−p) + θ1et−1 + · · · + θqet−q,
with initial conditions Zt = et = 0 for t ≤0. So the choice (p = 1, q = 0) gives
Zt = φ(Zt−1 + et−1), while (p = 0, q = 1) gives Zt = θet−1.
The latent process driving autocorrelation may also be modeled using dis-
crete mixture formulations. For example, Wang and Puterman (1999a) de-
ﬁne Markov Poisson regression in which for each observed count, yt, there
corresponds an unobserved categorical variable, St ∈(1, . . . , K), representing
the state by which yt is generated. The latent states are generated according
to a stationary Markov chain with transition probabilities,
Pr(St = j|St−1 = k) = πjk
{j, k = 1, . . . , K}.
Conditional on St = j, the tth observation, yt, is Poisson with mean µt =
exp(Xtβj).
5.7
Time-Varying Regression Eﬀects
Autocorrelated or heteroscedastic disturbances in time series regression may
be caused by assuming the eﬀects of regressors are constant across time, when

Regression Techniques Using Hierarchical Priors
235
in fact they are time varying. For example, Beck (1983) mentions how the
ARCH model for volatility may be expressed as a varying regression impact.
Thus, with εt ∼N(0, 1),
yt = α + βxt + δthtxt + htεt = α + βtxt + htεt,
where
βt = β + δtht,
h2
t = a0 +
q

k=1
akε2
t−k.
Then, in periods when it is diﬃcult to predict yt (and so with larger ht),
the impact of x on y ﬂuctuates according to the direction of δt and size of ht.
Consider a dynamic linear model for metric responses with dim(Xt) = R,
yt = Xtβt + εt.
A simple way to allow coeﬃcient variation is to take,
βt = βµ + ut,
with ut taken as exchangeable random eﬀects, as in the random coeﬃcient
model of Swamy (1971). However, in time series contexts it is likely that
deviations from the central coeﬃcient eﬀect, βµ, will be correlated with nearby
deviations in time. A ﬂexible framework for time-varying parameter eﬀects is
provided by the linear Gaussian state–space model (West and Harrison, 1997,
73), involving ﬁrst order random walks in scalar or vector coeﬃcients, βt,
yt = Xtβt + εt
εt ∼NT (0, Σt)
βt = Gtβt−1 + ωt
ωt ∼NR(0, Vt).
Often, Gt = I, Σt = Σ, and Vt = V , but if there is stochastic volatility,
the variances (more particularly the log variances) can also be brought into a
random walk order scheme with normal errors.
Subject matter considerations are likely to govern the anticipated level of
smoothness in the regression eﬀects. For example, Beck (1983) argues that the
RW (2) scheme,
βt = 2βt−1 −βt−2 + ωt
ωt ∼N(0, V ),
provides a more plausible smoothly changing evolution for changing regres-
sion eﬀects in political science applications. Dangl and Halling (2007) consider
dynamic linear models for asset returns, yt, and present procedures for formal
Bayes model choice between constant regression eﬀects with V = 0, and diﬀer-
ing levels of variation in βt, via a discrete prior over a small set of covariance
matrix discount factors. Cooley and Prescott (1976) argue that nonstationary

236
Applied Bayesian Hierarchical Methods
regression eﬀects in econometric models partly reﬂect slowly changing behav-
ioral relationships and propose an adaptive scheme, subject to permanent and
transitory changes. Thus for scalar or vector βt,
βt = βp
t + ω1t,
superscript p denotes the permanent component of the parameters and the
permanent component follows a random walk, as in,
βp
t = βp
t−1 + ω2t.
Varying regression eﬀects are important in particular applications of
dynamic generalized linear models for discrete responses (Ferreira and Gamer-
man, 2000; Fruhwirth-Schnatter and Fruhwirth, 2007; Gamerman, 1998). Con-
sider y from an exponential family density,
p(yt|θt) ∝exp(ytθt + b(θt))
φt
,
µt = E(yt|θt) = b′(θt),
where the predictors, Xt, may include past responses {yt−k, y∗
t−k}, both
observed and latent (Fahrmeir and Tutz, 2001, 345). For example, y∗
t , the
latent response (e.g., utility in economic applications) when yt is binary, may
depend on previous values of both y∗
t and yt. The link for µt involves random
regression parameters,
g(µt) = Xtβt,
where the parameter vector evolves according to a linear Gaussian transition
model,
βt = Gtβt−1 + ωt,
with multivariate normal errors, ωt ∼NR(0, Vt), independent of lagged
responses and of the initial condition, β0 ∼NR(B0, V0).
Models for binary time series with state–space priors on the coeﬃcients
have been mentioned in several studies. Thus, Fahrmeir and Tutz (2001) con-
sider a binary dynamic logit model involving trend and varying eﬀects of a
predictor and lagged response,
logit(πt) = β1t + β2txt + β3tyt−1,
βt ∼N3 (βt−1, V ) ,
while Gamerman (1998) considers nonstationary random walk priors in a mar-
keting application with binomial data, where logit(πt) = β1t + β2txt, and
xt is a measure of cumulative advertising expenditure. Similarly, Fruhwirth-
Schnatter and Fruhwirth (2007) consider time series of binary observations

Regression Techniques Using Hierarchical Priors
237
with probabilities πt, where some predictors, Xr
t , have time varying eﬀects, βt,
while some Xf
t have time constant parameters α, so that πt is modeled as
logit(πt) = Xf
t α + Xr
t βt. They point out that existing MCMC approaches
rely on Metropolis–Hastings proposal densities in possibly high-dimensional
parameter space, and instead use an auxiliary mixture sampler in the aug-
mented data model,
U1t = Xf
t α + Xr
t βt + εt,
where the latent utility of the alternative option, U0t, and the error, εt, follow
type 1 extreme value distributions. The error distribution is approximated as
a mixture of normals, and the model reduces to a linear Gaussian state–space
scheme with heteroscedastic errors.
Example 5.8. Epileptic Seizures
This
example
considers
correlated
error schemes for a count response, speciﬁcally data from a clinical trial into
the eﬀect of intravenous gamma-globulin on suppression of epileptic seizures
(Wang et al., 1996). Daily seizure counts are recorded for a single patient for
a period of 140 days, where the ﬁrst 27 days are a baseline period without
treatment, and the remaining 113 days are the treatment period. Predictors
are x1t = treatment, x2t = days treated, and an interaction x3t = x1tx2t
between days treated and treatment. A simple Poisson regression is applied
initially, and a predictive p test based on the DW statistic applied. In fact,
this does not appear to be signiﬁcant, having a value 0.76. Monte Carlo
estimates of CPO statistics do, however, indicate model failures (Figure 5.3),
with the log pseudo ML standing at −592. A stationary AR(1) error model
as in Equation 5.11 reduces the log(psML) to −372, with ρ having mean 0.23
(0.06, 0.40).
–16
–14
–12
–10
–8
–6
–4
–2
0
0
20
40
60
80
100
120
140
FIGURE 5.3
Log CPO plot.

238
Applied Bayesian Hierarchical Methods
Following Wang and Puterman (1999b), the dependence structure is also
modeled using an unobservable ﬁnite-state Markov chain with K = 2 latent
states. Conditional on state St = j, the Poisson mean for the seizure count on
day t is represented as
µt = exp(β0j + β1jx1t + β2jx12 + β3jx3t)
j = 1, 2.
An identiﬁability (ordered parameter) constraint is applied to the inter-
cepts, though classical estimation makes clear that the two regimes have
markedly diﬀerent treatment eﬀects, β1j, and a constraint could be applied
to them instead. The last 8000 iterations of a two chain run of 10,000 itera-
tions show a further improved log(psML) of −359. State 1 has a much higher
positive treatment eﬀect, and a more negative interaction eﬀect. If a subject
is in that state on day t, the probability, π11, of remaining there next day is
0.75, with probability, π12 = 0.25, of moving to state 2. If a subject currently
occupies state 2, the respective probabilities are 0.62 and 0.38.
Example 5.9. Mortality and Environment
This
example
illustrates
time-varying regression eﬀects, again for a count data application. It follows
Smith et al. (2000) and Chiogna and Gaetan (2002) in analyzing the relation-
ship between deaths, meteorological variables, and air pollution in Birming-
ham, Alabama, between August 3, 1985 and December 31, 1988 (T = 1247
observations). Related recent papers include Lee and Shaddick (2005) and
Erbas and Hyndman (2005). The dataset contains two death series; here the
over 65 deaths series is considered. In particular, Schwartz (1993) found a
signiﬁcant eﬀect of PM10 on mortality for these data, whereas Smith et al.
(2000) argued that results may depend on which meteorological variables are
adjusted for, and how (or whether) diﬀerent lagged values of PM10 are com-
bined into a single exposure measure.
Here a time constant regression is compared with an analysis similar to
that of Chiogna and Gaetan (2002) involving an RW 2 trend on the level,
and independent RW 1 priors for time-varying coeﬃcients on three predictors
(x1 = minimum temperature, x2 = humidity, and x3 = the ﬁrst lag of PM10).
So with yt ∽Po(µt), one has,
log(µt) = αt + β1tx1t + β2tx2t + β3tx3t,
αt ∽N

2αt−1 −αt−2, σ2
α

,
βjt ∽N(βj,t−1, Wj),
with 1/σ2
α assigned a Ga(1, 1) prior, and the coeﬃcient variances modeled in
terms of ratios to the trend variance σ2
α, namely,
Wj = qjσ2
α,
qj ∽U(0, 10).

Regression Techniques Using Hierarchical Priors
239
As a predictive check, one step ahead predictions, y∗
t ∽Po(µt−1), are made
and posterior probabilities, Qt = Pr(y∗
t ≤yt|y), obtained. Low or high values
for Qt indicate failures of ﬁt and/or prediction.
For the Poisson regression with constant predictor eﬀects, the average
(scaled) Poisson deviance from the last 9000 of a two chain run of 10,000
iterations is 1406, so there appears to be relatively little overdispersion in re-
lation to the 1247 observations. Of the three regression coeﬃcients, only β1
has a 95% posterior interval that excludes zero, namely, −0.013 to −0.034.
For the second model, the identiﬁcation of time-varying predictor eﬀects is
likely to be improved using the representation,
βjt = µβj + bjt,
bjt ∽N(bj,t−1, Wj),
where the three sets of eﬀects, bjt, are centered at each MCMC iteration to
have mean zero10.
Inferences are based on the second half of a two chain run of 20,000 itera-
tions, reﬂecting relatively slow convergence in q1. Figures 5.4 and 5.5 plot the
time-varying coeﬃcients, β2t and β3t. Signiﬁcant eﬀects of PM10 are limited
to a central period, similar to the ﬁndings of Chiogna and Gaetan (2002).
Only 22 of the 1247 points have Qt < 0.025 or Qt > 0.975, so judging
by its one step ahead predictions, the model seems to reproduce the data
satisfactorily.
–0.01
–0.005
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
1
54
107
160
213
266
319
372
425
478
531
584
637
690
743
796
849
902
955
1008
1061
1114
1167
1220
Mean
2.5%
97.5%
FIGURE 5.4
Time varying humidity coeﬃcient.

240
Applied Bayesian Hierarchical Methods
Mean
2.5%
97.5%
–0.015
–0.01
–0.005
0
0.005
0.01
0.015
1
54
107
160
213
266
319
372
425
478
531
584
637
690
743
796
849
902
955
1008
1061
1114
1167
1220
FIGURE 5.5
Time varying PM10 coeﬃcient.
5.8
Spatial Correlation in Regression Residuals
In economic and health applications involving area data, the outcomes from
neighboring areas tend to be positively correlated. If available predictors fail
to account completely for variations in the outcome and the regression model
treats units as independent, residual spatial correlation can bias regression
parameter estimates and cause standard errors to be understated (Boyd et al.,
2005). Cliﬀand Ord (1981, 197) suggest that possible nonlinear eﬀects of
predictors may account for residual spatial correlation, while Anselin (1988,
Chapter 8) mentions that spatially correlated errors may reﬂect spatial corre-
lation among predictors, spatial heterogeneity in functional form, and spatial
correlation in the response when a spatially lagged response is not present in
the model. Franzese and Hays (2008) review real world mechanisms in econo-
metric and political science applications that may underlie spatial interdepen-
dence. With regard to a speciﬁc form of spatial heterogeneity, Fotheringham
et al. (2002, 113) argue that spatial correlation in regression residuals often
results from incorrectly applying a global model (one with homogenous regres-
sion coeﬃcients) to a nonstationary process (that requires a varying regression
coeﬃcient approach)—see Section 5.9.
Cliﬀand Ord (1981, 199–206) consider test statistics (modiﬁed versions of
the Moran I and Geary c statistics) to measure spatial correlation in regression

Regression Techniques Using Hierarchical Priors
241
residuals. In a Bayesian MCMC estimation setting, one could calculate these
for observed and replicate data and apply the Gelman et al. (1996) posterior
predictive check test. For example, Moran’s I statistic for regression residuals,
e = y −Xβ, from a normal linear regression involving n areas is
I = e′We/S0
e′e/n
,
where S0 = 
i

j wij and W = [wij] is a chosen form of spatial interac-
tion. Franzese and Hays (2008) mention Lagrange multiplier tests for linear
regression residuals that could also be incorporated in a posterior predictive
procedure.
Alternatively, Congdon et al. (2007) apply a test suggested by Fothering-
ham et al. (2002, 106) that measures spatial correlation via linear regression of
appropriately deﬁned residuals, ei, on the spatial lag e∗
i = 
j wijej/ 
j wij.
The regression is simply,
ei = ρ0 + ρ1e∗
i + ui,
where ui are taken as unstructured. This is done at each MCMC iteration to
provide a posterior mean and 95% intervals on the spatial correlation index
ρ1. If the 95% interval excludes zero then spatial correlation is present. A
posterior predictive p test can also be applied with this criterion.
5.8.1
Spatial lag and spatial error models
Standard ways to deal with spatially correlated errors are to include a spatially
lagged response as a predictor or to explicitly incorporate spatial eﬀects in
the residual speciﬁcation. Correcting for spatial correlation in this way may
aﬀect the signiﬁcance, and even the direction of predictor eﬀects, as compared
to a model with nonspatial error structure (Kuhn, 2007). Including a lagged
response deﬁnes the spatial autoregressive or spatial lag model (Anselin, 1988),
which for y metric has the form,
yi = ρ

j
cijyj + Xiβ + ui,
where −1 ≤ρ ≤1, the ui ∼N(0, σ2) are white noise errors, and cij = wij/

j wij are a row-standardized transform of the original symmetric spatial
interactions, wij, with 
j cij = 1. If wij are binary and based on adjacency,
this is equivalent to including the average of the neighboring responses as an
extra predictor. One may express the response as spatially ﬁltered, namely,
y∗
i = yi −ρ

j
cijyj,
with the spatial autoregressive model then taking the indirect form,
y∗
i = Xiβ + ui.

242
Applied Bayesian Hierarchical Methods
This model has been proposed for discrete responses and is often modeled
by introducing augmented data, with a widely applied approach being known
as the spatial probit (Franzese and Hays, 2007; Holloway et al., 2002). So for y
binary, zi is a latent metric variable that is positive when y = 1 and negative
when y = 0. Then the usual model form is
zi = ρ

j
cijzj + Xiβ + ui,
with i.i.d. errors ui ∼N(0, 1). In econometric applications, this might amount
to expecting individuals located at similar points in space to exhibit similar
choice behavior (Smith and Lesage, 2004), or to expecting interaction between
neighboring areas in the underlying propensity of the event (Coughlin et al.,
2004). In matrix terms,
z = ρCz + Xβ + u,
and solving for z gives,
z = (I −ρC)−1Xβ + u∗,
where u∗= (I −ρC)−1u. The disturbances are now correlated (McMillen,
1992) with u∗∼N(0, Ω), where Ω= (I −ρC)−1[(I −ρC)−1]′.
An alternative solution to spatially correlated residuals—especially if there
is no strong evidence for spatial lag eﬀects—is to include spatial structure in
the errors. The rationale is that the eﬀects of unknown predictors spill over
across adjacent areas, causing spatially correlated errors. One option is the
simultaneous autoregressive scheme (SAR) (Richardson et al., 1992),
yi = Xiβ + εi,
εi = ρ

j
cijεj + ui,
with ui ∼N(0, Σu), and a maximum possible value of 1 for ρ since the spatial
weights are standardized. The lower prior limit for ρ is typically taken as 0
since negative values are implausible.
Writing the equation for the autoregressive error vector ε = (ε1, . . . , εn) as
ε = (I −ρC)−1u, the covariance matrix for ε is
(I −ρC)−1Σu(I −ρC′)−1,
and with D = I −ρC, the joint prior for ε is obtained as
(ε1, . . . , εn) ∽Nn(0, D−1Σu(D′)−1).
Assuming Σu = σ2I, the likelihood is
L

α, ρ, σ2|y

=
1
2πσn |D′D|0.5 exp

−1
2σ2 [(y −Xβ)′D′D(y −Xβ)]


Regression Techniques Using Hierarchical Priors
243
An indirect procedure for estimating the SAR error model involves spatial
diﬀerencing, whereby,
y = ρCy + Xβ −ρCXβ + u,
or taking y∗= y −ρCy, X∗= X −ρCX ,
y∗= X∗β + u,
where the errors are unstructured.
By contrast, conditional autoregressive errors (Besag, 1974) specify εi con-
ditional on remaining eﬀects ε[i]. One option takes unstandardized spatial
interactions with,
E(εi|ε[i]) = λ

j̸=i
wijεj,
Var(εi|ε[i]) = σ2,
with joint covariance σ2(I −λW)−1. In this case (Bell and Broemeling,
2000, 959), λ is constrained by the eigenvalues Ei of W, namely, λ ∈
[1/Emin, 1/Emax]. The conditional variances may diﬀer between subjects with
M = diag(σ2
i ) and the covariance is then (I −λW)−1M (Lichstein et al.,
2002).
If predictor eﬀects are written ηi = Xiβ, this formulation may be restated
in terms of an “own area” regression eﬀect, and a ﬁltered eﬀect of neighboring
regression residuals (Bell and Broemeling, 2000; Mollie and Richardson, 1991).
Thus for y metric,
yi ∼N(ηi + λ

j̸=i
wij(yj −ηj), σ2).
When y is Poisson, with means νi = Eiρi, where Ei are expected events
and ρi are relative risks, one may similarly (Bell and Broemeling, 2000, 966)
assume ri = log(ρi) are normal with11,
ri ∼N

ηi + λ

j̸=i
wij(rj −ηj), σ2

.
The other conditional autoregressive option takes standardized spatial
interactions,
E(εi|ε[i]) = κ

j̸=i
cijεj,
Var(εi|ε[i]) = σ2

j̸=i
wij,

244
Applied Bayesian Hierarchical Methods
with joint covariance for the εi then being σ2(D−κW)−1, where D is diagonal
with elements di = 
j̸=i wij (Sun et al., 1999, 342). Equivalently, in the
case wij = 1 for neighbors and wij = 0 otherwise, the diagonal terms of the
precision matrix are τdi, where τ = 1/σ2 (Kruijer et al., 2007), while oﬀ-
diagonal terms equal −τκ when i and j are neighbors and 0 otherwise. In the
case when κ = 1, one obtains the CAR(1) prior of Besag et al. (1991) with the
joint covariance matrix no longer positive deﬁnite. This approach generalizes
to the convolution model with distinct spatial and white noise errors. So with
regression mean, µi, and link, g, one has,
g(µi) = Xiβ + εi + ui,
though the separate error terms are subject to possibly weak identiﬁability,
as considered in Chapter 4.
5.9
Spatially Varying Regression Eﬀects: Geographically
Weighted Linear Regression and Bayesian Spatially
Varying Coeﬃcient Models
Further to the discussion in Fotheringham et al. (2002), linear and general
linear spatial models typically assume that model parameters are homogenous
over the study region without any local variation. The assumption of constant
parameter values over space may often be unrealistic, and schemes that admit
spatial variation or spatial nonstationarity in regression parameters may both
improve ﬁt and also account for spatially correlated residuals (e.g., Leung
et al., 2000; Osborne et al., 2007).
A widely applied method (Brunsdon et al., 1998), especially for metric
data, is geographically weighted linear regression (GWR). This method con-
sists in reusing the data n times, such that the ith regression regards the ith
area as the origin. With R predictors, the coeﬃcients β1i, . . . , βRi for the ith
regression are derived using interaction weights wik > 0 between the ith area
and other areas. These weightings in concert with an overall precision param-
eter, φ, deﬁne the precision parameters φwik for area k in a normal likelihood.
So for the ith regression (centered on area i),
yk ∼N(µik, 1/τik)
k = 1, . . . , n,
τik = φwik,
µik = β1ix1k + · · · + βRixRk.
The spatial interaction function, wik, might involve an exponential, bi-
square, spherical, or Gaussian kernel function of distances dik between areas.
Under weighted least squares, the estimator for βi = (β1i, . . . , βRi) is
βi = (X′WiX)−1X′Wiy,

Regression Techniques Using Hierarchical Priors
245
where Wi is an n × n diagonal matrix with entries wik (Assuncao, 2003). A
Gaussian decay in distance with positive bandwidth η would specify,
wik = exp

−d2
ik/2η2
η > 0,
(5.12)
so that for small distances between area i and k, the kernel wik is close to
1 and nearer observations have higher precisions. A cross-validation GWR
approach omits the kth response, yk, from the kth geographically weighted
regression (though wik still take account of the known geographic location of
area k) with the prediction of yk using the remaining n −1 areas (Farber and
Paez, 2007).
Lesage (2004) notes that local linear estimates based on a distance-
weighted subsample of data may suﬀer from weak identiﬁcation as the eﬀective
number of observations used to produce estimates for some points in space
may be small. This problem can be solved under a Bayesian approach by
incorporating prior information. For example, a prior may be set on η in
Equation 5.12, taking account of the maximum observed inter-point or inter-
area distance, and one may robustify against outlying areas (Lesage, 1999) by
taking a scale mixture (heavy tailed) approach. Thus, for ν degrees of freedom
in a Student t density, one has,
τik = φwikκik,
κik ∼Ga(0.5ν, 0.5ν).
Lesage (2004) and Lesage and Kelley Pace (2009) reframe the GWR
scheme to allow spatially nonconstant variance scaling parameters, νi, sub-
ject to an exchangeable chi-square prior density, namely,
νi ∼χ2(r),
with r a hyperparameter. Lesage (2004) also redeﬁnes wik as normalized
distance-based weights (with wii = 0), such as,
wik = exp(−dik/η)
 n

k=1
exp(−dik/η),
so the terms in the row-vector (wi1, . . . , win) sum to unity. Then with y being
the n × 1 response vector and,
Wiy = WiXβi + εi,
the smoothing of regression eﬀects across space is represented as,
βi = (wi1 ⊗IR, . . . , win ⊗IR)






β1
· · ·
· · ·
· · ·
βn






+ ui.
(5.13)

246
Applied Bayesian Hierarchical Methods
With Vi = diag(v1, . . . , vn), the error terms have priors,
εi ∼N(0, σ2Vi),
ui ∼N(0, σ2δ2(X′W 2
i X)−1),
with the speciﬁcation on ui being a form of Zellner g-prior, in which δ2 governs
adherence to the smoothing speciﬁcation (Equation 5.13).
5.9.1
Bayesian spatially varying coeﬃcient models
An alternative to the GWR approach is provided by spatially varying coeﬃ-
cient (SVC) models (Assuncao, 2003; Gamerman et al., 2003; Gelfand et al.,
2003; Wheeler and Calder, 2006, 2007). For a continuous space perspective,
let Y (s) be the n × 1 response vector for locations, s = (s1, . . . , sn), and β be
a nR × 1 stacked vector of spatially varying regression coeﬃcients. Then the
normal SVC model is (Gelfand et al., 2003, Section 3),
Y (s) ∼N(X(s)′β(s), σ2I),
where X′ is a n × nR block diagonal matrix of predictors. The prior for β is
β(s) ∼N(1n×1 ⊗µβ, Vβ),
where µβ = (µβ1, . . . , µβR)′ contains the mean regression eﬀects, and Vβ is the
nR × nR covariance matrix.
The latter can be expressed as,
Vβ = C(η) ⊗Λ,
where Λ is a R × R matrix containing covariances between regression coeﬃ-
cients at any particular location, and C(η) = [c(si−sj; η)] is a n×n correlation
matrix representing spatial interaction between locations or areas, with η de-
noting parameters governing such interaction. Hence, each of the R regression
coeﬃcients is assumed to follow the same spatial interaction structure. For
example, under exponential spatial interaction (Wheeler and Calder, 2007),
c(si −sj; η) = exp(−dij/η),
where η is a positive parameter.
Setting β = 1n×1 ⊗µβ + b, where b ∼N(0, C(η) ⊗Λ), the model may also
be written,
Y = X′µβ + X′b + ε,
where ε ∼N(0, σ2I). Integrating over b, the observed data likelihood (Gelfand
et al., 2003, 390) is
p(y|µβ, σ2, Λ, C(η)) ∝[X(C(η) ⊗Λ)X′ + σ2I]−0.5
× exp{−0.5(y −X(1n×1 ⊗µβ))′
× [X(C(η) ⊗Λ)X′ + σ2I]−1(y −X(1n×1 ⊗µβ))}.

Regression Techniques Using Hierarchical Priors
247
For discrete areas, distance-based kernel schemes for spatial interaction
have less substantive basis. Let i = 1, . . . , n denote a set of such areas, and βi =
(β1i, . . . , βRi) be spatially varying regression eﬀects in the linear predictor,
ηi =
R

r=1
βrixri,
of a general linear model with mean µi = E(yi), and link g(µi) = ηi. With β =
(β1, . . . , βn), one possible spatially structured scheme is a pairwise diﬀerence
prior (Assuncao, 2003),
p(β|Φ) ∝|Φ|n/2 exp

−0.5

i

j
wij(βi −βj)′Φ(βi −βj)

.
(5.14)
with R × R precision matrix Φ, and with spatial interactions, wij, usually
binary (wij = 1 when areas i and j are adjacent and zero otherwise).
When yi is metric with µi = ηi, precision τ = 1/σ2 and likelihood,
p(y|β, τ) = (2π)−n/2τ exp

−0.5τ
n

i=1
(yi −xiβi)2

,
one may, following Gamerman et al. (2003), scale the covariance in Equa-
tion 5.14 by τ, namely,
p(β|Φ, τ) ∝τnR/2|Φ|n/2 exp

−0.5τ

i

j
wij(βi −βj)′Φ(βi −βj)

. (5.15)
Assume gamma and Wishart priors for τ and Φ, namely, τ ∼Ga(ντ/2,
Sτντ/2), Φ ∼W(νΦ/2, SΦνΦ/2), then with normal data, y, conjugate full
conditional densities can be sampled in a Gibbs scheme (Assuncao, 2003, 9;
Gamerman et al., 2003, 517–18). With β[i] = (β1, . . . , βi−1, βi+1, . . . , βn), the
posterior conditional for βi is normal with,
p(βi|β[i], τ, Φ) = N(Hi(xiyi + wi+Φ¯β[i], σ2Hi),
Hi = [xix′
i + wi+Φ]−1,
¯β[i] =

j̸=i
wijβj/wi+.
The covariance matrix for β in Equation 5.14 is
K−1 ⊗Φ−1,
and for Equation 5.15 is
σ2K−1 ⊗Φ−1,

248
Applied Bayesian Hierarchical Methods
where K has elements,
kii = wi+ =

j̸=i
wij,
kij = −wij
i ̸= j.
Hence priors (Equation 5.14) and (Equation 5.15) are improper because
the elements in each row of K add to zero. Assuncao (2003, 460) notes that
propriety can be obtained by a constraint such as 
i βi = A, where A is any
known R vector. This consideration leads to a practical strategy representing
βi as βi = µβ + bi, where bi follow the prior in Equations 5.14 or 5.15, but are
zero centered at each MCMC iteration. So bi are eﬀectively zero mean spatially
structured deviations from the mean regression eﬀect, µβ = (µβ1, . . . , µβR).
Example 5.10. Bladder Cancer in US State Economic Areas
Fol-
lowing Wheeler and Tiefelsdorf (2005), this example considers white male
bladder cancer mortality rates over 1970–1994 in 508 State Economic Areas
(SEA) of the United States. The response is the age standardized mortality
rate per 100,000 person-years and the predictors are x1 = log population den-
sity; and x2 = white male lung cancer mortality rate. Population density may
proxy urban environmental risk factors, since other evidence shows bladder
cancer rates increase with urban density (Ayotte et al., 2006). Lung cancer
mortality rates proxy smoking, which is also a positive risk factor for blad-
der cancer: the attributable risk of smoking for lung cancer exceeds 80% and
the attributable risk of smoking for bladder cancer exceeds 55% (Mehnert
et al., 1992). The neighborhood scheme here is based on adjacency between
the SEAs; this is deﬁned according to a distance threshold of 150 km between
SEA population centroids (determined using US county populations for 1982).
For the 30 SEAs that have no neighbors on this basis, a single neighbor is de-
ﬁned as the closest SEA.
A global (i.e., stationary coeﬃcient) model is ﬁrst ﬁtted with only the
usual white noise error term. This has a DIC of 1529 (de = 4), with signiﬁ-
cant eﬀects for the ﬁrst predictor only. The posterior means (95% intervals)
for β1 and β2 are 0.386 (0.329, 0.451) and −4.5E-6 (−0.0074, 0.0053), with
the white noise variance having a mean of 1.18. The spatial residual regres-
sion coeﬃcient (SRRC) discussed above is positive, with 95% interval (0.104,
0.115), indicating spatially correlated residuals.
One possible remedy for this is to include a speciﬁc spatially structured
residual in the regression. Accordingly, a second model includes an additive
ICAR(1) spatial error, si, in addition to the usual white noise error of a normal
linear regression, namely,
yi = β0 + β1x1i + β2x2i + si + ui,
with Ga(0.5, 0.0005) priors assigned to the precisions of si and ui. The last
4500 of a two chain 5000 iterations run give a greatly improved DIC of 1179

Regression Techniques Using Hierarchical Priors
249
(de = 202) with signiﬁcant eﬀects now for both predictors, but a reduced
coeﬃcient for β1. The posterior means (95% intervals) for β1 and β2 are 0.177
(0.122, 0.234) and 0.029 (0.020, 0.037), so both coeﬃcients have entirely posi-
tive 95% credible intervals. Such a change in predictor eﬀects demonstrates the
importance of correct error speciﬁcation for inferences about measured pre-
dictors. The variance of the unstructured and spatial errors are 0.40 and 1.35.
An alternative possible solution to spatially correlated residuals is to con-
sider spatial nonstationarity in predictor eﬀects. Here,
yi = β0 + β1ix1i + β2ix2i + ui,
where βki = µβk + bki, and bki follow independent CAR(1) priors. The bki are
centered to average zero at each MCMC iteration. The last 4500 of a two chain
5000 iteration run give a DIC of 1093 (de = 235), again with signiﬁcant mean
eﬀects, µβ, for both predictors: posterior means (95% intervals) for µβ1 and
µβ2 are 0.237 (0.167, 0.313) and 0.031 (0.022, 0.039), so that recognizing het-
erogeneity has also enhanced the central predictor eﬀects. Although Wheeler
and Tiefelsdorf (2005, 169) found problems with implausible negative eﬀects
when using a classical GWR approach, the Bayesian SVC approach reveals
only 20 SEAs with posterior probabilities Pr(β1i > 0|y) under 0.5, and only
seven SEAs with posterior probabilities Pr(β2i > 0|y) under 0.5.
Example 5.11. Discrete
Poisson
Mixture
with
Spatial
Errors:
Alcohol-Related Hospitalizations This example considers a discrete Pois-
son regression mixture for male alcohol-related hospitalizations in 354 English
local authorities (data from http://www.nwph.net/nwpho/default.aspx).
These are related to two composite indicators of area social structure. The
ﬁrst is a social fragmentation score (x1), a standardized score derived in turn
from z scores on four 2001 Census percentage indicators, namely, one person
households, private rented households, recent migrants, and unmarried adults.
The second is a deprivation score (x2), also a standardized score and derived
from a total of z scores for three Census percentage indicators, namely, per-
centages of adult workers in classes 4 and 5 (low skill manual), unemployment
among the economically active, and social renting households.
One might expect spatially correlated residuals if there are major unknown
risk factors. However, an initial analysis is applied to a Poisson regression
mixture,
p(yi|x1i, . . . , xRi) =
K

k=1
pkPo

Ei exp

β0k +
R

r=1
xriβrk

,
where Ei are expected events and R = 2. The number of mixture components
K was taken to be 3, as earlier unconstrained analysis shows a stable three
group mixture, with clearly separated intercepts, with means and 95% inter-
vals −0.219 (−0.227, −0.211), 0.019 (0.011, 0.028), and 0.268 (0.254, 0.282);
these can be interpreted straightforwardly as low-, medium-, and high-risk
areas.

250
Applied Bayesian Hierarchical Methods
A subsequent analysis with intercepts subject to an order constraint shows
the same posterior intercepts with the groups having respective probabili-
ties (0.481, 0.384, 0.135). There are apparently stronger eﬀects of deprivation
(β21, β22, β23) for the three groups, namely, 0.105 (0.098, 0.113), 0.105 (0.098,
0.112), 0.093 (0.084, 0.102) than of fragmentation, namely, 0.019 (0.010,
0.027), 0.027 (0.019, 0.034), and 0.009 (−4.76E-4, 0.018). However, lack of ﬁt
is apparent in a scaled deviance of 1245 and spatial correlation in the errors
shows in a signiﬁcant SRRC, with mean 0.39 and 95% interval (0.28, 0.49).
The analysis is repeated but including an ICAR(1) spatial error (Besag
et al., 1991), namely,
p(yi|x1i, . . . , xRi) =
K

k=1
pkPo

Ei exp

β0k +
R

r=1
xriβrk + si

,
where si is centered at each MCMC iteration to have mean zero12. This op-
tion reduces the scaled deviance to 357, with the SRRC statistic now having
a mean −0.004 close to zero with 95% interval −0.30 to 0.27. Control for spa-
tially correlated residuals has the eﬀect of enhancing the fragmentation eﬀects
to signiﬁcance. The posterior mean fragmentation eﬀects and the 95% inter-
vals for (β11, β12, β13) are now 0.096 (0.059, 0.152), 0.026 (−0.003, 0.061), and
0.100 (0.029, 0.212). Eﬀects of deprivation are also enhanced, demonstrating
as for the previous example, the importance of correct error speciﬁcation for
inferences about measured predictors.
Appendix: Computational Notes
1. The BayesX code in Example 5.1 is
dataset d
d.inﬁle, maxobs=5000 using data\crab.txt
bayesreg b
b.regress y = x, family=nbinomial predict using d.
The WinBUGS code for the NBk model in this application is
model { for (i in 1:173) {y[i] ∼dpois(mu[i]); mu[i] ∼dgamma(a[i],b[i])
a[i] <- pow(xi[i],1-k)/phi; b[i] <- pow(xi[i],-k)/phi
log(xi[i]) <- beta[1]+beta[2]*(x[i]-mean(x[]))}
beta[1] ∼dnorm(0,0.001); beta[2] ∼dnorm(0,1)
k1∼dgamma(1,1); k <- k1-1; phi∼dgamma(1,1)}
2. The code for the overdispersed multinomial model in Example 5.2 is
model { for (i in 1:n) { log(phi[i,J]) <- 0; N[i] <- sum(y[i,]);
# likelihood and replicate data
y[i,1:J]∼dmulti(pi[i,1:J],N[i]); yrep[i,1:J]∼dmulti(pi[i,1:J],N[i])

Regression Techniques Using Hierarchical Priors
251
# random choice eﬀects
alp[i,1:JM] ∼dmnorm(A[],D.inv[,]);
for (j in 1:J) {pi[i,j] <- phi[i,j]/sum(phi[i,]); yh[i,j] <- N[i]*pi[i,j]
# chi square calculations
cr[i,j] <- pow(yrep[i,j]-yh[i,j],2)/yh[i,j]; c[i,j] <- pow(y[i,j]-yh[i,j],2)/yh[i,j]}
for (j in 1:J-1) {log(phi[i,j]) <- alp[i,j]+bet[j,1]*(x1[i,j]-mean(x1[,j]))+
bet[j,2]*(x2[i,j]-mean(x2[,j]))+bet[j,3]*(x3[i]-mean(x3[]))}}
# posterior predictive check
PPC <- step(sum(cr[,])-sum(c[,]))
# priors
for (j in 1:J-1) {A[j]∼dﬂat()
for (k in 1:3) {bet[j,k]∼dﬂat()}
for (k in 1:J-1) {Wsc[j,k] <- equals(j,k)}}
D.inv[1:JM,1:JM]∼dwish(Wsc[,],JM)}
3. A WinBUGS code for the Scott (2003) approach to logit regression aug-
mented data sampling with a single regressor is
model { for (i in 1:n) {Y[i] <- y[i]+1; z[i,1]∼dexp(1) I(A1[i,Y[i]],B1[i,Y[i]])
z[i,2] ∼dexp(lam1[i]) I(A2[i,Y[i]],B2[i,Y[i]])
A1[i,1] <- 0; B1[i,1] <- z[i,2]; A1[i,2] <- z[i,2]; B1[i,2] <- 10000
A2[i,1] <- z[i,1]; B2[i,1] <- 10000; A2[i,2] <- 0; B2[i,2] <- z[i,1]
log(lam1[i]) <- b[1]+b[2]*x[i]}
for (j in 1:2) {b[j] ∼dﬂat()}}
4. In Example 5.3, the probit model with skewed error has WinBUGS code,
model{for (i in 1:n) {m[i] <-b[1]+b[2]*DVRT[i]+
b[3]*sex[i]+b[4]*fathocc[i] +delta.s*V[i]
fathocc[i] ∼dnorm(mocc,tocc); V[i] ∼dnorm(0,1) I(0,)
ystar[i] ∼dnorm(m[i],prec) I(lo[lvcert[i]+1],up[lvcert[i]+1]) }
for (j in 1:4) {b[j] ∼dnorm(0,0.01)}
mocc ∼dnorm(30,0.01); tocc ∼dgamma(1,0.01)
k.delta ∼dbern(p.delta); p.delta ∼dbeta(1,1)
delta ∼dunif(-1,1); delta.s <- k.delta*delta; prec <- 1/(1-pow(delta.s,2))}
The code for an augmented data logit regression using the approximation of
Kinney and Dunson (2007) is
model {for (i in 1:n) {m[i] <-b[1]+b[2]*DVRT[i]+b[3]*sex[i]+b[4]*fathocc[i]
fathocc[i]∼dnorm(mocc,tocc); prec[i] <- lam[i]*0.419; lam[i]∼dgamma(3.65,
3.65)
ystar[i]∼dnorm(m[i],prec[i]) I(lo[lvcert[i]+1],up[lvcert[i]+1]) }
for (j in 1:4) {b[j]∼dnorm(0,0.01)}
mocc∼dnorm(30,0.01); tocc∼dgamma(1,0.01)}
5. Code for a conventional ordinal probit likelihood approach in Example
5.4 is as follows, with predictive checks based on replicate data,
model { for (t in 1:T) { for (j in 1:J-1) {gam[t,j] <- phi(a[j] - mu[t,j])

252
Applied Bayesian Hierarchical Methods
mu[t,j] <- b[1]*x[t,1]+b[2]*x[t,2]+b[3]*x[t,3]+b[4]*x[t,4]}
pi[t,1] <- gam[t,1]; pi[t,J] <- 1-gam[t,J-1]
for (j in 2:J-1) { pi[t,j] <- gam[t,j] - gam[t,j-1]}
y[t]∼dcat(pi[t,1:J]); yrep[t] ∼dcat(pi[t,1:J]);
match.pred[t] <- equals(y[t],yrep[t]);
a[1] ∼dnorm(0,1) I(,a[2]); a[2] ∼dnorm(0,1) I(a[1],);
b[1:4]∼dmnorm(b0[ ], B0[ , ]); Year.pred <- sum(match.pred[])/T}
The code for the latent data approach (with replicates zstar.rep now being of
latent data) in Example 5.4 is
model { for (t in 1:T) { for (j in 1:J-1) { z[t,j] <- step(j-y[t])
zstar[t,j]∼dnorm(nu[t,j],1) I(A[t,j],B[t,j])
A[t,j] <- -10*equals(z[t,j],0); B[t,j] <- 10*equals(z[t,j],1)
nu[t,j] <- a[j] - mu[t,j]; mu[t,j] <- b[1]*x[t,1]+b[2]*x[t,2]+b[3]*x[t,3]+b[4]
*x[t,4]
zstar.rep[t,j]∼dnorm(nu[t,j],1); zrep[t,j] <- step(zstar.rep[t,j])}
yrep[t] <- equals(zrep[t,1],1)*equals(zrep[t,2],1)
+2*equals(zrep[t,1],0)*equals(zrep[t,2],1)+3*equals(zrep[t,1],0)*equals
(zrep[t,2],0)
match.pred[t] <- equals(yrep[t],y[t])}
a[1]∼dnorm(0,1) I(,a[2]); a[2]∼dnorm(0,1) I(a[1],);
b[1:4]∼dmnorm(b0[ ], B0[ , ]); Year.pred <- sum(match.pred[1:T])/T}
6. An illustrative code for a Gaussian process with two predictors is
model { Tau[1:n,1:n] <- inverse(Cov[,])
y[1:n] ∼dmnorm(mu[1:n],Tau[,])
for (i in 1:n){mu[i] <- b[1]+b[2]*x1[i]+b[3]*x2[i]
for (j in 1:n) {Cov[i,j] <- sig2*(K[i,j]+gam*equals(i,j))
K[i,j] <- exp(-Disx[i,j])
Disx[i,j] <- pow(x1[i]-x1[j],2)/d[1]+pow(x2[i]-x2[j],2)/d[2]}}
d ∼dexp(1); gam ∼dunif(0,10); sig ∼dunif(0,10);
sig2 <- sig*sig; sigdiag <- sqrt(sig2+gam)
for (j in 1:3) {b[j] ∼dnorm(0,0.1)}}
with predictor-speciﬁc range parameters, but power coeﬃcients set to 2.
7. The variance model based on a power transform of the linear predictor
(Example 5.5) is coded as
model {for (i in 1:113) {y[i]∼dnorm(eta[i],tau[i])
ynew[i]∼dnorm(eta[i],tau[i]); predF[i] <- pow(y[i]-ynew[i],2)
s[i] <- sig*pow(1+abs(eta[i]),lam)
tau[i] <- 1/(s[i]*s[i]); eta[i] <- beta[1]+beta[2]*x[i]}
sig∼dunif(0,250); lam∼dunif(-2,2); C.F <- sum(predF[])
for (j in 1:2) {beta[j]∼dnorm(0,0.001)}}
8. The code for the clustered outlier model (Example 5.6) is
model {for (i in 1:50) {G[i] ∼dcat(p[i,1:3]); y[i]∼dnorm(mu[i,G[i]],tau[G[i]]);

Regression Techniques Using Hierarchical Priors
253
mu[i,1] <- b1[1]+b1[2]*x[i]; mu[i,2] <- b2[1]+b2[2]*x[i]; mu[i,3] <- mu[i,2]
for (j in 1:3) {post.group.prob[j,i] <- equals(G[i],j)}
h[i] <- kap*pow(x[i]-nu,2); p[i,1] <- exp(-h[i]); p[i,2] <- (1-pi)*(1-exp
(-h[i]));
p[i,3] <- pi*(1-exp(-h[i]))}
for (j in 1:2) {tau[j] ∼dgamma(1,0.001)} tau[3] <- tau[2]/D; D <- 10
pi∼dbeta(1,9); kap∼dgamma(1,1); nu∼dunif(0.04,8.09)
for (j in 1:2) {b1[j]∼dnorm(0,0.001); b2[j]∼dnorm(0,0.001)}}
9. ZIP regression (Example 5.7) involves either a nonstandard likelihood and
the Barry (2006) proposal, or a mixed Poisson obtained by using subject-
speciﬁc binary variables w[i]. In the following, the former option is commented
out:
model { for (i in 1:797)
# approach 1
# z[i] <- 1; Lz[i] <- -1/p[i]; Uz[i] <- 1/p[i]; z[i]∼dunif(Lz[i],Uz[i]);
# approach 2
y[i] ∼dpois(mu.w[i]); mu.w[i] <- (1-w[i])*mu[i]; w[i] ∼dbern(omeg)
# likelihood
p[i] <- D0[i]*p.eq.0[i]+(1-D0[i])*p.gt.0[i]; H[i] <- 1/p[i]
D0[i] <- equals(y[i],0);
p.eq.0[i] <- omeg+(1-omeg)*exp(-mu[i])
p.gt.0[i] <- (1-omeg)*p.pois[i]
log(p.pois[i]) <- -mu[i]+y[i]*log(mu[i])-logfact(y[i])
# regression
log(mu[i]) <- b1 + b2[sex[i]+1]+b3[ethnic[i]]+b4[school[i]]+
b5*log(base[i]+0.5)}
# priors
b1∼dnorm(0,0.001); b5∼dnorm(0,0.001); omeg∼dbeta(1,1)
b2[1] <- 0; b2[2]∼dnorm(0,0.001)
b3[1] <- 0; for (j in 2:3) {b3[j]∼dnorm(0,0.001)}
b4[3] <- 0; for (j in 1:2) {b4[j]∼dnorm(0,0.001)}
for (j in 4:6) {b4[j]∼dnorm(0,0.001)}}
10. The code for Example 5.9 is
model { for (t in 1:T) {y[t]∼dpois(mu[t])
LL[t] <- -mu[t]+y[t]*log(mu[t])-logfact(y[t]); G[t] <- 1/exp(LL[t])
Dv[t] <- y[t]*log(y[t]/mu[t])-(y[t]-mu[t])
beta1[t] <- beta[1]+b1[t]; beta2[t] <- beta[2]+b3[t]; beta3[t] <- beta[3]+b3[t]
log(mu[t]) <- alp[t] + (beta[1]+b1[t])*(x1[t]-mean(x1[]))+
(beta[2]+b2[t])*(x2[t]-mean(x2[]))+(beta[3]+b3[t])*(x3[t]-mean(x3[]))}
# predictions and ﬁt
for (t in 2:T) {ystar[t]∼dpois(mu[t-1]); Q[t] <- step(y[t]-ystar[t])}
Fit[1] <- -2*sum(LL[]); Fit[2] <- 2*sum(Dv[])
# RW1 priors on beta coeﬀs

254
Applied Bayesian Hierarchical Methods
w[1] <- 1;
adj[1] <- 2;
n[1] <- 1
w[(T-2)*2 + 2] <- 1;
adj[(T-2)*2 + 2] <- T-1;
n[T] <- 1
for (t in 2:T-1) {w[2+(t-2)*2] <- 1; adj[2+(t-2)*2] <- t-1
w[3+(t-2)*2] <- 1;adj[3+(t-2)*2] <- t+1; n[t] <- 2}
b1[1:T] ∼car.normal(adj[],w[],n[],inv.W[1])
b2[1:T] ∼car.normal(adj[],w[],n[],inv.W[2])
b3[1:T] ∼car.normal(adj[],w[],n[],inv.W[3])
for (j in 1:3) {q[j]∼dunif(0,10); inv.W[j] <- tau.alp/q[j]; beta[j]∼dnorm
(0,0.001)}
# RW2 on intercepts alp[t]
for (t in 3:T){m.alp[t] <- 2*alp[t-1]-alp[t-2];alp[t]∼dnorm(m.alp[t],tau.alp)}
alp1∼dnorm(3,0.01); alp2∼dnorm(3,0.01);alp[1] <- alp1; alp[2] <- alp2;
tau.alp∼dgamma(1,1)}
11. A code for this approach, oriented to the Scottish lip cancer data, with
wij taken as binary on the basis of adjacency, is
model { for (i in 1 : NN ) { We[i] <- e[adj[i]] }
lam ∽dunif(-0.326,0.175); inv.sig2 ∽dgamma(1,0.001)
for (j in 1:2) {b[j] ∽dnorm(0,0.001)}
for (i in 1 : N) { y[i] ∽dpois(nu[i]); nu[i] <- E[i]*rho[i]
log(rho[i]) <- r[i]; r[i] ∽dnorm(r.bar[i], inv.sig2);
e[i] <- r[i]-eta[i]; eta[i] <- b[1]+b[2]*x[i]
r.bar[i] <- eta[i]+lam*sum(We[cum[i] + 1:cum[i + 1] ])}}
where N=56 and NN=264.
12. The code for the second model in Example 5.11, including elements to
derive CPO statistics, is
model {for (i in 1:n) {y[i]∼dpois(mu[i,G[i]]); G[i]∼dcat(p[1:K])
L[i] <- sum(Lcomp[i,1:K]); H[i] <- 1/L[i]; logL[i] <- log(L[i])
Dv[i] <- y[i]*log(y[i]/mu[i,G[i]])-(y[i]-mu[i,G[i]])
for (k in 1:K) {mu[i,k] <- E[i]*exp(beta1[k]+
beta2[k]*x1[i]+beta3[k]*x2[i]+s[i])
Lcomp[i,k] <- p[k]*exp(LL[i,k])
LL[i,k] <- -mu[i,k]+y[i]*log(mu[i,k])-logfact(y[i])}}
# Priors
p[1:K]∼ddirch(w[1:K]); tau∽dgamma(1,0.001)
for
(k
in
1:K)
{w[k]
<-
1;
beta2[k]
∼dnorm(0,0.001);
beta3[k]
∼dnorm(0,0.001)}
s[1:n]∼car.normal(map[], wt[], num[], tau)
# tneigh is the total of neighbors in adjacency map
for (i in 1 : tneigh) { wt[i] <- 1}
# ordered intercept constraint
beta1[1] ∽dnorm(0,0.001)
for (j in 1:2) {delbeta[j]∽dgamma(1,0.001); beta1[j+1] <- beta1[j]+delbeta[j]}
Fit[1] <- -2*sum(logL[]); Fit[2] <- 2*sum(Dv[])
# Correlation in residuals

Regression Techniques Using Hierarchical Priors
255
SSRC <- sum(dt[])/sum(db[]);
for (i in 1 : n) {num[i] <- cum[i+1]-cum[i];
e[i] <- (y[i]-mu[i,G[i]])/sqrt(mu[i,G[i]]); estar[i] <- mean(We[cum[i]+1:cum
[i+1]])
de[i] <- e[i]-mean(e[]); d.estar[i] <- estar[i]-mean(estar[])
dt[i] <- de[i]*d.estar[i]; db[i] <-pow(d.estar[i],2)}
for (i in 1 : tneigh) {We[i] <- e[map[i]]}}

6
Bayesian Multilevel Models
6.1
Introduction
The rationale for applying multilevel models to hierarchical data is well estab-
lished (Skrondal and Rabe-Hesketh, 2004; Snijders and Bosker, 1999). When
lower level units are nested within one or more higher level strata, conven-
tional single level regression analysis is not appropriate since observations are
no longer independent: pupils in the same schools, or households in the same
communities, tend to be more similar to one another than pupils in diﬀer-
ent schools or households in diﬀerent communities. Such dependency means
standard errors are downwardly biased if the nesting is ignored, and spurious
inferences regarding predictor eﬀects may be made (Hox, 2002).
In multilevel analysis, predictors may be deﬁned at any level and the
interest focuses on adjusting predictor eﬀects for the simultaneous operation of
contextual and individual variability in the outcome. This may be important
in health applications, for example, if the impact of individual level risk factors
varies according to geographic context (Congdon and Lloyd, 2010). Another
major goal is variance partitioning (Goldstein et al., 2002); for example, what
proportion of area variations in mortality is due to the characteristics of those
areas (what is sometimes termed contextual variation), and how much is due
to the characteristics of the individuals who live in these areas (termed com-
positional variation) (Subramanian et al., 2003).
One may also be interested in estimates for geographic areas or institutions
that include both individual and area information; for example, the multi-
level model for county radon estimates discussed by Gelman (2006a). Gelman
(2006a) notes that compared to estimates involving no pooling or complete
pooling, inferences from multilevel models are more reasonable. Complete
pooling leads to identical estimates for all units, while a no-pooling model (no
borrowing strength) overﬁts the data, giving implausibly high or low estimates
for particular units and low precisions for such estimates.
As well as predictor eﬀects at any level, a multilevel model is likely to
involve random eﬀects deﬁned over the clusters at higher level(s), and possibly
correlation between diﬀerent cluster eﬀects. As in Chapter 3, one seeks to pool
strength in inferences about clusters when the number of observations for each
cluster might be quite small. While exchangeable cluster eﬀects dominate the
multilevel literature, there may well be instances where random cluster eﬀects
257

258
Applied Bayesian Hierarchical Methods
are better regarded as nonexchangeable, as recognized in the general design
general linear mixed model of Zhao et al. (2006). For example, it is possible
that the signiﬁcance level of cluster (i.e., contextual) eﬀects is overstated in
area multilevel applications that disregard spatial correlation between clusters
(Chaix et al., 2005).
Application of multilevel models from a Bayesian perspective exempli-
ﬁes many of the issues referred to in earlier chapters regarding speciﬁcation
of priors on variance components such as to ensure empirical identiﬁability
and posterior propriety. Devices such as hierarchical centering may reduce
correlation in the joint posterior and increase Markov Chain Monte Carlo
(MCMC) eﬀective sample sizes, and are relevant to both nested and crossed
random eﬀects (Browne, 2004; Gelfand et al., 1995). On the other hand, the
Bayesian approach has beneﬁts in ensuring that uncertainty in variance com-
ponents is fully reﬂected in the posterior inferences on other parameters, such
as cluster eﬀects; this is especially an issue when the number of level 2 units
is small and the likelihood function of level 2 variance parameters may be
asymmmetric (Selzter et al., 1996, 2002). As compared to commonly applied
frequentist approaches (e.g., penalized quasi-likelihood), obtaining variance
estimates of predicted random eﬀects is computationally straightforward in
MCMC approaches. The remaining sections of the chapter consider the nor-
mal linear multilevel model (Section 6.2), general linear and conjugate models
for multilevel discrete data (Section 6.3), crossed factor and multiple member
random eﬀect models (Section 6.4), and robust multilevel models (Section 6.5).
6.2
The Normal Linear Mixed Model
for Hierarchical Data
A multilevel model typically assumes observations to be independent con-
ditional on ﬁxed regression and random eﬀects deﬁned at one or more lev-
els in the data hierarchy. The prototype two level model for a continuous
response, yij, with repetitions j = 1, . . . , ni (e.g., pupils, patients, households)
in clusters i = 1, . . . , m (e.g., schools, hospitals, communities) tackles a simi-
lar scenario to that considered in Chapter 3, but assumes individual observa-
tions to be available rather than cluster averages. Consider observation level
attribute vectors, xij, of dimension p, and zij of dimension q, typically a sub-
vector of xij with q ≤p (Chen and Dunson, 2003).
Then a widely used form of the normal linear mixed model for nested data
(e.g., Snijders and Berkhof, 2002) speciﬁes,
yij = xijβ + zijbi + uij,
(6.1a)
with bi and uij
denoting random cluster eﬀects and observation level
random eﬀects, respectively. The intercept, x1ij = 1, with parameter β1 is

Bayesian Multilevel Models
259
included in xij. With N = m
i=1ni total observations, the nested form of the
model is
y = Xβ + Zb + u,
(6.1b)
where y is N ×1, X ≡
 X1
···
Xm
 
is N ×p, with Xi = (xi1, . . . , xini)′ of dimension
ni × p, and where the N × mq matrix Z is block diagonal with m diagonal
blocks, Zi = (zi1, . . . , zini)′ of dimension ni × q (Gamerman, 1997, 61; Zhao
et al., 2006, 3). Assuming Zi is a subset of Xi, β is a (p×1) vector of population
parameters and bi = (b1i, . . . , bqi)′ is a q×1 vector of zero mean cluster-speciﬁc
deviations around those population parameters, with bi assumed random.
While random eﬀects models oﬀer a way to borrow strength (e.g., when
level 2 cluster sizes, ni, are relatively small), ﬁxed eﬀect models, especially
for varying intercepts are, however, advocated in longitudinal applications,
especially in econometrics. Fixed eﬀects for parameter collections are some-
times used in cross-sectional multilevel applications (Snijders and Berkhof,
2002). The choice between the two depends on the purpose of the statistical
inference and how far the level 2 units can be regarded as a sample from a
policy-relevant population (Draper, 1995). If the sampled clusters are repre-
sentative of (exchangeable with) a wider population, then a random coeﬃcient
model is, in principle, appropriate (Hsiao, 1996). If statistical inference is con-
ﬁned to the particular unique set of level 2 units included in a data set, then
a ﬁxed eﬀects model may be more appropriate.
The conjugate linear normal model with random cluster eﬀects assumes
multivariate normality for these eﬀects and for the observation level errors.
Assuming zij are a subvector of xij, the cluster eﬀects have zero mean, so that,
(b1i, . . . , bqi)′ ∽Nq(0, Σb).
The total impact of xrij in cluster i is then obtained by cumulating over
ﬁxed and random components as βr + bri.
Assume the unstructured level 1 errors, ui = (ui1, . . . , uini)′, have prior
ui ∼Nni(0, Hi), where Hi represents the within-cluster dispersion matrix.
The stacked form of the linear mixed model at cluster level, namely, yi =
Xiβ + Zibi + ui, may then be expressed in joint likelihood form as,
yi
bi

∼Nni+q


Xiβ
ZiΣbZ′
i + Hi
ZiΣb
0
ΣbZ′
i
Σb

,
or in marginal form as,
yi ∼Nni(Xiβ, ZiΣbZ′
i + Hi).
The level 1 errors are typically assumed independent given cluster eﬀects
and regression terms, often with Hi = σ2I for all clusters.
The conjugate model then takes inverse gamma and inverse Wishart priors
for σ2 and Σb, respectively (or gamma and Wishart priors on σ−2 and Σ−1
b ),

260
Applied Bayesian Hierarchical Methods
and common practice is to adopt just proper priors, e.g., σ2 ∼IG(ε, ε),
where ε is small. Recent research shows that such priors can lead to eﬀec-
tively improper posteriors and also that inferences are sensitive to the choice
of hyperparameters (Natarajan and McCulloch, 1998). Alternatives for the
level 1 variance include uniform or half t priors on σ (Gelman, 2006a), while
hierarchical models for Σb are considered by Daniels and Kass (1999) and
Daniels and Zhao (2003).
Following Gamerman (1997, 62), one may sometimes also include randomly
varying predictor eﬀects at observation level,
yij = xijβ + zijbi + wijuij,
which is one way of specifying what is known as complex level 1 variation
or heteroscedasticity related to level 1 attributes (Browne et al., 2002). This
means that variances depend on subject level predictors (when subjects j are
nested in clusters i), or in panel data applications that variances are changing
over time (when times t are nested in subjects i). For categorical wij, one may
equivalently specify complex variation in terms of category-speciﬁc variances.
Thus, Goldstein (2005) considers school exam data, yij (pupils j nested in
schools i), with a single predictor gender, xij (=1 for boy, 0 for girl). Then
level 1 heteroscedasticity can be represented as,
yij = β1 + β2xij + xiju1ij + (1 −xij)u0ij ,
where u0ij ∼N(0, σ2
0) is the prior for girl observation level errors, and u1ij ∼
N(0, σ2
1) is the prior for boy observation errors. Equivalently, setting wij = xij,
yij ∼N(β1 + β2xij, σ2
wij ).
It can be seen that random variation over clusters or at level 1 in
Equation 6.1 raises questions of empirical identiﬁcation (see Chapter 1) as
the ﬁxed regression eﬀects are confounded with the mean of the associated
cluster random eﬀect. Suppose xij = (xﬁj, xhij ) and β = (βf, βh), where xﬁj of
dimension p −q contains predictors where no variation in clusters is posited,
while xhij contains predictors (usually including the constant term) that have a
randomly varying eﬀect over clusters. Under hierarchical centering of the clus-
ter eﬀects, which has been argued to improve MCMC convergence (Gelfand
et al., 1995), varying cluster eﬀects, γri, are centered on βr so that the rth
varying predictor eﬀect is γri = βhr + bri in cluster i. The parameterization
(β, bi) = ([βf, βh], bi) with zero mean bi, is replaced by the parameterization
(βf, γi), where γi = βh + bi. Then,
yij = xijβ + zijγi + uij(= xﬁjβf + xhij γi + uij)
(γ1i, . . . , γqi) ∽Nq(βh, Σγ),
(6.2)
where the vectors zij and xij are now distinct, with xij now containing only
xﬁj, while zij = xhij.

Bayesian Multilevel Models
261
6.2.1
The Lindley–Smith model format
An alternative fully hierarchical presentation of the normal linear multilevel
model (e.g., Candel and Winkens, 2003; Selzter, 1993) is based on the scheme
of Lindley and Smith (1972). It is assumed that all the eﬀects of level 1 pre-
dictor (e.g., pupil characteristics in a two-level educational attainment appli-
cation) vary randomly over clusters, with their variability explained by cluster
predictors, Wi = (w1i, . . . , wri)′ (e.g., school level attributes).
The two level scheme is
yi = Ziβi + ui,
βi = κWi + bi
i = 1, . . . , m,
(6.3)
where yi = (yi1, . . . , yini)′ is ni × 1, κ is q × r, Zi is ni × q, βi is a q × 1 vector
of random cluster regression parameters, and the errors ui = (ui1, . . . , uini)′
have prior uij ∼N(0, σ2). The level 2 regression for βi involves a ﬁxed eﬀect
parameter matrix, κ, and errors bi = (b1i, . . . , bqi)′ with mean zero and dis-
persion matrix, Tb. Substituting the second equation in Equation 6.3 into the
ﬁrst yields the model,
yi = ZiκWi + Zibi + ui.
To constrain the eﬀect of one or more level 1 predictors to have an identical
eﬀect across all clusters, the model may be reformulated as the mixed model
(Equation 6.2).
In Equation 6.3, one may assume ﬂat (uniform) priors for κ, and gamma
and Wishart priors for σ−2 and Tb, namely, 1/σ2 ∼Ga(au, bu), Tb ∼
W(Se, νe). Also deﬁne rij = yij −Zijβi, ˆβi = (Z′
iZi)−1Ziyi, ˜Vi = (σ−2Z′
iZi +
Tb)−1, Vi = σ2Z′
iZi, Λi = (V −1
i
+ Tb)V −1
i
, Ui = (βi −κWi), and G =
[ W ′
iTbWi]−1. Then the full conditionals for Gibbs sampling are
1/σ2 ∼Ga

0.5(au + m), 0.5

bu +
m

i=1
ni

j=1
r2
ij



,
βi ∼Nq

Λiˆβi + (I −Λi)κWi, ˜Vi

,
Tb ∼W

Se +
m

i=1
UiU ′
i, m + νe

,
κ ∼Nr

G
m

i=1
WiTbβi, G

.
Example 6.1. Exam Scores
Hierarchical centering and level 1 complex
variation in a mixed rather than fully hierarchical model are both illustrated
in an educational example concerning 4059 pupils in 65 London schools (the
“clusters” in this application). The response is a (normalized) exam score at
age 16, with predictors being a standardized London Reading Test (LRT) score

262
Applied Bayesian Hierarchical Methods
(obtained at age 11) and gender. The analysis assumes cluster level variation
in intercepts and in the slope of the LRT score, with the eﬀect of gender not
varying by cluster. Cluster variability on the impacts of level 1 predictors is
not related to school attributes. Therefore, this is a mixed model, which in
hierarchical form, as in Equation 6.2, is
yij = xijβf + zijγi + uij,
(γ1i, γ2i) ∽Nq(βh, Σγ),
where xij = (gend) excludes an intercept, and zij = (1, LRT). A Wishart
prior with identity scale matrix and 2 degrees of freedom is assumed for the
cluster precision matrix, Σ−1
γ , and a Ga(1, 0.001) prior for the observation
level precision σ−2. Two analyzes are run, one with σ2 constant over subjects,
and a second with σ2 diﬀering by gender. A pseudo marginal likelihood is used
to assess ﬁt1, with the posterior predictive density p(yrep|y) used for model
checking.
A two chain run of 10,000 iterations1 for the model with σ2 constant pro-
vides early convergence, with psML = −4596.7, and shows a satisfactory check
against the data: 95.2% of the 4059 observations are contained within 95%
intervals of the replicates yij,rep. Random variation over schools is conﬁrmed
by intercept and slope standard deviations (the square roots of the diagonal
terms in Σγ), that are bounded away from zero (MacNab et al., 2005).
The means and 95% intervals for σ1γ and σ2γ are 0.33 (0.27, 0.40) and 0.21
(0.17, 0.25), while the corresponding estimates for the observational standard
deviation are 0.74 (0.725, 0.757). The intercepts and slopes are positively
correlated so that schools with better exam results also show a stronger intake
eﬀect. Introducing complex level 1 variation, namely, gender-speciﬁc variances,
raises the psML only slightly, to −4594.9.
6.3
Discrete Responses: General Linear Mixed Model,
Conjugate, and Augmented Data Models
While conjugate multilevel structures can be developed for discrete responses
such as counts or proportions (see Section 6.3.2), a more ﬂexible approach is
based on the general linear mixed model (GLMM), which extends the linear
normal formulation to discrete outcomes. Thus consider univariate observa-
tions, yij, with repetitions j nested in clusters i, that conditional on cluster
eﬀects, bi, follow an exponential family density,
f(yij|bi) ∝exp
*yijθij −d(θij)
φij
+ c(yij, φij)
+
,
where θij is the canonical parameter, and φij is usually a known scale para-
meter. Additionally, E(yij|θij) = d′(θij) and Var(yij|θij, φij) = d′′(θij)φij.

Bayesian Multilevel Models
263
For example, under the Poisson, d(u) = exp(u) and for binomial data, d(u) =
log(1+eu). Taking the regression terms as ηij = g(θij), where g is a link func-
tion, and denoting ηi = (ηi1, . . . , ηini)′, the observation level model (including
a level 2 regression on cluster attributes) is
ηij = xijβ + zijbi,
bi = κWi + e,
where β and bi are of dimension p and q, respectively.
For Poisson data it is also common to include a residual term, ui =
(ui1, . . . , uini), to model overdispersion, so that
ηij = xijβ + zijbi + uij.
(6.4)
Following Gamerman (1997, 62), one may have observation level predic-
tors, gij, of dimension s with randomly varying eﬀects at observation level. In
this case, uij becomes a random vector, with
ηi = xijβ + zijbi + gijuij.
Assume priors β ∼Np(a, R), bi ∼Nq(0, Σb), and uij ∼Nr(0, Σu), with
inverse Wishart priors Σb ∼IW(νb, Sb) and Σu ∼IW(νu, Su). Then the full
posterior conditional for each bi vector is
p(bi|b[i], β, u, Σb, Σu) ∝exp


−0.5b′
iΣ−1
b bi +
ni

j=1
yijθij −d(θij)
φij


,
while the full conditional for each uij vector is
p(uij|u[ij], b, β, u, Σb, Σu) ∝exp
*
−0.5u′
ijΣ−1
u uij + yijθij −d(θij)
φij
+
.
Additionally, the covariance matrices have inverse Wishart full condition-
als, namely,
Σb ∼IW

νb + m, Sb +
m

i=1
bib′
i

,
Σu ∼IW

νu +
m

i=1
ni, Su +

i,j
uiju′
ij

.
The GLMM approach extends to multilevel multinomial observations in a
choice setting (e.g., brand, political party),
(dij1, . . . , dijK) ∼Mult(1, [pij1, . . . , pijK]),
with probability, πijk, that option k is chosen by subject j in cluster i, namely,
that yij = k (or dijk = 1) where options are unordered. A particular choice

264
Applied Bayesian Hierarchical Methods
(k ∈1, . . . , K) for subject j in cluster i results from comparing the latent
utilities of all options (ηij1, . . . , ηijK), with,
pijk = Pr(yij = k) = Pr(ηijk > ηijm),
m ̸= k,
where ηijk include systematic eﬀects and random errors, εijk. Suppose the
errors follow a Gumbel (extreme value type I) density, namely, P(ε) =
exp(−ε −exp(−ε)), then since diﬀerences between Gumbel errors follow a
standard logistic distribution, the choice probabilities reduce to the multino-
mial logit (Hedeker, 2003, 1439). Predictors in the systematic term may be
deﬁned at option-subject or at option level, but consider subject level predic-
tors xij and zij (e.g., voter age) of respective dimensions p and q that may
vary according to cluster i. Then with the ﬁnal category as a reference, ﬁxed
eﬀect parameters and random eﬀects are speciﬁc to choices k, with K −1 sets
of random eﬀects, bik, each of dimension q,
Pr(yij = k) =
exp(αk + xijβk + zijbik)
1 + K−1
h=1 exp(αh + xijβh + zijbih)
Pr(yij = K) =
1
1 + K−1
h=1 exp(αh + xijβh + zijbih)
k = 1, . . . , K −1.
The bi = (bi1, . . . , bi,K−1) are zero mean eﬀects, typically assumed multi-
variate normal.
6.3.1
Augmented data multilevel models
Another option for multilevel binary and multinomial responses is to intro-
duce augmented metric data, y∗
ij, with sampling constrained according to the
observed yij, and apply the linear mixed model to y∗
ij. The data augmentation
density depends on the assumed link. Thus, a logit link for two level binary
data implies truncated standard logistic sampling to generate the augmented
data, namely,
y∗
ij ∼Logistic(ηij, 1)I(Aij, Bij),
where Aij = −∞or 0, and Bijk = 0 or ∞, according as yij = 0 or 1. As
mentioned in Chapter 5, data augmentation leads to simpler MCMC sampling
and improved residual tests. In a multilevel setting, it may further assist in
assessing variance partitioning. Consider a regression with a random level 2
intercept,
ηij = xijβ + bi,
where bi ∼N(0, σ2
b). Since the variance of the standard logistic is π2/3, the
intraclass correlation at level 2 may be obtained as σ2
b/(σ2
b +π2/3), and moni-
tored over MCMC iterations. Moreover, if the composite ﬁxed eﬀect term, xijβ,

Bayesian Multilevel Models
265
is monitored and its posterior variance, ˜σ2
F , obtained, one may obtain a pro-
portion of variance explained as ˜σ2
F /[˜σ2
F +˜σ2
b +π2/3], where ˜σ2
b is the posterior
mean of σ2
b.
For multilevel ordinal outcomes with K levels, the observation,
(dij1, . . . , dijK) ∼Mult(1, [pij1, . . . , pijK]),
provides information about an underlying metric variable, y∗
ij, deﬁned by cut-
points such that,
yij = k (dijk = 1)
if κk−1 < y∗
ij ≤κk for k = 1, . . . , K,
where κ0 = −∞and κK = ∞, and by a corresponding hierarchical linear
regression in the latent variables,
y∗
ij = xijβ + zijbi + εij.
If xij
excludes an intercept, there are K −1 unknown cutpoints
(κ1, . . . , κK−1), with yij = 1 if y∗
ij ≤κ1, yij = 2 if κ1 < y∗
ij ≤κ2, etc.,
and yij = K if y∗
ij > κK−1. A standard logistic density for εij with mean 0,
variance π2/3, and distribution function F(ε) = (exp(ε)/1 + exp(ε)) leads to
a logit link for the cumulative probabilities,
∆ijk =
k

m=1
pijm = Pr(y∗
ij ≤κk) = Pr(yij ≤k),
k = 1, . . . , K −1,
with pijK = 1 −K−1
m=1pijm.
Taking εij ∼N(0, 1) corresponds to a probit link for ∆ijk. For ε logistic,
the hierarchical regression is expressed as follows,
∆ijk = Pr(xijβ + zijbi + εij ≤κk)
= Pr(εij ≤κk −xijβ −zijbi)
=
exp(κk −xijβ −zijbi)
1 + exp(κk −xijβ −zijbi),
that is,
logit(∆ijk) = κk −xijβ −zijbi.
6.3.2
Conjugate cluster eﬀects
An alternative to GLLMs for count and binomial data, is provided by con-
jugate random eﬀects at diﬀerent levels. For example, for two level Poisson
data, yij ∼Po(µij), a conjugate hierarchical model is a nested gamma mixture
model, as in Lee and Nelder (2000), namely,
µij = exp(xijβ)ρiρij,

266
Applied Bayesian Hierarchical Methods
where ρi and ρij are both gamma distributed with mean 1. Daniels and
Gatsonis (1999) also consider hierarchical conjugate priors for overdispersed
data following densities from the one-parameter exponential family (e.g.,
Poisson, binomial) and assume both cluster-speciﬁc regression eﬀects and
scale parameters. For binomial data, yij ∼Bin(Tij, pij), Daniels and Gatsonis
(1999, 32) assume pij to be beta with means πij, and cluster-speciﬁc scale
parameters δi. With a logit link to predictors, and level 2 regression involving
cluster level predictors, Wi, one has,
pij ∼Be(πijδi, (1 −πij)δi),
logit(πij) = xijβ + zijbi,
bi = κWi + ei.
To provide robustness (e.g., to outlier clusters), the ei are taken as Stu-
dent t distributed (see Section 6.5). The prior on δi has the form,
p(δi) ∝
δi
(hi + δi)2 ,
where hi = minj∈1,...,ni(Tij). A Metropolis–Hastings step is needed for log(δi).
For Poisson data, one has yij ∼Po(oijθij), where oij is an oﬀset for the
expected response, and θij ∼Ga(µijδi, δi). The regression model then involves
a log link for the µij,
log(µij) = xijβ + zijbi.
More specialized models apply for particular data structures. For example,
Van Duijn and Jansen (1995) suggest a model for repeated counts (e.g., tests
j = 1, . . . , ni within students i = 1, . . . , m) with Poisson means,
µij = νiδij,
and gamma distributed student ability eﬀects, νi ∼Ga(a1, a2), where a1
and a2 are additional parameters, and δij represent subject-speciﬁc diﬃculty
parameters for tests j, with identiﬁability constraint 
jδij = 1, and prior,
(δi1, . . . , δij) ∼Dir(ξ1, . . . , ξJ),
where ξj are also unknowns. If the subjects fall into known (or possibly
unknown) groups, k = 1, . . . , K, with allocation indicators, Si ∈(1, . . . , K),
then a more general model speciﬁes,
(νi|Si = k) ∼Ga(a1k, a2k).
A conjugate structure for stratiﬁed area health counts is considered by
Dean and McNab (2001). Thus for micro areas, j = 1, . . . , ni, nested within
larger areas, i = 1, . . . , m, let µ be an average event rate across all m areas

Bayesian Multilevel Models
267
and Tij be populations at risk. Assume ﬁrst, cluster level overdispersion rep-
resented by eﬀects ρi, so that yij ∽Po(µTijρi), where ρi have mean 1 and
let the mean and variance of yi+ be Ti+µ and Ti+µ(1 + σ2
ρ). Under gamma
mixing,
ρi ∽Ga

Ti+µ
σ2ρ
, Ti+µ
σ2ρ

,
with variance σ2
ρ/(Ti+µ). The interpretation is that ρi represents the average
relative risk over the Ti+ individuals in area i. An extended model considers
both micro area and cluster level overdispersion with micro area eﬀects, ρ2ij,
which given ρ1i ∽Ga(Ti+µ/σ2
1, Ti+µ/σ2
1), are themselves also gamma with
prior,
ρ2ij ∽Po

Tijρ1iµ
σ2
2
, Tijρ1iµ
σ2
2

.
Then E(yij|ρ1i) = ρ1iTijµ and V (yij|ρ1i) = Tijµρ1i(1 + σ2
1), while
marginally E(yij) = Tijµ and
V (yij) = Tijµ

(1 + σ2
2) + Tij
Ti+
σ2
1

.
Example 6.2. Modern Prenatal Care
This example illustrates multi-
level GLMM and augmented data methods applied to three level binary data,
namely, the use of modern prenatal care among Guatemalan women using
some form of prenatal care. The analysis is based on 2449 births (born in a
ﬁve-year period before the survey) to 1558 mothers living in one of m = 161
communities. The predictor variables are at all levels, namely, communities i
at level 3, mothers ij at level 2, and pregnancy episodes ijk at level 1, and
denoted Xi, Xij, and Xijk, respectively. The predictors include at level 3:
proportion of community population indigenous and distance to the nearest
clinic; at level 2: mother’s ethnicity, mother’s education, husband’s educa-
tion, husband’s occupation, and presence of a modern toilet; and at level 1:
(existing) child’s age, mother’s age, and birth order.
Then with yijk ∼Bern(pijk), the GLMM model used by Rodriguez and
Goldman (2001) speciﬁes random intercept variation at both levels 2 and 3,
which is according to both mother and community. Using a noncentered pa-
rameterization and logit link, one has,
logit(pijk) = α + bi3 + bij2 + Xiβ3 + Xijβ2 + Xijkβ1,
where bi3 are normal community level eﬀects, bi3 ∼N(0, σ2
3), and bij2 ∼
N(0, σ2
2) are mother level eﬀects2. In a WinBUGS application, convergence is
achieved by iteration 2500 in a two chain run of 5000 iterations. The posterior
summary based on the second half of the run (Table 6.1) shows similar results
to those obtained by Rodriguez and Goldman (2001). A BayesX application

268
Applied Bayesian Hierarchical Methods
TABLE 6.1
Modern pregnancy advice.
Fixed eﬀects
Mean
2.5%
97.5%
Intercept
5.46
1.60
10.82
Pregnancy level
Child aged 3–4 years
−1.35
−2.18
−0.64
Mother aged >25 years
1.31
0.09
2.57
Birth order 2–3
−1.04
−2.20
0.02
Birth order 4–6
−0.60
−2.07
0.89
Birth order >7
−1.40
−3.59
0.63
Mother level
Indigenous, no Spanish
−8.32
−13.37
−4.03
Indigenous Spanish
−4.29
−8.54
−1.44
Mother’s education primary
2.49
0.76
4.61
Mother’s education secondary
5.52
1.22
10.73
Husband’s education primary
0.89
−0.96
2.85
Husband’s education secondary
4.51
0.66
8.41
Husband’s education missing
−0.18
−3.16
2.70
Husband professional etc.
−0.47
−5.08
3.94
Husband agricultural self-employed
−2.58
−6.50
0.94
Husband agricultural employee
−3.66
−8.20
−0.16
Husband skilled service
−1.17
−5.00
2.57
Modern toilet in households
2.70
−0.06
5.64
Television not watched daily
2.26
−1.38
6.35
Television watched daily
2.16
−0.10
4.59
Community level
Proportion indigenous, 1981
−6.09
−11.22
−0.73
Distance to nearest clinic
−0.07
−0.13
−0.02
Random eﬀects (standard deviations)
Family
10.22
7.40
13.23
Community
5.55
3.87
7.46
Reference categories for ﬁxed eﬀects: child aged 0–2 years, mother aged un-
der 25, birth order 1, Ladino, mother no education, husband no education,
husband not working or unskilled occupation, no modern toilet in the house-
hold, and no television in the household.
provides similar results for ﬁxed eﬀects, but mother and community variances
have higher posterior means (117 and 34, compared to 104 and 31 from the
WinBUGS analysis). Alternative model options that might be considered are
(a) community variation in level 2 and level 1 predictor eﬀects, (b) maternal
variation in level 1 predictor eﬀects, and (c) random eﬀect priors allowing
non-normality.
Note that the same results are obtained (and left as an exercise) by con-
sidering the observed 0 or 1 as arising from an underlying continuous variable,

Bayesian Multilevel Models
269
y∗
ijk, so that 1 is observed when a certain threshold is exceeded, otherwise 0 is
observed. A logit link means the sampling mechanism,
y∗
ijk ∼Logistic(ηijk, 1)I(Aijk, Bijk),
where Aijk = −∞or 0 (and Bijk = 0 or ∞) according as yijk = 0 or 1. It
follows that the intraclass correlation at level 2 may be obtained as σ2
2/(σ2
2 +
π2/3), because the variance of the standard logistic is π2/3.
Example 6.3. Ordinal Three Level Model Hedeker et al. (1994) under-
take a two level analysis of a data subset from the Television School
and Family Smoking Prevention and Cessation Project (Flay et al., 1987).
Schools included in the project were randomized to one of four categories,
deﬁned by the presence or absence of a TV intervention (TV), and by the
presence or absence of a social-resistance classroom curriculum (CC). One
outcome measure from the project was a tobacco and health knowledge
(THK) score obtained as the total correct answers to seven items on to-
bacco and health knowledge. The response variable is the postintervention
THK score collapsed into K = 4 ordinal categories, with predictors being a
pre-intervention THK score, the binary intervention variables TV and CC,
and a CC by TV interaction.
The analysis is three level, with schools i = 1, . . . , m at level 3 (with
m = 28), and classrooms j within schools at level 2. With responses yijk ∈
(1, . . . , H), where H = 4, for subjects k = 1, . . . , nij in each class, consider a
logit model for the cumulative probabilities,
∆ijkh = Pr(yijk ≤h),
with two sets of higher level errors, namely, level 3 random errors u3i with
variance σ2
3, and level 2 class errors u2ij with variance σ2
2 (pertaining to eﬀects
of classrooms within schools). Then,
logit(∆ijkh) = κh −µijk,
µijk = xijkβ + u3i + u2ij
h = 1, . . . , H −1,
with N(0, 1000) priors on ﬁxed eﬀects and U(0, 1000) priors on the random
eﬀect standard deviations3.
A two chain run of 5000 iterations with 500 for convergence gives posterior
means for the cutpoints (κ1, κ2, κ3) of −0.09, 1.2, and 2.4, with a signiﬁcant
coeﬃcient of 0.89 on the curriculum intervention, but no signiﬁcant eﬀects for
TV or the interaction term. The posterior means for σ2 and σ3 are 0.41 and
0.28 with densities bounded away from zero. By contrast, a maximum like-
lihood analysis using numerical quadrature reported by Rabe-Hesketh et al.
(2004) ﬁnds an insigniﬁcant school variance. The analysis can also be carried
out using the latent data approach, which may be useful for obtaining intra-
class correlations or for model checking. This produces larger estimates of σ2
and σ3, namely, 0.60 and 0.38, but similar ﬁxed predictor eﬀects.

270
Applied Bayesian Hierarchical Methods
6.4
Crossed and Multiple Membership
Random Eﬀects
Crossed random eﬀects at level 2 and above occur when classiﬁcations in a
model are not completely nested. For a two level example, let i denote the main
level 2 nesting classiﬁcation and hij denote a crossed nesting. Raudenbush
(1993), Browne et al. (2001, Section 3.2), and Snijders and Bosker (1999)
mention educational examples, namely, pupils classiﬁed by primary school,
i, and by secondary school, hij, or pupils classiﬁed by school, i, and neigh-
borhood, hij. In the latter situation, a school can draw pupils from multiple
neighborhoods, and residents in a neighborhood can choose between multi-
ple schools for their children. By extension, if pupils are classiﬁed by pri-
mary school, secondary school, and neighborhood, then two crossed nestings
(denoted say as h1ij and h2ij) will be involved. An important issue is the
relationship between the crossed classiﬁcations since they may not be indepen-
dent, and introducing extra crossed factors will typically reduce the variance
explained by the main level 2 nesting.
A straightforward extension of the normal linear mixed model to account
for a single extra crossed factor is to add varying intercepts and slopes accord-
ing to that extra factor. Assuming hij varies between 1 and H, then adapting
Equation 6.1 format for zij of dimension q,
yij = xijβ + zij(bi + chij ) + uij,
where
(b1i, . . . , bqi) ∽Nq(0, Σb)
i = 1, . . . , m,
(ch1, . . . chq) ∽Nq(0, Σc)
h = 1, . . . , H.
Alternatively, variation over the extra crossed factor may be applied to
a diﬀerent predictor than those subject to random variation over the main
level 2 classiﬁcation. Often the additional random eﬀects would be conﬁned
to intercept variation over the extra crossed factor, so that with q = 1 and
zi1 = 1 also, one has,
yij = xijβ + bi + chij + uij.
In these situations the random eﬀects are confounded and empirical identi-
ﬁcation may be impeded. Selection between random eﬀects may well be needed
(Browne et al., 2001).
Another possible source of variation in crossed models is deﬁned in cells
formed by cross-classiﬁcation of two or more higher level factors. For ex-
ample, N patients living in a particular administrative health district may
be classiﬁed into subpopulations, s, based on intersections of their primary
care general practitioner, i1 = 1, . . . , m1, and small area of residence, i2 =
1, . . . , m2 (Congdon and Best, 2000). Often there may be no subjects in certain

Bayesian Multilevel Models
271
combinations of higher level factors. So deﬁne total nonempty cells as Sn, equal
to or less than the total, S = m1m2, of all possible combinations, with dif-
ferent values, s = 1, . . . , Sn, deﬁned by cross-hatched factor identiﬁers [i1, i2].
Let r = 1, . . . , N denote a single string subject level identiﬁer. Subjects will be
classiﬁed by subpopulation, sr ∈{1, . . . , Sn}, by higher level factor 1 classiﬁ-
cation indicator, h1r (general practitioner), higher level factor 2 classiﬁcation
indicator, h2r (small area of residence), and so on. Random intercept variation
in a metric response over the two factors and the cells then takes the form,
yr = xrβ + zr(α1,h1r + α2,h1r + ηsr) + ur,
(6.5)
where α1i1, α2,i2, ηs, and ur are random eﬀects.
Multiple membership schemes are a generic weighting scheme applicable to
cross-classiﬁed data (Browne et al., 2001), and may be illustrated by the case
where subjects at level 1 may belong to more than one level 2 unit. Suppose
a pupil’s entire primary school career is of interest, then there may be moves
between schools. Multiple aﬃliations then need to be taken account of in terms
of school impacts on attainment. Another example is analysis of neighborhood
health eﬀects to take account of changes in residence (Subramanian, 2004).
Suppose there are m level 2 units (clusters such as schools) that are included
in the analysis, and that subjects j = 1, . . . , J (not taken to be nested within
schools) have Kj level 2 aﬃliations with weights {wj1, wj2, . . . , wjKj}, where
Kj
k=1wjk = 1. The weights would in many situations be taken as known (e.g.,
based on number of terms spent by a pupil in diﬀerent schools). Then for pupil
level predictors, zj, of dimension q not varying over aﬃliations, the normal
linear mixed model becomes,
yj = xjβ + zj
Kj

k=1
wjkbk + uij,
where (b1i, . . . , bqi) ∽Nq(0, Σb), i = 1, . . . , m. If the pupil predictors vary over
aﬃliations, then,
yj = xjβ +
Kj

k=1
wjkzjkbk + uj.
Multiple member schemes extend to data frames that are structured spa-
tially or temporally rather than nested. A particular kind of multiple member
prior can be applied to spatially conﬁgured count responses, yi, subject to
random intercept variation. Thus, let yi ∼Po(oiµi), where oi are expected
events, and where µi measure the Poisson intensity relative to expected levels
(in spatial health applications, µi are termed relative risks). Then the impact
of neighboring areas can be represented by random eﬀects, bk, while own area
eﬀects are represented by eﬀects, ui, in a model,
log(µi) = xiβ +
Ki

k=1
wikbk + ui,

272
Applied Bayesian Hierarchical Methods
where wik are row standardized with Ki
k=1wik = 1. They might be based
on binary spatial interactions, cik (cik = 1 if areas i and k are contiguous,
cik = 0 otherwise), or based on distances, dik, between area centers, such as
cik = exp(−ηdik) where η is positive; then,
wik = cik
, Ki

k=1
cik.
Example 6.4. Educational Attainment and Neighborhood Garner
and Raudenbush (1991) consider attainment data from a Scottish education
authority with R = 2310 pupils classiﬁed by crossed factors (neighborhood and
secondary school). Some neighborhoods send pupils to multiple schools, while
some schools draw pupils from multiple neighborhoods. They consider eﬀects
of the “place variable,” namely, neighborhood social deprivation, in reducing
educational attainment after controlling for the impacts on attainment of pupil
level attributes (pupil aptitude and family background). Their data involves
m1 = 524 neighborhoods and m2 = 17 schools with child-speciﬁc predictors
being gender (1 = M, 0 = F), and a verbal reasoning quotient (VRQ) and a
reading test score (RTS) both obtained when the child was at primary school;
parent-speciﬁc predictors are the father’s status (metric) and three binary in-
dicators (whether the father was educated beyond age 15, whether the mother
was educated beyond 15, and whether the father was unemployed).
Two models are considered. In the ﬁrst there are random eﬀects for both
neighborhoods and schools, with varying neighborhood eﬀects linked to social
deprivation. Let h1r and h2r denote neighborhood and school for pupils,
r = 1, . . . , R. Uniform U(0, 1000) priors are adopted on neighborhood, school,
and pupil random eﬀect standard deviations in the model,
yr = xrβ + α1,h1r + α2,h2r + ur,
α1i1 ∼N(β1 + γDepi1, σ2
1)
i1 = 1, . . . , m1,
α2i2 ∼N(0, σ2
2)
i2 = 1, . . . , m2,
Ur ∼N(0, σ2
3),
with xr excluding a constant term4. The second half of a two chain run of 5000
iterations shows pupil variation, σ2
3, to be more substantial than school varia-
tion, σ2
2, and shows a negative deprivation eﬀect γ (with mean −0.156 and 95%
interval from −0.206 to −0.107). Area eﬀects act to signiﬁcantly reduce school
variation. Predictor eﬀects are close to those cited by Raudenbush (1993, 335).
A second model allows the deprivation eﬀect to vary by school—expressing
varying eﬀectiveness in schools countering catchment area eﬀects (also known
as contextual value added eﬀects). There are now four random variances, with
yr = xrβ + α1,h1r + α2,h2r + γh2rDeph1r + ur,
α1i1 ∼N(β1, σ2
1),
α2i2 ∼N(0, σ2
2),
γi2 ∼N(Γ, σ2
3),
ur ∼N(0, σ2
4).

Bayesian Multilevel Models
273
In fact, this model has a very similar psML (around −2398) to the ﬁrst
model. The school deprivation eﬀects, γi2, on attainment have a mean −0.16,
and vary from −0.178 (−0.31, −0.09) for school 11 to −0.132 (−0.20, −0.02)
for school 9. Their standard deviation is 0.037.
6.5
Robust Multilevel Models
Under normality assumptions regarding errors at diﬀerent levels, extreme data
points can inﬂuence estimates of ﬁxed eﬀect and variance component param-
eters and reduce the precision of estimates (e.g., widen the width of credible
intervals). Sensitivity of the level 2 ﬁxed eﬀect estimates, κ, to alternative
assumptions regarding the prior on level 2 eﬀects, bi, in Equation 6.3 is the
focus of Selzter (1993). Estimates of level 2 random cluster eﬀects may also
be sensitive when level 2 normality of eﬀects is assumed (Selzter et al., 1996,
137). For a two level model, outliers may occur both in level 2 cluster eﬀects
and in level 1 within-cluster errors (Langford and Lewis, 1998; Pinheiro et al.,
2001), and the two sources may be confounded. For example, a discordant
school eﬀect might be due to a systematic eﬀect across all pupils or because
a few pupils in the school are responsible for the discrepancy. Selzter et al.
(2002) investigate how level 1 outliers aﬀect estimation of ﬁxed eﬀect regres-
sion parameters and inferences regarding level 2 cluster eﬀects (e.g., treatment
contrasts for individual clusters) in two level models for continuous outcomes.
Robust alternatives to the normal linear mixed model based on the t den-
sity have been proposed by Pinheiro et al. (2001) and Staudenmayer et al.
(2009), and shown to outperform Gaussian error assumptions when outliers
are present in multilevel data. Daniels and Gatsonis (1999, 31) assume multi-
variate t random eﬀects at level 2 by default in a GLMM, while Selzter et al.
(1996) present Gibbs sampling steps for the linear mixed model case where
a multivariate t with a single degrees of freedom parameter is assumed for
level 2 random eﬀects. Seltzer et al. (2002) adopt Student t priors at both lev-
els and apply a U(0, 1) prior to sample from a discrete grid of values on the
degrees of freedom parameter. Thus, for an equally spaced grid of potential
values {2.1, 2.2, 2.3, . . . , 49.9} with equal prior probabilities, the cumulative
probability, Pr(ν = 2.1) + Pr(ν = 2.2) + · · · , is calculated for each point and
the U(0, 1) draw determines which is sampled.
Following the Pinheiro et al. (2001) scheme, assume a gamma-normal hier-
archical representation with si ∼Ga(0.5ν, 0.5ν), and also that ei ∼Nq(0, I).
Then for continuous responses, yi = (yi1, . . . , yini)′, a level 2 assumption of t
distributed random eﬀects, bi = (b1i, . . . , bqi)′, with dispersion Σb leads to,
yi = Xiβ + Zibi + ui,
bi = κWi + Σ0.5
b ei/√si,
i = 1, . . . , m.

274
Applied Bayesian Hierarchical Methods
For outlier clusters with low si, the overall dispersion, Σb/s2
i , is inﬂated,
but the ﬁxed eﬀect, κ, will be less distorted than under normal level 2 errors.
The degrees of freedom parameters of the level 2 multivariate t prior may
be taken to vary between clusters, namely,

yi
bi

∼tni+q

Xiβ
0 ,

ZiΣbZ′
i + Λi
ZiΣb
ΣbZ′
i
Σb

, νi

.
or under a gamma-normal hierarchical representation,

yi
bi

∼Nni+q

Xiβ
0 ,
1
si

ZiΣbZ′
i + Λi
ZiΣb
ΣbZ′
i
Σb

,
where si ∼Ga(0.5νi, 0.5νi). The si can then be used for identifying cluster
outliers. An alternative to assuming cluster-speciﬁc degrees of freedom is to
take νi = νgi, according to a known or possibly unknown grouping variable,
gi ∈(1, . . . , G), applicable to clusters, for example, type of school in an edu-
cational application. Then {ν1, . . . , νG} may be extra parameters. The level 1
random prior may be speciﬁed as ui ∼tni(0, Λi, νhi), where hi is another
grouping indicator that may be the same as gi.
Discrete mixtures of random eﬀects are also possible for outlier accommo-
dation, modeling non-normality or other asymmetry in random eﬀects. Latent
mixtures of regression eﬀects may also be present: Muth´en and Asparouhov
(2009) show how latent regression classes may be misrepresented as ran-
dom cluster variation. To detect outlier random eﬀects, Daniels and Gatsonis
(1999, 36) adapt the approach of Albert and Chib (1997) in their models
for hierarchical conjugate priors for discrete data. For nested binomial data,
yij ∼Bin(nij, pij), a mechanism to detect level 1 outliers may be speciﬁed
with pij drawn for a two group mixture of beta densities both with means πij.
For the main group, the dispersion parameters are δi, while for the outlier
group they are deﬂated as δi/K, where K ≫1. Then,
pij ∼(1 −λ)Be(πijδi, (1 −πij)δi) + λBe

πij
δi
K , (1 −πij) δi
K

.
If the outlier probability λ is preset to a low value (e.g., λ = 0.05), then K
might be taken as an extra parameter. Weiss et al. (1999) suggest a similarly
motivated prior for mixtures of normal random eﬀects at levels 1 and 2 in
Equations 6.1 and 6.3, namely,
bi ∼(1 −λb)Nq(0, Σb) + λbNq(0, KbΣb),
uij ∼(1 −λu)N(0, σ2
u) + λuN(0, Kuσ2
u).
An alternative mixture prior to reduce the impact of parametric assump-
tions is the mixture of Dirichlet process approach (Guha, 2008; Kleinman and
Ibrahim, 1998). Thus, a conventional ﬁrst stage likelihood,
yi ∼N(Xiβ + Zibi, σ2),

Bayesian Multilevel Models
275
may be combined with a semiparametric approach for bi = (b1i, . . . , bqi)′,
typically with a multivariate normal base G0 as in,
bi ∽G,
G ∽DP(α, G0),
G0 = Nq(0, D),
D−1 ∼Wish(d0, R0).
Gibbs sampling for D−1 is modiﬁed for clustering among the sampled bi
(Kleinman and Ibrahim, 1998, 94).
Example 6.5. Police Stops and Ethnicity
Gelman and Hill (2006) pre-
sent multilevel Poisson regression analysis of counts, yij, of “stop and frisk”
over a 15-month period in 1998–1999. For each of m = 75 New York
police precincts, counts are disaggregated both by ethnic group (1 = black,
2 = hispanic, 3 = white), and crime type (1 = violent, 2 = weapons, 3 =
property, 4 = drug), so that there are j = 1, . . . , ni observations, with ni = 12,
for each precinct i. These 12 categories are called classes here. As an oﬀset
oij, Gelman and Hill suggest arrests by precinct, ethnicity, and type in 1997
(multiplied by 15/12); in fact, oij + 1 is used instead since some arrest counts
are zero.
Here, an initial GLMM with log link estimates ﬁxed ethnicity eﬀects and
random errors at both precinct and precinct-class level, the latter introduced
to account for overdispersion, while the former measures overall crime levels
in a precinct. So, yij ∼Po(µij[oij + 1]) with,
log(µij) = βethij + bi + uij,
uij ∼N(0, σ2
u),
bi ∼N(0, σ2
b).
With yij,rep denoting replicate data sampled from the model, predictive
checks involve the underprediction criterion, Pr(yij ≥yij,rep|y) (Daniels and
Gatsonis, 1999), and the log(CPO), with overall ﬁt measured by the expected
predictive deviance (EPD) and log(psML). The signiﬁcance of individual bi is
assessed using the probabilities, Pr(bi > 0|y).
With U(0, 100) priors on the random standard deviations, the last 7000
of a two chain run of 10,000 iterations5 produce a mean scaled deviance of
898, so extravariation is accounted for, while the maximum and minimum
underprediction probabilities are 0.92 and 0.25. The ethnic coeﬃcients have
95% intervals (−0.87, −0.56), (−0.80, −0.55), and (−1.26, −0.97), so whites
have lower chances of being subject to “stop and frisk.” Despite the pres-
ence of precinct-cell errors (which might reduce the need for separate precinct
eﬀects), a relatively high number (29) of the precinct eﬀects, bi, are signif-
icant in the sense that the probabilities, Pr(bi > 0|y), exceed 0.95 or are
under 0.05.

276
Applied Bayesian Hierarchical Methods
–4
–2
0
2
4
Observed value
–4
–2
0
2
4
Expected normal value
FIGURE 6.1
Normal Q–Q plot of b[i].
–4
–2
0
2
4
Observed value
–4
–2
0
2
4
Expected normal value
FIGURE 6.2
Normal Q–Q plot of u[i, j].
Of interest in terms of the robustness of the model assumptions are
the characteristics of the posterior estimates of bi and uij. A normal
Q–Q plot for the posterior means of the standardized zb
i = bi/σb from the
ﬁrst model suggests no major departure from normality (Figure 6.1), and the
same applies for zu
ij = uij/σu (Figure 6.2). However, for illustrative purposes,
a discrete mixture prior is adopted for the uij, namely,

Bayesian Multilevel Models
277
Precinct effects
–2.00
–1.50
–1.00
–0.50
0.00
0.50
1.00
0
2
4
6
8
10
12
14
Frequency
FIGURE 6.3
Random eﬀects (Posterior means) under MDP prior.
uij ∼λN(0, σ2
u) + (1 −λ)N(0, σ2
uK),
K = K′ + 1;
K′ ∼U(0, 9);
λ ∼Be(19, 1),
where the prior on λ favors a low outlier probability (1 −λ), and the prior
on the inﬂation factor K speciﬁes values between 1 and 10. This model has
delayed convergence, but the second half of a two chain run of 50,000 itera-
tions provides an estimated λ of 0.98, with K = 3.6. The ethnic coeﬃcients
are slightly enhanced with 95% intervals (−1.03, −0.68), (−0.88, −0.57), and
(−1.40, −1.10). The psML is −3873 compared to −3923 for the ﬁrst model
considered (an estimate also based on the second half of a run of 50,000 iter-
ations). Figure 6.3 plots precinct eﬀects under this model.
Appendix: Computational Notes
1. In Example 6.1, the code uses a stacked data form with h ≡[ij] and
h = 1, . . . , N, where N = m
i=1ni. Both options for the observational variance
are included, so one or other must be commented out:
model { for (i in 1:4059) {
# constant observational variance (option 1)
y[i]∼dnorm(mu[i],tau); yrep[i]∼dnorm(mu[i],tau)

278
Applied Bayesian Hierarchical Methods
LL[i] <- -0.5*tau*(y[i]-mu[i])*(y[i]-mu[i])+0.5*log(tau/6.28);
mu[i] <- gam[sch[i],1]+gam[sch[i],2]*LRT[i]+beta[3]*gend[i]}
# complex observational variance (option 2)
# y[i]∼dnorm(mu[i],tau.cx[gend[i]+1]); yrep[i]∼dnorm(mu[i],tau.cx[gend[i]
+1])
# LL[i] <- -0.5*tau.cx[gend[i]+1]*(y[i]-mu[i])*(y[i]-
# mu[i])+0.5*log(tau.cx[gend[i]+1]/6.28)
# Other priors
for (j in 1:65) {gam[j,1:2] ∼dmnorm(beta[1:2],T.gam[,])
for (k in 1:2) {gamr[k,j] <- gam[j,k]}}
T.gam[1:2,1:2]∼dwish(Q[,],2); tau∼dgamma(1,0.001);
# inverse LKD node for CPO estimation
for (i in 1:4059) {G[i] <- 1/exp(LL[i])}
for (j in 1:2) {tau.cx[j]∼dgamma(1,0.001); sig.cx[j] <- 1/sqrt(tau.cx[j])}
Sigma.gam[1:2,1:2] <- inverse(T.gam[,]); sigobs <- sqrt(1/tau)
r.gam <- Sigma.gam[1,2]/(sigclus[1]*sigclus[2]);
for (j in 1:2) {sigclus[j] <- sqrt(Sigma.gam[j,j])
for (k in 1:2) {Q[j,k] <- equals(j,k)}}
for (j in 1:3) {beta[j]∼dnorm(0,0.001)}}
2. The GLMM logit code in Example 6.2 adopts Uniform U(0, 100) priors
on the random eﬀect standard deviations and normal priors with variance
1000 on the ﬁxed eﬀects. The code uses a stacked data form ith h ≡[ijk],
namely,
model { for (h in 1:2449) {y[h]∼dbern(p[h])
logit(p[h]) <- alph+b3[comm[h]]+b2[mom[h]]
+beta1[1]*kid3p[h]+beta1[2]*mom25p[h] +beta1[3]*ord23[h]+beta1[4]*
ord46[h]
+beta1[5]*ord7p[h]+beta2[1]*indNS[h]+beta2[2]*indS[h]
+beta2[3]*momPr[h]+beta2[4]*momSc[h]+beta2[5]*husPr[h]+beta2[6]*
husSc[h]
+beta2[7]*husDK[h]+beta2[8]*Prof[h]+beta2[9]*AgrS[h]+beta2[10]*
AgrE[h]
+beta2[11]*Sk[h]+beta2[12]*toi[h]
+beta2[13]*tvND[h]+beta2[14]*tvD[h] +beta3[1]*Ind81[h]+beta3[2]*
ssDist[h]}
alph ∼dnorm(0,0.001)
for (m in 2:3) {sig[m] ∼dunif(0,100); tau[m] <- 1/pow(sig[m],2)}
for (i in 1:161) {b3[i]∼dnorm(0,tau[3])}
for (j in 1:1558) {b2[j]∼dnorm(0,tau[2])}
for (a in 1:5) {beta1[a] ∼dnorm(0,0.001)}
for (a in 1:14) {beta2[a] ∼dnorm(0,0.001)}
for (a in 1:2) {beta3[a]∼dnorm(0,0.001)}}.

Bayesian Multilevel Models
279
The BayesX code for this example is
dataset d
d.inﬁle, maxobs=5000 using data\prenatal.txt
bayesreg b
b.regress y = mom(random)+comm(random)+kid3p+mom25p+ord23+
ord46+ord7p+indNS+indS+momPr+momSc+husPr+husSc+husDK+Prof+
AgrS+AgrE+Sk+toi+tvND+tvD+Ind81+ssDist,
family=binomial
predict
using d
3. The code for the ordinal logit analysis in Example 6.3 again assumes stacked
data with composite indicator, h ≡[ijk]. The code is
model { for (h in 1:1600) { thk[h] ∼dcat(p[h,])
for (j in 1:H-1) {logit(gam[h,j]) <- kap[j] - mu[h] }
p[h,1] <- gam[h,1]; p[h,H] <- 1-gam[h,H-1]
for (r in 2:H-1) { p[h,r] <- gam[h,r] - gam[h,r-1] }
mu[h] <- beta[1]*prethk[h]+beta[2]*cc[h]+beta[3]*tv[h]
+beta[4]*cctv[h]+u3[sch[h]]+u2[sch[h],cls[h]]}
for (i in 1:m) {u3[i] ∼dnorm(0,tau[3]);for (j in 1:n[i]) {u2[i,j]∼dnorm(0,
tau[2])}}
for (j in 2:3) {sig[j] ∼dunif(0,1000); sig2[j]<-sig[j]*sig[j]; tau[j]<-1/sig2[j]}
for (j in 1:4) {beta[j] ∼dnorm(0,0.001)}
# Cut points on latent scale
kap[1] ∼dnorm(0, 0.01) I(,kap[2]); kap[2] ∼dnorm(0, 0.01) I(kap[1],kap[3]);
kap[3] ∼dnorm(0, 0.01) I(kap[2],)}
The code for the data augmented approach is as above, except that the ﬁrst
few lines are replaced by
model { for (h in 1:1600) { for (j in 1:H-1) {z[h,j] <- step(j-thk[h])
A[h,j] <- -10*equals(z[h,j],0); B[h,j] <- 10*equals(z[h,j],1)
ystar[h,j]∼dlogis(nu[h,j],1) I(A[h,j],B[h,j])
nu[h,j] <- kap[j] - mu[h]}
mu[h] <- . . . }
4. The code for the ﬁrst crossed factor analysis in Example 6.4 is
model { for (r in 1:R) {y[r]∼dnorm(mu[r],tau[3])
# h1 is neighborhood, h2 is school
mu[r] <- alph1[h1[r]] +alph2[h2[r]]+beta[2]*VRQ[r]+beta[3]*RTS[r]
+beta[4]*FSTAT[r]+beta[5]*FUNEM[r]
+beta[6]*FED[r]+beta[7]*MED[r]+beta[8]*MALE[r]
LL[r] <- 0.5*log(tau[3]/6.28)-0.5*tau[3]*pow(y[r]-mu[r],2); H[r] <- 1/
exp(LL[r])}
for (i1 in 1:m1) {alph1[i1]∼dnorm(mu.alph[i1],tau[1])
mu.alph[i1] <- beta[1]+gam*DEP[i1]}
for (i2 in 1:m2) {alph2[i2]∼dnorm(0,tau[2])}

280
Applied Bayesian Hierarchical Methods
for (j in 1:3) {sig[j]∼dunif(0,1000); tau[j] <- 1/(sig[j]*sig[j])}
for (j in 1:8) {beta[j]∼dﬂat()} gam ∼dﬂat()}
The analysis with area deprivation impacts varying by school has code
model { for (r in 1:R) {y[r] ∼dnorm(mu[r],tau[4])
mu[r] <- beta[1]+alph1[h1[r]]+gam[h2[r]]*DEP[h1[r]] +alph2[h2[r]]+
beta[2]*VRQ[r]
+beta[3]*RTS[r]+beta[4]*FSTAT[r]+beta[5]*FUNEM[r]+
beta[6]*FED[r]+beta[7]*MED[r]+beta[8]*MALE[r]
LL[r] <- 0.5*log(tau[4]/6.28)-0.5*tau[4]*pow(y[r]-mu[r],2); H[r] <- 1/
exp(LL[r])}
for (i1 in 1:m1) {alph1[i1] ∼dnorm(0,tau[1])}
for (i2 in 1:m2) {alph2[i2] ∼dnorm(0,tau[2]); gam[i2] ∼dnorm(Gam,tau[3])}
for (j in 1:4) {sig[j] ∼dunif(0,1000); tau[j] <- 1/(sig[j]*sig[j])}
for (j in 1:8) {beta[j] ∼dﬂat()} Gam ∼dﬂat()}
5. The code in Example 6.5 is as follows with the log(CPO) estimated using
the negative of the logged mean of H[h]:
model { for (h in 1:900) {y[h] ∼dpois(mu[h]); ynew[h] ∼dpois(mu[h])
mu[h]
<-
(15/12)*(o[h]+1)*nu[h];
u[h]
∼dnorm(0,tau.u);
st.u[h]
<-
u[h]*sqrt(tau.u)
# eth groups: Black, Hispanic, White
log(nu[h]) <- beta[eth[h]]+b[precinct[h]]+u[h]
# ﬁt criteria
under[h] <- step(y[h]-ynew[h])+0.5*equals(y[h],ynew[h])
yp[h] <- y[h]+0.5; ypp[h] <- ynew[h]+0.5; mh[h] <- mu[h]+0.5
EPD[h] <- 2*(yp[h]*log(yp[h]/ypp[h])-(y[h]-ynew[h]))
Dev[h] <- 2*(yp[h]*log(yp[h]/mh[h])-(y[h]-mu[h]))
LL[h] <- -mu[h]+y[h]*log(mu[h])-logfact(y[h]);
H[h] <- 1/exp(LL[h])}
# cluster eﬀects
for (j in 1:75) {b[j] ∼dnorm(0,tau.b); st.b[j] <- b[j]*sqrt(tau.b)
step.b[j] <- step(b[j]-mean(b[]))}
sig.b ∼dunif(0,100); sig.u ∼dunif(0,100)
tau.u <- 1/(sig.u*sig.u); tau.b <- 1/(sig.b*sig.b)
F[1] <- sum(EPD[]); F[2] <- sum(Dev[])
for (k in 1:3) {beta[k] ∼dﬂat()}}
For the mixture model, one has amended code elements
model { for (h in 1:900) {. . . u[h] ∼dnorm(0,tau.u[G[h]])
G[h] ∼dcat(lam[1:2]); st.u[h] <- u[h]*sqrt(tau.u[G[h]]). . . }
. . . . . . ..
lam[1] ∼dbeta(19,1); lam[2] <- 1-lam[1];
tau.u[2] <- tau.u[1]/(1+Kd); Kd ∼dunif(0,9)}

7
Multivariate Priors, with a Focus on Factor
and Structural Equation Models
7.1
Introduction
A range of multivariate techniques are available for modeling multivariate col-
lections of metric, binary, or count data, or for modeling multivariate random
eﬀects or regression residuals. These include data reduction (reduced dimen-
sion) methods, such as factor and principal component analysis (e.g., Hayashi
and Arav, 2006; Lopes and West, 2004), discriminant analysis (e.g., Brown
et al., 1999; Rigby, 1997), data mining, as well as direct (full dimension)
modeling of the joint density of the observations or regression residuals (e.g.,
Chib and Winkelmann, 2001). Structured multivariate eﬀects in the analysis
of spatial or time-conﬁgured data raise additional issues, such as representing
intervariable correlation within units as well as nonexchangeability between
units (Song et al., 2005).
Bayesian applications in the area of factor and structural equation model-
ing have grown considerably in recent years; for overviews, see Ando (2009),
Lee (2007), and Palomo et al. (2007), while for frequentist perspectives see
Hayashi et al. (2008) and Sanchez et al. (2005). The rationale for introducing
latent variables lies in parsimonious representation of the covariance structure
of multivariate collections of data, while also revealing underlying clustering
of, or associations between, the variables, ideally one with substantive rel-
evance and interpretability. The latent variables are typically unobservable
constructs (e.g., authoritarianism, population morbidity, or a common trend
shared between several time series) that can only be imperfectly measured
by observed indicators. The latent variables may be continuous, as in factor
analysis (Fokoue, 2004; Lopes and West, 2004) or categorical, as in latent
class analysis (Berkhof et al., 2003). The original variables might themselves
also be discrete or continuous. For example, item response models typically
involve multiple binary observed items and a single latent continuous ability
score (Albert and Ghosh, 2000; Bazan et al., 2006).
The extraction of information from multivariate observed indicators to de-
rive a smaller set of latent variables deﬁnes a measurement model, as in con-
ﬁrmatory and explanatory factor analysis (Bartholomew, 1987; Skrondal and
Rabe-Hesketh, 2007). The subsequent use of the latent constructs in describing
281

282
Applied Bayesian Hierarchical Methods
causal relationships or associations leads into structural equation modeling
(Lee, 2007). Both types of model have been developed especially in areas such
as psychology, marketing, educational testing, and sociology, where underlying
constructs are not possible to measure directly. Newer areas of development
include environmental modeling (Malaeb et al., 2000; Nikolov et al., 2007),
biomass models (Arhonditsis et al., 2006), and time series and spatial data
analysis using common factor approaches.
The observed variables in a measurement model may be variously known as
items (e.g., in psychometric tests), indicators, or manifest variables. Canonical
assumptions are that (a) conditional on the constructs, the observed indicators
are independent, in which case the constructs explain the observed correlations
between the indicators; and (b) that the construct scores are independent
over subjects. As Bollen (2002) points out, the local independence property
in (a) is not an intrinsic feature of structural equation models, while recent
developments in spatial and time series factor and structural equation models
(Congdon et al., 2007; Hogan and Tchernis, 2004) exemplify how construct
scores may be dependent over space or time.
This chapter presents a selective review of multivariate techniques, namely,
1.
factor modeling via continuous latent constructs, as applied in nor-
mal linear and general linear model contexts (Sections 7.2, 7.3,
and 7.4);
2.
models for multivariate discrete area (lattice) data, including spatial
factor models (Sections 7.6 and 7.7); and
3.
models for multivariate time series (Section 7.8), with a focus on
dynamic linear and general linear models.
A Bayesian approach is arguably of beneﬁt in such multivariate applica-
tions. Many classical applications of factor and structural equation methods
assume multivariate normality of the indicators and/or residuals with estima-
tion based on minimizing a discrepancy between the observed and predicted
covariance matrix—under multivariate normality, the covariance matrix is suf-
ﬁcient for describing the correlations between observed indicators (Hox and
Bechger, 1998; Sanchez et al., 2005). Considerations of robustness to outliers
and departures from normality, and the ease with which parameter restrictions
may be imposed and predictions made for new cases, may point to a Bayes
approach that retains the full observation set as input (Lee, 2007). Section 7.5
discusses robust approaches to factor models and structural equation models
(SEMs).
The fully Bayes method has further potential advantages over maximum
likelihood or empirical Bayes estimates in terms of fully taking account of
uncertainty in variance component estimates, for describing the densities of
the parameters of structural equation models without making asymptotic ap-
proximations (Aitkin and Aitkin, 2005), and in estimating models conven-
tionally considered unidentiﬁable, for instance regressions with all predictors

Multivariate Priors, with a Focus on Factor and SEMs
283
measured with error so that instrumental variable estimation is infeasible
(Scheines et al., 1999). Maximum likelihood standard errors calculated assum-
ing asymptotically normal estimators may be distorted for small sample sizes,
whereas in the Bayesian approach, Markov Chain Monte Carlo (MCMC)
samples are taken from the true posterior regardless of sample size, and so
standard errors calculated from MCMC output are reliable regardless of sam-
ple size, or when there are other sources of non-normality.
7.2
The Normal Linear SEM and Factor Models
Following Joreskog (1973) and further classical presentations (e.g., Bollen,
1989; Hoyle, 1995), several Bayesian treatments of normal linear or general
linear structural equation models have appeared recently (e.g., Nikolov et al.,
2007; Palomo et al., 2007; Song et al., 2006). Consider observed multivariate
metric indicators, y and x, and continuous endogenous and exogenous con-
struct vectors, denoted F and H, respectively. For subjects i = 1, . . . , n, the
measurement model components of a normal linear SEM are
yi = αy + ΛyFi + ui,
xi = αx + ΛxHi + ei,
where yi = (y1i, . . . , yPyi)′ is a Py × 1 vector of indicators describing or mea-
suring an endogenous construct vector, Fi = (F1i, . . . , FQyi)′, of dimension Qy
less than or equal to Py; and xi is a Px × 1 vector of indicators measuring
an exogenous construct vector, Hi, of dimension Qx ≤Px. The individual
factor variables, Fqi, may be independent of each other or intercorrelated,
and similarly for Hqi. The matrices, Λy and Λx, are of dimension Py × Qy
and Px × Qx and contain loading parameters describing how observed indica-
tors are related to the latent constructs. The {F, H} are sometimes known as
common factors, while the errors {u, e} are sometimes called unique factors
(Skrondal and Rabe-Hesketh, 2007). The errors are assumed independent of
the common factors.
A structural model may describe (a) interrelations between Fqi (namely,
reciprocal ﬂows between endogenous variables such as social authoritarianism
and religiosity) and (b) eﬀects of exogenous constructs, Hqi, on the endogenous
ones (e.g., eﬀects of socioeconomic status on authoritarianism or religiosity).
These eﬀects are represented by the equation system,
Fi = BF i + CH i + wi,
where an intercept is typically not identiﬁed, and B is a Qy × Qy matrix
with zero diagonal elements and oﬀ-diagonal parameters describing relations
between endogenous constructs. The matrix C is Qy × Qx with parameters
describing the impact of exogenous on endogenous constructs. The structural
model may also contain further observed variables as responses or predictors.

284
Applied Bayesian Hierarchical Methods
Many multivariate reduction applications involve just a measurement
model (i.e., a simple factor analysis), and so distinction between diﬀerent
types of observed indicator and factor is not needed. Then a normal linear
factor model is
yi = α + ΛFi + ui,
(7.1)
where yi = (y1i, . . . , yPi)′ is P × 1, and Fi = (F1i, . . . , FQi)′ is of dimen-
sion Q ≤P, and normality of errors and factors is often assumed with
(u1i, . . . , uPi)′ ∼NP (0, Σ) and Fi ∼NQ(0, Φ). Identifying assumptions on Λ
and Φ are considered below. Under a local independence assumption, the
residuals (u1i, . . . , uPi)′ are typically taken to be independent over cases i and
variables, so that Σ = diag(σ2
1, σ2
2, . . . , σ2
P )I, and upi ∼N(0, σ2
p). This assump-
tion can equivalently be stated as that the outcome variables are conditionally
independent given the latent variables (Skrondal and Rabe-Hesketh, 2007).
Uncertainty in the number of factors in the normal linear factor model,
or choice between models involving diﬀerent numbers of factors, may be
tackled using parameter expansion combined with a Bayes factor approxi-
mation (Ghosh and Dunson, 2008), by RJMCMC methods (Lopes and West,
2004) or by marginal likelihood approximation using path sampling. The latter
approach may be extended to full SEMs (Lee and Song, 2008). The parameter
expansion method may also improve MCMC performance (Ghosh, 2008), and
involves reference model (Equation 7.1), but with standardized factors, and
a lower triangular structure for Λ (see Section 7.3) including the diagonals
constraint, λqq > 0. Thus, the reference model is
yi = α + ΛFi + ui
Fi ∼NQ(0, I),
and the expanded model is
yi = α + Λ∗F ∗
i + ui
F ∗
i ∼NQ(0, Ψ),
where Ψ = diag(ψq), and the loadings Λ∗are not subject to the diagonals con-
straint. Priors on parameters in the expanded model induce priors on (Λ, F, Σ)
in the reference model, via,
λpq = S(λqq)λ∗
pqψ0.5
q ;
Fqi = S(λqq)F ∗
qi/ψ0.5
q ,
and a Bayes factor is derived using the integrated likelihood, y ∼N(α, ΛΛ′ +
Σ). The sign function, S(x) = −1 if x < 0 and S(x) = 1 if x ≥0, is used to
ensure the diagonals constraint in Λ.
7.2.1
Forms of model
If all loadings, λpq, in the P × Q matrix Λ are free parameters (apart from
those subject to identiﬁcation constraints, as discussed below), this structure
is known as an exploratory factor analysis. By contrast, in a conﬁrmatory
factor analysis or measurement model some of the loadings take preset values

Multivariate Priors, with a Focus on Factor and SEMs
285
(usually zero) on the basis of substantive theory. A particular form of con-
ﬁrmatory model is known as simple structure, such that each observed vari-
able, ypi, loads on only one of the constructs, Fqi. For example, Fleishman
and Lawrence (2003) apply a simple structure model to ordinal items from
the SF12 questionnaire, assuming that each item reﬂects either a physical or
mental health construct.
A multiple indicator-multiple cause (MIMIC) model extends conﬁrmatory
models by incorporating the eﬀects of exogenous observed variables on latent
factors (Joreskog and Goldberger, 1975). MIMIC models for normal outcomes
consist of (a) measurement equations,
yi = α + ΛFi + ϕXi + ui,
relating multiple indicator variables, yi, to latent constructs, Fi, and possibly
also to known inﬂuences, Xi; and (b) structural equations. In the latter, the
latent variables, Fi, are related both to one another and to observed exogenous
variables, Zi, which are viewed as “causes” of the factors, namely,
Fi = BF i + CZ i + wi,
where Zi excludes a constant term, and the coeﬃcient matrix B allows re-
ciprocal eﬀects between latent factors. A MIMIC model with a single latent
construct, as applied, for instance, in analyzes of the size of underground
economies (Wang et al., 2006; Frey and Weck-Hannemann, 1984), would typ-
ically take the form,
ypi = αp + λpFi + ϕpXi + upi,
Fi = γZi + wi.
As noted by Bruesch (2005), the correlation structure in a MIMIC model
may need substantive support, as it typically assumes that (i) the indicators y
are conditionally independent of the causes Z, given the latent construct(s) F;
and (ii) that the indicators y1, . . . , yP are mutually independent given F. This
amounts to saying that all connections that indicator variables y have with
the causal variables Z, and with one another, are transmitted through the
latent variable(s). Ghosh (2008, Section 4.7) demonstrates the application of
parameter expansion in a MIMIC model.
7.2.2
Marginal and complete data likelihoods, and
Markov Chain Monte Carlo sampling
From Equation 7.1, the conditional likelihood of the normal linear factor model
is p(yi|Fi, α, Λ, Φ, Σ) = N(α + ΛFi, Σ), with conditional covariance matrix,
V (yi|Fi, Σ) = Σ, and hence {cov(yji, ymi) = 0, m ̸= j} if Σ is diagonal. The
marginal likelihood obtained by integrating out the factor scores in the normal
linear factor model (Fokoue, 2004; Lee and Shi, 2000, 724) is p(yi|α, Λ, Φ, Σ) =
N(α, ΛΦΛ′ + Σ). The joint likelihood of yi and Fi, obtained by multiplying

286
Applied Bayesian Hierarchical Methods
the marginal density of F, Fi ∼NQ(0, Φ), and the conditional density of yi
given Fi, is

yi
Fi

∼NP +Q


α
0

,

ΛΦΛ′ + Σ
ΛΦ
ΦΛ′
Φ

.
When the factors are standardized (Bartholomew et al., 2002, 150; Lopes
and West, 2004, 44), the marginal variance of yp is, accordingly, λ2
p1 + · · · +
λ2
pQ +σ2
p and the marginal covariance of yp and ym is λp1λm1 +λp2λm2 +· · ·+
λpQλmQ. The contribution, λ2
p1 +· · ·+λ2
pQ, of the common factors to explain-
ing the marginal variability in yp is known as the communality, while that part
due to the residual error, σ2
p, is called the unique variance or uniqueness.
The marginal likelihood structure for cov(y) as ΛΦΛ′ + Σ does not lead
to any simple form for the posterior distributions of the unknowns, though it
can be used in RJMCMC approaches to estimation and factor model selection
(Lopes and West, 2004). In Gibbs sampling estimation of linear Bayesian
factor and SEM models, it is simplest to approach estimation of the parameters
(F, α, Λ, Φ, Σ) indirectly through the conditional likelihood or complete data
model (Aitkin and Aitkin, 2005; Fokoue, 2004), with the F scores regarded
as missing data rather than integrated out (Lee and Shi, 2000). Setting θ =
(α, Λ, Φ, Σ), the posterior density is then,
p(θ, F|y) ∝L(θ|y, F)p(θ).
While MCMC sampling is typically used with the conditional likelihood,
the marginal covariance, ΛΦΛ′ + Σ, may be useful in posterior checking of
model assumptions (e.g., conditional independence between y variables given
the factor scores). For example, Lee and Shi (2000) suggest a posterior check
using D(y, θ) =  y′
i(ΛΦΛ′ + Σ)−1yi. Following Gelman et al. (1996), repli-
cate data yrep,i are sampled from the predictive distribution p(yrep|y, θ) and
D(y, θ) compared to D(yrep, θ).
From a set of MCMC samples, one seeks the marginal posterior density,
p(θ|y), of the hyperparameters, and the predictive distribution, p(F|y), of the
factor scores. Estimation at iteration t + 1 proceeds by switching between
(a) sampling θ(t+1) from the posterior conditional, p(θ|y, F (t)), for θ condi-
tional on y and sampled F scores, and (b) updating F (t+1) from the condi-
tional density, p(F|y, θ(t+1)). The latter corresponds to the imputation step
in data augmentation (Tanner, 1996).
A range of inference issues may occur, subject to identiﬁability being fully
considered (Section 7.3). The choice between diﬀerent numbers of factors may
be made via BIC or DIC criteria, or by formal Bayes factor estimates. Lee
(2007) uses path sampling to estimate formal Bayes model choice criteria,
and RJMCMC methods may also be used in the normal linear factor model
(Lopes and West, 2004). The patterns of signiﬁcant loadings and subject fac-
tor scores raise questions of substantive theory, depending on the application
area. As noted by Aitkin and Aitkin (2005), one can assess the signiﬁcance of

Multivariate Priors, with a Focus on Factor and SEMs
287
parameter or factor score contrasts on the basis of the MCMC sample, such
as pairwise diﬀerence or ratio comparisons of scores on the kth factor for sub-
jects i1 and i2, Fi1k −Fi2k and Fi1k/Fi2k. Compared to classical analysis, the
posterior density characteristics of the factor scores (and of factor contrasts)
are routinely obtained.
To illustrate MCMC complete data sampling, assume Σ is diagonal in the
conjugate normal model (Equation 7.1) with priors σ−1
pp ∼Ga(α0p, β0p), that
the precision matrix for F has a Wishart prior Φ−1 ∼W(R0, ρ0), and that
the prior for Λ follows the form proposed by Press and Shigemasu (1989).
Speciﬁcally, with Λp as the pth row of Λ,
Λp ∼NQ(Λ0p, σppH0p),
where the Q × Q matrix, H0p, is positive deﬁnite. Often, simple assumptions
such as H0p = IQ are made (Lee and Shi, 2000, 729). Letting y′
p be the
pth row of y, and denoting Ωp = (H−1
0p + F ′F)−1, and ηp = Ωp(H−1
0p Λ0p +
Fyp), the posterior conditional for the unique variances is (Lee and Shi,
2000, 725)
σ−1
pp ∼Ga(α0p + n/2, β0p + 0.5[y′
pyp −η′
pΩ−1
p ηp + Λ′
0pH−1
0p Λ0p]).
The conditional for Λp is a Q-variate normal with mean, ηp, and covari-
ance, σppΩp, and the conditional for Φ−1 is Wishart with scale matrix,
FF ′ + R0, and degrees of freedom, n + ρ0. Finally, the conditional p(Fi|y, θ)
for the factor scores for subject i is a Q-variate normal with mean [Φ−1 +
Λ′Σ−1Λ]−1Λ′Σ−1yi and covariance [Φ−1 + Λ′Σ−1Λ]−1.
7.3
Identiﬁability and Priors on Loadings
Under the model (Equation 7.1), the marginal covariance of y is V
=
ΛΦΛ′ + Σ. It can be seen that the contribution, ΛΦΛ′, of the factor scores
to explaining variation in y may be achieved by an inﬁnite number of pairs
(Λ, Φ), and constraints must be imposed to ensure a unique location and scale
for the factor scores (Wedel et al., 2003, 358–9). One way of providing identi-
ﬁability (the scaling constraint) is to deﬁne the factors to be in standardized
form, with zero means and variances of 1 (Bentler and Weeks, 1980). Under
the alternative anchoring constraint (Skrondal and Rabe-Hesketh, 2004), one
among the set of loadings {λpq, p = 1, . . . , P} on each construct is preset for
identiﬁcation. The factors are still required to have zero means (providing
unique location), but may have unknown variances.
For the measurement model to be identiﬁable, the number of unknown
parameters in θ = (Σ, Φ, Λ) must be less than the number, P(P +1)/2, of dis-
tinct elements in the residual variance–covariance matrix V of y. For example,

288
Applied Bayesian Hierarchical Methods
in the standardized factor case, and with Φ = I excluding correlations, one has
V = ΛΛ′ + Σ,
with PQ + P parameters on the right-hand side under a local independence
assumption (Σ taken as diagonal). For P(P +1)/2 ≥PQ +P to apply requires
that P ≥2Q + 1 (Geweke and Zhou, 1996). In conﬁrmatory models, elements
of Λ may be preset to zero, alleviating requirements such that Σ be diagonal
or that Φ exclude covariances/correlations.
When Q > 1, additional identifying constraints must be set to avoid rota-
tion invariance. Otherwise, there is no unique solution because any orthogonal
transformation of Λ leaves the likelihood unchanged (Everitt, 1984, 16). Thus
for F ∗= H′F and Λ∗= ΛH, where HH′ = I,
y = 1α + ΛF + u = 1α + (ΛH)(H′F) + u = 1α + Λ∗F ∗+ u,
where cov(F ∗) = H′cov(F)H = cov(F). The exception is the simple struc-
ture case (each observed variable loading on only one factor) when rotational
identiﬁability is not an issue (Liu et al., 2005, 550; Wedel et al., 2003, 358).
In other cases, identiﬁcation may be achieved by ﬁxing enough λpq to
ensure a unique solution; in the case, Q = 2, setting any λp2 = 0 would
be suﬃcient. Provided the variables are ordered in such a way as to ensure
substantive justiﬁcation, a widely adopted option is to assume Λ to be lower
triangular, as in Geweke and Zhou (1996), Quinn (2004), Ghosh and Dunson
(2008), and Lopes and West (2004), namely,
Λ =


λ11
0
0
· · ·
0
0
λ21
λ22
0
· · ·
0
0
λ31
λ32
λ33
· · ·
0
0
...
...
...
...
...
...
λQ−1,1
λQ−1,2
λQ−1,3
· · ·
λQ−1,Q−1
0
λQ1
λQ2
λQ3
· · ·
λQ,Q−1
λQQ
...
...
...
...
...
...
λP 1
λP 2
λP 3
· · ·
λP,Q−1
λPQ


.
To avoid potential labeling issues, this structure can be combined with the
diagonals constraint,
λqq > 0,
and if λqq are unknowns under a ﬁxed factor scale with Φ = I, one might
take,
λqq ∼N(0, δqq)I(0, ).
Without such a constraint, the loadings and scores on a particular factor
may ﬂip over during MCMC iterations—see Geweke and Zhou (1996, 566) for

Multivariate Priors, with a Focus on Factor and SEMs
289
discussion of this issue in multivariate factor time series. For Q ≥1, setting
one loading for each construct to be ﬁxed (usually at 1.0) under an anchor-
ing constraint, usually ensures remaining loadings conform to a consistent
interpretation and direction of the factor.
An illustration is in item analysis of educational tests (with Q = 1)
where one generally seeks a univariate positive ability measure, Fi (Albert
and Ghosh, 2000; Sinharay, 2004, 465). Without suitable constraints on one
or more of the loadings, λp (e.g., gamma or lognormal priors), a negative abil-
ity construct may be obtained. To completely avoid the possibility of label
switching, a positivity constraint may be applied to all loadings; for example,
Sahu (2002) applies half normal priors with informative variance in an item
analysis, i.e.,
λq ∽N(0, δq)I(0, ),
where δq = 0.5 or 1.
While not necessarily a device to ensure consistent labeling but instead to
seek relatively simple structure (a Bayesian version of varimax rotation), one
may follow Fokoue (2004) and take the loading variances as unknown gamma
variables, namely,
λpq ∼N(0, δpq),
δpq ∼Ga(ν, ν),
with ν small.
7.3.1
An illustration of identiﬁability issues
To exemplify identiﬁability constraints, consider a spatial example involving
English local authorities, and suppose six observed indicators {y1, . . . , y6} are
taken to measure two latent area constructs, F1 and F2, deprivation and frag-
mentation. Thus, several studies have shown that area material deprivation
(i.e., meaning economic hardship represented by observed variables such as
high unemployment, and low car and home ownership) tends to be associ-
ated with higher psychiatric morbidity and suicide mortality (Gunnell et al.,
1995). So also does social fragmentation, meaning relatively weak commu-
nity ties associated with observed indices such as one person households, high
population turnover, and many adults outside married relationships (Evans
et al., 2004). Indicators {y1, y2, y3} of deprivation are provided by square roots
(a normalizing transform) of the UK 2001 Census rates of renting from so-
cial landlords, and of unemployment among the economically active, together
with the square root of the 2001 rate of households claiming income support.
Indicators {y4, y5, y6} of social fragmentation are provided by square roots of
Census rates of one person households, migration in the year 2000–2001, and
people over 15 not married.
A conﬁrmatory factor model (with simple structure) is assumed with
{y1, . . . , y3} loading only on a deprivation score, F1, and with {y4, . . . , y6}

290
Applied Bayesian Hierarchical Methods
loading only on a fragmentation score, F2. Let Dpi be the denominator (e.g.,
total population) used to deﬁne the transformed Census index, ypi. Then the
measurement model has the form,
y1i = α1 + λ11F1i + u1i,
y2i = α2 + λ21F1i + u2i,
y3i = α3 + λ31F1i + u3i,
y4i = α4 + λ42F2i + u4i,
y5i = α5 + λ52F2i + u5i,
y6i = α6 + λ62F2i + u6i,
where uji are mutually uncorrelated, with upi ∽N(0, τp/Dpi) (Hogan and
Tchernis, 2004, 316).
Since F1 and F2 have arbitrary location and scale, one way of providing
identiﬁability (the variance scaling or standardization constraint) is to de-
ﬁne them to be in standard form with zero means and variances of 1 (while
still possibly allowing nonzero correlations between factors, which is possible
under this conﬁrmatory model). Under the alternative anchoring constraint
(Skrondal and Rabe-Hesketh, 2007), one loading on each construct is preset
for identiﬁcation, e.g., λ11 = λ42 = 1. The Fqi may be assumed independent
of one another, although correlation over areas i may still be incorporated via
two separate univariate CAR priors (Besag et al., 1991). Alternatively, corre-
lation both between factors and over areas may be assumed, so that {F1i, F2i}
follow a bivariate CAR prior (see Section 7.6). Under an anchoring constraint,
the within-area factor covariance matrix would then contain three unknowns
{φ11, φ22, ρ},
Φ =

φ11
ρ√φ11φ22
ρ√φ11φ22
φ22

,
whereas under a standardization constraint the diagonal elements in Φ are set
to 1, and only ρ would be unknown.
Adopting an anchoring constraint has utility in helping to prevent
“relabeling” of the construct scores, Fki, during MCMC sampling. Since
the indicators {y1, . . . , y3} in this example are positive measures of mate-
rial deprivation, setting λ11 = 1 is consistent with the construct F1i being
a positive deprivation measure. If, however, one adopted the ﬁxed scale con-
straint with φpp = 1 and all λpq free, it would be necessary, in order to prevent
label switching, to set a prior on one or possibly more loadings constraining
positivity, e.g.,
λp1 ∼N(1, 1)I(0, ),
λp2 ∼N(1, 1)I(0, ),
for one or more p.

Multivariate Priors, with a Focus on Factor and SEMs
291
TABLE 7.1
Maximum likelihood factor solution.
Factor loadings
Variable
1
2
Uniqueness
Murder/manslaughter
−0.07
0.65
0.57
Rape
0.46
0.67
0.34
Robbery
0.32
0.54
0.61
Assault
0.34
0.91
0.06
Burglary
0.76
0.19
0.39
Larceny
1.00
0.00
0.00
Autotheft
0.31
0.31
0.81
Example 7.1. American City Crime: Exploratory Factor Model
Everitt (1984) presents crime rates per 100,000 population in 1970 for 16
American cities. There are P = 7 diﬀerent types of crime namely, (a) mur-
der/manslaughter, (b) rape, (c) robbery, (d) assault, (e) burglary, (f) larceny,
and (g) autotheft. A maximum likelihood factor analysis of the data in Stata
leads to Q = 2 factors with loadings in Table 7.1. The ﬁrst factor is inter-
pretable as representing nonviolent crime contrasts, and the second represents
violent crime. The Stata analysis does not provide estimation intervals for the
loadings.
An exploratory factor model1 is then applied under a Bayesian approach,
with the ﬁrst model adopting standardized and uncorrelated factors. On the
basis of the maximum likelihood analysis, the priors on selected loadings are
informative with λ61 (the larceny loading on factor 1) constrained to be posi-
tive with the intention of ensuring a nonviolent crime score. Similarly, λ42 (the
assault loading on factor 2) is constrained to be positive with the intention
of ensuring scores on the second factor measure violent crime, and with λ62
set to zero to avoid rotation invariance. Otherwise, the loadings have N(0, 1)
priors. A second model applies an anchoring constraint with λ61 = λ42 = 1
and λ62 = 0, and has unknown variances for the factor scores, which are still
assumed uncorrelated. Uniform U(0, 1000) priors are assumed for the unique
standard deviations and the factor standard deviations in model 2.
Results from a two chain run of 20,000 iterations (with early convergence
in loading parameters and unknown standard deviations) show the solutions
for both models are imprecise (Table 7.2). In the second model, λ22 is more
precisely deﬁned. On the other hand, the imprecision may be a valid reﬂection
of a relatively complex model being applied to a small dataset. More precise
posterior densities for the loadings are obtained using the Press-Shigemasu
prior—see also Lee (2007, 83–7). Thus,
(λp1, λp2) ∼NQ([Λ0p], σppH0p),
where the 2 × 2 matrix, H0p, is assumed to be an identity matrix, and Λ0p =
(0, 0). This prior is combined with an anchoring constraint to form model 3.

292
Applied Bayesian Hierarchical Methods
TABLE 7.2
Posterior summary: Crime EFA.
Model 1
Model 2
Model 3
Mean
2.5%
97.5%
Mean
2.5%
97.5%
Mean
2.5%
97.5%
λ11
0.04
−0.77
0.88
0.00
−1.19
1.06
−0.17
−0.93
0.59
λ12
0.61
−0.27
1.33
0.72
−0.15
1.71
0.67
0.12
1.26
λ21
0.49
−0.43
1.22
0.58
−0.59
1.64
0.33
−0.31
0.96
λ22
0.63
−0.23
1.27
0.76
−0.04
1.61
0.70
0.24
1.17
λ31
0.33
−0.47
1.09
0.33
−0.87
1.40
0.20
−0.60
0.93
λ32
0.50
−0.35
1.22
0.58
−0.39
1.45
0.57
0.03
1.14
λ41
0.40
−0.50
1.23
0.42
−0.79
1.54
0.14
−0.33
0.72
λ42
0.84
0.12
1.43
1.00
1.00
λ51
0.77
−0.17
1.45
0.87
−0.36
1.84
0.73
−0.04
1.38
λ52
0.17
−0.49
0.81
0.21
−0.71
1.02
0.24
−0.27
0.77
λ61
0.86
0.10
1.52
1.00
1.00
λ62
0.00
0.00
0.00
λ71
0.33
−0.41
1.08
0.37
−0.69
1.41
0.29
−0.54
1.11
λ72
0.29
−0.50
1.03
0.32
−0.61
1.19
0.33
−0.28
0.95
σ1
0.84
0.32
1.35
0.85
0.40
1.35
0.82
0.54
1.23
σ2
0.63
0.13
1.10
0.63
0.17
1.06
0.66
0.43
1.01
σ3
0.84
0.30
1.35
0.86
0.50
1.36
0.83
0.56
1.24
σ4
0.43
0.02
0.94
0.42
0.02
0.91
0.33
0.02
0.77
σ5
0.68
0.13
1.22
0.69
0.15
1.24
0.70
0.43
1.11
σ6
0.61
0.06
1.26
0.65
0.06
1.27
0.50
0.03
1.14
σ7
0.98
0.58
1.51
0.98
0.63
1.49
0.93
0.64
1.38
φ1
0.68
0.04
2.00
0.92
0.06
2.36
φ2
0.80
0.10
2.12
1.05
0.31
2.43
7.4
Multivariate Exponential Family Outcomes
and General Linear Factor Models
The normal linear factor and structural equation models considered above
generalize straightforwardly to general linear factor and SEM models for non-
normal data from the exponential family density: namely, binomial, Poisson,
and multinomial or ordinal data. Consider multivariate observations, yi =
(y1i, . . . , yPi)′, that conditional on factor scores Fi = (F1i, . . . , FQi)′ follow an
exponential family density, namely,
p(ypi|Fi) ∝exp
*ypiθpi −b(θpi)
φpi
+ c(ypi, φpi)
+
,
where θpi is the canonical parameter, with φpi typically taken as known scale
parameters. Denoting regression terms as ηpi = g(θpi), where g is a link
function, and ηi = (η1i, . . . , ηPi)′, intercept α = (α1, . . . , αP )′, and P × Q
loading matrix Λ, the regression term without extra-variation is
ηi = α + ΛFi,
(7.2)

Multivariate Priors, with a Focus on Factor and SEMs
293
while allowing extravariation,
ηi = α + ΛFi + ui,
(7.3)
with ui = (u1i, . . . , uPi)′, where upi are independent of each other under
conditional independence. The errors u (if present) and factor scores F are
also independent.
Normality of errors and factors is often assumed with (u1i, . . . , uPi)′ ∼
NP (0, Σ), where Σ is diagonal, and Fi ∼NQ(0, Φ), where Φ may be non-
diagonal according to the form of model (e.g., exploratory or conﬁrmatory)
assumed. Compared to the normal data-normal factor model, the marginal
densities of y are no longer simply derived, but involve integration over F,
namely,
p(yi|θ, ψ) =

P

p=1
p(ypi|Fi, θ)p(Fi|ψ)dF i,
where ψ are hyperparameters deﬁning the density of Fi. The usual conditional
independence assumptions are made. For example, for a P-variate categorical
response (Kp categories for the pth response), the conditional probability that
subject i with factor scores Fi = (F1i, . . . , FQi)′ exhibits a particular set of
responses is the product of separate categorical likelihoods,
Pr(y1i = k1, y2i = k2, . . . , yP i = kP |Fi)
= Pr(y1i = k1|Fi)Pr(y2i = k2|Fi), . . . , Pr(yPi = kP |Fi).
For factor reduction of binary, multinomial, or ordinal data, there may be
beneﬁt (e.g., in simpliﬁed MCMC sampling algorithms) in considering latent
variables posited to underlie the observed discrete responses. The missing data
then consists not only of factor scores, but of the latent scale data, y∗
pi, that
underlie the observed data, ypi. Thus for ypi binary, and ypi = 1 if y∗
pi > 0 and
ypi = 0 otherwise, one might take y∗
i = (y∗
1i, . . . , y∗
Pi) to be normal or logistic,
with the diagonal terms in the unique covariance matrix Σ set (usually to 1) for
identiﬁability. For instance, a normal model taking the underlying responses
to be conditionally independent given the factors, would be
y∗
pi ∼N(αp + ΛpFi, 1)I(Api, Bpi),
where Λp is the pth row of Λ, and the truncation ranges are determined by
the observed ypi.
7.4.1
Multivariate Poisson data
Factor models with Q < P may be more parsimonious than full dimension
error models for multivariate exponential family data. However, multivariate
reduction may not always be preferred in terms of ﬁt, so parsimony may
sometimes be at the expense of predictions that reproduce the data satisfac-
torily. Chib and Winkelmann (2001) illustrate how multivariate count data

294
Applied Bayesian Hierarchical Methods
may not always be suitable for reduction using latent factors. In their full-
dimension model, ypi ∼Po(µpi), with outcome-speciﬁc predictors, xpi =
(x1pi, x2pi, . . . , xRpi)′, and
µpi = exp(βpxpi + upi),
(u1i, . . . , upi) ∼NP (0, D).
The ypi are conditionally independent given the correlated errors, ui =
(u1i, . . . , uPi)′. Deﬁning vpi
=
exp(upi), one has, equivalently, ypi
∼
Po(λpivpi) with
λpi = exp(βpxpi),
(v1i, . . . , vpi) ∼LN P (µv, Σv).
That is, vpi are multivariate lognormal with mean vector µv = exp(0.5
diag(D)), and covariance Σv = diag(µv)[exp(D) −11′]diag(µv). Other ways
to generate correlated count data include the overlapping sums technique
(Madsen and Dalthorp, 2007). Thus consider independent Poisson variables,
Z12, Z1, and Z2, with means θ12, θ1, and θ2; then y1 = Z1 + Z12 and
y2 = Z2 + Z12 are correlated with marginal means θ1 + θ12 and θ2 + θ12 and
covariance θ12. The mean and covariance of the corresponding joint Poisson
density for three variables is provided by Karlis and Meligkotsidou (2005, 257).
Factor models for count data typically may include both normal factor
scores and residuals, upi, taken as uncorrelated if the usual conditional inde-
pendence assumption is made. Thus,
ypi ∼Po(µpi),
µpi = exp(βpxpi + ΛpFi + upi),
where Λp is 1 × Q, Fi = (F1i, . . . , FQi)′ and under a standardized factor
constraint, Fi ∼NQ(0, RF ), where RF is a correlation matrix, with possi-
bly unknown oﬀ-diagonal terms subject to identiﬁability. Alternatively, Wedel
et al. (2003) consider gamma distributed factors in an identity link model as
well as normal F scores combined with a log link. Gamma factors would have
mean 1 to avoid location invariance, and taking their cumulative impact to
be multiplicative, one could have
µpi = exp(βpxpi + upi)

F ωp1
1i F ωp2
2i , . . . , F ωpQ
Qi

,
with comparable identiﬁcation restrictions on the loadings, Ωp = (ωp1, . . . ,
ωpQ), to those in the normal linear factor model (see also Dunson and Herring,
2005). The constraints would diﬀer according to whether the variance of the F
scores were unknown, as in,
Fqi ∼Ga(ϕq, ϕq),
with ϕq to be estimated, or whether the variance of F is preset, as in Fqi ∼
Ga(1, 1).

Multivariate Priors, with a Focus on Factor and SEMs
295
An alternative to outcome-speciﬁc residuals, upi, in the above models is a
common residual factor, especially when Fi are derived as part of a broader
structural model involving further observed indicators. For example, consider
count observations, ypi (p = 1, . . . , P), on clinical outcomes for a set of hospi-
tals, while also available are metric measures, xri (r = 1, . . . , R), of resource
inputs, eﬃciency, etc. The latter variables are relevant to deﬁning a multivari-
ate latent “care quality” construct, Fi, in a MIMIC framework that assists in
explaining the clinical outcomes, but this construct may not explain all the
covariation among (or overdispersion in) the y variables and correlated resid-
uals and/or common residual factors are needed. The cause equation deﬁning
the latent construct might take the form (for standardized x),
Fi = βxi + wi,
while the errors in the Poisson likelihood measurement equations for ypi ∼
Po(µpi) are correlated over outcomes under a common factor model,
log(µpi) = αp + ΛpFi + κpui.
Assuming ui is univariate, one of the loadings, κp, is preset if the vari-
ance, σ2
u, of the common residual scores, ui, is unknown. Spatial applications
of common factors are exempliﬁed by Wang and Wall (2003) and Congdon
(2008b).
7.4.2
Multivariate binary data and item response models
As for counts, models for P-variate binary outcomes, ypi ∼Bern(πpi), may
retain the observed binary data likelihood and represent joint or residual cor-
relations by additive full-dimension multivariate eﬀects, upi, for example,
logit(πpi) = βpxpi + upi,
(u1i, . . . , upi) ∼NP (0, D).
By contrast, multivariate probit or logit models may also follow from an
augmented data perspective in which unobserved metric variables, y∗
i = (y∗
1i,
y∗
2i, . . . , y∗
Pi), result in the observed binary vector (Chen and Dey, 1998, 2000).
Thus, Bayesian estimation of the multivariate probit involves augmenting
the data with the latent normal variables obtained by truncated multivariate
normal sampling. Thus, with ηpi = βpxpi and ηi = (ηpi, . . . , ηP i),
(y∗
1i, y∗
2i, . . . , y∗
Pi) ∼NP (ηi, Σ)I(Ai, Bi),
(7.4)
with the observations generated according to,
ypi = I{y∗
pi > 0}.
The lower and upper sampling limits in the vectors Ai = (A1i, . . . , APi)
and Bi
= (B1i, . . . , BPi) depend on the observations: sampling of the

296
Applied Bayesian Hierarchical Methods
constituent y∗
pi is conﬁned to values above zero when ypi = 1, and to zero
or negative values when ypi = 0. Scale mixtures of multivariate normal den-
sities for y∗
pi are also possible leading to multivariate Student t, which for
particular degrees of freedom approximates a multivariate logit link (Chen
and Dey, 1998). A multivariate logit regression may be achieved directly with
suitable mixing strategies (Chen and Dey, 2000; O’Brien and Dunson, 2004).
The covariance matrix Σ in Equation 7.4 is not identiﬁed, and when the
predictor eﬀects vary by response only the correlation matrix can be identiﬁed
(Rossi et al., 2005). The identiﬁcation criteria for the multivariate probit diﬀer
from those of the multinomial probit where identiﬁcation is obtained by setting
one of the diagonal variance elements, σpp (e.g., the ﬁrst), to 1 (McCulloch
et al., 2000). While it is possible to sample the correlation matrix directly
(Barnard et al., 2000; Chib and Greenberg, 1998), one may also (Edwards
and Allenby, 2003; McCulloch and Rossi, 1994) sample the Σ matrix or its
inverse from an unrestricted prior, and then scale both the ﬁxed eﬀects and
the covariance matrix to their identiﬁed forms, namely,
β∗
p = βp/√σpp,
and the correlation matrix,
R = ∆Σ∆,
where ∆= diag(√σpp).
Factor models for multiple binary data most typically have the general
linear mixed form,
ypi ∼Bern(πpi),
g(πpi) = βpxpi + ΛpFi,
where g is the link, and Fi = (F1i, . . . , FQi)′. As for the normal linear factor
model, a common assumption for the density of F is normal with known scale.
If, additionally, factors are independent, then Fqi ∼N(0, 1), q = 1, . . . , Q. If
instead the assumption, Fqi ∼logist(0, 1) is made, with loadings κpq in,
ηpi = αp + κp1F1i + · · · + κpQFQi,
then κpq ≈(
√
3/π)λpq, since the variance of a standard logistic is π2/3
(Bartholomew, 1987). Another possibility involves F scores linked (e.g., by
probit or logit transforms) to uniform scores z. For example, the scheme,
g(πpi) = αp + λp1F1i + · · · + λpQFQi,
Fqi = logit(zqi),
zqi ∼U(0, 1),
corresponds to Fqi being logistic.

Multivariate Priors, with a Focus on Factor and SEMs
297
A widely applied paradigm in educational and psychometric evaluation
(Albert, 1992; Fox and Glas, 2005; Rupp et al., 2004) is based on item response
theory (IRT). Typically, the observation vector, yi, consists of P binary items
measuring ability, with 1 denoting a correct answer and 0 an incorrect answer,
and a model seeks a single latent ability factor score, Fi. Under conditional
independence the joint success probability given Fi is
Pr(y1i = 1, y2i = 1, . . . , ypi = 1|Fi)
= Pr(y1i = 1|Fi)Pr(y2i = 1|Fi) · · · Pr(yPi = 1|Fi).
If the Bernoulli likelihood, ypi ∼Bern(πpi), is retained, one has a factor
type model
g(πpi) = ηpi = αp + λpFi.
The intercepts αp can be interpreted as measures of diﬃculty of item p,
while λp measures an item’s power to discriminate ability between subjects.
Fox and Glas (2005) describe Bayesian model choice analysis for IRT mod-
els allowing for diﬀerential item functioning (DIF)—when an item is not ap-
propriate for measuring ability because the knowledge needed for a correct
answer is culturally speciﬁc (Swanson et al., 2002). Thus, let xi = 0 for a ref-
erence population and xi = 1 for a focal group (e.g., disadvantaged or minority
group); then DIF is indicated if the extended model,
Pr(ypi = 1|Fi) = Φ(ηpi),
ηpi = αp + λpFi + xi(γp + δpFi),
has better ﬁt than the standard model without group diﬀerentiation (Swami-
nathan and Rogers, 1990).
7.4.3
Latent scale binary models
As an alternative to binary likelihood modeling in IRT and binary SEM ap-
plications, the latent scale method may be applied with the appropriate un-
derlying density deﬁned by the link g. Thus, for a probit link with g−1 = Φ,
the latent metric scale, y∗, is normal, such that ypi = 1 corresponds to the
imputation scheme,
y∗
pi ∽N(ηpi, 1) I(0, )
and ypi = 0 corresponds to y∗
pi ∽N(ηpi, 1) I(0, ). For a logit link, g−1(u) =
L(u) = (eu/1 + eu) and sampling of y∗is from a standard logistic. Sahu (2002)
considers an extra data imputation to provide three-parameter IRT models.
The three-parameter probit IRT model speciﬁes,
πpi = cp + (1 −cp)Φ(αp + λpFi),

298
Applied Bayesian Hierarchical Methods
while the three-parameter logistic IRT is
πpi = cp + (1 −cp)L(αp + λpFi),
where cp is interpretable as a guessing parameter.
Lee and Song (2003) adopt a latent scale approach to a structural equation
model for multiple binary observations. Their model speciﬁes,
y∗
i = α + ΛFi + ui,
where the latent constructs, Fi, are partitioned into endogenous and exogenous
vector components, Fi = (F1i, F2i), of dimension Q1 and Q2, respectively, with
structural model,
F1i = BF 1i + ΓF2i + wi.
For identiﬁcation, ui
∼
NP (0, I), while F1i
∼
NQ1(0, Φ1), F2i
∼
NQ2(0, Φ2), wi ∼NQ1(0, Σw), and each row of Λ follows a separate normal
prior. The observed binary data, y, is augmented with latent data {y∗, F}
to provide complete data {y, y∗, F}. Setting θ = (α, Λ, Φ1, Φ2, Σδ, B, Γ), the
updating sequence involves sampling from conditionals p(θ(t+1)|F (t), y∗(t)),
p(F (t+1)|θ(t+1), y∗(t)), and p(y∗(t+1)|F (t+1), θ(t+1)).
Dunson and Herring (2005) consider instead the case where the underly-
ing y∗
pi (e.g., tumor counts) are Poisson, or overdispersed Poisson, and the
observations, ypi (e.g., whether tumors are present), are binary. Thus,
y∗
pi ∼Po(exp(xpiβ)Λpξi)I(Api, Bpi),
where ξi = (ξ1i, . . . , ξQi) are gamma distributed latent constructs, and the
loadings, Λp, are also gamma distributed. The sampling limits are (Api = 0,
Bpi = 0) when ypi = 0, and (Api = 1, Bpi = ∞) when ypi = 1.
7.4.4
Categorical data
For unordered polytomous indicators, ypi, with Mp categories (p = 1, . . . , P),
intercept and loading parameters are typically speciﬁc to the category of
each item, with one category (e.g., the ﬁnal one) as reference. Assume a
multiple logit link (Bartholomew, 1987), with multinomial parameter, πpi =
(πpi1, . . . , πpiMp), for subject i and indicator p. Then while factors are com-
mon across categories, loadings are speciﬁc to indicator p and category h of
each indicator,
ypi ∼categoric(πpi1, πpi2, . . . , πpiMp),
πpih = ϕpih
 Mp

m=1
ϕpim
h = 1, . . . , Mp,
log(ϕpih) = αph + λph1F1i + · · · + λphQFQi
h = 1, . . . , Mp−1,
ϕpiMp = 1,
with the usual constraints on Λ and/or F to avoid scale and rotational
invariance.

Multivariate Priors, with a Focus on Factor and SEMs
299
Both Bartholomew et al. (2002) and Moustaki (2000) mention the item
response function approach to estimating factor models for ordinal data (see
Example 7.3). Thus, let π(m)
ji
denote the probability of responding correctly
to category m ∈(1, . . . , Mj) of item j and denote the cumulative probability
of a response to item j in category m or lower as
∆(m)
ji
= π(1)
ji + π(2)
ji + · · · + π(m)
ji
.
Then with cut points, δjm, an ordinal factor model may be estimated via
Mj −1 binary regressions,
g(∆(m)
ji
) = δjm −
Q

k=1
λjkFik,
where the negative sign preceding the factor impact term indicates that as F
scores increase, the responses to item j are more likely to fall at the upper
end of the scale.
For ordinal data, the latent variable approach is also appealing. For
example, suppose observations y consist of P = P1 + P2 variables, the ﬁrst
P1 of which are continuous, and the subsequent P2 are ordinal containing
M1, M2, . . . , MP2 categories (e.g., Lee and Shi, 2001; Lee and Song, 2004; Lee
and Tang, 2006). To model correlation among these variables or introduce
regression eﬀects, one may deﬁne latent metric variables, y∗
pi, for p > P1 with
Mp −1 unknown cut points δpm (and preset ones, δp0 = 0, δpMp = ∞) such
that,
ypi = m ⇐⇒δp,m−1 ≤y∗
pi ≤δpm(m = 1, . . . , Mp),
0 ≤δp1 ≤· · · ≤δp,Mp−1 ≤∞.
For identiﬁcation, the submatrix of cov(y) relating to the last P2 outcomes
is a correlation matrix. Instead of a P-dimensional multivariate model for
the joint responses {y1i, . . . , yP1i, y∗
P1+1,i, . . . , y∗
Pi}, a common factor model
proposes that the correlation structure result from a smaller set (Q < P) of
metric factors, Fi ∼NQ(0, Φ), as in,
ypi = αp + λp1F1i + · · · + λpQFQi + upi
p = 1, . . . , P1,
y∗
pi = αp + λp1F1i + · · · + λpQFQi + upi
p = P1 + 1, . . . , P,
where cov(y) = ΛΦΛ + Σ, and under conditional independence, the covari-
ance matrix Σ for errors, ui, is diagonal (Shi and Lee, 2000) with var(upi) = 1
for p > P1. One possible framework (Moustaki, 2000) assumes that the latent
variables, Fki, are standard normal and uncorrelated, and the P2 × P2 covari-
ance submatrix of cov(y) corresponding to the y∗
pi is a matrix with elements,
rab =
Q

m=1
λamλbm.
To avoid rotational invariance, there are then only PQ−Q(Q−1)/2 indepen-
dent factor loadings.

300
Applied Bayesian Hierarchical Methods
Example 7.2. Greek Crime Totals
This example considers count data
and compares a common factor model to a full dimension covariance struc-
ture. The data relate to P = 4 counts of crimes (rapes, arsons, manslaugh-
ter, smuggling of antiquities) in 49 Greek prefectures, as used in Karlis and
Meligkotsidou (2005)∗. The counts are assumed to be Poisson with oﬀset
being prefecture populations, oi (in millions). Predictors are unemployment
rate (z1), a binary indicator (z2) for whether the prefecture is at the Greek
borders, gross domestic product (GDP) per capita in euros (z3), and a binary
indicator (z4) for whether the prefecture has at least one large city (>150,000
inhabitants).
Event rates are low in relation to populations at risk, so a reasonable sam-
pling model takes ypi ∼Po(oiρpi), with ρpi being crime rates per million. The
full dimension model speciﬁes,
ρpi = exp(ziβp + upi)
p = 1, . . . , P,
(u1i, . . . , uPi) ∼NP (0, D),
with prior D−1 ∼W(PI, P). A 25,000 iteration two chain analysis is run in
OpenBUGS, with inferences based on the second half of the sequence. The
eﬀective parameter count is estimated at 99.5, and the mean scaled deviance
at 203, comparing closely to the number of observations, namely, 196. The
DIC is therefore 302.5. Adequate performance is also shown by the fact that
only 9 of the 196 observations have mixed predictive p values under 0.05 or
over 0.95 (Marshall and Spiegelhalter, 2007). Most predictor eﬀects are in-
signiﬁcant: the only signiﬁcant eﬀects are of unemployment on the rape crime
rate (with the relevant β coeﬃcient having mean 0.064), and of the border and
GDP variables on manslaughter rates. Most correlations, rjm = corr(uji, umi),
in the regression residuals have credible intervals straddling zero, though r13
has posterior mean 0.47 with 95% interval (−0.05, 0.80).
To illustrate a factor analytic approach to these data, the four predictors
are taken to be causes of a single underlying crime construct, Fi, in a MIMIC
analysis. The Poisson regressions form a measurement model in which crime
levels are indicators of Fi. A further common factor, ui, is included in the model
for the crime types to account for residual variation in the crime data. So,
ρpi = exp(αp + λpFi + κpui),
Fi = b1z1i + b2z2i + b3z3i + b4z4i + wi,
wi ∼N(0, 1/τw);
ui ∼N(0, 1/τu).
Anchoring constraints are used to deﬁne the scale of the factor scores,
Fi and ui. So λ1 = 1 and κ2 = 1, with the latter setting corresponding to a
belief that arson is relatively distinct from the other variables in its spatial
patterning.
∗Data kindly provided by Dimitris Karlis.

Multivariate Priors, with a Focus on Factor and SEMs
301
Inferences are based on the second half of a 30,000 run of two chains. The
posterior means (sd) of the unknown λp coeﬃcients (p = 2, 3, 4) are, respec-
tively, −0.32 (0.77), 0.49 (0.29), 0.87 (0.42). These loadings tend to conﬁrm
F as a positive crime construct with positive loadings on all crime variables
except arson. The posterior mean F scores range from −1.28 to 1.44, with
high F scores in prefectures with above average violent crime (such as prefec-
ture 13), or where high violent crime is combined with smuggling. By contrast,
low F scores occur in prefectures with little crime (prefecture 40), or in areas
where arson is unduly elevated (e.g., prefecture 48). The zi are relatively weak
predictors of Fi, though the GDP coeﬃcient (b3) has a mainly positive 95%
interval (−0.02, 0.34). The average scaled deviance of this model (274) indi-
cates some residual dispersion, though the complexity is lower than model 1
at 37, so the DIC is not that much higher than model 1. Model checks are
adequate: 11 of the 196 observations have mixed predictive p values under
0.05 or over 0.95.
The fact that this particular data reduction method did not yield a better
ﬁt may be taken to illustrate caveats to discrete data factor reduction, as also
illustrated by Chib and Winkelmann (2001). They undertake a Poisson regres-
sion analysis of six health use outcomes, and conclude that “a ﬂexible model
with a full set of correlated latent eﬀects is needed to adequately describe the
correlation structure [in the regression residuals].”
Example 7.3. Political and Economic Risk: Factor Analysis for
Mixed Ordinal and Continuous Responses
Quinn (2004) considers a
mix of continuous, binary, and ordinal indicators of a single latent construct,
namely, political–economic risk in 62 countries. The ﬁrst indicator (indepen-
dence of judiciary) is binary, set to 1 if the judiciary is judged to be indepen-
dent. The next indicator is continuous, the log of the black-market premium
in each country where the premium is the black-market exchange rate. The
third measure of political–economic risk is ordinal (with M3 = 6 levels), mea-
suring the lack of expropriation risk. The fourth indicator, also ordinal with
M4 = 6 levels, measures lack of corruption. The ﬁnal indicator is productivity,
measured by logged values of GDP per worker.
The latent construct has a preset variance of 1 for identiﬁcation (according
to a standardized factor rather than anchoring constraint), and the discrete
response variables are analyzed using metric data augmentation2. In particu-
lar, the model for the ordinal outcomes, y3 and y4, has the form,
ypi = m if y∗
pi ∈(δp(m−1), δpm),
y∗
pi = λpFi + εpi,
εpi ∼N(0, 1),
where δp0 = −∞and δpM = ∞. This is implemented using M3 −1 = 5
and M4 −1 = 5 binary regressions as discussed in Section 7.4.4. To ensure
consistent labelling of the factor, the loading λ3 of y3 (lack of expropriation

302
Applied Bayesian Hierarchical Methods
TABLE 7.3
Political and economic risk factor model.
Mean
St. devn.
MC st. error
2.5%
97.5%
α1
−0.05
0.37
0.01
−0.80
0.70
κ31
−3.85
0.50
0.02
−4.79
−2.88
κ32
−2.60
0.40
0.02
−3.42
−1.88
κ33
−1.75
0.34
0.01
−2.42
−1.10
κ34
0.06
0.30
0.01
−0.53
0.64
κ35
1.95
0.42
0.02
1.17
2.80
κ41
−3.20
0.45
0.02
−4.11
−2.35
κ42
−1.72
0.34
0.01
−2.41
−1.08
κ43
0.04
0.31
0.01
−0.58
0.65
κ44
1.48
0.39
0.02
0.77
2.29
κ45
2.99
0.52
0.03
1.98
4.01
λ1
−2.98
0.81
0.04
−4.68
−1.59
λ2
0.77
0.12
0.00
0.56
1.02
λ3
−2.21
0.32
0.02
−2.84
−1.60
λ4
−2.34
0.38
0.02
−3.14
−1.63
λ5
−0.72
0.12
0.00
−0.97
−0.50
threat) on the common factor F is constrained to be negative. A two chain
run of 10,000 iterations shows early convergence, with parameter estimates
close to those of Quinn (2004) (see Table 7.3).
Example 7.4. Maths Tests: Item Response Model
This example com-
pares item analysis (IRT) models to a full dimensional multivariate probit
for binary item data from Tanner (1996) concerning maths aptitude; there
are n = 39 students and P = 6 items. For the IRT models, a probit link
is adopted and two- and three-parameter models compared. The augmented
data two-parameter model3 for subjects i and item p is
y∗
pi ∽N(αp + λpFi, 1) I(Api, Bpi),
where Fi ∼N(0, 1) and all λp are unknowns. Following Sahu (2002) and
others, the λp are assigned N(0, 1) priors truncated to positive values. The
sampling limits (Api, Bpi) depend on the observed ypi. The model is checked
by assessing whether replicates, yrep,pi, sampled from the model are concor-
dant with actual values, ypi, though one may also compare actual and pre-
dicted totals falling into particular item response patterns (Sahu, 2002). The
three-parameter probit IRT model including diﬃculty parameters speciﬁes
ypi ∼Bern(πpi) with,
πpi = cp + (1 −cp)Φ(αp + λpFi).
This model is estimated from the binary data likelihood with truncated
normal priors assumed for λp and Beta(1, 3) priors for cp.

Multivariate Priors, with a Focus on Factor and SEMs
303
Convergence on both models is obtained early in two chain runs of 5000
iterations with inferences based on the last 4500. The two-parameter model
has log(psML) = −161.8, and posterior mean percentages of predictive con-
cordance for the six items (52.6, 54.1, 60.8, 62.4, 65.2, 61.6). The lowest CPO
(of 0.12) is for subject 28 and item 6. The three-parameter model provides
log(psML) = −159, but predictive concordance is not improved for all items
standing at (53.1, 55.6, 60.1, 60.1, 62.4, 60). The guess parameters, cp, for the
ﬁrst two items both have posterior means of 0.275, but for the other items are
below their prior means of 0.25.
The multivariate probit, as in Equation 7.4, is applied with unrestricted
Wishart sampling of Σ−1, so that parameters need to be scaled by the sampled
standard deviations in Σ. The prior degrees of freedom and scale matrix in the
Wishart are set at P and PI, respectively, so that E(Σ) = I under the prior.
Initially, the item means in the MVN model are simply taken as unknown con-
stants, but predictive concordancies are higher when item means are extended
to take a factor form, with αp + λpFi where Fi ∼N(0, 1). This amounts to a
factor analysis without assuming conditional independence since,
(y∗
1i, y∗
2i, . . . , y∗
pi) ∼Np(αp + λpFi, R) I(Ai, Bi),
with R a correlation matrix with unknown oﬀ-diagonal terms. This extension
improves predictions: mean percent concordancies from the last 4000 of a two
chain run of 5000 iterations are (54.4, 54.8, 59.5, 62.3, 61.7, 57.7) though the
identiﬁed loadings, λ∗
j = λj/√σjj, are estimated less precisely than under the
IRT models. None of the correlations in R has a 95% interval entirely conﬁned
to positive or negative values, so setting R = I might be considered.
7.5
Robust Options in Multivariate
and Factor Analysis
Real world data structures may exhibit segmentation and unobserved het-
erogeneity such that a single multivariate density or multivariate reduction
model is inappropriate. Techniques are also required to ensure inferences in
multivariate models are robust against outlier observations or departures from
normality. A ﬂexible method for dealing with heterogeneity, and one adapted
to elucidating subpopulations with substantive meaning (e.g., in the case of
market segmentation), involves the use of discrete mixtures (Jedidi et al.,
1997; Arminger et al., 1999; Lubke and Muthen, 2005).
7.5.1
Discrete mixture multivariate models
Discrete mixtures are familiar as a technique in standard multivariate analysis,
where the full covariance parameterization of the error structure is retained

304
Applied Bayesian Hierarchical Methods
but extended to diﬀer between K latent populations. While conceptually
appealing, discrete mixture models in practice may encounter diﬃculties with
label switching and assessing the optimal number of components. Such prob-
lems may be reduced under a nonparametric approach via Dirichlet process
and other priors (Kottas et al., 2005).
To illustrate discrete parametric mixtures, let yi be a P × 1 vector of
observations for subject i on P continuous variables. Let there be K mixture
components with πk denoting the prior probability of belonging to the kth
component or latent class. In a discrete parametric mixture model, it is as-
sumed that the density of yi, p(yi|θ), is a mixture of K multivariate densities,
pk(yi|θk), with θ = (θ1, . . . , θK), namely,
p(yi|θ) =
K

k=1
πkpk(yi|θk).
Commonly used mixtures for multivariate continuous data, residuals, or
random eﬀects take each component density to be multivariate normal (Muller
et al., 1996) with parameters θk = {µk, Σk}, or multivariate Student t with
distinct degrees of freedom parameters, θk = {µk, Σk, νk} (Lin et al., 2004).
Bayesian estimation is facilitated by considering latent group allocation
indicators, Si = k where k ∈(1, . . . , K), and with consequent focus on the
complete data likelihood. In the case of a multivariate normal mixture,
p(yi|Si = k) = N(µik, Σk),
where µik may be modeled via regressions, µik = Xiβk, on known predictors
Xi, while probabilities, πik, that subjects belong to particular subpopulations
may also be predicted (e.g., in a multinomial logit regression) by further known
attributes, Zi. Rossi et al. (2005, Section 5.5) consider the application of such
models in analyzing market segmentation.
An unrestricted multivariate normal or student t mixture involves distinct
covariance matrices for each component and for large P and/or large K this
may imply a heavily parameterized model. Hence, simplifying assumptions
such as Σk = Σ may be suitable. Banﬁeld and Raftery (1993) propose a
parsimonious reparameterization of the component-speciﬁc covariance matrix
via an eigenvalue decomposition,
Σk = λkEkAkE′
k,
where Ak is a diagonal matrix scaled such that |Ak| = 1 and with elements
proportional to the eigenvalues of Σk, Ek is a matrix of eigenvectors, and
λk = |Σk|1/p.
7.5.2
Discrete mixtures in SEM and factor models
Parsimony as well as enhanced substantive knowledge are the goals of discrete
mixture factor and structural equation models. Discrete mixture factor anal-
ysis and SEM models have similar features to multigroup methods where the

Multivariate Priors, with a Focus on Factor and SEMs
305
population exhibits a known, rather than latent, segmentation based typically
on demographic and psychometric variables (Jedidi et al., 1997; Lee and Song,
2003; Zhu and Lee, 2001). Under a discrete mixture factor analysis model for
normal metric data one has, conditioning on membership Si = k of the kth
component (k = 1, . . . , K),
yi = αk + ΛkFki + uki,
(7.5)
where the factor scores for subject i in the kth group, Fki = (Fk1i, . . . , FkQi)′,
are of dimension Q ≤P. With normality assumptions for each component,
(uk1i, . . . , ukPi)′ ∼NP (0, Σk),
and
(Fk1i, . . . , FkQi)′ ∼NQ(0, Φk),
where the form of Φk is subject to the identifying restrictions imposed on Λk,
and vice versa. Under conditional independence, Σk is diagonal with elements
{σ2
kj , j = 1, . . . , P}. The unconditional likelihood for the kth subpopulation is
pk(yi|θk) = N(αk, ΛkΦkΛ′
k + Σk),
where θk = (αk, Λk, Φk, Σk), and the entire observed data likelihood is
p(yi|θ) =
K

k=1
πkN(αk, ΛkΦkΛ′
k + Σk),
where θ = (θ1, . . . , θK). Restricted covariance structures can be obtained (Lee,
2007, 322; Zhu and Lee, 2001, 139) by making some parameters or covariance
matrices invariant across subpopulations.
Bayesian estimation is facilitated by considering latent multinomial al-
location indicators, Si = k where k ∈(1, . . . , K), with prior probabilities,
Pr(Si = k) = πk, and the complete or augmented data likelihood,
p(yi|Si, θ) = N(αk + ΛkFki, Σk).
As mentioned in Chapter 3, an additional issue involved in Bayesian dis-
crete mixture estimation via MCMC methods is that of unique labeling. In
this regard, Lee and Song (2003) suggest an identifying constraint via order-
ing α1 < α2 < · · · < αK of component locations. For purposes of MCMC
sampling, the conditional posterior for the allocation indicators, Si, is
p(Si = k|yi, θ) = πkpk(yi|θk)
p(yi|θ)
,
and so multinomial simulation is straightforward. It is simplest (Zhu and Lee,
2001) to apply a conjugate prior structure where the π vector follows a sym-
metric Dirichlet density with prior vector (d, d, . . . , d). The conditional update

306
Applied Bayesian Hierarchical Methods
for the subgroup probabilities π is then Dirichlet with elements d + nk, where
nk is the number allocated to the kth subpopulation at a particular MCMC
iteration.
As well as facilitating estimation, assessing the ﬁt of diﬀerent models and
the appropriateness of their assumptions (e.g., normality or otherwise of con-
struct scores and measurement errors) is arguably more straightforward using
augmented data. For example, predictive discrepancies using the complete
likelihood are mentioned by Zhu and Lee (2001, 141). For replicate data, yrep
i
,
sampled from the model, one possible discrepancy criterion is
D =
K

k=1

Si=k
(yrep
i
−αk −ΛkFki)′Σ−1
k (yrep
i
−αk −ΛkFki).
Since D is chi-square with nP degrees of freedom, one may use the pre-
dictive check at each MCMC iteration,
Pr(χ2
nP ≥D(t)),
and assess the posterior probability over a long MCMC sampling run.
A discrete mixture structural equation model extends Equation 7.5 to both
endogenous and exogenous manifest indicators, and to specify a structural
model also speciﬁc to each subpopulation or component. Consider a P1 × 1
vector, yi, of endogenous indicators, and a P2 × 1 vector, xi, of exogenous in-
dicators. Conditional on membership of the kth subpopulation, one has mea-
surement models,
yi = α1k + Λ1kFki + uki,
xi = α2k + Λ2kHki + wki,
where uk and wk are normal with mean zero and covariances Σ1k and Σ2k.
The endogenous indicators measure an endogenous construct vector Fki =
(Fk1i, . . . , FkQ1i)′, of dimension Q1 < P1, and the exogenous indicators mea-
sure the exogenous construct vector, Hki, of dimension Q2, assumed to be
NQ2(0, ϕk). The structural model speciﬁes,
Fki = ak + BkFki + CkHki + eki,
where eki ∼NQ1(0, ψk), Bk is Q1 × Q1 with a diagonal of zeroes, and Ck is
Q1 × Q2 containing regression eﬀects of exogenous on endogenous constructs
in the kth subpopulation. Letting B0k = I −Bk, the covariance matrix of
(Fki, Hki) is given (Lee, 2007, 322) by,
Ωk =

B−1
0k (CkϕkC′
k + ψk)(B−1
0k )′
B−1
0k Ckϕk
ϕkC′
k(B−1
0k )′
ϕk

,
and the observed data likelihood in the kth subpopulation has covariance
ΛkΩkΛk + Σk, where Σk = diag(Σ1k, Σ2k) and Λk = diag(Λ1k, Λ2k).

Multivariate Priors, with a Focus on Factor and SEMs
307
7.5.3
Robust density assumptions in factor models
Discrete mixture estimation can be demanding with questions of the ap-
propriate number of components, K, and labeling issues. An alternative to
discrete mixtures, for instance in relation to robust random error or factor
speciﬁcation, involves the use of heavy-tailed or skew densities (Ando, 2009;
Yuan et al., 2004). Consider the linear factor reduction model (Equation 7.1),
namely, yi = α + ΛFi + ui. Instead of conventional normality assumptions
for residuals ui = (u1i, . . . , uPi)′ or factor scores Fi = (F1i, F2i, . . . , FQi)′, one
might use options that are robust to measurement or construct outliers. For
example, a Student t model with ν1p degrees of freedom for the measurement
model regressions for ypi is obtainable via scale mixing, with,
ypi ∼N(αp + ΛpFi, σ2
p/ζpi),
ζpi ∼Ga(0.5ν1p, 0.5ν1p).
To identify possible outliers, one may monitor the lowest weights, ζpi. As-
sume also standardized and uncorrelated factor scores, but following a Student
t rather than normal density. Then the corresponding heavy-tailed construct
score model is
Fqi ∼N(0, 1/ωqi),
ωqi ∼Gamma(0.5ν2q, 0.5ν2q).
Skewness in outcomes or factor scores may also be present. Following Az-
zalini (1985), let f and g be symmetric probability density functions, with G
being the cumulative distribution function (cdf) associated with g. Then for
location parameter µ and scale parameter σ, the density,
2
σf

x −µ
σ

G

κx −µ
σ

,
is a skew pdf for any κ. If f = φ and G = Φ, one obtains the skew-normal
distribution. Positive (negative) values of κ indicate positive (negative) skew-
ness, while κ = 0 provides the normal density. Bazan et al. (2006) consider
application of the skew-normal density in item analysis. For binary items,
p = 1, . . . , P, and with δp = (κp/
8
(1 + κ2p)), they deﬁne a skew probit IRT
model involving a common factor, Fi, and item-speciﬁc eﬀects, Vpi, to allow
for skew errors. So,
y∗
pi ∽N(αp + λpFi + δpVpi, 1 −δ2
p) I(Api, Bpi),
Fi ∼N(0, 1);
Vpi ∼HN(0, 1),
with sampling limits {Api, Bpi} deﬁned according to the observed binary re-
sponses. This parameterization necessitates priors for δp in the interval [−1, 1].
Example 7.5. Market Segmentation: Discrete Mixture SEM
This
example follows the scenario provided by Jedidi et al. (1997, Figure 1).

308
Applied Bayesian Hierarchical Methods
The unobserved univariate aﬀect, F, for a new food product depends on two
latent product dimensions, sweetness (H1) and richness (H2). There are K = 2
unobserved consumer segments, of equal size πk = 0.5, the ﬁrst being “plea-
sure seeking” (with latent group indicator Si = 1) and the other “health
conscious” (Si = 2). Sweetness and richness have positive impacts on aﬀect
for the ﬁrst group, but negative impacts on aﬀect for the second group. Thus,
FSi,i = γSi,1H1i + γSi,2H2i + eSi,i,
where eki ∼N(0, 0.5), and there are positive impacts, γ11 = γ12 = 0.5, for the
ﬁrst consumer group, but γ21 = γ22 = −0.5 for the second. The response con-
struct, namely, aﬀect, and the exogenous constructs, sweetness and richness,
are each measured by two observed metric variables. Thus,
x1i = αx1 + λx11H1i + λx12H2i + w1i,
x2i = αx2 + λx21H1i + λx22H2i + w2i,
x3i = αx3 + λx31H1i + λx32H2i + w3i,
x4i = αx4 + λx41H1i + λx42H2i + w4i,
where wpi ∼N(0, 0.5), and the intercepts are αx1 = αx2 = αx3 = αx4 = 0.
Nonzero loadings are λx11 = λx21 = λx32 = λx42 = 1, and zero loadings are
λx12 = λx22 = λx31 = λx41 = 0. The exogenous constructs (H1i, H2i) follow
a bivariate normal density with mean zero and covariance terms, ϕ11 = 1,
ϕ22 = 1, ϕ12 = ϕ21 = 0.5. Also,
y1i = αy1 + λy1Fi + u1i,
y2i = αy2 + λy2Fi + u2i,
where αy1 = αy2 = 0; λy11 = λy21 = 1, and upi ∼N(0, 0.5).
The observed data generated under this scheme are the y and x variables.
First of all, a single population SEM is applied to the sampled data with
structural model,
Fi = γ1H1i + γ2H2i + ei,
and var(ei) = 1 for identiﬁcation. The Hqi are in standard form, taken to
be bivariate normal with correlation matrix containing an unknown ϕ12, with
both γ coeﬃcients then being unknowns that are assigned N(0, 10) priors. The
λx coeﬃcients are taken to deﬁne a conﬁrmatory model, and so only {λx11,
λx21, λx32, λx42} are taken as unknown (i.e., to have possibly nonzero values).
This simple structural model aggregates over two distinct subpopulations
(of equal size) and as might be expected, the γ coeﬃcients are estimated as
eﬀectively zero (with 95% credible intervals straddling zero) from the last
20,000 of a two chain run of 25,000 iterations. Otherwise, the original param-
eter structure is reproduced; for example, the posterior means for {λy1, λy2}
are {1.37, 0.98}, and for {λx11, λx21, λx32, λx42} are {1.05, 1, 1.23, 0.82}, while
for corr(H1, H2) the posterior mean is 0.40.

Multivariate Priors, with a Focus on Factor and SEMs
309
For the two population mixture SEM4, an identifying constraint is imposed
(to produce unique labeling for H scores), so for Si = k,
Fki = γk1H1i + γk2H2i + eki,
γ1k ∼N(0, 10)I(0, ), γ2k ∼N(0, 10)I(, 0).
A Dirichlet prior with unity weights is assumed for the prior subpopulation
proportions. With the same run lengths as for the single population SEM, the
estimated structural parameters clearly distinguish the two populations. Thus,
the posterior means parameters {γ11, γ12} in the pleasure-seeking population
are {0.84, 0.59} with entirely positive credible intervals, while for the health-
conscious population the parameters {γ21, γ22} have means {−0.76, −0.73}.
The subpopulation probabilities are estimated at 0.52 and 0.48, with the cor-
relation ϕ12 between sweetness and richness estimated at 0.46.
Example 7.6. Greek Crimes by Prefecture: Nonparametric Prior for
Random Eﬀects
The analysis of the Greek crime data in Example 7.2 as-
sumed normally distributed errors, upi, in the log link model for the crime
rates, ρpi, As noted by Knorr-Held and Rasser (2000), a fully parametric
speciﬁcation of the random eﬀects distribution may result in oversmoothing,
and in masking local discontinuities especially when the true distribution is
characterized by a ﬁnite number of locations. Here a truncated Dirichlet pro-
cess prior is adopted to model the density of the residuals, upi, with potential
values {u∗
pk, p = 1, . . . , P} from K clusters centered on the multivariate nor-
mal, G0 = NP (0, D), where P = 4. D−1 has a Wishart prior with identity
scale matrix and P degrees of freedom.
Thus the inﬁnite DP representation is approximated by one truncated
at K ≤n components, with appropriate values, upi, for prefecture i chosen
according to an allocation indicator, Si ∈(1, . . . , K). The probabilities, πk,
of allocation to clusters {1, . . . , K} are determined by K −1 beta distributed
random variables, Vk ∽Beta(1, κ), with unknown concentration parameter κ
and VK = 1 to ensure the random weights, πk, sum to 1 (Ishwaran and James,
2001; Sethuraman, 1994). Then, π1 = V1 and
πk = (1 −V1)(1 −V2) · · · (1 −Vk−1)Vk
k > 1.
Following Ishwaran and Zarepour (2000, 377), the gamma prior for κ,
namely, κ ∼Ga(ν1, ν2), has relatively large ν1 and ν2, with ν2 set larger than
ν1. Such a setting discourages small and large values for κ. Here, ν2 = 4 and
ν1 = 2. The maximum possible clusters is set at K = 20.
A two chain run of 7500 iterations5 shows early convergence and repli-
cates Example 7.2 in showing mostly nonsigniﬁcant predictor eﬀects. There
are, however, signiﬁcant positive eﬀects of unemployment on rape, and of ur-
ban center on manslaughter, and a signiﬁcant negative eﬀect of GDP levels
on manslaughter. The posterior mean deviance Dev is 231 with 81 eﬀective
parameters, giving a DIC of 312. This is obtained by comparing Dev with

310
Applied Bayesian Hierarchical Methods
0
0.5
1
–0.5
0
0.5
1
1.5
Manslaughter
0
0.2
0.4
0.6
0.8
–2
–1
0
1
2
Smuggling
0
0.2
0.4
0.6
0.8
–2
–1
0
1
2
3
Arsons
0
0.2
0.4
0.6
0.8
1
Density
Density
Density
Density
–1
–0.5
0
0.5
1
Rape
FIGURE 7.1
Residual plots, DPP mixture model.
the deviance at the posterior means of the Poisson means µpi. The posterior
mean for κ is 1.32 (from the second half of the MCMC iterations) with the
average number of nonempty clusters, K∗, being 8.45. Kernel smoothed plots
of the posterior mean residuals demonstrate greater apparent non-normality
for the last three outcomes (see Figure 7.1, which uses a Gaussian kernel with
optimal half width).
Example 7.7. Maths Aptitude: Skew Probit
A skew probit link is
adopted for the data from Tanner (1996) following the approach of Bazan
et al. (2006). So latent metric data are sampled according to,
y∗
pi ∽N(αp + λpFi + δpVpi, 1 −δ2
p),
with Fi ∼N(0, 1) and λp all being unknowns. A U(−1, 1) prior is adopted on
the δp parameters, and,
λp ∼N(1, 0.5) I(0, ),
providing an identifying constraint (cf. Sahu, 2002).
A two chain run of 10,000 iterations (with convergence at under 1,000)
shows none of the δp (and hence κp) parameters to be signiﬁcantly positive or

Multivariate Priors, with a Focus on Factor and SEMs
311
negative. Despite the apparent absence of skew, this model has log(psML)=
−149, and posterior mean percentages of predictive concordance for the six
items raised to (57.3, 58.5, 67.3, 66.6, 70.6, 67.0). The gain in performance over
the analysis in Example 7.4 may be related to the introduction of subject-item
level parameters, Vpi.
7.6
Multivariate Spatial Priors for Discrete
Area Frameworks
Consider multivariate spatial responses (y1i, . . . , yPi)′ of dimension P from an
exponential family density observed over n discrete areas (e.g., administra-
tive regions). Conditional on spatial eﬀects, si = (s1i, . . . , sPi)′, of the same
dimension, and predictors, xi = (x1i, . . . , xRi)′, one then has,
p(ypi|spi, xi) ∝exp
*ypiθpi −b(θpi)
φpi
+ c(ypi, φpi)
+
,
where θpi is the canonical parameter, and φpi a known scale. Denoting regres-
sion terms as ηpi = g(θpi) with link g, such a term is likely to include a random
eﬀect, spi, to measure spatially conﬁgured but unmeasured predictors. So one
has at a minimum the representation,
ηpi = αp + βpxi + spi,
where the spatial eﬀects for area i, si = (s1i, . . . , sPi)′, follow a multivariate
spatial prior. For certain deﬁnitions of spatial eﬀects, it may be appropriate to
also include unstructured (i.e., exchangeable over areas) multivariate eﬀects,
in line with a multivariate form of the Besag et al. (1991) convolution prior.
Thus, the full dimension analogue to the convolution prior is
ηpi = αp + βpxi + spi + upi,
(7.6)
where upi also follow a multivariate prior. Other possibilities, following
Chapter 5, include regression eﬀects, βpi, which vary spatially as well as over
response variables.
Conditions for a valid multivariate spatial prior, speciﬁcally a multivariate
Gaussian Markov random ﬁeld (MGMRF), are discussed by Rue and Held
(2005, Section 2.2) and Banerjee et al. (2004, Section 7.4). Thus, denote the
nP length vector over all areas as s = (s1, . . . , sn)′, and denote the mean
vector, possibly including regression eﬀects, as µi = (µ1i, . . . , µPi), with µ =
(µ1, . . . , µn)′. Also denote the matrix describing observed spatial interactions
in the region by W = [wij], with wij = wji, and set D = diag(d1, . . . , dn),
where di = 
j̸=i wij. If wij = 1 when areas i and j are contiguous, and zero
otherwise, then di is the number of neighbors for area i. The neighborhood

312
Applied Bayesian Hierarchical Methods
for area i is often denoted ∂i, and if area j is a neighbor of area i, then the
neighbor relation (under binary interaction) is denoted j ∼i.
The joint density for a normal MGMRF for P spatial eﬀects and with
nP × nP precision matrix Q may be expressed,
p(s|Q) =

 1
2π
nP/2
|Q|0.5 exp[(s −µ)′Q(s −µ)]
=

 1
2π
nP/2
|Q|0.5 
ij
exp[(si −µi)′Qij(sj −µj)].
Q is block diagonal with P × P submatrix elements Qij that are nonzero
(zero) if area j is (is not) a neighbor of area i. Retaining the possibility of a
regression model in the means µi (Rue and Held, 2005), the corresponding
full conditional density is
si|s[i] ∼N

µi −Q−1
ii

j̸=i
Qij(sj −µj), 1
Qii

,
with conditional precision matrices,
prec(si|s[i]) = Qii = ∆i.
Equivalently, deﬁne P × P matrices, Bij = −Qij/Qii, with Bii = 0, and
∆i = Qii. Then,
E(si|s[i]) = µi +

j̸=i
Bij(sj −µj),
(7.7)
prec(si|s[i]) = ∆i.
Most commonly the µi are set to zero.
Under the parameterization in Equation 7.7, the joint density has mean µ
and precision matrix Q = ∆(I −B), where ∆is block diagonal with blocks
∆i, and the nP × nP matrix B is block diagonal with (i, j)th block Bij. The
requirements for a valid joint density to exist (e.g., if speciﬁcation is starting
from a prior involving the full conditionals) are that (Sain and Cressie, 2007;
Rue and Held, 2005, 31),
∆iBij = ∆jBji.
For example, setting Bij = [wij/di]IP ×P , and ∆i = diζ (where ζ is a P ×P
within area precision matrix) will ensure a valid joint density.
A number of multivariate priors that incorporate spatial dependence be-
tween areas have been proposed. The generalization of the intrinsic univariate
CAR to a multivariate setting, is denoted as the multivariate CAR or MCAR
prior (Mardia, 1988; Jin et al., 2005, Equation 6; Song et al., 2005, 254). This

Multivariate Priors, with a Focus on Factor and SEMs
313
takes the vector of multivariate area eﬀects, s, as multivariate normal with
mean consisting of a vector of zeroes of length nP, and with nP ×nP precision
matrix, Q = (D −αW) ⊗ζ, namely,
p(s|ζ, α) =

 1
2π
nP/2
|D −αW|P/2|ζ|n/2 exp

−1
2s′Qs

,
(7.8)
where α ∈(0, 1) is a propriety parameter. The P ×P positive deﬁnite symmet-
ric matrix, ζ−1, describes covariation between the outcomes, and D −αW is
the precision matrix for the spatial eﬀects. The latter matrix can also be writ-
ten as D(I −αB) where B = D−1W. Let the eﬀects be arranged by variable
rather than subject, so that S1 = (s11, s12, . . . , s1n)′, S2 = (s21, s22, . . . , s2n)′,
etc., then for P = 2, the joint prior is

S1
S2

∼N

0
0

,

ζ11(D −αW)
ζ12(D −αW)
ζ12(D −αW)
ζ22(D −αW)
−1
,
where each submatrix, ζpq(D −αW), is of dimension n × n.
The conditional prior under Equation 7.8 for si given the remaining ef-
fects, s[i] = (s1, . . . , si−1, si+1, . . . , sn), is multivariate normal with means
E(si|s[i]) = (M1i, . . . , MPi), where,
E(spi|s[i]) = Mpi = α

j̸=i
wijspj
, 
j̸=i
wij,
and with precisions,
prec(si|s[i]) = diζ.
If wij are set to 1 for neighboring areas and to 0 otherwise, then Mpi =
α 
j∈∂i spj/di are locality averages of the spatial eﬀect for the pth response.
Setting α = 1 provides the multivariate version of the intrinsic CAR prior of
Besag et al. (1991); such intrinsic GMRFs (for spatial and nonspatial priors)
are considered by Rue and Held (2005, Chapter 3).
MacNab (2007) discusses a multivariate extension of the prior of Leroux
et al. (1999), which allows the data to determine the appropriate mix between
spatial or exchangeable dependence. Hence, if a mix of local and global
smoothing is regarded as a reasonable prior structure, this may be achieved
with a single set of random eﬀects, rpi, rather than the two sets {spi, upi}
present in the multivariate extension (Equation 7.6) of the convolution prior.
Thus, with ri = (r1i, . . . , rPi)′, parameter κ ∈(0, 1), and spatial interactions
W = [wij],
E(ri|r[i]) = [M1i, . . . , Mpi] = κ

j̸=i
wijIP rj

1 −κ + κ

j̸=i
wij

,
prec(ri|r[i]) =

1 −κ + κ

j̸=i
wij

ζ,

314
Applied Bayesian Hierarchical Methods
where, as above, ζ is of dimension P × P. Thus,
Bij =

κwij
[1 −κ + κ 
j̸=i wij]

IP ×P ,
∆i =

1 −κ + κ

j̸=i
wij

ζ,
and ∆iBij = ∆jBji holds. When wij are binary adjacency indicators, the
conditional expectations become,
E(rpi|r[i]) = Mpi =
κ 
j∈∂i rpj
[1 −κ + κdi].
Deﬁne,
H = diag

1 −κ + κ

j̸=1
w1j, . . . , 1 −κ + κ

j̸=n
wnj

= (1 −κ)In + κD.
Then the joint density is multivariate normal with mean vector 0 and
nP × nP precision matrix (H −κW) ⊗ζ.
Jin et al. (2005) propose a generalized MCAR (GMCAR) model whereby
the joint distribution for a multivariate spatial eﬀect is obtained by specify-
ing a sequence of conditional and marginal models. Let eﬀects be arranged
by variable rather than subject. Then for a bivariate spatial eﬀect with
P(S1, S2) = p(S1|S2)P(S2), where S1 = (s11, s12, . . . , s1n)′ and S2 = (s21,
s22, . . . , s2n)′, one has,

S1
S2

∼N


0
0

,

Σ11
Σ12
Σ12
Σ22

,
where E(S1|S2) = Σ12Σ−1
22 S2, and var(S1|S2) = Σ11.2 = Σ11 −Σ12Σ−1
22 Σ′
12.
Hence with G = Σ12Σ−1
22 , one has equivalently,

S1
S2

∼N


0
0

,

Σ11.2 + GΣ22G′
GΣ22
(GΣ22)′
Σ22

.
To specify the joint distribution of S1 and S2, it is therefore necessary to
specify the matrices Σ11.2, Σ22, and G.
Jin et al. take Σ−1
11.2 = τ1[D −α1W], Σ−1
22
= τ2[D −α2W], and G =
γ0I + γ1W. The marginal joint prior for the second set of eﬀects is then,
S2 ∼N(0, τ−1
2 [D −α2W]−1),
and the conditional prior for the ﬁrst set of eﬀects is
S1|S2 ∼N(GS2, τ−1
1 [D −α1W]−1).

Multivariate Priors, with a Focus on Factor and SEMs
315
As above, the 0 < αj < 1 are propriety parameters, and the γ0 param-
eter links diﬀerent variable-same area eﬀects, namely, regresses s1i on s2i,
while γ1 links s1i with other variable-other area eﬀects {s2j, j ̸= i}. This
approach is possibly more suitable for small P, as P! conditional density se-
quences are possible, and may give diﬀerent inferences or ﬁts—though Jin
et al. (2005, 957) demonstrate how initial regression analysis may lead one to
prefer one sequence to another6.
7.7
Spatial Factor Models
When high correlations are evident in ζ−1, common spatial factor models may
be more parsimonious (Congdon et al., 2007; Liu et al., 2005; Tzala and Best,
2007). Standard presentations of the normal and general linear factor models
assume factor scores are independent over subjects, though in fact they might
be spatially or temporally structured. So for P outcomes, Q factors, and for
P > Q in a spatial application, the F scores of dimension Q may be correlated
over both variables and areas. Then for Poisson or binomial responses with
mean µpi = g−1(ηpi) for the pth dependent variable and area i, one might
have a regression term,
ηpi = αp + βpxi + ΛpFi,
where the vector Λp is of dimension Q, and the factor score variables
Fi = (F1i, . . . , FQi)′ are spatially dependent over areas i, as well as mutually
intercorrelated. For example, a MCAR prior would specify the joint pairwise
diﬀerence density for the factor scores,
p (F |ΣF) ∝| ΣF |−n/2 exp

−0.5

i,j
wij(Fi −Fj)′Σ−1
F (Fi −Fj)

.
As in other factor models, constraints are required to deal with location,
scale, and rotational indeterminacy. In the multivariate CAR model for Fi =
(F1i, . . . , FQi)′, the location is ﬁxed in practice by centering each of the Q sets
of spatial factor scores at each MCMC iteration. Scale may be determined by
ﬁxing the Q variances of the Fqi scores at 1, or by ﬁxing one of the loadings
(λ1q, . . . , λPq) linking the P manifest indicators to the qth factor. Additional
loadings would need to be ﬁxed to avoid rotational indeterminacy, typically
λpq = 0 for q > p. For example, if Q = 2, and the variances of the F scores
are free parameters, then the two loadings, λqq, may be set to 1 to deﬁne the
scale, while rotational invariance is avoided by setting λ12 = 0.
A simultaneous errors approach to a spatial SEM is provided by Oud and
Folmer (2008). Let W = [wij] denote a row standardized spatial interaction
matrix (Anselin and Hudak, 1992, 514). The structural model interrelating

316
Applied Bayesian Hierarchical Methods
the factor scores has a MIMIC form involving known exogenous variables, Xi,
and the spatially lagged transform (weighted average of neighboring values)
of a Q dimensional factor score vector Fi,
Fi = ρWF i + γXi + ζi,
where ζi is an error vector with preset variances, and ρ has maximum value 1
and can be taken to have minimum 0.
Example 7.8. Psychiatric Hospitalizations in England
This
exam-
ple contrasts a full dimension covariance model for multivariate spatial out-
comes with a common spatial factor approach. It considers gender-speciﬁc
counts of hospitalizations for schizophrenia and bipolar disorder for 354
English local authorities over 2002–2003 to 2004–2005 for patients aged 15
to 64. The P = 4 outcomes are counts ypi of male schizophrenia, female
schizophrenia, male bipolar disorder, and female bipolar disorder; oﬀsets are
expected hospitaliations, Epi, based on England-wide hospitalization rates
speciﬁc to gender and ﬁve-year age bands (15–19, 20–24, etc.).
The ﬁrst model applied is the multivariate generalization of the Leroux
et al. (1999) conditional autoregressive prior (LMCAR) under a Poisson like-
lihood, and with binary adjacencies, wij. Then the ﬁrst regression involves
a constant term and spatially conﬁgured eﬀects (r1i, . . . , rPi) that are of the
same dimension as the response vector,
ypi ∼Po(Epieηpi),
ηpi = αp + rpi.
The conditional mean of rpi is
E(rpi|r[i]) = Mpi = κ 
k∈∂i rpk
[1 −κ + κdi],
where κ is between 0 and 1. A Wishart prior for the conditional precision
matrix, ζ, with prior mean covariance I, is assumed7.
Early convergence is attained in a two chain run of 5000 iterations, with
the last 4000 showing a mean scaled deviance of 1474 (compared to 4 × 354 =
1416 observations), with de = 1124, and a posterior mean (sd) for κ of 0.66
(0.09) Setting Φ = ζ−1, mean correlations, rjk = Φjk/(ΦjjΦkk)0.5, between
the spatial eﬀects vary from 0.66 (between y2 and y3) to 0.87 (between the
two bipolar disorder outcomes y3 and y4). The correlation between the two
schizophrenia outcomes is also high, namely, 0.86.
Only one observation is not contained within the 95% intervals of replicate
data sampled from the model, suggesting that a less heavily parameterized
model could be found still giving a satisfactory ﬁt. A common factor model is
therefore applied with,
ηpi = αp + λpFi,

Multivariate Priors, with a Focus on Factor and SEMs
317
where Fi follows a univariate (LCAR) prior. Thus for κ ∈(0, 1), conditional
precision τF , and with F[i] = (F1, . . . , Fi−1, Fi+1, . . . , Fn) and binary spatial
interactions W = [wij],
E(Fi|F[i]) =
κ 
j∈∂i Fj
[1 −κ + κdi],
and
prec(Fi|F[i]) = [1 −κ + κdi]τF .
With τF = σ−2
F
taken as unknown, with prior σF ∼U(0, 1000), one of
the loadings λj must be ﬁxed for identiﬁcation, and accordingly λ1 = 1. This
model has a posterior mean scaled deviance of 8125 and only 69% coverage of
the observations by 95% intervals of replicate data sampled from the model.
To improve ﬁt, a two factor analysis is applied. The revised model is con-
ﬁrmatory in the sense that certain loadings are set to zero. The full dimension
error model showed high correlations between male and female outcomes with
the same diagnosis, and the conﬁrmatory model framework accordingly in-
volves two diagnosis-speciﬁc factors, F1i for schizophrenia and F2i for bipolar
disorder. These are, however, assumed to be correlated under a bivariate LM-
CAR prior. The loadings {λ31, λ41, λ12, λ22} are set to zero in line with a
conﬁrmatory analysis.
To further ensure adequate predictive ﬁt, outcome-speciﬁc unstructured
eﬀects are included, but with a selection mechanism to avoid excess parame-
terization. Thus, exchangeable errors upi ∼N(0, 1/τp) are added only when a
binary area speciﬁc indicator δi is 1, with the prior probability πδ = Pr(δi = 1)
set low at 0.05. The selection mechanism corresponds to a prior expectation
that unusual psychiatric referral patterns over outcomes tend to occur in par-
ticular areas, perhaps due to distinctive care provision in such areas.
Then, ypi ∼Po(Epieηpi) with,
η1i = α1 + λ11F1i + δiu1i,
η2i = α2 + λ21F1i + δiu2i,
η3i = α3 + λ32F2i + δiu3i,
η4i = α4 + λ42F2i + δiu4i.
The prior variances of the two factors are taken as unknown, so an an-
choring constraint needs to be used for identiﬁcation, with loadings λ11 and
λ32 set to 1. N(0, 1) priors are assumed for the two unknown loadings. A two
chain run (5000 iterations, with the last 4000 for inference) converges early
and provides precise estimates for the loadings, with mean (sd) for λ21 of 1.05
(0.02) and for λ42 of 0.96 (0.02).
There is correlation of 0.77 between the two factors, with the κ parameter
in the spatial prior estimated at 0.66 (with 95% interval from 0.47 to 0.91).
Predictive ﬁt seems adequate with only 4 out of 1416 observations having

318
Applied Bayesian Hierarchical Methods
probabilities of underprediction (Marshall and Spiegelhalter, 2007) below 0.05
or above 0.95. In fact, all four are overpredicted; that is, they have posterior
probabilities of underprediction below 0.05. However, despite apparent pre-
dictive adequacy, the posterior mean scaled deviance stands at 2026, in excess
of the number of observations.
7.8
Multivariate Time Series
Multivariate time series can occur in several ways. One example is where
the same measurement process (e.g., repeated environmental readings) is car-
ried out at several locations and where high correlation between the series
is expected. Another situation occurs with ﬁnancial data, such as exchange
rates or stock returns, where high correlations observed raise questions such
as whether there are feedbacks between diﬀerent series, or whether common
factors (e.g., market risk) aﬀect all series. Classical approaches using autore-
gressive moving average models rest on assumptions that series are stationary,
typically after transformation or diﬀerencing. In econometrics, time series are
said to be integrated of order d or I(d), when diﬀerencing to order d of the
original series is needed for stationarity. Such series are cointegrated if some
linear combination of the series has a lower order of integration than the indi-
vidual series (Phillips and Durlauf, 1986). A particular case of cointegration
is when two series, yt and xt, are both I(1), but there is a parameter α such
that ut = yt −αxt is stationary (integrated of order zero).
Much classical multivariate time series analysis is based on extending the
ARMA model to vector responses (Tiao and Tsay, 1989). For observation
vector, yt = (y1t, . . . , yPt)′, the vector ARMA(r, s) model has the form,
yt = µ + Φ1yt−1 + · · · + Φryt−r + ut −Θ1ut−1, . . . , −Θsut−s,
where the coeﬃcient matrices are all of order P ×P, and ut denotes P-variate
white noise, with E(ut) = 0, and
E(utu′
t−k) = 0
k ̸= 0;
E(utu′
t−k) = Σ
k = 0.
For the vector autoregressive or VAR model obtained by omitting mov-
ing average terms, stationarity requires that the roots of the characteristic
equation,
det(I −Φ1z + · · · + Φrzr) = 0,
lie outside the unit circle. Bayesian analyzes of the VAR model are exten-
sive, and include treatments of cointegration (Koop et al., 2006), model
selection and averaging (Andersson and Karlsson, 2007), and informative

Multivariate Priors, with a Focus on Factor and SEMs
319
and restricted priors (Litterman, 1986; Sims and Zha, 1998). A library of
MATLAB programs is available for Bayesian VAR estimation at http://home
.earthlink.net/˜tzha02/ProgramCode/programCode.html.
7.8.1
Multivariate dynamic linear models
The structural model approach is widely applied in Bayesian time series
studies (e.g., Carter and Kohn, 1994; West and Harrison, 1997; Durbin and
Koopman, 2000) and focuses on underlying components of multiple series
without requiring initial diﬀerencing. The multivariate normal dynamic linear
model (DLM) speciﬁes,
yt = Ftθt + et,
et ∼N(0, Vt),
t = 1, . . . , T,
θt+1 = Gtθt + Rtut,
ut ∼N(0, Wt),
where yt is a P × 1 observation vector, and θt is a Q × 1 latent state vector
following a Markov process. The disturbance vectors, et and ut, are normally
distributed, and uncorrelated with each other and over time. The initializing
prior for the state vector is typically assumed to be normal with mean m1 and
covariance matrix C1, θ1 ∼N(m1, C1). The system matrices Ft, Gt, Vt, Wt,
and Rt may be assumed to be known, in which case simple updating, forecast-
ing, and ﬁltering densities can be derived—see West and Harrison (1997, 582).
In more realistic settings where the covariances Vt and Wt are unknown, time-
invariant assumptions, such as Vt = Σe and Wt = Σu, are one possible pa-
rameterization. A simple case occurs (Koopman and Durbin, 2000) when Vt
is diagonal, the assumption being that the observations are independent con-
ditional on the latent states.
Common model forms include the local level (LL) model with measurement
and transition equations,
yt = θt + et,
et ∼N(0, Σe),
θt+1 = θt + ut,
ut ∼N(0, Σu),
t = 1, . . . , T,
where yt is a P × 1 metric observation, θt also has dimension P, and Σe and
Σu are of dimension P × P. A local linear trend (LLT) includes a mechanism
for trend in the underlying levels, as in,
yt = θt + et,
et ∼N(0, Σe),
θt+1 = θt + δt + ut,
ut ∼N(0, Σu),
δt+1 = δt + wt,
wt ∼N(0, Σw),
t = 1, . . . , T.
For example, Proietti (2006) applies a LL model to measuring core in-
ﬂation, while Moauro and Savio (2005) apply a LLT approach to temporal
disaggregation of multiple economic series. Multivariate signal models may
be applied to measure latent risk, as in the accident rate and credit card use
examples of Bijlevel et al. (2005). This approach involves time series or panel

320
Applied Bayesian Hierarchical Methods
data on exposure totals (xt or xit), outcomes (yt or yit), and what may be
generically termed “losses” (zt or zit). A simple bivariate case with xt=vehicle
registrations and yt=motor accidents would lead to a model,
log(xt) = θ(E)
t
+ e(x)
t
,
log(yt) = θ(E)
t
+ θ(R)
t
+ e(y)
t
,
where the components of θt = (θ(E)
t
,θ(R)
t
) represent underlying log exposure
and log risk, which evolve according to a bivariate LLT,
θt+1 = θt + δt + ut,
ut ∼N(0, Σu),
δt+1 = δt + wt,
wt ∼N(0, Σw).
A simplifying “homogenous” model (Harvey, 1989, Chapter 8) for the co-
variance matrices is obtained for the LL model by setting,
Σu = qΣe,
where q is an unknown signal-to-noise ratio, and for the LLT model by setting,
Σu = q1Σe,
Σw = q2Σe.
Generalizations to include trend, seasonal, and cyclical eﬀects can be
made in which each sort of eﬀect is independent of the other and each fol-
lows its own multivariate evolution prior (Durbin and Koopman, 2001, 44).
These assumptions lead to what is termed a seemingly unrelated time se-
ries equations (SUTSE) model (Harvey and Koopman, 1997; Harvey and
Shephard, 1993), since the individual series are connected only via the corre-
lated disturbances in the measurement and transition equations. More com-
plex matrix normal priors (West and Harrison, 1997, 597) result from assuming
interdependence between diﬀerent types of parameter.
A multivariate model with level, seasonal, and cyclical eﬀects would
specify,
yt = θt + γt + ψt + et,
et ∼N(0, Σe),
θt+1 = θt + ut,
ut ∼N(0, Σu)
t = 1, . . . , T,
where the seasonal components for the pth variable (with s seasons) evolve
according to,
γpt = γp,t−1 + γp,t−2 + · · · + γp,t−s+1 + ωpt,
with
(ω1t, ω2t, . . . , ωPt) ∼N(0, Σω).
Following Harvey and Koopman (1997), the cyclical eﬀects, ψt, may be
assumed “similar,” namely, to have the same damping factor, ρ, and frequency,

Multivariate Priors, with a Focus on Factor and SEMs
321
0 ≤λ ≤π, across variables. The period is then 2π/λ with the full prior
being,
ψt = (ψ1t, ψ2t, . . . , ψPt) ∼N(mψ, Ση),
with additional shadow period eﬀects,
ψ∗
t = (ψ∗
1t, ψ∗
2t, . . . , ψ∗
Pt) ∼N(mψ∗, Ση∗),
where means mψp and mψ∗
p for the pth variable are obtained according to,
ψpt
ψ∗
pt

= ρ

cos(λ)
sin(λ)
−sin(λ)
cos(λ)
 ψp,t−1
ψ∗
p,t−1

+
ηpt
η∗
pt

.
It may be noted that multivariate DLMs occur in the analysis of univariate
data, for example for categorical and ordinal outcomes. Thus, Cargnoni et al.
(1997) propose a model for time series of a multinomial outcome with M
categories in which,
(y1t, y2t, . . . , yMt) ∼Mult(nt, [π1t, π2t, . . . , πMt]),
πmt = exp(ηmt)
 M

h=1
exp(ηht),
ηmt = αmt + βmxt
m = 1, . . . , M −1,
ηMt = 0,
where the time-varying category intercepts, αt = (α1t, . . . , αM−1,t), follow a
multivariate normal random walk prior,
αt ∼NM−1(αt−1, Σα).
West and Harrison (1997, 586) assume a normal approximation to the
multinomial in which,
ymt = ntπmt + emt,
and the vector of errors, et = (e1t, . . . , eMt), has a covariance matrix,
Vmmt = ntπmt(1 −πmt)
Vmkt = −ntπmtπkt
k ̸= m.
7.8.2
Dynamic factor analysis
Time series factor models become sensible for large P, as they result in less
heavy parameterization of covariance between series, and may provide in-
sights into latent structure, as well as more eﬃcient inferences and forecasts
(Durbin and Koopman, 2001). Typically, the covariance structure between

322
Applied Bayesian Hierarchical Methods
series is attributed to the common factors only, with observation errors as-
sumed independent (Jungbacker et al., 2009). There are a number of appli-
cation areas, and Bayesian approaches have been important. Prado and West
(1997) consider the case of a single latent series, Ft, underlying multiple series,
yt = (y1t, . . . , yPt), of electroencephalogram readings, and discuss TVAR
autoregressive models for the latent Ft involving time-varying coeﬃcients
that follow random walk priors. Thus with ﬁrst order random walk priors
in h = 1, . . . , r autoregressive parameters one has,
ypt ∼N(αp + λpFt, τy),
Ft ∼N
 r

h=1
φhtFt−h, τF

,
φht ∼N(φh,t−1, τh).
Another example occurs in econometric modeling of asset returns, where
the number of assets may exceed the length of the time series and factor models
for returns are a clear option (Zivot and Wang, 2006). Factor models are
also one approach to multivariate volatility (changing variances)—see Section
7.8.3.
A relatively simple approach for reducing a metric P vector yt to a Q
vector Ft involves a dynamic linear model for the factor score vector. Thus, a
local linear factor or factor trend model would propose a measurement model
linking indicators and factors,
yt = α + ΛFt + et,
et ∼N(0, Σe)
t = 1, . . . , T,
with the transition equation specifying a random walk in the factors, namely,
Ft+1 = Ft + ut,
ut ∼N(0, Σu),
where Ft is a Q × 1 multivariate latent construct, with Q < P, and Λ is of
dimension P × Q. If the series, et and Ft, are uncorrelated, then the marginal
mean and covariance of yt are α and ΛΣuΛ+Σe, respectively. To avoid location
invariance in the F scores, devices such as centering at each iteration or setting
initial factor scores to known values can be used (see Example 7.10).
The loadings matrix Λ and/or the factor score covariance matrix Σu are
parameterized to ensure identiﬁcation and avoid various forms of invariance.
If all elements in Σe are taken as unknown (i.e., oﬀ-diagonal as well as diagonal
terms) and Σu is also unknown, then Harvey and Koopman (1997) mention
the form,
Λ =

IQ
Λ∗

,
with Λ∗of dimension (P −Q) × Q containing unknown loadings. If Σe is di-
agonal (that is, just residual variances are assumed unknown), and Σu is also
diagonal but contains unknown factor variances, then one may set λpp = 1
and λpq = 0 for q > p. This is the anchoring constraint of Skrondal and

Multivariate Priors, with a Focus on Factor and SEMs
323
Rabe-Hesketh (2004), with the latter constraint used to avoid rotation invari-
ance (Geweke and Zhou, 1996, 565–6).
If Σe contains just residual variances, and Σu is diagonal with known factor
variances (typically of 1), then constraints on λpq to ensure scale identiﬁcation
are not needed, but the rotational constraint, λpq = 0, for q > p still applies.
However, Geweke and Zhou (1996) suggest λpp > 0 as an identiﬁcation device
in this case, to ensure a unique labeling of factors.
7.8.3
Multivariate stochastic volatility
Many multivariate series (e.g., share prices, exchange rates, asset returns)
may be subject to volatility clustering, with the clustering correlated over
diﬀerent series. For example, Yu and Meyer (2006) mention that ﬁnancial
decision making needs to take correlations into account when market volatil-
ities move together across multiple assets. Harvey et al. (1994) suggested the
ﬁrst multivariate stochastic volatility (MSV) model, involving metric series
(y1t, y2t, . . . , yP t)′ either mean centered or in transformed form (e.g., logs of
successive share prices) with eﬀectively zero means.
Thus, for centered or appropriately transformed prices or returns, yt, one
possible MSV model is
yt = Htet,
Ht = diag(exp(h1t/2), ) exp(h2t/2), . . . , exp(hP t/2)),
with ht = (h1t, . . . , hPt)′, a vector of unobserved log variances (or volatilities),
typically evolving according to a stationary VAR scheme, either,
ht+1 = µ + φ(ht −µ) + ut,
or
ht = µ + φ(ht−1 −µ) + ut.
The errors in the price series and in the volatilities are assumed to be
multivariate normal or multivariate t, with the MVN assumption expressed,

et
ut

∼N

0
0
 
Re
0
0
Σu

,
where Re is a positive deﬁnite correlation matrix with a diagonal of ones, and
Σu is a P × P covariance matrix for volatility shocks. Taking Re to be nondi-
agonal means shocks in prices may be correlated, while taking Σu to be nondi-
agonal allows volatility shocks to be correlated (Yu and Meyer, 2006, 365–66).
The simplest form for the coeﬃcient vector in the VAR autoregression for ht
is φ = diag(φ11, φ22, . . . , φP P ), and this may be combined with a stationar-
ity assumption by adopting the prior φpp ∼U(−1, 1)
(Chan et al., 2006).

324
Applied Bayesian Hierarchical Methods
The autoregression can be extended to full vector autoregressive form at the
expense of heavier parameterization (Asai et al., 2006).
Yu and Meyer (2006) consider various extensions using a bivariate series
as an example. Thus, taking,
φ =

φ11
φ12
φ21
φ22

,
to be nondiagonal amounts to allowing bilateral Granger causality in volatility
between the two series. Allowing for Re to evolve through time according to
Ret =

1
ρt
ρt
1

,
means that not only log volatilities, ht, but also correlation coeﬃcients are
time varying. Speciﬁcally with,
ρt = exp(gt) −1
exp(gt) + 1,
an additional autoregression can be set, with,
gt+1 = µg + φg(gt −µg) + wt.
Factor analytic models may include a correlated volatility feature (Chan
et al., 2006; Pitt and Shephard, 1999). As an example, for two series {ypt, p =
1, 2} and a univariate factor, Ft, one might have,
y1t = λ1Ft + e1t,
y2t = λ2Ft + e2t,
with evolving variances for Ft and ept. The stochastic variance prior for the
residuals, ept, may include autoregressive dependence, since a factor structure
may be suﬃcient to account for the nondiagonal elements of the residual vari-
ance matrix of the outcomes, but not suﬃcient to explain all the marginal
persistence in volatility (Pitt and Shephard, 1999, 551). Thus one might have
Ft ∼N(0, eh1t), e1t ∼N(0, eh2t), and e2t ∼N(0, eh3t), with ﬁrst order au-
toregressive dependence in the log variances, hpt,
hpt = φphk,t−1 + upt
t = 2, . . . , T,
with possibly unknown initial conditions, hp1. For identiﬁcation, one may set
one or other of the λp parameters to 1 (an anchoring constraint). Alternatively,
a standardized factor constraint might be implemented by setting the scale
of the factors at one time point, for instance by taking F1 ∼N(0, 1), that is
h11 = 0.
Extensions to provide greater adaptivity in the modeling of stochastic
variances can be combined with factor reduction. Chib et al. (2005) propose
an MSV factor model that permits both series-speciﬁc jumps at each time,

Multivariate Priors, with a Focus on Factor and SEMs
325
and Student t innovations with unknown degrees of freedom. For bivariate
data and a univariate factor, this model has the form,
y1t = λ1Ft + δ1tq1t + ε1t,
y2t = λ2Ft + δ2tq2t + ε2t,
where qpt = 1 with probability πp, and εpt follow independent Student t
densities with unknown degrees of freedom, νp. In hierarchical form,
εpt = λptept,
λpt ∼Ga
νp
2 , νp
2

,
[e1t, e2t] ∼N(0, Vt),
where Vt is diagonal with elements exp(hpt), with evolution scheme,
hp,t+1 −µp = φp(hpt −µp) + σput,
ut ∼N(0, 1).
The variables, ζpt = log(1 + δpt), are assumed to be N(−0.5ξ2
p, ξ2
p) where
ξp are additional unknowns. The more general form for yt = (y1t, . . . , yPt)′
and Ft = (F1t, . . . , FQt)′, Q ≤P is
yt = ΛFt + ∆tqt + εt,
with identiﬁcation constraints λpp = 1 and λpq = 0 for q > p. These con-
straints set a scale and prevent rotation invariance. The covariance matrix for
Ft is diagonal with evolution scheme as for the log diagonal elements of Vt.
Example 7.9. Minks and Muskrats: Multivariate Dynamic Linear
Models
Harvey and Koopman (1997) consider a bivariate series, namely,
numbers of skins of minks and muskrats traded annually (1848–1909) by the
Hudson Bay Company. There is a prey-predator relationship between the
P = 2 species leading to interlinked cycles. A model is ﬁtted including trends
and similar cycles, so that,
yt = θt + ψt + et,
et ∼N(0, Σe),
θt+1 = θt + βt + ut,
ut ∼N(0, Σu),
βt+1 = βt + wt,
wt ∼N(0, Σw),
ψt = (ψ1t, ψ2t) ∼N(mψ, Ση),
ψ∗
t = (ψ∗
1t, ψ∗
2t) ∼N(mψ∗, Ση∗)
t = 1, . . . , T,
where the cyclical eﬀects for the two species have the same damping factor,
ρ ∼U(0, 1), and frequency, λ, and the nondiagonal covariance matrices are of
order P × P. Since the series contains 64 points, an informative assumption
is made that the period is between 4.2 and 21, namely, that λ ∼U(0.3, 1.5).
Taking a simple uniform prior on λ between 0 and π was associated with
implausibly low λ. Covariances are linked using the homogeneity assumption,
namely, Σu = quΣe, Σw = qwΣe, Ση = qηΣe, and Ση∗= qη∗Σe, with the
signal-to-noise ratios {qu, qw, qη, qη∗} all assumed to follow Ga(1, 1) priors. For

326
Applied Bayesian Hierarchical Methods
9.5
10.0
10.5
11.0
11.5
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63
Data
Trend mean
2.5%
97.5%
FIGURE 7.2
Data and trend, minks.
Σ−1
e , a Wishart prior assumes ﬁve degrees of freedom and a prior covariance
matrix based on the observed variances and covariance8.
With inferences from the second half of a two chain run of 10,000 iterations,
one ﬁnds the cycles have a mean period of 10.7 years, though this parameter
has a skew posterior density with lower and upper 2.5% points of 9.3 and 20.
Figures 7.2 and 7.3 show trends in the mink and muskrat series together with
the original data, while Figure 7.4 plots the two cycles. The posterior means
for qu, qw, qη, and qη∗are (0.088, 0.0036, 0.049, 0.13).
The interlinking of the two series (and its predator-prey nature) also shows
in a VAR(1) model with,
yt1 = γ1 + α11y1,t−1 + α12y2,t−1 + u1t,
yt2 = γ2 + α21y1,t−1 + α22y2,t−1 + u2t,
ut ∼N(0, Σu)
t = 2, . . . , T,
with y11 and y12 taken as known, and where Σu is nondiagonal. The esti-
mated α coeﬃcient matrix from the second half of a two chain run of 5000
iterations is

0.72
0.18
−0.45
0.92

,
though residuals between the two series are positively correlated after account-
ing for the lag 1 eﬀect of one series on the other.

Multivariate Priors, with a Focus on Factor and SEMs
327
11.50
12.00
12.50
13.00
13.50
14.00
14.50
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63
Data
Mean
2.5%
97.5%
FIGURE 7.3
Data and trend, muskrats.
–0.9
–0.7
–0.5
–0.3
–0.1
0.1
0.3
0.5
0.7
Mink cycle
Muskrat cycle
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63
FIGURE 7.4
Estimated cycles.

328
Applied Bayesian Hierarchical Methods
4.4
4.6
4.8
5
5.2
5.4
5.6
1
11
21
31
41
51
61
71
81
91
Series1
Series2
Series3
FIGURE 7.5
Flour price series.
Example 7.10. Common Factor Model for Flour Prices
Tiao
and
Tsay (1989) analyze a trivariate series formed by the logarithms of indices
of monthly ﬂour prices in Buﬀalo, Minneapolis, and Kansas City between Au-
gust 1972 and November 1980. The data are plotted in Figure 7.5, which shows
that the series are closely related, and a common factor model is indicated.
The variance of the factor scores, Ft, is taken as unknown, so a loading con-
straint is needed. The factor scores are assumed to follow a random walk with
F1 = 0 to identify the level of the scores. The residuals after accounting for the
common factor are assumed multivariate normal, with a Wishart prior on the
precision matrix with three degrees of freedom and a diagonal scale matrix.
The elements of the scale matrix are taken as the observed variances, Vp, of
the three series, leading to a data-based prior. Thus with P = 3,
ypt = αp + λpFt + upt,
(u1t, u2t, u3t) ∼NP (0, Σu);
Σ−1
u
∼W(PS, P);
S = diag(V1, V2, . . . , VP );
λ1 = 1;
λk ∼N(1, 1), k = 2, 3;
Ft ∼N(Ft−1, σ2
F )
t = 2, . . . , T;
F1 = 0; σF ∼U(0, 10).
An alternative model adopts a locally adaptive prior for the factor scores,
allowing for changing variance through time (Lang et al., 2002). Thus,

Multivariate Priors, with a Focus on Factor and SEMs
329
–0.2
–0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
1
11
21
31
41
51
61
71
81
91
Mean
2.5%
97.5%
FIGURE 7.6
Common factor score, model 1.
Ft ∼N(Ft−1, exp(ht))
t = 2, . . . , T;
ht ∼N(ht−1, τ−1
h )
t = 2, . . . , T;
τh ∼Ga(1, 1);
h1 ∼N(0, 1);
F1 = 0.
Following Migon and Moreira (2004), ﬁt is assessed using the predictive
approach of Gelfand and Ghosh (1998), based on a goodness of ﬁt term,
G = 
p

t(yrep,pt −ypt)2, and a penalty term, H = 
p

t var(yrep,pt).
Figure 7.6 shows the estimated factor scores through time under the constant
variance model. The posterior mean for σ2
F is 0.0018, with posterior mean for
G of 1.416 and with H = 1.107. The nonconstant variance model has very
similar ﬁt criteria, namely, a posterior mean for G of 1.423 with H = 1.106.
There seems little to choose between the models though the plot of the evolving
log variances (Figure 7.7) suggests a reduction in volatility in the second half
of the observation period.
Example 7.11. Multivariate Stochastic Volatility model for FTSE
and S&P ﬂuctuations during 2006–2007
This example follows the
FTSE 100 and S&P 500 stock indices {rpt, t = 1, . . . , 253; p = 1, 2} over
253 trading days (October 27, 2006–October 19, 2007, as recorded by
uk.ﬁnance.yahoo.com) that include two periods of market turbulence, the sec-
ond being associated with US subprime mortgage lending. Where a trading
day is present in one index but not the other, the gap is ﬁlled by taking
an average of the preceding and subsequent days. Figure 7.8 plots the series

330
Applied Bayesian Hierarchical Methods
–15
–13
–11
–9
–7
–5
–3
–1
1
0
1
5
9
13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89 93 97
2.5%
Mean
97.5%
FIGURE 7.7
Nonconstant log factor variance.
90
95
100
105
110
115
30/10/2006
13/11/2006
27/11/2006
11/12/2006
25/12/2006
08/01/2007
22/01/2007
05/02/2007
19/02/2007
05/03/2007
19/03/2007
02/04/2007
16/04/2007
30/04/2007
14/05/2007
28/05/2007
11/06/2007
25/06/2007
09/07/2007
23/07/2007
06/08/2007
20/08/2007
03/09/2007
11/09/2007
01/10/2007
15/10/2007
Relative to index start point (30–10–2006)
FTSE
S&P
FIGURE 7.8
US and GB share indices 30th October 2006–19th October 2007.

Multivariate Priors, with a Focus on Factor and SEMs
331
–2.5
–2
–1.5
–1
–0.5
0
0.5
1
1.5
2
30/10/2006
13/11/2006
27/11/2006
11/12/2006
25/12/2006
08/01/2007
22/01/2007
05/02/2007
19/02/2007
05/03/2007
19/03/2007
02/04/2007
16/04/2007
30/04/2007
14/05/2007
28/05/2007
11/06/2007
25/06/2007
09/07/2007
23/07/2007
06/08/2007
20/08/2007
03/09/2007
17/09/2007
01/10/2007
15/10/2007
h1
h2
FIGURE 7.9
Log volatility plot.
relative to their start points, namely, in the form 100rpt/rp1. The data to be
analyzed are obtained as ypt = 100rp,t/rp,t−1 −100.
The model allows for correlated shocks in the stock exchange variables and
correlated log variances, so that,
yt = Htet,
Ht = diag[exp(h1t/2), ) exp(h2t/2)],
with unobserved log volatilities ht = (h1t, h2t)′ evolving via a VAR(1) model,
ht+1 = µ + diag(φ11, φ22)(ht −µ) + ut,
h1 = µ + u1.
The errors in the price series and volatilities equations are multivariate
normal,

et
ut

∼N

0
0
 
Re
0
0
Σu

.
where Re is a nondiagonal correlation matrix, and Σu is also nondiagonal,
allowing volatility shocks to be correlated (Yu and Meyer, 2006, 365–66).
The WinBUGS code9 follows Yu and Meyer (2006) in sampling standard
normal h∗
1t and h∗
2t and applying the standard deviations (σu1, σu2) and corre-
lation ρu of the u1t and u2t series to the standard normal log volatilities. Thus,
h1t = σu1h∗
1t,
h2t = σu2ρuh∗
1t + σu2(1 −ρ2
u)0.5h∗
2t.

332
Applied Bayesian Hierarchical Methods
This raises an identiﬁcation issue for the correlation ρu, since ρuh∗
1t =
(−ρu)(−h∗
1t), which is resolved by assuming ρu to be U(0, 1) rather than
U(−1, 1). The correlation ρe in Re is taken as U(−1, 1). The stationary
autocorrelation parameters are obtained as φpp = 2φ∗
pp −1, where φ∗
pp ∼
Beta(19, 1). The diagonal terms in Σ−1
u
are taken to be Ga(1, 1).
A two chain run of 10,000 iterations, converges after around 1500, with
posterior means for ρe and ρu of 0.54 and 0.91, and with the autoregressive
coeﬃcients in the AR1 log volatility equations having means 0.88 and 0.81.
Figure 7.9 plots the resulting log volatility series (posterior means of h1t and
h2t) with the two periods of market turbulence apparent. The DIC is 1056
(de = 59.4).
Appendix: Computational Notes
1. In Example 7.1, the code for models 1 and 2 is
model {for (j in 1:p) {tau[j] <- 1/(s[j]*s[j]);s[j]∼dunif(0,1000)}
for (j in 1:5){lam[j,1] ∼dnorm(0,1)}
lam[6,1] ∼dnorm(0,1) I(0,); lam[7,1] ∼dnorm(0,1)
for (j in 1:3) {lam[j,2] ∼dnorm(0,1)}
lam[4,2] ∼dnorm(0,1) I(0,); lam[5,2] ∼dnorm(0,1)
lam[6,2] <- 0; lam[7,2] ∼dnorm(0,1)
for (i in 1:n) {F[1,i] ∼dnorm(0,1); F[2,i] ∼dnorm(0,1);
for (j in 1:p){yst[i,j] <- (y[i,j]-mean(y[,j]))/sd(y[,j]); yst[i,j]∼dnorm(mu[i,j],
tau[j]);
mu[i,j] <- lam[j,1]*F[1,i] + lam[j,2]*F[2,i] }}}
and
model {for (j in 1:p) {tau[j] <- 1/(s[j]*s[j]);s[j]∼dunif(0,1000)}
for (j in 1:5){lam[j,1] ∼dnorm(0,1)} lam[6,1] <- 1; lam[7,1] ∼dnorm(0,1)
for (j in 1:3){lam[j,2] ∼dnorm(0,1)} lam[4,2] <- 1; lam[5,2] ∼dnorm(0,1);
lam[6,2] <- 0; lam[7,2] ∼dnorm(0,1)
for (i in 1:n) {F[1,i] ∼dnorm(0,inv.phi[1]); F[2,i] ∼dnorm(0,inv.phi[2]);
for (j in 1:p){ yst[i,j] <- (y[i,j]-mean(y[,j]))/sd(y[,j]); yst[i,j] ∼dnorm(mu[i,j],
tau[j]);
mu[i,j] <- lam[j,1]*F[1,i] + lam[j,2]*F[2,i] }}
for (k in 1:2) {phi[k] ∼dunif(0,1000); inv.phi[k] < - 1/phi[k]}}
2. The code relating to the ﬁrst indicator, y1, in Example 7.3 is
for (i in 1:n) {F[i]∼dnorm(0,1); yst1[i]∼dnorm(mu1[i],1) I(A1[i],B1[i])
A1[i] <- -10*equals(y1[i],0); B1[i] <- 10*equals(y1[i],1)
mu1[i] <- alph1+lam[1]*F[i]}
The code relating to the third indicator uses M3 −1 probit regressions:
for (i in 1:n) {for (j in 1:M3-1) { z3[i,j] <- step(j-y3[i])
A3[i,j] <- -10*equals(z3[i,j],0); B3[i,j] <- 10*equals(z3[i,j],1)

Multivariate Priors, with a Focus on Factor and SEMs
333
yst3[i,j] ∼dnorm(nu3[i,j],1) I(A3[i,j],B3[i,j]); nu3[i,j] <- kap3[j] - mu3[i]}
mu3[i] <- lam[3]*F[i]}}
3. The code for the two parameter probit IRT model in Example 7.4, including
elements to calculate CPOs, and hence obtain a pseudo marginal likelihood, is
model {for (i in 1:39) {F[i] ∼dnorm(0,1)
for (j in 1:6) {A[i,j] <- -10*equals(y[i,j],0);B[i,j] <- 10*equals(y[i,j],1)
pi[i,j] <- phi(mu[i,j]); mu[i,j] <- lam[j]*F[i]-alpha[j];
yst[i,j]∼dnorm(mu[i,j],1) I(A[i,j],B[i,j]);
# sample new data without truncation
ystnew[i,j]∼dnorm(mu[i,j],1)
ynew[i,j] <- step(ystnew[i,j]); conc[i,j] <- equals(y[i,j],ynew[i,j])
LL[i,j] <- y[i,j]*log(pi[i,j])+(1-y[i,j])*log(1-pi[i,j]); H[i,j] <- 1/exp(LL[i,j]) }}
for (j in 1:6) {lam[j] ∼dnorm(0,1) I(0,); alpha[j] ∼dnorm(0,0.001)
conc.item[j] <- sum(conc[,j])/39 }}.
The code for the full multivariate probit in this example is
model {for (i in 1:39) {F[i] ∼dnorm(0,1);
ystnew[i,1:6]∼dmnorm(m[i,1:6],T[1:6,1:6])
yst[i,1:6] ∼dmnorm(m[i,1:6],T[1:6,1:6]) I(A[i,1:6],B[i,1:6])
for (j in 1:6){conc[i,j] <- equals(y[i,j],ynew[i,j])
m[i,j] <- alp[j]+lam[j]*F[i]; ynew[i,j] <- step(ystnew[i,j])
A[i,j]<- -10*equals(y[i,j],0);B[i,j]<- 10*equals(y[i,j],1)}}
# Priors
T[1:6,1:6] ∼dwish(Sc[,],6); Sigma[1:6,1:6] <- inverse(T[,])
for (j in 1:6) {alp[j] ∼dnorm(0,0.001);lam[j] ∼dnorm(0,1) I(0,)
conc.item[j] <- sum(conc[,j])/39
# scale loadings
s[j] <- sqrt(Sigma[j,j]); lamst[j] <- lam[j]/s[j];
for (k in 1:6) {Sc[j,k] <- 6*equals(j,k)}}
for (j in 2:6) {for (k in 1:j-1){r[j,k] <- Sigma[j,k]/(s[j]*s[k])}}}.
4. The code for the market segment model (Example 7.5) is
model { for (i in 1:500) {S[i] ∼dcat(p[1:2])
for (j in 1:2){ y[i,j] ∼dnorm(mu.y[i,j],tauy[j])
mu.y[i,j] <- alph.y[j]+lamy[j]*F[i]}
F[i] ∼dnorm(mu.F[i],1)
mu.F[i] <- gam[S[i],1]*H[i,1]+gam[S[i],2]*H[i,2]}
p[1:2] ∼ddirch(alph[1:2])
rho ∼dunif(-1,1); tau.H <- 1/(1-rho*rho)
for (j in 1:2) {tauy[j] ∼dgamma(1,0.001); alph.y[j]∼dnorm(0,0.01)}
for (j in 1:4) {taux[j] ∼dgamma(1,0.001); alph.x[j] ∼dnorm(0,0.01)}
for (k in 1:2) {gam[1,k] ∼dnorm(0,0.1) I(0,); gam[2,k] ∼dnorm(0,0.1) I(,0)}
for (j in 1:2) {lamx[1,j] ∼dnorm(0,0.1);
lamx[1,j+2] <- 0
lamx[2,j] <- 0; alph[j] <- 1;

334
Applied Bayesian Hierarchical Methods
lamx[2,j+2] ∼dnorm(0,0.1)
lamy[j] ∼dnorm(0,0.1)}
for (i in 1:500) {H[i,1] ∼dnorm(0,1); m.H[i] <- rho*H[i,1]
H[i,2] ∼dnorm(m.H[i],tau.H)
for (j in 1:4){x[i,j] ∼dnorm(mu.x[i,j],taux[j])
mu.x[i,j] <- alph.x[j]+lamx[1,j]*H[i,1]+lamx[2,j]*H[i,2]}}}
5. The code relevant to the Dirichlet process mixture model on the residuals
in Example 7.6 is
model { for (i in 1:n) {S[i] ∼dcat(pi[1:K])
for (p in 1:P) {y[i,p] ∼dpois(mu[i,p]);
log(mu[i,p]) <- log(pop[i])+beta[p,1]+beta[p,2]*unem[i]
+beta[p,3]*border[i]+beta[p,4]*GDP[i]+beta[p,5]*urb[i]+u[i,p];
u[i,p] <- ustar[S[i],p]}
for (k in 1:K) {d[i,k] <- equals(S[i],k)}}
# Priors
for (p in 1:P) { for (r in 1:R) {beta[p,r] ∼dﬂat()}}
inv.D[1:P,1:P] ∼dwish(Sc[,],P)
# truncated Dirichlet process
kap ∼dgamma(2,4) I(0.1,); V[K] <- 1; pi[1] <- V[1]
for (k in 1:K-1){ V[k] ∼dbeta(1,kap)}
for (j in 2:K) { pi[j] <- V[j]*(1-V[j-1])*pi[j-1]/V[j-1]}
for (j in 1:K) {ustar[j,1:P] ∼dmnorm(nought[],inv.D[,])}
# total non-empty clusters
Kstar <- sum(C[])
for (j in 1:K) {C[j] <- step(sum(d[,j])-1)}}
6. Consider Poisson outcomes with oﬀsets, Epi, and with a marginal/conditional
sequence starting with S1. For example, for P = 3, one has P(S1, S2, S3) =
p(S3|S2, S1)p(S2|S1)P(S1). A WinBUGS code is then, with the entire (binary)
interaction matrix W included in the data input:
model {for(p in 2:P) {for (q in 1:p-1) {gam0[p,q] ∼dnorm(0, 0.1); gam1[p,q]
∼dnorm(0, 0.1)
for (i in 1:N) {M[1,i] <- 0 ; inv.d[i] <- 1/d[i]
G0[i,p,q] <- gam0[p,q]*s[q,i]; G1[i,p,q] <- gam1[p,q]*inprod(W[i,],s[q,])}}}
for (p in 1:P) {y[i,p] ∼dpois(mu[i,p]); mu[i,p]<- E[i,p]*exp(s[p,i])}}
for(p in 2:P) {M[p,i] <- sum(G0[i,p,1:p-1])+sum(G1[i,p,1:p-1])}}
for (p in 1:P){tau[p] ∼dgamma(1,0.01);alph[p] ∼dunif(0,0.999)
s[p,1:N] ∼car.proper(M[p, ], C[], adj[], d[], inv.d[], tau[p], alph[p])}}
The priors on the regression eﬀects {γ0, γ1} follow the recommendations of
Jin et al. (2005, 955).
7. The core code for the LMCAR model in Example 7.8 is
model { for (i in 1 : N) {r[i,1:P]∼dmnorm(M[i,1:P],Zeta.r[i,,])
for (p in 1:P) {mu[i,p] <- nu[i,p]*E[i,p]; log(nu[i,p]) <- alph[p]+r[i,p]

Multivariate Priors, with a Focus on Factor and SEMs
335
y[i,p]∼dpois(mu[i,p]);
M[i,p] <- (kap/(1-kap+kap*d[i]))*sum(radj[cum[i]+1 : cum[i+1], p ])
for (k in 1:P) {Zeta.r[i,j,k] <- Zeta[j,k]*(1-kap+kap*d[i])}}}
Zeta[1:P,1:P] ∼dwish(Sc[,],P); kap ∼dunif(0,1); Inv.Zeta[1:P,1:P]
<- inverse(Zeta[,])
for (j in 1:P) {alph[j] ∼dnorm(0,0.01)
for (k in 1:P) {Sc[j,k] <- P*equals(j,k)}}
for (i in 2:P) {for (j in 1:i-1){r.Zeta[i,j] <- Inv.Zeta[i,j]/sqrt(Inv.Zeta[i,i]
*Inv.Zeta[j,j])}}
for (i in 1 : NN) { for (j in 1:P){radj[i,j] <- r[adj[i],j]}}}
8. The code in Example 7.9 is
model { for ( t in 1:T){ for (p in 1:P) {beta.var[p,t] <- beta[t,p];
# trends and cycles by variable p
th.var[p,t] <- th[t,p]; psi.var[p,t] <- psi1[t,p]}
y[t,1] <- logmink[t]; y[t,2] <- logmuskrat[t]; y[t,1:P] ∼dmnorm(nu[t,1:P],
Precy[,])
for (p in 1:P) {nu[t,p] <- th[t,p]+psi1[t,p]}}
for (t in 2:T) {th[t,1:P] ∼dmnorm(M.th[t,1:P],Precth[,])
beta[t,1:P] ∼dmnorm(beta[t-1,1:P],Precbeta[,])
psi1[t,1:P] ∼dmnorm(M.psi1[t,1:P],Precps1[,])
psi2[t,1:P] ∼dmnorm(M.psi2[t,1:P],Precps2[,])
for (p in 1:P) {M.th[t,p] <- th[t-1,p]+beta[t,p]
M.psi1[t,p] <- rho*cos(lam)*psi1[t-1,p]+rho*sin(lam)*psi2[t-1,p]
M.psi2[t,p] <- -rho*sin(lam)*psi1[t-1,p]+rho*cos(lam)*psi2[t-1,p]}}
for (p in 1:P){beta1[p] ∼dnorm(0,0.01);th1[p] ∼dnorm(0,0.01)
psi11[p] ∼dnorm(0,0.01); psi21[p] ∼dnorm(0,0.01)
psi1[1,p] <- psi11[p]; psi2[1,p] <- psi21[p]
beta[1,p] <- beta1[p]; th[1,p] <- th1[p]}
rho ∼dunif(0,1); lam ∼dunif(0.3,1.5); Period <- 2*pi/lam
# prior precision matrices
Precy[1:P,1:P] ∼dwish(Scy[1:P,1:P],nu.y);
for (a in 1:4) {q[a]∼dgamma(1,1)}
for (p1 in 1:P){ for (p2 in 1:P) {Scy[p1,p2] <- Sigy[p1,p2]*nu.y
Precth[p1,p2] <- Precy[p1,p2]/q[1]; Precbeta[p1,p2] <- Precy[p1,p2]/q[2]
Precps1[p1,p2] <- Precy[p1,p2]/q[3]; Precps2[p1,p2] <- Precy[p1,p2]/q[4]}}}
9. The code in Example 7.11, including direct calculation of the precision
matrix for y, is
model { for (t in 1:T) {D[t] <- exp(h[1,t]+h[2,t])*(1-rho.e*rho.e);
y.Prec[t,1,1] <- exp(h[2,t])/D[t]; y.Prec[t,2,2] < - exp(h[1,t])/D[t];
y.Prec[t,1,2] <- -rho.e*exp(0.5*h[1,t]+0.5*h[2,t])/D[t]; y.Prec[t,2,1]
<- y.Prec[t,1,2];
y[t,1:2] ∼dmnorm(nought[1:2],y.Prec[t,,])}
# log volatility VAR

336
Applied Bayesian Hierarchical Methods
for (p in 1:P) { h.st[1,p] ∼dnorm(mu[p],1)
for (t in 2:T) { h.st[t,p] ∼dnorm(h.mu[t,p],1)
h.mu[t,p] <- mu[p] + ph[p]*(h.st[t-1,p]-mu[p]) }}
for (t in 1:T) {h[1,t] <- sig.u[1]*h.st[t,1];
h[2,t] <- sig.u[2]*rho.u*h.st[t,1]+sig.u[2]*sqrt(1-rho.u*rho.u)*h.st[t,2] }
# priors
for (p in 1:P) {inv.sig2.u[p] ∼dgamma(1,1); sig.u[p] <- 1/sqrt(inv.sig2.u[p])
phstar[p] ∼dbeta(19,1); ph[p] <- 2*phstar[p] -1; mu[p] ∼dnorm(0,1)}
rho.e ∼dunif(-1,1); rho.u ∼dunif(0,1)}

8
Hierarchical Models for Panel Data
8.1
Introduction
Panel or longitudinal datasets occur when continuous or discrete observations
yit on a set of subjects or units i = 1, . . . , n are repeated over a number of mea-
suring occasions t = 1, . . . , Ti possibly diﬀering between subjects (with N =
 Ti). There are many contexts for such data to occur, and many variations
in study design and data format as well as variations in how subjects or units
are deﬁned. For instance in economic and marketing applications (Rossi et al.,
2005), the panel is typically at the level of an individual consumer, household
or ﬁrm, and relates to questions such as economic participation or brand choice
(for households or consumers), or investments and outputs at ﬁrm level. In
actuarial applications (Antonio and Beirlant, 2007; Frees et al., 2001) the “sub-
jects” may consist of groups of policyholders (risk classes) with responses being
insurance claim counts. In clinical trials, patients are randomly assigned to
treatments and measures taken during follow-up to compare treatment eﬀects.
As well as regular panel surveys in which repeat measurements on all
subjects are contemporaneous, continuous measurement of variables, causing
unbalanced longitudinal data (Daniels and Hogan, 2008), may be the most
suitable method of identifying treatment eﬀects or assessing social change. In
the latter situation, the times {ait, t = 1, . . . , Ti} at which events are recorded
will diﬀer between subjects. Furthermore, measuring occasions may be over
more than one time scale. An example is analysis of mortality or cancer inci-
dence by calendar time and age at onset or death, leading to a further implicit
cohort scale deﬁned by the diﬀerence between age and time (Berzuini and
Clayton, 1994; Lagazio et al., 2003; Schmid and Held, 2007); see Section 8.7.
There are also a variety of approaches to analyzing panel data, such as the
generalized estimating equation method proposed by Liang and Zeger (1986),
as well as general linear mixed models (Molenberghs and Verbeke, 2006), and
conditional log-linear models for categorical outcomes (Gilula and Haberman,
1994). One may further distinguish between random eﬀects or conditional
models on the one hand, and marginal or population-averaged approaches on
the other (Heagerty and Zeger, 2000; Lee and Nelder, 2004), with parameters
obtained under the former not necessarily having the same interpretation as
under a marginal model (Neuhaus et al., 1991). The focus of this chapter
is on conditionally speciﬁed hierarchical and random eﬀect models, and on
337

338
Applied Bayesian Hierarchical Methods
Markov Chain Monte Carlo (MCMC) estimation via conditional likelihood
with random eﬀects as part of the parameter set (e.g., Chib and Carlin, 1999;
Daniels and Hogan, 2008); see Section 8.2.
Panel data oﬀer major advantages over cross-sectional designs in the anal-
ysis of causal interrelationships between variables, including developmental
and growth processes and clinical studies (Davies, 1994; Finkel, 1995; Menard,
2002; Ruspini, 1999). The accumulation of information over both times and
subjects increases the power of statistical methods to identify treatment
eﬀects or values added (Lockwood et al., 2003), and permits the estimation
of parameters (e.g., permanent random eﬀects or “frailties” for subjects i)
that are not identiﬁable from cross-sectional analysis or from repeated cross-
sections on diﬀerent subjects.
On the other hand, analysis of panel data may be problematic if the panel
sequences are subject to missing observations; see Section 8.8. Missingness
may involve intermittently missing values of responses (or predictors) or total
loss to observation after a certain point. The latter is variously known as
attrition (Schafer and Graham, 2002) or dropout (Hogan et al., 2004). A
particular question relevant to estimation of the main structural model is
whether such permanent exit is random (independent of the response that
would otherwise have been observed) or informatively related to the missing
response (Goodman and Blum, 1996).
Bayesian estimation via repeated sampling from posterior densities
facilitates hierarchical modeling of panel data, whether of permanent sub-
ject eﬀects (often simply called “random eﬀects”), correlated or unstructured
observation level errors, time varying regressor eﬀects or common factors in
multivariate panel data. As noted by Davidian and Giltinan (2004), the ran-
dom eﬀects are treated as parameters in Bayesian MCMC estimation, and
are ordinarily not integrated out as often done in frequentist approaches. The
integrated or marginal likelihood estimation approach may become infeasi-
ble or unreliable in complex varying coeﬃcient models (Tutz and Kauer-
mann, 2003), and diﬀerent parameter estimates may be obtained according to
the maximization methods used (Molenberghs and Verbeke, 2004). Bayesian
modeling perspectives are also important in the application of latent met-
ric augmentation to categorical panel outcomes (binary, multinomial) (Chib
and Carlin, 1999), and for dealing with missing data, especially attrition of
subjects (Little and Rubin, 2002). By contrast, quasi-likelihood methods for
categorical panel outcomes may be biassed, especially for binary panel data
(Lesaﬀre and Spiessens, 2001).
8.2
General Linear Mixed Models for Panel Data
Following Tutz and Kauermann (2003), the ﬁrst stage of general linear
mixed model may be characterized by two components, the distributional and

Hierarchical Models for Panel Data
339
structural assumptions. Thus, conditional on predictors and random eﬀects it
is assumed that data yit for subjects i and times t are distributed according
to the exponential family,
p(yit|θit, φ) = exp

yitθit −a(θit)
φ
+ C(yit, φ)

,
where θit denotes the natural parameter (e.g., see Chib and Carlin, 1999;
Gamerman, 1997; Gamerman, 1998; Natarajan and Kass, 2000; Tsai and
Hsiao, 2008). The structural assumption governs the forms assumed for the
conditional means E(yit) = µit = a′(θit), with link g(µit) = ηit to a regres-
sion term ηit, and for the variances Vit = φVar(µit). This involves questions
such as whether the conditional mean is linear or nonlinear in predictors and
random eﬀects, and at what levels random eﬀects are present.
Thus there are likely to be enduring diﬀerences between subjects that may
be represented by permanent (time-invariant) random eﬀects. To represent
excess dispersion in discrete outcomes there may also need to be observation-
level random eﬀects. Fixed eﬀects are also often used for representing subject
level heterogeneity, especially in econometrics (Frees, 2004). This is equiva-
lent to generating dummy variables for each subject and works best for rel-
atively few subjects and more time periods, as there is no pooling strength
in ﬁxed eﬀects models and the parameter count increases with the number
of subjects n. In this chapter the focus is on random subject eﬀects that are
exchangeable over subjects, i.e., unstructured random eﬀects, though if the
units are spatially conﬁgured (say) then a structured prior for the permanent
eﬀects can be used. It is relevant to note that Marshall and Spiegelhalter
(2007) assess prior-likelihood conﬂict in hierarchical models by p-tests that
involve replicates sampled from hierarchical as against ﬁxed eﬀects priors for
subject eﬀects.
Conjugate priors may be suitable to handle unstructured random varia-
tion at subject or observation level for exponential family responses, especially
if random variation does not involve predictors. For example, suppose yit are
overdispersed counts, then one possible scheme (Lee and Nelder, 2000, 593) in-
volves multiplicative permanent eﬀects hi and observation level random eﬀects
hit, so that the structural assumption takes the form:
E(yit|hi, hit) = exp(Xitβ)hihit.
If the 1 × P predictor vector Xit = (x1it, . . . , xPit) includes an intercept,
then both hi and hit have mean 1 for identiﬁcation and would be gamma
variables, hi ∼Ga(ϕ1, ϕ1), hit ∼Ga(ϕ2, ϕ2), with unknown hyperparameters.
However, more ﬂexible models, possibly involving subject-speciﬁc regres-
sion eﬀects as well as varying intercepts, involve a vector of subject level eﬀects
bi = (b1i, . . . , bQi)′ in a general linear mixed model format. These are typi-
cally taken to be normal with covariance D, and mean B = (B1, . . . , BQ)
which is zero or nonzero depending on how the predictors are deﬁned

340
Applied Bayesian Hierarchical Methods
(see Section 8.2.1). As considered above (Chapter 6), mixed models extend
linear regression by including both random and ﬁxed eﬀects in the model for
the mean. So with link g, the structural assumption speciﬁes
g[E(yit|bi.uit)] = ηit = Xitβ + Zitbi + uit,
(8.1a)
where Zit = (z1it, . . . , zQit) is 1 × Q. In a typical analysis bi and ui =
(ui1, . . . , uiT i)′ are assumed independent, and both also taken to be nor-
mal, at least initially. Variations on the independence assumption might be to
take the cluster eﬀects to be spatially correlated, or the observation errors to
be correlated through time. In some applications (e.g., Poisson data without
overdispersion) the observation level errors uit may not be present.
For a normal linear mixed model where responses are assumed independent
given ﬁxed eﬀects β, and normal random eﬀects bi with covariance matrix D,
one has
yit = Xitβ + Zitbi + uit,
with ui = (ui1,, . . . , uiTi)′ unstructured normal with mean zero, Ti × Ti
covariance matrix Σi = σ2I, and conditional expectations,
E(yit|bi) = ηit = Xitβ + Zitbi.
Equivalently therefore yit|bi ∽N(Xitβ + Zitbi, σ2). The normal linear
mixed model may be achieved with latent rather than actual data, when the
observed data are binary or categorical (e.g., Chib, 2008; Chib and Jeliazkov,
2006; Czado, 2000). Thus, for binary yit,
yit|bi ∽N(Xitβ + Zitbi, 1)
I(0, )
if
yit = 1,
yit|bi ∽N(Xitβ + Zitbi, 1)
I(, 0)
if
yit = 0,
with unstructured residuals under conditional independence having known
variance σ2 = 1, but with D still unknown.
Stacked over times the conditional mean in Equation 8.1a is expressed as
ηi = Xiβ + Zibi + ui,
(8.1b)
where ηi is Ti × 1, Xi is Ti × P, and Zi is Ti × Q, while the normal mixed
model is
yi = Xiβ + Zibi + ui.
For the linear normal mixed model, the marginal model (with bi integrated
out) is obtainable analytically as
yi ∽N(Xitβ, ZiDZ′
i + σ2I),
which is a feature not present for the broader class of general linear mixed
models (Molenberghs and Verbeke, 2006).

Hierarchical Models for Panel Data
341
Given the ﬁxed eﬀect regression and the full set of subject permanent
eﬀects b = (b1, . . . , bn), the assumption that repeated observations on the
same subject (or more generally within units or clusters) are conditionally
independent (Kleinman and Ibrahim, 1998; Tutz and Kauermann, 2003),
means that the conditional likelihood factors as
p(y|b, β, σ2) =
n

i=1
p(yi|bi, β, σ2),
where p(yi|bi, β, σ2) = Ti
t=1 p(yit|bi, β, σ2). Similarly the joint density,
p(y, b|β, D, B, σ2) = p(y|b, β, σ2)p(b|B, D)
factors into subject speciﬁc elements
 Ti
t=1 p(yit|bi, β, σ2)

p(bi|B, D).
If model checking reveals that a conditional independence assumption does
not provide an adequate ﬁt to the actual correlation structure, then the model
is incomplete and requires elaboration. For example, such checking may show
that in fact the regression errors are correlated through time, and the white
noise assumption for the observation level errors uit has to be reconsidered, or
lagged eﬀects in the response included in the predictor sets Xit or Zit (Frees,
2004, 279)—see Sections 8.3 and 8.5.
One may also generalize Equation 8.1a to include predictors Hit of dimen-
sion 1 × R with eﬀects varying by time, as well as by subject. Denoting time
varying regression coeﬃcients as ct = (c1t, . . . , cRt)′, the structural assumption
becomes
g[E(yit|bi, ct.uit] = Xitβ + Zitbi + Hitct + uit.
(8.2)
A particular example (with Q = R = 1) is the two-way error component
model (Baltagi, 2003; Hjellvik and Tjøstheim, 1999) with
g[E(yit|bi, ct.uit] = Xitβ + bi + ct + uit,
where the ct represent eﬀects over time inﬂuencing all the series. Tutz and
Kauermann (2003) consider a time varying regression form of Equation 8.1a,
namely
ηit = Xitβt + Zitbi + uit
with time acting as an “eﬀect modiﬁer.” For example, they mention that
assuming a constant eﬀect of treatment variables in clinical trials may often
be unrealistic.
8.2.1
Centered or noncentered priors
The parameterization adopted in the prior for bi depends on whether Xit and
Zit are speciﬁed to be overlapping or distinct, and also on MCMC convergence

342
Applied Bayesian Hierarchical Methods
considerations. In many presentations of the GLMM in panel analysis, the Zit
are assumed to be a subset of Xit, in which case the bi are typically taken
to be zero mean random eﬀects usually following a standard density (e.g.,
multivariate normal) (Section 8.2.2). If the Xit and Zit are nonoverlapping,
then the bqi may be taken to have nonzero means equal to the central (ﬁxed
eﬀect) regression parameters Bq for zqit (Chib and Carlin, 1999, 20), namely
g[E(yit|bi.uit)] = Xitβ + Zitbi + uit,
bi ∼N(B, D).
Such hierarchical centering may assist precise identiﬁcation and MCMC
convergence. If no predictors have ﬁxed eﬀect coeﬃcients, one has what is
sometimes termed a random coeﬃcient regression, namely
g[E(yit|bi.uit)] = Zitbi + uit,
where bqi have nonzero means Bq (e.g., Daniels and Hogan, 2008, 22; Yang
and Chen, 1995).
Papaspiliopoulos et al. (2003) compare MCMC convergence for centered,
noncentered, and partially noncentered hierarchical model parameterizations,
and mention that hierarchical centering may be less eﬀective when the latent
eﬀects bi are relatively weakly identiﬁed. Consider the normal linear mixed
model in the form:
yi = Xiβ + Zibi + (σ2ITi)ei
bi = B + D0.5vi,
where ei and vi, of dimension Ti and Q, respectively, are standard normal
variables.
Then the noncentered parameterization (NCP) and partially noncentered
parameterizations (PNCP) are, respectively,
bi = bi −B
and
bw
i = bi −WiB,
where Wi = UiD−1, Ui = (1/σ2)ZiZi + D−1, and
bi ∼N(0, D),
bw
i ∼N(B −WiB, D).
The proportion of B subtracted from bi under the PNCP form (that has
favorable MCMC convergence properties) is observation speciﬁc. The longi-
tudinal model under the NCP and PNCP becomes
yi = Xiβ + ZiB + Zibi + (σ2ITi)ei,
yi = Xiβ + ZiWiB + Zibw
i + (σ2ITi)ei.

Hierarchical Models for Panel Data
343
The NCP form has potential use in random eﬀects selection (see Section
8.2.3).
8.2.2
Priors on permanent random eﬀects
The most commonly adopted prior for the random subject or cluster eﬀects
bi = (b1i, . . . , bQi) is an unstructured multivariate normal
(b1i, . . . , bQi) ∽NQ(B, D),
(8.3)
where the means B = (B1, . . . , BQ) are either zeroes or unknown ﬁxed eﬀects,
and D = [drs] represents covariation within subjects between the rth and
sth random eﬀects bri and bsi. If the Zit are a subset of the Xit, then the
means Bq will be zero. For robustness against non-normality or outliers, other
forms of mixture, including scale mixtures of normals or discrete mixtures of
random eﬀects, may be assumed for subject eﬀects (Section 8.6). For spatially
conﬁgured units a prior for (b1i, . . . , bQi) including correlation over areas is
likely to be relevant. For doubly nested data (e.g., observations yijt within
subjects i within clusters j), the second stage parameters are likely to be
cluster speciﬁc and possibly also randomly varying, as in
(b1ij, . . . , bQij) ∽NQ(Bj, Dj),
(B1j, . . . , BQj) ∽NQ(MB, CB).
In many applications the Zit will be of relatively small dimension, conﬁned
to the intercept or simple time functions. For example, if Q = 1 and Zit = 1,
one has the normal linear form:
yit = bi + Xitβ + uit,
(8.4)
where bi represent permanent subject eﬀects, namely enduring diﬀerences
between subjects due to unmeasured attributes. If Xit excludes (or includes)
an intercept, then the bi will be normal with mean B (or zero) and variance D.
In growth curve and educational attainment applications the Zit typically
include transforms of time or age, and the mean level for an individual changes
with time or age (e.g., linearly or quadratically) with growth rate coeﬃcients
speciﬁc to each subject. For example, under a linear growth model with Q = 2,
each subject has their own linear growth rate (Darby and Fearn, 1979; Weiss,
2005)
yit = b1i + b2it + Xitβ + uit,
where D12 measures the correlation between intercepts and slopes. Assuming
Xit omits an intercept and linear time term, one may take
(b1i, b2i) ∼N([B1, B2], D).
In particular, Weiss (2005, 254) refers to random intercept and slope
(RIAS) models in which
yit = b1i + b2it + uit,

344
Applied Bayesian Hierarchical Methods
so that an individual’s observed performance will diﬀer from his/her mean
level at a particular time or age by a random term uit. Another option is to
replace known time functions by an unknown time varying function, δt, as in
yit = b1i + b2iδt + Xitβ + uit,
with δt subject to identifying constraints (e.g., δ1 = 1), or with the variance
of bi preset. The δt are interpretable as factor loadings by time. Related models
are considered by Lee and Carter (1992) and Tutz and Reithinger (2007).
To illustrate MCMC sampling, consider the random coeﬃcient normal
linear model, namely
yit = Zitbi + uit
with uit ∼N(0, σ2), and (b1i, b2i, . . . , bQi) ∼NQ([B1, B2, . . . , BQ], D). Let τ =
1/σ2 and assume, following Wakeﬁeld et al. (1994), that τ ∼Ga(ν0/2, τ0ν0/2).
Also assume a multivariate normal prior for the second-stage population
means B, and a Wishart prior for D−1, namely
B ∼N(B0, C),
D−1 ∼W([ρR]−1, ρ).
Setting N = n
i=1 Ti, E−1
i
= τZ′
iZi + D−1, V −1 = nD−1 + C−1, and
¯b = n
i=1 bi/n, then Gibbs sampling involves the posterior conditionals
bi ∼N

Ei[τZ′
iy + D−1B], Ei

,
i = 1, . . . , n,
B ∼N

V
!
nD−1b + C−1B0
"
, V

,
D−1 ∼W


 n

i=1
(bi −B)(bi −B)′ + ρR
−1
, n + ρ

,
τ ∼Ga

ν0 + N
2
, 1
2
 n

i=1
(yi −Zibi)′(yi −Zibi) + ν0τ0

.
When predictors are otherwise available that might explain heterogeneity
between subjects (e.g., treatment allocations), regression priors may be used
for the permanent random eﬀects bqi (Chib, 2008, 481). Regression priors
are illustrated by growth curve applications in which randomly varying ef-
fects of time variables are related to ﬁxed subject attributes in a higher stage
regression (Candel and Winkens, 2003). Thus, Muthen et al. (2002) consider a
model with varying intercepts b1i, varying linear growth eﬀects b2i, and vary-
ing quadratic growth eﬀects b3i. Subjects are observed at diﬀerentially spaced
time points {ai1, ai2, . . . , aiTi}. So
yit = b1i + b2iait + b3ia2
it + uit,

Hierarchical Models for Panel Data
345
where random growth coeﬃcients are related to an intervention variable Tri
according to
b1i = B1 + e1i,
b2i = B2 + δ2Tri + e2i,
(8.5)
b3i = B3 + δ3Tri + e3i,
where (e1i, . . . , eQi) ∽NQ(0, D). Treatment is randomized so the permanent
(equivalently baseline) eﬀects b1i are taken to be independent of the interven-
tion Tri.
8.2.3
Priors for random covariance matrix and random
eﬀect selection
Inferences may be sensitive to the form of prior adopted for D, and the amount
of information it contains. Improper or overly diﬀuse priors on D or other vari-
ance hyperparameters may be associated with actual or eﬀectively improper
posterior densities. For example, the Jeﬀrey’s rule prior, namely
p(D) ∝det(D)−(Q+1)/2
may lead to an improper joint posterior for D and β under certain condi-
tions (Natarajan and Kass, 2000). The conjugate model for Q > 1 involves a
Wishart prior for D−1, D−1 ∼Wish(S, ν), or
p(D−1|S, ν) ∝|S|ν/2|D−1|0.5(ν−Q−1) exp(−0.5tr(SD−1),
where E(D−1) = νS−1 and E(D) = S/(ν −Q −1).
Setting the elements in S may be diﬃcult in the absence of substan-
tive information. Greater ﬂexibility, including random eﬀects selection, may
be gained with matrix decomposition alternatives to the Wishart (e.g.,
Fr¨uhwirth-Schnatter and T¨uchler, 2008; Hedeker, 2003; Kinney and Dunson,
2007; Tutz and Kauermann, 2003), or with adaptations of the uniform shrink-
age prior (Natarajan and Kass, 2000; Tsai and Hsiao, 2008).
Consider the Cholesky decomposition D = CC′ where C is a lower trian-
gular matrix, with Dpq = Q
r=1 cprcqr and variances obtained as
Dqq =
Q

r=1
c2
qr.
Then if Zit is a subset of Xit, Equation 8.1a may be expressed,
ηit = Xitβ + ZitCζi + uit,
where (ζ1i, . . . , ζQi) ∽NQ(0, I). For example with Q = 2,
(z1it, z2it)

c11
0
c21
c22
 
ζ1i
ζ2i

= ζ1i(z1itc11 + z2itc21) + ζ2iz2itc22.

346
Applied Bayesian Hierarchical Methods
Instead of a Wishart prior on D−1, priors are then adopted for each element
of C. To ensure D is positive deﬁnite, the diagonal terms c11 and c22 need to
be assigned positive priors, while the prior c21 is unconstrained. For Q = 3,
one has
(z1it, z2it, z3it)


c11
0
0
c21
c22
0
c31
c32
c33




ζ1i
ζ2i
ζ3i


= ζ1i(z1itc11 + z2itc21 + z3itc31) + ζ2i(z2itc22 + z3itc32) + ζ3iz3itc33,
with three positive unknowns cqq and three unconstrained lower diagonal
unknowns.
Cai and Dunson (2006) and Chen and Dunson (2003) use the Cholesky
decomposition
D = ΛΩΩ′Λ,
where Λ = diag(λ1, . . . , λQ) and Ωis lower triangular,
Ω=





1
0
· · ·
0
ω21
1
· · ·
0
· · ·
· · ·
...
0
ωQ1
ωQ2
· · ·
1




.
Hence C in D = CC′ can be written
C =





λ1
0
· · ·
0
ω21λ2
λ2
· · ·
0
· · ·
· · ·
...
0
ωQ1λQ
ωQ2λQ
· · ·
λQ




.
Then positive priors (e.g., log-normal, gamma) are taken for the elements of Λ,
while normal N(0, VΩ) priors may be assumed for the unconstrained elements
of Ω. Chen and Dunson (2003, 865) mention that taking VΩ= 0.5 leads to
relatively diﬀuse priors on the correlations between the random eﬀects bqi.
Retention or otherwise of the terms in Λ is determined by binary indicators
γqq ∼Bern(πqq), where πqq may be preset or extra unknowns. Retention or
otherwise of the unknown terms in Ωis determined both by binary indicators
γqr ∼Bern(πqr), and also by whether λq and λr are retained; if either of
{λq, λr} is omitted, then ωqr necessarily is.
If Zit is not a subset of Xit, Fr¨uhwirth-Schnatter and T¨uchler (2008) adopt
the noncentered parameterization:
ηit = Xitβ + ZitB + ZitCζi + uit,
where (ζ1i, . . . , ζQi) ∽NQ(0, I). As above, diagonal terms cqq need to be as-
signed positive priors, while priors for cqr (q > r) are unconstrained. Selection

Hierarchical Models for Panel Data
347
of which cqq and cqr terms to retain may be based on binary indicators {γqq ∼
Bern(πqq), πqq ∽Be(aqq, bqq)}, {γqr ∼Bern(πqr), πqr ∽Be(aqr, bqr), q > r}
where aqq = bqq = aqr = bqr = 1 is a default option. In eﬀect the model
involves composite terms:
Gqq = cqqγqq,
Gqr = cqrγqr,
q > r
so that for Q = 2:
ηit = Xitβ + ζ1i(z1itG11 + z2itG21) + ζ2iz2itG22 + uit.
The posterior estimate for D would be based on MCMC monitoring of
Dqr = Q
s=1 GqsGrs.
A regression approach to covariance estimation for panel data is proposed
by Daniels and Pourahmadi (2002); Pourahmadi (1999, 2000), and Pourah-
madi and Daniels (2001). For the essence of the method, consider normal
metric data yit for subjects i = 1, . . . , n with individual speciﬁc covariance
matrices Σi of dimension T × T. The model yit ∼N(µit, Σi) may be re-
expressed (for the purposes of decomposing Σi) as an antedependence model:
yit −µit =
t−1

j=1
φitj(yij −µij) + uit,
where the errors uit ∼N(0, hit) are uncorrelated. Denote,
Hi = diag(hi1, . . . , hiT),
together with the lower triangular matrix,
Fi =


1
−φi21
1
−φi31
−φi32
1
· · ·
· · ·
· · ·
· · ·
−φiT 1
−φiT 2
· · ·
−φiT,T −1
1


.
One then has the decomposition,
Var(ui) = Hi = FiΣiF ′
i.
The parameters φitj and hit may be referred to respectively as the gener-
alized autoregressive parameters and the innovation variances of Σi (Daniels
and Pourahmadi, 2002).
A parsimonious covariance model, especially for large T, may then be
achieved by using predictors zit and witj in the regressions,
log(hit) = zitγ,
φitj = witjλ.

348
Applied Bayesian Hierarchical Methods
Often one might take Σi = Σ, in which case
yit −µit =

φtj(yij −µij) + uit
with uit ∼N(0, ht), H = diag(h1, . . . , hT ), and
F =


1
−φ21
1
−φ31
−φ32
1
· · ·
· · ·
· · ·
· · ·
−φT 1
−φT 2
· · ·
−φT,T −1
1


,
with Var(ui) = H = FΣF ′. The covariates used for covariance model become
{zt, wtj} where the wtj might simply be powers in (t −j) as illustrated by
Cepeda and Gamerman (2004), and the zt are simply powers of t. A possible
drawback to using polynomial functions of time is the multicollinearity that
may be encountered, and Bayesian regression selection may then be applied.
One may also consider autoregressive or random walk priors in ht and model-
ing φtj as a collection of unstructured random eﬀects under a shrinkage prior
strategy (Daniels and Pourahmadi, 2002, 558).
8.2.4
Priors for multiple sources of error variation
Estimation of variance components and convergence of MCMC samplers for
longitudinal data may also be sensitive to the assumed prior interlinkages
(or not) between multiple sources of random variation. Consider a random
intercept model
yit = bi + Xitβ + uit,
with unknown variances D = Var(bi) and σ2 = Var(uit). The conjugate
approach with the advantage of simple posterior conditionals involves separate
gamma priors on D−1 and τ = σ−2. These could be informative (e.g., down-
weighted results from a maximum likelihood ﬁt), but are often taken to be
diﬀuse with small scale and shape parameters, leading to potentially delayed
convergence of Gibbs sampling methods since sampling is from an almost
improper posterior (Natarajan and McCulloch, 1998). These problems may
increase if an autocorrelated error term is added to the white noise error as in
yit = bi + Xitβ + uit + εit,
εit = ρεi,t−1 + vit,
where vit ∽N(0, σ2
ν), and there are three variances.
An alternative is to allow for potential interdependence between variance
components via adaptations of the uniform shrinkage prior (Natarajan and
Kass, 2000). The uniform shrinkage principle extends to beta priors on the

Hierarchical Models for Panel Data
349
relative shares for two variances and to Dirichlet priors on the relative shares
for three or more variance components. So one might set a prior on one or
other of D or σ2, but then specify a variance partitioning rule such as κ =
D/(D + σ2) ∼U(0, 1) to obtain the other. A related strategy might take κ =
D/(D + σ2) ∼Be(aκ, bκ), where aκ and bκ are preset or hyperparameters. Lee
and Hwang (2000) use uniform shrinkage priors in a multilevel panel context
when repetitions t = 1, . . . , Tij are for subjects i nested within clusters j, and
where there is an autocorrelated error εijt as well as a white noise error uijt.
An extension to multivariate bi of the uniform shrinkage prior proposed by
Natarajan and Kass (2000) takes the form:
p(D) ∝det

IQ +

1
n
n

i=1
Z′
iWiZi

D

,
where Wi is diagonal of dimension Ti with elements 1/Vit[∂ηit/∂µit]2, where
Vit = φVar(µit) and g(µit) = ηit.
Example 8.1. Growth Model Simulation
To illustrate random eﬀects
selection in a panel setting, observations yit (i = 1, . . . , 500; t = 1, . . . , 5)
are generated according to
yit = b1i + b2it + b3ixit + uit,
xit ∼U(−1, 1),
(b1i, b2i, b3i) ∼N(B, D),
uit ∼N(0, 1/τ); τ = 0.5,
D−1 =


1
0
0
0
100
0
0
0
10,000

,
B = (5, 0.5, 0.5),
with the random eﬀects bqi having respective standard deviations {1, 0.1, 0.01}.
The parameters are then re-estimated under a “standard model” with
conjugate prior for the precision matrix D−1 ∽W(I, 3), and with τ ∼
Ga(1, 0.001) and (Bq ∼N(0, 100), q = 1, 3). A more diﬀuse prior on D−1
(e.g., a scale matrix with diagonal terms 0.001) is avoided as it delays con-
vergence on the parameters in D. The last 4000 of a 5000 iteration two chain
run provides estimated means (sd) for σbq = D0.5
qq of 0.99 (0.09), 0.206 (0.02),
and 0.401 (0.063). All three standard deviations σbq suggest signiﬁcant vari-
ation (at odds with the original simulation parameters), and additionally an
oﬀ-diagonal term in D, namely D12, is signiﬁcant, in the sense of a posterior
95% interval conﬁned to entirely negative values.
The posterior results for the standard deviations σbq from the standard
model are used to set priors on the diagonal Cholesky terms cqq in a ran-
dom eﬀects selection model (Fruhwirth-Schnatter and Tuchler, 2008). Infer-
ences from such selection may be sensitive to the prior used on the Cholesky

350
Applied Bayesian Hierarchical Methods
elements, and a full analysis would consider several choices of prior. Then
as mentioned in Section 8.2.3, with composite terms Gqr = cqrγqr and Zit =
(1, t, xit), the linear predictor is
yit = ZitB + ZitGζi + uit
= B1 + B2t + B3xit + ζ1i(z1itG11 + z2itG21 + z3itG31)
+ ζ2i(z2itG22 + z3itG32) + ζ3iz3itG33 + uit.
For the selection indicators, γqr ∼Bern(πqr), where πqr are assigned uni-
form priors, while the oﬀ-diagonal Cholesky terms cqr (q > r) are assigned
N(0, 1) priors. The posterior means and standard deviations on σbq from the
standard model analysis can be summarized by gamma priors Ga(122, 124),
Ga(100, 489), and Ga(40, 100). These are used to set gamma priors on cqq
in the selection model, but with precision downweighted a 100 times, namely
Ga(1.22, 1.24), Ga(1, 4.9), and Ga(0.4, 1); heavier downweighting (e.g., a thou-
sandfold) is avoided as it may lead to over-diﬀuse priors.
The last 4000 of a 5000 iteration two chain run using random eﬀect
selection1 with D = CC′ provides estimated means (medians) for σbq = D0.5
qq
of 0.95 (0.95), 0.012 (0), and 0.092 (0.023). The posterior densities for the stan-
dard deviations σb2 and σb3 both have spikes at zero, while no oﬀ-diagonal
terms in D are signiﬁcant. While not completely reproducing the original
simulation parameters, the selection approach has provided more accurate
estimates of the original σbq, namely {1, 0.1, 0.01}.
Random eﬀect selection is also undertaken with D = ΛΩΩ′Λ, namely
C = ΛΩ. Priors on λq are the same as for cqq under the decomposition
D = CC′, while N(0, 0.5) priors are used for the elements of Ω, and Bernoulli
priors with preset probability 0.5 for γqr. The last 4000 of a 5000 iteration two
chain run provides estimated means (medians) for σbq = D0.5
qq of 0.95 (0.95),
0.012 (0), and 0.041 (0). The posterior densities for the standard deviations
σb2 and σb3 again both have spikes at zero, and no oﬀ-diagonal terms in D are
signiﬁcant.
It may be noted that either of the Cholesky decomposition approaches
could be applied to estimate the random eﬀects covariance parameters, but
without selection being applied (in eﬀect γqr = 1); this is left as an exercise.
For example, with Ga(1, 1) priors on λq and N(0, 0.5) priors on the ωqr, the
Chen and Dunson (2003) method gives posterior means (and 95% intervals)
for σb2 and σb3 of 0.04 (0.002, 0.12), and 0.18 (0.01, 0.43), with σb3 less
inﬂated (as compared to the true value) than under the conjugate Wishart
prior.
Example 8.2. Joint Regression for Mean and Covariance
This ex-
ample follows Cepeda and Gamerman (2004) in applying the method of
Pourahmadi (1999) to T = 24 monthly height readings yit for n = 6 stu-
dents. The antedependence re-expression of the model yit ∼N(µt, Σ) is
yit −µt =

φtj(yij −µj) + uit

Hierarchical Models for Panel Data
351
with uit ∼N(0, ht). Taking H = diag(h1, . . . , hT ) and
F =


1
−φ21
1
−φ31
−φ31
1
· · ·
· · ·
· · ·
· · ·
−φT 1
−φT 1
· · ·
−φT,T −1
1


provides the covariance decomposition Var(ui) = H = FΣF ′. The covariates
{wtj, zt} used for the covariance regression model are powers of t −j for wtj,
and powers of t for zt. Then the model takes
µt = β1 + β2t + β3t2 + β4t3,
log(ht) = γ1 + γ2t + γ3t2,
φtj = λ1 + λ2(t −j) + λ3(t −j)2,
with the model for φtj here extending only to a quadratic term in (t−j) rather
than a quartic as in Cepeda and Gamerman (2004).
The last 8000 iterations from a two chain run of 10,000 iterations2 pro-
vide posterior mean and standard deviation estimates for the parameters as
follows: β1 = 94.25(0.37), β2 = 0.82(0.11), β3 = −0.021(0.011), β4 = 3.9E −
4(3.3E −4), γ1 = 0.36(0.38), γ2 = −0.194(0.077), γ3 = 0.0087(0.0032), λ1 =
0.37(0.038), λ2 = −0.06(0.01), and λ3 = 0.0021(5.2E −4). Predictions from
the model reproduce the observations satisfactorily, with 139 of the 144 (i.e.,
96.5%) data points contained within 95% credible intervals of replicate data.
8.3
Temporal Correlation and Autocorrelated
Residuals
Correlation between regression errors at diﬀerent times is obtained as a
by-product of other random eﬀect schemes, not only from explicit time series
priors. The random intercept model in Equation 8.4, applied widely in econo-
metrics and clinical studies, illustrates how subject level random eﬀects induce
temporal correlation. It is important to control for such heterogeneity in order
to avoid spurious “state dependence,” namely dependence of the current out-
come or probability on past outcomes or occurrences (Chib and Jeliakov,
2006). Thus for metric data, suppose
yit = bi + Xitβ + uit,
where Xit includes an intercept, bi ∼N(0, D), and uit ∼N(0, σ2). On the
assumption that uit and bi are independent, the correlation between ωit =
uit + bi and ωis = uis + bi at periods t and s is
κ = cov(ωit, ωis)/Var(ωit) = D/(D + σ2),

352
Applied Bayesian Hierarchical Methods
sometimes called the intra-class correlation. The random intercept model leads
to the “compound symmetry” form for the intra-subject covariance matrix Σi
(Weiss, 2005, 246–50), with diagonal terms Σitt = σ2, and oﬀ-diagonal terms
Σist = σ2κ, s ̸= t. Equivalently
Σi = σ2[(1 −κ)I + κJ],
where J is an Ti × Ti matrix of ones.
A factor analytic form of the random intercept model (Weiss, 2005, 269)
includes period-speciﬁc loadings Dt,
yit = D0.5
t
bi + Xitβ + uit,
with bi ∼N(0, 1) having a known variance to provide identiﬁcation, so that
κt = Dt/(Dt + σ2),
and the correlation between ωit = D0.5
t
bi + uit at times t and s is (κtκs)0.5.
The corresponding RIAS model has loadings D0.5
1t
and D0.5
2t
and standard
normal random eﬀects b1i and b2i, so that
yit = D0.5
1t b1i + D0.5
2t b2it + Xitβ + uit.
For discrete data, the temporal correlation under random intercept and
RIAS models may be conﬁned to positive values only. Thus for Poisson counts
yit, with log[E(yit|bi)] = log(µit) = Xitβ + bi, and γit = exp(Xitβ), one has
under conditional independence that
cov(yit, yis) = E[cov(yit, yis|bi)] + cov[E(yit|bi), E(yis|bi)]
= cov([ebiγit], [ebiγis]) = γitγisvar(ebi),
while
var(yit) = E[var(yit|bi)] + var[E(yit|bi)]
= E[ebiγit] + var[ebiγit] = µit + γ2
itvar(ebi),
with correlation then necessarily positive.
8.3.1
Explicit temporal schemes for errors
When residuals from Equations 8.1 and 8.2 show temporal correlation, auto-
correlated residuals may be used instead of, or in addition to, the white noise
errors uit. Let these take generic form:
(εi1, . . . , εiTi) ∽N(0, Σi),
where Σi is a unit level covariance matrix of dimension Ti × Ti. Commonly
adopted schemes for such residuals include low-order random walks (e.g.,

Hierarchical Models for Panel Data
353
ﬁrst order or RW1 priors), or low-order stationary schemes (typically AR1
or MA1). For example, Xu et al. (2007), Oh and Lim (2001), and Ibrahim
et al. (2000) adopt stationary AR1 errors in models for panel count data,
with yit ∼Po(µit),
log(µit) = Xitβ + εit,
εit = ρεi,t−1 + υit,
where υit ∽N(0, σ2
υ) are unstructured and |ρ| < 1. For metric data, a station-
ary AR1 error scheme with
yit = Xitβ + εit,
εit = ρεi,t−1 + υit,
where |ρ| < 1 and υit ∽N(0, σ2
υ), leads to error covariance matrix Σi with
elements
Σist = var(εit)ρ|s−t| =
σ2
υ
1 −ρ2 ρ|s−t|,
with (e.g., Witkovsky, 1996),
Σi =
σ2
υ
1 −ρ2






1
ρ
ρ2
· · ·
ρTi−1
ρ
1
ρ
ρ2
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
ρ2
ρ
1
ρ
ρTi−1
· · ·
ρ2
ρ
1






.
Assuming homogenous parameters across subjects so that Σi = Σ, and
that subjects are independent, the full population covariance matrix is
Φ =
σ2
υ
1 −ρ2 In ⊗Σ,
where In is an identity matrix of order n. With eit = yit −Xitβ, the
marginal likelihood for parameters χ = (ρ, σ2
υ, β) is then of the form L(χ|y) =
const −0.5 log |Φ| + e′Φ−1e.
A stationary ﬁrst-order moving average or MA1 scheme (Baltagi and Li,
1995), with
yit = Xitβ + uit + θui,t−1,
and with |θ| < 1, leads to a particular form of a Toeplitz covariance matrix
(Weiss, 2005, 267). Thus, set ϕ2 = var(uit + θui,t−1) = σ2(1 + θ2) and γ =
θ/(1 + θ2), then
Σi = ϕ2






1
γ
0
0
· · ·
γ
1
γ
0
· · ·
· · · · · · · · · · · · · · ·
· · ·
0
γ
1
γ
· · · · · ·
0
γ
1






= σ2






1 + θ2
θ
0
0
· · ·
θ
1 + θ2
θ
0
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
0
θ
1 + θ2
θ
· · ·
· · ·
0
θ
1 + θ2






.

354
Applied Bayesian Hierarchical Methods
Stationary or random walk models for errors can be extended in various
ways. Thus for unequally spaced data at points {ai1, ai2, . . . , aiT }, the AR1
model becomes
εit = ρ|ait−ai,t−1|εi,t−1 + υit,
with covariance between errors given by (Baltagi and Wu, 1999),
cov(εit, εis) = ρ|ait−ais|σ2
υ.
Another option when Ti is relatively large are subject varying autocorrela-
tion parameters, with Ryu et al. (2007) proposing independently distributed
ρi ∼U(−1, 1). Autoregressive and random walk priors are also applicable
for subject level predictor eﬀects βit which are changing over time. Thus, an
autoregressive prior could be centered on an average subject eﬀect Bi, as in
βit = Bi + ρβ(βi,t−1 −Bi) + eit,
where Bi is itself random and the eit are unstructured (see Example 8.3).
The use of autocorrelated or random walk eﬀects raises issues about how
to specify the initial conditions (initial random eﬀects) such as εi1 under an
AR1 or RW 1 prior on εit, and {εi1, εi2} under an AR2 or RW 2 prior. For
stationary autoregressive errors, such as the AR1 prior
εit = ρεi,t−1 + υit,
the variances of εit and υit are analytically linked, so that the initial conditions
are necessarily speciﬁed as part of the prior. So for stationary AR1 dependence
in εit and equally spaced data, one has
εi1 = υi1/(1 −ρ2)0.5,
and
var(εi1) = σ2
υ/(1 −ρ2),
and the joint distribution of the εit is obtained (Xu et al., 2007, 418) as
p(εi1)

t=2
p(εit|εi,t−1),
where
p(εit|εi,t−1) =
1
συ(2π)0.5 exp(−0.5[εit −ρεi,t−1]2/σ2
υ).
In nonstationary and random walk models without the constraint |ρ| < 1,
the initial conditions are usually speciﬁed by diﬀuse ﬁxed eﬀect priors, though
Chib and Jeliakov (2006) interlink the variance of the initial conditions with

Hierarchical Models for Panel Data
355
that of the main sequence of eﬀects to provide a proper joint prior on
{εi1, . . . , εiTi} under a RW2 prior. One may also link initial conditions εi1
and subject heterogeneity, as in
bi ∼N(ψεi1, σ2
b),
where ψ can be positive or negative (Chamberlain and Hirano, 1999). This
amounts to assuming a bivariate density for bi and εi1.
Regressions involving low-order autoregressive errors may sometimes be
transformable to models with unstructured errors by diﬀerencing the regres-
sion means. Thus, the diﬀerence εit −εi,t−1 between a random walk error εit
and its predecessor is white noise, as is the diﬀerence εit −ρεi,t−1 under an AR1
error assumption (Lee and Nelder, 2001). So for y continuous the speciﬁcation
yit = Xitβ + εit,
εit = ρεi,t−1 + υit,
t = 2, . . . , T,
where υit is unstructured is equivalent to
yit = ρyi,t−1 + Xitβ −ρXi,t−1β + υit,
t = 2, . . . , T.
(8.6)
Example 8.3. Capital Asset Pricing Model
This example considers a
metric outcome for what may be termed a medium n, large T scenario (not
typical of many panel datasets). Following the theme of the capital asset
pricing model from ﬁnancial economics, Frees (2004, 302) considers links be-
tween the performance of (i.e., returns from) a particular security and market
performance in general. The particular application is to n = 90 insurance
ﬁrms observed over T = 60 months (January 1995–December 1999). The re-
sponse yit is the security return for ﬁrm i in excess of the risk-free rate and
the predictor xt is the market return in excess of the risk-free rate.
To allow for varying impacts of xt on yit, a baseline model (Model 1)
proposed by Frees (2004) is the RIAS speciﬁcation:
yit = b1i + b2ixt + uit,
with unstructured errors uit ∼N(0, 1/τu). The coeﬃcients b2i measure how
far the return of security i is attributable to market factors. A bivariate nor-
mal prior is assumed for {b1i, b2i}, with mean (B1, B2) and covariance D.
A Wishart W(4I, 4) prior for D−1 is assumed, with the prior mean for the
covariance matrix D then being the identity matrix.
The last 4000 of a 5000 iteration two chain run provide a signiﬁcant ef-
fect for xt with B2 having posterior mean (95% credible interval) of 0.72
(0.63, 0.81). To assess whether ﬁrst-order autoregressive dependence might be
present, deﬁne realized residuals eit = yit −b1i −b2ixt. Then a ﬁrm-speciﬁc
statistic proposed by Baltagi and Li (1995) can be obtained, namely
T 0.5(˜ρ2i −˜ρ2
1i)/(1 −˜ρ2i),

356
Applied Bayesian Hierarchical Methods
where
˜ρ1i =
T

t=2
eitei,t−1
 T

t=1
eit
2,
˜ρ2i =
T

t=2
eitei,t−2
 T

t=1
eit
2.
This statistic tends to N(0, 1) for large T, and over half the 90 ﬁrms
have signiﬁcantly negative or positive values on this basis. Another evaluation
involves a posterior predictive check based on an average of Durbin–Watson
(DW ) statistics taken over all 90 ﬁrms. Thus, at each iteration r, a DW
statistic is derived for each ﬁrm, namely
DW (r)
i
=
T

t=2

e(r)
it −e(r)
i,t−1
2
 T

t=1

e(r)
it
2.
A summary statistic for autocorrelation is then the average over ﬁrms
DW
(r) = 
i DW (r)
i /n. This can be obtained for both actual data DW
(r)
obs,
and for replicate data DW
(r)
new, and the procedure of Gelman et al. (1996)
applied. The resulting posterior probability Pr(DW obs ≥DW new|y) is 1,
indicating inadequate ﬁt.
Accordingly a revised model3 (Model 2) includes a stationary AR1 error,
so that
yit = b1i + b2ixt + εit,
εit = ρεεi,t−1 + υit,
and ρε ∼U(−1, 1). A 5000 iteration two chain run (with the last 4000 for
inference) gives signiﬁcant ρε, B2, and diag(D) estimates, with respective
means and 95% intervals −0.09 (−0.12, −0.06), 0.74 (0.64, 0.84), 0.63 (0.29,
1.20), and 0.17 (0.12, 0.25). The densities for D11 and D22 are bounded away
from zero. This model lowers the DIC by 27 compared to model 1 (from 39,721
to 39,694), albeit with complexity de rising from 69 to 89.
Frees (2004) suggests an extension to unit-time speciﬁc predictor eﬀects βit.
Thus Model 3 speciﬁes,
yit = b1i + βitxt + εit,
εit = ρεεi,t−1 + υit,
where a stationary AR1 prior is assumed for the evolving market eﬀects βit:
βit = b2i + ρβ(βi,t−1 −b2i) + eit.
Priors are as above on {b1i, b2i}, D, and ρε, and additionally ρβ ∼U(−1, 1),
eit ∼N(0, σ2
β), βi1 ∼N(0, σ2
β1), 1/σ2
β1 ∼Ga(1, 0.001), and 1/σ2
β ∼Ga(1, 0.001).

Hierarchical Models for Panel Data
357
This model shows a predominantly negative density for ρβ, but not signiﬁ-
cantly negative, with 95% interval (−0.38, 0.05), and a similar estimate for ρε
to that obtained under Model 2. The DIC falls to 39,566, despite the com-
plexity index de rising to 630. With a diﬀuse Ga(1,0.001) prior on 1/σ2
β, the
estimates for βit have relatively low precision and a prior stressing smoothly
varying parameter change may be preferred.
8.4
Panel Categorical Choice Data
Repeated categorical data involving ordered or unordered options or choices
k = 1, . . . , K by subjects i = 1, . . . , n for repetitions t = 1, . . . , Ti are of-
ten found in brand choice, labor market and political science applications
(Niedermeier and Von Eye, 1999; Pettitt et al., 2006; Rossi et al., 2005). These
may be expressed via binary indicators dikt = 1 if category or choice k applies
(dikt = 0 for remaining categories) or by categorical responses yit ∈(1, . . . , K).
Clinical and pharmaceutical applications commonly involve ordinal rating
scales (e.g., Agresti and Natarajan, 2001; Qiu et al., 2002; Tan et al., 1999;
Zayeri et al., 2005). Particular issues raised by such data include the possi-
bility that permanent subject eﬀects vary between choices (or more generally
between categories), and that predictor eﬀects may vary over one or more of
choices, as well as over subjects or times. If lagged eﬀects of the dependent
variable are included (Section 8.5), these may include both own category and
cross-category lags, leading to categorical transition models (Fokianos and
Kedem, 2003).
Chintagunta et al. (2001) consider repeated brand choice data and allows
subject heterogeneity in relation to attributes of the choices (e.g., variable
consumer responsiveness to brand prices), as well as randomly varying subject-
choice intercepts bik. A Bayesian perspective, including optimal MCMC
sampling schemes, on consumer heterogeneity in multinomial panel data for
purchase choices is provided by Rossi et al. (2005, Chap. 5). For identiﬁability,
choice or category-speciﬁc parameters must be set to a ﬁxed value (usually
zero) in a reference category. For example, the probability that a consumer
chooses brand k in period t might be modeled using a multinomial logit (MNL)
regression,
πikt = Pr(yit = k) = φikt
 K

k=1
φikt,
log(φikt) = β0k + bik + Pktβk + Aktγ,
k = 1, . . . , K −1,
log(φiKt) = AKtγ,
where β0k are intercept terms, Pkt and Akt are brand-time speciﬁc charac-
teristics (e.g., price and advertising spend) varying in whether associated

358
Applied Bayesian Hierarchical Methods
regression parameters are choice speciﬁc, and bik are random consumer-brand
taste eﬀects. These are typically taken as multivariate normal of dimension
K −1, with biK = 0 for identiﬁability (Malchow-Moller and Svarer, 2003).
Consumer variation in response to prices or attributes would involve mak-
ing the βk and γ coeﬃcients speciﬁc to each consumer and deﬁning hyperpa-
rameters for the densities of βki and γi. For Pkt of dimension R, Rossi et al.
(2005, 136) propose a conjugate normal hierarchical prior structure for subject
eﬀects βi = (β1i, . . . , βRi) with mean Zi∆, where Zi are consumer attributes,
and with variance Vβ of dimension dim(βi) = (R −1)R. Vβ is assigned an in-
verse Wishart prior having with expectation I and dim(βi) + three degrees of
freedom. They demonstrate the improved MCMC convergence for βi obtained
by using a random walk Metropolis with increments that have covariance
s2(Hi + (V (r)
β
)−1)−1, where Hi is the Hessian of a composite likelihood based
on multiplying the MNL subject-speciﬁc likelihood by the pooled (all subject)
likelihood raised to power ρi = (Ti/cN), and c > 1 and s = 2.93/sqrt[dim(βi)]
are tuning constants.
Hedeker (2003) considers categorical longitudinal data with subject level
predictors only, namely Xit and Zit of dimension P and Q, and category-
speciﬁc ﬁxed regression eﬀects, namely
log(φikt) = β0k + Xitβk + Zitbik,
log(φiKt) = 0,
where Zitbik = z1itbik1 + z2itbik2 + · · · + zQitbikQ. Assuming the Xit and Zit
are nonoverlapping, one may adopt Q independent sets of subject-category
eﬀects each of dimension K −1, one for each predictor zqit,
(bi1q, . . . , bi,K−1,q) ∼NK−1(Bq, Dq).
Alternatively the covariance matrix of the random eﬀects may be of di-
mension (K −1)Q with the bik correlated over both categories and predictors.
Hedeker (2003) in fact considers the case where Zit is a subset of Xit, so the
bikq are zero mean random eﬀects, and takes the covariance matrices to be
choice-speciﬁc Dk of dimension Q, so that
(bik1, . . . , bikQ) ∼NQ(0, Dk).
This permits a latent variable interpretation based on a Cholesky decom-
position of Dk and standardized random eﬀects ζik, namely
log(φikt) = β0k + Xitβk + ZitCkζik,
where CkC
′
k = Dk.
Examples of repeated ordinal observations are provided by labor mar-
ket perception data (Spiess, 2006), changing attitudes to divorce (Berrington
et al., 2005), and repeated ordinal scores in horticultural research (Parsons

Hierarchical Models for Panel Data
359
et al., 2006). Suppose responses yit have K ordered categories, with corre-
sponding latent responses y∗
it speciﬁed by thresholds, possibly time varying
κkt, or subject varying κik. For time varying thresholds
yit = k
if
κk−1,t < y∗
it ≤κkt,
with predictor eﬀects also possibly varying over (at least one of) categories,
subjects or times. For example, Spiess (2006) considers predictor eﬀects vary-
ing over times, as in
y∗
it = Xitβt + εikt,
where P(εikt) is usually a normal or logistic distribution; these distribu-
tions are very similar though the logistic places more probability in the tails
(Hedeker, 2003). So
Pr(y∗
it ≤κkt) = Pr(Xitβt + εikt ≤κkt) = Pr(εikt ≤κkt −Xitβt).
According to the form for P(εikt), one has
Pr(y∗
it ≤κkt) = Φ(κkt −Xitβt),
or
Pr(y∗
it ≤κkt) = 1/(1 + exp(−[κkt −Xitβt])).
Let γikt = Pr(y∗
it ≤κkt), then
Pr(yit = k) = Pr(κk−1,t < y∗
it ≤κkt) = γikt −γi,k−1,t.
An equivalent speciﬁcation of this model involves sets of K −1 binary
variables for each subject–time pairing, namely gikt = 1 if yit ≤k, and gikt = 0
otherwise. Then for ε logistic,
Pr(yit ≤k)) = Pr(gikt = 1) = 1/(1 + exp(−κkt + Xitβt).
Example 8.4. Yoghurt Purchases
Data on yoghurt brand choice from
Chen and Kuo (2001) and Frees (2004), exemplify household heterogeneity in
consumer behavior, and panel analysis of unordered choices data, as consid-
ered by authors such as Chintagunta et al. (2001). The yoghurt choice data
relate to repeated purchases by i = 1, . . . , n households (n = 100) between
K = 4 brands, with widely varying numbers of repetitions Ti for each house-
hold (between 4 and 185). The total of observations is N = n
i=1 Ti = 2412.
Known inﬂuences on brand choice are brand and time speciﬁc, namely fea-
tures Akt (= 1 if the brand k was subject to an advertising feature at the
time t of purchase, = 0 otherwise), and shelf price Pkt. Of potential interest is
the beneﬁt of considering (a) random choice variation due to subject and/or

360
Applied Bayesian Hierarchical Methods
choice heterogeneity, and (b) consumer heterogeneity in response to known
features.
A baseline ﬁxed eﬀects model4 (Model 1) has the form:
πikt = Pr(dikt = 1) = φikt
 K

k=1
φikt,
log(φikt) = β0k + Aktγ1 + Pktγ2,
k = 1, . . . , K −1,
log(φiKt) = AKtγ1 + PJtγ2.
A random intercepts model (Model 2) allows for heterogeneity at subject-
choice level but homogenous impact of brand attributes, and has the form:
log(φikt) = Aktγ1 + bik + Pktγ2,
k = 1, . . . , K −1,
log(φiKt) = AKtγ1 + PKtγ2,
(bi1, . . . , bi,K−1) ∼N(B, D),
where the vector B denotes the average category intercepts (β01, . . . , β0,K−1).
Inferences are based on the last 4000 of a two chain run of 5000 iterations
in Model 1, and on the second half of a two chain run of 10,000 iterations in
Model 2. The ﬁxed eﬀect model has DIC of 5324 (de = 5.1) and log(psML)
of −2662, whereas the random heterogeneity model has a DIC of 2540 (de =
251) and log(psML)= −1330. Estimates of the covariance matrix D under
Model 2 show brand 2 choice to be negatively related to choice of both brand 1
and brand 3, while the covariance parameter between brands 1 and 3 straddles
zero. While Model 2 yields a pronounced gain in ﬁt, it has not controlled for
consumer variation in price or advertising responsiveness. Such variation might
be modeled by additional random eﬀects over subjects (i.e., making the γ1 and
γ2 coeﬃcients household speciﬁc) without necessarily also assuming random
variation over subject–brand combinations; this is left as an exercise.
Example 8.5. National Institute of Mental Health Schizophrenic
Collaborative Study: Ordinal Symptom Score
This study exempliﬁes
panel modeling of repeated ordinal outcomes, and involves an evaluation of
four drug treatments to alleviate symptoms in schizophrenia subjects: chloro-
promazine, ﬂuphenazine, thioridazine, and a placebo. Similar eﬀects were ob-
tained for the three anti-psychotic drugs, and so here the treatment is reduced
to a binary comparison of any drug vs. the placebo (cf. Hedeker and Gibbons,
1994). Symptom severity scores yit are observed for n = 324 subjects on three
occasions after the ﬁrst reading (at week 0), which is coincident with treatment
commencing, namely at weeks 1, 3, and 6. The score is ordinal with K = 7
levels, namely 1 = normal, 2 = borderline, 3 = mildly ill, 4 = moderately ill,
5 = markedly ill, 6 = severely ill, and 7 = extremely ill. Random intercepts
are assumed, together with random slopes on a time variable Zt obtained as
the square root of weeks. Fixed eﬀect predictors Xit are the treatment eﬀect,
a treatment by time interaction and the patient’s sex.

Hierarchical Models for Panel Data
361
In clinical applications it may be useful to have continuous measures of
diﬀerent types of patient morbidity or “caseness,” for example, a measures
of any symptom level as against normal status, or of markedly ill or worse
symptoms vs. less severe symptoms. Rather than a single latent metric frailty,
this indicates the utility of several latent scales in some settings, as deﬁned
by the K −1 binary variables gikt implied by each ordinal subject–time pair-
ing yit. So the analysis here5 involves augmentation with latent metric data
w∗
ikt deﬁned by truncated normal or logit sampling according as gikt = 1 (if
yit ≤k) and gikt = 0 (if yit > k). Then for a probit link,
w∗
ikt ∼N(κk −µit, 1)I(0, ),
when gikt = 1,
w∗
ikt ∼N(κk −µit, 1)I(, 0),
when gikt = 0,
where
µit = b1i + b2iZt + β1Tri + β2ZtTri + β3Gendi,
(b1i, b2i) ∼N2(B, D)
and B = (B1, B2) contains an overall intercept and time slope. With B1 as
an unknown, identiﬁcation of the K −1 = 6 thresholds requires setting κ1
to zero, and estimating the remaining ﬁve threshold parameters subject to
monotonicity constraints. Here κk = κk−1 + δk, where δk ∼Ga(1, 1).
Table 8.1 summarizes posterior densities obtained from the second half
of a two chain run of 20,000 iterations, with sb1 and sb2 equivalent to D0.5
11
and D0.5
22 , and ρb equivalent to D12/(D0.5
11 D0.5
22 ). The main treatment eﬀect
β1 is not signiﬁcant, but there is a steeper decline in morbidity for treated
subjects—shown by the signiﬁcantly negative coeﬃcient β2. Wide variation
TABLE 8.1
Posterior parameter summary.
Monte
Mean
St. devn.
Carlo SE
2.5%
97.5%
β1
0.085
0.232
0.01621
−0.449
0.524
β2
−0.735
0.100
0.00686
−0.920
−0.553
β3
0.133
0.131
0.00864
−0.126
0.375
η1
4.996
0.230
0.01524
4.500
5.500
η2
−0.570
0.091
0.00542
−0.736
−0.393
κ2
1.305
0.120
0.00718
1.068
1.546
κ3
2.355
0.124
0.00745
2.121
2.609
κ4
3.569
0.129
0.00785
3.328
3.828
κ5
5.163
0.142
0.00870
4.894
5.441
κ6
7.412
0.181
0.01034
7.065
7.762
Sb1
1.353
0.089
0.00456
1.178
1.531
Sb2
0.817
0.049
0.00233
0.725
0.917
ρb
−0.433
0.064
0.00270
−0.551
−0.299

362
Applied Bayesian Hierarchical Methods
0
5
10
15
20
25
30
35
40
45
50
–2.5
–1.75
–1.5
–1.25
–1
–0.75
–0.5
–0.25
0
0.25
0.5
0.75
1
1.25
1.5
1.75
2.5
More
Bin
Frequency
FIGURE 8.1
Histogram plot, posterior means of time slopes.
in time paths is apparent in the density of sb2, and in a plot (Figure 8.1) of
the posterior means of b2i. Diagnostic tests such as Q–Q plots and Jarque-
Bera tests support normality of the permanent eﬀects (b1i, b2i). The averages
of the posterior mean b2i over treated and placebo subjects are very similar,
but an alternative approach (left as an exercise) is to relate variation in the
permanent eﬀects directly to treatment, as in
µit = b1i + b2iZt + β1Gendi,
(b1i, b2i) ∼N2([B1i, B2i], D),
Bqi = γ0q + γ1qTri.
8.5
Observation-Driven Autocorrelation:
Dynamic Panel Models
Diﬀerences in behavior or event proneness between individuals (e.g., in econo-
metric or health applications) may operate through an autoregression in the
observations, latent or observed. Panel models including lagged observations
are often termed dynamic panel models, whereas static panel models do not
include lagged response values (e.g., Nerlove, 2002). A canonical dynamic
model for metric data involves lagged values of the dependent variable with
the overall error combining a time-invariant individual eﬀect and observation
level random noise (Bond, 2002).
Thus with a ﬁrst-order lag in the response, one has
yit = φyi,t−1 + Xitβ + bi + uit,
t = 2, . . . , T,

Hierarchical Models for Panel Data
363
where the uit ∼N(0, σ2) are independent of each other, and under standard
assumptions (Ahn and Schmidt, 1995) are also uncorrelated with the initial
observations yi1 and with permanent subject eﬀects bi. If Xit contains a con-
stant term, then the bi have mean zero and bi ∼N(0, D). Allowing for subject
level variation in a Q length vector of predictors Zit as well as for ﬁrst-order
lagged response leads to
yit = φyi,t−1 + Xitβ + Zitbi + uit.
Assuming a stationary process with |φ| < 1, one possible model for yi1 is
yi1 = Zitbi
1 −φ + Xitβ
1 −φ + ui1
with ui1 ∼N(0, σ2/(1 −φ2)) (Gourieroux et al., 2006). A simplifying ap-
proach, more feasible for large T, is to condition on the ﬁrst observation in
a model involving a ﬁrst-order lag in y, so that y1 is nonstochastic (Bauwens
et al., 1999, 135; Hjellvik and Tjøstheim, 1999). Geweke and Keane (2000) and
Lancaster (2002) consider Bayesian approaches to the dynamic linear panel
model, in which the model for period 1 is not necessarily linked to those for
subsequent periods in a way consistent with stationarity.
Maximum likelihood analysis of dynamic panel models is subject to an
initial condition problem if in fact there is correlation between the permanent
subject eﬀects bi and the initial observations (Hsiao, 1996). In case of such
correlation, possible options are a joint random prior (e.g., bivariate normal)
involving bi and ui1 (Dorsett, 1999), or a prior for bi that is conditional on
yi1, such as (Hirano, 2002; Wooldridge, 2005)
bi|yi1 ∼N(ϕyi1, σ2
1).
Dynamic linear models may be extended in several ways, to include
ARMA(p, q) error schemes, eﬀects of time functions, or random variation over
subjects or times in the impacts of lagged predictors. For example, Ulrick
(2007) uses a dynamic earnings model with AR1 autocorrelated errors,
yit = bi + φyi,t−1 + Xitβ + Wiγ + εit,
εit = ρεi,t−1 + υit,
where Wi are ﬁxed human capital attributes. Such a speciﬁcation follows
related earnings modeling work by authors such as Geweke and Keane (2000),
Lillard and Willis (1978), and MacCurdy (1982). The earnings regression equa-
tion may be extended (Galler, 2001) to a RIAS form:
yit = b1i + b2it + φyi,t−1 + Xitβ + Wiγ + εit,
where the random eﬀects b1i and b2i allow subject-speciﬁc variation in wage
level and wage growth. Taking the time function to be an unknown function

364
Applied Bayesian Hierarchical Methods
of t, δt, lead to the autoregressive latent trait (ALT) models considered by
Bollen and Curran (2004, 2006). Allowing for time varying coeﬃcients on
lagged responses yi,t−1 as well as random subject intercepts and growth rates
one might then have
yit = b1i + b2iδt + Xitβ + φtyi,t−1 + uit,
with δt subject to identifying constraints, such as δ1 = 1.
8.5.1
Dynamic panel models for discrete data
For discrete data, a range of dynamic panel approaches have been proposed,
varying according to the type of response (e.g., count or binary) and the
initial conditions method. For example, Wooldridge (2005) considers models
for binary and count data using a conditional prior method relating bi and
yi1, while Pettitt et al. (2006) follow the Heckman (1981) strategy, whereby
the model for the initial period does not include permanent eﬀects or a lagged
response eﬀect.
For counts yit taken as Poisson, yit ∼Po(µit), problems with taking a
linear impact of the ﬁrst lag outcome yi,t−1, as in
µit = exp(Xitβ + φyi,t−1 + bi),
t = 2, . . . , T
are mentioned by Fahrmeir and Tutz (2001, 244). This option for modeling
lag response impacts deﬁnes the Markov property scheme studied by Fotouhi
(2005) and Fotouhi (2007), under which the initial observation is modeled as
µi1 = exp(Xi1β + ci),
where Xi1 includes any relevant predictors for the ﬁrst period, and the subject
eﬀects bi and ci follow a bivariate normal with correlation ρ.
Alternatively the impact of a lagged count response may be modeled by a
log or other transform g(y), with extra preset or unknown parameters in case
the lagged y is zero. Thus if g(y) = log(y + c) where c = 1 (say), one has
µit = exp(Xitβ + φg(yi,t−1) + bi),
t = 2, . . . , T
and following Wooldridge (2005), one might assume
bi|yi1 ∼N(ϕyi1, σ2
1).
By contrast, an extension of the conditional linear autoregressive process
to panel data (Grunwald et al., 2000) would lead to Poisson means
µit = φyi,t−1 + exp(Xitβ + bi),
while a particular form of the full autoregressive conditional Poisson speciﬁ-
cation of Jung et al. (2006) speciﬁes
µit = φyi,t−1 + ηµi,t−1 + exp(Xitβ + bi).

Hierarchical Models for Panel Data
365
By contrast to count regression, regression for binary responses yit ∼
Bern(πit) may straightforwardly include lags in observed outcomes yi,t−s
leading to Markov chain models of various orders (Azzalini, 1994; Frees, 2004;
Hamerle and Ronning, 1995). In an early paper, Korn and Whittemore (1979)
consider a logit model,
logit(πit) = α0 + α1yi,t−1 + Xitβ
with ﬁrst-order Markov dependence. They ﬁnd a highly signiﬁcant α1, and
so strong evidence against an assumption that successive responses are inde-
pendent. Erkanli et al. (2001) consider higher-order Markov logistic regression
combined with random heterogeneity,
logit(πit) = α0 +
Smax

s=1
αkyi,t−s + Xitβ + bi,
where bi ∼N(0, D), and Smax is determined by a coeﬃcient selection pro-
cess. Alternatively ﬁxed predictor eﬀects β, and parameters (B, D) for random
eﬀects bi, may vary according to the previous value of the binary response.
So for one lag dependence, regression parameters and random eﬀect hyperpa-
rameters {βs, Bs, Ds} may be speciﬁc to previous response {yi,t−1 = s, s = 0
or 1} (Islam and Chowdhury, 2006).
Such alternatives extend in principle to multinomial outcomes yit
∈
(1, . . . , K) or equivalently dikt = 1 if category k applies (or is chosen) and
ditk = 0 otherwise. So
(dit1, . . . , ditK) ∼Mult(nit, [πit1, . . . , πitK]),
where nit = 1. Use of lags is complicated by the possible inﬂuence of cross-
category lags as well as own-category lags. Pettitt et al. (2006) consider a
Bayesian hierarchical multinomial model for changes in employment status
(a trichotomy), with one period lags in status as predictors. Thus, with em-
ployment status 1 as the reference (and so φi1t = 1), one has for t > 1
πikt = Pr(yit = k) = φikt
 K

k=1
φikt,
log(φikt) = bik + βkXit + γk1I(yit = 2) + γk2I(yit = 3),
k = 2, . . . , K,
where bik are category-speciﬁc random eﬀects. For the initial period, they
adopt a static multinominal login model which does not include lag eﬀects or
bik (Pettitt et al., 2006, 102), and has distinct ﬁxed regression eﬀects, namely
log(φik1) = δkXi1,
k = 2, . . . , K.
This follows from a linear approximation to the reduced form obtained
when lagged response variables are replaced by their speciﬁcations under the
dynamic model for periods preceding t = 1.

366
Applied Bayesian Hierarchical Methods
Dynamic modeling approaches may also be applied using latent metric
responses associated with binary or ordinal observations. Suppose observations
yit are binary such that the latent continuous response y∗
i,t > 0 if and only if
yit = 1, and y∗
i,t ≤0 if yit = 0. Then one might specify,
y∗
i,t = Xitβ + φ1yi,t−1 + φ2y∗
i,t−1 + uit
I(0, ),
for yit = 1,
y∗
i,t = Xitβ + φ1yi,t−1 + φ2y∗
i,t−1 + uit
I(, 0),
for yit = 0,
with standard normal white noise errors,
uit ∼N(0, 1),
and lag one dependence on both previous events and latent utilities. Chib and
Jeliazkov (2006) propose a scheme with lags only in observed binary outcomes
but with both heterogeneity and autocorrelated errors. Thus they take,
y∗
i,t = Xitβ + Zitbi +
K

k=1
φkyi,t−k + εit
I(0, ),
for yit = 1,
y∗
i,t = Xitβ + Zitbi +
K

k=1
φkyi,t−k + εit
I(, 0),
for yit = 0,
so distinguishing between alternative sources of intertemporal dependence.
The ﬁrst such source is state dependence on lagged responses yi,t−k; the second
is serial correlation in the errors, namely
εit = ρ1εi,t−1 + · · · + ρSεi,t−S + υit,
where υit ∼N(0, 1); and third is intraclass correlation arising because of
heterogeneity. In this way one may avoid spurious state dependence in which
previous responses proxy unobserved variation (Heckman, 1981).
Example 8.6. National Longitudinal Study of Youth: Lagged Earn-
ings Model
This example considers a metric outcome, namely earnings data
from the US National Longitudinal Survey (NLS) relating to young women
aged between 14 and 26 in 1968, and either already in the labor market in
1968, or entering the labor market during the period 1968–1988. In this period
there were 15 measuring occasions, namely each year during 1968–1988 except
1974, 1976, 1979, 1981, 1984, and 1986. There are 4711 subjects varying con-
siderably in their observed histories; many subjects are subject to attrition
or intermittent observation. The analysis here is based on a 10% sample of
the 4164 subjects who have at least two measurements on yearly log earnings,
where earnings ﬁgures for each subject are divided by calendar year averages
to correct for inﬂation. In this way the earnings proﬁle of a subject observed
over 1968–1975 (say) can be compared with that for a subject observed over
1978–1985. An alternative might be to have ﬁxed or random eﬀects for each

Hierarchical Models for Panel Data
367
calendar year to model population trends in average income (Hjellvik and
Tjoshteim, 1999).
Although not all years were subject to survey updates, the analysis here
takes a subject’s entire observation span (obtained by comparing initial and
last observation year) to deﬁne that subject’s total times Ti. Any intervening
years without observations are treated as missing data, whether this is due to
intermittent missingness or the absence of a NLS update in particular years.
Thus, the ﬁrst subject is observed on 12 occasions (in the studies in 1970,
1971, 1972, 1973, 1975, 1977, 1978, 1980, 1983, 1985, 1987, and 1988), but
that subject’s total times Ti is set at 19, with the intervening years without
observations (e.g., 1974, 1976, etc.) treated as missing data. Missingness is
taken to be at random, not depending on the possibly missing response value.
With yit denoting (inﬂation corrected) log earnings, the initial regression
model includes subject eﬀects bi, and ﬁxed binary attributes {W1i, W2i, W3i},
with W1i for college graduate (= 1, 0 otherwise), W2i for white ethnicity (= 1, 0
for other ethnicities), and an interaction W3i = W1iW2i. So for i = 1, . . . , n
where n = 416,
yit = β1 + bi + Wiγ + uit,
t = 1, . . . , Ti,
bi ∼N(0, D), and uit ∼N(0, σ2). Uniform U(0, 10) priors are assumed
for σ and D0.5, and N(0, 1000) priors are assumed for the ﬁxed eﬀects
{β1, γ1, γ2, γ3}.
The last 9000 of a two chain run of 10,000 gives a DIC of −1424 with
de = 354. The estimated γ coeﬃcients show signiﬁcantly higher earnings for
college graduates, and a positive but not signiﬁcant white ethnicity eﬀect,
with posterior means (sd) for γ1 and γ2 of 0.32 (0.05) and 0.033 (0.022). The
eﬀect of the interaction term is signiﬁcantly negative, with mean (sd) of −0.11
(0.055), suggesting a greater positive impact of college education on earnings
for nonwhite subjects. The posterior mean for the standard deviation of the
bi is 0.18, so that a subject for whom bi is one standard deviation above
the average would have earnings about 20%, namely 100 × exp(0.18), above
average, given observed personal characteristics Wi. Taking ˆuit = yit −β1 −
bi −Wiγ, there is evidence of autocorrelated errors, with the 95% interval for
the statistic ru = Σn
i=1ΣTi
t=2ˆuit ˆui,t−1/Σn
i=1ΣTi
t=2ˆu2
it being (0.06, 0.12).
To improve ﬁt a second dynamic model is nonstationary and similar to
Geweke and Keane (2000), in that there is a distinct model for the ﬁrst period
for each subject, and a one period lag eﬀect in earnings in subsequent periods,
with this eﬀect not constrained to stationarity. Permanent subject eﬀects are
also included in the model for periods t = 2, . . . , Ti so that
yit = bi + Wiγ + φyi,t−1 + uit,
t = 2, . . . , Ti,
yi1 = Wiγ1 + ui1,
where a N(0, 1) prior on φ is adopted, and the errors uit ∼N(0, σ2) and
ui1 ∼N(0, σ2
1) are independent.6 The last 9000 of a two chain run of 10,000

368
Applied Bayesian Hierarchical Methods
show a 95% interval for φ of (0.55, 0.63), along with considerably reduced
autocorrelation, with 95% interval for ru now from −0.058 to 0.000. Fit is
improved with DIC now lower at −1541 with de = 582. The γ coeﬃcients
are reduced in absolute size, but the college eﬀect γ1 remains signiﬁcant, with
95% interval (0.09, 0.18). The posterior mean for the standard deviation of
the bi is also reduced to 0.074.
Example 8.7. Epileptic Seizure Data: Lagged Count Model
These
data from Thall and Vail (1990) have been widely analyzed, albeit not nec-
essarily including lagged response eﬀects. They relate to counts of epileptic
seizures in four successive two-week periods. An anti-epileptic drug treatment
(progabide) was applied for some of the n = 59 patients, with others receiv-
ing a placebo. A pre-treatment eight-week baseline seizure count was also
obtained, and may be treated either as exogenous, or as an endogenous initial
condition (Fotouhi, 2007). Here the baseline count is included in the outcome
proﬁle, so that T = 5 with the baseline seizure count denoted as yi1. The
analysis here follows Lindsey (1993) in terms of including a lagged response
as one predictor. The predictor set for periods t = 2, . . . , T is a subset of that
in Table 12 of Fotouhi (2007), as initial runs showed most eﬀects in the full
set to be nonsigniﬁcant. The predictors for t ≥2 are then age, treatment,
and lagged seizure count, while the predictor set X1it = X1i consists of age
at baseline only. A bivariate normal model correlates the permanent eﬀects bi
for periods t ≥2 with the errors ci in the model for yi1.
So with Xit including an intercept and age, Model 1 takes
yit ∽Po(µit), t = 1, 5
with the means modeled as
µit = exp(Xitβ + φyi,t−1 + bi),
t = 2, . . . , T,
µi1 = exp(Xi1˜β + ci),
(bi, ci) ∼N2(0, D),
where D−1 ∼W(I, 2), and ﬁxed eﬀects are assigned N(0,10) priors. The last
9000 of a two chain run of 10,000 iterations7 show that in fact this model
leaves excess dispersion: the mean scaled deviance of 496 is well in excess
of the number, 5 × 59 = 295, of observations. This issue is returned to in
Example 8.10 below. The model for t ≥2 shows a 95% credible interval for
treatment (−0.61, 0.02) mostly conﬁned to negative values, while the 95%
interval for lagged seizures is (0.0001, 0.0042). The correlation between bi and
ci is 0.81.
Fotouhi (2007) demonstrates that inferences for these data may be aﬀected
by assuming the ﬁrst observation as exogenous or endogenous. Accordingly a
second model takes
yit ∽Po(µit),
t = 2, 5

Hierarchical Models for Panel Data
369
TABLE 8.2
Epilepsy count data, with and without model for initial observations.
Mean
St. devn.
MC St. Error
2.5%
97.5%
With Period 1 Model (N = 295), Permanent Eﬀects Bivariate Normal
Scaled Deviance
495.7
16.0
0.2
465.6
528.8
Const
1.74
0.15
0.0073
1.45
2.027
Age
−0.007
0.02
0.0011
−0.048
0.036
Trt
−0.29
0.16
0.0064
−0.61
0.02
Lagcount
0.0022
0.0011
0.00002
0.0001
0.0042
Corr(bi, ci)
0.81
0.05
0.0006
0.69
0.90
Without Period 1 Model (N = 236), Permanent Eﬀects Univariate Normal
Scaled Deviance
438.3
12.5
0.1
415.9
464.6
Const
1.74
0.18
0.0097
1.392
2.091
Age
−0.008
0.02
0.0009
−0.047
0.030
Trt
−0.30
0.25
0.0139
−0.80
0.20
Lagcount
0.0025
0.0010
0.00002
0.0004
0.0045
With Period 1 Model (N = 295), Permanent Eﬀects Bivariate Skew-Normal
Scaled Deviance
494.2
16.0
0.2
464.8
527.4
Const
1.62
0.26
0.02
1.12
2.14
Age
−0.008
0.020
0.001
−0.047
0.033
Trt
−0.29
0.16
0.006
−0.62
0.02
Lagcount
0.0021
0.0011
0.00002
0.0000
0.0042
Corr(bi, ci)
0.83
0.05
0.001
0.70
0.91
Skew parameter ci
−0.027
0.256
0.015
−0.517
0.454
Skew parameter bi
0.126
0.294
0.018
−0.453
0.673
and conditions on yi1, so that bi is now a univariate permanent eﬀect. Thus,
the means are
µit = exp(Xitβ + φyi,t−1 + bi),
t = 2, . . . , T,
bi ∼N(0, D),
where the precision parameter of the bi is assigned a gamma prior, D−1 ∼
Ga(1, 0.001). The main impact of this changed speciﬁcation is a lessening of
the treatment eﬀect (Table 8.2). The mean scaled deviance of 438, now for
4 × 59 = 236 data points, again shows excess dispersion. This indicates that
a complete model for these data requires observation level errors.
A third analysis (Model 3) replicates Model 1 except that it investigates
whether taking (bi, ci) as multivariate skew normal aﬀects ﬁt or inferences (see
Section 8.6), as unobserved morbidity may not be symmetric. Thus,
µit = exp(Xitβ + φyi,t−1 + bi + δ2W2i),
t = 2, . . . , T,
µi1 = exp(Xi1˜β + ci + δ1W1i),
(bi, ci) ∼N2(0, D),
where the {W1i, W2i} are independently half normal HN(0, 1) a priori, and
the skew parameters have δk ∼N(0, 10) priors. Fit is not improved under this
model (i.e., excess dispersion remains), and the skew parameters are not sig-
niﬁcant. Similar conclusions are reached using a multivariate skew t (Model 4)

370
Applied Bayesian Hierarchical Methods
for patient heterogeneity—namely that excess dispersion remains. As expected
the lowest scale factors ξi, in the notation of Equations 8.8a through c below,
are for the exceptionally ill subjects 18 and 49, namely ξ18 = 0.84 and
ξ49 = 0.71 (cf. Fotouhi, 2007, 601). A U(0.01, 0.5) prior is adopted on the
inverse of the multivariate t degrees of freedom parameter ν. The posterior
mean for ν is 24, not strongly indicating heavy tailed permanent intercepts.
8.6
Robust Panel Models: Heteroscedasticity,
Generalized Error Densities, and Discrete Mixtures
Preceding sections consider the normal linear mixed model for continuous
longitudinal outcomes yi = (yi1, . . . , yiT i)′ assuming normal errors at both
levels, and constant variances (or dispersion matrices) across subjects and
observations. Thus, assuming Zit is a subset of Xit, one has
yit = Xitβ + Zitbi + uit,
(b1i, b2i, . . . , bQi) ∼NQ(0, D),
and
(ui1, . . . , uiTi) ∼N(0, σ2ITi).
The general linear mixed model for y possibly being a nonmetric response
from the exponential family may not include observation level residuals, and
then takes the form:
g[E(yit|bi)] = Xitβ + Zitbi,
with (b1i, b2i, . . . , bQi) ∼NQ(0, D), where again normality of errors and con-
stant dispersion D are default assumptions.
Violation of standard assumptions regarding the forms of error density,
or of homoscedasticity, are likely to aﬀect inferences. For example, Neuhaus
et al. (1992) show that mis-speciﬁcation of the density for random intercepts
in a mixed logistic regression with πit = E(yit|bi) and
logit(πit) = bi + Xitβ
results in inconsistent estimation of the β coeﬃcients. Among principles that
may provide a robust approach to departures from such standard assumptions
is that of embedding the model in a more general framework (Ma et al., 2004;
Rice, 2005), with conventional assumptions (e.g., normality and homoscedas-
ticity of errors) as special cases of a broader model.
Following Chapter 5, assumptions of homoscedasticity at level 1 (repeated
observations within subjects) or at level 2 (heterogeneity between subjects)

Hierarchical Models for Panel Data
371
may be modiﬁed to allow more general variance functions varying over sub-
jects, times, or both, including dependence of the variance on subject or
observation level attributes. For example, studies by Baltagi and Griﬃn (1988)
and Roy (2002) are concerned with heteroscedasticity in the permanent ran-
dom eﬀects component of panel models, with variance linked to predictors in a
positive function. For varying intercepts bi as in Equation 8.4, one might relate
the subject-speciﬁc variances Di to predictor values averaged over time, Xi,
as in
Di = α2(1 + ϕXi)2,
where terms in the scalar or vector ϕ are positive. Li and Stengos (1994)
consider heteroscedasticity at observation level, so that for yit = Xitβ +
Zitbi + uit one might take
uit ∽N(0, σ2
it),
σ2
it = α2(1 + ϕXit)2.
Wakeﬁeld et al. (1994) in a nonlinear pharmacokinetic panel analysis with
positive structural eﬀects ηit specify a Bayesian heteroscedastic model at ob-
servation level. Thus, yit ∼N(ηit, ηω
it/τ), where ω is an unknown power and τ
is an overall precision parameter, and ω = 0 corresponds to homoscedasticity.
Similarly, more general error densities allowing for skewness, heavy tails
or other non-normal features may be adopted, with the standard assumptions
embedded within them. Alternatives to assuming multivariate normal subject
eﬀects may include heavy tail Student t heterogeneity (Chib, 2008; Lin and
Lee, 2006), skew normal and skew-t densities, and skew-elliptical densities (Ma
et al., 2004). Thus, the normal linear mixed model can be embedded within a
wider class of scale mixture normal densities, with the subject or observation
level scale parameters measuring outlier status (Chib, 2008; Wakeﬁeld et al.,
1994). Thus, the model of (8.1b), with normal cluster eﬀects bi and normal
residuals uit, is a special case of a scale mixture model with
yit = Xitβ + Zitbi + uit,
uit ∽N

0, 1
λi
Σi

,
bi ∽N

B, 1
ξi
D

,
λi ∽Gλ, ξi ∽Gξ.
A widely applied option takes the densities {Gλ, Gξ} to be gamma densities
with equal scale and shape νλ/2 and νξ/2, respectively, leading to t density
random eﬀects with {νλ, νξ} degrees of freedom. This provides resistance to
atypical data at both observation and cluster levels.

372
Applied Bayesian Hierarchical Methods
For possibly skew residual or subject eﬀects, transformation is one option:
Candel and Winkens (2003) consider transformed exponential errors for mod-
eling heterogeneity, obtained by sampling cqi ∼E(ηq), and centering the
sampled cqi giving bqi = cqi −cq, and providing errors that may be strongly
skewed to the right rather than symmetric. Ghosh et al. (2007) consider bivari-
ate skew-normal errors at both subject and observation level in a linear panel
model for metric responses, while Jara et al. (2008) allow both subject random
eﬀects and observation level errors to follow a multivariate skew-t distribution.
Thus, for a mixed panel model for a metric response of dimension Ti:
yi = Xiβ + Zibi + ui
(8.7)
suppose yi follows the multivariate skew-t density (Sahu et al., 2003). So
yi|β, bi, σ2, Ri, ∆i ∼ST ν(Xiβ + Zibi, σ2Ri, ∆i),
where ν is the degrees of freedom, Ri is a Ti × Ti matrix and ∆i =
diag(δ1i, . . . , δTi,i) contains skewness parameters relevant to the observation
level residuals that may in principle be speciﬁc to individuals and times. The
density of the entire observation set y = (y1, . . . , yn) conditional on collections
of bi, Ri and ∆i is (Jara et al., 2008)
p(y|β, b, σ2, R, ∆)
∝
n

i=1
2TitTi,ν(yi|Xiβ + Zibi, σ2Ri + ∆2
i ) ×
 ∞
0
tTi,ν(wi|µw, Σw)dwi,
where tm,ν(x|µx, Σx) denotes a multivariate t density of dimension m. When
Ri reduces to an identity matrix ITi and the subject–time skewness parame-
ters δit to a global parameter δ, namely δit = δ, the conditional expectation
and variances for each subject are
E(yi|β, bi, σ2, δ) = Xiβ + Zibi + (ν/π)0.5 Γ[(ν −1)/2]
Γ(ν/2)
δ1,
Var(yi|β, bi, σ2, δ) =
ν
ν −2(σ2 + δ2)ITi + (ν/π)
Γ[(ν −1)/2]
Γ(ν/2)
2
δ2ITi.
Under the reductions Ri = ITi, δit = δ, the conditional density may be de-
scribed by a mixture of normal distributions by conditioning on positive vari-
ables wi = (w1i, . . . , wTii) obtained by truncated sampling from a multivariate
normal with identity covariance matrix of dimension Ti and subject-speciﬁc
scalings λi ∼Ga(ν/2, ν/2), so that
yi|β, bi, σ2, wi, λi, δ) ∼NTi

Xiβ + Zibi + δwi, σ2
λi
I

.
wi ∼NTi

0, 1
λi
I

I(0, ).

Hierarchical Models for Panel Data
373
In the (usual) case when Xiβ + Zibi contains an intercept, then for iden-
tiﬁability reasons the elements in the vector wi may be centered (subsequent
to truncated sampling) (Jara et al., 2008). Thus, at each iteration the average
of the wit can be obtained, and then the centered variables Wit = wit −¯wi,
so that
yit ∼N

Xitβ + Zitbi + δWit, σ2
λi

.
Additionally in the model Equation 8.7, the permanent random eﬀects bi
may also be taken as skew multivariate t. Assuming the Z predictors are a
subset of the X predictors, one then has
bi|D, Γi ∼STνb(0, D, Γi),
(8.8a)
where D is Q×Q, νb is the degrees of freedom, and Γi = diag(γ1i, . . . , γQi) con-
tains skewness parameters relevant to the permanent eﬀects. Assuming com-
mon skew parameters Γi = Γ = diag(γ1, . . . , γQ), and conditional on a Q
vector of positive variables, hi = (h1i, . . . , hQi), with
hi ∼NQ

0, 1
ξi
I

I(hi > 0),
(8.8b)
ξi ∼Ga
νb
2 , νb
2

,
the random eﬀects are mixtures of normals, namely
bi ∼NQ

Γhi, 1
ξi
D

.
(8.8c)
For improved identiﬁcation, the hi can be centered around their means (at
each MCMC iteration), namely Hqi = hqi −hq., so that
bi ∼NQ

ΓHi, 1
ξi
D

.
8.6.1
Robust panel data models:
discrete mixture models
Another way of reducing the impact of arbitrarily selecting a particular para-
metric form for random variation in bi and/or uit is by using discrete mixtures
of random eﬀects priors—for example, see Butler and Louis (1992), Verbeke
and Lesaﬀre (1996), Sharples (1990), Weiss et al. (1999). A discrete mixture
prior may be more ﬂexible in dealing with unusual cases, skewness, and multi-
ple modes. The possibly conﬂicting criteria required in the case of a prior on bi
are considered by Muller and Rosner (1997): namely that the prior should be
ﬂexible to allow for heterogeneity in the population, though on the other hand,
unusual cases should not have an undue predictive inﬂuence.

374
Applied Bayesian Hierarchical Methods
An often suitable approach would involve two group normal mixture priors
with the groups typically being a main group and outlier group (Weiss et al.,
1999, 1563). Such schemes apply both for heterogeneity bi:
bi ∽πbNQ(0, D) + (1 −πb)NQ(0, ϕ2
bD),
and for unstructured observation level uit:
uit ∽πuN(0, σ2) + (1 −πu)N(0, ϕ2
uσ2),
where the factors {ϕb > 1, ϕu > 1} are used for variance inﬂation for the
outlier group. The prior probabilities of being in the main population are set
high (e.g., πb = πu = 0.95), and variance inﬂation factors are typically large,
e.g., ϕb = ϕu = 5 or 10. Provided one or other of the parameter sets {πb, πu}
or {ϕb, ϕu} is assumed known (i.e., is assigned preset values), the other set
may be taken as unknowns.
Another option are “switching” or shift priors whereby one group has
zero eﬀects, but a minority group has nonzero eﬀects. These may be used for
unstructured errors introduced to reﬂect overdispersion in count or binomial
data. For example, for yit ∼Po(µit), one may have
log(µit) = Xitβ + Zitbi + σkituit,
where σ is a scale factor, kit ∼Bern(πu), uit ∼N(0, 1), such that observation
level eﬀects are zero when kit = 0. One may preset πu low, say πu = 0.05.
For a longitudinal series with level ct subject to possible shifts, and Xit not
containing an intercept. one may similarly propose in an adaptation of Gerlach
et al. (2000) that
yit = ct + Xitβ + Zitbi + σuit,
ct = ct−1 + ktσwt,
where uit ∼N(0, 1), wt ∼N(0, 1), and kt ∼Bern(πc) with πc low.
A diﬀerent emphasis is when there is a substantive rationale for assuming
subject level eﬀects bqi follow a discrete prior at subject level. The hyperpa-
rameters governing the subject eﬀects {b1i, b2i, . . . , bQi} then become speciﬁc
for the latent category. Thus, in a growth curve model for modeling changes in
aggression ratings, Muthen et al. (2002) assume that a small number of latent
trajectories characterize growth in aggression. For subject i, let the latent cat-
egory be denoted ki ∈(1, . . . , K). Then conditional on ki = k, Equation 8.5
would become
b1i = B1k + e1i,
b2i = B2k + δ2kTr i + e2i,
b3i = B3k + δ3kTr i + e3i,
where (e1i, e2i, e3i) ∽N3(0, Dk). Observation level dispersion parameters may
also diﬀer according to latent group.

Hierarchical Models for Panel Data
375
Flexible discrete mixture models are also obtained under Dirichlet process
and related semi-parametric priors, as considered for repeated binary data by
Quintana et al. (2008), and for panel count data by Kleinman and Ibrahim
(1998). Averaging over diﬀerent number of mixture components K is possible
under discrete parametric mixture models using the reversible jump MCMC
algorithm—see Ho and Hu (2008) for an application to the linear mixed model.
In the nonparametric mixture approach, the number of clusters is an outcome
of other parameters such as the DP mass parameter κ. Under the truncated
Dirichlet process (Ohlssen et al., 2007), one may set a maximum Km possi-
ble clusters, with the realized number at each iteration being K ≤Km. The
posterior density of K will indicate whether the assumed maximum Km is
suﬃcient.
Hirano (2000, 2002) discusses nonparametric alternatives regarding white
noise observation errors uit in panel data, while Kleinman and Ibrahim (1998)
and Muller and Rosner (1997) consider mixed Dirichlet process (MDP) mod-
eling of permanent eﬀects bi. Under the MDP option, one has bi following a
density G which is itself unknown, centered on a speciﬁed base density G0
with precision κ. For example, with a base density G0 = NQ(B, D), one has
g[E(yit|bi)] = ηit = Xitβ + Zitbi + uit,
uit ∼N(0, σ2),
bi ∼G,
G ∼DP(κG0),
G0 = Nq(B, D),
where priors on β, B, D, σ2 are typically as considered above. This is the con-
jugate MDP prior for the normal linear mixed model which tends to the
conventional hierarchical prior as κ →∞.
The model considered by Hirano (2002) is also conjugate, and based on a
dynamic model,
yit = bi + ρyi,t−1 + uit,
where the bi are zero mean eﬀects that are modeled parametrically, and uit =
yit −bi −ρyi,t−1 may have nonzero means. One has for θit =

µit, σ2
it

,
uit ∼N

µit, σ2
it

,
θit ∼G,
G ∼DP(κG0),
where G0 speciﬁes,
G0(µ, σ2) : 1
σ2 ∼χ2(s)
sL ; µ ∼N(m, bσ2).
where s, L, m and b are preset. As discussed in Chapter 3, κ may be preset
or taken as an unknown. Thus Kleinman and Ibrahim (1998, 2592) consider
defaults such as κ = 1.5 and κ = 100, while Hirano (2002) takes κ ∼Ga(2, 0.5).

376
Applied Bayesian Hierarchical Methods
Example 8.8. A Pharmacokinetic Application
To exemplify heteros-
cedastic panel analysis, this example considers pharmacokinetic panel data
relating to plasma concentrations yit of the drug Cadralazine in n = 10 car-
diac failure patients at various times t = 1, . . . , Ti (in hours) following admin-
istration of a single dosage of G = 30 mg. Wakeﬁeld et al. (1994) propose a
one compartment nonlinear model for these data with mean concentration at
time t expressed as
ηit = (G/αi) exp(−βit/αi),
where αi > 0 and βi > 0 are, respectively, the volume of distribution and
clearance parameters for each subject. A hierarchical model is proposed with
second stage consisting of a multivariate normal or multivariate t for the
transformed subject eﬀects (b1i, b2i) = {log(αi), log(βi)}. For the ﬁrst stage
model, one option is a log-normal since y is positive, or a truncated normal,
with yit constrained to be positive. Under the latter, a heteroscedastic power
model, with a single precision parameter τ, leads to a variance ηω
it/τ, and the
ﬁrst stage model is
yit ∼N(ηit, ηω
it/τ)
I(0, ).
Another option for the ﬁrst stage model involves a normal scale mixture,
namely
yit ∼N(ηit, ηω
it/[λiτ])
I(0, ),
λi ∼Ga(0.5ν, 0.5ν).
Here these options are compared under the priors τ ∼Ga(1, 0.001), and 1/ν ∼
U(0.01, 0.5). A lognormal LN(0, 1) prior was assumed here for ω, rather than
ω ∼U(0, 5) as in Wakeﬁeld et al. (1994), as the latter led to convergence
problems. At the second stage, a bivariate normal for (b1i, b2i) is assumed
with
(b1i, b2i) ∼N2([B1, B2], D),
B ∼N(B0, C),
D−1 ∼W([ρR]−1, ρ),
with ρ, R, B, and C as in Wakeﬁeld et al. (1994).
Inferences are based on the second halves of 100 thousand iteration runs
in WinBUGS14 (with two chains); the scale mixture model with variances
ηω
it/[λiτ] has a lower log(psML), namely 48.4 vs. 74.3, than the model with
variances ηω
it/τ. This may reﬂect the relatively heavy parameterization in the
scale mixture approach, even though the average ν under the scale mixture
is 7.6. The power ω is estimated at 0.92 under the better performing model,
whereas a log-normal model would imply ω ⋍2. Out-of-sample predictions
of concentrations are important and these are made at a duration 32 hours.

Hierarchical Models for Panel Data
377
For subject 2, whose plasma concentrations remain relatively high compared
to other subjects, the mean prediction is 0.109.
An alternative robustiﬁcation8 involves a scale mixture at the second stage
(i.e., in the prior for random permanent eﬀects) with
yit ∼N(ηit, ηω
it/τ)
I(0, ),
(b1i, b2i) ∼N2([µ1, µ2], D/ξi),
ξi ∼Ga(0.5ν, 0.5ν).
This provides a log(psML) of 53.6, with ω having mean 0.88. The lowest weight
(ξ2 = 0.66) is for subject 2, whose mean prediction at 32 hours becomes 0.115.
Example 8.9. Skewed Cholesterol Data
This example relates to longi-
tudinal data on cholesterol levels collected during the Framingham heart study
for n = 200 randomly selected subjects, as considered by Zhang and Davidian
(2001). Relevant subject attributes are sex (1 = M, 0 = F) and age at base-
line. Several studies have re-considered the linear mixed model used by those
authors, namely
yit = Xitβ+Zitbi+uit = β1+β2Sexi+β3Agei+β4ait +b1i+b2iait +uit, (8.9)
where yit is cholesterol level divided by 100, and ait is (time −5)/10, where
time is years from baseline. Total periods Ti diﬀer between subjects, varying
from 1 to 6.
Here two models are considered to reﬂect positive skew apparent from
plots of the outcome. One may, for example, consider multivariate normal or t
skew in the permanent eﬀects (b1i, b2i). For skew bivariate normal permanent
eﬀects one has (Model 1)
bi|D, Γ ∼SN(0, D, Γ),
where D is 2 × 2, and Γ = diag(γ1, γ2). Equivalently, conditional on the posi-
tive standard normal eﬀects
hi ∼NQ(0, I)
I(0, ),
(with Q = 2), the random intercepts and slopes in Equation 8.9 are obtained as
bi ∼NQ(Γhi, D).
However, an alternative perspective (Model 2) is provided9 by allowing
changing skew through time. This involves a Ti vector of period-speciﬁc skew-
ness parameters δi = (δ1, . . . , δTi), that is δit = δt, in a multivariate skew
normal scheme for the observation level errors. Hence
uit|σ2, wit, δt ∼NTi

δtwit, σ2
,
wit ∼N(0, 1)
I(0, ).

378
Applied Bayesian Hierarchical Methods
While centered positive variables hi and wit may be preferred for identi-
ﬁcation, this slowed MCMC analysis considerably and uncentered eﬀects are
used for illustration.
The second half of a two chain run of 7500 iterations for Model 1 shows sig-
niﬁcant skewness in subject intercepts b1i, but not in the time slopes, with the
respective γ parameters having 95% intervals (0.40, 0.61) and (−0.26, 0.22).
The log(psML) obtained by monitoring inverse likelihoods is 7.7. A slightly
lower log(psML) of 6 is obtained for a run of the same length for Model 2.
The δt coeﬃcients show greater skewness at earlier follow-up times with
δ1, δ2, and δ3 having positive 95% credible intervals, respectively (0.10, 0.30),
(0.07, 0.26), and (0.01, 0.22), but later δt parameters having credible intervals
straddling zero.
Example 8.10. Robust GLMM for Epilepsy Data
This example con-
siders forms of robust modeling for the seizure data discussed in Example 8.7.
For example, Yau and Kuk (2002) consider sensitivity of ﬁxed eﬀects param-
eter estimates to the speciﬁcation of the random eﬀects components at both
subject level and observation level, and seek inferences that are robust to
outliers at both levels. They consider data for the 59 patients over the last
T = 4 visits by conditioning on the initial observation, though they include
it as a baseline measure of severity. The ﬁve predictors (X1 to X5) that they
use are: log of baseline seizure (Base), treatment (Tr), treatment interaction
with baseline, log of patient age, and a binary variable equal to 1 for the ﬁnal
visit, V4. Yau and Kuk consider ﬁrst two normal random eﬀects models, one
with such eﬀects at unit level only, namely
log(µit) = α + Xitβ + bi
with bi ∼N(0, D), and the other with random variation at both unit and
observation levels, namely
log(µit) = α + Xitβ + bi + uit.
The ﬁrst model applied here (Model 1) has subject level eﬀects only, and
assumes a uniform prior on D0.5 and ﬂat priors on ﬁxed eﬀects; convergence
is obtained before iteration 1000 in a two chain run of 10,000 iterations. This
model shows predictive coverage limitations, since only 91% of the data are
contained within 95% intervals of replicates yrep,it sampled from the model.
There is also excess heterogeneity with posterior mean scaled deviance of 432
compared to 236 observations. Standardized subject eﬀects (namely poste-
rior means of bi divided by their posterior standard deviations) include three
values over 5 (patients 25, 56, and 35 with standardized eﬀects 5.47, 6.26,
and 6.62). Examination of the observation level CPO estimates suggests poor
ﬁts to some points, for example, the third visit of patient 25, whose series
is {18, 24, 76, 25}.

Hierarchical Models for Panel Data
379
A second model (Model 2) has random variation at both subject
and subject–time levels, with hierarchically centered random eﬀect priors
(cf. Roberts and Sahu, 2001), namely
uit ∼N

bi, σ2
u

,
bi ∼N(α, D),
µit = uit + Xitβ,
with a U(0,100) prior for D0.5. Additionally a uniform shrinkage prior
(Natarajan and Kass, 2000) is adopted in relation to the other variance com-
ponent var(uit) = σ2
u, with φ = D/(D + σ2
u) ∼U(0, 1). Convergence in a two
chain run of 10,000 iterations is obtained before iteration 2500, and iterations
2501–10,000 give posterior means for σ2
u and D of 0.135 and 0.255, close to
the restricted maximum likelihood (REML) estimates of Yau and Kuk (2002).
The coeﬃcient on V4 loses its signiﬁcance, but predictive coverage is now over
99% and the posterior mean of the scaled deviance is now 248. The pseudo
marginal likelihood for this model is −605, compared to −671 for the simpler
model with subject level random intercepts only. The standardized subject
level eﬀects for patients 25, 56, and 35 are less extreme, namely 3.38, 3.74,
and 4.01, but still suggest outlier status.
Yau and Kuk (2002) also mention models where the heterogeneity is mod-
eled using a discrete mixture of intercepts, namely
log(µit) = αki + xitβ,
where the latent categorical allocation ki ∈(1, . . . , K) is multinomial with
probabilities (π1, . . . , πK) following a diﬀuse Dirichlet prior. The intercepts
α1, . . . , αK are subject to an order constraint. For illustrative purposes this
approach is applied with K = 4 (as Model 3), but is clearly inferior to a two
level random eﬀect approach. The posterior mean deviance is 449.
Model 4 retains observation errors uit as in Model 2, but with a selection
mechanism for these eﬀects.10 This model adapts to the scenario where many
patients may exhibit a stable diﬀerential over the visits (modeled by a level 2
eﬀect bi) with only a subset of patients exhibiting erratic trajectories that
require a random eﬀect for each visit. Thus binary indicators δi ∼Bern(πδ)
are introduced for each subject in a model where
log(µit) = α + xitβ + bi + δiuit,
with a U(0,100) prior for D0.5, and φ = D/(D + σ2
u) ∼U(0, 1). One may set
πδ to be an unknown or preset its value. Here a value πδ = 0.05 is adopted
initially, so that the posterior values Pr(δi = 1|y) can provide clear contrasts
to the prior values Pr(δi = 1) = πδ. A two chain run of 10,000 iterations
converges early and from the last 7500 iterations it emerges that 10 patients
have values for Pr(δi = 1|y) that exceed 0.1, and four patients, namely 25,

380
Applied Bayesian Hierarchical Methods
56, 10, and 16, have values that exceed 0.9. This model produces a mean
scaled deviance of 291 with predictive coverage of 98.3%. However, its psML
is slightly worse than Model 2, namely −608. Setting πδ at 0.10 reduces the
psML to −605, comparable to Model 2.
Finally, Model 5 reverts to a random eﬀect only model, but allows for
possibly non-normality via a mixed Dirichlet process. The random eﬀects are
bivariate, with nonzero means, one for the intercept (α in above models) and
one for a linear slope on visit. Thus
log(µit) = Xiβ + Zitbi,
where Xi = (Base, Tr, Base ∗Tr, Age), with predictor variables deﬁned as in
Kleinman and Ibrahim (1998, 2592), and with Zit = (1, Visit), where the visit
times are centered weeks/10. The patient random eﬀects have prior,
(b1i, b2i) ∼G,
G ∼DP(κG0),
G0 = NQ(B, D),
κ ∼Ga(2, 4),
(B1, B2) ∼N2(0, 1000I),
D−1 ∼W(R, ρ),
R = diag(20),
ρ = 10,
so that E(D−1) = diag(0.5), as in Kleinman and Ibrahim (1998). The maxi-
mum number of possible clusters is set at Km = 20.
A two chain run of 10,000 iterations converges after 5000. Conditional on
the particular choice made for the prior on κ, one obtains a mean scaled de-
viance of 392, better than Model 1 but still leaving excess variability. The
posterior density for the number of clusters has 0.025 and 0.975 percentiles
at 6 and 13, with mean 8.9, while κ has posterior mean 1.36. Histograms of
the mean {b1i, b2i} with superimposed normal curves suggest excess kurtosis
rather than skewness (Figures 8.2 and 8.3). The treatment eﬀect under this
model is signiﬁcant, with 95% interval (−0.66, −0.03).
8.7
Multilevel, Multivariate, and Multiple Time Scale
Longitudinal Data
Applications involving longitudinal data often involve contextual nesting of
subjects, multiple responses or multiple time scales. Consider ﬁrst data yijt
for repetitions t = 1, . . . , Tij for subjects i = 1, . . . , nj nested within clus-
ters j = 1, . . . , J. The general linear mixed model now assumes that condi-
tional on predictors and random eﬀects, the data are distributed independently
according to the exponential family,

Hierarchical Models for Panel Data
381
0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00
Random intercepts
0
5
10
15
20
Frequency
FIGURE 8.2
Random intercepts (seizure data).
p(yijt|θijt, φ) = exp

yijtθijt −a(θijt)
φ
+ C(yijt, φ)

with conditional means E(yijt) = µijt = a′(θijt), and link g(µijt) = ηijt to
regression terms ηijt. The structural model may specify permanent random
eﬀects {dj, bij} for both clusters and subjects within clusters. Fixed eﬀect
regression parameters may now be cluster speciﬁc, namely
g[E(yijt|βj, ci, bij)] = Xijtβj + Wijtdj + Zijtbij.
Taking βj as ﬁxed eﬀects is appropriate when the categorization j = 1, . . . , J
refers to a small number of treatment groups or demographic categories, as
in the much analyzed data from Pothoﬀand Roy (1964), or the data from
Oman et al. (1999) where four groups are formed by crossing treatment by
gender—see Example 8.11.

382
Applied Bayesian Hierarchical Methods
–2.00
–1.50
–1.00
–0.50
0.00
0.50
Random slopes
0
5
10
15
20
25
Frequency
FIGURE 8.3
Random slopes (seizure data).
Where predictor eﬀects vary randomly over time as in Equation 8.2, one
may now include time and cluster-speciﬁc eﬀects cjt, so that
g [E (yijt|βj, ci, bij)] = Xijtβj + Wijtdj + Hijtcjt + Zijtbij.
Autocorrelated errors may also be required to model temporal dependen-
cies, so that the unexplained variance may be due to a number of sources.
For example, Lee and Hwang (2000) consider a normal mixed eﬀects model,
applicable in growth curve applications with multiple groups of subjects
j = 1, . . . , J, with
yijt = Xijtβj + bij + εijt + uijt,
where
εijt = ρεij,t−1 + vijt
and the variances of bij, uijt, and vijt are subject to uniform shrinkage priors
(see Section 8.2.3).

Hierarchical Models for Panel Data
383
For nested panel data inferences (e.g., on growth patterns) may be
improved by borrowing strength over clusters. Similarly with panel data on
multiple outcomes, ymit for subjects i = 1, . . . , n, outcomes m = 1, . . . , M, and
repetitions t = 1, . . . , T, inferences on particular outcomes may be strength-
ened by incorporating correlations between outcomes. An example might be
for panel data on correlated but relatively rare spatially conﬁgured health
events, such as cancer types. Multiple outcome panel data are common in
clinical and educational applications, and the eﬀectiveness of interventions
may be judged in terms of multiple (usually) correlated outcomes rather than
by a single criterion (Dunson, 2007). In environmental applications multiple
outcomes with related aetiology are likely to be correlated (e.g., Jorgensen
et al., 1999; Liu and Hedeker, 2006).
With metric or discrete data ymit for multiple outcomes, the general lin-
ear mixed model with time homogenous, time varying and subject varying
predictor eﬀects becomes
g [E (ymit|βm, bmi, cmt)] = ηmit = Xitβm + Zitbmi + Hitcmt,
where Xit, Zit, and Hit are of length P, Q, and R. For example, Agresti (1997)
considers multivariate repeated binary responses,
ymit ∼Bern(πmit),
and a prediction model based on outcome–subject and outcome–time eﬀects,
namely
logit(πmit) = βm + bmi + cmt.
Given multivariate random outcome–subject eﬀects bmi, and ﬁxed eﬀects
cmt subject to an identifying corner constraint such as cm1 = 0 or cmT = 0,
the ymit are assumed conditionally independent.
The corresponding normal linear mixed model for multivariate metric re-
sponses is
ymit|βm, bmi, cmt, σ2
m = Xitβm + Zitbmi + Hitcmt + umit,
where the residuals umit are typically unstructured normal with variances σ2
m
speciﬁc to outcome m. The M sets of permanent eﬀect priors bmi, each of
dimension Q, may be correlated between predictors q within outcomes m, or
between outcomes m within variables q, or most generally over both variables q
and outcomes m. The same applies to the outcome–time eﬀects cmt, which may
be random, and incorporate short-range temporal dependence. For example,
time varying intercepts ct = (c1t, . . . , cMt) in the case R = 1 (and Hit = 1) could
follow autoregressive or random walk priors correlated over outcomes, as in
(c1t, . . . , cMt) ∼NM(ct−1, Σc).
Suppose Tmi responses are observed on outcome m for subject i, with Si =

m Tmi. In vector form the multivariate normal longitudinal model is then
Yi = Xiβ + Zibi + Hict + ui,

384
Applied Bayesian Hierarchical Methods
where Yi is of length Si. For example, Beckett et al. (2004) consider a bivariate
response (M = 2), with Zitm of dimension Q = 2, and Zi of dimension
(Si×4) = (Si×QM ). Heterogeneity involves a covariance matrix of dimension
QM with outcome-speciﬁc random intercepts and random time slopes, and
parameters of interest include covariance between person-speciﬁc initial levels,
D13, and covariance between person-speciﬁc slopes, D24.
Conjugate structures (e.g., Poisson–gamma, beta–binomial) may also be
used instead of the GLMM approach for discrete multivariate panel outcomes.
For example, overdispersed count data ymit may be assumed Poisson with
ymit ∼Po(µmitθimξmit),
where µmit = exp(Xmitβm), and
θim ∼Ga(am, am),
represent subject–outcome permanent random eﬀects. The ξmit represent
observation level eﬀects that are unstructured, or autoregressive, as in
ξmit ∼Ga(bmξmi,t−1, bm)
with variance parameters bm (e.g., Jorgensen et al., 1999).
8.7.1
Latent trait longitudinal models
As M increases the full dimensional approach becomes cumbersome, and fac-
tor analytic or latent trait approaches may pool information just as eﬀectively
and more parsimoniously (e.g., Dunson, 2003, 2006, 2007; Jorgensen et al.,
1999; Roy and Lin, 2000). Panel data on multiple outcomes raise the possi-
bility of shared random eﬀects across outcomes, instead of outcome-speciﬁc
eﬀects. For example, in spatio-temporal health applications, it is common to
have correlated count responses ymit such as diﬀerent types of cancer or psy-
chiatric illness. Observed risk factors for such outcomes may be limited or
incomplete. Common unobserved area-time risks may be summarized in ef-
fects rit, with loadings λm linking the common factor scores to each outcome.
These may be taken as unstructured (Tzala and Best, 2008), or assumed to be
spatially and/or temporally correlated. For identiﬁability, one may either set
var(rit) = 1, in which case the loadings are free parameters, or set one of the
loadings to a ﬁxed value, such as λ1 = 1, in which case var(rit) is an unknown.
Time and area common eﬀects, rit, may be combined with common area eﬀects
bi with loadings γm, and common time eﬀects ct with loadings κm, and the
same type of identifying rules. Then ymit ∼Po(µmit), with ﬁxed regression
eﬀects that might vary over outcomes, as in an extension of Equation 8.2,
log(µmit) = Xitβm + λmrit + γmbi + κmct.
Additionally unstructured eﬀects umit may be included to represent re-
maining overdispersion.

Hierarchical Models for Panel Data
385
In item analysis and psychometric longitudinal applications, a measure-
ment model might involve both constant and time-varying common factors.
Thus, for M items or tests carried out on T occasions, responses may be
determined by M item-speciﬁc factors bmi and by T time-speciﬁc factors rit
(Eid, 1996; Marsh and Grayson, 1994). The impact of these is governed by
time and outcome speciﬁc loadings γt and λm respectively, so that
ymit = αm + γtbmi + λmrit + umit.
Structural equation models for longitudinal data typically involve both
response indicators ymit of dimension Py which measure latent outcomes ηqit
of dimension Qy < Py, and exogenous predictors xkit of dimension Px which
measure latent causal inﬂuences ξqit of dimension Qx < Px (Dunson, 2007).
For example, for Qy = Qx = 1, ξit might be a time varying stress severity scale
related to short-term stressors {xkit, k = 1, . . . , Px}, and ηit might be a time
varying latent depression scale related to mood scale measures {ymit, m =
1, . . . , Py}. Then the measurement model is
ymit = α1m + λ1mηit + u1mit,
m = 1, . . . , Py,
xkit = α2k + λ2kξit + u2kit,
k = 1, . . . , Px,
while the structural model might include a linear eﬀect, possibly time varying,
of ξit on ηit. Additional aspects of the structural model might be lagged eﬀects
in each factor score on its current value, as in
ηit = ρ1ηi,t−1 + βtξit + Witγ1 + δ1it,
ξit = ρ2ξi,t−1 + Witγ2 + δ2it,
where {δhit ∼N(0, 1), h = 1, 2} have known scale for identiﬁability, and the
Wit are additional known predictors relevant to the factors, but there are no
intercepts (Daniels and Normand, 2006).
A simple common factor model may be applied when there are alternative
measuring scales, typically a gold standard measure, and one or more measures
of the same quantity but less expensive to obtain. Consider a situation where
bivariate metric data {y1ijt, y2ijt} are obtained for subjects i within clusters
j, where y1ijt denotes repetitions on the standard measure, and y2ijt denotes
repetitions on the proxy measure. The goal is to assess the reliability of the
proxy measure. One may postulate a shared permanent eﬀect bij between the
two outcomes as well as a unique permanent eﬀect cij for the proxy measure.
In the absence of intercepts for the y1 model one has
y1ijt = bij + u1ijt,
y2ijt = αj + λjbij + cij + u2ijt,
where the bij have nonzero cluster means Bj, but the cij are zero mean eﬀects,
namely
bij ∼N(Bj, D1j), cij ∼N(0, D2j).

386
Applied Bayesian Hierarchical Methods
The residuals are distributed as umijt ∼N(0, 1/τmj). The hypothesis that
{αj = 0, λj = 1} corresponds to y1 and y2 being identically calibrated in
group j (Oman et al., 1999, 43), that is, they both measure the same quantity
on the same scale (see Example 8.11).
8.7.2
Multiple scale panel data
Aggregate health and demographic event data are often available as totals
yixt for multiple time scales, for example by age group x = 1, . . . , X, as well
as by period t = 1, . . . , T, and possibly also by area or actuarial risk group
i = 1, . . . , n. A further cohort dimension c = 1, . . . , C is implicit in biological
age–time data via the relation c = t −x + X, and there have been extensive
developments in Bayesian age–period–cohort (APC) and area APC models
(AAPC) models (Baker and Bray, 2005; Bray, 2002; Lagazio et al., 2003;
Schmid and Held, 2004). For rare event totals yixt in relation to large popu-
lations Nixt, and assuming yixt ∼Po(Nixtµixt), a baseline model age–period
(AP) model might assume independence of age and period dimensions, with
µixt = exp(ηix) exp(θit), or equivalently
log(µixt) = κ + ηix + θit,
where structured (e.g., random walk or autoregressive) priors might be adopted
for age–area eﬀects ηix and area–time eﬀects θit, and the intercept κ is iden-
tiﬁed according to possible constraints on the random eﬀects.
Thus, Clayton and Schiﬄers (1987) consider data of the form yxt (i.e.,
without further stratiﬁcation), with means µxt where
log(µxt) = ηx + θt,
with both sets of eﬀects assumed to be random, though ﬁxed eﬀects may be
used when X or T is small. In the absence of an overall intercept in this
model, one or other series (say ηx) sets the level, and identiﬁability may be
gained by centering the remaining series θt at zero (possibly repeatedly at
each MCMC iteration), or by setting one parameter in the remaining series
to a ﬁxed value, e.g., θ1 = 0. If the model includes an overall intercept κ, then
centering both sets of eﬀects, namely 
x ηx = 
t θt = 0, provides a way of
ensuring identiﬁability. An APC model including a mean and structured age,
period and cohort eﬀects is
log(µxt) = κ + ηx + θt + γc
and identiﬁability requires either that the three sets of eﬀects be centered, or
that edge constraints such as η1 = θ1 = γ1 = 0 are used to avoid confounding
of the three series. Additionally the relation c = X −x + t means an extra
constraint is needed for full identiﬁcation, for example by taking γ1 = γ2 = 0
(Clayton and Schiﬄers, 1987).

Hierarchical Models for Panel Data
387
The convolution prior of Besag et al. (1991) may be generalized by adopting
structured and unstructured eﬀects for each time scale, as well as for areas
(Knorr-Held, 2000). Hence an APC model would become
log(µxt) = κ + ηx + θt + γc + u1x + u2t + u3c,
where u1x, u2t, and u3c are unstructured zero mean random eﬀects, while
{ηx, θt, γc} follow structured (i.e., random walk or other autoregressive) form.
For area–age–period data, yixt ∼Po(Nxitµxit), this approach leads to
log(µixt) = κ + ηx + θt + γc + si + u1x + u2t + u3c + u4i,
where si follows a structured spatial autoregressive prior, but the u4i are
unstructured zero mean random eﬀects.
In the preceding models, the dimensions are independent and multiplica-
tive in the risk scale (additive in the log risk scale). In particular, Hoem
(1987) discusses multiplicative models for data yix observed over ages and
other strata such as areas. In practice, interactions between one or more of
the diﬀerent time scales, or between the time scales and the units (e.g., areas
or actuarial risk groups), are likely. There may also be overdispersion, neces-
sitating more complex parameterizations. Interactions ψxc between age and
cohort are relevant if the age slope is changing between cohorts (e.g., cancer
deaths at younger ages are less common in recent cohorts), while in mortal-
ity forecasting, age–time interactions ψxt are of interest since diﬀerent age
groups may be subject to diﬀerent mortality improvements (Lee and Carter,
1992; Pedroza, 2006). In area APC models, area–cohort and area–time inter-
actions might be relevant (Lagazio et al., 2003), while in area life table models
(Congdon, 2006a), age–area interactions may be investigated, since deprived
areas may have relatively high “premature” mortality or illness (premature
mortality is sometimes deﬁned by death before age 75).
In area–time models, one may extend the RIAS principle, and assume area-
speciﬁc random variation for both the level and a time covariate. This amounts
to taking the interaction ψit as a linear trend model, with neighboring areas
having similar trend parameters, as in Bernardinelli et al. (1995). Thus with
yit ∼Po(Nitµit),
log(µit) = κ + ω1i + ω2i(t −¯t),
where ω1i and ω2i are spatially correlated over areas. One may further adopt
a bivariate spatial (e.g., bivariate CAR) prior for {ω1i, ω2i}, allowing level
and trend parameters to be correlated. Additionally, a convolution form may
be adopted both for level and trend, so that
log(µit) = κ + ω1i + u1i + (ω2i + u2i)(t −¯t),
where u1i and u2i are unstructured random eﬀects. Equivalently letting cji =
ωji + uji one has
log(µit) = κ + c1i + c2i(t −¯t).

388
Applied Bayesian Hierarchical Methods
A variation is to introduce an overall nonlinear trend via parameters δt,
along with time-speciﬁc spatial and unstructured eﬀects {ωit, uit}, and sta-
tionary AR1 dependence in the total lagged spatial eﬀect cit = ωit + uit
(Martinez-Beneito et al., 2008). Thus for t > 2,
log(µit) = κ + δt + cit + ρci,t−1,
with ρ ∈(−1, 1), while for t = 1,
log(µit) = κ + δ1 +
ci1
(1 −ρ2)0.5 .
This is equivalent to assuming log(µit) = κ + δt + ρt−1(1 −ρ2)−0.5ci1 +
t
k=2 ρt−kcik, where the last term is zero when t = 1.
In area–age–time models, area–age–time interactions ψixt may be parsi-
moniously modeled by separate linear trends for each age and area, namely
ψixt = (ω1x + ω2i)(t −¯t)
as in Sun et al. (2000), where the random coeﬃcients ω1x and ω2i may be
structured over ages and areas, respectively. Sun et al. (2000) actually assume
a spatial CAR(ρ) prior with mean zero for the ω2i (Section 4.8.2), but take
the ω1x to be unrelated ﬁxed eﬀects. The full model of Sun et al. (2000) also
includes unstructured age–area–time eﬀects, uixt, so that
log(µixt) = κ + si + ηx + (ω1x + ω2i)(t −¯t) + uixt.
Alternatively the time function in ψixt may be unknown, as in
ψixt = (ω1x + ω2i)δt,
where positive loadings ω1x and ω2i specify which ages are most sensitive to
trend eﬀects δt. For identiﬁcation, the δt are centered at zero or have a corner
constraint such as δ1 = 0, and the loadings ω1x and ω2i may be centered at 1,
constrained to sum to 1, or have a minimum of 1 (e.g., Osborn, 1975). So
for declining mortality, represented by δt following (say) a ﬁrst-order random
walk, larger ω1x and ω2i indicate which age groups and areas contribute most
to the mortality decline. Lee and Carter (1992) apply the age–time product
model ψxt = ωxδt in mortality forecasting, with identiﬁcation obtained by
ensuring δt sum to zero and that the ωx sum to 1.
Interaction priors may also be based on a Kronecker product of the struc-
ture matrices for the relevant dimensions (Clayton, 1996; Knorr-Held, 2000),
where a structure matrix is a constituent part of the precision (inverse co-
variance) matrix. For example, if the structure matrix of separate area and
age eﬀects are denoted Ks and Kx, then Ksx = Ks ⊗Kx deﬁnes the struc-
ture matrix for the joint prior for ψix, and conditional priors on ψix can be
obtained from Ksx. Thus, an RW 1 prior in age has a structure matrix with
oﬀ-diagonal elements Kx[ab] = −1 if ages a and b are adjacent, and Kx[ab] = 0

Hierarchical Models for Panel Data
389
otherwise. Diagonal elements are 1 if a = b = 1 or a = b = X, and equal 2 for
other diagonal terms. An RW 2 prior for age has structure matrix:
Kx =


1
−2
1
−2
5
−4
1
−4
6
−4
1
1
−4
6
−4
1
·
·
·
·
1
−4
6
−4
1
1
−4
6
−4
1
1
−4
5
−2
1
−2
1


.
The CAR(1) prior for spatially structured errors s = (s1, . . . , sn) based on
adjacency of areas is multivariate normal with precision matrix τsKs, where τs
is an overall precision parameter, and oﬀ-diagonal terms Ks[ij] = −1 if areas
i and j are neighbors, and Ks[ij] = 0 for nonadjacent areas. The diagonal
terms in Ks are Li where Li is the cardinality of area i (its total number
of neighbors). Then an area–age interaction eﬀect ψix formed by crossing an
RW 1 age prior with a CAR(1) spatial eﬀect has joint precision
1
σ2
ψ
Ks ⊗Kx,
and full prior conditionals with variances σ2
ψ/Li when x = 1 or x = X, and
σ2
ψ/(2Li) otherwise. With ∂i denoting the neighborhood of area i, the prior
conditional means Ψix for ψix are
Ψi1 = ψi2 +

j∈∂i
ψj1/Li −

j∈∂i
ψj2/Li,
Ψix = 0.5(ψi,x−1 + ψi,x+1) +

j∈∂i
ψjx/Li
−

j∈∂i
(ψj,x+1 + ψj,x−1)/(2Li),
1 < x < X,
ΨiX = ψi,X−1 +

j∈∂i
ψjX /Li −

j∈∂i
ψj,X−1/Li.
For identiﬁcation, the ψix should be doubly centered at each iteration (over
areas for a given age x, and over ages for a given area i).
Example 8.11. Alternative Measures of Creatinine Clearance
Oman
et al. (1999) compare a standard measure of creatinine clearance (MCC) with
a proxy measure ECC. MCC is obtained as the ratio of the amount of crea-
tinine (CR24) excreted in the urine over 24 hours, divided by serum creati-
nine (SERUMCR) concentration and by the number of minutes in the period,
namely
MCC = CR24/(SERUMCR × 60 × 24).

390
Applied Bayesian Hierarchical Methods
ECC is obtained from patient age and weight WT as
ECC = (140 −Age) ∗WT/(SERUMCR × 60 × 24),
with a further scaling by 0.85 for women only. There are four patient groups
formed by crossing gender with whether third-space body ﬂuids were present
on at least one visit. The J = 4 groups are then (1 = female, no ﬂuids;
2 = female, ﬂuids; 3 = male, no ﬂuids; 4 = male, ﬂuids), with group sizes
n = (51, 12, 41, 9) and total visits within groups N = (211, 42, 148, 36).
The repeated responses for patients i = 1, . . . , nj within groups j are
y1ijt = log(MCCijt) and y2ijt = log(ECCijt), with the common factor model
described in Section 8.7.1 then being applied, namely
y1ijt = bij + u1ijt,
y2ijt = αj + λjbij + cij + u2ijt,
bij ∼N(Bj, D1j),
cij ∼N(0, D2j),
umijt ∼N(0, 1/τmj).
Gamma priors with index and shape parameters of unity are assumed
for the precisions {1/Dmj, τmj}, and N(0,1000) priors for the ﬁxed eﬀects
{αj, λj, Bj}.
A two chain run of 50,000 iterations11 converges after around 15,000 itera-
tions, with the the second half of the run providing posterior mean estimates
(with standard deviations) for λj of 0.62 (0.14), 0.82 (0.81), 0.85 (0.14), and
0.91 (0.91). In fact, only the third (male-no ﬂuid) group has a 95% inter-
val for λ both straddling 1 and conﬁned to positive values. The α coeﬃcients
straddle zero for all groups except the ﬁrst. So identical calibration only seems
to hold for group 3.
The lack of precision for the λ coeﬃcients for groups 2 and 4 may reﬂect the
small samples and the heavily parameterized model being applied to them. It
may in fact be reasonable to apply more informative priors such as constrain-
ing the λj to be positive, or adopting priors (with downweighted precision)
based on the frequentist results of Oman et al. (1999).
Example 8.12. Mortality Change, with Area and Age Dimensions
Consider deaths and population data {yixt, Pixt} for areas i = 1, . . . , n, ages
x = 1, . . . , X, times t = 1, . . . , T. One may assume Poisson sampling yixt ∼
Po(Pixtµixt) with a log link for the mortality rates µixt (e.g., Hoem, 1987;
Sun et al., 2000). The application here involves annual male deaths over the
period 1999–2006 (T = eight years), in n = 32 London boroughs (in alphabetic
order, with Hackney including the City of London), and X = 19 age bands
(ages under 1, 1–4, 5–9, 10–14, . . . , 80–84, and 85+). Populations Pixt are
from the UK Oﬃce of National Statistics mid-year population estimates. This
example considers age–area interactions in level and trend and how these can
be modeled parsimoniously.
Thus one might adopt a linear trend model (Model 1) with independent
age and area impacts (ηx and si) on the mortality level, and parallel eﬀects
(ρ1x and ρ2i) on the trend also. Thus

Hierarchical Models for Panel Data
391
log(µixt) = κ + ηx + si + (ρ1x + ρ2i)(t −¯t) + uixt,
where the intercept κ is assigned a normal N(0, 1000) prior, the area eﬀects
si follow a spatial CAR(1) prior, and age eﬀects ηx following a normal ﬁrst-
order random walk. The associated conditional precisions (τs, τη) are assigned
gamma Ga(1, 0.01) priors. The ρ1x and ρ2i linear trend coeﬃcients are taken to
be unstructured normal random eﬀects with zero means, and with precisions
τρ1 and τρ2 that are assigned gamma Ga(1, 0.01) priors. Model 1 allows for mis-
cellaneous departures (e.g., including age–area interactions in level and trend)
from a linear trend by adding unstructured Normal errors uixt ∼N(0, 1/τu)
for each observation, where τu ∼Ga(1, 0.01).
By contrast, Model 2 allows for nonlinear trend and for explicit age–area
interactions in both level and trend. Thus
log(µixt) = κ + ηx + λxsi + ωixδt,
where priors on κ, si, ηx, and (τs, τη) are as for Model 1. To ensure identiﬁca-
tion, the ωix are positive random eﬀects with mean 1, ωix ∼Ga(αω, αω) with
αω ∼Ga(1, 0.01). Similarly, the δt are assumed to be ﬁxed eﬀects with identify-
ing corner constraint δ1 = 0, and δt ∼N(0, 1000), t = 2, . . . , T. The λx param-
eters are gamma with mean 1, namely λx ∼Ga(αλ, αλ) with αλ ∼Ga(1, 0.01).
The way the age–area interaction in the level of mortality is expressed is
that ages with elevated λx (signiﬁcantly above 1) are those that are most sen-
sitive to (in other words, are most relevant to deﬁning) the spatial eﬀects si.
For example, high mortality areas (those with si signiﬁcantly above zero) may
particularly demonstrate excess mortality (elevated λx) at younger and middle
ages. Similarly high posterior ωix identify age–area combinations that strongly
contribute to the trend expressed in the δt. In the case where interactions
in age and area are absent for both level and trend (i.e., the λx and ωix
parameters are eﬀectively all equal to 1), Model 2 reduces to an independent
dimension model,
log(µixt) = κ + ηx + si + δt.
Whether independence (multiplicativity of area, age, and time in the risk
scale) is supported or not would be ascertainable from the posterior 95%
intervals for λx and ωix. If such intervals all straddle 1, then both the λx (for
all x) and the ωix (for all x, i combinations) are eﬀectively 1.
Comparisons of model ﬁt use ﬁrstly the DIC, based on monitoring the
scaled Poisson deviance,
D =

i

x

t
yixt log(yixt/Pixtµixt) −(yixt −Pixtµixt),
with the complexity estimate de obtained by comparing the average devi-
ance ¯D over MCMC chains with the deviance D(¯µ) at the posterior means of
µixt. The second criterion is the pseudo marginal likelihood (psML), derived
using Monte Carlo estimates of conditional predictive ordinates p(yixt|y[ixt]),

392
Applied Bayesian Hierarchical Methods
namely the density for yixt when the model is estimated using data y[ixt]
for remaining areas, groups, ages, and times (Ibrahim et al., 2001). Model
checking involves sampling predictions yrep,ixt from the posterior predictive
density p(yrep|y) which are compared with the actual observations (Gelfand,
1996). Concordance with the data may be represented by the probabilities
Pr(yixt,rep ≤yixt|y), with extreme values (e.g., under 0.05 or over 0.95) indi-
cating cases where the model doesn’t ﬁt the data well. These probabilities are
estimated in practice by counting MCMC iterations r where the constraint
y(r)
ixt,rep ≤yixt holds, which for discrete death totals is based on the probability
(Marshall and Spiegelhalter, 2003)
Pr(yrep,ixt < yixt|y) + 0.5Pr(yrep,ixt = yixt|y).
Inferences for both models are based on the second halves of two chain runs
of 5000 iterations. Table 8.3 shows that the heavy parameterization involved
in Model 1 (an extra nXT parameters to account for model discrepancies)
results a high de, and the DIC in fact prefers Model 2. The log(psML) also
prefers Model 2. The close ﬁt achieved by Model 1 (albeit with a heavy pa-
rameterization) does, however, have the beneﬁt that predictive discrepancies
are low.
Figure 8.4 shows variation between age bands in their impact on the spa-
tial eﬀects; the posterior mean for αλ is 3.1, implying a variance in the λx of
around 0.3. The ages between 35–39 and 65–69 are those most associated with
area contrasts in the level of mortality. Table 8.4 shows the age–area combina-
tions with the highest and lowest ωix—those most and least associated with
the trend demonstrated in the ∆t. The highest ωix (signiﬁcantly exceeding 1)
associated with the mortality decline are concentrated in central London areas
(such as Kensington and Chelsea, Westminster) and some inner boroughs
(e.g., Wandsworth, Hammersmith) where falls in mortality over 1999–2006
were largest. For example, the observed SMR for males in Kensington and
Chelsea (obtained as 100   yit/   Eit with expected deaths Eit based
on England and Wales death rates in 2006) fell sharply: from 104 in 1999 to 94
(2000), 86 (2001), 86 (2002), 82 (2003), 72 (2004), 66 (2005), and 61 (2006).
TABLE 8.3
Model ﬁt criteria, Example 8.12.
% of
observations
Deviance
Mean
yixt over or
at ¯µ
deviance
de
DIC
log(psML)
underpredicted∗
Model 1
3887
5234
1347
6581
−14,500
4.0
Model 2
5440
5784
344
6128
−14,115
8.7
∗Observations where Pr(yrep = y|y)+0.5 Pr(yrep = y|y) exceeds 0.95 or underceeds
0.05.

Hierarchical Models for Panel Data
393
0
0.5
1
1.5
2
2.5
Under 1
1–4
5–9
10–14
15–19
20–24
25–29
30–34
35–39
40–44
45–49
50–54
55–59
60–64
65–69
70–74
75–79
80–84
85+
Mean
2.5%
97.5%
FIGURE 8.4
Age weights on spatial level eﬀects.
8.8
Missing Data in Panel Models
Attrition and intermittently missing data are frequently found in panel data,
and disregarding the process underlying such missingness may lead to biased
and ineﬃcient estimates, though diﬀerent mechanisms may apply for attrition
as opposed to intermittent missingness (Ma et al., 2005). In particular, miss-
ingness may be nonignorable, meaning that the probability of a missing obser-
vation or of permanent drop-out is associated with the value or values of the
variable that would otherwise have been observed (Troxel et al., 1998). Thus
in clinical trials, patients may drop out because of adverse treatment eﬀects, or
because they don’t feel the treatment is of beneﬁt, leading to biased estimates
of treatment eﬀects unless the missing data mechanism is allowed for.
Missingness generates an additional form of binary (or sometimes categor-
ical) data R, depending on whether responses Y and/or predictor variables
X are missing. Li et al. (2007) obtain a categorical (trinomial) missing data
indicator by distinguishing between intermittent and permanent missingness.
Similarly, if missing data is entirely due to attrition, it may be summarized
in a single multinomial indicator Ri = j if an individual drops out between
the (j −1)th and jth measurement (Fitzmaurice et al., 2004, Section 14.4;
Hedeker and Gibbons, 2006, 290). In pattern mixture models for attrition,
the dropout pattern may be summarized in various ways, most simply via a
binary variable contrasting completers as against dropouts, regardless of when

394
Applied Bayesian Hierarchical Methods
TABLE 8.4
Area–age weights, highest and lowest posterior means.
Borough
Age
Mean
2.5%
97.5%
Highest Weights
Wandsworth
30–34
4.36
2.78
6.10
Kensington-Chelsea
85+
3.37
2.81
3.96
Wandsworth
25–29
3.16
1.61
4.88
Westminster
80–84
2.75
2.20
3.33
Lewisham
30–34
2.56
1.15
4.14
Kensington-Chelsea
80–84
2.50
1.90
3.14
Kensington-Chelsea
75–79
2.46
1.80
3.17
Westminster
85+
2.38
1.92
2.90
Newham
85+
2.27
1.76
2.81
Brent
70–74
2.21
1.68
2.78
Hammersmith
75–79
2.20
1.59
2.86
Westminster
75–79
2.11
1.57
2.68
Lowest Weights
Lewisham
80–84
0.40
0.11
0.77
Brent
50–54
0.38
0.08
0.85
Kingston upon Thames
65–69
0.37
0.07
0.83
Tower-Hamlets
60–64
0.35
0.07
0.80
Barnet
85+
0.35
0.12
0.61
Barking-Dagenham
70–74
0.33
0.07
0.69
Redbridge
85+
0.32
0.09
0.61
Hounslow
85+
0.30
0.07
0.61
Havering
80–84
0.27
0.07
0.55
Barking-Dagenham
80–84
0.22
0.04
0.48
Greenwich
85+
0.20
0.04
0.45
Havering
85+
0.19
0.04
0.41
Waltham-Forest
80–84
0.19
0.04
0.43
Waltham-Forest
85+
0.14
0.03
0.33
the droput occurred (Hedeker and Gibbons, 1997). Finally, for longitudinal
datasets with continuous measurement at diﬀering observation times ait, one
may record actual drop out times Ui (Hogan et al., 2004), and use these in
the model for the observed Y .
However, initially consider binary indicators Rit = 1 when a response vari-
able Yit is missing, whether intermittent and permanent, and Rit = 0 for when
the response is observed. Further, let Y = (Yobs, Ymis) denote the observed
and unobserved response data. The totality (R, Y ) is sometimes known as the
complete or full data (Daniels and Hogan, 2008, 89; Ibrahim et al., 1999).
How one deals with missing data depends on the generating mechanism
assumed. Two broad missing data schemes (the selection approach and the
pattern mixture approach) involve a diﬀerent conditioning for the joint density
P(Y, R|θY , θR) of the responses and the missingness indicators. The pattern

Hierarchical Models for Panel Data
395
mixture model (Little, 1993) starts with a model for the missing data P(R|θR),
and models Y conditional on R, namely P(Y |R, θY ). When dropout times are
discrete, the model for P(R|θR) is often not speciﬁed (Hogan et al., 2004), or
when missingness is expressed in various dropout patterns, P(R|θR) may be
speciﬁed simply by the relevant multinomial probabilities of diﬀerent dropout
options (Curran et al., 2002, 13). By contrast, the selection model (Diggle
and Kenward, 1994; Heckman, 1976) starts with the data likelihood P(Y |θY ),
and models missingness conditional on the responses, P(R|Y, θR), so that
P(Y, R|θY , θR) = P(R|Y, θR)P(Y |θY ).
A classiﬁcation of missingness mechanisms is set out by Little and Rubin
(2002), and framed in terms of the selection approach, though is applicable
also to pattern mixture analysis. They distinguish between
(a)
missingness completely at random (abbreviated as MCAR), when
the probability Pr(R = 1) of a missing response is independent of
both observed and missing data Y = (Yobs, Ymis), namely P(R|Y ) =
P(R);
(b)
missingness at random (MAR), when missingness is independent
of the unobserved data Ymis, but may depend on observed data
Yobs, such as when the chance that Rit = 1 depends on preceding
observations yi,t−s; in this case one has the simpliﬁcation P(R|Y ) =
P(R|Yobs);
(c)
missingness not at random (MNAR), when the probabilities of miss-
ingness depend on unobserved missing responses, namely P(R|Y ) =
P(R|Yobs, Ymis). Since the data are partly missing, and R now
depends on the complete outcome data (Yobs, Ymis), the selection
model factors the joint distribution into a complete outcome model
and a missing-data mechanism given the partially unobserved com-
plete outcomes (Troxel et al., 2004).
An additional distinction is made between ignorable and nonignorable
missingness. Assume a MAR mechanism and that the missing-data model
is independent of the response data parameters θY . Then the missing-data
process is ignorable in the sense that that a model for missingness is not
needed in order to make valid inferences from the main Y-likelihood (Rubin,
1976; Fichman and Cummings, 2003). However, for nonignorable missingness
both the R-likelihood and Y-likelihood must be modeled.
As an illustration, drop-out at time t is classed as being at random if
Pr(Rt = 1|Y ) = Pr(Rt = 1|Y1, . . . , Yt−1), namely when the missingness prob-
ability is related to lagged observed responses. However, if the probability of
missingness at time t is related to the current outcome Yt, possibly missing, so
that Pr(Rt = 1|Y ) = Pr(Rt = 1|Y1, . . . , Yt) then missingness is nonrandom
or informative (Diggle and Kenward, 1994). In practice, informative missing-
ness is assessed empirically, and would require a signiﬁcant eﬀect of Yit on
πit = Pr(Rit = 1) in a binary regression also involving other inﬂuences on

396
Applied Bayesian Hierarchical Methods
missingness, with the regression taken over subjects i and repetitions Ti. For
dropouts one takes Ti = Ti,obs + 1 where Ti,obs is the last interval where data
on subject i was obtained (Roy and Lin, 2002). Since MNAR missingness can
never be excluded as a generating mechanism, a sensitivity analysis under
diﬀerent mechanisms may be considered (Kenward, 1998). This means esti-
mating the model under a “range of assumptions about the nonignorability
parameters and assessing the impact of these parameters on key inferences”
(Ma et al., 2005).
A common set of predictors Xit may be relevant to modeling both the
data Yit and missingness indicators Rit, or diﬀerent predictors Wit may be
used in the R model. King (2001) accordingly presents a statement of the
MCAR–MAR–MNAR alternatives as above, but replacing Y by D = (Y, X),
namely predictor and outcome data combined, and where D = (Dobs, Dmis)
denotes the subdivision of the data according to observation status. For exam-
ple, the MCAR assumption then requires P(R|D) = P(R), while missingness
at random requires P(R|D) = P(R|Dobs).
An alternative less stringent deﬁnition of MCAR missingness is used by
Little (1995), in which missingness is independent of Y , whether observed or
not, but may depend on fully observed covariates X (Curran et al., 2002, 12;
Daniels and Hogan, 2008, 92). Such covariates might for instance include time,
as missingness rates often increase at later stages of panels (Hedeker and
Gibbons, 2006, 281). So given Xobs, R is independent of both Yobs and Ymis,
leading to what is sometimes termed covariate dependent MCAR missingness.
8.8.1
Forms of missingness regression (selection approach)
A logit or probit regression is the most common approach to predicting
πit = Pr(Rit = 1), and to assessing ignorability and MCAR assumptions.
For example, πit might at a minimum be a function of immediately preceding
and current Y values, namely (Curran et al., 2002; Mazumdar et al., 2007)
logit(πit) = γ1 + γ2yit + γ3yi,t−1,
with a signiﬁcant γ2 indicating nonignorable missingness. Reﬁnements, espe-
cially in problems with intermittently missing data, include transition proba-
bility approaches (Li et al., 2007) with the model for
πi01t = Pr(Rit = 1|Ri,t−1 = 0)
having distinct parameters from that for
πi11t = Pr(Rit = 1|Ri,t−1 = 1).
If missingness is restricted to dropout only (i.e., there is no intermittent
missingness), then one may use a logit or clog–log link for the probability that
Ri = j|Ri ≥j, where Ri = j if a subject drops out between the (j −1)th and
jth measurement.

Hierarchical Models for Panel Data
397
Choice of additional predictors in the missingness model is an area of
potential sensitivity in terms of whether the coeﬃcient on the current Y value
is found to be signiﬁcant. Hedeker and Gibbons (2006) use logit or clog–log link
models to assess whether a covariate dependent MCAR assumption applies for
a given dataset. They relate Pr(Ri = j|Ri ≥j) to observed covariates Xobs
such as time and treatment, as well as to the history h(yit) of observed Y
values, and to interactions between Xobs and h(y). For example, h(yij) might
be the average of all yit between periods 1 and j. Then to test for covariate-
dependent MCAR, one might use a logit regression for Pr(Ri = j|Ri ≥j)
that includes main eﬀects {t, Tr, h(y)}, as well as interactions between h(y)
and t, between h(y) and Tr, and between h(y), Tr and t jointly.
The missingness model may have a role not only as part of a likelihood
analysis allowing nonrandom missing data or testing for diﬀerent types of
missingness, but as a method for imputing missing data. Thus a “propensity
score” analysis may be based on categorizing the regression terms ηit in
logit(πit) = ηit
into quantile groups (e.g., quartiles) (Rosenbaum and Rubin, 1983). Within
subjects located within particular quantiles of ηit, some subjects will exit but
some remain. Sampling of the missing yit for exiting subjects may be based
on sampling with replacement from the known yit values of stayers in the
same quantile—this is sometimes called the approximate Bayesian bootstrap
method (Lavori et al., 1995; Rubin and Schenker, 1986). In multiple impu-
tation, this imputation process would be repeated several times to provide
multiple ﬁlled-in datasets.
8.8.2
Common factor models
Latent variables may be introduced to explain both the Y and R data. Thus
a latent data perspective on the selection model might consider bivariate data
(Y, Z) where Yit is observed if the latent data Zit is positive (Copas and Li,
1997). Furthermore let Xit be predictor data potentially relevant to explain-
ing both Y and Z and deﬁne bivariate standard normal errors (ε1i, ε2i) with
correlation ρ. Assume a linear regression for Y with
yit = Xitβ + σ1ε1i,
and a missingness model
Zit = Xitγ + ε2i.
Then if ρ ̸= 0 the missing data are informative or nonignorable, whereas ρ = 0
corresponds to missingness at random.
A similar principle involves low dimension random eﬀects F, also known as
common factors, that are shared between outcome and missingness models;
similar shared frailty models are used for models with outcome-dependent

398
Applied Bayesian Hierarchical Methods
follow-up (Ryu et al., 2007). As often in factor models, the outcome data
and missingness patterns may be viewed as conditionally independent given
the common factors (Albert et al., 2002; Roy and Lin, 2002; Song and Belin,
2004; Ten Have et al., 1998). Equivalently, it is assumed that “all information
about the missing data in the observed response is accounted for through the
shared random eﬀects” (Albert and Follmann, 2007). In fact, Li et al. (2007)
and Yang and Shoptaw (2005) distinguish such models as an alternative to
selection and pattern mixture methods, since under conditional independence
one may represent the (R, Y, F) joint density as
P(Ri, Yi, Fi|θR, θY , θF ) = P(Ri, Yi|θY , θR, Fi)P(Fi|θF )
= P(Ri|θR, Fi)P(Yobs,i, Ymis,i|θY , Fi)P(Fi|θF ).
Integrating out the Fi, one has
P(Ri, Yi|θY , θR) =

P(Ri|θR, Fi)P(Yobs,i, Ymis,i|θY , Fi)P(Fi|θF )dF i.
Other assumptions are possible, as under the “conditional linear model”
(Daniels and Hogan, 2008, 112), with the conditioning sequence,
P(Ri, Yi, Fi|θR, θY , θF ) = P(Yi|θY , Fi, Ri)P(Fi|θF , Ri)P(Ri|θR).
One form of common eﬀect that may be used to model informative miss-
ingness is based on shared heterogeneity (e.g., Chib, 2008, 507; Li et al., 2007).
An example is a general linear mixed model with permanent subject random
eﬀects bi = (b1i, . . . , bQi);
g[E(yit|bi)] = Xitβ + Zitbi,
where the model for Pr(Rit = 1) also conditions on the bi, and possibly on
separate predictors Wit, and on the history of responses Hit = {yi1, . . . , yit}.
Consider the case Q = 1 with zit = 1, and suppose predictors Wit are relevant
to dropout (e.g., baseline health status in a clinical trial). Then a common
factor model adapted to predicting πit = Pr(Rit = 1|Wit, Hit) might take the
form:
g[E(yit|bi)] = Xitβ + bi,
(8.10)
logit(πit) = Witγ + λbi + yitδ1 + yi,t−1δ2,
where bi are zero mean random eﬀects, and the predictors {Xit, Wit} both
include an intercept. For example, Li et al. (2007) consider Poisson data with
yit ∼Po(λit),
log(λit) = Xitβ + bi,
and with binary indicators for missingness, and a lagged outcome scheme
adapted to counts, one would obtain
logit(πit) = Witγ + λbi + log(yit + 1)δ1 + log(yi,t−1 + 1)δ2.

Hierarchical Models for Panel Data
399
In fact the model of Li et al. (2007) distinguishes between intermittently
missing data and permanent attrition via a multinomial rather than binary
regression, and uses a transition probability missingness model.
A model with shared latent eﬀects exempliﬁed by Equation 8.10 imposes
possibly restrictive assumptions on the correlations among repeated responses
for a given subject. Conditional on the time-invariant shared eﬀects bi,
observations on a subject are uncorrelated (Albert and Follmann, 2007). An
alternative is a shared autoregressive process, as in
g[E(yit|Fit)] = Xitβ + Fit,
Fit = ρFi,t−1 + uit,
logit(πit) = Witγ + λFit + Yitδ1 + Yi,t−1δ2,
where the uit are white noise and ρ ∈(−1, 1).
For multivariate responses {ymit, m = 1, . . . , M}, one might propose com-
mon factors to model both correlation between the observed responses, and
the probabilities of missing response, especially attrition aﬀecting all outcomes
(Lin et al., 2004). Thus, consider a single time varying factor Fit, and load-
ings {λm, κ} in the Y and R likelihoods, and let Hit denote a subset of the
history of the observed X and Y variables up to time t. Then for outcomes
m = 1, . . . , M, one might have
g[E(ymit|Xit, Fit)] = Xitβm + λmFit
while the drop out probability Rit ∼Bern(πit) is modeled as
logit(πit) = Witγ + ϕHi,t−1 + κFit
for t = 1, . . . , Ti, where for dropouts Ti = Ti,obs + 1 and Ti,obs is the last
interval where data was observed. Furthermore, the factor scores may depend
on known predictors {Uit, Zit} and zero mean random permanent eﬀects bi,
as in
Fit = Uitη + Zitbi + υit
with υit ∼N(0, 1) if all loadings {κ, λm} are unknowns, and with Uit omitting
an intercept for identiﬁability (Roy and Lin, 2002, 42). The missingness model
is nonignorable by virtue of dependence of πit on Fit, which represents possibly
missing ymit (Roy and Lin, 2002, 43).
8.8.3
Missing predictor data
Often panel data will have missingness on covariates as well as on the response,
so that binary or categorical indicators RX are deﬁned according as covariates
have missing values or not. With R = (RY , RX), the joint density under a
selection approach has the form:
p(Y, X, RY , RX|η, β, θ) = pR(RX, RY |Y, X, η)pY (Y |X, β)pX(X|θ),

400
Applied Bayesian Hierarchical Methods
where pX now models the likelihood of the predictors. If RY is conditional on
all the components of RX one has
p(Y, X, RY , RX|η, β, θ)
= p(RY |RX, Y, X, ηY )p(RX|Y, X, ηX)pY (Y |X, β)pX(X|θ).
Alternatively RY may be modeled jointly with the RX, though complexity
increases as the number of predictors subject to missingness rises, giving rise
to diﬀerent possible conditional sequences for RY and the components of RX.
Suppose a subset of q predictors have missing values, with Rji = 1 if Xji
is missing, and Rji = 0 otherwise. If Y is fully observed, a selection approach
speciﬁes
p(Y, X, RX|η, β, θ) = p(RX|Y, X, η)pY (Y |X, β)pX(X|θ),
where p(RX) is a multinomial with 2q cells. To deﬁne pX, one needs to
specify the joint distribution of Xi,mis = {X1i, . . . , Xqi}. Suppose the in-
completely observed covariates Xmis = (X1, . . . , Xq) are both continuous
Xmis,C = {X1, . . . , Xr} and categorical Xmis,D = {Xr+1, . . . , Xq}, with fully
observed covariates denoted Xobs = {Xq+1, . . . , Xp}. Ibrahim et al. (1999)
propose the joint density of Xmis be speciﬁed as a series of conditional distri-
butions, namely
p(X1, . . . , Xq|θ}
= pq(Xq|Xq−1, . . . , X1, θq, Xobs} · · · p2(X2|X1, θ2, Xobs)p1(X1|θ1, Xobs)
though there may be sensitivity to the which of the q! conditioning sequences
is adopted. The completely observed predictors may be used in predicting the
missing covariates. For continous predictors the form of density (e.g., gamma,
normal) can be adapted to whether only positive values are observed. Ibrahim
et al. (1999, 180) suggest one-dimensional or joint distributions for the contin-
uous predictors in the lower stages (p1, p2, etc.), with the higher stages being
models for categorical predictors that are based on the imputed continuous
covariates (e.g., logistic regression models).
Another general scheme for specifying the jont density of Xmis adopts a dif-
ferent strategy by ﬁrst representing the joint density of categorical predictors.
This is the general location model (e.g., Cho and Schenker, 1999)
p(Xmis|θ, Xobs) = p(Xmis,C, Xmis,D|θC, θD, Xobs)
= p(Xmis,C|Xmis,D, θC, Xobs)p(Xmis,D|θD, Xobs),
typically involving a multivariate normal or multivariate Student t distribu-
tion for the continuous predictors, conditional on a given combination of val-
ues of the categorical covariates. For example, means and covariances for the
multivariate normal model could be speciﬁc to each combination of the cat-
egorical predictors. The ﬁrst stage of the joint density for predicting missing

Hierarchical Models for Panel Data
401
categorical covariates p(Xmis,D|θD, Xobs) would be a multinomial distribution,
or possibly loglinear regression, over discrete outcomes, missing and observed.
Possible approaches for modeling the covariate missingness indicators
p(Rji|Yi, Xi, η) under a selection approach include a joint log-linear model
with Xi = (Xi,mis, Xi,obs) as predictors, or equivalently a multinomial model
with all possible classiﬁcations of nonresponse as categories (Schafer, 1997,
Chapter 9). For example, if Xi,mis contains two variables subject to missing-
ness, then there are four possible combinations of values of R1i and R2i for
each subject. The joint density of missingness indicators can be expressed
(Ibrahim et al., 1999) as a series of conditional distributions, namely
p(R1i, . . . , Rqi|η, Xi, Yi}
= p(Rqi|Rq−1,i, . . . R1i, ηq, Xi, Yi) · · · p(R2i|R1i, η2, Xi, Yi)p(R1i|η1, Xi, Yi),
which in practice implies a series of binary regressions. For assessing nonran-
domness in covariate missingness, one allows Pr(R2i = 1|R1i, η2, Xi, Yi) to
depend on predictors Xi that may be subject to missing values, as well as on
earlier Rji in the conditional sequence.
In practice, a multivariate density for a set of continuous variables might
be represented indirectly by a series of regressions, and missing values for
binary or categorical data items modeled or imputed via regressions on other
predictors—see Austin and Escobar (2005) for an illustration of such meth-
ods. Such procedures are related to multivariate imputation procedures for
covariates and possibly responses also (Allison, 2000; Schafer, 1997). Consider
the case where Z and X are predictors, with Z subject to missingness. Schafer
(1997) proposes random regression imputation by initially regressing Z on X
and Y, but using only cases with Z observed, and from this regression forms
point estimates ˆZ for cases with missing data. Let ˆσ be the square root of
the mean square error from the observed data regression, then for subjects
with missing Z, one obtains imputations ˜Z = ˆZ + ˆσU where U is a draw from
a standard normal. For cases with observed Z, one sets ˜Z = Z. One then
carries out a ﬁlled-in data regression of Y on X and ˜Z for all subjects. The
Z-imputation and ﬁlled-in data regressions may be repeated M times. Such a
procedure is, however, not proper in the sense of Rubin (1987).
8.8.4
Pattern mixture models
Pattern mixture models may have a beneﬁt in avoiding intricate modeling
of the missingness indicators. For regular panel data (repeat measures at
ﬁxed intervals for all subjects) subject to missingness only through attri-
tion, a pattern mixture analysis (Little, 1995) might simply involve diﬀer-
entiating regression eﬀects in the Y -model according to discrete drop out
times Ui ∈(2, . . . , T −1), as well as completers with Ui = T. Thus “the
missing-data patterns can be used as grouping variables in the [Y regression]
analysis” (Hedeker and Gibbons, 1997). If there are hm subjects in the M
diﬀerent missingness patterns, with associated proportions φm = hm/n, then

402
Applied Bayesian Hierarchical Methods
the “marginal” or composite parameter (e.g., the regression impact of a pre-
dictor xp) is obtained as a weighted average of the pattern-speciﬁc parameters
βpm, namely βp = M
m=1 φmβpm (Curran et al., 2002). A Bayesian analysis
might involve repeated multinomial sampling of the φm at each MCMC iter-
ation, and monitoring the composite parameters β(r)
p
= M
m=1 φ(r)
m β(r)
pm. Often
the preliminary model for missingness P(R|θR) would be conﬁned to such
multinomial sampling.
For example, in a clinical application, separate intercepts, growth coeﬃ-
cients, and treatment eﬀects would be estimated (in the Y -model) according
to dropout category; the variance or covariance parameters for random eﬀects
may also be diﬀerentiated. In an initial analysis, droput category might just
be binary, diﬀerentiating between completers and dropouts, regardless of the
interval when the dropout occurred. Thus, set Gi = 1 for dropouts and Gi = 2
for completers, and consider a regression model for ﬁxed interval (balanced)
panel data yit with intercept, time, treatment (Tr), and time–treatment in-
teraction (e.g., Hedeker and Gibbons, 1997; Mazumdar et al., 2007). Then a
grouped regression with varying intercepts could take the form:
yit = β1,Gi + β2,Git + β3,GiTri + β4,Gi(t.Tri) + b1i + b2it + eit,
bi ∼N(0, DGi); eit ∼N(0, σ2
Gi).
Curran et al. (2002, 13) allow for an additional autocorrelated error εit
with pattern-speciﬁc covariance matrix RGi.
The conditional linear model (Hogan et al., 2004; Paddock, 2007; Wu and
Bailey, 1989) is a version of the pattern mixture model that may be applied
to continuously recorded longitudinal data (rather than ﬁxed interval panel
data). The impact of missingness on Y involves functions βj(Ui) of possi-
bly continuous dropout times Ui though this reduces to a grouping approach
for ﬁxed intervals; that is, the βj(Ui) become step functions (Hogan et al.,
2004, 856). At their most simple such functions are linear in U, but poly-
nomial functions or nonparametric models (e.g., splines) can be used. In the
preceding example, one might have
yit = β1(Ui) + β2(Ui)t + β3(Ui)Tri + β4(Ui)(t.Tri) + b1i + b2it + eit,
bi ∼N(0, D); eit ∼N(0, σ2),
βj(Ui) = αj0 + αj1Ui,
j = 1, . . . , 4,
and a test for missingness at random is whether the αj1 are zero. Paddock
(2007) applies a Bayesian regression selection approach to coeﬃcients in mod-
els involving quadratic eﬀects of Ui.
Example 8.13. Cocaine Use and Desipramine
These data are used to
compare some of the models for missing data described above, including
common factor and pattern mixture approaches. They are from a trial of
the antidepressant desipramine in cocaine-dependent patients with depressive

Hierarchical Models for Panel Data
403
comorbidity, and relate to ﬁxed interval panel data on 106 patients, with 52 in
the treatment arm, and the remainder given a placebo (Ma et al., 2005). The
responses yit are average dollars per day spent on cocaine use. Only 47 pa-
tients completed the full 12 weeks of observation. Let T ∗
i = 12 for completers,
while for drop-outs let T ∗
i denote the week subsequent to the last week T ∗
i −1
when an observation is obtained. So T ∗
i = 7 if a subject is observed for the
ﬁrst six weeks, but is missing for all the last six weeks.
A plot of the average responses for the two arms (including the baseline)
shows that the treatment group begins with a higher average baseline spending
level, and reduces its cocaine spending more. The Y -model involves predictors
X = {1, Tr, t, Tr.t, B} where B = baseline cocaine spending. So
yit = β1 + β2Tri + β3(t −¯t) + β4Tri(t −¯t) + β5Bi + uit,
where uit ∼N(0, 1/τu). Assessment of desipramine eﬃcacy focuses especially
on the coeﬃcient for treatment–time interaction, Tr.t. N(0, 100) priors are
assumed on the ﬁrst three predictors, but for numeric stability a more infor-
mative N(0, 0.1) prior is assumed for the impact of baseline spend (as large
predictor values are observed). Assessing whether missingness is informative
or not is initially based on a selection approach, with Rit ∼Bern(πit), t =
1, . . . , T ∗
i , and
logit(πit) = γ1 + γ2yit + γ3yi,t−1,
using both yit and yi,t−1 as predictors (Mazumdar et al., 2007).
Posterior estimates (from iterations 1001–10,000 of a two chain run) show
a signiﬁcant positive eﬀect on πit of the lagged outcome yi,t−1, but also an
impact (of borderline signiﬁcance) of the possibly unobserved current outcome
yit, with 95% interval {−0.015, 0.0005}. The coeﬃcient for the treatment–time
interaction in the Y -model is negative, but with an inconclusive 95% credible
interval {−2.4, 0.6). The DIC is 9395 (de = 11) with 8890 for the Y -model
and 505 for the R-model.
An alternative model involves a common factor Fi that depends on Bi =
baseline spend; the mean for Fi omits an intercept for identiﬁability. The
missingess model now involves a lagged response and the common factor,
while the Y likelihood no longer involves baseline spending.12 Thus
Fi ∼N(ηBi, 1),
yit = β1 + β2Tri + β3(t −¯t) + β4Tri(t −¯t) + λFi + uit,
Rit ∼Bern(πit),
t = 1, . . . , T ∗
i ,
logit(πit) = γ1 + γ2yi,t−1 + κFi,
where a N(1, 1) prior is adopted for κ and the prior on λ is constrained to
positive values.
Posterior estimates (from iterations 1001–10,000 of a two chain run) show
the coeﬃcient for treatment–time to be still inconclusive (see Table 8.5), but

404
Applied Bayesian Hierarchical Methods
TABLE 8.5
Cocaine use, common factor model, posterior summary.
Monte
Mean
St. devn.
Carlo SE
2.5%
97.5%
β1
25.1
2.2
0.048
20.8
29.4
β2
2.868
2.865
0.048
−2.718
8.499
β3
−0.255
0.502
0.008
−1.220
0.745
β4
−1.077
0.690
0.010
−2.436
0.273
η
0.964
0.247
0.006
0.488
1.470
γ1
−2.243
0.155
0.002
−2.555
−1.940
γ2
−0.005
0.004
0.000
−0.014
0.002
κ
0.326
0.143
0.003
0.064
0.631
λ
9.3
0.8
0.012
7.7
10.8
with a 95% interval more clearly focused on negative values. The common
factor is a positive function of baseline spend and its impact on πit is posi-
tive; so the chance of a missing value increases with the common factor. The
DIC is reduced to 9213 despite a higher complexity count of 48, with 8683
for the Y -model and 529 for the R-model. While the generating mechanism
for missing data is always unknown, this model describes both the original
observations and missing data indicators more eﬀectively.
Finally, a pattern mixture analysis is applied, distinguishing simply be-
tween noncompleters (Gi = 1) and completers (Gi = 2). The assumed model is
yit = β1,Gi + β2,GiTri + β3,Git + β4,GiTri(t −¯t) + β5,GiBi + bi + eit,
bi ∼N(0, DGi); eit ∼N

0, σ2
Gi

.
The precisions 1/Dj and 1/σ2
j are assumed to follow independent gamma
priors with shape 1 and scale 1.
Convergence is attained by iteration 10,000 in a two chain run of 20,000
iterations, with the last 10,000 showing the dropouts to have higher cocaine
spending (β11 and β12 have respective means 29.2 and 16.8) together with
a signiﬁcantly positive baseline eﬀect, β51, for dropouts, with 95% inter-
val (0.09, 0.29). Completers do not have a signiﬁcant baseline eﬀect, and
their time-treatment eﬀect, namely −1.31 with 95% interval (−2.8, 0.14) is
more precisely estimated than that for droputs, namely −1.64 (−4.0, 0.8).
The pooled estimates for β2 and β4 (pooling over dropout patterns) show
an insigniﬁcant main treatment eﬀect, but β4 is virtually signiﬁcant, with
mean and 95% interval −1.52 (−3.1, 0.07). The DIC for this model is 8576,
with de = 77.1.
Example 8.14. Shared Eﬀect Missingness Model for IMPS (Inpa-
tient Multidimensional Psychiatric Scale) Data
Hedeker and Gibbons
(2006, 297–302) consider a shared latent eﬀect model for these data, relating
to psychiatric morbidity; in particular, item 79 of the IMPS scale is a positive

Hierarchical Models for Panel Data
405
measure of morbidity with values ranging from 0 (normal) to 7 (extremely
ill). The analysis here follows Hedeker and Gibbons (2006) in treating the
outcomes as metric, but adopts a simpler shared eﬀects model. The data in-
volve n = 437 patients with up to Ti = 5 repeat measurements not necessarily
at the same times (in weeks) after the baseline at 0 weeks; most patients
have four measurements. Follow up is terminated after six weeks, with most
patients only measured at weeks ai1 = 0, ai2 = 1, ai3 = 3, and ai4 = 6;
completers are those terminating at six weeks, with all sequences ending in
earlier weeks considered as dropouts. So in a similar way to that used for
discrete time hazards in Chapter 9 (Section 9.5), one may deﬁne event indi-
cators {wij = 0, j = 1, . . . , Ti} for completer subjects whose last week is 6,
and {wij = 0, j = 1, . . . , Ti −1; wiTi = 1} for subjects whose last observation
is before six weeks.
Let Drugi = 1 for the treatment group subjects, with Drugi = 0 otherwise.
Also let Sit = a0.5
it
be the square root of the number of weeks at which the
tth observation of patient i is obtained. The model for the morbidity outcome
then has the form:
yit = β1 + β2Drugi + β3Sit + β4SitDrugi + b1i + b2iSit + uit,
with priors
(b1i, b2i) ∼N([0, 0], D); D−1 ∼Wish(I, 2),
uit ∼N(0, 1/τu); τu ∼Ga(1, 0.001).
The missing data model13 is a complementary log–log regression, sharing
the random intercept b1i and with an interaction between treatment and the
shared eﬀect. Thus
log(−log[1 −Pr(wij = 1|Ti ≥j)]) = γ1j + γ2Drugi + α1b1i + α2b1iDrugi,
with {γ1j ∼N(0, 1000), j = 1, max(Ti)}, γ2 ∼N(0, 1000), and {αk ∼
N(1, 1), k = 1, 2}. Nonignorable missingness corresponds to any of the αk
coeﬃcients being distinct from zero (Hedeker and Gibbons, 2006, 298).
A two chain run of 5000 iterations shows early convergence, and posterior
means on β coeﬃcients (from the last 2500 iterations) similar to those reported
by Hedeker and Gibbons (2006). In particular β4 has mean (sd) of −0.65 (0.08)
consistent with a greater reduction in morbidity for the treatment group.
Dropout is lower for treated patients with γ2 having mean (sd) of −0.75
(0.22). Both the α coeﬃcients have 95% credible intervals excluding zero, and
so can be said to be “signiﬁcant”: α1 has mean and 95% interval 0.86 (0.22, 1.5)
indicating that (in general) more ill patients are likely to dropout, while α2
has mean and 95% interval −1.4 (−2.1, −0.7), showing that for those being
treated, the more ill are in fact less likely to dropout.

406
Applied Bayesian Hierarchical Methods
Appendix: Computational Notes
1. For the random eﬀects selection Example 8.1, the code is
model { for (i in 1:500) { for (t in 1:5) {
y[i,t] ∼dnorm(mu[i,t],tau); z1[i,t] <-1; z2[i,t] <- t; z3[i,t] <- x[i,t]
mu[i,t] <- B[1]+B[2]*t+B[3]*x[i,t]
+zeta[i,1]*(z1[i,t]*G[1,1]+z2[i,t]*G[2,1]+z3[i,t]*G[3,1])
+zeta[i,2]*(z2[i,t]*G[2,2]+z3[i,t]*G[3,2])+zeta[i,3]*(z3[i,t]*G[3,3])}
for (k in 1:3) {zeta[i,k]∼dnorm(0,1)}}
G[1,2] <- 0; G[1,3] <- 0; G[2,3] <- 0
for (p in 1:Q) { sigb[p] <- sqrt(D[p,p])
for (q in 1:Q) {D[p,q] <- sum(G.s[p,q,])
for (r in 1:Q) {G.s[p,q,r] <- G[p,r]*G[q,r]}}}
tau∼dgamma(1,0.001); sig2 <- 1/tau
for (k in 1:Q) {B[k]∼dnorm(0,0.01); c[k,k]∼dgamma(a[k],b[k]);
G[k,k] <- c[k,k]*gam[k,k]; gam[k,k]∼dbern(pi[k,k]); pi[k,k]∼dbeta(1,1)
for (m in 1:k-1){c[k,m]∼dnorm(0,1);G[k,m] <- c[k,m]*gam[k,m]
gam[k,m]∼dbern(pi[k,m]);pi[k,m]∼dbeta(1,1)}}}
The code for the Chen–Dunson method replaces the last four lines by
for (k in 1:Q) {B[k]∼dnorm(0,0.01); lam[k]∼dgamma(a[k],b[k]);
gam[k,k]∼dbern(0.5); omeg[k,k] <- 1; G[k,k] <- lam[k]*gam[k,k]
for (m in k+1:Q){omeg[k,m]<- 0; gam[k,m]<- 0; G[k,m] <- 0}
for (m in 1:k-1) {omeg[k,m]∼dnorm(0,2); gam[k,m]∼dbern(0.5)
G[k,m] <- lam[k]*omeg[k,m]*gam[k,k]*gam[m,m]*gam[k,m]}}}.
2. The central code for the regression approach to covariance matrix spec-
iﬁcation (Example 8.2) is
model { for (i in 1:n) { for (t in 1:T) {y[i,t] ∼dnorm(nu[i,t],inv.d[i,t]);
log(d[i,t]) <- gam[1]+gam[2]*t+gam[3]*t*t; inv.d[i,t] <- 1/d[i,t]
mu[i,t] <- beta[1]+beta[2]*t+beta[3]*t*t+beta[4]*t*t*t}
nu[i,1] <- mu[i,1]
for (t in 2:T) {nu[i,t] <- mu[i,t]+sum(F[i,t,1:t-1])
for (j in 1:t-1) {ph[i,t,j] <- lam[1]+lam[2]*(t-j)+lam[3]*(t-j)*(t-j)
F[i,t,j] <- ph[i,t,j]*(y[i,j]-mu[i,j])}}}
for (j in 1:3) {lam[j] ∼dnorm(0,0.001); gam[j] ∼dnorm(0,0.001)}
for (j in 1:4) {beta[j] ∼dnorm(0,0.001)}}
3. The response data input in this example is in stacked form with 5400
rows, with each row containing ﬁrm identiﬁer, time identiﬁer and the return
yit. Diﬀerencing the regression means as in Equation 8.6, and taking 1/σ2
ν ∼
G(1, 0.001), leads to code for Model 2 as follows:
model { for (i in 1:5400) { y[id[i],time[i]] <- Y[i]}
for (i in 1:n) { b[i,1:2] ∼dmnorm(B[1:2],D.inv[1:2,1:2])

Hierarchical Models for Panel Data
407
for (t in 1:T) {mu[i,t] <- b[i,1]+b[i,2]*x[t]}
y[i,1] ∼dnorm(mu[i,1],tau1);
for (t in 2:T) {y[i,t] ∼dnorm(nu[i,t],tau)
nu[i,t] <- mu[i,t]-rho*mu[i,t-1]+rho*y[i,t-1]}}
# Priors
for (j in 1:2) {B[j] ∼dnorm(0,0.001);
for (k in 1:2) {Wsc[j,k] <- 4*equals(j,k);
C[j,k] <- D[j,k]/sqrt(D[j,j]*D[k,k])}}
D.inv[1:2,1:2] ∼dwish(Wsc[,],4); D[1:2,1:2] <- inverse(D.inv[,])
tau ∼dgamma(1,0.001); rho ∼dunif(-1,1); tau1<- (1-rho*rho)*tau}
4. Assume stacked household-repetition (i.e., purchase level) data with N =
2412 observations, and binary indicators {Di1, Di2, . . . , DiK} for each obser-
vation with Dik = 1 if the kth brand is chosen. The data for each observation
contains the J feature and price attributes relevant to each purchase. Then a
model with ﬁxed eﬀects only and the ﬁnal category as the reference, and with
KM = K −1 is coded as
model {for (i in 1:N) {for (k in 1:K) {pi[i,k] <- ph[i,k] / sum(ph[i,])
d[hh[i],rep[i],1:K] ∼dmulti( pi[i,1:K] , 1 )
d[hh[i],rep[i],k] <- D[i,k]; LL[i,k] <- d[hh[i],rep[i],k]*log(pi[i,k]);
log(ph[i,k]) <- alph[k] + del[1]*feature[i,k]+ del[2]*price[i,k]}}
# priors
alph[K] <- 0; for (k in 1:KM) {alph[k] ∼dnorm(0,Pr)}
for (k in 1:2) {del[k] ∼dnorm(0,Pr)}}
where Pr is a known (low) precision, e.g., Pr = 0.0001. Introducing subject
speciﬁc-random eﬀects (which are also necessarily choice speciﬁc) leads to the
code
model {for (i in 1:n) {alph[i,K] <- 0;
alph[i,1:KM] ∼dmnorm(mu.alph[],invD[1:KM,1:KM])}
for (i in 1:N) {for (k in 1:K) {pi[i,k] <- ph[i,k] / sum(ph[i,])
d[hh[i],rep[i],1:K] ∼dmulti( pi[i,1:K] , 1 ); d[hh[i],rep[i],k] <- D[i,k];
LL[i,k] <- d[hh[i],rep[i],k]*log(pi[i,k]);
log(ph[i,k]) <- alph[hh[i],k] + del[1]*feature[i,k]+ del[2]*price[i,k]}}
# priors
for (k in 1:2) {del[k] ∼dnorm(0,Pr)}
invD[1:KM,1:KM] ∼dwish(ScD[,],KM)
for (k1 in 1:KM) {mu.alph[k1] ∼dnorm(0,Pr)
for (k2 in 1:KM) {ScD[k1,k2] <- equals(k1,k2)}}}
5. The code in Example 8.5 is
model { for (i in 1:N) {y[id[i],time[i]] <- Rank[i]
Z[id[i],time[i]] <- sqrt(Week[i])}
P.slope.tr <- step(av.slope.tr[1]-av.slope.tr[2])
for (j in 1:2) {av.slope.tr[j] <- sum(slope.tr[j,1:n])/tot.tr[j]}

408
Applied Bayesian Hierarchical Methods
for (i in 1:n) {b[i,1:2] ∼dmnorm(eta[1:2],InvD[,])
slope.tr[1,i] <- b[i,2]*equals(Tr[i],1); slope.tr[2,i] <- b[i,2]*equals(Tr[i],0);
for (t in 1:T) { mu[i,t] <- b[i,1]+b[i,2]*Z[i,t]+beta[1]*Tr[i]+ beta[2]*Tr[i]
*Z[i,t]+beta[3]*Gend[i]
for (j in 1:C-1) { d[i,t,j] <- step(j-y[i,t]); nu[i,t,j] <- kap[j]-mu[i,t]
# truncated sampling for latent scale
wstar[i,t,j] ∼dnorm(nu[i,t,j],1) I(A[i,t,j],B[i,t,j])
A[i,t,j] <- -10*equals(d[i,t,j],0); B[i,t,j] <- 10*equals(d[i,t,j],1)}}}
# thresholds for latent variable
kap[1] <- 0
for (k in 2:CM){ kap[k] <- kap[k-1]+del[k]; del[k] ∼dgamma(1,1)}
# permanent eﬀects prec’n matrix
InvD[1:2,1:2] ∼dwish(Q.b[,],2); D[1:2,1:2] <- inverse(InvD[,])
for (i in 1:2) { eta[i] ∼dnorm(0,0.01); sig[i] <- sqrt(D[i,i])
for (j in 1:2) {corr.b[i,j] <- D[i,j] / (sig[i]*sig[j])}}
Q.b[1,1] <- 1; Q.b[2,2] <- 1; Q.b[2,1] <- 0; Q.b[1,2] <- 0
# covariate eﬀects
for (j in 1:3) {beta[j] ∼dnorm(0,0.01)}}
6. The code for the second analysis in Example 8.6 is
model {for (i in 1:2849) {y[id[i],time[i]] <- log.earnings[i]}
for (i in 1:416) {b[i] ∼dnorm(beta[1],invD)
P1[i] <- sum(p1[i,2:T[i]]); P2[i] <- sum(p2[i,2:T[i]])
w1[i] <- college[i]; w2[i]<- equals(eth[i],1)
y[i,1] ∼dnorm(mu[i,1],tau1);
# regression for t=1
mu[i,1] <- beta1.1+gam1[1]*w1[i]+gam1[2]*w2[i]+gam1[3]*w1[i]*w2[i]
for (t in 1:T[i]) { e[i,t] <- y[i,t]-mu[i,t]; p2[i,t] <- pow(e[i,t],2)
LL[i,t] <- 0.5*log(tau/6.28)-0.5*tau*pow(y[i,t]-mu[i,t],2)
H[i,t] <- 1/exp(LL[i,t])}
for (t in 2:T[i]) {y[i,t] ∼dnorm(mu[i,t],tau);
# elements for testing autocorrelation
p1[i,t] <- e[i,t]*e[i,t-1]
# regression for t>1
mu[i,t] <- ph*y[i,t-1]+gam[1]*w1[i]+gam[2]*w2[i]+gam[3]*w1[i]*w2[i]+b[i]}}
ph ∼dnorm(0,1); sig ∼dunif(0,10); sig1∼dunif(0,10);
tau <- 1/(sig*sig); tau1 <- 1/(sig1*sig1);
sqrtD ∼dunif(0,10); invD <- 1/(sqrtD*sqrtD)
beta[1] ∼dnorm(0,0.001);beta1.1 ∼dnorm(0,0.001);
for (j in 1:3) {gam[j] ∼dnorm(0,0.001); gam1[j] ∼dnorm(0,0.001)}
ARerr <- sum(P1[])/sum(P2[]); test.ARerr <- step(ARerr)}
7. The code for the ﬁrst analysis in Example 8.7 is
model {for (i in 1:n) {for (t in 1:T) {y[i,t] ∼dpois(mu[i,t])
ynew[i,t] ∼dpois(mu[i,t])

Hierarchical Models for Panel Data
409
LL[i,t] <- -mu[i,t]+y[i,t]*log(mu[i,t])-logfact(y[i,t]); G[i,t] <- 1/exp(LL[i,t])
dv[i,t] <- y[i,t]*log((y[i,t]+0.5)/(mu[i,t]+0.5)) -(y[i,t]-mu[i,t])}}
for (i in 1:n) {b[i,1:2] ∼dmnorm(zero[1:2],invD[1:2,1:2])
Age[i] <- age[i]-mean(age[]))
log(mu[i,1]) <- beta1[1]+beta1[2]*Age[i]+b[i,1]
for (t in 2:T) {log(mu[i,t]) <- beta[1]+beta[2]*Age[i]+beta[3]*Trt[i]+ph
*y[i,t-1]+b[i,2]}}
for (j in 1:3) {beta[j] ∼dnorm(0,0.1)}
for (j in 1:2) {beta1[j] ∼dnorm(0,0.1)}
Fit[1] <- 2*sum(dv[,]); Fit[2] <- -2*sum(LL[,])
invD[1:2,1:2] ∼dwish(Q[,],2); D[1:2,1:2] <- inverse(invD[,])
sigb <- sqrt(D[2,2]); rh <- D[1,2]/sqrt(D[1,1]*D[2,2]); ph ∼dnorm(0,0.1)}
8. The code for the second analysis in Example 8.8 is
model { for (i in 1:N) { y[i] ∼dnorm(mu[i], tau.pow[i]) I(0,)
LL[i] <- 0.5*(log(tau.pow[i]/6.28)-tau.pow[i]*pow(y[i]-mu[i],2))
tau.pow[i] <- tau/pow(mu[i],kap)
mu[i] <- dose[i] *exp(-beta[subj[i]] * time[i]/alpha[subj[i]])/alpha[subj[i]]}
for (i in 1:n) {mu.new[i] <- 30 *exp(- beta[i] * 32/alpha[i])/alpha[i]
tau.pow.new[i] <- tau/pow(mu.new[i],kap)
lamb[i] ∼dgamma(nub.2,nub.2)
ynew[i] ∼dnorm(mu.new[i], tau.pow.new[i]) I(0,)
alpha[i] <- exp(b[i,1]) ; beta[i] <- exp(b[i,2]) ;
for (k1 in 1:2) { for (k2 in 1:2) {
InvDsc[i,k1,k2] <- lamb[i]*Inv.D[k1,k2]}}
b[i,1:2] ∼dmnorm(mu.b[1:2], InvDsc[i,1:2, 1:2]) }
mu.b[1:2] ∼dmnorm(eta[1:2], Inv.C[1:2, 1:2])
Inv.D[1:2, 1:2] ∼dwish(R[1:2, 1:2], 2)
VOLpop <- exp(eta[1]) ; CLRpop <- exp(eta[2]) ;
D[1:2,1:2] <- inverse(Inv.D[1:2, 1:2])
nub.2 <- nub/2; nub <- 1/inv.nub; inv.nub ∼dunif(0.01,0.5)
kap ∼dlnorm(0,1); tau ∼dgamma(1,0.001)}
9. The code for the second analysis in Example 8.9 is
model { for (i in 1:N) {y[Subj[i],rep[i]] <- chol[i]/100
years[Subj[i],rep[i]] <- yr[i]}
for (i in 1:n) {b[i,1:2] ∼dmnorm(nought[1:2],invD[1:2,1:2])
age[i] <- ag[i]-mean(ag[])
tLL[i] <- sum(LL[i,1:T[i]])
for (t in 1:T[i]) {y[i,t] ∼dnorm(mu[i,t],tau)
LL[i,t] <- 0.5*log(tau/6.28)-0.5*tau*pow(y[i,t]-mu[i,t],2)
G[i,t] <- 1/exp(LL[i,t])
a[i,t] <- (years[i,t]-5)/10; w[i,t] ∼dnorm(0,1) I(0,)
mu[i,t] <- beta[1]+beta[2]*sx[i]+beta[3]*age[i]
+beta[4]*a[i,t]+b[i,1]+b[i,2]*a[i,t] +del[t]*w[i,t]}}

410
Applied Bayesian Hierarchical Methods
for (j in 1:4) {beta[j] ∼dnorm(0,0.01)}
for (j in 1:6) {del[j] ∼dnorm(0,0.01)}
sig ∼dunif(0,10); s2 <- sig*sig; tau <- 1/s2
TLL <- sum(tLL[])
D[1:2,1:2] <- inverse(invD[,]); invD[1:2,1:2] ∼dwish(ScD[,],2)}
10. The code for the fourth analysis in Example 8.10 is
model {for (i in 1:n) {bh[i]∼dnorm(beta[1],invD);
b[i] <- bh[i]-beta[1];
# selection indicators for random eﬀects u[i,t]
delu[i] ∼dbern(0.1)
ln.base[i] <- log(y0[i]/4); ln.age[i] <- log(age[i])
Base[i] <- ln.base[i]-mean(ln.base[]); Age[i] <- ln.age[i]-mean(ln.age[])
for (t in 1:T) {y[i,t] ∼dpois(mu[i,t]);ynew[i,t] ∼dpois(mu[i,t])
u[i,t] ∼dnorm(0,tau2u)
LL[i,t] <- -mu[i,t]+y[i,t]*log(mu[i,t])-logfact(y[i,t]); H[i,t] <- 1/exp(LL[i,t])
dev[i,t] <- y[i,t]*log((y[i,t]+0.5)/(mu[i,t]+0.5)) -(y[i,t]-mu[i,t]);
# regression
log(mu[i,t]) <- bh[i]+beta[2]*Base[i]+beta[3]*Trt[i]+
beta[4]*Base[i]*Trt[i]+beta[5]*Age[i]+beta[6]*V4[t]+delu[i]*u[i,t]}}
for (j in 1:6) {beta[j] ∼dﬂat()}
Fit[1] <- 2*sum(dev[,]); Fit[2] <- -2*sum(LL[,])
sqrtD ∼dunif(0,100); D <- sqrtD*sqrtD; invD <- 1/D;
sig2u <- (D-v*D)/v; tau2u <- 1/sig2u; v ∼dunif(0,1)}
The MDP code (ﬁfth analysis) is
model {for (i in 1 : n) { ln.base[i] <- log(y0[i]/4); ln.age[i] <- log(age[i])
Base[i] <- ln.base[i]-mean(ln.base[]); Age[i] <- ln.age[i]-mean(ln.age[])
for( t in 1 : T) { y[i, t] ∼dpois(mu[i, t])
log(mu[i, t]) <- b[1,i]+beta[1]*Base[i]
+beta[2]*Trt[i]+beta[3]*Base[i]*Trt[i]+beta[4]*Age[i]+b[2,i]*Visit[t]
LL[i,t] <- -mu[i,t]+y[i,t]*log(mu[i,t])-logfact(y[i,t]);
dev[i,t] <- y[i,t]*log((y[i,t]+0.5)/(mu[i,t]+0.5)) -(y[i,t]-mu[i,t])}}
Fit[1] <- 2*sum(dev[,]); Fit[2] <- -2*sum(LL[,])
# select cluster
for (i in 1:n) { S[i] ∼dcat(p[1:Km])
for (k in 1:Km) {Sr[i,k] <- equals(k,S[i])}
# realized heterogeneity
for (j in 1:2) {b[j,i] <- bstar[S[i],j]}}
alpha ∼dgamma(2,4); V[Km] <- 1; p[1] <- V[1]
for (k in 1:Km-1){V[k] ∼dbeta(1,alpha)}
for (k in 2:Km) { p[k] <- V[k]*(1-V[k-1])*p[k-1]/V[k-1]}
# Base Density
for (k in 1:Km) { bstar[k,1:2] ∼dmnorm(B[], invD[,])
# total non-empty clusters
clusn[k] <- sum(Sr[,k]); nonempty[k] <- step(clusn[k]-1)}

Hierarchical Models for Panel Data
411
K <- sum(nonempty[])
# priors:
invD[1:2,1:2] ∼dwish(R[ , ], 10); D[1:2,1:2] <- inverse(invD[,])
for (j in 1:2) {B[j] ∼dnorm(0,0.001)}
for (j in 1:4) {beta[j] ∼dnorm(0,0.001)}}
11. The code in Example 8.11 is
model { for (i in 1:437) {y[i] ∼dnorm(mu2[Group[i],PatGroup[i],Visit[i]],
tauy[Group[i]])
x[i] ∼dnorm(mu1[Group[i],PatGroup[i],Visit[i]],taux[Group[i]])}
# Models for each of J=4 clusters
for (i in 1:n[1]) { b[1,i] ∼dnorm(B[1],invD1[1]);c[1,i] ∼dnorm(0,invD2[1])
for (t in 1:nvis1[i]) {
mu1[1,i,t] <- b[1,i]; mu2[1,i,t] <- alph[1]+lam[1]*b[1,i]+c[1,i]}}
for (i in 1:n[2]) { b[2,i] ∼dnorm(B[2],invD1[2]);c[2,i] ∼dnorm(0,invD2[2])
for (t in 1:nvis2[i]) {
mu1[2,i,t] <- b[2,i]; mu2[2,i,t] <- alph[2]+lam[2]*b[2,i]+c[2,i]}}
for (i in 1:n[3]) {b[3,i] ∼dnorm(B[3],invD1[3]);c[3,i] ∼dnorm(0,invD2[3])
for (t in 1:nvis3[i]) {
mu1[3,i,t] <- b[3,i]; mu2[3,i,t] <- alph[3]+lam[3]*b[3,i]+c[3,i]}}
for (i in 1:n[4]) {b[4,i] ∼dnorm(B[4],invD1[4]);c[4,i] ∼dnorm(0,invD2[4])
for (t in 1:nvis4[i]) {
mu1[4,i,t] <- b[4,i]; mu2[4,i,t] <- alph[4]+lam[4]*b[4,i]+c[4,i]}}
# Priors
for (j in 1:J) {tauy[j] ∼dgamma(1,1); taux[j] ∼dgamma(1,1); invD2[j]
∼dgamma(1,1);
invD1[j] ∼dgamma(1,1); B[j] ∼dnorm(0,0.001); alph[j] ∼dnorm(0,0.001);
lam[j] ∼dnorm(0,0.001)}}
12. For the cocaine-use data the second missingness (common factor) model
has code
model { for (i in 1:106) {F[i]∼dnorm(mu.F[i],1); mu.F[i] <- eta*basey[i]/100
for (t in 1:Tstar[i]) {y[i,t]∼dnorm(mu[i,t],tau) I(0,)
mu[i,t] <- beta[1]+beta[2]*Trt[i]+beta[3]*(t-6)+beta[4]*Trt[i]*(t-6)+lam*F[i]}
for (t in 2:Tstar[i]) {R[i,t]∼dbern(p[i,t])
logit(p[i,t]) <- gam[1]+gam[2]*y[i,t-1]+kap*F[i]}}
tau∼dgamma(1,0.001); lam∼dnorm(1,1) I(0,);kap∼dnorm(1,1)
eta∼dnorm(0,0.01); beta[1]∼dnorm(20,0.001);
for (j in 2:4) {beta[j]∼dnorm(0,0.01)}
for (j in 1:2) {gam[j]∼dnorm(0,1)}}
13. The code for the model in Example 8.14 is
model {# response data in stacked form
for (i in 1:N) {y[i]∼dnorm(mu[subj[i],rep[i]],tau); S[subj[i],rep[i]] <-
sqrt(week[i])}

412
Applied Bayesian Hierarchical Methods
for (i in 1:n) {b[i,1:2]∼dmnorm(nought[],D.inv[,])
# model means for nested data form
for (t in 1:T[i]) {mu[i,t] <- beta[1]+beta[2]*drug[i]+beta[3]*S[i,t]
+beta[4]*drug[i]*S[i,t]+b[i,1]+b[i,2]*S[i,t]
w[i,t]∼dbern(p[i,t])
# equivalent cloglog forms
p[i,t] <- 1-exp(-exp(eta[i,t]))
# cloglog(p[i,t]) <- eta[i,t]
eta[i,t] <- gam1[t]+gam2*drug[i]+alph[1]*b[i,1]+alph[2]*b[i,1]*drug[i]}}
# set up missingness indicators
for (i in 1:n) {w[i,T[i]] <- 1-step(Lastweek[i]-6)
for (t in 1:T[i]-1) {w[i,t] <- 0}}
# Priors
for (j in 1:4) {beta[j]∼dnorm(0,0.001); gam1[j]∼dnorm(0,0.001)}
gam1[5] <- gam1[4]; gam2∼dnorm(0,0.001)
for (j in 1:2) { alph[j]∼dnorm(1,1)}
tau∼dgamma(1,0.001); D.inv[1:2,1:2]∼dwish(Sc[,],2)}

9
Survival and Event History Models
9.1
Introduction
In many applications in the health and social sciences the response of interest
is duration to a certain event, such as age at ﬁrst maternity, survival time
after diagnosis, or times spent in diﬀerent jobs or places of residence. In clin-
ical applications the interest is typically in representing and comparing the
distribution of times to an event among diﬀerent patient groups (e.g., treat-
ment vs. control groups), whereas in social science applications the interest
may focus on the impacts of demographic or socioeconomic attributes on
human behaviors. Typically durations or event times are not observed for all
subjects, either because not all subjects are followed up, or because for some
events the event may never occur (e.g., age at ﬁrst marriage). So some times
are missing or censored, and the missingness mechanism is generally assumed
to be at random. The most common form is right-censoring, when the event
has not occurred by the end of the observation period; the unknown failure
time exceeds the subject’s survival time c when observation ceased. A failure
time is left censored at c if its unobserved actual value is less than c (e.g., a
population census may record limiting illness status by current age, but not
the age when it commenced). A failure time is interval censored if it is known
only that it lies in the interval (c1, c2).
Distributions of durations or survival times are equivalently described by
hazard rates, also known as failure rates, exit rates, or forces of mortality
according to the application. The modeling of the hazard rate through time
may be undertaken parametrically. Alternatively, one may adopt nonpara-
metric methods, such as assuming piecewise constancy in the rates within
subintervals of the observation span (Ibrahim et al., 2001). Pooling strength
through correlated priors is then relevant as rates in successive intervals tend
to be similar. Imposing smoothness conditions on the baseline hazard also pro-
vides stable estimators when observations are sparse at particular durations
(Omori, 2003).
Variations in failure rates between subjects or other units may be explained
to a large degree by observed characteristics, the impact of which may also
vary over intervals or time. However, unobserved random variations between
subjects are present in many applications and may be modeled by introduc-
ing subject level frailty (see Section 9.4). Additionally duration times may be
413

414
Applied Bayesian Hierarchical Methods
hierarchically stratiﬁed (e.g., patient survival by hospital or by area of resi-
dence), or they may be diﬀerentiated by types of possible exit, as in competing
risk analysis (see Sections 9.6 and 9.7). One may also consider multivariate sur-
vival outcomes, as in multiple component failure (Damien and Muller, 1998)
or in familial survival studies (Viswanathan and Manatunga, 2001). In such
situations, shared frailty models may account for correlated unobserved vari-
ation over diﬀerent strata or causes of exit.
9.2
Survival Analysis in Continous Time
Let T denote a survival time. The distribution function of T, providing the
probability of exit before time T = t, is then
F(t) = Pr(T ≤t),
while the probability of surviving beyond t is S(t) = 1 −F(t) = Pr(T > t).
Note that one has S(∞) = 0. So the density of T can be expressed as
f(t) = dF(t)
dt
= −dS(t)
dt
.
The chance of an event occurring in a short interval (t, t+dt), given survival
to t, is
Pr(t < T ≤t + dt|T > t) = Pr(t < T ≤t + dt)
Pr(T > t)
= F(t + dt) −F(t)
S(t)
.
The hazard function h(t) is the instantaneous event rate, obtained as
dt →0 in the ratio of the preceding probability to the length of the inter-
val dt. That is
h(t) = lim
dt→0
F(t + dt) −F(t)
dt
1
S(t) = lim
dt→0
S(t) −S(t + dt)
dt
1
S(t) = f(t)
S(t).
Since −f(t) is the derivative of S(t), one obtains that h(t) = (−S′(t)/S(t)),
and so
h(t) = −d log S(t)
dt
.
(9.1)
On integrating both sides in Equation 9.1, one obtains the cumulative hazard
rate
H(t) =
 t
0
h(u)du =
 t
0
−d log S(u)
du

du
= −
 −log S(t)
0
d log S(u) = −log S(t)

Survival and Event History Models
415
and so
S(t) = exp[−H(t)] = exp

−
 t
0
h(u)du

.
If predictors Zi are available their impact is most simply modeled using a
proportional hazards form (e.g., Cox, 1972; Kiefer, 1988; Li, 2007):
h(t|Z) = h0(t) exp(Ziβ),
where h0(t) is known as the baseline hazard and the regression impact is
constant across time. Letting ηi = Ziβ, the associated survivor function is
S(t|Zi) = exp

−
 t
0
h(u|Zi)du

= exp[−H0(t)eηi] = [S0(t)]exp(ηi)
= exp{−exp[ηi + log H0(t)]},
where H0(t) is the integrated baseline hazard. The proportional hazard
assumption is often restrictive, though Yin and Ibrahim (2006) show the
proportional hazard model (PHM) may be nested in a broader class of trans-
formation hazard models, with parameter 0 ≤γ ≤1 and
h(t|Z) = [h0(t)γ + exp(Ziβ)]1/γ
which reduces to the proportional model when γ = 0 and to an additive model
when γ = 1.
Consider an absorbing (nonrepeatable) type of exit, and let di = 1 for
an observed exit and di = 0 for a censored time. Assuming censoring is non-
informative, the likelihood contribution for subject i is
f(ti|Zi) = h(ti|Zi)S(ti|Zi)
if di = 1, and S(ti|Zi) if di = 0. The likelihood contribution may be expressed
in equivalent forms as
h(ti|Zi)diSi(ti|Zi) = f(ti|Zi)diSi(ti|Zi)1−di.
For a PHM the likelihood contribution also may be written (Aitkin and
Clayton, 1980; Orbe and Nunez-Anton, 2006) as
[h0(ti) exp{Ziβ −H0(ti) exp(Ziβ)}]di[exp{−H0(ti) exp(Ziβ)}]1−di
=

µdi
i e−µi 
 h0(ti)
H0(ti)
di
,
(9.2)
where
µi = H0(ti) exp(Ziβ)
(9.3)

416
Applied Bayesian Hierarchical Methods
and the second bracketed term in Equation 9.2 depends only on the baseline
hazard and is independent of β. The ﬁrst term in Equation 9.2 is the kernel
of a Poisson likelihood for the event status indicators di ∼Po(µi). From
Equation 9.3, the corresponding log-linear model is
log(µi) = log(H0(ti)) + Ziβ,
(9.4)
where log(H0(ti)) is an oﬀset using the observed time, whether censored or
uncensored.
9.2.1
Counting process functions
For repeated events in continuous time, especially with successive durations
not necessarily independent, it is advantageous to use additional functions.
The count of failures N(t) occurring over (0, t] for a given individual or com-
ponent system deﬁnes a counting process satisfying N(s) ≤N(t) for s < t.
For a nonrepeatable event the counting process may still be useful (e.g., in
modeling time varying predictors), and one may denote N(t) = I(T ≤t),
namely by an indicator of whether the event has occurred by t.
For all event types considered over suﬃciently small intervals, the counting
process increments dN(t) = N(t) −N(t−) are either 1 or 0, where N(t−)
denotes limδ↓0N(t−δ) (Manda et al., 2005). Let A(t−) denote the antecedent
history of the event sequence up to but not including t. Then conditional on
A(t−), the probability that dN(t) = 1 can be written in terms of an intensity
process λ(t), namely,
Pr{N(t + δ) −N(t−) = 1|A(t−)} ⋍λ(t)δ.
Equivalently
Pr{dN(t) = 1|A(t−)} ⋍dΛ(t),
where Λ(t) =
	 t
0 λ(u) du is the integrated intensity, with Λ(t) = E(N(t)).
The intensity is equal to the hazard while the subject or system is still
under observation, that is still at risk, but is zero when the event has happened
(when the event is nonrepeatable), or when a sequence of (repeatable) events
has ﬁnished. An example of the latter might be when a repairable system
subject to repeated breakdowns is ﬁnally decommissioned—see Watson et al.
(2002) for a counting process analysis of failure times of water pipes. Let
Y (t) = I(T ≥t) denote the at risk indicator then
λ(t) = Y (t)h(t).
This representation of the intensity function generalizes to include predic-
tors and random eﬀects (or frailties). So for proportional hazards, predictor
eﬀects would be included via
λ(ti|Zi) = Y (ti)h0(ti) exp(Ziβ).

Survival and Event History Models
417
One may then compare observed and predicted counts via the Martingale
residual at t, deﬁned as
Mi(t) = N(ti) −Λ0(ti|Zi) = N(ti) −
 ti
0
Yi(u) exp(Ziβ)dH0(u).
The total residual Mi = Mi(∞) for a subject with observation time ti is
obtainable for a nonrepeatable event as
Mi = di −Λ0(ti|Zi).
Deviance residuals ri are obtained as
ri = sgn(Mi)
9
2

Mi −Ni(∞) log

Ni(∞) −Mi
Ni(∞)

.
9.2.2
Parametric hazards
The hazard rate h(t) is called duration dependent if its value changes over t;
under negative duration dependence (often observed in job or residential
careers), h(t) decreases with time. In practice, plots of survivor proportions
are often jagged with respect to time, and semi- or nonparametric methods
for representing the hazard function reﬂect this. However, parametric lifetime
models are also often applied to test whether certain basic features of duration
dependence are supported by the data.
The simplest parametric model is the exponential model, under which the
leaving rate is constant, deﬁning a stationary process with hazard
h(t) = λ,
survival function S(t|λ) = exp(−λt), and density
f(t|λ) = λ exp(−λt).
With covariates and assuming proportionality h(t|Zi) = λeZiβ. Equiva-
lently under the Poisson likelihood approach of Aitkin and Clayton (1980),
one has di ∼Po(µi) and from Equation 9.4, a log-linear model
log(µi) = log(λti) + Ziβ,
since H0(t) = λt. Absorbing λ into the regression term one has
log(µi) = log(ti) + Ziβ.
This Poisson likelihood device can be used in piecewise exponential models
as considered below.
Another commonly used parametric form is the Weibull with scale param-
eter λ and shape κ, namely
h(t|λ, κ) = λκtκ−1,

418
Applied Bayesian Hierarchical Methods
so that S(t|λ, κ) = exp[−λtκ], and f(t|λ, κ) = λκtκ−1 exp[−λtκ]. The Weibull
hazard rate is monotonic, with positive duration dependence if κ > 1 (and a
95% credible interval excludes 1), and negative dependence if κ < 1.
Since log(S(t|λ, κ)) = −λtκ, one has log(−log(S(t|λ, κ))) = log λ + κ log t.
Therefore a plot of log(−log(S(t|λ, κ))) against log(t) should be approximately
linear when a Weibull is appropriate. An initial assessment can be made us-
ing a Kaplan–Meier estimate of S(t) in the R package. Assume a dataset
named survdat containing variables time (corresponding to ti) and status
(corresponding to di). Then the procedure is
library(survival)
KMinputs <- Surv(survdat$time,survdat$status)
KM <- survﬁt(KMinputs)
plot(log(KM$time), log(-log(KM$surv)), type=“S”).
However, many processes exhibit peaks in exit rates; for example, the rate
may at ﬁrst increase but after reaching a peak tail oﬀagain (Gore et al., 1984;
Shao and Zhou, 2004). Parametric models accommodating such a pattern in-
clude the log-logistic model and the sickle model (Bennett, 1983; Br¨uderl and
Diekmann, 1995; Diekmann and Mitter, 1983). The log-logistic density has
hazard
h(t) = λκt
κ−1[1 + λtκ]−1,
and survivor function
S(t) = [1 + λtκ]−1,
where all parameters are positive, and the scale parameter λ can be adapted
to model the impact of predictors; see Li (1999) for a Bayesian application to
Chapter 11 bankruptcies. An alternative common parameterization (Florens
et al., 1995) sets λ = νκ, so that
h(t) =
νκκtκ−1
[1 + (νt)κ].
(9.5)
The sickle model has corresponding functions
h(t) = ct e−t/λ
S(t) = exp[−λc{λ −(t + λ)e−t/λ}]
with both c and λ positive. The sickle model has a permanent survival proba-
bility or “cure rate” (Chen et al., 1999) in that S(∞) > 0 (see Section 9.2.3).
In general one may deﬁne a cure rate r = 1 −π as the limit as t →∞of the
survivor function, namely (Tsodikov et al., 2003)
r = lim
t→∞S(t) = exp

−
 ∞
0
h(u)du

with π denoting the proportion of susceptibles.

Survival and Event History Models
419
9.2.3
Accelerated hazards
In contrast to the proportional hazard model with h(ti|Zi) = h0(ti) exp(Ziβ)
in an accelerated failure time (AFT) model the explanatory variates are
assumed to act multiplicatively on time (Wei, 1992). So with Bi = exp(Ziβ),
one has
h(ti|Zi) = h0(tiBi)Bi,
S(ti|Zi) = [S0(tBi)]Bi
and the eﬀect of the predictors Zi on survival time is more direct, acting
to accelerate or decelerate the time to failure. To illustrate this in the case
of a treatment comparison, assume Zi excludes an intercept and that the
baseline hazard includes a scale parameter to model the mean hazard (e.g.,
the parameter λ in exponential and Weibull models). Also assume a single
predictor such as zi = 1 for a new treatment and zi = 0 for control. Then
with Bi = eβzi = eβ(= φ) for a treated subject, one has a hazard φh0(φti) and
survivor function S(φti) for such a subject, but a hazard h0(ti) and survivor
function S(ti) for a control subject. So the lifetime under the new treatment
is φ times the lifetime under the control regime.
More inclusive schemes are possible. For example, deﬁning Gi = exp(Ziγ),
one has
h(ti|Zi) = h0(tiGi)Bi,
which includes the AFT and PHM forms as special cases (Chen and Jewell,
2001). For example, for the log-logistic this would imply
h(ti|Zi) = Biλκ(tiGi)
κ−1[1 + Biλ(tGi)κ]−1.
Apart from avoiding the assumption of proportional hazards, the AFT
approach has the advantage of a direct regression form which may be useful
in modeling nonlinear eﬀects of predictors (Orbe and Nunez-Anton, 2006).
Let Zi be of dimension p and Ti denote the completed failure time which for
censored subjects is unobserved. Then Ti = ti when di = 1 but Ti > ti when
di = 0, so truncated sampling with the censored time as the lower limit is
necessary.1 The regression formulation is then
log(ti) = Ziγ + σui,
where σ is a scale parameter, and the errors are deﬁned by the survivor func-
tion, namely
S(ti) = Pr(Ti > ti) = Pr(log(Ti) > log(ti))
= Pr

ui > log(ti) −γ0 −γ1z1i −· · · −γpzpi
σ

.
A positive γj coeﬃcient means that zj leads to longer survival or length
of stay.

420
Applied Bayesian Hierarchical Methods
Taking u to be standard normal with variance 1 corresponds to a log-
normal density for failure times ti, under which
S(ti) = 1 −Φ

log(ti) −γZi
σ

.
Taking u to be standard logistic with density p(u) = eu/(1 + eu)2 corre-
sponds to a log-logistic failure time density with
S(ti) =

1 + exp
*log(ti) −γZi
σ
+−1
with σ corresponding to the inverse of the shape parameter κ. Finally, consider
a Weibull density for failure times with hazard h(ti|Zi) = λκtκ−1
i
exp(βZi)
where Zi excludes a constant term. Taking u to follow a standard extreme
value density, namely p(u) = exp(u −eu), the AFT regression takes the form
(Keiding et al., 1997):
log(ti) = −log λ
κ
−z1i
β1
κ · · · −zpi
βp
κ + ui
κ .
Example 9.1. Nursing Home Stays
Morris et al. (1994) analyze lengths
of stay ti for n = 1601 nursing home patients, with stay usually terminated by
death. There are 322 censored lengths of stay. Predictor eﬀects are assessed
via a proportional Weibull hazard,
h(t|λi, κ) = λiκtκ−1
i
,
λi = exp(Ziβ).
This is equivalent to accelerated hazards regression for logged length of stay
with error ui
log(ti) = γZ + σui,
where γ = −βσ and σ = 1/κ. The γ coeﬃcients2 express inﬂuences on length
of stay (i.e., survival) while the β coeﬃcients express inﬂuences on mortality.
Parameter estimates (Table 9.1) for the treatment and attribute variables
replicate those of Morris et al. (1994), with the age covariate included in
the regression in the form age/100. The estimates are based on the second
half of a two chain run of 10,000 iterations. Health status is measured in
terms of dependency in activities of daily living; with health = 2 if there are
four or fewer activities with dependence, health = 3 for ﬁve dependencies,
health = 4 for six dependencies, and health = 5 if there were special medical
conditions requiring extra care. It can be seen that higher ADL dependency
is associated with earlier mortality and lower stays. The age eﬀect is not
signiﬁcant, but its negative sign is possibly misleading and may reﬂect varying
frailty (selection eﬀects)—see Section 9.4. The κ coeﬃcient shows negative

Survival and Event History Models
421
TABLE 9.1
Nursing home stays.
WinBUGS
BayesX
Mean
2.5%
97.5%
Mean
2.5%
97.5%
Inﬂuences on Mortality
Intercept
−3.22
−3.85
−2.58
−6.93
−7.27
−6.63
Age
−0.44
−1.18
0.27
Treatment
−0.13
−0.23
−0.02
−0.06
−0.17
0.05
Male
0.35
0.22
0.48
0.34
0.21
0.47
Married
0.16
0.00
0.31
0.16
0.01
0.31
ADL Status 3
−0.03
−0.18
0.12
−0.03
−0.19
0.11
ADL Status 4
0.23
0.07
0.38
0.22
0.06
0.37
ADL Status 5
0.53
0.33
0.73
0.52
0.32
0.72
κ
0.61
0.58
0.64
Inﬂuences on Length
of Stay
Intercept
5.25
4.24
6.26
Age
0.72
−0.45
1.92
Treatment
0.21
0.03
0.38
Male
−0.57
−0.79
−0.36
Married
−0.25
−0.51
0.00
ADL Status 3
0.05
−0.20
0.30
ADL Status 4
−0.37
−0.62
−0.12
ADL Status 5
−0.87
−1.19
−0.54
σ
1.64
1.56
1.71
duration dependence. The DIC for this model (based on the unstandardized
deviance) is 16,462 (de = 9).
To illustrate use of BayesX for right-censored survival data a piecewise
exponential (PE) model (Section 9.3) is also applied. This application addi-
tionally models the impact of age using a B-spline with second-order random
walk penalty on the parameters (see Chapter 10). Due to the diﬀerent baseline
hazard the intercept changes, but otherwise inﬂuences on mortality are simi-
lar, except that the treatment variable is no longer signiﬁcant. The changing
impact of age on the log hazard is shown in Figure 9.1, and shows that the
95% interval straddles zero for all ages. The changing baseline parameters are
shown in Figure 9.2, and conﬁrm negative duration dependence. The negative
duration eﬀect may be diminished if frailty were allowed for, and including
frailty in the BayesX model is left as an exercise; this involves adding an extra
patient identiﬁer column, patno, into the data input, and adding a term for
patno(random) in the model. The DIC falls to 16,362 (de = 17) under the PE
model without frailty, and to 15,984 for a PE model with frailty (under the
default inverse gamma parameter settings).

422
Applied Bayesian Hierarchical Methods
–1
–0.8
–0.6
–0.4
–0.2
0
0.2
0.4
0.6
65
70
75
80
85
90
95
100
105
Age
'2.5%
Mean
97.5%
FIGURE 9.1
Age eﬀect, Nursing home stays.
–4
–3
–2
–1
0
1
2
3
0
200
400
600
800
1000
FIGURE 9.2
Piecewise log hazard, Nursing home stays.

Survival and Event History Models
423
9.3
Semi-Parametric Hazards
In the proportional hazards model
h(t|Z) = h0(t) exp(Zβ)
it may be diﬃcult to choose a parametric form for the baseline hazard h0(t),
and semi-parametric or nonparametric approaches are often preferable. These
have beneﬁts in avoiding possible mis-speciﬁcation of parametric hazard forms,
and in facilitating other aspects of hazard regression, such as time varying
predictor eﬀects (Gamerman, 1991). Such aproaches have been applied to the
cumulative hazard, and implemented in counting process models (Clayton,
1991). However, they may also be speciﬁed for the baseline hazard h0 itself
(e.g., Gamerman, 1991; Sinha and Dey, 1997) and typically use only informa-
tion about the intervals in which exit times occur.
Consider a partition of the response time scale into J intervals (a0, a1], . . . ,
(aJ−1, aJ], where aJ equals or exceeds the largest observed time, censored or
uncensored (Ibrahim et al., 2001, 106). The partition scheme can be based
on distinct values in the proﬁle of observed times {t1, . . . , tn}, whether cen-
sored or not, or by siting knots aj at selected points in the range (tmin, tmax).
Yin and Ibrahim (2006, 173) propose that the partitioning should ensure an
approximately equal number of failures in each of the J intervals, with each
interval containing at least one failure. Among alternatives are knots sited at
(j −1/J)th quantiles of observed times (Gustafson et al., 2000), or evenly
spaced along the range of the observed t values. As the number of intervals J
tends to inﬁnity, a truly nonparametric model is obtained but not likely to be
empirically well identiﬁed (Lopes et al., 2007).
Diﬀerent approaches may be based on the asumption that the baseline haz-
ard is constant within each interval. Thus Ibrahim et al. (1999) and Ibrahim
et al. (2001, 55) consider discrete approximation to the gamma process of
Dykstra and Laud (1981). This involves a prior on the increments
∆j = h0(aj) −h0(aj−1),
j = 1, . . . , J
in the baseline hazard, and use of the approximate survival function
S(t|Zi) = exp

−Bi
 t
0
h0(u)du

⋍exp

−Bi
J

j=1
∆j(t −aj−1)+

,
where Bi = eZiβ, and (u)+ = u if u > 0 and is zero otherwise. The probability
of exit in interval j is then
qj = S(aj−1) −S(aj)
⋍

exp

−Bi
j−1

m=1
∆m(aj−1 −am−1)

1 −exp

−Bi(aj −aj−1)
j

m=1
∆m

.

424
Applied Bayesian Hierarchical Methods
Piecewise exponential priors (Brezger et al., 2008, 23; Gamerman, 1991;
Ibrahim et al., 2001, 106; Sinha et al., 1999) specify a baseline parameter λj for
each interval, possibly combined with interval speciﬁc regression parameters
βj, so that
h(ti ∈(aj−1, aj]|Zi) = λj exp(Ziβj),
where Zi excludes an intercept. Let Bij = exp(Ziβj). For a subject surviving
beyond the jth interval (with ti > aj) the likelihood contribution during
interval j is
exp(−λj(aj −aj−1)Bij).
For a subject with aj−1 < ti ≤aj, either failing (wij = 1) in interval j, or
censored but nevertheless exiting (wij = 0) in the jth interval, the likelihood
contribution is
[λjBij]wij exp[−λk(ti −aj−1)Bij)].
So a Poisson likelihood approach may be applied3 as in Equations 9.2
through 9.4, with responses deﬁned by the event type in each interval and
with oﬀsets deﬁned according to whether the subject survives the interval.
The successive baseline parameters λj are likely to be correlated, but also
possibly to show erratic ﬂuctuations or be imprecisely estimated if treated
as ﬁxed eﬀects. Hence a smoothing prior is indicated. One might assume a
parametric model (e.g., polynomial in j) but allowing for additional random
variation. Thus Albert and Chib (2001) and Omori (2003) assume a polyno-
mial for αj = log(λj),
αj = ψ0 + ψ1(j −1) + ψ2(j −1)2 + uj,
where uj ∼N(0, 1/τu). Pooling strength under hierarchical autocorrelated
priors linking successive λj or αj is also widely applied. These are known
as correlated prior processes or Martingale prior processes for the baseline
hazard. Possibilities are ﬁrst or second-order random walks in the αj, possibly
adjusted to reﬂect unequal width δj = (aj −aj−1) of the intervals. Thus one
might take a ﬁrst-order random walk,
αj ∼N(αj−1, σ2
αδj),
with α1 a separate ﬁxed eﬀect, and with τα = 1/σ2
α following a gamma or
uniform prior. Alternatively, as in Gustafson et al. (2003), one may take wj =
0.5(aj + aj+1), ζj = wj −wj−1, and
αj ∼N

αj−1 + (αj−1 −αj−2) ζj
ζj−1
, σ2
α(ζj/¯ζ)2

.
Since setting particular partitions of the time scale involves an element of
arbitrariness, Sahu and Dey (2004) apply RJMCMC techniques in which J is
an additional unknown; they specify a sparse precision matrix formulation for
the joint prior for the (α1, . . . , αJ) under an RW1 prior for given J.

Survival and Event History Models
425
Since random walk priors of degree r set a mean level not on the αj them-
selves, but on diﬀerences of order r (e.g., an RW1 prior speciﬁes a zero mean
for αj −αj−1), identiﬁability may require that a separate regression intercept
is omitted or that the αj are centered to sum to zero at each MCMC iteration,
by the operation α′
j = αj −¯α. Alternatives are to set any value, say the hth, to
zero (by the operation α′
j = αj −αh at each iteration), or set the ﬁrst eﬀect α1
to zero (Sahu and Dey, 2004).
A gamma prior in the baseline hazard rates is also possible (Arjas and
Gasbarra, 1994), namely
λj ∼Ga(b, b/λj−1),
where λ1 is a separate positive eﬀect, and larger b values lead to smoother
sequences of λj. The same identiﬁability issues obtain as for αj = log(λj) and,
if a regression intercept is used, devices such as normalization of the λj (to
value 1) at each iteration may be applied.
Piecewise priors may also be used to model nonconstant predictor eﬀects,
though typically values of time varying regression coeﬃcients βj in successive
intervals are expected to be close (Sinha et al., 1999). Sargent (1997) considers
alternative gamma priors for the precision τβ = 1/σ2
β of regression coeﬃcients
assumed to evolve according to a ﬁrst-order random walk with normal errors.
Prior knowledge in his application (the Veterans Administration lung cancer
trial) suggests that values of time varying coeﬃcients on successive days would
diﬀer by at most 0.001. Taking this as the standard deviation of the normal
distribution, the prior mean precision for the gamma is 106. This corresponds
to quartiles (0.0027, 0.0038, 0.0059) for σβ. An alternative prior adopted by
Sargent has mean precision 105. Posterior inferences for the mean precision
were diﬀerent under the alternative priors, but not those on the estimated βj.
Fahrmeir and Knorr-Held (1997, 432) suggest gamma Ga(1, b) priors on pre-
cision parameters τα on varying log baseline rates, or precisions τβ on varying
predictor eﬀects. Sensitivity is gauged with b taking alternative values (e.g.,
b = 0.05 and b = 0.0005), since b determines how close to zero the variances
are allowed to be a priori.
9.3.1
Cumulative hazard speciﬁcations
Semi-parametric approaches may also be applied to the cumulative base-
line hazard H0 (Kalbﬂeisch, 1978). Consider a counting process approach
with data (Ni(t), Yi(t), Zi(t)) and independent priors on β(t) and H0. For
an individual i exiting or censored before t, so that Yi(s) = 0 for s > t,
one may apply a Poisson likelihood with binary responses dNi(t) and means
Yi(t) exp(Zi(t)β)dH0(t). An independent gamma increments prior for dH0 may
be adopted (assuming a constant baseline hazard in each interval), namely
dH0(t) ∼Ga(c[dH∗(t)], c),

426
Applied Bayesian Hierarchical Methods
where dH∗(t) is a prior estimate of the hazard rate per unit time. Other
possibilities include normal priors on log(dH0).
Let J + 1 intervals (s0, s1], . . . , (sJ, sJ+1] be deﬁned by the J distinct fail-
ure times in a dataset, with s1 equal to the minimum observed failure time,
and sJ+1 exceeding the largest failure time sJ (Sargent, 1997, 16). The likeli-
hood for individual i exiting or censored before sj, so that Yij = 0 for t > sj,
reduces to a discretized form of Poisson likelihood4 over all possible inter-
vals j with binary resposes dNij and means Yij exp(Zijβj)dH0j. This model
may be adapted to allow for unobserved covariates or other sources of hetero-
geneity (‘frailty’) as considered in Section 9.4. It also allows for autoregressive
dependencies between intervals.
Example 9.2. Veterans Lung Cancer Trial
To illustrate the implemen-
tation of semi-parametric hazards and the opportunity they oﬀer to model
time varying regression eﬀects, consider data from the Veteran’s Administra-
tion lung cancer trial. In this trial, n = 137 male subjects with advanced
inoperable lung cancer were randomized to either a standard or a test
chemotherapy, with the end point being time to death in days. Only 13 of
the 137 survival times are censored. Most analyzes ﬁnd the treatment to be
insigniﬁcant and consider the remaining predictors, namely:
celltype (1 = squamous, 2 = smallcell, 3 = adeno, 4 = large);
the Karnofsky score or KS, based on a patient’s ability to perform common
tasks (with values 0–100, where a score of 100 signiﬁes normal physical abilities
with no evidence of disease);
prior therapy or PT, (0 = no, 1 = yes);
an interaction between KS and PT.
Sargent (1997) considers a counting process version of the Cox model for
these data (see Section 9.3.1) with time varying eﬀects on the KS predictor,
and ﬁnds its relevance to be less at higher durations.
Here a piecewise exponential model
h(ti ∈(aj−1, aj]|Zi) = λj exp(Ziβj)
is adopted, with the partitioning of the time scale involving 51 equally spaced
points between 0 and the maximum survival time of 999 days. The ﬁrst model5
assumes a constant Karnofsky score eﬀect, but time varying (log) baseline
hazard, with αj ∼N(αj−1, σ2
α), a U(0, 108) prior on σ2
α, and α1 ∼N(0, 1000).
With 20,000 (and 5000 burn-in) iterations in a two chain run, the posterior
density of σα is found to be bounded away from zero, with median 0.14. There
is a slight upward shift to higher mortality between 500 and 1000 days in the
trial (Figure 9.3). The DIC is 993 (de = 11). The coeﬃcient on the Karnofsky
score has 95% interval (−0.32, −0.12), while the interaction term has coeﬃ-
cient with 95% interval (−0.54, −0.10).

Survival and Event History Models
427
–5
–4.5
–4
–3.5
–3
–2.5
–2
–1.5
–1
–0.5
0
0
100
200
300
400
500
600
700
800
900
1000
Days
Mean
2.5%
97.5%
FIGURE 9.3
Baseline log hazard.
–0.6
–0.5
–0.4
–0.3
–0.2
–0.1
0
0.1
0.2
0.3
0
100
200
300
400
500
600
700
800
900
1000
Days
Mean
2.5%
97.5%
FIGURE 9.4
Varing eﬀect of Karnofsky score.
A second model instead takes the Karnofsky score to have a time vary-
ing coeﬃcient. The DIC is slightly smaller at 991.5 (de = 13) and there is a
slight upward trend in the coeﬃcient, with an insigniﬁcant eﬀect becoming
apparent at higher days (Figure 9.4). Topics for further investigation might
be the sensitivity of the form of time variation in the KS eﬀect to the par-
titioning scheme of the durations, or to unobserved heterogeneity between
subjects.

428
Applied Bayesian Hierarchical Methods
9.4
Including Frailty
Subjects with a given proﬁle of attributes are still likely to show variations in
survival times due to unobserved factors. Such factors mean that subjects have
diﬀerent frailties and the most frail will exit before others (Aalen, 1988), so
that survivors are subject to a selection eﬀect. Inferences from survival analysis
may be incorrect if unobserved heterogeneity is ignored (Lancaster, 1990). The
canonical form for introducing unobserved diﬀerences between observation is
via a multiplicative frailty, γi, distributed independently of Zi and ti, with
h(ti|Zi, γi) = γih0(ti) exp(Ziβ)
leading to mixed proportional hazard or MPH models (Abbring and van den
Berg, 2007; Mosler, 2003; Van den Berg, 2001). Except for the case of positive
stable frailty distributions, the MPH model is inconsistent with the usual Cox
proportional hazard formulation (Henderson and Oman, 1999).
A typical assumption for the distribution p(γi) of multiplicative frailties
is that they are gamma distributed (Perperoglou et al., 2006), typically γi ∼
Ga(k, k) where k is unknown. So the frailties have mean 1 and variance 1/k to
ensure identiﬁcation when Zi includes an intercept. Another possibility is to
include the regression eﬀect exp(Ziβ) in the speciﬁcation of the frailty density.
So, for example,
h(ti|Zi, γi) = γih0(ti)
γi ∽Ga(k exp[Ziβ], k).
Sohn et al. (2007) assume Weibull distributed survival times, with density
form
f(ti) = a
γi
tα−1
i
exp(tα
i /γi)
and then take γi to be inverse gamma. With the form x ∽IG(a, b) corre-
sponding to f(x) = [ba/Γ(a)]x−(α+1) exp[−b/x] the frailty density is then
γi ∽IG(α + 1, α exp[Ziβ]).
Other positive parametric densities can be used to represent frailty, such
as the log-normal (Gustafson, 1997). An advantage of gamma frailty com-
bined with Weibull hazard is that joint and marginal survival functions can
be obtained analytically. An alternative is to assume the γi have a positive
stable distribution (Hougaard, 2000), in which case the proportional hazards
property is preserved after the γi are integrated out (Aalen and Hjort, 2002).
Ravishanker and Dey (2000) consider a ﬁnite mixture of stable densities for
robust frailty modeling.
Estimates resulting from the mixed proportional hazard model are often
sensitive to the functional form of the heterogeneity distribution, and may be
biased if the functional form of the distribution is mis-speciﬁed (Baker and

Survival and Event History Models
429
Melino, 2000; Keiding et al., 1997). Heckman and Singer (1984) report sen-
sitivity of regression estimates according to diﬀerent parametric distributions
of frailty. They propose discrete mixture models with ﬁnite support at a small
number K of points, so that
h(ti|Zi, γi) = γGih0(ti) exp(Ziβ),
where Gi is a multinomial indicator with K categories. Sahu and Dey (2004)
compare gamma, stable and skewed log-t frailty models and show how the
gamma assumption may attenuate covariate eﬀects as compared to the other
forms.
Despite such sensitivity it is important to consider possible heterogeneity.
One can show (Lancaster, 1990) that a model neglecting frailty will show spu-
rious duration dependence, and speciﬁcally over-estimate the extent of neg-
ative duration dependence in the true baseline hazard, and under-estimate
the extent of positive duration dependence. This is a consequence of selec-
tion since in the presence of negative duration dependence, subjects with high
values of γ exit faster, so survivors at a given survival time are increasingly
biased toward relatively low γ values and lower hazard rates. These features
can be illustrated with the MPH assumption and particular parametric haz-
ards. Conditional on a particular value of γi, the survivor function is
S(ti|Zi, γi) = exp

−γi exp(Ziβ)
 ti
0
h0(u)du

,
or in terms of the cumulative hazard H0(ti),
S(ti|Zi, γi) = exp[−γi exp(Ziβ)H0(ti)].
The unconditional survival function (integrating out the frailties) is
therefore
S(ti|Zi) =
 ∞
0
S(ti|Zi, γi)p(γi)dγi
=
 ∞
0
p(γi) exp[−γiH0(ti)eZiβ]dγi.
For γi following a gamma density, γi ∼Ga(a, b), the unconditional survivor
function is (Vaupel et al., 1979)
S(ti|Zi) = ba!
b + H0(ti)eZiβ"−a
which for a = b = k (with Zi including a constant) reduces to
S(ti|Zi) =
!
1 + k−1H0(ti)eZiβ"−k.
Consider exponentially distributed times so that h0(ti) = 1 and H0(ti) = ti.
Then
S(ti|Zi) = [1 + k−1eZiβti]−k,
f(ti|Zi) = eZiβ[1 + k−1eZiβti]−k−1,
h(ti|Zi) = eZiβ[1 + k−1eZiβti]−1.

430
Applied Bayesian Hierarchical Methods
For a frailty variance 1/k > 0, the hazard rate is a decreasing function of t,
an example of spurious duration dependence. If frailty is present but ignored
not only will duration eﬀects be mis-stated, but covariate eﬀects will be un-
derestimated (Hougaard et al., 1994; Pickles and Crouchley, 1995). Lancaster
(1990) conﬁrmed this analytically for uncensored Weibull survival data.
More general forms of subject level random variation can be achieved by a
general linear mixed model form where the impact of selected predictors wi =
(w1i, . . . , wri) is assumed to vary over subjects, or clusters of subjects. Thus
h(ti|Zi, wi) = h0(t) exp(Ziβ + wibi).
When r = 1 and wi = 1, the random eﬀect bi ∼N(B, 1/τb) is used to
represent variability in frailties between subjects. If Zi contains an intercept,
the bi are constrained to have zero mean, namely bi ∼N(0, 1/τb).
The general linear mixed model form for frailty may take account of spatial
locations of subjects, as in geoadditive hazard regression (Henderson et al.,
2002; Kneib, 2006); so the bi could be spatially correlated with local pooling
of strength. This may make sense if individuals in neighboring locations are
subject to similar environmental risks that aﬀect survival. Heterogeneity in
risks may be combined with nonparametric modeling of predictor eﬀects, as
illustrated in the BayesX analysis in Example 9.1.
In accelerated failure time models (Section 9.2.3), frailty is conveniently
obtained by discrete mixture modeling of the error term. Following Roeder
and Wasserman (1997) a mixture of normals provides a ﬂexible model for es-
timation of densities. Suppose membership of latent subgroups is denoted by a
categorical variable Gi with K options, and prior Gi ∼Mult(1, [π1, . . . , πK]).
Assuming a log-normal density for exit times, one may transform observed
failure or censoring times as ri = log(ti), and to account for right-censoring
deﬁne lower sampling limits Li = log(ti) if di = 0, and Li = 0 if di = 1 and all
failure times are at least 1. Then the discrete mixture adopts varying group
intercepts and variances in the survivor function:6
S(ti) = 1 −
K

k=1
πkΦ

log ti −γ0k −γ1z1i −γ2z2i −· · ·
σk

.
Mixed Dirichlet process and Polya Tree priors for the errors u in an AFT
regression are used by Kuo and Mallick (1997) and Walker and Mallick (1999).
9.4.1
Cure rate models
A particular form of heterogeneity may arise when permanent survival from
an event is possible. Demographic examples are provided by age at ﬁrst mar-
riage or age at ﬁrst maternity. The issue is then to identify latent subpop-
ulations in the censored group, namely to distinguish a permanent survival
subgroup from a subgroup still liable or susceptible to experience the event
but exhibiting extended survival. Not allowing for permanent survival when

Survival and Event History Models
431
it can occur will distort the failure time parameter estimates for the true
susceptible population. Herring and Ibrahim (2002) point out—in the context
of cancer survival—that improved treatment means that a substantial pro-
portion of patients may now be cured, whereas traditional survival analysis,
including the Cox (1972) regression model, assume that no patients are cured
but that all remain at risk of death or relapse. Similarly in the context of
component reliability, Sinha et al. (2003) consider the case where if a unit
is free of manufacturing faults, it will never fail in its technological lifetime
under usual stress levels.
The most common approach to modeling events with a permanent sur-
vival fraction or cure rate assumes the total survival rate is a binary mixture
(Ibrahim et al., 2001). One subpopulation has Sc(t) = 1 with probability
(1 −π), and the other (the noncured or suceptible subpopulation) follows a
conventional survival pattern in which Sn(t) →0 as t →∞. So the overall
survivor function is
S∗(t) = (1 −π) + πSn(t),
and the overall distribution function (Bruderl and Diekmann, 1995) is
F ∗(t) = πFn(t).
Ibrahim et al. (2001, 157) point out that if covariate eﬀects are modeled
via binary regression for πi then the proportional hazard property no longer
obtains.
Let Ri be a partially unobserved binary indicator with Ri = 1 if a subject is
susceptible. Banerjee and Carlin (2004) and Schmidt and Witte (1989) follow
the standard cure rate model and take Ri to be Bernoulli with Pr(Ri = 1) =
πi being a propensity to experience the event (e.g., propensity to relapse).
For simplicity, omit the subscript n in the survivor function for susceptibles.
Then for subjects observed to fail, namely with di = 1, it necessarily follows
that Ri = 1, and so the likelihood contribution from such cases is
Pr(Ri = 1)f(ti) = πif(ti).
Censored subjects may be either susceptibles or nonsusceptibles with like-
lihood contribution
Pr(Ri = 0) + Pr(Ri = 1)Pr(T > ti) = (1 −πi) + πiS(ti).
The total likelihood contribution7 is then
[πif(ti)]di[(1 −πi) + πiS(ti)]1−di,
which reduces to the usual form f(ti)diS(ti)1−di when Ri = 1 for all subjects,
and so πi = 1 (i.e., there is no permanent survivor fraction (PSF)). Any form of
binary regression (e.g., logit) may be used for predicting πi (Schmidt and
Witte, 1989). Banerjee and Carlin (2004) carry out a Bayesian analysis with

432
Applied Bayesian Hierarchical Methods
individual level regression in the scale parameter of the failure distribution f(t),
but without a regression for the susceptible probability. However, their
observations are hierarchical (spatially conﬁgured) response times tij (sub-
jects i within areas j), and they allow spatial variability in the propensities
so that πij = πj; see also Cooner et al. (2006).
Chen et al. (1999) describe an alternative structure in which there is a
latent count of risks Ci, taken to be Poisson with mean θ (for example, tumor
cells remaining after treatment that have varying potentials to cause relapse),
and unobserved times Ui1, . . . , UiCi associated with each of these risks. The
Uir are assumed to follow the same failure distribution F(t) = 1 −S(t). An
observed failure time ti is the minimum of these times. If Ci = 0 then a subject
survives permanently from the event being modeled (e.g., a form of cancer).
In this case the composite survival function is
S∗(ti) = Pr(Ci = 0) + Pr(Ui1 > ti, . . . , UiCi > ti|Ci ≥1),
= exp(−θ) +
∞

k=1
S(t)k θk
k! exp(−θ),
= exp(−θ + θS(t)) = exp(−θF(t))
and the composite hazard rate is
h∗(ti) = θf(ti).
An alternative derivation of this model, not tied to the notion of multiple
latent risks, is that the cumulative hazard H(t) =
	 t
0 h(u)du tends to a ﬁnite
positive limit θ as t →∞(Tsodzikov et al., 2003). Chen et al. (1999) and
Ibrahim et al. (2001, 158) mention that the survivor function of the noncured
subpopulation can be written as
Sn(ti) = exp(−θF(ti)) −exp(−θ)
1 −exp(−θ)
so that the composite survival function is in fact also representable as a binary
mixture, namely
S∗(ti) = exp(−θ) + (1 −exp(−θ))Sn(ti).
Chen et al. (1999) introduce covariates into a Poisson regression model
for subject-speciﬁc θi. Consider Weibull distributed times with F(ti|Zi) =
1 −exp[−λitκ
i], λi = exp(Ziβ), and f(ti|κ, Zi) = λiκtκ−1 exp(−λitκ
i). The
likelihood8 when predictors are used to explain both θi and λi, and with
di being event status indicators, is then
[h∗(ti)]diS∗(ti) = [θiλiκt
κ−1
i
exp(−λit
κ
i)]di exp(−θi{1 −exp(−λitκ
i)}).
Multiplicative frailty, as in the MPH setup above, can be introduced in cure
rate models but identiﬁability may be weak because susceptibility responses
are partially unobserved themselves. Models for frailty in multivariate cure

Survival and Event History Models
433
fraction models are considered by Yin (2005). Thus for times tij observed on
subjects i and events j, Yin proposes multiplicative frailty at subject level
combined with Poisson regression for θij in the cure fractions exp(−θij). One
option takes
S∗(tij) = exp(−θijγiF(tij)),
with hazard rates h∗(tij) = θijγif(tij).
Example 9.3. Age at First Maternity
To illustrate frailty modeling in
a cure rate model, this example follows Winkelmann and Boes (2005) in an-
alyzing ages at ﬁrst maternity for 1517 women in the German General Social
Survey for 2002. The subsample considered by Winkelmann and Boes involves
1371 women, comprised of (a) 1154 uncensored subjects who may have been
over 40 at the time of the survey, but whose age at ﬁrst maternity (AFM)
was under 40 and (b) 217 women aged under 40 in 2002, but who had not
yet had a child. Here we consider all 1517 women (including childless women
aged over 40).
A log-logistic model with hazard h(t) = (λκtκ−1/[1 + λtκ]) and survivor
function S(t) = [1 + λtκ]−1 is appropriate to the form of hazard for ﬁrst
maternity, typically peaking between ages 20 and 30. A standard log-logistic
is here compared with a log-logistic model with a PSF, modeled according
to the latent count approach (Chen et al., 1999). The PSF log-logistic model
is then generalized to allow for unmeasured heterogeneity in the age at ﬁrst
maternity. Permanent survivorship in this case is equivalent to a woman never
undergoing a maternity, and at population level is essentially equivalent to the
rate of childlessness.
Regression eﬀects are included in the scale parameter of the log-logistic
hazard via λi = exp(Ziβ), with θ assumed constant. However, a Poisson
regression for θi could be included. Predictors Zi and regression eﬀects β
under the standard log-logistic are as in Table 9.2. Predictors are binary
apart from number of siblings and education years. The modal age χ =
[(κ −1) exp(−ZT β)]1/κ reported in Table 9.2 is based on a predictor vector
ZT for a white subject with 13 years of education, and three siblings.
The standard log-logistic model gives a DIC of 8775 from the second half
of a two chain run of 5000 iterations. The signiﬁcant coeﬃcients show that
delayed AFM is associated with greater education, being white and immi-
grant status. Allowing for a permanently childless subpopulation, but with-
out allowing for frailty, reduces the DIC to 7989 with inferences based on the
ﬁnal third of a two chain run of 7500 iterations. Finally, adding log-normal
frailty via
λi = exp(Ziβ + ui),
ui ∼N(0, 1/τu)
reduces the DIC to 7877, albeit with a large increase in model dimen-
sion (de = 290). This analysis9 uses starting values based on an earlier

434
Applied Bayesian Hierarchical Methods
TABLE 9.2
First maternity: log-logistic model parameters.
Log-logistic with
Log-logistic with childless
Standard log-logistic
childless fraction
fraction and frailty
Predictor
Mean
2.5%
97.5%
Mean
2.5%
97.5%
Mean
2.5%
97.5%
Years of education
−0.203
−0.241
−0.164
−0.275
−0.312
−0.244
−0.315
−0.365
−0.261
Number of siblings
0.019
−0.009
0.051
0.022
−0.009
0.053
0.025
−0.016
0.062
White
−0.607
−0.850
−0.380
−0.921
−1.148
−0.683
−1.086
−1.349
−0.798
Immigrant
−0.325
−0.611
−0.071
−0.577
−0.905
−0.270
−0.661
−1.054
−0.276
Low income at age 16
0.040
−0.202
0.261
0.207
−0.042
0.468
0.259
−0.006
0.539
Living in city at age 16
−0.077
−0.254
0.101
−0.017
−0.207
0.171
−0.015
−0.251
0.200
Modal age (typical individual)
33.0
32.1
34.0
31.8
31.0
32.6
30.8
30.2
31.4
Shape parameter, κ
5.0
4.7
5.3
8.8
8.2
9.4
10.3
9.9
10.9
Proportion childless
0.17
0.15
0.19
0.17
0.15
0.19
Frailty standard deviation
1.036
0.947
1.181

Survival and Event History Models
435
analysis, with inferences based on the second half of a two chain run of 7500
iterations.
Allowing for a childless subpopulation is a form of frailty in itself, and
enhances (absolutely) the coeﬃcients on signiﬁcant predictor eﬀects. Formally
including frailty in the modeling of the failure density scale parameter further
enhances predictor eﬀects. The low income eﬀect comes close to being “signif-
icant” in the log-normal frailty model, in the sense of having a 95% credible
interval conﬁned to positive values. The childless fraction (i.e., the perma-
nent survival fraction), exp(−θ), is estimated at around 0.17, regardless of the
presence or not of frailty. A standard log-logistic model leads to a signiﬁcantly
later modal age than the extended models. In fact, a better representation of
the age at ﬁrst maternity process is provided by the generalized log-logistic of
Br¨uderl and Diekmann (1995), as discussed in Congdon (2008c).
9.5
Discrete Time Hazard Models
In applications with interval censored times, analysis using a discrete time
scale becomes appropriate, and in fact such analysis has certain beneﬁts also
for modeling time varying or lagged predictor eﬀects (Fahrmeir and Tutz,
2001, 410). Let the time scale be grouped into J intervals A1 = [a0, a1), . . . ,
AJ = [aJ, aJ+1) with interval j being [aj−1, aj), and a0 = 0, aJ+1 = ∞,
where aJ denotes either the end of the observation period, or the largest time
(censored or failed). The intervals may be of equal length δj = aj −aj−1 but
are not necessarily so. Instead of continuous observed failure times, only the
discrete times ti ∈Aj are observed. Equivalently let ti = j denote that a time
of failure or censoring is observed within [aj−1, aj).
With Sj denoting the probability of surviving to the end of interval j, the
unconditional probability of failing in interval j is
fj = Pr(t ∈[aj−1, aj)) = Sj−1 −Sj,
and the hazard function (the conditional probability of failing in interval j
given survival till the start of the interval) is
qj = Pr(t ∈[aj−1, aj)|t ≥aj−1) = Pr(t = j|t ≥j) = fj/Sj−1 = Sj−1 −Sj
Sj−1
.
Alternatively stated, qj is the proportion of subjects at risk at the begin-
ning of interval j who experience the event sometime during the interval. The
survivor function (the probability of surviving beyond interval j) is obtained as
Sj = Pr(t > aj) =
j
k=1
(1 −qk) = fj+1 + fj+2 + · · · + fJ = Sj−1(1 −qj),

436
Applied Bayesian Hierarchical Methods
though an alternative survivor function ˜Sj = Pr(t > aj−1) may be deﬁned as
the probability of surviving to the start of interval j (Aitkin et al., 2004, 350;
Fahrmeir and Tutz, 2001, 396).
Let wij = 1 if individual i undergoes the event during interval j and wij
otherwise. The likelihood up to interval k for that individual is then (Aitkin
et al., 2004, 351),
f wik
ik S1−wik
ik
= (qikSi,k−1)wik [Si,k−1(1 −qik)]1−wik
= Si,k−1qik
wik (1 −qik)1−wik
= qwik
ik (1 −qik)1−wik
k−1

j=1
(1 −qij)(1−wij )
=
k

j=1
qwij
ij (1 −qij)(1−wij ).
This shows that the likelihood involves binary responses wij ∼Bern(qij),
where the qij may vary between time intervals, but are assumed constant
within them. So the hazard probability becomes
q(j|Zij) = Pr(t = j|t ≥j, Zij) = F(αj + Zijβ),
where F is a suitable distribution function, and αj models the baseline haz-
ard (Singer and Willetts, 1993). If the predictors include lagged event status
indicators {wi,j−1, wi,j−2, etc.} one is led to discrete Markov event histories
(e.g., Barmby, 2002); lagged predictor eﬀects may also be used (Fahrmeir and
Tutz, 2001, 410).
A beneﬁt of the discrete framework is that the baseline hazard can be mod-
eled via polynomial functions of j (Efron, 1988; Mantel and Hankey, 1978),
for example:
αj = ψ0 + ψ1(j −1) + ψ2(j −1)2 + uj,
where uj ∼N(0, 1/τu). Parametric time models can also be modeled straight-
forwardly: a Weibull model is represented in a complementary log–log link by
taking the log of the time interval as a covariate (Allison, 1997). Nonpara-
metric models for time (e.g., via splines) can also be applied, or a correlated
random eﬀect prior assumed, as in Section 9.2.2. Time varying predictor eﬀects
are straightforward to use (Muthen and Masyn, 2005), and nonproportional ef-
fects are readily modeled by including interactions between subject attributes
Zij and j.
Commonly used links for the probabilities qij are the logit, probit, and
complementary log–log. For example, a logit link with time varying intercepts
and predictor eﬀects (where the vector Zij excludes a constant term) would
mean
q(j|Zij) =
exp(αj + Zijβj)
1 + exp(αj + Zijβj).

Survival and Event History Models
437
Adopting a logit link means the log-odds of the event occurring are mod-
eled as functions of predictors and time (i.e., interval). The complementary
log–log link model with
q(j|Zij) = 1 −exp(−exp(αj + Zijβj)),
can be derived by assuming an underlying proportional hazard in continuous
time, under which
S(ti|Zi) = exp

−
 ti
0
h(u|Zi)du

= exp{−exp[Ziβ + log H0(ti)]}.
Then taking αj = log
	 aj
aj−1 h0(t) leads to the complementary log–log
model, with the same predictor eﬀects as under a PH model (Fahrmeir and
Tutz, 2001, 401; Kalbﬂeisch and Prentice, 1980).
If correlated priors (e.g., random walks) on the αj and βj are adopted, the
setting of priors on the hyperparameters (e.g., precisions) following the same
considerations as discussed above in connection with semi-parametric models
for continuous time hazards (Section 9.2.2). Fahrmeir and Knorr-Held (1997)
discuss alternative Hastings sampling schemes for collections of time varying
coeﬃcients {αj, βj1, . . . , βjp} in discrete hazard regression.
As for continuous time survival modeling, neglecting unobserved hetero-
geneity may mean that the estimated baseline hazard parameters are biased
downwards, the impact of constant covariates is underestimated, or that spuri-
ous time-dependent eﬀects for observed predictors are obtained. For improved
identiﬁcation, frailties may be included at subject level, rather than at subject-
interval level, though bilinear schemes are possible. Thus a log-normal frailty
might specify
qij = F(αj + Zijβ + bi),
where bi ∼N(0, σ2
b). Alternatively a bilinear scheme might be used
qij = F(αj + Zijβ + δjbi),
where one of the δj is set to a ﬁxed value for identiﬁcation if the variance of
bi is unknown. Muthen and Masyn (2005) use a discrete mixture approach in
which Gi ∈(1, . . . , K) are latent groups (e.g., developmental trajectories in
educational applications). Then
F −1(qij) = αj,Gi + ZijβGi + δj,Gibi,
where the probability that Gi = k is deﬁned by predictors Ui in a separate mul-
tiple logit regression. The factor scores bi may be deﬁned by bi ∼N(0, 1/τb),
or by a hierarchical linear regression on the predictors Ui.
9.5.1
Life tables
Life tables are a particular way of analyzing discrete time survival data.
They may be applied to situations where permanent survival or withdrawal is

438
Applied Bayesian Hierarchical Methods
possible, such as marital status life tables (Schoen and Weinick, 1993), or to
population mortality. The intervals in such applications refer to age or dura-
tion bands and discretization may extend beyond that present in the data, as
in abridged life tables (Kostaki and Panousis, 2001). The intervals are not nec-
essarily of equal length (Wong, 1977). For example, in one common scheme for
human life tables, ages under 1 form the ﬁrst interval, ages 1–4 comprise the
second interval, ages 5–9 interval 3, and so on for successive ﬁve-year bands,
with the ﬁnal interval typically open ended, such as ages over 90. Often human
life tables are estimated from population deaths data over a speciﬁed calendar
period, to provide “period” life tables, based on current mortality in individ-
uals born in diﬀerent periods, as distinct from cohort life tables, based on
follow-up studies of mortality in a group of individuals born in the same time
period (Richards and Barry, 1998).
Following life table conventions, ages are denoted x and age intervals are
denoted [x, x + n), e.g., n = 5 if intervals are ﬁve years in length. Let t denote
a random variable for the total lifetime (age of death) of an individual. Also
in line with life table conventions, the probability Pr(T > x) that the age
of death T is x or higher (the survivor function) is denoted l(x). The hazard
rate—also called the force of mortality in life table applications—is then
h(x) =
lim
∆x→∞
l(x) −l(x + ∆x)
l(x)∆x
= −l′(x)
l(x) ,
with solution
l(x) = l(0) exp

−
 x
0
h(u)du

.
With l(0) = 1, the density of the age at death is f(x) = h(x)l(x). The
probability of surviving from age x to age x + n, given survival to x, namely
Pr(t > x + n|t > x), is denoted npx with
npx = l(x + n)/l(x) = exp[−
	 x+n
0
h(u)du]
exp[−
	 x
0 h(u)du]
= exp

−
 n
0
h(x + u)du

while the probability of dying before age x+n conditional on reaching age x is
nqx = 1 −npx = 1 −l(x + n)/l(x) = l(x) −l(x + n)
l(x)
.
Important in linking these functions to estimable quantities is the central
rate of mortality, which represents a weighted average of the force of mortality
applying over the interval [x, x+n). Let P(x) denote the population of age x.
Then the death rate for age interval [x, x + n) is
nMx =
 x+n
x
h(a)P(a)da
,  x+n
x
P(a)da.

Survival and Event History Models
439
Assuming linearity of l(a) in the interval from x to x + n, this can be
simpliﬁed (Namboodiri and Suchindran, 1987, 36) to
nMx =
l(x) −l(x + n)
0.5n[l(x) + l(x + n)].
Hence the survivor probability can be written
l(x + n)
l(x)
= npx = 1 −0.5n(nMx)
1 + 0.5n(nMx)
giving
nqx =
n(nMx)
1 + 0.5n(nMx).
To clarify the operations involved, life tables involve hypothetical popu-
lations of initial size l0 = 100,000 (the radix) with lx denoting numbers still
alive at age x from the initial population. The number dying between age x
and x + n is denoted ndx = lx −lx+n and from above
nqx = 1 −lx+n/lx = lx −lx+n
lx
= ndx
lx
.
To develop the life table from observed deaths and populations requires an
estimator for the probability nqx. Let Dx denote observed deaths for age band
[x, x+n) over a certain period, Px denote observed mid-period populations at
risk (or person-years) and Mx denote age speciﬁc death rates. One estimator
of probability of dying in interval [x, x + n) conditional on being alive at the
start of the interval is then (Chiang, 1984)
nqx =
nnMx
1 + n(1 −nax)nMx
,
where nax is the fraction of the interval lived by those dying during it. For
most age groups nax is taken as a half but for infants (ages under 1) can be
taken as 0.1, and for the 1–4 age group as 0.4.
Under conventional life table methods that are usually applied to large
populations, the Mx are treated as unrelated ﬁxed eﬀects and estimated
by assuming binomial sampling Dx ∼Bin(Px, Mx) or Poisson sampling
Dx ∼Po(MxPx). In a Bayesian version of the ﬁxed eﬀect approach, the Mx
would be assigned diﬀuse beta or gamma priors with known hyperparameters,
e.g., Mx ∼Beta(1, 1). Overdispersed versions of binomial or Poisson densities
may also be used, namely hierarchical schemes for “borrowing strength” over
correlated mortality rates, with a higher stage density for the Mx involving
unknown hyperparameters. An example might be when age-speciﬁc deaths
Dix for a set of areas or hospitals (i = 1, . . . , I) are to be analyzed and popu-
lations at risk are relatively small. Then the conjugate binomial-beta approach

440
Applied Bayesian Hierarchical Methods
would mean taking death rates Mix to be distributed according a hierarchical
model, namely
Dix ∼Bin(Pix, Mix),
Mix ∼Beta(a, b),
where {a, b} are unknown parameters. Congdon (2009) adopts a general linear
mixed model approach for data involving an additional stratifying group g in
which
Dixg ∼Bin(Pixg, Mixg),
and a logistic regression with group-speciﬁc autoregressive area and age eﬀects
has the form:
logit(Mixg) = αg + sig + hxg.
Other options might be to model the impact of age by a parametric func-
tion; for example, Neves and Migon (2007) use Makeham’s Law, by which
Dx ∽Po(MxPx),
Mx = α + βδx
and extend this to a time series model for age-speciﬁc death rates, namely
Mxt = αt + βtδx
t .
Example 9.4. Cancer Survival
This example illustrates discrete sur-
vival with potential heterogeneity (frailty). It involves survival times in months
for 48 participants in a cancer drug trial. Of the 48 patients, 28 receive an
experimental drug treatment (drug = 1) and 20 receive a control treatment
(drug = 0). The other predictor is patient age at the start of the trial, ranging
from 47 to 67 years. The observed times provide the month of death or the
last month the patient was known to be alive.
With a complementary log–log link, Weibull time dependence (model 1)
is compared with a semi-parametric baseline hazard modeled via a ﬁrst-order
random walk (model 2).10 Convergence in the latter is assisted by omitting
an intercept β0, and instead using the parameterization αj = β0 +aj where aj
are random walk eﬀects with precision τa = 1/σ2
a centered to have mean zero
at each MCMC iteration. For numeric stability age values are divided by 100.
A two chain run of 100 thousand iterations on the semi-parametric model
gives a DIC of 234.3 with eﬀective parameter count de = 3.9. The low de
despite 39 random eﬀect parameters suggests relatively little ﬂuctuation about
the central value of β0 which has posterior mean −7.3. The impression is
conﬁrmed by plot of the αj showing virtual linearity (Figure 9.5 with 80%
credible intervals), and by the density plot of the standard deviation σa of the
aj which has a spike at zero. A Weibull model has a lower DIC (namely 230.8),
but in fact the Weibull parameter has a 95% interval straddling one: its mean

Survival and Event History Models
441
–10.5
–9.5
–8.5
–7.5
–6.5
–5.5
–4.5
1
3
5
7
9
11 13 15 17 19 21 23 25 27 29 31 33 35 37 39
Interval
Mean
10%
90%
FIGURE 9.5
Varying intercept, Cancer survival data.
(95% interval) is 0.59 (0.15, 1.12) while the treatment and age eﬀects are −2.2
(−3, −1.4) and 11.5 (3.6, 18.5). Mortality declining with time is possibly an
unexpected eﬀect, and might be due to unmodeled heterogeneity.
A lognormal frailty eﬀect at subject level is then added to the Weibull
model, so that
q(j|Zij) = 1 −exp(−exp(β0 + Drugiβ1 + Ageiβ2 + κ log(j) + σbbi)),
where bi ∼N(0, 1) and σb is assigned a uniform prior with maximum 10.
Convergence in a two chain run is obtained after around 6000 iterations, and
basing inferences on a subsequent 6000 leads to a κ coeﬃcient with mean 3.3
and 95% interval from 0.8 to 7.6. There are much ampliﬁed treatment and
age eﬀects, namely −6.4 (−13, −2.4) and 33.5 (12.6, 57). These large shifts in
parameter values may partly reﬂect the small sample, but point to the way
inferences may be aﬀected by neglecting frailty. The DIC falls to 196, with
de = 26.
9.6
Dependent Survival Times: Multivariate
and Nested Survival Times
Multivariate and nested survival data can occur in a number of diﬀerent
ways; for discussions, see Hougaard (1987) and Sinha and Ghosh (2005) for
a Bayesian perspective. Examples are when each subject may experience rep-
etitions of the same event; when subjects may experience more than one

442
Applied Bayesian Hierarchical Methods
event; when times are for subjects arranged in clusters; or in competing risks
situations (considered in Section 9.7). For example, bivariate survival models
can be used to analyze:
•
survival data on twins or other types of matched pair (Anderson
et al., 1992);
•
reliability data when the lifetime of one component is related to the
lifetimes of other components;
•
failure times of paired human organs (Sahu and Dey, 2000; Tosch
and Holmes, 1980).
Examples of grouped or clustered data are provided by Gustafson (1997)
as when several response times are measured for a single patient in a clinical
trial, or when responses are for patients categorized according to clinic of
treatment. Multivariate perspectives on more specialized survival models are
exempliﬁed by Bayesian multivariate cure rate models (Chen et al., 2002; Yin,
2005), and multivariate counting processes (Sinha and Ghosh, 2005).
The statistical model applied to such data needs to account for the intra-
cluster or inter-event correlation. It may be possible to model the dependence
structure directly, for example, via multivariate versions of widely adopted
parametric survival models (Yashin et al., 2001). Thus Sahu and Dey (2000)
consider bivariate exponential and Weibull survival models for data on times
to visual impairment for paired eyes, while Damien and Muller (1998) provide
a Bayesian treatment of a bivariate Gumbel model. The multivariate log-
normal is another possibility, which adapts to the situation of conditional
multivariate data, when durations on a second event are obtained conditional
on the duration in a ﬁrst event (Henderson and Prince, 2000).
The other approach is to introduce random frailty terms at the cluster
level or common frailties across events. The frailty term represents common
inﬂuences across clusters or events that are neglected or not observed, and
responses on members of a cluster (or on correlated events) are typically
assumed independent given the value of the cluster eﬀect (or shared frailty
factor). Sahu and Dey (2004, 325) describe how diﬀerent frailty assumptions
lead to diﬀerent correlations between log survival times in a bivariate situa-
tion (under the assumption a Weibull baseline hazard). Let tij be the failure
time for the jth component or outcome (j = 1, . . . , mi) of the ith subject
(i = 1, . . . , n). Then the hazard function assuming a common multiplicative
frailty takes the form (Sahu et al., 1997; Yin and Ibrahim, 2005):
h(tij|Zij, γi) = γih0(tij) exp(Zijβj)
with the unit frailty eﬀect γi distributed independently of Zij and tij. If γi
is high then all hazards are raised, and so times tij tend to be low; if γi is
low then all hazards are lowered and the tij tend to be relatively extended. In
this way the common frailty induces a positive association between observed
times. In the case of repeated occurrences r = 1, . . . , Ri of the same outcome

Survival and Event History Models
443
to the same subject (e.g., multiple occupation shifts or repeat cardiac events),
the hazard function conditional on γi is independent of the number r of pre-
vious occurrences (Sinha, 1993). Unconditionally, however, the hazard for the
(r + 1)th occurrence is
hr(tir|Zi) = h0(tir) exp(Ziβ)(1 + rVar(γi)).
The same scenario applies when subjects i are nested within clusters j,
with cluster eﬀects γj shared between the nj individuals in the same cluster:
h(tij|Zij, γj) = γjh0(tij) exp(Zijβj),
i = 1, . . . , nj; j = 1, . . . , J.
If the γj are assumed gamma distributed γj ∼Ga(h, h) with variance
1/h then smaller values of h signify a closer relationship between subjects in
the same group and greater heterogeneity between the groups. For models
including cure rates, Yin (2005) proposes mutiplicative frailty at cluster level
combined with Poisson regression for θij in the cure fractions exp(−θij). One
option takes
S∗(tij) = exp(−θijγjF(tij)),
with hazard rates h∗(tij) = θijγjf(tij).
Survival time data are often highly skewed and this may aﬀect the appro-
priate form of frailty. Frailty models allowing for fat tails and skewness are
obtained under the skew log-normal or skew log-t common frailty approach of
Sahu and Dey (2004); in practice they consider only positively skewed frailty.
Consider a parametric hazard (e.g., Weibull) for multiple event time data
(subjects i = 1, . . . , n and events j = 1, . . . , m) and with subject level scale
parameters λij for event j, namely
h(tij|λij, κ) = λijκjtκj−1
ij
.
Then a skew log-normal frailty model implies
log(λij) = Ziβj + bi + δui,
where bi ∼N(0, σ2
b), δ is positive, and ui ∼N(0, 1)I(0, ) with ui independent
of bi. Under the skew log-t model,
bi ∼t(0, ν, σ2
b),
where ν is a degrees of freedom parameter and ui ∼N(0, 1)I(0, ).
In practice, this kind of model may need informative priors for stable
identiﬁcation, bearing in mind that censoring reduces identiﬁability of complex
random eﬀect models, that bi and vi are to some extent overlapping in their
roles and σ2
b and δ2 are confounded in var(bi + δui) = σ2
b + δ2. To illustrate
relevant strategies for priors on the variance components, uncensored bivariate
times (n = 100, m = 2) are generated with Weibull hazards,11 and scales

444
Applied Bayesian Hierarchical Methods
λij = exp(β1j + β2jxi + bi + δui) where the xi are standard normal, with
β1 = (−5, −6), β2 = (0.5, 1), κ = (1.5, 2), δ = 0.5, and 1/σ2
b = τb = 2, so that
σb ≃0.7. A U(0, 5) prior on δ is adopted in the analysis to re-estimate the
parameters (cf. Sahu and Dey, 2004). The re-estimated parameters lead to
considerable under-estimation of σb with the second half of a single chain run
of 10,000 iterations leading to posterior mean of 0.054, whereas the posterior
mean of δ is 1.6. Assuming instead a U(0, 100) prior on V = δ2 + σ2
b, and
a U(0, 1) prior on the ratio δ2/(δ2 + σ2
b), improves the estimation of σb with
posterior mean 0.55, while the posterior mean of δ is now 1.17.
As for univariate models, considerable generality is obtained by adopting
a semi-parametric hazard while allowing also for common frailty. An example
involves a semi-parametric counting process including multiplicative frailty for
repeated occurrences of the same event (Sinha, 1993). The semi-parametric
hazard is based on J −1 intervals Aj = [aj−1, aj) obtained by considering dis-
tinct failure times, with aJ equal to the maximum time (censored or failed).
Thus for subject-occurrence index i, subject s, and interval j deﬁne an inten-
sity function:
λ(tij|Zi) = Y (tij)b0(tij) exp(Zijβ)γs,
where b0(t) is the baseline intensity function, and the γs represent subject
level frailty. The integrated baseline intensity B0(t) =
	 t
0 b0(u)du is assumed
to follow an independent increments gamma process, namely
dB0(t) ∼Ga(cdB∗
0(t), c),
where B∗
0(t) is an assumed mean intensity. The likelihood kernel for each spell
within each subject is Poisson12 in form with response variables dNij = 1 or 0,
and means dB0(tij) exp(Zijβ)γs.
Example 9.5. Clustered Trial of Infection Treatment
This example
involves two forms of nesting: repetitions of a single event within patients and
multi-level nesting of patients within hopitals. The data are from Fleming and
Harrington (1991) and Yau (2001), and concern a randomized trial of gamma
interferon in treating infections among patients with chronic granulomatous
disease. The 126 patients were nested in 13 hospitals and patients may ex-
perience more than one infection. Of 63 patients in the treatment group, 14
had at least one infection and 20 infections were recorded in all, whereas in
the placebo group, 30 patients had at least one infection and there were 56
infections in all.
The n = 201 observations are therefore at three levels: infections at level 1,
patients at level 2, and hospitals as level 3 units. Let tklm be times between
recurrent infections, with k denoting events within patients, l denoting
patients (l = 1, . . . , L), and m denoting hospitals (m = 1, . . . , M). The anal-
ysis seeks to assess the eﬀect of gamma interferon in reducing the rate of
infection as well as taking account of the clustering in the data; ignoring such

Survival and Event History Models
445
0.0
0.5
1.0
1.5
2.0
0.0
0.5
1.0
1.5
2.0
FIGURE 9.6
Posterior density of sigma.u.
clustering may aﬀect the estimated treatment eﬀect. A piecewise exponential
baseline hazard13 is assumed with J = 20 intervals (aj−1, aj] based on 5th
percentiles of the observed times, with aJ being the maximum time of 389.
Then with a single predictor (zlm = 1 for treated subjects, 0 otherwise)
h(tklm ∈(aj−1, aj]|zlm) = λj exp(zlmβ + elm + um)
with a gamma process prior on the λj, and normally distributed patient and
hospital eﬀects elm ∼N(0, σ2
e), and um ∼N(0, σ2
u). Since the two sources of
variation are confounded, a uniform prior V ∼U(0, 100) is adopted on the
total variance V = σ2
u + σ2
e, and a U(0, 1) prior on the ratio σ2
u/(σ2
u + σ2
e).
A two chain run shows convergence in the variance parameters after around
3500 iterations. Although Yau (2001) reported no signiﬁcant hospital varia-
tion, here posterior means for σe and σu of 1.01 and 0.49 are obtained (us-
ing iterations 5000 to 10,000). The posterior density for σu (Figure 9.6) has
no spike at zero but rather is bounded away from zero (cf. MacNab et al.,
2004, 13). The treatment eﬀect is estimated as −1.22 (sd = 0.37) compared
to the estimate of −1.07 reported by Yau (2001). Centered hospital eﬀects
have posterior means varying from 0.43 (hospital 2) to −0.26 (hospital 10).
Example 9.6. Bivariate Survival
The Diabetic Retinopathy Study was
conducted by the National Eye Institute to assess the eﬀect of laser photo-
coagulation in delaying onset of severe visual loss in patients with diabetic
retinopathy. One eye of each patient was randomly selected for photocoagu-
lation and the other was observed without treatment, with patients followed
up over several years for the occurence of blindness in one or other eye. The
follow-up time is in months, with 80 patients censored on both eyes at the
same time, while 36 patients have onset in both eyes. Censoring is caused by
dropout, death, or termination of the study. Following Huster et al. (1989),
a subset of the dataset containing n = 197 high-risk patients is considered

446
Applied Bayesian Hierarchical Methods
here, so there are i = 1, . . . , n patients and j = 1, . . . , m events with m = 2.
The correlation between pairs of uncensored observations for patients in both
treatment and control groups is 0.28, indicating possible dependence between
the two times.
The Weibull might be appropriate for these data, as a plot of the trans-
formed Kaplan–Meier survivor function namely log[−log(SKM(t))] on log(t),
is approximately linear when either ti1 or ti2 are considered.14 Alternative an-
alyzes consider Weibull survival with and without log-normal frailty at patient
level. Under the latter
tij ∼Wei(κj, λij),
log(λij) = β0 + β1Agei/10 + β2Trtij + β3Typei + bi,
bi ∼N(0, σ2
b),
where Age is age at diagnosis and Type relates to diabetes type. A model
without frailty produces signiﬁcant Weibull shape eﬀects—both shape param-
eters κj have 95% intervals below 1, suggesting a lesser chance of impairment
at longer follow-ups. However, predictor eﬀects, including treatment, are not
signiﬁcant. The DIC is 1684, and log(PsML), based on Monte Carlo estimates
of log(CPO) statistics, is −1460. The worst ﬁtted observation is eye 2 for pa-
tient 68. The hazard ratio θ = e−β2 for untreated eyes averages 2.1, but has a
95% interval straddling 1.
In the fraility model, a U(0, 10) prior on the standard deviation σb of the
eﬀects is adopted, and this model suggests the time eﬀect was spurious (the
95% intervals for the shape parameters now straddle 1). The DIC improves
to 1616 (de = 88) and the log(psML) rises to −1422, in line with signiﬁcant
unobserved heterogeneity. The treatment eﬀect increases, with θ now averag-
ing 2.4, but remains nonsigniﬁcant. A histogram and normal Q–Q plots of the
posterior mean bi show a subgroup with high negative values (see Figure 9.7)
−3
−2
−1
3
2
1
0
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
Theoretical quantiles
Sample quantiles
FIGURE 9.7
Normal Q–Q plot of b[i].

Survival and Event History Models
447
suggesting that a discrete mixture approach (e.g., a two group normal) to
frailty might be appropriate.
9.7
Competing Risks
Competing risks (CR) models involve the tracking of multiple durations cor-
responding to diﬀerent types of exit or transition. With nonrepeatable events
subjects are observed until the ﬁrst exit and completion of one of the multiple
durations, but for repeatable events (e.g., occupational or migration histories)
event histories might include repeated transitions between diﬀerent job or
residential destinations. Assume that there are K possible mutually exclusive
causes of exit or K possible outcomes that a subject is at risk of. Let Ci be
a subject level categorical random variable with K possible levels. Under the
latent failure time approach (Box-Steﬀensmeier and Jones, 2004; Crowder,
2001; Gelfand et al., 2000; Kozumi, 2004) with independent risks, there is
a latent failure time Tik corresponding to each outcome, but only the min-
imum time is observed when individual i exits for cause ki, so that ti =
min(Ti1, . . . , Tik) with ki = argmin(Ti1, . . . , Tik). The remaining times are
censored. All times are censored if an individual does not exit for any of the
K possible reasons.
With these assumptions and conditioning on possibly cause-speciﬁc pre-
dictors Zk, the hazard rate may be expressed as a sum of cause-speciﬁc
hazards, h(t|Zk) = K
k=1hk(t|Zk), where
hk(t|Zk) = lim
∆t→0
Pr(t < T ≤t + ∆t, C = k|T > t, Zk)
∆t
.
The survival function may be decomposed into K marginal survival func-
tions, with
S(t|Z) =
K

k=1
Sk(t|Zk).
Assuming a failure to risk Ci is observed, the contribution of the ith subject
to the likelihood has the form:
fCi(ti|ZiC i)
K

l̸=Ci
Sl(ti|Zil) = hCi(t|ZiC i)
K

l=1
Sl(ti|Zil),
while for a subject censored on all risks the contribution is K
l=1Sl(ti|Zil).
With event indicators dik = 1 if Ci = k, and dir = 0 for r ̸= k, the likelihood
contribution is equivalently
K

r=1
[fr(ti|Zir)]dir [Sr(ti|Zir)]1−dir .

448
Applied Bayesian Hierarchical Methods
For continous survival times, one may assume parametric forms for the
time eﬀect, e.g., a Weibull hazard
hk(t) = λkκktκk−1,
or model risk-speciﬁc semi-parametric hazard sequences that may be corre-
lated over causes. Possible label switching problems under the latent failure
approach may require parameter constraints, such as ordering the shape pa-
rameters κk (Gelfand et al., 2000).
Often competing risk models are applied to repeated transitions between
occupational, residential, or marital states. The hazard rate then generalizes
to reﬂect moves between the mth observed state and the (m + 1)th state. If
Tim denotes the time spent in the mth state, and occupancy of the mth state
for subject i is denoted Cim = k, then
hkl(t|Zik) = lim
∆t→0Pr(t < Tim ≤t + ∆t, Ci,m+1 = l|Tim > t, Cim = k, Zik)/∆t,
is the instantaneous risk of moving from state k to state l (with l ̸= k), given
survival in the mth state until t. Under independent risks, the overall hazard
for leaving state k is then
hk(t|Zik) =
K

l̸=k
hkl(t|Zik).
For discrete time data the functions described in Section 9.5 similarly gen-
eralize to the competing risk case. For nonrepeated events, intervals [aj−1, aj)
for j = 1, . . . , J + 1, and Ci ∈(1, . . . , K):
fjk = Pr(t ∈[aj−1, aj), C = k),
with risk-speciﬁc hazard function:
qjk = Pr(t ∈[aj−1, aj), C = k|t > aj−1),
= fjk/Sj−1,
and survivor function obtained as
Sj =
j
m=1
K

h=1
(1 −qmh).
Deﬁne event indicators dimh = 1 when risk h occurs in interval m, and 0
otherwise. Then for subject i undergoing the kth risk in the jth interval, the
event indicators are dijk = 1, {dijh = 0, h ̸= k} and di1h = di2h = · · · di,j−1,h = 0
for all h, with likelihood
qijk
 j−1

m=1
K

h=1
(1 −qimh)

= qijkSi,j−1.
The response at each interval is multinomial, and to model the impact of
predictors diﬀerent links may be used such as the multiple logit, or multiple

Survival and Event History Models
449
probit. Consider a multiple logit link with K + 1 categories (K alternate
risks plus an extra category for survival, denoted by Ci = 0). Let the ﬁrst
category be for survival, and deﬁne regression coeﬃcients βk for the kth risk.
Then identiﬁcation is obtained if one category is taken as a reference category.
Using the survivor category as reference, and assuming the βr do not contain
an intercept, would lead to
q(t ∈[aj−1, aj), Ci = 0) =
1
1 + K
r=1 exp(αjr + Zirβr)
,
q(t ∈[aj−1, aj), Ci = h|Zih) =
exp(αjh + Zihβh)
1 + K
r=1 exp(αjr + Zirβr)
,
h = 1, . . . , K,
where the parameters αjh describe the baseline hazard for risk. K-dimensional
versions of the correlated prior processes discussed in Section 9.3 may be used
for the αjh, for example, multivariate normal ﬁrst or second-order random
walks.
9.7.1
Modeling frailty
Assuming independent risks one may introduce unobserved frailties γik that
impact on each risk but are uncorrelated across risks, such as independent
gamma densities with mean 1 for each possible cause. Under proportionality,
the risk-speciﬁc hazard in a continuous time CR hazard is then
hk(ti|Zik) = γikh0k(ti) exp(Zikβk).
The assumption of independent risks may not hold in practice because
particular groups of subjects may be more likely to experience subsets of the
events. Just as it may be unrealistic in multinomial discrete choice situations
to assume independence of irrelevant alternatives (i.e., that ratios of choice
probabilities of any two alternatives are unaﬀected by changes in utilities
of any other alternatives, or by their removal), so it may be unrealistic in
survival analysis that the relative risks of two outcomes will be unaﬀected by
the removal of a third (Gordon, 2002).
To allow for dependent competing risks, especially for multiple spell
data, one may assume correlated or dependent frailties. In a generalization
of the MPH scheme, Abbring and van den Berg (2003) mention that the
joint distribution of (Ti1, . . . , Tik) given predictors Zik and correlated frail-
ties (γi1, . . . , γik) factorizes into independent densities f(Tk|Zik, {γi1, . . . , γik})
which are fully characterized by cause-speciﬁc hazard rates
h(Tk|Z, {γ1, . . . , γK}) = γkλk(t) exp(Zkβk).
Correlated frailties are also obtained by expanding the regression term to
a general mixed form, as in Section 9.4, so that in a continuous time analysis,
hk(ti|bik, Zik) = λk(ti) exp(βkZik + bik),

450
Applied Bayesian Hierarchical Methods
where bik are zero mean eﬀects that might be multivariate normal, discrete
mixtures of multivariate normal, etc. Assuming a multivariate normal with
covariance matrix Σb, dependent risks will be apparent in signiﬁcant oﬀ-
diagonal terms. Whether there are signiﬁcant correlations in the frailty eﬀects
over diﬀerent risks will depend in part on whether observed predictors success-
fully explain variations in event proneness. Another possibility is a common
frailty model with risk-speciﬁc loadings, so that
bik = λkbi,
where λk > 0 and bi ∼N(0, 1) for identiﬁcation.
Example 9.7. Political Careers
This example consider data on career
paths in U.S. House of Representative incumbents (Box-Steﬀensmeier and
Jones, 2004, 169) and adopts a discrete time approach to yearly data. The
data relate to all new incumbents during 1950–1976, and a competing risk
analysis is undertaken to possibly repeated events for each incumbent. There
are K = 4 types of career exit: these are k = 1 for loss in general election,
k = 2 for loss in primary election, k = 3 for retirement, and k = 4 for moves
to seek alternative oﬃce. The predictors are
Party: Republican (1), Democrat (0);
Redistrict: whether or not the incumbent’s district was substantially
redistricted;
Scandal: whether or not the incumbent was involved in scandal;
OpenGub: whether or not an open gubernatorial seat was available dur-
ing election cycle;
OpenSen: whether or not an open U.S. Senatorial seat was available
during election cycle;
Leadership: whether or not the incumbent had a leadership position in
the House;
Age (divided by 10);
Prior Margin: % of votes the incumbent (or party) received in his/her
previous election (divided by 10).
Baseline hazard time eﬀects are assumed to be quadratic in time with
coeﬃcients diﬀering across causes. Following Fukumuto (2005), the predictors
Zik are cause speciﬁc: the full set of predictors is used only for loss in general
election; for loss in primary election, the predictors (apart from time) are party
and age; for retirement, they are party and redistrict; and for alternative oﬃce
they are party, OpenGub, OpenSen, and Age.
The data are arranged so that each year’s observation for each incumbent is
a separate line, with the time variable incrementing until an exit occurs; there
are 5429 year-person records for 997 subjects. In a year when no type of exit

Survival and Event History Models
451
occurs, the categorical response Ci is 0. An independent competing risk model
(model 1) with ﬁxed eﬀects only is applied using a multiple logit link with
K + 1 possible outcomes, including no exit as the reference. This is compared
to a model (model 2) including multivariate normal frailty at subject level.15
So for years j = 1, . . . , Li for subject i, and with αjk = α0k + α1kj + α2kj2 as
the baseline hazard,
q(t ∈[aj−1, aj), Ci = 0) =
1
1 + K
h=1 exp(αjh + Zihβh + bih)
,
q(t ∈[aj−1, aj), Ci = k|Zik) =
exp(αjk + Zikβk + bik)
1 + K
h=1 exp(αjh + Zihβh + bih)
,
k = 1, . . . , K,
where (bi1, bi2, . . . , bik) ∼N(0, Σb).
A Wishart prior with identity scale matrix for Σ−1
b
is adopted for Σb.
Inferences are from the second half of a two chain run of 10,000 iterations.
The variances (diagonal terms in Σb) are estimated as 0.16 (0.12, 0.22), 0.70
(0.48, 0.90), 0.89 (0.73, 1.11), and 0.96 (0.80, 1.26). There is negative cor-
relation between risk 1 and risks 3 and 4; risk 2 is also negatively corre-
lated with the third and fourth risks. So there is departure from independent
risks. The DIC falls from 6340 (de = 25) for model 1 to 6160 (de = 236) for
model 2.
Appendix: Computational Notes
1. In WinBUGS one may transform observed failure or censoring times as
ri = log(ti), and to account for right-censoring deﬁne lower sampling limits
Li = log(ti) if di = 0, and Li = 0 if di = 1 and all failure times are at least
1. The lower limit Li may be set at a negative value rather than zero if some
failure times are between 0 and 1. Then a log-normal AFT regression involves
truncated sampling of the ri as in the WinBUGS code
model { for (i in 1:n) {r[i] ∼dnorm(mu[i],invsig2) I(L[i],)
mu[i] <- gam0+gam[1]*z[1,i]+· · · }}
while a log-logistic would use a logistic rather than normal model. The log-
normal or log-logistic AFT regression can be extended to allow ﬁnite mixtures
of survival densities, and hence model frailty (Section 9.4).
2. The WinBUGS code for the Weibull model of nursing home mortality (Ex-
ample 9.1) includes code to derive the log-likelihoods. Thus
model {for (i in 1 : 1601) {t[i] ∼dweib(kap, mu[i])I(t.cen[i],)
L[i] <- pow(f[i],1-cens[i])*pow(S[i],cens[i]); LL[i] <- log(L[i])
S[i] <- exp(-mu[i]*pow(t[i],kap)); f[i] <- mu[i]*kap*pow(t[i],kap-1)*S[i]

452
Applied Bayesian Hierarchical Methods
log(mu[i]) <- beta[1] + beta[2]*age[i]/100 + beta[3]*trt[i] + beta[4]*gender[i]
+ beta[5]*marstat[i] + c[hltstat[i]-1]}
kap ∼dgamma(1,1); TLL <- sum(LL[])
# impacts on exit rate
for (j in 1:5) {beta[j] ∼dnorm(0,0.01)}
c[1] <- 0; for (j in 2:4) {c[j] ∼dnorm(0,0.01); beta[4+j] <- c[j]}
# impacts on stay length
sigma <- 1/kap; for (j in 1:8) {gam[j] <- -beta[j]/kap}}
The BayesX code for the nursing home stay piecewise exponential model in-
volves recoding the categorical health status variable which has categories
2,3,4, and 5. Thus with category 2 as reference,
dataset d
d.inﬁle using data\nurshome.txt
d.generate hlth3 = 0
d.replace hlth3 = 1 if hlth=3
d.generate hlth4 = 0
d.replace hlth4 = 1 if hlth=4
d.generate hlth5 = 0
d.replace hlth5 = 1 if hlth=5
bayesreg b
b.regress d = t(baseline)+trt+sex+marr+hlth3+hlth4+hlth5+age(psp-
linerw2), family=cox predict using d
3. For illustration, deﬁne J +1 knots sited evenly along (0, tmax), where tmax is
the maximum observed time (including both exits and censored times). Also
set di = 1 for an observed exit at time ti and di = 0 for a censored time. A
generic WinBUGS code with a single predictor (omitting priors) is then
model { for (j in 1:J+1) {a[j] <- ranked(t[],n)*(j-1)/J}
for (i in 1:n) for (j in 1:J){ w[i,j] <- d[i]*step(t[i]-a[j])*step(a[j+1] - t[i])
# oﬀset term
o[i,j] <- (min(t[i],a[j+1])-a[j])*step(t[i]-a[j]);
# Poisson likelihood with oﬀset
w[i,j] ∼dpois(mu[i,j]);
mu[i,j] <- o[i,j]*lambda[j]*exp(beta[j]*z[i,j])}}}
4. To represent a generic BUGS code for n subjects, suppose exit or cen-
soring times are denoted t[i], the J distinct exit times as s[j], exit indicators as
d[i], and a single time varying predictor as z[i,j]. Then relevant functions and
the regression are deﬁned as follows, with a gamma increment prior on dH0j,
model { for (j in 1:J) { beta1[j] ∼dﬂat();beta2[j] ∼dﬂat();
for (i in 1:n) {Y[i,j] <- step(t[i] - s[j] + eps)
dN[i, j] <- Y[i, j] * step(s[j + 1] - t[i] - eps) * d[i]
dN[i, j] ∼dpois(mu[i, j]); mu[i,j] <- mu1[i,j]
mu1[i, j] <- Y[i, j] * exp(beta1[j] * z[i,j]) * dH0[j]
mu2[i, j] <- Y[i, j] * exp(beta2[j] * z[i,j] + alpha[j]) }
alpha[j] ∼dnorm(0,tau.alph); dH0[j] ∼dgamma(cstar[j], c)

Survival and Event History Models
453
cstar[j] <- dH0star[j] * c; dH0star[j] <- r * (s[j + 1] - s[j])}
# M[] are martingale residuals, dvres[] are deviance residuals
for (i in 1:n) { M[i] <- sum(dN[i,]) - sum(mu[i,]);
dvres[i] <- step(M[i])-1)*sqrt(2*(-M[i]-sum(dN[i,])*log((sum(dN[i,])-
M[i]))/M[i]))}}
In this code eps is a small positive constant and the hyperparameters {r,c}
may be preset or taken as unknowns. The code includes total Martingale
residuals M[i], namely the diﬀerence over the completed observation period
between the actual number of events for a subject and the expected number.
Martingale residuals are not symmetrically distributed, even when the ﬁtted
model is correct. The deviance residual dvres[] is a normalized transform of
the martingale residual that is more symmetric about zero. Observations with
large deviance residuals are poorly predicted by the model.
5. The WinBUGS code for the ﬁrst model applied to the Veterans data (Ex-
ample 9.2) is
model {for (j in 1:J+1){ a[j] <- ranked(t[],n)*(j-1)/J}
for (j in 2:J) {alph[j] ∼dnorm(alph[j-1],tau.0)}
tau.0 <- 1/sig2.0; sig.0 <- sqrt(sig2.0)
sig2.0 ∼dunif(0,100000000); alph[1] ∼dnorm(0,0.001)
for (i in 1:n) {KSr[i] <- KS[i]/10
for (j in 1:J){w[i,j] <- d[i]*step(t[i]-a[j])*step(a[j+1] - t[i]);
# oﬀset term
o[i,j] <- (min(t[i],a[j+1])-a[j])*step(t[i]-a[j]);
log(th[i,j]) <- alph[j]+b.cell[cell[i]] + b.PT[PT[i]] + b.KS*KSr[i] +
b.int*KSr[i]*(PT[i]-1)
# Poisson likelihood with oﬀset
mu[i,j] <- o[i,j]*th[i,j]; w[i,j] ∼dpois(mu[i,j])}}
# Priors:
b.KS ∼dnorm(0.0, 0.01); b.int ∼dnorm(0.0, 0.001);
b.PT[1] <- 0; b.PT[2] ∼dnorm(0.0, 0.0001);
b.cell[1] <- 0; for (k in 2:4) { b.cell[k] ∼dnorm(0.0, 0.0001)}}
6. The basic WinBUGS code is then
model { for (i in 1:n) {G[i]∼dcat(pi[1:K]);
r[i] ∼dnorm(mu[i],invsig2[G[i]]) I(L[i],)
mu[i] <- gam0[G[i]]+gam[1]*z[1,i]+...}}.
7. Consider log-logistic failure times as in Equation 9.5, with regression in
both the susceptibility and failure time aspects of the process, and respective
predictors w[1:n,1:Q] and z[1:n,1:P]. The basis of a WinBUGS code, includ-
ing the uniform trick for nonstandard densities (Barry, 2006), can then be as
follows:
model { for (i in 1:n) {# log-likelihood
log(L[i]) <- d[i]*log(pi[i]*f[i])+(1-d[i])*log(1-pi[i]+pi[i]*S[i])

454
Applied Bayesian Hierarchical Methods
logit(pi[i]) <- gam[1]+gam[2]*w[i,1]+..
log(nu[i]) <- beta[1]+beta[2]*z[i,1]+...
S[i] <- 1/(1+pow(nu[i]*t[i],alph))
log(f[i]) <- log(alph)+alph*log(nu[i])+(alph-1)*log(t[i])-2*log(1+pow(nu[i]
*t[i],alph))
y[i] <- 1; y[i] ∼dunif(A1[i],A2[i]); A1[i] <- -1/L[i]; A2[i] <- 1/L[i]}
# priors
for (j in 1:P) {beta[j] ∼dﬂat()}; for (j in 1:Q) {gam[j] ∼dﬂat()}
alph ∼dgamma(a.alph,b.alph)}
8. This model can be applied using the uniform trick (Barry, 2006) in the
following WinBUGS code, with predictors w[1:n,1:Q] and z[1:n,1:P], both in-
cluding a constant, a Ga(1,0.01) prior on the Weibull shape parameter, and
L[i] denoting likelihoods:
model { for (i in 1:n) {log(th[i]) <- gam[1]+gam[2]*w[i,1]..;
log(lam[i]) <- beta[1]+beta[2]*z[i,1]+...
log(L[i]) <- d[i]*(log(th[i])+log(kap)+log(lam[i])
+(kap-1)*log(t[i])-lam[i]*pow(t[i],kap))-th[i]*(1-exp(-lam[i]*pow(t[i],kap)))
z[i] <- 1; z[i] ∼dunif(G[i],H[i]); G[i] <- -1/L[i]; H[i] <- 1/L[i]}
# priors
for (j in 1:P) {beta[j] ∼dﬂat()}; for (j in 1:Q) {gam[j] ∼dﬂat()}
kap ∼dgamma(1,0.01)}
9. The code for the ﬁnal analysis in Example 9.3 (age at ﬁrst maternity) is
model { for (i in 1:n) {Sstar[i] <- exp(-th*F[i]); fstar[i] <- th*f[i]*Sstar[i]
b[i] ∼dnorm(0,tau.b); F[i] <- 1-1/(1+lam[i]*pow(t[i],kap))
log(f[i]) <- log(kap)+log(lam[i])+(kap-1)*log(t[i])-2*log(1+lam[i]*pow(t[i],
kap))
log(lam[i]) <- beta[1]+beta[2]*educ[i]+beta[3]*sibs[i]+beta[4]*white[i]
+beta[5]*immig[i]+beta[6]*lowinc[i]+beta[7]*city[i]+b[i]
# log-likelihood
log(L[i]) <- d[i]*log(fstar[i])+(1-d[i])*log(Sstar[i]); LL[i] <- log(L[i]);
H[i] <- 1/L[i]; G[i] <- -1/L[i]; z[i] <- 1; z[i] ∼dunif(G[i],H[i])}
Dv <- -2*sum(LL[]); p.nochild <- exp(-th)
# regn function, hazard and modal age (modeT) for “typical” individual
log(lamT) <- beta[1]+beta[2]*13+beta[3]*3+beta[4]
for (age in 15:50) {log(hazT[age]) <-
log(lamT)+log(kap)+(kap-1)*log(age)-log(1+pow(age,kap)*lamT)}
modeT <- pow((kap-1)/lamT,1/kap)
# priors
th ∼dgamma(1,0.01); for (j in 1:P) {beta[j] ∼dﬂat()}
kap ∼dgamma(1,0.01); sig.b <- 1/sqrt(tau.b); tau.b∼dgamma(1,0.01)}
Taking the negative of the logs of the posterior means of H[i] in the above
code provides Monte Carlo estimates of log(CPO) statistics and (on totalling
over subjects) a pseudo log marginal likelihood.

Survival and Event History Models
455
10. In Example 9.4 (cancer survival), let t[i] denote time of death or censoring,
and d[i] be binary according to whether death is observed. The code (including
options on modeling time eﬀects) is
model {for (i in 1:n) {w[i,t[i]] <- d[i]; for (j in 1:t[i]-1) {w[i,j] <- 0}
for (j in 1:t[i]) {w[i,j] ∼dbern(q[i,j])
# alternative time eﬀects (Weibull or semi-parametric)
# cloglog(q[i,j]) <- beta0+beta[1]*drug[i]+beta[2]*age[i]/100 + kap*log(j)
cloglog(q[i,j]) <- beta0+beta[1]*drug[i]+beta[2]*age[i]/100 + a[j]}}
beta0 ∼dnorm(0,0.001); for (j in 1:2) {beta[j] ∼dnorm(0,0.001)}
tau.a ∼dgamma(1,0.001); sig.a <- 1/sqrt(tau.a); kap ∼dgamma(1,0.001)
# RW1 prior with centered values
a[1:J] ∼car.normal(adjage[],wage[],nage[],tau.a)
adjage[1] <- 2; adjage[(J-1)*2] <- J-1;
for (j in 2:J-1) {adjage[2+(j-2)*2] <- j-1; adjage[3+(j-2)*2] <- j+1}
for (j in 1:J) {alph[j] <- beta0+a[j]
alphtr[1,j] <- alph[j]; alphtr[2,j] <- alph[j]+beta[1]}}
11. The BUGS code to generate the simulated data is
model {for (i in 1: n) { b[i]∼dnorm(0,tau.b)
x[i]∼dnorm(0,1); u[i] ∼dnorm(0,1)I(0,)
for (j in 1:m) {t[i,j] ∼dweib(kap[j],lam[i,j]);
log(lam[i,j]) <- beta1[j]+beta2[j]*x[i]+b[i]+ delta*u[i]}}}
with input values β1 = (−5, −6), β2 = (0.5, 1), κ = (1.5,2), δ = 0.5, and
1/σ2
b = τb = 2, so that σb ≃0.7. The simulated values of t[ ] and x[ ] are
obtained using gen inits/save state, and then the model is re-estimated using
the code:
model {for (i in 1: n) { b[i]∼dnorm(0,tau.b); u[i]∼dnorm(0,1)I(0,)
for (j in 1:m) {t[i,j]∼dweib(kap[j],lam[i,j])
log(lam[i,j]) <- beta1[j]+beta2[j]*x[i]+b[i]+ delta[j]*u[i]}}
for (j in 1:m) { delta[j] ∼dunif(0,5); kap[j] ∼dgamma(1,0.001);
beta1[j] ∼dnorm(0,0.001) ; beta2[j] ∼dnorm(0,0.001) }
tau.b ∼dgamma(1,0.001)}
with initial values ﬁle list(beta1=c(-5,-5),kap=c(1,1),beta2=c(0,0),delta=1,
tau.b=1).
12. An example of the computation involves repeated times to mammary tu-
mor in rats randomly assigned to treatment and control groups (Sinha, 1993).
Totals of tumors diagnosed in each rat vary between 0 and 13; so spell totals
for each rat (including possibly censored ﬁnal spells) range from 1 to 14. There
are n = 253 spells in all for K = 48 rats, and J = 35 distinct times relevant
to deﬁning the intervals, with aJ = tmax = 182. A code for such an analysis,
including gamma frailty for each rat, a treatment covariate, and indicators
d[i] of tumor occurrence or censoring, is
model {for (j in 1:J) { for(i in 1:n) {# Y indicates whether case still at
risk

456
Applied Bayesian Hierarchical Methods
Y[i,j] <- step(t[i] - a[j] + eps)
dN[i, j] <- Y[i, j] * step(a[j + 1] - t[i] - eps) * d[i]
dN[i, j] ∼dpois(lam[i, j])
lam[i, j] <- Y[i, j] * exp(beta * trt[i]) * dB0[j] * gam[rat[i]]}
# independent increment gamma process
dB0[j] ∼dgamma(mu[j], c); mu[j] <- dB0.star[j] * c
dB0.star[j] <- M * (a[j + 1] - a[j])
# Survivorship in two groups
S.tr[j] <- pow(exp(-sum(dB0[1 : j])), exp(beta));
S.cntr[j] <- exp(-sum(dB0[1 : j]))}
c <- 1; M ∼dexp(1); beta ∼dnorm(0,0.001)
# frailty prior
for (k in 1:K) {gam[k] ∼dgamma(h,h)}
h ∼dgamma(1,0.001); vargam <- 1/h; th <- exp(beta)}
where eps is a small positive value to ensure at risk and counting indices
are correctly deﬁned. The gamma process includes an unknown parameter M
deﬁning the mean intensity.
13. The code in Example 9.5 (clustered trial of infection treatment) assumes
data in stacked rather than nested form. Then the code, with centered hospital
eﬀects denoted u.r[], is
model {for (i in 1:n) { for (k in 1:J) {# risk status for subject i at interval k,
y[i,k] <- d[i]*step(t[i] - a[k])*step(a[k+1] - t[i])
# time spent in interval k
o[i,k] <- (min(t[i], a[k+1]) - a[k])*step(t[i] - a[k])
# piecewise exponential
theta[i,k] <- lam[k]*exp(beta*trt[i]+e[pat[i]]+u[hos[i]])
mu[i,k] <- o[i,k]*theta[i,k]; y[i,k] ∼dpois(mu[i,k]);
# likelihood (nu used to avoid logs of zero)
nu[i,k] <- equals(mu[i,k],0) +(1-equals(mu[i,k],0))*mu[i,k]
LL[i,k] <- y[i,k]*log(nu[i,k])-mu[i,k]-logfact(y[i,k])}}
# multi-level variation: patient eﬀects
for (j in 1:L) {e[j]∼dnorm(0,tau.e); e.r[j] <- e[j]-mean(e[])}
# hospital eﬀects
for (k in 1:M) {u[k] ∼dnorm(0,tau.u); u.r[k] <- u[k]-mean(u[])}
V ∼dunif(0,100); r ∼dunif(0,1); sig2.u <- r*V; sig2.e <- V-sig2.u
tau.e <- 1/sig2.e; tau.u <- 1/sig2.u
sig[1] <- 1/sqrt(tau.e); sig[2] <- 1/sqrt(tau.u)
# correlated process prior on baseline hazard
for (k in 2:J) {lam[k] ∼dgamma(a0, b0[k]); b0[k] <- a0/lam[k-1]}
lam[1] ∼dgamma(0.1,0.1)
# treatment parameter
beta ∼dnorm(0, 0.001); a0∼dgamma(0.1,0.1)
# Cum Hazard and Survivorship
H0[1] <- lam[1]*a[1]; for (k in 2:J) {H0[k] <- lam[k]*(a[k]-a[k-1])}

Survival and Event History Models
457
for (j in 1:J) {S[1,j] <- pow(exp(-sum(H0[1:j])), exp(beta))
S[2,j] <- exp(-sum(H0[1:j]))}
# deviance
Dv <- -2*sum(LL[,])}
14. For example, after creating a ﬁle vi.csv with columns headed t1, t2, d1,
and d2, the commands for the ﬁrst eye survival times ti1 are
vis <- read.csv(“vi.csv”, header = TRUE)
vis.inp <- Surv(vis$t1,vis$d1)
KM.vis <- survﬁt(vis.inp)
t <- KM.vis$time
S <- KM.vis$surv
plot(log(t),log(-log(S)),type=“S”).
For the Weibull survival analysis the data are arranged in successive lines
for each patient, one line for each eye. The predictors are at patient level,
namely age at diagnosis of diabetes, and type of diabetes (type 1 or 2), and
the eye-level variable, treatment (0=untreated eye, 1=treated eye). The Win-
BUGS code for the bivariate survival model allows diﬀerent shape parameters
for each eye, namely
model {for (i in 1:n) {b[i] ∼dnorm(0, tau.b)
for (j in 1:m) {t[i,j] ∼dweib(kap[j],lam[i,j]) I(t.cen[i,j],)
tnew[i,j] ∼dweib(kap[j],lam[i,j])
log(lam[i,j]) <- beta[1] + beta[2] *age[i]/10 + beta[3]*trt[i,j]+beta[4]
*type[i]+b[i]
S[i,j]
<-
exp(-lam[i,j]*pow(t[i,j],kap[j]));
h[i,j]
<-
kap[j]*lam[i,j]
*pow(t[i,j],kap[j]-1)
# log-likelihood and inverse likelihood
LL[i,j] <- d[i,j]*log(h[i,j])+log(S[i,j]); g[i,j] <- 1/exp(LL[i,j])}}
Dv <- -2*sum(LL[,]);
# Excess risk for untreated patients
th <- exp(-beta[3])
# uniform prior on SD(frailty)
sig.b∼dunif(0,10); tau.b <-1/(sig.b*sig.b);
for (j in 1:2) {kap[j] ∼dgamma(1,0.001)}
for (j in 1:4) {beta[j]∼dnorm(0, 0.001)}}
15. The code for the second model in Example 9.7 (Political Careers) with
K=4 risks, KP=K+1, and P=11 predictors, is
model { for (i in 1:5429) {Y[i] <- C[i]+1; Y[i] ∼dcat(p[i,1:KP])
dv[i] <- log(p[i,Y[i]]); D[i] <- (1+sum(ph[i,1:K])); p[i,1] <- 1/D[i]
for (k in 1:K) {p[i,k+1] <- ph[i,k]/D[i]
log(ph[i,k]) <- beta[k,1]+beta[k,2]*rep[i]+beta[k,3]*redist[i]
+beta[k,4]*scand[i]+beta[k,5]*opengov[i]
+beta[k,6]*opensen[i]+beta[k,7]*lead[i]
+beta[k,8]*age[i]/10+beta[k,9]*primrg[i]/10

458
Applied Bayesian Hierarchical Methods
+beta[k,10]*time[i]+beta[k,11]*time[i]*time[i]+b[subj[i],k]}}
for (i in 1:997) {b[i,1:4] ∼dmnorm(nought[],T.b[,])}
T.b[1:4,1:4] ∼dwish(Q[,],4); Sig.b[1:4,1:4] <- inverse(T.b[,])
for (k in 1:4) {nought[k] <- 0; for (m in 1:4) {Q[k,m] <- equals(k,m)}
# inc[k,m] deﬁne included predictors for particular risks
for (m in 1:P) {gam[k,m] ∼dnorm(0,0.001); beta[k,m] <- inc[k,m]*gam[k,m]}}
Dev <- -2*sum(dv[])}

10
Hierarchical Methods for Nonlinear
Regression
10.1
Introduction
Standard versions of the normal linear model and general linear models assume
additive and linear predictor eﬀects in the regression mean, and a constant
variance. While linear regression eﬀects are often suitable, nonlinear predictor
eﬀects and heteroscedasticity are common in areas as diverse as economics,
hydrology (Qian et al., 2005), and epidemiology (Natario and Knorr-Held,
2003). Simple nonlinear forms such as polynomials or logarithmic transfor-
mations of predictors or responses may often be suitable, but arguably are
seeking to provide a global parameterization when local ﬂexibility is needed
to reproduce observed reponse patterns (Beck and Jackman, 1998). In some
applications there may be a theoretical basis for a particular form of nonlin-
earity, though some elements of speciﬁcation will be uncertain—see Borsuk
and Stow (2000) for an example on biochemical oxygen demand and Meyer
and Millar (1998) for models of ﬁshery stock.
In other situations the form of nonlinearity is unknown and to be assessed
from the data—hence the term “nonparametric” since a particular form for
the mean function is not assumed. In many applications, a nonlinear eﬀect is
present or suspected in only a subset of predictors leading to partially linear
models or semiparametric regression models (Beck and Jackman, 1998, 600).
Consider outcomes {yi, i = 1, . . . , n} from an exponential density:
p(yi|θi, φ) = exp

yiθi −a(θi)
φ
+ c(yi, φ)

with E(yi) = µi = a′(θi) and link g(µi) = ηi to a regression term ηi. Sup-
pose it is intended that R metric predictors (w1i, w2i, . . . , wRi) be modeled
nonparametrically via unknown smooth functions S(wri),
g(µi) = ηi = α + Xiβ + S1(w1i) + · · · + SR(wRi) + ui,
with ui ∼N(0, σ2). For instance, Engle et al. (1986) analyze the relation-
ship between temperature and monthly electricity sales (y metric and u nor-
mal, and with g an identity link) for four US cities. The impact of electricity
459

460
Applied Bayesian Hierarchical Methods
price, month (11 dummy variables), and income is modeled parametrically,
but an unknown smooth function is adopted to model the impact of monthly
temperature.
Residual errors ui will be present when yi is metric and may also be present
for overdispersed discrete outcomes. While an assumption of independent
errors with constant variance is standard, nonparametric regression for the
regression mean may be extended to modeling heteroscedastic errors (Yau and
Kohn, 2003). When the observations are taken through time or over space it
may also be important to control for correlations in the u. Kohn et al. (2000)
and Smith et al. (1998) consider the case when the observations yt are ar-
ranged in time, smooth functions are used for predictor eﬀects, and the ut are
autocorrelated; the estimate of the smooth function will be adversely aﬀected
if independent residuals are incorrectly assumed.
The two major forms of nonparametric regression involve basis functions
(e.g., polynomial spline methods) and general additive methods based on
smoothness priors; these are considered in Sections 10.2 and 10.5, respec-
tively. Extending nonparametric regression to multiple predictors raises the
same issues as multiple linear regression, for example, whether interactions
are necessary and how the presence of smooths for other predictors alters the
smooth for a given predictor—see Section 10.3. Robustness in nonparametric
regression (e.g., to heteroscedastic errors) may be obtained through spatially
adaptive methods which allow the level of smoothness to vary over the space
of the covariates (Baladandayuthapani et al., 2005; Wood et al., 2002)—see
Section 10.4. A major application area for nonparametric regression is in lon-
gitudinal settings, as discussed in Section 10.6.
10.2
Nonparametric Basis Function Models
for the Regression Mean
A wide range of methods for nonparametric regression in one or more pre-
dictors typically assume linear combinations of basis functions Sr(wr) of
predictors (w1, . . . , wR). Numerous basis functions can be used, including
truncated polynomial functions, B-spline functions, radial basis functions
(Yau et al., 2003), logistic functions (Hooper, 2001), trigonometric basis func-
tions, and wavelets (Dennison et al., 2002). For exponential family responses
yi with mean µi and link g, a truncated polynomial spline (or piecewise poly-
nomial spline) regression on a single predictor wi has the form (Dennison
et al., 2002, 52):
g(µi) = α +
K

k=1
βk(wi −κk)q
+ + ui,
(10.1)

Hierarchical Methods for Nonlinear Regression
461
where ui ∼N(0, σ2), q is a known positive integer, and the κk are knots placed
within the range [wmin, wmax] of w. In Equation 10.1, the piecewise polynomi-
als are ﬁtted in each interval [κk, κk+1) and preferably join smoothly at each
knot (e.g., this applies for a cubic spline as it has continous ﬁrst and second
derivatives at each knot).
An alternative spline speciﬁcation (e.g., Meyer, 2005; Tutz and Reithinger,
2007, 2877) matches the degree q of the truncated function T(wi)
=
K
k=1 βk(wi −κk)q
+ by a standard polynomial of order q, namely Q(wi) =
ϕ1wi + · · · + ϕqwq
i . So the total smooth is
S(wi) = Q(wi) + T(wi)
and one has
g(µi) = α + ϕ1wi + · · · + ϕqwq
i +
K

k=1
βk(wi −κk)q
+ + ui.
(10.2)
Values q = 1, 2, or 3 are most typical with q = 1 often being suitable for repro-
ducing a smooth function given a large enough set of knots (Ruppert et al.,
2003, 68), but also capable of reproducing abrupt changes in the underlying
function (Denison et al., 2002, 52).
The knots in Equations 10.1 and 10.2 may be known, or unknown. If
known, then they are typically much less than the sample size in number.
They could be sited at percentile points (e.g., deciles) of w, or possibly placed
more densely at points where the function is known to be rapidly changing
and less densely elsewhere. Choosing too few knots can result in oversmooth-
ing and choosing too many in overﬁtting—see the light detection and ranging
(LIDAR) data examples discussed by Ruppert et al. (2003, 63). Coull et al.
(2001, 540) suggest allocation of one knot for every four to ﬁve observations,
up to a maximum of about 40 knots. Yau and Kohn (2003) suggest ﬁtting
a model with a small number of knots ﬁrst and gradually increasing their
number until estimates and ﬁt stabilize. An alternative procedure known as
smoothing splines places a knot at every observed distinct predictor value
(Berry et al., 2002; Dias and Gamerman, 2002). The most general model-
averaging approach takes both the number of knots and their sitings as un-
knowns, while both Biller (2000) and Denison et al. (1998) assume a large
number of potential but prespeciﬁed candidate knot locations. If knots are
taken to have unknown locations within [wmin, wmax], identiﬁcation may rely
on order constraints such as κk > κk−1 and analysis resembles time series with
multiple change points.
Assuming the βk in Equations 10.1 through 10.3 are modeled as ﬁxed
eﬀects, predictor coeﬃcient selection is open as a way of achieving model
parsimony, and is especially indicated under the smoothing spline method
(Smith and Kohn, 1996). With a large number of preset potential knot sitings,
predictor selection involves obtaining posterior probabilities Pr(δjk = 1|y)

462
Applied Bayesian Hierarchical Methods
on binary indicator variables δ1k (k = 1, . . . , q) for retaining coeﬃcients in
the Q(w) component and δ2k (k = 1, . . . , K) in the T(w) component. One
then has
g(µi) = α + δ11ϕ1wi + · · · + δ1qϕqwq
i +
K

k=1
δ2kβk(wi −κk)q
+ + ui,
(10.3)
with coeﬃcients estimated by means of the products δ1jϕj and δ2kβk.
10.2.1
Mixed model splines
By contrast to models 10.1 through 10.3 where all coeﬃcients are ﬁxed eﬀects,
under the mixed model spline regression, or penalized spline method, the
coeﬃcients in Q(wi) usually remain ﬁxed eﬀects, but the coeﬃcients in T(wi)
follow a penalizing random eﬀects or P-spline prior (Brumback et al., 1999;
Ruppert et al., 2003; Wand, 2003). In Yau and Kohn (2003) all coeﬃcients are
treated as random, e.g., both ϕ and b in Equation 10.5. Currie and Durban
(2002) argue that under a P-spline approach the problem of choosing the
number and position of the knots is largely overcome, since providing enough
knots are used, the penalty function should ensure that the resulting ﬁts are
very similar. Under the P-spline approach, Equations 10.1 and 10.2 become
g(µi) = α + S(wi) = α +
K

k=1
bk(wi −κk)q
+ + ui,
(10.4)
g(µi) = α + ϕ1wi + · · · + ϕqwq
i +
K

k=1
bk(wi −κk)q
+ + ui,
(10.5)
where bk is a collection of random parameters from a common density with
unknown hyperparameters.
Possible priors for the random bk include an unstructured normal (Currie
and Durban, 2002; Ruppert et al., 2003)
bk ∽N(0, φ),
(10.6)
which, by comparison with a ﬁxed eﬀects prior, imposes a restriction on the
bk when φ < ∞and tends to shrink the bk leading to a smooth ﬁt (Wand,
2003). A common choice for φ is an inverse gamma prior, or a gamma prior
may be used for θ = 1/φ. A standard approach recommended by Lang and
Brezger (2004) is φ ∼IG(g, h) with g = 1 and h small (e.g., 0.001, 0.0001 or
0.00001), though Jullion and Lambert (2007) report sensitivity to the value
chosen for h. Jullion and Lambert (2007) suggest a prior θ ∼Ga( ν
2, δ ν
2) with
ν ∼U(0, K) with K large (e.g., 100) and δ ∼Ga(gδ, hδ) with gδ = hδ taken
small. They also suggest a mixture prior over alternative plausible values of h
in the prior φ ∼IG(1, h).

Hierarchical Methods for Nonlinear Regression
463
To illustrate equivalence to mixed models, deﬁne design matrices
W = [1, wi, . . . , wq
i ]
1≤i≤n
,
Z = [(wi −κk)q
+]
1≤k≤K, 1≤i≤n
and vectors β = (α, ϕ1, . . . , ϕq)′ and b = (b1, . . . , bK)′. Then under normal
error assumptions, model Equation 10.5 can be written in the mixed model
form:
g = Xβ + Zb + u,

b
u

∼N

0
0,

φI
0
0
σ2I

.
Opsomer et al. (2008) extend this framework to encompass random area
eﬀects relevant for small area estimation in survey data modeling.
Alternatives schemes for bk are a random walk penalty (Eilers and Marx,
1996), such as ∆dbk ∽N(0, φ). For instance, taking d = 1 gives
bk ∽N(bk−1, φ).
(10.7)
Another option providing monotonic smooths in applications where such
smooths have a substantive rationalization (Brezger and Steiner, 2008) invol-
ves monotonically constrained bk. Thus one may have bk ∽N(0, φ), but sub-
ject to
bk ≥bk−1,
k = 2, . . . , K
for an increasing function T(wi) = K
k=1 bk(wi −κk)q
+ or bk ≤bk−1 for a
decreasing function. Brezger and Steiner argue that unconstrained estimation
of spline models (with nonmonotonic bk) may produce artifactual features
(e.g., local upturns and downturns in a dose–response or economic relations
at odds with substantive knowledge) due to sparse data and “overﬁtting” due
to excess ﬂexibility in the smooth function.
The function S(wi) resulting from a ﬁxed eﬀects prior on {βk} in Equa-
tions 10.1 through 10.3 may be quite rough, due to the large number of trun-
cated polynomials being ﬁtted, whereas the shrinkage prior under the mixed
model approach tends to penalize large coeﬃcients and lead to a smoother ﬁt
(Meyer, 2005; Ngo and Wand, 2004; Yau et al., 2003). Under an unstructured
prior bk ∼N(0, φ), and smoothing or penalty parameter λ, the mode of the
posterior density of {ϕ, b, φ} is the same as that obtained by maximizing a
penalized likelihood:
PL = log[P(y|ϕ, b, φ)] −λ
K

k=1
b2
k,
where the form of λ (in terms of variance parameters) depends on whether
or not there is an unstructured residual term ui in the regression model.

464
Applied Bayesian Hierarchical Methods
For a metric outcome and ui ∼N(0, σ2), one has λ = σ2/φ (Fahrmeir and
Knorr-Held, 2000). This penalized likelihood is analogous to “ridge” penal-
ties sometimes used with correlated predictors (Eilers and Marx, 2004). For
random walk priors of order d, one has (Lang and Brezger, 2004)
PL = log[P(y|ϕ, b, φ)] −λ
K

k=d+1
(∆dbk)2.
10.2.2
Model selection
Nonparametric regressions are often heavily parameterized and parameter
redundancies are likely (Belitz and Lang, 2008; Panagiotelis and Smith, 2008;
Yau et al., 2003). As a simple approach, one might consider examining a pro-
ﬁle of penalized likelihoods for a series of values of φ, including the null value
φ = 0 corresponding to the spline term being unnecessary. Taking φ as an
unknown is more general, and one option, following Albert and Chib (1997),
is a discrete prior on alternative values of φ that include φ = 0. Yau et al.
(2003) discuss variable and model selection in nonparametric basis models
using binary indicators Jr for retaining or dropping the random eﬀect term
for the rth of R predictors. So for r = 1, . . . , R predictors modeled by smooths
Sr(wri) = Qr(wri)+Tr(wri), where Tr(wri) = Kr
k=1 brk(wri−κrk)qr
+ the model
including random component selection indices would be
g(µi) = α + Q1(w1i) + · · · + QR(wRi) + J1T1(w1i) + J2T2(w2i)
+ · · · + JRTR(wRi) + ui
= α +
R

r=1
Qr(wri) + J1
K1

k=1
b1k(w1i −κ1k)q1
+
+ J2
K2

k=1
b2k(w2i −κ2k)q2
+ · · · + JR
KR

k=1
bRk(wRi −κRk)qR
+ + ui.
Yau et al. (2003) mention that selection for retention (Jr = 1) is inﬂuenced
by the degree of informativeness of the prior adopted for the variances φr of
br = (br1, . . . , brKr). Flat priors will tend to lead to low posterior probabilities
Pr(Jr = 1|y) for retaining random components. They suggest initial runs
with diﬀuse priors to develop an informative data-based prior. Suppose the
Markov Chain Monte Carlo (MCMC) iterates h = 1, . . . , H from the initial
run were φ(1)
r , φ(2)
r ,. . . , φ(H)
r
. A possible data-based prior in a subsequent run
is log-normal with
p(φr|mr, Vr) =
1
φr
√2πnVr
exp

−
1
2nVr
(log(φr) −mr)2

,
where (mr, Vr) are the posterior median and variance of the logged variances
from the initial run, log(φ(1)
r ), log(φ(2)
r ), . . . , log(φ(H)
r
). The use of a data-based

Hierarchical Methods for Nonlinear Regression
465
prior with inﬂation of the variance Vr by the sample size n follows the devel-
opment of Shively et al. (1999) who relate the resulting posterior selection to
the Bayesian Information Criterion (BIC). Related approaches include Pana-
giotelis and Smith (2008) who adopt hierarchical log-normal priors on φr,
namely
log(φr) ∼N(ar, br),
ar ∼N(0, 100),
br ∼IG(101, 10100),
independent of those for Jr.
10.2.3
Basis functions other than truncated polynomials
The ﬁxed or random coeﬃcient approaches can equally be applied with other
basis functions to represent T(wi). Truncated polynomial basis functions span
the space of degree q polyomials with knots located at κ1, . . . , κK (Friedman,
1991). This property also holds for radial basis functions based on distances
rik = |wi −κk|, such as the polyharmonic spline T(wi) = K
k=1 H(rik), with
H(rik) = rq
ik,
q = 1, 3, 5, . . .
H(rik) = rq
ik log(rik),
q = 2, 4, 6,
of which the thin plate spline (Kohn et al., 2001; Koop and Tole, 2004)
H(rik) = r2
ik log(rik)
is a special case. These are examples of functions which are radially symmetric
around knots κk, such that the value of the function at wi depends only on
the distance between wi and the knot location. They have the form H(u) =
H(|w −κk|), where |v| =
√
v′v is the length of the vector v. Other types of
radial basis include Gaussian functions (Konishi et al., 2004) with
Hk(wi) = exp

−|w −κk|
2νηk

,
where ν is the same over diﬀerent knots. As for truncated splines, smoothing
based on radial basis functions may include a parametric polynomial term to
degree q to match the degree of the radial function. For example, with q = 1:
g(µi) = α + ϕ1wi +
K

k=1
βk|wi −κk| + ui.
Both radial and truncated power splines may be ill-conditioned in terms of
broader regression considerations (Eilers and Marx, 2004). An alternative ba-
sis less prone to ill-conditioning is provided by B-splines, with health mapping

466
Applied Bayesian Hierarchical Methods
applications exempliﬁed by MacNab and Gustafson (2007) and Silva et al.
(2008). B-splines are deﬁned to be nonzero for at most q + 2 interior knots for
a qth degree B-spline (also called a B-spline of order q + 1), which means the
condition number of the design matrix product is relatively low (Biller, 2000;
Dennison et al., 2002, 75; Eilers and Marx, 1996, 90). A B-spline of degree
q consists of q + 1 polynomial pieces of degree q and overlaps with 2q of its
neighbors. For K knots, and so K + 1 intervals, in the domain [wmin, wmax]
of a predictor, there will be K∗= K + 1 + q B-spline schedules because extra
knots are placed outside the domain of w to get q overlapping B-splines in
each interval.
Let Bk(wi, q) be the value at wi of the kth B-spline of degree q, with
k = 1, . . . , K∗. Successive B-spline values are deﬁned by the recursion
Bk(wi, 0) = I(κk ≤wi < κk+1)
Bk(wi, q) =
wi −κk
κk+q −κk
Bk(wi, q −1) +
κk+q+1 −wi
κk+q+1 −κk+1
Bk+1(wi, q −1).
The initial terms in the recursion are simply binary indicators deﬁning
a partition of the w values. For equally spaced knots a simpliﬁed B-spline
recursion applies involving diﬀerences in truncated power splines (Eilers and
Marx, 2004).1
B-spline bases for T(w) can be combined with random or ﬁxed eﬀects
priors for the spline coeﬃcients; for example, random bk in an analysis with
a single predictor wi leads to
g(µi) = α + ϕ1wi + · · · + ϕqwq
i +
K∗

k=1
bkBk(wi, q) + ui.
In particular, Eilers and Marx (1996) combine a B-spline basis with a
penalty on dth-order diﬀerences in adjacent bk coeﬃcients. As mentioned
above, diﬀerence penalties can be achieved by random walk priors under a
Bayesian approach (e.g., a second-order random walk prior if d = 2).
Bayesian application of spectral (Fourier series) basis functions is discussed
by Fahrmeir and Tutz (2001, chap. 5), Kitagawa and Gersch (1996), and Lenk
(1999). Here the smooth may be represented by the series
T(wi) =
∞

k=1
bkHk(wi),
with Hk including sine and/or cosine terms. Setting zi = (wi −wmin)/
(wmax −wmin) and including only cosine terms in Hk as in Lenk (1999) gives
Hk(wi) =

2
wmax −wmin
0.5
cos(πkzi).
Since a smooth T will not have high-frequency components, a natural prior
on the bk expresses decay as k increases (penalizes terms at higher k values)
as in

Hierarchical Methods for Nonlinear Regression
467
bk ∽N(0, φ exp[−δck]),
where ck can be taken as a known increasing function of k, and δ determines
the rate of decay of the Fourier coeﬃcients. Possibilities are ck = log(k) with
δ > 1, and ck = k with δ > 0. An alternative is a power function such as
bk ∽N(0, φδk),
where δ ∈(0, 1). Sampling of parameters is from standard densities except for
the decay parameter δ, for which Lenk (1999) uses slice sampling. For practical
application, the Fourier Series is truncated above at K, namely
T(wi) =
K

k=1
bkHk(wi).
where K can be regarded as another parameter (cf. Ruppert et al., 2003, 86).
Example 10.1. Fossil Data
This example concerns a continuous out-
come, namely ratios Y of strontium isotopes in fossil shells, with shell age
as predictor (Ngo and Wand, 2004; Ruppert et al., 2003), and with response
transformed as y = 100,000Y −70,700. The initial analysis compares a linear
truncated spline with a cubic B-spline (q = 3 in Bk(wi, q)). These two models
are ﬁtted in WinBUGS using K = 19 knots sited at the 5th, 10th,. . . ,95th
percentiles of age. So the linear spline model is
yi = α + ϕ1Agei +
19

k=1
bk(Agei −κk)+ + ui,
where ui ∼N(0, σ2). In the truncated spline model an unstructured normal
random eﬀect prior bk ∼N(0, φ) is assumed on the spline coeﬃcients, while
the B-spline model assumes a ﬁrst-order random walk, penalizing ﬁrst diﬀer-
ences in the bk, and with b1 assigned a diﬀuse N(0, 1000) prior. A linear term
in age is also included. For precisions 1/σ2 and θ = 1/φ, gamma Ga(1,0.001)
priors are assumed.2
The Bayesian version of the cubic P-spline method of Eilers and Marx
(1996) as implemented in BayesX is also applied3—see Brezger and Lang
(2006) and Lang and Brezger (2004). In this analysis, inverse gamma priors
on the variance parameters have shape and scale parameters both set at 0.001.
Furthermore, there are K = 20 equally spaced knots in the domain of age,
and a second-order random walk penalty is used for the B-spline coeﬃcients.
The last 40,000 iterations of two chain runs of 50,000 iterations in
WinBUGS show similar smooths, but with ﬁt values favoring the truncated
linear spline. The respective DIC (and de) values are 511 (12) and 517 (16.1).
Figure 10.1 shows the B-spline ﬁt. The BayesX implementation of a B-spline
smooth gives a DIC (de) of 510.3 (13.0), with the corresponding smooth shown
in Figure 10.2.

468
Applied Bayesian Hierarchical Methods
70715
70720
70725
70730
70735
70740
70745
70750
70755
90
95
100
105
110
115
120
125
Age
Strontium ratio
Fitted
Actual
FIGURE 10.1
B-spline ﬁt and observations.
70720
70725
70730
70735
70740
70745
70750
70755
90
95
100
105
110
115
120
125
Age
Prediction
Actual
FIGURE 10.2
BayesX smooth for fossil data.
10.3
Multivariate Basis Function Regression
Generalization of Bayesian basis function methods to multiple metric pre-
dictors follows three main methodologies. The ﬁrst involves tensor product-
truncated polynomial bases, including the multivariate adaptive regression

Hierarchical Methods for Nonlinear Regression
469
spline (MARS) method of Friedman (1991); the second is the generalization
of radial basis methods (e.g., Yau et al., 2003); and the third is the general-
ization of mixed model P-splines (e.g., Durban et al., 2006). The full tensor
product approach is a multiplicative generalization of Equation 10.2 or 10.5,
with particular versions discussed by Brezger et al. (2005), Chen (1993), Den-
nison et al. (2002, 104), Ruppert et al. (2003, 240), and Smith and Kohn (1997,
1524). Interactions between categorical and metric predictors in nonparamet-
ric regression are considered by Coull et al. (2001) and Ruppert et al. (2003).
Assume a predictor vector wi = (w1i, . . . , wRi) of dimension R, with spline
degree q for all predictors. Omitting the corresponding standard polynomial
eﬀects Qr(wr), the tensor product generalization of Equation 10.1 for two or
more metric predictors involves an analysis of variance type representation
with main and various order interaction eﬀects,
g(µi) = α +
R

r=1
Kr

k=1
βrk(wri −κrk)q
+ +
R

r̸=s
Kr

k=1
Ks

l=1
γrs,kl(wri −κrk)q
+(wsi −κsl)q
+
+
R

r̸=s̸=t
Kr

k=1
Ks

l=1
Kt

m=1
δrst,klm(wri −κrk)q
+
× (wsi −κsl)q
+(wti −κtm)q
+ + · · · + ui,
where Kr is the number of knots for predictor wr. There may be R main
eﬀects,
R
2

second-order interactions,
R
3

third-order interactions and so on,
with the associated parameters {β, γ, δ, . . . , } having dimension determined by
the number of knots in Kr, {Kr, Ks}, {Kr, Ks, Kt}, etc. Higher-order interac-
tions may be excluded even if deﬁnable in principle, as an acceptable smooth
may often be obtained by restricting attention to main eﬀects and low-order
interactions; so a model with main and second-order eﬀects only would have
R +
R
2

parameter sets. Gustafson (2000) considers a BWISE approximation
to smooth functions involving main eﬀects S1(w1), . . . , SR(wR), and second-
order interactions only, namely
S12(w1, w2), . . . , S1R(w1, wR), . . . , S(R−1),R(wR−1, wR).
Main eﬀects are assumed to be either conventional linear regression eﬀects
or cubic splines. The form of the interaction depends on which form of main
eﬀect is selected for predictors wr and ws.
As an example, consider a tensor product of truncated polynomials with
q = 1 and R = 3, so that wi = (w1i, w2i, w3i) and with K1 = K2 = K3 = 5. Also
just consider the step functions (w −κ)+ though Dennison et al. (2002) con-
sider sign reversed steps (κ−w)+. Then there may be R = 3 main eﬀects,
R
2

=
3 second-order interactions, and
R
3

= 1 third-order interactions. In a model
conﬁned to main eﬀects and second-order interactions, the main eﬀects would
be terms K1
k = 1 β1k(w1i −κ1k)+, K2
k = 1 β2k(w2i −κ2k)+, and K3
k = 1 β3k(w3i −
κ3k)+ involving 15 parameters. The second-order interactions would be

470
Applied Bayesian Hierarchical Methods
terms K1
k = 1
K2
l = 1 γ12,kl(w1i −κrk)+(w2i −κ2l)+, K1
k = 1
K3
l = 1 γ13,kl(w1i −
κ1k)+(w3i −κ3l)+, and K2
k = 1
K3
l = 1 γ23,kl(w2i −κ2k)+(w3i −κ3l)+ involving
75 parameters. If the coeﬃcients {βrk, γrs,kl} are assumed to be ﬁxed eﬀects,
then predictor selection methods are relevant as in Smith and Kohn (1996)
or the RJMCMC methods discussed by Denison et al. (2002, 105). If the
{βrk, γrs,kl} are assumed to be random eﬀects, smoothness may be achieved
by penalizing large coeﬃcients, and parsimony achieved by selection between
zero and positive variance components {φβ1, φβ2, φβ3, φγ12, φγ13, φγ23}.
The tensor product generalization of Equation 10.2 or 10.5 includes
interactions between the terms in T(w) and Q(w) (Ruppert et al., 2003, 240;
Smith and Kohn, 1997). Consider a two predictor situation, with K1 knots in
w1i and K2 knots in w2i. For a linear spline (q = 1), and random eﬀect spline
coeﬃcients {brk, drsk, crskm} one would have
g(µi) = α + ϕ1w1i + ϕ2w2i + ϕ3w1iw2i +
K1

k=1
b1k(w1i −κ1k)
+
K2

k=1
b2k(w2i −κ2k)+ +
K2

k=1
d12,kw1i(w2i −κ2k)
+
K1

k=1
d21kw2i(w1i −κ1k)+
+
K1

k=1
K2

m=1
c12km(w1i −κ1k)+(w2i −κ2m)+ + ui,
where there are six variance components (φb1, φb2, φd12, φd21, φc12, σ2). In the
bivariate example of Smith and Kohn (1997, 1530), K1 = K2 = 9 and q = 3
leading to a (ﬁxed eﬀects) analysis involving 169 coeﬃcients.
A similar scheme applies when interactions between metric and categorical
predictors are considered. Thus, let Ci ∈(1, . . . , L) be a categorical predictor
and w1i and w2i be metric predictors. Suppose that only the smooth in w2 is
postulated to vary according to the level of C, and deﬁne
zil = 1
if Ci = l
= 0
otherwise.
Also consider a metric response yi and assume that interactions between w1
and w2 are not present. Then with a qth degree truncated polynomial basis
in both predictors, Coull et al. (2001) suggest the model
yi = α + Q1(w1i) + Q2(w2i) + T1(w1i) + T2,Ci(w2i) + ui
= α + ϕ11w1i + · · · + ϕ1qwq
1i + ϕ21w2i + · · · + ϕ2qwq
2i +
K1

k=1
b1k(w1i −κ1k)q
+
+
K2

k=1
b2k(w2i −κ2k)q
+ +
L

l=2
zil
 K2

k=1
ckl(w2i −κ2k)q
+

,

Hierarchical Methods for Nonlinear Regression
471
where b1k ∽N(0, φb1), b1k ∽N(0, φb1), ckl ∽N(0, φcl), and ui ∽N(0, σ2).
The amount of smoothing under S1 = Q1 + T1 and S2,Ci = Q2 + T2,Ci then
depends on the ratios σ2/φb1 and σ2/[φb2 + φcl].
In a multivariate mixed model generalization of the radial basis, Yau et al.
(2003) consider thin-plate functions with exponents (2q −d) speciﬁed by
integer combinations (q, d), where d is the dimension of the covariate vectors
in the relevant interaction. So
Hk(z) = |z −tk|(2q−d) log(|z −tk|)
for (2q −d) even
Hk(z) = |z −tk|(2q−d)
for (2q −d) odd,
where z are univariate or multivariate vector predictor values, and tk are
univariate or multivariate knots. In applying such functions, Yau and Kohn
(2003) argue that heavily parameterized multivariate spline models are often
not likely to be well identiﬁed, and suggest additive models involving just
univariate smooths in each predictor (with d = 1), and all possible bivariate
interactions (with d = 2). Consider the setting q = 2, with predictors, w1
and w2, and let zi = (w1i, w2i) denote bivariate covariate combinations, with
K1,2 bivariate centers tk = (t1k, t2k) that might be provided by an initial
cluster analysis. Also denoting distances hik = |zi −tk|, the bivariate basis
for 2q −d = 2 is of the form h2 log(h). With linear terms in the parametric
component Q(w), this leads to the representation,
g(µi) = α + S1(w1i) + S2(w2i) + S12(w1i, w2i)
= α + ϕ1w1i +
K1

k=1
b1k|w1i −κ1k|3 + ϕ2w2i
+
K2

k=1
b2k|w2i −κ2k|3 +
K1,2

k=1
ckh2
ik log(hik).
In general with Kr knots {κr1, . . . , κrKr} for predictor wri, the R main
eﬀects are
Sr(wri) = ϕrwri +
Kr

k=1
brk|wri −κrk|3,
where the R sets of coeﬃcients {[br1, br2, . . . , brKr], r = 1, . . . , R} are assumed
to be random with variances φb1, . . . , φbR. Let the Kr,s bivariate knots (or
centers) for ﬁrst-order (wr, ws) interaction eﬀects be denoted trs,k = (trk, tsk).
Then the interaction bases have the form:
Trs(wri, wsi) =
Kr,s

k=1
crs,k|(wri,wsi) −(tsk, trk)|2 log(|(wri,wsi) −(trk, tsk)|).
The
R
2

sets of coeﬃcients crs,k are also assumed to be random.

472
Applied Bayesian Hierarchical Methods
A simply applied multivariate nonparametric regression involves the adap-
tive logistic basis (ALB) proposed by Hooper (2001), with the ALB Lq esti-
mator obtained by minimizing  |yi −S(w)|q. The ALB basis uses an M
component discrete mixture of multinomial logit regressions, namely
g(µi) = S(w1i, . . . , wRi) =
M

m=1
αmBm(wi),
where
Bm(wi) = exp(γm + wiδm)
 M

m=1
exp(γm + wiδm),
with the vectors δm = (δm1, . . . , δmR)′ each of dimension R and γM =
δM = 0 for identiﬁability. By virtue of the multinomial logit form one has
M
m=1 Bm(w) = 1 and there are 1+(R+2)(M −1) unknowns. As for trigono-
metric function bases, the complexity and smoothness of the ﬁt are controlled
by M; typically M = 2R + 1 where R is the number of predictors (Hooper,
2001, 350). The αm parameters (which may be assigned diﬀuse normal priors)
are ﬁxed eﬀects in Hooper (2001), and are not identiﬁed unless an overall in-
tercept α is omitted in the speciﬁcation for g(µi). They may be interpreted as
a grid of intercepts, and an ordering constraint on the αm may be imposed to
achieve unique labeling. Marginal smooths in predictor wr may be obtained
by setting δms = 0 for s ̸= r, and monitoring
S(wri) =
M

m=1
αmBr
m(wi),
where Br
m(wi) = exp(γm + wriδmr)/ M
m=1 exp(γm + wriδmr).
Example 10.2. Under 18 Conceptions
These data relate to concep-
tions (yi) to women aged under 18 in 352 English local authorities over a
three-year period 2003–2005; denominators ni are populations of women aged
15–17 in 2004 (times 3). Binomial sampling yi ∽Bin(ni, µi) is assumed with
potential explanatory factors being area deprivation, measured by an Index
of Multiple Deprivation (IMD), and the percentage of 15-year-old pupils not
achieving 5 or more GCSE subjects at grade C or above. The acronym GCSE
refers to the General Certiﬁcate of Secondary Education, and educational pro-
ﬁciency is set by the criterion of grade C or above. Plots of moment estimates
ri = yi/ni against both predictors suggest some nonlinearity (Figures 10.3
and 10.4).
The ﬁrst model is BayesX analysis with cubic B-splines for both main
eﬀects and a bivariate interaction in w1 = IMD and w2 = GCSE, with the
interaction eﬀect involving a tensor product of two one-dimensional B-splines
(Lang and Brezger, 2004). As well as the smooth functions of the predictors,
an unstructured residual ui ∼N(0, 1/τu) is included in a logit link regression4

Hierarchical Methods for Nonlinear Regression
473
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.10
0
5
10
15
20
25
30
35
40
45
50
IMD
FIGURE 10.3
Conception rates against IMD scores.
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.10
20
25
30
35
40
45
50
55
60
65
70
Percent not achieving GCSE proficiency
FIGURE 10.4
Conception rates and low GCSE attainment.
to account for overdispersion, where τu ∼Ga(1, 0.001). The regression then
speciﬁes
logit(µi) = α + S1(w1i) + S2(w2i) + S12(w1i, w2i) + ui,
Sr(wri) =
K∗
r

k
brkBk(wri, 3),
r = 1, 2,
S12(w1i, w2i) =
K∗
1

k
K∗
2

l
cklBk(w1i, 3)Bl(w2i, 3).

474
Applied Bayesian Hierarchical Methods
–4
–3.8
–3.6
–3.4
–3.2
–3
–2.8
0
5
10
15
20
25
30
35
40
45
50
Mean
2.5%
97.5%
FIGURE 10.5
Logit conception probability and IMD, B-spline basis.
The main eﬀect coeﬃcients are subject to a second-order random walk
roughness penalty, and the interaction coeﬃcients are subject to an RW1
penalty. There are K1 = K2 = 10 equally spaced knots, where min(wri) =
κr0 < κr1 · · · < κr,Kr+1 = max(wri).
The second model uses the Hooper (2001) ALB basis with M = 10 compo-
nents, with the additional feature that the αm parameters are random around
a central parameter,
αm ∼N(α, 1/τα),
where τα ∼Ga(1, 0.001). Then
logit(µi) = S(w1i, w2i) + ui
S(w1i, w2i) =
M

m=1
αmBm(wi),
Bm(wi) = exp(γm + wiδm)
 M

m=1
exp(γm + wiδm),
with the vectors γm and δm of dimension R, and γM
= δM
= 0 for
identiﬁability.
The ﬁrst model produces a mean scaled deviance of 366 and de = 293, so
the DIC is 659. Figures 10.5 and 10.6 represent the main eﬀect smooths (these
include the overall intercept α with posterior mean −3.226). A two chain run of

Hierarchical Methods for Nonlinear Regression
475
–3.7
–3.6
–3.5
–3.4
–3.3
–3.2
–3.1
–3
–2.9
20
25
30
35
40
45
50
55
60
65
70
GCSE
Mean
2.5%
97.5%
FIGURE 10.6
Logit conception probability and GCSE, B-spline basis.
–3.8
–3.6
–3.4
–3.2
–3
–2.8
5
10
15
20
25
30
35
40
45
50
IMD
Smooth
2.5%
97.5%
FIGURE 10.7
Logit conception probability and IMD.
5000 iterations of the ALB model (with second half for inferences) produces a
mean scaled deviance of 367 and de = 294.5, so the DIC is 661.5. Figures 10.7
and 10.8 contain the marginal smooths for the two predictors under the second
model, obtained as described above.

476
Applied Bayesian Hierarchical Methods
–3.7
–3.6
–3.5
–3.4
–3.3
–3.2
–3.1
–3
–2.9
20
25
30
35
40
45
50
55
60
65
70
GCSE
Smooth
2.5%
97.5%
FIGURE 10.8
Logit conception probability and GCSE.
10.4
Heteroscedasticity via Adaptive
Nonparametric Regression
As mentioned above, a random eﬀects spline regression in a predictor wi typ-
ically takes the form:
g(µi) = α + S(wi) = α + ϕ1wi + · · · + ϕqwq
i +
K

k=1
bk(wi −κk)q
+ + ui,
where ui ∼N(0, σ2), and the spline coeﬃcients may be taken as normal, for
example, bk ∼N(0, φb). This approach is spatially homogenous (in terms of
the predictor space) whereas a spatially adaptive regression allows for het-
eroscedasticity, where such heteroscedasticity is also related to w values, or
possibly to the values of other predictors (Currie and Durban, 2002). Thus
with ui ∼N(0, σ2
i ), the variances σ2
i = exp(hi) may be modeled by a sub-
sidiary spline regression with M knots in the same predictor,
hi = γ0 + γ1wi + · · · + γqwq
i + · · · +
M

m=1
cm(wi −ψm)q
+,
with cm ∼N(0, φc). Ruppert and Carroll (2000) suggest M be taken much
less than K, and apply the end knot constraints {ψ1 = κ1, ψM = κK}.
Jerak and Lang (2005) instead consider two alternative approaches. One
is to use random walk priors in hi, such as an RW1
hi ∼N(hi−1, 1/τh).

Hierarchical Methods for Nonlinear Regression
477
The other involves independent local variances
σ2
i ∼IG
ν
2, ν
2

which may be especially useful for functions with discontinuities. Taking
ν = 1 provides the Cauchy distribution. Jerak and Lang in fact consider
heteroscedasticity in nonparametric regression for binary outcomes, and use
the latent normal approach to representing the probit link, as in Wood and
Kohn (1998).
Wood et al. (2002) suggest spatially adaptive nonparametric regression
involving a discrete mixture over two or more smoothing functions, with the
mixture probabilities based on multinomial logit regression involving addi-
tional covariates xi. For y metric and M mixture components one might have
p(yi|xi, wi) ∼
M

m=1
πm(xi)N(Sm(wi, θm), Vm),
M

m=1
πm(xi) = 1,
where each smooth function Sm(w, θm) has its own parameter set θm.
Example 10.3. Elementary School Attainment
The
data
for
this
example are a random sample of 400 elementary schools from California Edu-
cation Department’s API dataﬁle for 2000 (http://www.cde.ca.gov/ta/ac/ap/
apidataﬁles.asp), which reports school academic performance (yi) together
with school characteristics such as average class size and the poverty rate
among the pupil intake (Chen et al., 2003). A linear regression analysis involves
regressing 2000 performance on the percent of pupils receiving free meals
(FSM), percent of English language pupils (ELP), and percent of teachers
with emergency credentials (EMCRED).
Let σ2 = Var(ui) and assume 1/σ2 ∼Ga(1, 0.001) in a homoscedastic
linear regression
yi = α + β1FSMi + β2ELPi + β3EMCREDi + ui.
This provides a DIC of 4386.8, with de = 4.9. However, a plot of the
residuals shows residual variation to decrease as ﬁtted attainment increases
(Figure 10.9). All three predictors have signiﬁcant (negative) eﬀects on at-
tainment, but the highest ratio of posterior mean to standard deviation is for
FSM, and a plot of the residual variation against FSM (Figure 10.10) suggests
such variation increases with FSM.
A second model therefore speciﬁes yi ∼N(µi, σ2
i ):
µi = α + β1FSMi + β2ELPi + β3EMCREDi + ui,

478
Applied Bayesian Hierarchical Methods
–250
–200
–150
–100
–50
0
50
100
150
200
400
450
500
550
600
650
700
750
800
850
900
Fitted Y
Residuals
FIGURE 10.9
Fitted Y against residuals.
6
6.5
7
7.5
8
8.5
9
9.5
10
0
10
20
30
40
50
60
70
80
90
100
FSM
log(V)
2.5%
97.5%
FIGURE 10.10
log(σ2
i ) against FSM.
where ui ∼N(0, σ2
i ), with σ2
i modeled by a spline regression
log(σ2
i ) = γ1 + γ2FSMi +
M

m=1
cm(FSMi −ψm)+.
The spline coeﬃcients are random cm ∼N(0, φc) with 1/φc ∼Ga(1, 1). There
are M = 18 knots, sited at the 5th, 10th,. . . ,85th, and 90th percentiles of
FSM. The 95th percentile of FSM is not included as it is 100%. The second
half of a two chain run of 50,000 iterations gives an estimate for φ0.5
c
of 0.41

Hierarchical Methods for Nonlinear Regression
479
with 95% interval (0.29,0.60) whereas homoscedasticity would imply φ0.5
c
= 0.
There is still nonconstancy in log(σ2
i ) as FSM varies, though no a consistent
monotonic upward or downward trend in variability as FSM increases. The
DIC under the second model falls to 4372 (de = 16.7).
10.5
General Additive Methods
Consider ranked values of a single predictor w1, . . . , wn such that
w1 < w2 < · · · < wn
and let St = S(wt) be a smooth function representing the locally changing
impact of wt on g(µt) as it varies over its range. Thus
g(µt) = α + S(wt) + ut,
where ut ∼N(0, σ2) and depending on identiﬁcation procedures used the
intercept α may not be present (Koop and Poirier, 2004). Appropriate priors
for St reﬂect the ordering and spacing of the w values, and typically follow
dynamic linear priors or other time series schemes. Normal or Student t ran-
dom walks in the ﬁrst, second or higher diﬀerences of St are one possibility
(Fahrmeir and Lang, 2001; Knorr-Held, 1999). For identiﬁability, especially
when there are smooths Srt = S(wrt) in several predictors one may adopt
devices such as centering of the Srt, or corner constraints (e.g., Sr1 = 0).
Alternatively to expedite computing speed, one may monitor identiﬁed quan-
tities such as the centered series Srt −¯Srwithout actually imposing center-
ing constraints within the estimation. Because there is only local smoothing,
inferences may also be sensitive to priors assumed for evolution variance τ2
and other aspects of the model.
If the w values are equally spaced and distinct, then ﬁrst and second-order
random walk priors are just
St ∼N(St−1, τ2),
St ∼N(2St−1 −St−2, τ2),
where smaller values of τ2 result in a smoother curve. For metric or overdis-
persed discrete responses the parameterization τ2λ = σ2 may be used, allow-
ing for trade oﬀbetween the residual variance and the variance of the smooth
(Koop and Poirier, 2004).
In ordinary regression applications, values of the wt are typically unequally
spaced and there may be tied values. To take account of unequal spacing
between successive wt, the prior is modiﬁed such that for second and higher-
order walks, the weighting on lagged values is varied according to how distant

480
Applied Bayesian Hierarchical Methods
they are from the current value (Fahrmeir and Lang, 2001). In all orders of
random walk, the precision of St is reduced the wider the gap between wt and
its preceding ordered values. Let gaps between points be denoted δ2 = w2−w1,
δ3 = w3 −w2, . . . , δn = wn −wn−1 (with δ1 = 0). Then a ﬁrst-order Normal
random walk becomes (for t > 1)
St ∼N(St−1, δtτ2),
and a second order one becomes (for t > 2)
St ∼N([1 + δt/δt−1]St−1 −[δt/δt−1]St−2, δtτ2).
Separate usually ﬁxed eﬀect priors are assumed for the initial values (e.g., S1
in a ﬁrst-order random walk). A scheme allowing choice between RW1 and
RW2 dependence for unequally spaced w is proposed by Berzuini and Larizza
(1996), namely
st ∼N(Mt, δtτ2)
where
Mt = st−1[1 + (δt/δt−1) exp(−ηδt)) −st−2[(δt/δt−1) exp(−ηδt)).
Larger values of η > 0, such that exp(−ηδt) tends to zero, imply an approxi-
mate RW1 prior and less smoothness.
If there are ties in the w values with only m < n distinct values,
denoted {w∗
j , j = 1, . . . , m}, then the above priors would be on the diﬀer-
ences δj = w∗
j −w∗
j−1 in the ranked distinct values, and it is necessary to
specify a grouping index Gt (ranging between 1 and m) for each observation
t = 1, . . . , n to indicate which distinct value it takes. Assuming an RW1 prior
in the smooth of the predictor eﬀects, the regression in wt can then be written
g(µt) = α + S(Gt) + ut,
t = 1, . . . , n,
Sj ∼N(Sj−1, δjτ2),
j = 1, . . . , m,
with Gt ∈(1, . . . , m).
If there is more than one predictor then a semi-parametric model might be
adopted with smooth functions Sr(wr) on a subset r = 1, . . . , q of R predictors,
with the remainder modeled by assuming global linearity. So
g(µt) = α+S1(w1t)+S2(w2t)+· · ·+Sq(wqt)+β1wq+1,t +· · ·+βR−qwR,t +ut.
If nonparametric functions are estimated for several regressors w1t, w2t, . . . , wqt,
then a unique ordering across all predictors is usually infeasible and group-
ing indices G1t, G2t, . . . , Gqt for each of q regressors are necessary, even if the
regressors have no tied values. In the case of tied values the indices range
between 1 and m1,1 and m2, . . . , 1 and mq (rather than between 1 and n).

Hierarchical Methods for Nonlinear Regression
481
Another approach (Biller and Fahrmeir, 1997; Wahba, 1983; Wood and
Kohn, 1998) to Bayesian general additive modeling involves the state–space
version of the polynomial smoothing spline. For a spline of general order 2h−1,
St = S(wt) is generated by a diﬀerential equation:
dhSt
dth = τdWt
dt
with Wt a Weiner process and τ2 the evolution variance. The state vector
Zt =

St, dSt
dt , d2St
dt2 , . . . , d(h−1)St
dt(h−1)

is then of order h, evolving stochastically according to
Zt = FtZt−1 + et,
(10.8)
where Ft is an h × h transition matrix and et is a multivariate error. For the
cubic spline case with h = 2, Zt = (St, dSt/dt) is bivariate and the transition
matrix is
Ft =

1
δt
0
1

,
where δt = wt+1 −wt. The et are also bivariate, for example MVN with zero
mean and covariance τ2Et, where
Et =

δ3
t/3
δ2
t/2
δ2
t/2
δt

.
As usual there may be ties in the w values and the prior in Equation 10.8 would
be on j = 1, . . . , m distinct ranked values. Each observation for t = 1, . . . , n
would have a grouping index Gt with values between 1 and m.
Example 10.4. Conceptions under 18, RW2 Smooths
This example
considers again the data on conceptions to women aged under 18 (yi) in 352
English local authorities. The model involves additive RW2 priors in w1 =
IMD and w2 = GCSE. Let G1i and G2i indicate which of the unique IMD
and GCSE values is taken by area i, where such unique values are ranked,
with m1 = 352 and m2 = 351 unique values (there is a single tie in the
GCSE values). Some of these distinct values are, however, very close to each
other (a consideration relevant in a BayesX application). With j = 1, . . . , mr
denoting ranked predictor values,
yi ∼Bin(ni, µi),
logit(µi) = α + s1(w1,G1i) + s2(w2,G2i),
srj ∼N([1 + δrj/δr,j−1]sr,j−1 −[δrj/δr,j−1]sr,j−2, τ2
rδrj),
r = 1, 2; j = 1, . . . , mr,

482
Applied Bayesian Hierarchical Methods
–4.1
–3.9
–3.7
–3.5
–3.3
–3.1
–2.9
–2.7
–2.5
0
5
10
15
20
25
30
35
40
45
50
IMD
Logit conception probability
Mean
2.5%
97.5%
FIGURE 10.11
RW2 smooth in IMD.
where τ2
r is the variance for the randomly varying srj. There is excess dis-
persion which may be removed by a model also including an unstructured
eﬀect,
logit(pi) = α + s1(w1,G1i) + s2(w2,G2i) + ui,
where ui ∼N(0, σ2
u).
A BayesX analysis5 is applied with inverse gamma priors IG(g, h) on vari-
ance parameters, and an initial setting of {g = 1, h = 0.001} on all three
variances. In a second run, the setting on h is changed to 0.0001 for the two
variances τ2
r. To avoid estimation of a large number of coeﬃcients, BayesX
performs internal grouping if a covariate has a large number of distinct values
(for ﬁrst- and second-order random walks), so the actual number of distinct
values used will be lower than the observed mr. The posterior means of the
precisions (smoothing parameters) θr = 1/τ2
r are increased from {5192,5357}
to {37178,35604} as h is lowered. Plots of the smooths under h = 0.0001 are
based on 94 distinct IMD values and 91 distinct GCSE values; Figures 10.11
and 10.12 (which include the intercept) do not show implausible short-term
ﬂuctuations present in the smooths under h = 0.001. The DICs (based on
the scaled deviance) are very similar between the two options, 662.9 under
h = 0.001 and 662.6 under h = 0.0001.
Internal grouping of distinct covariate values can be avoided with the
option “maxint,” though for nonequidistant observations some grouping might
be performed even if the number of distinct values is smaller than maxint.
It is advisable to use a value of maxint that is larger than the number of dis-
tinct values. Setting maxint = 1000 produces an analysis based on 239 distinct
values of IMD and 241 values of GCSE. With h set at 0.0001 this produces a

Hierarchical Methods for Nonlinear Regression
483
–3
–2.9
20
25
30
35
40
45
50
55
60
65
70
GCSE
–3.2
–3.1
–3.4
–3.3
–3.6
–3.5
Logit conception probability
–38
–3.7
FIGURE 10.12
RW2 smooth in GCSE.
slight increase in DIC to 664.2, and reintroduces short-term ﬂuctuations into
the smooth in GCSE.
10.6
Nonparametric Regression Methods
for Longitudinal Analysis
Two major applications of nonparametric regression to longitudinal datasets
are to time varying regression coeﬃcients and subject speciﬁc curves (Wu and
Zhang, 2006; James et al., 2000). Time varying regression eﬀects are a special
case of the general varying coeﬃcient model of Hastie and Tibshirani (1993),
namely
g(µi, υ) = β0(υ0) + w1iβ1(υ1) + · · · + wRiβR(υR),
where the eﬀect modiﬁers υ = (υ1, . . . , υR) govern the eﬀect of predictors
w = (w1, . . . , wR). If the modiﬁers are all the same (e.g., time) with υ1 =
υ2 = · · · = υR = t then
g(µit) = β0(t) + w1iβ1(t) + · · · + wRiβR(t)
and the time varying coeﬃcient model, or dynamic general linear model (West
and Harrison, 1997), is obtained. This extends to time varying predictors writ,
with
g(µit) = β0(t) + w1itβ1(t) + · · · + wRitβR(t).

484
Applied Bayesian Hierarchical Methods
Time varying intercept or regression eﬀects βr(t) of unknown form can be
ﬁtted by any nonparametric method, such as regression or penalized splines,
or random walks. For example, a B-spline approach would take
βr(t) =
K∗

k=1
brkBk(writ, q),
where brk are modeled as ﬁxed or random eﬀects. The ﬁxed eﬀects approach
would typically be combined with selection of signiﬁcant coeﬃcients.
Allowing for intercepts or regression eﬀects to vary by subject makes ran-
dom eﬀects a more sensible option. A comprehensive review of frequentist
approaches to such nonparametric mixed models is provided by Wu and Zhang
(2006)—see also Chapter 9 in Ruppert et al. (2003). A typical application is
in growth curve analysis and involves subject speciﬁc nonparametric growth
curves in time or age. For example, a growth curve model where observations
at each wave included age could be modeled using a truncated spline,
g(µit) = αt + ci + Si(Ageit) = αt + ci +
K

k=1
bik(Ageit −κk)q
+ + uit,
where uit ∼N(0, σ2), with σ2 representing within subject variation, while
ci ∼N(0, σ2
c) with σ2
c measuring between subject heterogeneity. The subject
speciﬁc spline coeﬃcients bik are subject to a roughness penalty, such as a
normal ﬁrst diﬀerence penalty,
bik ∼N(bi,k−1, 1/θi),
with subject-speciﬁc precisions potentially modeled hierarchically. For exam-
ple, one might take the log(θi) to be normal with unknown variance. For
applications with distinct recording times ait, Wu and Zhang (2006, 205) sug-
gest extended general linear mixed models with
g(µit) = Xitβ + η(ait) + Zitbi + Si(ait) + uit,
where η(a) is the population mean function, estimated nonparametrically,
and Si(a) are subject-speciﬁc deviation functions. Silva et al. (2008) consider
cubic B-spline bases to model region-wide and area-speciﬁc trends for health
outcomes yit ∽Bin(nit, πit), namely
logit(πit) = α + η(t) + Si(t) + di = α +
K∗

k=1
bkBk(t, 3) +
K∗

k=1
cikBk(t, 3) + di,
where di and cik are random area eﬀects.
Another possible scheme for allowing variability across subjects is by
random “slopes” around the population smooth functions, also sometimes
denoted as random scaling of nonlinear functions (Tutz and Reithinger, 2007).

Hierarchical Methods for Nonlinear Regression
485
For example, consider a longitudinal (e.g., growth curve) application with a
single predictor wit the impact of which is modeled at population level by a
smooth function S(wit). Then one may wish to allow both for intercept (base-
line) variation and for subject level variation around the average function
S(w). Thus
g(µit) = α + b1i + S(wit) + b2iS(wit) + uit
= α + b1i + S(wit)(1 + b2i) + uit,
where (b1i, b2i) ∼N(0, D), and for identiﬁcation 
it Sit = 0 where Sit =
S(wit). The smooth function S(wit) represents the mean eﬀect of predictor
wit, but this eﬀect is stronger for subjects with b2i > 0, and weaker for subjects
with b2i < 0. So b2i acts to amplify or attenuate the nonparametric impact
of the variable wit. For some subjects one may even obtain large negative
estimates, b2i < −1, so that the eﬀect of wit is inverted. This model adapts
to cross-sectional data where
g(µi) = α + S(wi) + biS(wi) + ui
particularly in cases where the units are nonexchangeable, for example if the
units were areas and bi followed a spatial prior.
The impact of (1 + b2i) on the unknown function S(wit) is analogous to
(subject-speciﬁc) factor loadings operating on factor scores and is subject to
identiﬁability (label switching) issues, since [−(1+b2i)][−S(wit)] = S(wit)(1+
b2i). However, labeling issues (see Section 7.3) should be avoided in practice
if the impact of wit represented by S(w) is well identiﬁed by the data. An
alternative product scheme is applied by Congdon (2006b) based on the Lee
and Carter (1992) mortality forecasting model. In this scheme subject-speciﬁc
weights qi that sum to 1 over all subjects operate on S(wit), so that for 
i qi =
1 the product scheme is qiS(wit). The eﬀect of w is stronger for subjects with
higher qi, and weaker for subjects with lower qi, with the average qi being 1/n.
Example 10.5. Progesterone Readings over Menstrual Cycle
This
example uses progesterone readings yit in a study of early pregnancy loss
(Brumback and Rice, 1998; Wu and Zhang, 2006). There are i = 1, . . . , 91 ob-
served cycles of length T = 24 days, so N × T = 2184; the days are coded as
−8, −7, . . . , 13, 14, 15 with 0 as day of ovulation. There are J = 2 groups of ob-
servations, the ﬁrst 69 cycles being nonceptive, the last 22 being conceptive.
Two models are ﬁtted, diﬀering in that one involves nonparametric regression
at conceptive group level, while the other involves subject level growth paths.
So instead of a linear or polynomial function in the days variable, cubic B-
splines are used with knots at (−5, 0, 5, 10). The K∗= 8 basis functions are
obtained from the R-splines package via the command:
bs(cycval,df=NULL,knots=c(-5,0,5,10),degree=3,intercept=TRUE,Boundary
.knots=range(cycval))
where cycval = c(−8, −7, . . . , 14, 15).

486
Applied Bayesian Hierarchical Methods
–1.5
–1
–0.5
0
0.5
1
1.5
2
2.5
–8
–3
2
7
12
Day
Reading
Nonconceptive
Conceptive
FIGURE 10.13
Smooths (posterior means) for groups.
In a baseline model, the spline coeﬃcients are group speciﬁc random
coeﬃcients {bjk, j = 1, 2, k = 1, K∗}, with group-speciﬁc precisions.6 Let
Gi ∈(1, 2) denote conceptive group, then yit ∼N(µit, 1/τ) with
µit = αGi +
K∗

k=1
bGikBk(t, 3),
bjk ∼N(0, 1/θj)
and θj ∼Ga(1, 0.001), τ ∼Ga(1, 0.001). A two chain run of 5000 iterations
(with the last 4000 for inference) shows a similar path between the two groups
(posterior mean bjk) up to the week after ovulation but distinct trends there-
after (Figure 10.13). The DIC is 5510 (de=16.5). A subject-speciﬁc model
adds both intercept heterogeneity and subject (cycle) speciﬁc growth eﬀects,
so that
µit = αGi + bi0 +
K∗

k=1
bikBk(t, 3)
with
bi0 ∼N(0, 1/τ0), {i = 2, . . . , n},
b10 = 0,
bi1 ∼N(0, 1/τ1),
bik ∼N(bi,k−1, 1/θGi),
k = 2, K∗,
τj ∼Ga(1, 0.001),
j = 0, 1; θj ∼Ga(1, 0.001), j = 0, 1.

Hierarchical Methods for Nonlinear Regression
487
The corner constraint b10 = 0 is not strictly needed but aids distinct identiﬁ-
cation of the group intercepts αj, and the subject heterogeneity eﬀects. The
DIC for this model is 2772 (de = 515). Note that instead of assuming bi0 and
bi1 are independent one might assume they are correlated (see Section 8.5).
Example 10.6. Birthweight and Maternal Age
Neuhaus and Mc-
Culloch (2006) consider a subset of data from a more extensive longitudinal
study that involves the birthweights of babies born to n = 878 mothers from
the state of Georgia, USA, all of whom has at least T = 5 babies. The analysis
here is focused on the impact on birthweight yit of mother’s age at birth wit,
and the extent to which there is heterogeneity in the overall smooth S(wit),
which is based on a second-order random walk. Thus for each ﬁve birth history
for mother i one may stipulate,
yit = β0 + b1i + S(wit) + b2iS(wit) + uit,
where (b1i, b2i) ∼N(0, D), and D−1 follows a Wishart prior with iden-
tity scale matrix and two degrees of freedom. The random walk smooth
is estimated over all (i, t) pairs using a normal RW2 prior with a single
variance parameter, rather than on the basis of successive ages within each
fertility sequence, which would permit distinct variance parameters for each
subject.7 The smooth involves 31 random parameters, namely for maternal
ages 12–42.
A two chain run of 5000 iterations shows early convergence, with signﬁcant
heterogeneity in the b2i, namely a posterior mean for var(b2) of 1.35, and 95%
interval {0.95, 1.74}. Figure 10.14 shows the varying nonparametric impact of
2.5
2.7
2.9
3.1
3.3
3.5
3.7
3.9
15
20
25
30
35
40
Maternal age
Birthweight (kg)
High b2
b2 = 0
Low b2
FIGURE 10.14
Heterogenity in nonlinear impact of maternal age.

488
Applied Bayesian Hierarchical Methods
0
20
40
60
80
100
120
140
160
–4.75
–4.19
–3.62
–3.06
–2.50
–1.94
–1.38
–0.82
–0.26
0.30
0.87
1.43
1.99
2.55
3.11
Posterior mean b2i
Frequency
FIGURE 10.15
Histogram of mean b2.
maternal age wit according to b2i, namely for subjects with b2i = sd(b2),
b2i = 0 and b2i = −sd(b2), where the standard deviations are those at
particular MCMC iterations. A histogram plot of the posterior mean b2i
(Figure 10.15) indicates normality, though an extreme negative outlier of
−4.75 occurs for subject 470, whose fourth and ﬁfth infants weighed under
1 kg, whereas the ﬁrst two exceeded 3 kg, in weight.
Example 10.7. Suicide Mortality and Deprivation
This spatio-tem-
poral panel example is used to illustrate both random spatial scaling of
spline smooths and autocorrelated errors. The data are suicide death totals
yit (to all persons) over years t = 1, . . . , T (namely 1996–2006 so that T = 11)
in 33 London boroughs. These are taken as Poisson, yit ∼Po(Eitρit), with
expected deaths Eit based on England wide age-sex suicide rates for 2006. The
smooth of interest involves an area deprivation score wi from the 2001 Cen-
sus, and constant and time varying B-spline smooths expressing how suicide
relative risk varies with deprivation. K = 9 knots are set at the 10th, 20th,
. . . , 90th deciles of deprivation, and with q = 3 and K∗= 13, the n × K∗
cubic B-spline function values Bk(wi, 3) are obtained using the R-splines
routine.
The ﬁrst model involves a constant B-spline smooth S(wi), and a bivariate
CAR spatial eﬀect (c1i, c2i), together with ﬁxed eﬀect time trend parameters
∆t subject to a corner constraint ∆1 = 0. Hence
log(ρit) = c1i + (1 + c2i)S(wi) + ∆t,
S(wi) =
K∗

k=1
bkBk(wi, 3),

Hierarchical Methods for Nonlinear Regression
489
–0.5
–0.4
–0.3
–0.2
–0.1
0
0.1
–2
–1
0
1
2
3
4
5
Deprivation score
Log relative risk
Mean
2.5%
97.5%
FIGURE 10.16
Suicide risk and deprivation.
where the bk follow a ﬁrst-order random walk, and to avoid confounding
between the spline function and an overall intercept term, the latter is omitted.
To assess autocorrelation in residuals eit = (yit −µit)µ−0.5
it
, the statis-
tic re = Σn
i=1ΣT
t=2eitei,t−1/Σn
i=1ΣT
t=2e2
it is monitored. This model converges
within 5000 iterations of a two chain run and iterations 5000–10,000 produce
a DIC of 1960 (de = 37). Figure 10.16 reproduces the smooth S(w) and it
can be seen that varying deprivation is associated with a relatively small vari-
ation in relative risk, though there is a positive eﬀect. The autocorrelation
parameter has 95% interval (0.05,0.13).
A second model involves time varying splines, without random spatial
scaling, so that
log(ρit) = ci + St(wi) + ∆t,
St(wi) =
K∗

k=1
btkBk(wi, 3),
with year-speciﬁc random walk penalty priors
btk ∼N(bt,k−1, 1/θt), k = 2, K∗,
bt1 ∼N(0, 1/τ1).
This model converges after 50,000 iterations of a two chain run and it-
erations 50,000–100,000 produce a slightly improved DIC of 1957 (de = 43).
The positive deprivation eﬀect now shows more in later years such as 2004
(Figure 10.17). The autocorrelation parameter now has a 95% interval
(0.03,0.13).

490
Applied Bayesian Hierarchical Methods
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
–2
–1
0
1
2
3
4
5
Deprivation score
Suicide relative risk
FIGURE 10.17
Time varying spline, smooth for 2004.
–0.35
–0.3
–0.25
–0.2
–0.15
–0.1
–0.05
0
0.05
0.1
–2
–1
0
1
2
3
4
5
Deprivation score
Log relative risk
Mean
2.5%
97.5%
FIGURE 10.18
Suicide risk and deprivation, AR errors.
An alternative to time varying splines is to include a stationary AR1 error
in the random spatial scaling model. So,
log(ρit) = c1i + (1 + c2i)S(wi) + ∆t + εit,
εit ∼N(ρεit, σ2),
t > 1,
εi1 ∼N(0, σ2(1 −ρ2)−1),
with ρ ∼U(−1, 1). The second half of a two chain run of 50,000 iterations
for this model gives a DIC of 1947 (de = 62), and produces a 95% interval
for re that now straddles zero, namely (−0.04, 0.10), with ρ estimated at 0.73
(0.39, 0.93). Compared to Figure 10.16 the mean smooth of relative risk on

Hierarchical Methods for Nonlinear Regression
491
deprivation is, however, virtually unchanged, though the credible interval is
narrower (see Figure 10.18).
Appendix: Computational Notes
1. Suppose y is observed at 15 points in time (w1 = 1,w2 = 2, . . . , w15 = 15),
and K = 2 knots are chosen at times 5 and 10. Then cubic B-spline values
{Bk(wi, 3), k = 1, K∗} with K∗= 6, may be obtained by loading the splines
package in R, inputting the values of {w1, . . . , w15} with name wvec, and then
using the command
bs(wvec, df = NULL, knots = c(5,10), degree = 3, intercept = TRUE,
Boundary.knots = range(wvec)).
Eilers and Marx (1996, 100) provide MATLAB r
⃝code for obtaining B-spline
values assuming equally spaced knots. B-spline schedules obtained by diﬀer-
encing truncated polynomials, and with the property K∗
k=1 Bk(wi, q) = 1,
are produced by the R code (for K1 = K + 1 intervals) (Eilers and Marx,
2004),
trunc <- function(x, t, p) {(x - t) ˆp * (x > t)}
B <- function(wvec, wmin, wmax, K1, q){
dw <- (wmax - wmin) / K1
knots <- seq( - q * dw, wmax + q * dw, by = dw)
P <- outer(wvec, knots, trunc, q); n <- dim(P)[2]
D <- diﬀ(diag(n), diﬀ= q + 1) / (gamma(q + 1) * dw ˆ q)
B <- (-1) ˆ(q + 1) * P %*% t(D)
B}
2. The linear truncated spline in Example 10.1 is coded in WinBUGS as
model { for (i in 1:106) {y[i] <- 100000*SR[i]-70700; y[i] ∼dnorm(mu[i],inv.s2)
mu[i] <- beta0+beta1*age[i]+sum(linpol[i,1:K])
for (k in 1:K) {linpol[i,k] <- b[k]*max(0,age[i]-kap[k])}}
# penalty prior
for (k in 1:K) {b[k] ∼dnorm(0,th)}
beta0 ∼dnorm(37,0.0001); beta1 ∼dnorm(0,0.0001)
inv.s2 ∼dgamma(1,0.001); th ∼dgamma(1,0.001)}
The code for the cubic B-spline model (with the same knots) is the same
except for lines 2–4 which are
mu[i] <- beta0+beta1*age[i]+sum(bsterms[i,1:K+q+1])
for (k in 1:K+q+1) {bsterms[i,k] <- b[k]*BS[i,k]}}
# random walk penalty
b[1] ∼dnorm(0,0.001); for (k in 2:K+3) {b[k] ∼dnorm(b[k-1],th)}
The B-spline coeﬃcients are obtained in R by ﬁrst inputting the age values,
siting knots at every 5th percentile, and then using the command

492
Applied Bayesian Hierarchical Methods
bs(age, df = NULL, knots = c(93.2,93.9,95.2,100.7,104.4,104.8,106.2,108.2,
109.0,109.5,110.3,111.5,112.4,113.7,115.4,118.0,119.3,120.8,122), degree = 3,
intercept = TRUE,Boundary.knots = range(age)).
3. The BayesX program code for the Fossil data assumes the data ﬁle
c:\data\stront.raw (ascii column format) has variable headings y and age.
The code is then
dataset dstront
dstront.inﬁle, maxobs=5000 using c:\data\stront.raw
bayesreg bstront
bstront.regress y = age(psplinerw2),family=gaussian predict using dstront
The entire code can be named stront.prg and saved in c:\program ﬁles\
BayesX. Implementing it then requires typing the command
useﬁle stront.prg
in the Command window of BayesX. The data for the smoothed plot can be
obtained from the output ﬁle bstront predictmean.raw.
4. The BayesX program code for the B-spline analysis of the conceptions
data (with 10 knots rather than the default 20) is
dataset d
d.inﬁle, maxobs=5000 using c:\data\concep.raw
bayesreg b
b.regress y = imd(psplinerw2,nrknots=10)+gcse(psplinerw2,nrknots=10)
+gcse*imd(pspline2dimrw1,nrknots=10)+areaid(random) weight femp,family
=binomial predict using d
The plots of the smooths are based on relevant *.res ﬁles.
The WinBUGS code for the ALB model as applied in Example 10.2 is
model { for (i in 1:n) {u[i] ∼dnorm(0,tau.u)
y[i] ∼dbin(p[i],femp[i]); logit(p[i]) <- sum(phi[i,])+u[i]
# total smooths in predictors 1 and 2
S[1,i] <- sum(S1[i,]); S[2,i] <- sum(S2[i,])
yhat[i] <- p[i]*femp[i]; yhatp[i] <- yhat[i]+con
yp[i] <- y[i]+con; dy[i] <- femp[i]-y[i]+con
dyhat[i] <- femp[i]-yhat[i]+con
dv[i] <- y[i]*log(yp[i]/yhatp[i]) +dy[i]*log(dy[i]/dyhat[i])
# total regression function
for (m in 1:M) {phi[i,m] <- alph[m]*EX[i,m]/sum(EX[i,1:M])
# components of “marginal” smooths in predictors 1 and 2
S1[i,m] <- alph[m]*EX1[i,m]/sum(EX1[i,1:M]);
S2[i,m] <- alph[m]*EX2[i,m]/sum(EX2[i,1:M])
EX[i,m] <- exp(gam[m]+del1[m]*(imd[i]-mean(imd[]))
+del2[m]*(gcse[i]-mean(gcse[])))
EX1[i,m] <- exp(gam[m]+del1[m]*(imd[i]-mean(imd[])))
EX2[i,m] <- exp(gam[m]+del2[m]*(gcse[i]-mean(gcse[])))}}
# scaled deviance

Hierarchical Methods for Nonlinear Regression
493
Dv <- 2*sum(dv[])
# priors
tau.u ∼dgamma(1,0.001);
for (m in 1:M) {alph[m] ∼dnorm(alph.m,tau.alph) }
alph.m ∼dnorm(0,0.01); tau.alph ∼dgamma(1,0.001)
for (m in 1:M-1) {gam[m] ∼dnorm(0,0.01);
del1[m] ∼dnorm(0,0.01); del2[m] ∼dnorm(0,0.01)}
gam[M] <- 0; del1[M] <- 0; del2[M] <- 0}
5. The BayesX code for the RW2 general additive priors in the teenage con-
ceptions analysis (Example 10.4) is
dataset d
d.inﬁle, maxobs=5000 using c:\data\concep.raw
bayesreg b
b.regress y = imd(rw2,a=1,b=0.0001)+gcse(rw2,a=1,b=0.0001)+areaid
(random,a=1,b=0.001) weight femp,family=binomial predict using d
6. The progesterone reading data are arranged in stacked form in terms of
cycles 1 to 91 and times -8 to 15. With G[1:91] containing the binary concep-
tive group values, the code is
model { for (i in 1:2184) {y[i] ∼dnorm(mu[cyc[i],time[i]+9),tau)}
for (i in 1:91) { for (t in 1:T) {mu[i,t] <- mean[G[i],t)}}
for (j in 1:2) {for (t in 1:T) {mean[j,t] <- alph[j]+sum(bspl[j,t,1:Kstar])
for (k in 1:Kstar) {bspl[j,t,k] <- b[j,k]*B[t,k]}}}
for (j in 1:2) {alph[j] ∼dnorm(0,0.001); th[j] ∼dgamma(1,0.001)
for (k in 1:Kstar) {b[j,k] ∼dnorm(0,th[j])}}
tau ∼dgamma(1,0.001)}
The code for the subject speciﬁc model is
model { for (i in 1:2184) {y[i] ∼dnorm(mu[cyc[i],time[i]+9),tau)}
for (i in 1:91) { for (t in 1:T) {mu[i,t] <- alph[G[i]]+
b0[i]+sum(bspl[i,t,1:Kstar])
for (k in 1:Kstar) {bspl[i,t,k] <- b[i,k]*B[t,k]}}}
for (j in 1:2) {alph[j] ∼dnorm(0,0.001); th[j] ∼dgamma(1,0.001)}
b0[1] <- 0; for (i in 2:91) {b0[i] ∼dnorm(0,tau0)}
for (i in 1:91) { b[i,1] ∼dnorm(0,tau1)
for (k in 2:Kstar) {b[i,k] ∼dnorm(b[i,k-1],th[G[i]])}}
tau ∼dgamma(1,0.001); tau0 ∼dgamma(1,0.001);
tau1 ∼dgamma(1,0.001)}
7. The code for the random heterogeneity maternal age eﬀect model, includ-
ing weight and adjacency information for the RW2 prior using the car.normal
function is as follows:
model { for (i in 1:n) {b[i,1:2] ∼dmnorm(nought[],Dinv[,])
for (t in 1:T) {Y[i,t] <- y[i,t]/1000; Y[i,t] ∼dnorm(mu[i,t],tau)
mu[i,t] <- alpha+b[i,1]+S[i,t]+b[i,2]*S[i,t]

494
Applied Bayesian Hierarchical Methods
S[i,t] <- s[age[i,t]-11]}}
# bwt proﬁles by matage according to diﬀerent b2
for (m in 15:42) {ageprof[1,m] <- alpha+s[m-11]*(1+sig.b[2]);
ageprof[2,m] <- alpha+s[m-11]
ageprof[3,m] <- alpha+s[m-11]*(1-sig.b[2])}
# RW2 prior in matage
s[1:X] ∼car.normal(adj[], w[], nage[], taus)
w[1] <- 2; adj[1] <- 2; nage[1] <- 2
w[2] <- -1; adj[2] <- 3; nage[2] <- 3
w[3] <- 2; adj[3] <- 1; w[4] <- 4; adj[4] <- 3; w[5] <- -1; adj[5] <- 4
for (x in 3:X-2) {nage[x] <- 4;
w[6+(x-3)*4] <- -1; adj[6+(x-3)*4] <- x-2
w[7+(x-3)*4] <- 4;
adj[7+(x-3)*4] <- x-1;
w[8+(x-3)*4] <- 4; adj[8+(x-3)*4] <- x+1
w[9+(x-3)*4] <- -1; adj[9+(x-3)*4] <- x+2}
w[(X-4)*4 + 6] <- 2; adj[(X-4)*4 + 6] <- X;
w[(X-4)*4 + 7] <- 4; adj[(X-4)*4 + 7] <- X-2
w[(X-4)*4 + 8] <- -1; adj[(X-4)*4 + 8] <- X-3;
w[(X-4)*4 + 9] <- 2; adj[(X-4)*4 + 9] <- X-1
w[(X-4)*4 + 10] <- -1; adj[(X-4)*4 + 10] <- X-2;
nage[X-1] <- 3; nage[X] <- 2
# other priors
alpha ∼dnorm(3,0.001); Dinv[1:2,1:2] ∼dwish(ScD[,],2)
D[1:2,1:2] <- inverse(Dinv[,]); for (j in 1:2) {sig.b[j] <- sqrt(D[j,j])}
tau ∼dgamma(1,0.01); taus ∼dgamma(5,1)}

Appendix 1: Using WinBUGS and
BayesX
A1.1
WinBUGS: Compiling, Initializing,
and Running Programs
WinBUGS provides a versatile programming environment that is potentially
adapted to a wide range of applications. The most usual approach involves
specifying priors on parameters and stating the data likelihood. WinBUGS
then selects conditional posterior distributions and sampling methods via an
inbuilt expert system. However, for parameters obtainable using Gibbs sam-
pling, one can also directly code the full conditionals.
Unlike other programming environments such as R, C, or Fortran, a Win-
BUGS program does not operate sequentially, and there is no prescribed order
for programming statements of diﬀerent kinds (e.g., it is not necessary that
priors be speciﬁed before the likelihood). The program is ﬁrst and foremost a
description of the model and of the stochastic nodes that may be monitored
at each Markov Chain Monte Carlo (MCMC) step. One may nevertheless
perform more traditional programming tasks such as data manipulations. In
the event of unexplained computational problems, it is often worth trying
OpenBUGS as an alternative to WinBUGS14 and vice versa.
The following brief guide is intended for new users and applies to both
programs. More comprehensive guides to developing and applying WinBUGS,
as well as focused reviews, are provided by Fryback et al. (2001), Giminez et al.
(2008), Lunn et al. (2009), Ntzoufras (2009), Scollnik (2002), and Woodworth
(2004, Appendix B).
A1.2
WinBUGS Steps in Program Checking
and Execution
A. Loading and checking the program: Open the program document (usually
with an odc suﬃx) using “ﬁle” then “open.” Select “model” then “speciﬁ-
cation” from the main menu. Highlight the word model (or just the ﬁrst few
letters of the word model). Alternatively, select the entire model program code.
Then select “check model.” Any syntax errors will be reported at this stage.
495

496
Appendix 1: Using WinBUGS and BayesX
B. Loading the data: After loading the program, all datasets must be
loaded. Two data formats are possible for datasets: what are known as s-ﬁles
and ascii or formatted column ﬁles with each variable headed by a name in
the ﬁrst row. For s-ﬁles (starting with the word list) one loads by highlighting
the whole data ﬁle or just the word list itself, or even just the ﬁrst letter or
two of the word list. Then select “load data.” For ascii ﬁles one may select the
whole ﬁle or just the ﬁrst few letters in the ﬁrst row. Then again select “load
data.” It is possible to have multiple data ﬁles, either s-ﬁles or ascii ﬁles. Note
that “NA” means missing data, which implies that the model must include a
mechanism to randomly generate them.
C. Setting the number of MCMC chains: The default is a single chain, so
reset the number of chains if multiple chains are to be run.
D. Compile the Program. Select “compile”: Errors reported here are many
and various but may, for instance, include unknowns without prior distri-
butions assigned, or variables mentioned in the data ﬁles but not in the
model code.
E. Specifying initial parameter values: If compilation is successful, ini-
tial parameter values must then be assigned or randomly generated. Usually
assigned (preset) values are chosen for at least a subset of the parameters, if
not for the totality of parameters. The preset values are put together in what
is colloquially known as an “inits” ﬁle, which also may be s-ﬁles or formatted
column ﬁles. For an s-ﬁle, one may highlight the entire contents of the inits
ﬁle or just the ﬁrst letter or two of the word list at the start of the inits. Then
select “load inits.” If more than one inits ﬁle is used then repeat the proce-
dure. An inits value is set to NA when the parameter is preset, or which has
no prior itself but can be obtained from free parameters that do have priors.
An example for a preset value is a corner constraint β1 = 0 on a parameter
set {βk, k = 1, 4} so that the initial values might be beta = c(NA, 0, 0, 0). If
there are parameters not initialized then one may press “gen inits” to gen-
erate them from the priors speciﬁed in the model code. If applied for a set
of random eﬀects (say), this can generate extreme values when the prior on
the precision or precision matrix is diﬀuse; so an informative initial setting on
the hyperparameter (e.g., a random eﬀects precision of 10 or 100) should be
used if initial values of the associated random eﬀects are to be generated at
random.
F. Running the estimation: To starting the MCMC sampling, select
“model” from the main menu and then “update.” An “update tool” icon ap-
pears. Often (e.g., in complex models) the default “refresh” of 100 will need
to be reset to a smaller value (e.g., just 5 or 1). Also usually more than 1000
iterations are needed for a model to converge and produce sensible estimates;
so resetting “updates” from 1000 to at least 5000 or 10,000 is advisable. Then
select the stippled light-blue “update” icon. Only at the refresh point can the
model run be stopped by selecting the now stippled update box, e.g., to list
out current parameter estimates or to assess convergence. To set the model
running again, select the stippled light-blue update box again.

Appendix 1: Using WinBUGS and BayesX
497
G. Monitoring model parameters and other outputs: Either when estima-
tion of the model is temporarily halted (as described in F), or before selecting
“model” and “update,” it is usually necessary to select which parameters or
“nodes” are to be monitored. So select “inference” from the main menu and
then “samples.” In the “node” box enter the name of the parameter (or other
model-related quantity) to be monitored. The word parameter is here used
generically to include vectors and matrices. Then press “set”. If more than
one chain is running it is useful also to select the “trace” option to assess
convergence visually.
H. Obtaining summaries: To obtain the current summary posterior statis-
tics and/or density proﬁle, select the stippled “update” button on the update
icon to temporarily halt the run and select the appropriate node name and
press “stats” or “density.” If more than one chain is running one may also
select “bgr diag” to check on convergence of that parameter or parameter set.
The “history” button will also indicate the degree of mixing over chains.
I. Using inference/summary: To monitor large parameter sets (e.g.,
theta[1:N] where N = 1000) it is better to use the “inference” then “sum-
mary” option rather than the “inference/samples” option. Otherwise the mem-
ory may become overloaded. The inference/summary option however provides
only summary posterior statistics, not features like density plots.
J. Running programs in batch mode using script: The above steps can be
replicated in batch mode using a script ﬁle. Assume one has a program, data,
and single inits ﬁle named rain model.odc, rain data.odc, and rain inits.odc.
These need to be placed in the WinBUGS program directory. The program is
model {for (i in 1:n) {y[i] ˜dnorm(mu[i],tau)
mu[i] <- beta[1] + beta[2]*(x[i]-mean(x[]))}
# priors
beta[1] ˜dnorm(40,0.0001); beta[2] ˜dnorm(0,0.001)
tau ˜dgamma(1,0.001); sig2 <- 1/tau}.
The data ﬁle is
list(n=10, y=c(41,52,18.7,55,40,29.2,51,17.6,46.6,57),
x=c(23.9,43.3,36.3,40.6,57,52.5,46.1,142,112.6,23.7)),
and the inits ﬁle is
list(beta=c(40,0),tau=1).
One needs to open a new ﬁle using File/New and then paste in the list of
relevant “script” commands, such as
display(‘log’)
check(‘rain model.odc’)
data(‘rain data.odc’)
compile(1)
inits(1,‘rain inits.odc’)
thin.samples(5)
update(10,000)
set(beta)
set(sig2)

498
Appendix 1: Using WinBUGS and BayesX
update(10,000)
stats(*)
history(*)
density(*)
autoC(*).
Then select Model/Script and the compilation, data and initial value loading
and estimation stages will run automatically.
A1.3
Using BayesX
At the time of writing, BayesX is less general than WinBUGS in its program-
ming syntax, and in features such as specifying alternative priors or nonstan-
dard densities. For example, there is no equivalent to a for loop, and use of
categorical predictors (with J levels) involves J-1 commands deﬁning J-1 bi-
nary variables. There are also limits on windows functionality; for example,
one cannot paste text to the command window, or select and copy text from
any window.
However, for the problem types where BayesX does apply (e.g., nonpara-
metric nonlinear regression, general linear models, spatial models with uni-
variate CAR priors, univariate survival models), it can provide considerable
computational advantages in speed and automatically provides extensive use-
ful outputs. Calculation of the DIC and eﬀective parameters may be included
in the output, as well as ﬁles for graphical presentation of posterior densities,
trace plots, etc. Reviews of BayesX include Brezger et al. (2005) and Kneib
et al. (2008).
A current important limitation is that multivariate random eﬀects,
whether unstructured or spatially structured are not possible to specify. Sim-
ilarly only univariate responses can be speciﬁed, not multivariate responses.
Univariate autoregressive priors over area units (CAR priors) are included, but
temporally autoregressive or moving average priors are not, except for random
walk or P-spline priors in time. Thus, following Section 8.1.4 of the BayesX
Reference Manual (version 2.00, from www.stat.uni-muenchen.de/∼bayesx/
manual/reference manual.pdf) assume a Gaussian response y at quarters t,
and dataset object named d containing values of y, t, and a predictor x.
Then a Bayes analysis with a P-spline trend subject to second-order penalty,
together with a seasonal component for the time scale t, may be speciﬁed via
b.regress y = x + t(psplinerw2) + t(season,period= 4), family=gaussian
using d.
BayesX is conﬁgured in such a way that editing program ﬁles (with
usual extension *.prg) is easiest in another ﬁle preparation program such as

Appendix 1: Using WinBUGS and BayesX
499
wordpad. Then one may use the batch facility in the command window of the
BayesX screen, for example by typing in
useﬁle credit.prg
Although it is not possible to paste in text to the command window, one
may restore command entries (and then edit them) using the review window.
The usual working directory is c:\program ﬁles\Bayesx, so one suggestion
is to save program ﬁles to a subdirectory c:\program ﬁles\Bayesx\programs
relative to the usual working directory. To use the useﬁle command one then
types in
useﬁle programs\credit.prg
Similarly data ﬁles with extension *.raw or *.txt may be saved to a subdirec-
tory of c:\program ﬁles\Bayesx\data and then invoked from that subdirectory
root.
To illustrate such features consider a Poisson regression using male lung
cancer deaths in 32 London boroughs and standard rates provided by England
annual age-speciﬁc rates 2004–2006; the standard rates are applied to area
populations to provide expected deaths which are then log transformed to
obtain the oﬀset variable logE below. Assuming the subdirectory options as
discussed above, a regression with spatial and unstructured random eﬀects
would then be invoked by typing in
useﬁle programs\london.prg
at the command prompt. The data ﬁle and model form are speciﬁed in lon-
don.prg as
dataset d
d.inﬁle, maxobs=50 using data\london.txt
map m
m.inﬁle, graph using data\london.gra
bayesreg b
b.regress y = logE(oﬀset) + area(spatial,map=m) + area(random),
family=poisson predict using d
Inclusion of the word predict in the model (b.regress) command ensures the
DIC and eﬀective parameters are produced. To run and compare two models,
one with and one without an unstructured error, one may use the code
dataset d
d.inﬁle, maxobs=50 using data\london.txt
map m

500
Appendix 1: Using WinBUGS and BayesX
m.inﬁle, graph using data\london.gra
bayesreg b1
b1.regress y = logE(oﬀset) + area(spatial,map=m), family=poisson pre-
dict using d
bayesreg b2
b2.regress y = logE(oﬀset) + area(spatial,map=m) + area(random),
family=poisson predict using d
The dataﬁle london.txt includes a header line and 33 subsequent records.
area
y
logE
0
4
1.98
1
170
4.82
.....
32
128
5.05
The areas are numbered 0 to 32 in order to coincide with the area num-
bering in the spatial adjacency ﬁle london.gra. This ﬁle has ﬁrst line with the
number of areas (here 33). There are then 3*33=99 remaining lines in the
gra ﬁle. For each area, one line speciﬁes its code, the second its number of
neighbors, and third, the codes of the neighbors. Hence the ﬁle has structure
33
0
6
6 11 18 27 29 32
1
5
3 10 15 24 25
2
5
9 13 6 4 14
....
32
6
0 6 21 31 19 4

References
Aalen O (1988) Heterogeneity in survival analysis. Statistics in Medicine, 7,
1121–37.
Aalen O, Hjort N (2002) Frailty models that yield proportional hazards. Statis-
tics & Probability Letters, 58, 335–42.
Abbring J, van den Berg G (2003) The identiﬁability of the mixed propor-
tional hazards competing risks model. Journal Royal Statistical Society:
Series B, 65, 701–10.
Abbring J, van den Berg G (2007) The unobserved heterogeneity distribution
in duration analysis. Biometrika, 94, 87–99.
Abraham B, Ledolter J (1983) Statistical methods for forecasting. New York:
Wiley.
Abrams K, Gillies C, Lambert P (2005) Meta-analysis of heterogeneously
reported trials assessing change from baseline. Statistics in Medicine, 24,
3823–44.
Abrams K, Lambert P, Sanso B, Shaw S, Marteau T (2000) Meta-analysis
of heterogeneously reported study results: A Bayesian approach. In
D Berry, D Stangl (eds), Meta-Analysis in Medicine and Health Policy.
Amsterdam: Marcel Dekker, 29–64.
Agresti A (1997) A model for repeated measurements of a multivariate binary
response. Journal of the American Statistical Association, 92, 315–21.
Agresti A, Hitchcock D (2005) Bayesian inference for categorical data analysis.
Statistical Methods and Applications, 14, 297–330.
Agresti A, Natarajan R (2001) Modeling clustered ordered categorical data:
A survey. International Statistical Review, 69, 345–71.
Ahn S, Schmidt P (1995) Eﬃcient estimation of models for dynamic panel
data. Journal of Econometrics, 68, 5–27.
Aitchison J, Ho C (1989) The multivariate Poisson-log normal distribution.
Biometrika, 76, 643–53.
Aitchison J, Shen S (1980) Logistic-normal distributions: Some properties and
uses. Biometrika, 67, 261–72.
Aitkin M, Aitkin I (2005) Bayesian inference for factor scores. In A Maydeu-
Olivares, J McArdle (eds), Contemporary psychometrics. Mahwah, NJ:
Lawrence Erlbaum Associates.
Aitkin M, Clayton D (1980) The ﬁtting of exponential, Weibull and ex-
treme value distributions to complex censored survival data using GLIM.
Applied Statistics, 29, 156–63.
501

502
References
Akaike H (1973) Information theory and an extension of the maximum like-
lihood principle. In B Petrov, F Csaki (eds), The second international
symposium on information theory. Budapest: Akademiai Kiado, 267–81.
Alanko T, Duﬀy J (1996) Compound binomial distributions for modeling con-
sumption data. The Statistician, 45, 269–86.
Albert J (1988) Computational methods using a Bayesian hierarchical gen-
eralized linear model. Journal of American Statistical Association, 83,
1037–45.
Albert J (1992) Bayesian estimation of normal ogive response curves using
Gibbs sampling. Journal of Educational Statistics, 17, 251–69.
Albert J (1996a) A MCMC algorithm to ﬁt a general exchangeable model.
Communications in Statistics: Simulation and Computation, 25, 573–92.
Albert J (1996b) Bayesian selection of log-linear models. Canadian Journal
of Statistics, 24, 327–47.
Albert J (1999) Criticism of a hierarchical model using Bayes factors. Statistics
in Medicine, 18, 287–305.
Albert J (2007) Bayesian Computation with R. New York: Springer.
Albert J, Chib S (1993) Bayesian analysis of binary and polychotomous re-
sponse data. Journal of the American Statistical Association, 88, 669–79.
Albert J, Chib S (1997) Bayesian tests and model diagnostics in conditionally
independent hierarchical models. Journal of American Statistical Associ-
ation, 92, 916–25.
Albert J, Chib S (2001) Sequential ordinal modeling with applications to
survival data. Biometrics, 57, 829–36.
Albert J, Ghosh M (2000) Item response modeling. In D Dey, S Ghosh,
B Mallick (eds), Generalized linear models: A Bayesian perspective. New
York: Addison–Wesley, 173–93.
Albert J, Gupta A (1982) Distributions and estimation in contingency tables.
Annals of Statistics, 10, 1261–1268.
Albert J, Pepple P (1989) A Bayesian approach to some overdispersion models.
Canadian Journal of Statistics, 17, 333–44.
Albert P, Follmann D (2007) Random eﬀects and latent processes approaches
for analyzing binary longitudinal data with missingness: A comparison of
approaches using opiate clinical trial data. Statistical Methods in Medical
Research, 16, 417–39.
Allison P (1997) Survival analysis using the SAS system: A practical guide.
Cary, NC: SAS Institute Inc.
Allison P (2000) Multiple imputation for missing data: A cautionary tale.
Sociological Methods and Research, 28, 301–309.
Alqallaf F, Gustafson P (2001) On cross-validation of Bayesian models. Cana-
dian Journal of Statistics, 29, 333–40.
Altaleb A, Chauveau D (2002) Bayesian analysis of the logit model and com-
parison of two Metropolis–Hastings strategies. Computational Statistics
& Data Analysis, 39, 137–52.
Anderson J, Louis T, Holm N, Harvald B (1992) Time-dependent associa-
tion measures for bivariate survival distributions. Journal of American
Statistical Association, 87, 641–50.

References
503
Andersson M, Karlsson S (2007) Bayesian forecast combination for VAR mod-
els. Working Paper, ¨Oebro University.
Ando T (2007) Bayesian predictive information criterion for the evaluation
of hierarchical Bayesian and empirical Bayes models. Biometrika, 94,
443–58.
Ando T (2009) Bayesian factor analysis with fat-tailed factors and its exact
marginal likelihood. Journal of Multivariate Analysis, 100, 1717–26.
Andrews R, Currim I (2003) Retention of latent segments in regression-based
marketing models. International Journal of Research in Marketing, 20,
315–21.
Andrieu C, Moulines E (2006) On the ergodicity properties of some adaptive
MCMC algorithms. Annals of Applied Probability, 16 (3), 1462–1505.
Angers J-F, Biswas A (2003) A Bayesian analysis of zero-inﬂated generalized
Poisson model. Computational Statistics & Data Analysis, 42, 37–46.
Anselin L (1988) Spatial econometrics: Methods and models. Dordrecht:
Kluwer Academic.
Anselin L, Bera A (1998) Spatial dependence in linear regression models, with
an introduction to spatial econometrics. In A Ullah, D Giles (eds), Hand-
book of applied economic statistics. New York: Marcel Dekker, 237–90.
Anselin L, Hudak S (1992) Spatial econometrics in practice: A review of soft-
ware options. Regional Science & Urban Economics, 22, 509–36.
Antonio K, Beirlant J (2007) Actuarial statistics with generalized linear mixed
models. Insurance: Mathematics and Economics, 40, 58–76.
Arends L (2006) Multivariate meta-analysis: Modelling the heterogeneity. Re-
pub/EUR Repository; http://repub.eur.nl/publications/med hea.
Arhonditsis G, Paerl H, Valdes-Weaver L, Stow C, Steinberg J, Reckhow K
(2006) Application of Bayesian structural equation modeling for exam-
ining phytoplankton dynamics in the Neuse River Estuary. Estuarine,
Coastal & Shelf Science, 72, 63–80.
Arjas E, Gasbarra D (1994) Nonparametric Bayesian inference from right cen-
sored survival data, using the Gibbs sampler. Statistica Sinica, 4, 505–24.
Arminger G, Stein P, Wittenberg J (1999) Mixtures of conditional mean- and
covariance-structure models. Psychometrika, 64, 475–94.
Asai M, McAleer M, Yu J (2006) Multivariate stochastic volatility: A review.
Econometric Reviews, 25, 145–75.
Aslanidou H, Dey D, Sinha D (1998) Bayesian analysis of multivariate survival
data using Monte Carlo methods. Canadian Journal of Statistics, 26,
33–48.
Assun¸c˜ao R (2003) Space varying coeﬃcient models for small area data.
Environmetrics, 13, 1–21.
Austin P, Escobar, M (2005) Bayesian Modeling of Missing Data in Clinical
Research. Computational Statistics and Data Analysis, 49, 821–36.
Ayotte J, Baris D, Cantor K, Colt J, Robinson G, Lubin J, Karagas M,
Hoover R, Fraumeni J, Silverman D (2006) Bladder cancer mortality
and private well use in New England: An ecological study. Journal of
Epidemiology and Community Health, 60, 168–72.

504
References
Azzalini A (1985) A class of distributions which includes the normal ones.
Scandinavian Journal of Statistics, 12, 171–78.
Azzalini A (1994) Logistic regression and other discrete data models for se-
rially correlated observations. Statistical Methods and Applications, 3,
169–79.
Bae S, Famoye F, Wulu J, Bartolucci A, Singh K (2005) A rich family of
generalized Poisson regression models with applications. Mathematics and
Computers in Simulation, 69, 4–11.
Baker A, Bray I (2005) Bayesian projections: What are the eﬀects of excluding
data from younger age groups? American Journal of Epidemiology, 162,
798–805.
Baker M, Melino A (2000) Duration dependence and nonparametric hetero-
geneity: A Monte Carlo study. Journal of Econometrics, 96, 357–93.
Baladandayuthapani V, Mallick B, Carroll R (2005) Spatially adaptive
Bayesian penalized regression splines (P-splines). Journal of Computa-
tional and Graphical Statistics, 14, 378–94.
Balke N (1993) Detecting level shifts in time series. Journal of Business &
Economic Statistics, 11, 81–92.
Baltagi B (2003) Econometric Analysis of Panel Data, 2nd edn. Chichester,
Sussex: Wiley.
Baltagi B, Griﬃn, M (1988) A generalized error component model with het-
eroskedastic disturbances. International Economic Review, 29, 745–53.
Baltagi B, Li Q (1995) Testing AR(1) against MA(1) disturbances in an error
component model. Journal of Econometrics, 68, 133–51.
Baltagi B, Wu P (1999) Unequally spaced panel data regressions with AR(1)
disturbances. Econometric Theory, 15, 814–23.
Banerjee S, Carlin B (2004) Parametric spatial cure rate models for interval-
censored time-to-relapse data. Biometrics, 60, 268–75.
Banerjee S, Carlin B, Gelfand A (2004) Hierarchical modeling and analysis
for spatial data. Boca Raton, FL: Chapman & Hall/CRC.
Banﬁeld J, Raftery A (1993) Model-based Gaussian and non-Gaussian clus-
tering. Biometrics, 49, 803–21.
Banister J, Hill K (2004) Mortality in China 1964–2000. Population Studies,
58, 55–75.
Barmby T (2002) Worker absenteeism: A discrete hazard model with bivariate
heterogeneity. Labour Economics, 9, 469–47.
Barnard J, McCulloch R, Meng X (2000) Modeling covariance matrices in
terms of standard deviations and correlations, with applications to shrink-
age. Statistica Sinica, 10, 1281–1311.
Barnett G, Kohn R, Sheather S (1996) Bayesian estimation of an autoregres-
sive model using Markov chain Monte Carlo. Journal of Econometrics,
74, 237–54.
Barry R (2006) An alternative to the ‘ones’ trick?. BUGS Mailing List
08/11/2006 (http://www.jiscmail.ac.uk/lists/BUGS.html).
Bartholomew D (1987) Latent variable models and factor analysis. London:
Charles Griﬃn.

References
505
Bartholomew D, Steele F, Moustaki I, Galbraith J (2002) The analysis and
interpretation of multivariate data for social scientists. Boca Raton, FL:
CRC Press.
Bartlett M (1957) A comment on D.V. Lindley’s statistical paradox.
Biometrika, 44, 533–34.
Basu S (1996) Bayesian tests for unimodality. In Proceedings Sect. on Bayesian
Statistical Science. Amer. Statistical Assn., 77–82.
Batterham M (2005) Investigating heterogeneity in studies of resting energy
expenditure in persons with HIV/AIDS: a meta-analysis. American Jour-
nal of Clinical Nutrition, 81, 702–13.
Bauwens L, Lubrano M (1998) Bayesian inference on GARCH models using
the Gibbs sampler. Econometrics Journal, 1, C23–C46.
Bauwens L, Lubrano M, Richard J-F (1999) Bayesian inference in dynamic
econometric models. Oxford: Oxford University Press.
Bayarri M, Berger J (1999) Quantifying Surprise in the Data and Model Ver-
ication. In J Bernardo, J Berger, A Dawid, A Smith (eds), Bayesian
statistics 6. London: Oxford University Press, 53–82.
Bayarri M, Berger J (2000) P-values for composite null models. Journal of the
American Statistical Association, 95, 1127–42.
Bayarri M, Castellanos M (2007) Bayesian checking of the second levels of
hierarchical models. Statistical Science, 22, 363–67.
Bazan J, Bolfarine H, Branco M (2005) A general skew-probit link for bi-
nary response. In Proceedings of the 9th School of Regression Models. Sao
Pedro, Brazil: Associacao Brasileira de Estatstica, 267–81.
Bazan J, Branco M, Bolfarine H (2006) A skew item response model. Bayesian
Analysis, 1, 861–92.
Beck N (1983) Time-varying parameter regression models. American Journal
of Political Science, 27, 557–600.
Beck N (2004) Time series. In M Lewis-Beck, A Bryman, T Futing
Liao (eds), Encyclopedia of social science research methods. Thousand
Oaks, California: Sage.
Beck N, Jackman S (1998) Beyond linearity by default: Generalized additive
models. American Journal of Political Science, 42, 596–627.
Belitz C, Lang S (2008) Simultaneous selection of variables and smoothing pa-
rameters in structured additive regression models. Computational Statis-
tics & Data Analysis, 53, 61–81.
Bell B, Broemeling L (2000) A Bayesian analysis for spatial processes with
application to disease mapping. Statistics in Medicine, 19, 957–74.
Benjamin M, Rigby R, Stasinopoulos D (2003) Generalized autoregressive
moving average models. Journal of the American Statistical Association,
98, 214–23.
Bennett S (1983) Log-logistic regression models for survival data. Applied
Statistics, 32, 165–71.
Bentler P, Weeks D (1980) Linear structural equations with latent variables.
Psychometrika, 45, 289–308.

506
References
Bera A, Jarque C (1980) Eﬃcient tests for normality, homoscedasticity and
serial independence of regression residuals. Economics Letters, 6, 255–59.
Berger J (1990) Robust Bayesian analysis: Sensitivity to the prior. Journal of
Statistical Planning and Inference, 25, 303–28.
Berger J, Bernardo J (1992) On the development of reference priors. In
J Bernardo, J Berger, A Dawid, A Smith (eds), Bayesian Statistics 4.
Oxford: Clarendon Press, 35–60.
Berger J, Strawderman W, Tang D (2005) Posterior propriety and admissi-
bility of hyperpriors in normal hierarchical models. Annals of Statistics,
33, 606–46.
Berke O (2004) Exploratory disease mapping: Kriging the spatial risk function
from regional count data. International Journal of Health Geographics,
3, 18.
Berkes I, Horvath L, Ling S (2009), Estimation in nonstationary random
coeﬃcient autoregressive models. Journal of Time Series Analysis, 30,
395–416.
Berkhof J, van Mechelen I, Gelman A (2003) A Bayesian approach to the
selection and testing of mixture models. Statistica Sinica, 13, 423–42.
Berkhof J, van Mechelen I, Hoijtink H (2000) Posterior predictive checks:
Principles and discussion. Computational Statistics, 3, 337–54.
Berliner L (1996) Hierarchical Bayesian time series models. In K Hanson and
R Silver (eds), Maximum entropy and Bayesian methods. Amsterdam:
Kluwer Academic, 15–22.
Bernardinelli L, Clayton D, Montomoli C (1995) Bayesian estimates of disease
maps: How important are priors? Statistics in Medicine, 14, 2411–31.
Bernardinelli L, Clayton D, Pascutto C, Montomoli C, Ghislandi M, Songini M
(1995) Bayesian analysis of space-time variation in disease risk. Statistics
in Medicine, 14, 2433–43.
Bernardo J, Smith A (1994) Bayesian theory. Chichester, Sussex: Wiley.
Berrington A, Hu Y,Ramirez-Ducoing K, Smith P (2005) Multilevel modelling
of repeated ordinal measures: An application to attitude towards divorce.
Southampton Statistical Sciences Research Institute Applications and
Policy Working Paper M05/10 and ESRC Research Method Programme
Working Paper No 26.
Berry S, Carroll R, Ruppert D (2002) Bayesian smoothing and regression
splines for measurement error problems. Journal of the American Statis-
tical Association, 97, 160–69.
Berzuini C, Clayton D (1994) Bayesian analysis of survival on multiple time
scales. Statistics in Medicine, 13, 823–38.
Berzuini C, Larizza C (1996) A uniﬁed approach for modeling longitudinal and
failure time data, with application in medical monitoring. IEEE Trans-
actions on Pattern Analysis and Machine Intelligence, 18, 109–23.
Besag J (1989) Towards Bayesian image analysis. Journal of Applied Statistics,
16, 395–407.
Besag J (1974) Spatial interaction and the statistical analysis of lattice sys-
tems. Journal of the Royal Statistical Society: Series B, 36, 192–225.

References
507
Besag J, Green P (1993) Spatial statistics and Bayesian computation. Journal
of the Royal Statistical Society: Series B, 55, 25–37.
Besag J, Green P, Higdon D, Mengersen K (1995) Bayesian computation and
stochastic systems. Statistical Science, 10, 3–66.
Besag J, Kooperberg C (1995) On conditional and intrinsic autoregressions.
Biometrika, 82, 733–46.
Besag J, York J, Mollie A (1991) Bayesian image restoration, with two appli-
cations in spatial statistics. Annals of the Institute of Statistical Mathe-
matics, 43, 1–21.
Best N, Ickstadt K, Wolpert R (2000) Spatial Poisson regression for health and
exposure data measured at disparate resolutions. Journal of the American
Statistical Association, 95, 1076–88.
Bhattacharjee A, Jensen-Butler C (2006) Estimation of the spatial weights
matrix in the spatial error model. Discussion Paper, School of Economics
and Finance, University of St. Andrews.
Bijleveld F, Commandeur J, Gould P, Koopman S (2005) Model-based
measurement of latent risk in time series with applications. Tinbergen
Institute Discussion Paper No. 05-118/4. Available at SSRN: http://
ssrn.com/abstract=873466.
Bijma F, De Munck J, Huizenga H, Heethaar R, Nehorai A (2005) Simultane-
ous estimation and testing of sources in multiple MEG data sets. IEEE
Transactions on Signal Processing, 53, 3449–60.
Biller C (2000) Adaptive Bayesian regression splines in semiparametric gener-
alized linear models. Journal of Computational and Graphical Statistics,
9, 122–40.
Biller C, Fahrmeir L (1997) Bayesian spline-type smoothing in generalized
regression models. Computational Statistics, 12, 135–51.
Birkes D, Dodge Y (1993) Alternative methods of regression. Chichester: John
Wiley.
Bivand R, Gebhardt A (2000) Implementing functions for spatial statisti-
cal analysis using the R language. Journal of Geographical Systems, 2,
307–17.
Bockenholt U (1999) An INAR(1) negative multinomial regression model for
longitudinal count data. Psychometrika, 64, 53–68.
Bohning D (1999) Computer-assisted analysis of mixtures and applications:
Meta-analysis, disease mapping and others. New York: Chapman & Hall.
Bohning D, Dietz E, Schlattmann P, Mendonca L, Kirchner U (1999b) The
zero-inﬂated Poisson model and the decayed, missing and ﬁlled teeth
index in dental epidemiology. Journal of the Royal Statistical Society A,
162, 195–209.
Bollen K (1989) Structural equations with latent variables. New York: Wiley.
Bollen K, Curran P (2004) Autoregressive latent trajectory (ALT) models:
A synthesis of two traditions. Sociological Methods & Research, 32,
336–83.
Bollen K, Curran P (2006) Latent curve models: A structural equation ap-
proach. Hoboken, NJ: Wiley.

508
References
Bond S (2002) Dynamic panel data models: A guide to microdata methods
and practice. Portuguese Economic Journal, 1, 141–62.
Borsuk M, Stow C (2000) Bayesian parameter estimation in a mixed-order
model of BOD decay. Water Research, 34, 1830–36.
Bos C (2002) A comparison of marginal likelihood computation methods. In
W H¨ardle, B Ronz (eds), COMPSTAT 2002: Proceedings in computa-
tional statistics. Heidelberg: Physica-Verlag, 111–17.
Box-Steﬀensmeier J, Jones B (2004) Event history modeling. Cambridge: Cam-
bridge University Press.
Boyd H, Flanders W, Addiss D, Waller L (2005) Residual spatial correlation
between geographically referenced observations: A Bayesian hierarchical
modeling approach. Epidemiology, 16, 532–41.
Brown H, Prescott R (1999) Applied mixed models in medicine. Chichester:
Wiley.
Br¨uderl J, Diekmann A (1995) The log-logistic rate model: Two generaliza-
tions with an application to demographic data. Sociological Methods &
Research, 24, 158–86.
Bradlow E, Hardie B, Fader P (2002) Bayesian inference for the negative
binomial distribution via polynomial expansions. Journal of Computa-
tional and Graphical Statistics, 11, 189–201.
Brandt P, Freeman J (2006) Advances in Bayesian time series modeling and
the study of politics: Theory testing, forecasting, and policy analysis.
Political Analysis, 14, 1–36.
Brandt P, Williams J (2007) Modeling multiple time series. Thousand Oaks,
CA: Sage.
Breusch T (2005) Estimating the underground economy using MIMIC models.
Working Paper, National University of Australia, Canberra.
Brezger A, Kneib T, Lang S (2005) BayesX: Analysing Bayesian structured ad-
ditive regression models. Journal of Statistical Software, 14 (11), http://
www.jstatsoft.org/v14/i11/paper/
Brezger A, Kneib T, Lang S (2008) BayesX: Software for Bayesian inference
in structured additive regression models, Methodology Manual. Munich,
Version 1.5.
Brezger A, Lang S (2006) Generalized structured additive regression based
on Bayesian P-Splines. Computational Statistics and Data Analysis, 50,
967–91.
Brezger A, Steiner W (2008) Monotonic regression based on Bayesian
P-splines: An application to estimating price response functions from
store-level scanner data. Journal of Business and Economics Statistics,
26, 90–104.
Brooks S, Gelman A (1998) Alternative methods for monitoring convergence of
iterative simulations. Journal of Computational and Graphical Statistics,
7, 434–56.
Brooks S, Roberts G (1998) Convergence assessment techniques for Markov
chain Monte Carlo. Statistics and Computing, 8, 319–35.

References
509
Broto, C, Ruiz E (2004) Estimation methods for stochastic volatility models:
A survey. Journal of Economic Surveys, 18, 613–49.
Brown P, Fearn T, Haque M (1999) Discrimination with many variables. Jour-
nal of the American Statistical Association, 94, 1320–29.
Browne W (2004) An illustration of the use of reparameterisation methods for
improving MCMC eﬃciency in crossed random eﬀect models. Multilevel
Modelling Newsletter, 16, 13–25.
Browne W, Draper D (2006) A comparison of Bayesian and likelihood-based
methods for ﬁtting multilevel models. Bayesian Analysis, 1, 473–550.
Browne W, Draper D, Goldstein H, Rasbash J (2002) Bayesian and likeli-
hood methods for ﬁtting multilevel models with complex level-1 variation.
Computational Statistics and Data Analysis, 39, 203–25.
Browne W, Goldstein H, Rasbash J (2001) Multiple membership multiple
classiﬁcation (MMMC) models. Statistical Modelling, 1, 103–24.
Browne W, Steele F, Golalizadeh M (2009) The use of simple reparameteriza-
tions to improve the eﬃciency of Markov chain Monte Carlo estimation
for multilevel models with applications to discrete time survival models.
Journal of the Royal Statistical Society: Series A, 172, 579–98.
Brumback B, Rice J (1998) Smoothing spline models for the analysis of nested
and crossed samples of curves. Journal of the American Statistical Asso-
ciation, 93, 961–75.
Brumback B, Ruppert D, Wand M (1999) Variable selection and function
estimation in additive nonparametric regression using a data-based prior:
Comment. Journal of the American Statistical Association, 94, 794–97.
Brunsdon C, Fotheringham A, Charlton M (1998) Spatial nonstationarity and
autoregressive models. Environment and Planning A, 30, 957–73.
Buck C, Sahu S (2000) Bayesian models for relative archaeological chronology
building. Applied Statistics, 49, 423–44.
Buenconsejo J, Fish D, Childs J, Holford T (2008) A Bayesian hierarchical
model for the estimation of two incomplete surveillance data sets. Statis-
tics in Medicine, 27, 3269–85.
Bulmer M (1974) On ﬁtting the Poisson log-normal distribution to species
abundance data. Biometrics, 30, 101–110.
Burnham K, Anderson D (2002) Model selection and multimodel inference: A
practical information-theoretic approach. 2nd edn. New York: Springer-
Verlag.
Burr D, Doss H (2005) A Bayesian semi-parametric model for random ef-
fects meta analysis. Journal of the American Statistical Association, 100,
242–51.
Butler S, Louis T (1992). Random eﬀects models with non-parametric priors.
Statistics in Medicine, 11, 1981–2000.
Cai B, Dunson D (2006) Bayesian covariance selection in generalized linear
mixed models. Biometrics, 62, 446–57.
Cai B, Dunson D (2008) Bayesian variable selection in generalized linear mixed
models. In D. Dunson (ed.), Random eﬀect and latent variable model
selection. New York: Springer, 63–83.

510
References
Cai Z, Yao Q, Zhang W (2002) Smoothing for discrete-valued time series.
Journal of the Royal Statistical Society: Series B, 357–75.
Calder C (2003) Exploring latent structure in spatial temporal processes using
process convolutions. PhD thesis, Duke University.
Calder C (2007) Dynamic factor process convolution models for multivariate
space–time data with application to air quality assessment. Environmen-
tal and Ecological Statistics, 14, 229–47.
Cameron A, Trivedi P (1998) Regression analysis of count data. Cambridge:
Cambridge University Press.
Candel J, Winkens B (2003) Performance of empirical Bayes estimators of
level-2 random parameters in multilevel analysis: A Monte Carlo study
for longitudinal designs. Journal of Educational and Behavioral Statistics,
28, 169–94.
Cao G, West M (1996) Practical Bayesian inference using mixtures of mix-
tures. Biometrics, 52, 1334–41.
Cargnoni C, Muller P, West M (1997) Bayesian forecasting of multinomial
time series through conditionally Gaussian dynamic models. Journal of
the American Statistical Association, 92, 587–606.
Carlin B, Klugman S (1993) Hierarchical Bayesian Whittaker graduation.
Scandinavian Actuarial Journal, 183–96.
Carlin B, Louis T (2000) Bayes and empirical Bayes methods for data analysis.
2nd edn. Chapman and Hall: London.
Carlin B, Polson D, Stoﬀer D (1992) A Monte Carlo approach to nonnormal
and nonlinear state space modelling. Journal of the American Statistical
Association, 87, 493–500.
Carlin B, Polson N (1992) Monte Carlo Bayesian methods for discrete regres-
sion models and categorical time series. In J Bernardo, J Berger, A Dawid,
A Smith (eds), Bayesian Statistics 4. Oxford: Oxford University Press,
577–86.
Carlin J (1992) Meta-analysis for 2×2 tables: A Bayesian approach. Statistics
in Medicine, 11, 141–58.
Carroll R, Ruppert D (1982) Robust estimation in heteroscedastic models.
Annals of Statistics, 10, 429–44.
Carroll D, Ruppert D (1984) Power transformations when ﬁtting theoreti-
cal models to data. Journal of the American Statistical Association, 79,
321–28.
Carter C, Kohn R (1994) On Gibbs sampling for state space models.
Biometrika, 81, 541–53.
Celeux G, Forbes F, Robert C, Titterington M (2006) Deviance information
criteria for missing data models. Bayesian Analysis, 1, 651–74.
Celeux G, Hurn M, Robert C (2000) Computational and inferential diﬃculties
with mixture posterior distributions. Journal of the American Statistical
Association, 95, 957–70.
Cepeda E, Gamerman D (2000) Bayesian modeling of variance heterogeneity
in normal regression models. Brazilian Journal of Probability and Statis-
tics, 14, 207–21.

References
511
Cepeda E, Gamerman D (2004) Bayesian modeling of joint regressions for the
mean and covariance matrix. Biometrical Journal, 46, 430–40.
Cepeda-Benito A, Reynoso N, Erath S (2004) Meta-analysis of the eﬃcacy of
nicotine replacement therapy for smoking cessation: Diﬀerences between
men and women. Journal of Consulting and Clinical Psychology, 72,
712–22.
Chaix B, Merlo J, Chauvin P (2005) Comparison of a spatial approach with
the multilevel approach for investigating place eﬀects on health: The
example of healthcare utilisation in France. Journal of Epidemiology and
Community Health, 59, 517–26.
Chaloner K, Brant R (1988) A Bayesian approach to outlier detection and
residual analysis. Biometrika, 75, 651–60.
Chamberlain G, Hirano K (1999) Predictive distributions based on longitudi-
nal earnings data. Annales d’Economie et de Statistique, 55, 211–42.
Chan D, Kohn R, Kirby C (2006) Multivariate stochastic volatility models
with correlated errors. Econometric Reviews, 25, 245–74.
Chan K, Ledolter J (1995) Monte Carlo EM estimation for time series mod-
els involving counts. Journal of the American Statistical Association, 90,
242–52.
Chang Y, Gianola D, Heringstad B, Klemetsdal G (2006) A comparison
between multivariate Slash, Student’s t and probit threshold models for
analysis of clinical mastitis in ﬁrst lactation cows. Journal of Animal
Breeding and Genetics, 123, 290–300.
Chatuverdi A, Kumar J (2005) Bayesian unit root test for model with main-
tained trend. Statistics & Probability Letters, 74, 109–15.
Chen C, Liu L (1993) Joint estimation of model parameters and outlier eﬀects
in time series. Journal of the American Statistical Association, 88, 284–97.
Chen C, So M (2006) On a threshold heteroscedastic model. International
Journal of Forecasting, 22, 73–89.
Chen M, Ibrahim J (2000) Bayesian predictive inference for time series count
data. Biometrics, 56, 678–85.
Chen M-H (2005) Computing marginal likelihoods from a single MCMC out-
put. Statistica Neerlandica, 59, 16–29.
Chen M-H, Dey D (1998) Bayesian modeling of correlated binary responses
via scale mixture of multivariate normal link functions. Sankhya 60A,
322–43.
Chen M-H, Dey D (2000) Bayesian analysis for correlated ordinal data mod-
els. In D Dey, S Ghosh, B Mallick (eds), Generalized linear models: A
Bayesian perspective. New York: Marcel Dekker, 133–58.
Chen M-H, Ibrahim J (2006) The relationship between the power prior and
hierarchical models. Bayesian Analysis, 1, 551–74.
Chen M-H, Ibrahim J, Shao Q-M (2000) Power prior distributions for gen-
eralized linear models. Journal of Statistical Planning and Inference, 84,
121–37.
Chen M-H, Ibrahim J, Sinha D (1999) A new Bayesian model for survival data
with a surviving fraction. Journal of the American Statistical Association,
94, 909–19.

512
References
Chen M-H, Ibrahim J, Sinha D (2002) Bayesian inference for multivariate
survival data with a cure fraction. Journal of Multivariate Analysis, 80,
101–26.
Chen M-H, Shao Q-M (1999) Monte Carlo estimation of Bayesian credible
and HPD intervals. Journal of Computational & Graphical Statistics, 8,
69–92.
Chen X, Ender P, Mitchell M, Wells C (2003) Regression with Stata, from
http://www.ats.ucla.edu/stat/stata/webbooks/reg/default.htm
Chen Y, Jewell N (2001) On a general class of semiparametric hazards regres-
sion models. Biometrika, 88, 687–702.
Chen Z (1993) Fitting multivariate regression functions by interaction spline
models. Journal of the Royal Statistical Society: Series B, 55, 473–91.
Chen Z, Dunson D (2003) Random eﬀects selection in linear mixed models.
Biometrics, 59, 762–69.
Chen Z, Kuo L (2001) A note on the estimation of the multinomial logit model
with random eﬀects. The American Statistician, 55, 89–95.
Chi E, Reinsel G (1989) Models for longitudinal data with random eﬀects
and AR(1) errors. Journal of the American Statistical Association, 84,
452–59.
Chiang C (1984) The life table and its applications. Malabar, FL: R.E. Krieger.
Chiang J, Chib S, Narasimhan C (1999) Markov Chain Monte Carlo and mod-
els of consideration set and parameter heterogeneity. Journal of Econo-
metrics, 89, 223–48.
Chib S (1993) Bayes regression with autoregressive errors: A Gibbs sampling
approach. Journal of Econometrics, 58, 275–94.
Chib S (2008) Panel Data Modeling and Inference: A Bayesian Primer. In
L Matyas, P Sevestre (eds), The econometrics of panel data. 3rd edn.
Berlin: Springer-Verlag, 479–515.
Chib S, Carlin B (1999) On MCMC sampling in hierarchical longitudinal
models. Statistics & Computing, 9, 17–26.
Chib S, Greenberg E (1994) Bayes inference in regression models with ARMA
(p, q) errors. Journal of Econometrics, 64, 183–206.
Chib S, Greenberg E (1995) Understanding the Metropolis-Hastings algo-
rithm. The American Statistician, 49, 327–35.
Chib S, Greenberg E (1998) Analysis of multivariate probit models.
Biometrika, 85, 347–61.
Chib S, Jeliazkov I (2001) Marginal likelihood from the Metropolis-Hastings
output. Journal of the American Statistical Association, 96, 270–81.
Chib S, Jeliazkov I (2006) Inference in semiparametric dynamic models for
binary longitudinal data. Journal of the American Statistical Association,
101, 685–700.
Chib S, Nardari F, Shephard N (2002) Markov Chain Monte Carlo methods
for stochastic volatility models. Journal of Econometrics, 108, 281–316.
Chib S, Nardari F, Shephard N (2005) Analysis of high dimensional multivari-
ate stochastic volatility models. Journal of Econometrics, 134, 341–71.

References
513
Chib S, Winkelmann R (2001) Markov chain Monte Carlo analysis of corre-
lated count data. Journal of Business & Economic Statistics, 19, 428–35.
Chintagunta P, Kyriazidou E, Perktold J (2001) Panel data analysis of house-
hold brand choices. Journal of Econometrics, 103, 111–53.
Chiogna M, Gaetan C (2002) Dynamic generalized linear models with appli-
cation to environmental epidemiology. Applied Statistics, 51, 453–68.
Cho M, Schenker N (1999) Fitting the Log-F accelerated failure time model
with incomplete covariate data. Biometrics, 55, 826–33.
Christensen O, Waagepetersen R (2002) Bayesian prediction of spatial count
data using generalised linear mixed models. Biometrics, 58, 280–86.
Christiansen C, Morris C (1996) Fitting and checking a two-level Poisson
model: Modeling patient mortality rates in heart transplant patients.
In D Berry, D Stangl (eds), Bayesian Biostatistics. New York: Marcel
Dekker, 467–501.
Christiansen C, Morris C (1997) Hierarchical Poisson regression modeling.
Journal of the American Statistical Association, 92, 618–32.
Chun Y, Sumichrast R (2007) Bayesian inspection model with the negative
binomial prior in the presence of inspection errors. European Journal of
Operational Research, 182, 1188–1202.
Chung H, Loken E, Schafer J (2004) Diﬃculties in drawing inferences with
ﬁnite-mixture models: A simple example. The American Statistician, 58,
152–58.
Clayton D (1991) A Monte Carlo method for Bayesian inference in frailty
models. Biometrics, 47, 467–85.
Clayton D (1996) Generalized linear mixed models. In W Gilks, S Richardson,
D Spiegelhalter (eds), Markov Chain Monte Carlo in practice. London:
Chapman and Hall, 275–301.
Clayton D, Kaldor J (1987) Empirical Bayes estimates of age-standardised
relative risks for use in disease mapping. Biometrics, 43, 671–82.
Clayton D, Schiﬄers E (1987) Models for temporal variation in cancer rates.
II: Age-period-cohort models. Statistics in Medicine, 6, 467–810.
CliﬀA, Ord J (1973) Spatial autocorrelation. London: Pion.
CliﬀA, Ord J (1981) Spatial processes: Models and applications. London, Pion.
Cohen J, Nagin D, Wallstrom G, Wasserman L (1998) Hierarchical Bayesian
analysis of arrest rates. Journal of the American Statistical Association,
93, 1260–70.
Collett D (2002) Modelling binary data, 2nd edn. New York, CRC Press.
Congdon P (2003) Applied Bayesian modelling. Chichester: Wiley.
Congdon P (2006a) A model framework for mortality and health data classiﬁed
by age, area and time. Biometrics, 61, 269–78.
Congdon P (2006b) A model for geographical variation in health and total life
expectancy. Demographic Research, 14, 157–78.
Congdon P (2007a) Model weights for model choice and averaging. Statistical
Methodology, 4, 143–57.
Congdon P (2007b) Mixtures of spatial and unstructured eﬀects for spatially
discontinuous health outcomes. Computational Statistics and Data Anal-
ysis, 51, 3197–3212.

514
References
Congdon P (2008a) A spatially adaptive conditional autoregressive prior for
area health data. Statistical Methodology, 5, 552–63.
Congdon P (2008b) Modelling the impact of socioeconomic structure on spa-
tial health outcomes. Computational Statistics and Data Analysis, 53,
3047–56.
Congdon P (2008c) A bivariate frailty model for events with a permanent
survivor fraction and non-monotonic hazards; with an application to age
at ﬁrst maternity, Computational Statistics & Data Analysis, 52, 4346–56.
Congdon P (2009) Life expectancies for small areas: a Bayesian random eﬀects
methodology. International Statistical Review, 77, 222–40.
Congdon P, Almog M, Curtis S, Ellerman R (2007) A spatial structural
equation modelling framework for health count responses. Statistics in
Medicine, 26 (29), 5267–84.
Congdon P, Lloyd P (2010) Estimating small area diabetes prevalence in the
US using the behavioral risk factor surveillance system. Journal of Data
Science, 8 (2), forthcoming.
Conlon E, Louis T (1999) Addressing multiple goals in evaluating region-
speciﬁc risk using Bayesian methods. In A Lawson, A Bigger, D Bohning,
E Lesaﬀre, J Viel, R Bertollini (eds), Disease mapping and risk assessment
for public health. Chichester: John Wiley, 31–47.
Conlon E, Song N, Liu A (2007) Bayesian meta-analysis models for microarray
data: A comparative study. BMC Bioinformatics, 8, 80 doi:10.1186/1471-
2105-8-80.
Consul P (1989) Generalized Poisson distributions. New York: Marcel Dekker.
Cook D, Pocock S (1983) Multiple regression in geographical mortality studies,
with allowance for spatially correlated errors. Biometrics, 39, 361–71.
Cooley T, Prescott E (1976) Estimation in the presence of stochastic para-
meter variation. Econometrica, 44, 167–84.
Cooner F, Banerjee S, McBean A (2006) Modelling geographically referenced
survival data with a cure fraction. Statistical Methods in Medical Re-
search, 15, 307–24.
Copas J, Li H (1997) Inference for non-random samples. Journal of the Royal
Statistical Society B, 59, 55–95.
Coughlin C, Garrett T, Hernandez-Murillo R (2004) Spatial probit and the
geographic patterns of state lotteries. No 2003-042, Working Papers from
Federal Reserve Bank of St. Louis.
Coull B, Ruppert D, Wand, M (2001) Simple incorporation of interactions
into additive models. Biometrics, 57, 539–45.
Cox D (1970) The analysis of binary data. London: Methuen.
Cox D (1972) Regression models and life-tables. Journal of the Royal Statis-
tical Society: Series B, 34, 187–220.
Cox D (1981) Statistical analysis of time series: Some recent developments.
Scandinavian Journal of Statistics, 8, 93–115.
Cressie N, Kapat P (2008) Some diagnostics for Markov random ﬁelds. Journal
of Computational and Graphical Statistics, 17, 726–49.

References
515
Crowder M (1978) Beta-binomial Anova for proportions. Applied Statistics,
27, 34–37.
Crowder M (2001) Classical competing risks. Boca Raton, FL: CRC Press.
Curran D, Molenberghs G, Aaronson N, Fossa S, Sylvester R (2002) Analyz-
ing longitudinal continuous quality of life data with dropout. Statistical
Methods in Medical Research, 11, 5–23.
Currie I, Durban M (2002) Flexible smoothing with P-splines: A uniﬁed ap-
proach. Statistical Modelling, 2, 333–49.
Czado C (2000) Multivariate regression analysis of Panel data with binary
outcomes applied to unemployment data. Statistical Papers, 41, 281–304.
Czado C, Erhardt V, Min A, Wagner S (2007) Zero-inﬂated generalized Pois-
son models with regression eﬀects on the mean, dispersion and zero-
inﬂation level applied to patent outsourcing rates. Statistical Modelling,
7, 125–53.
Damien P, Muller P (1998) A Bayesian bivariate failure time regression model.
Computational Statistics & Data Analysis, 28, 77–85.
Dangl T, Halling M (2007) Predictive regressions with time-varying coeﬃ-
cients (March 15, 2007). Available at SSRN: http://ssrn.com/abstract=
971712.
Daniels M (1999) A prior for the variance in hierarchical models. Canadian
Journal of Statistics, 27, 569–80.
Daniels M, Gatsonis C (1999) Hierarchical generalized linear models in the
analysis of variations in health care utilization. Journal of the American
Statistical Association, 94, 29–42.
Daniels M, Hogan J (2008) Missing data in longitudinal studies: Strate-
gies for Bayesian modeling and sensitivity analysis. Boca Raton, FL:
CRC/Chapman & Hall.
Daniels M, Kass R (1999) Nonconjugate Bayesian estimation of covariance
matrices and its use in hierarchical models. Journal of the American Sta-
tistical Association, 94, 1254–63.
Daniels M, Kass R (2001) Shrinkage estimators for covariance matrices. Bio-
metrics, 57, 1174–84.
Daniels M, Normand S (2006) Longitudinal proﬁling of health care units based
on continuous and discrete patient outcomes. Biostatistics, 7, 1–15.
Daniels M, Pourahmadi M (2002) Bayesian analysis of covariance matrices
and dynamic models for longitudinal data. Biometrika, 89, 553–66.
Daniels M, Zhao Y (2003) Modelling the random eﬀects covariance matrix in
longitudinal data. Statistics in Medicine, 22, 1631–47.
Darby S, Fearn T (1979) The Chatham blood pressure study. An application
of Bayesian growth curve models to a longitudinal study of blood pressure
in children. International Journal of Epidemiology, 8, 15–21.
Das S, Dey D (2006) On Bayesian analysis of generalized linear models using
the Jacobian technique. The American Statistician, 60, 264–68.
Das S, Dey D (2007) On Bayesian Analysis of Generalized Linear Models: A
New Perspective. Technical Report 2007-8, Statistical and Applied Math-
ematical Sciences Institute, UNC (www.samsi.info).

516
References
Dauxois J-Y, Druilhet P, Pommeret D (2006) A Bayesian choice between
Poisson, binomial and negative binomial models. Test, 15, 423–32.
Davidian M, Giltinan D (2003) Nonlinear models for repeated measures data:
An overview and update. Journal of Agricultural, Biological, and Envi-
ronmental Statistics, 8, 387–419.
Davies R (1994) From cross-sectional to longitudinal analysis. In A Dale,
R Davies (eds), Analysing social and political change: A casebook of meth-
ods. London: Sage Publications, 20–40.
Davis R, Dunsmuir W, Streett S (2003) Observation-driven models for Poisson
counts. Biometrika, 90, 777–90.
De Jong P, Penzer J (1998) Diagnosing shocks in time series. Journal of the
American Statistical Association, 93, 796–806.
De Jong P, Penzer J (2004) The ARMA model in state space form. Statistics &
Probability Letters, 70, 119–25.
De Jong P, Shephard N (1995) The simulation smoother for time series models.
Biometrika, 82, 339–50.
de la Horra J, Rodrıguez-Bernal M (2005) Bayesian model selection: A pre-
dictive approach with losses based on distances. Statistics & Probability
Letters, 71, 257–65.
De Oliveira V, Kedem B, Short D (1997) Bayesian prediction of transformed
Gaussian random ﬁelds. Journal of the American Statistical Association.
92, 1422–33.
Dean C, MacNab Y (2001) Modeling of rates over a hierarchical health
administrative structure. Canadian Journal of Statistics, 29, 405–19.
Deely J, Smith A (1998) Quantitative reﬁnements for comparisons of insti-
tutional performance. Journal of the Royal Statistical Society: Series A,
161, 5–12.
Dellaportas P, Smith A (1993) Bayesian inference for generalized linear and
proportional hazards models via Gibbs sampling. Applied Statistics, 42,
443–59.
Delucchi K, Bostrom A (2004) Methods for analysis of skewed data distri-
butions in psychiatric clinical studies: Working with many zero values.
American Journal of Psychiatry, 161, 1159–68.
Denison D, Mallick B, Smith A (1998) Automatic Bayesian curve ﬁtting.
Journal of the Royal Statistical Society B, 60, 333–50.
Dennison D, Holmes C, Mallick B, Smith A (2002) Bayesian methods for
non-linear classiﬁcation and regression. John Wiley: Chichester.
Dey D, Ghosh S, Mallick B (eds) (2000) Generalized linear models: A Bayesian
perspective. New York: Marcel Dekker.
Dey D, Ravishanker N (2000) Bayesian approaches for overdispersion in gen-
eralized linear models. In D Dey, S Ghosh, B Mallick (eds), Generalized
linear models: A Bayesian perspective. New York: Dekker, 73–88.
Diaconis P, Ylvisaker D (1979) Conjugate priors for exponential families. An-
nals of Statistics, 7, 269–81.
Dias R, Gamerman D (2002) A Bayesian approach to hybrid splines non-
parametric regression. Journal of Statistical Computation and Simulation,
72, 285–98.

References
517
Diebolt N, Robert C (1994) Estimation of ﬁnite mixture distributions through
Bayesian sampling. Journal of the Royal Statistical Society: Series B, 56,
363–75.
Diekmann A, Mitter P (1983) The “Sickle Hypothesis”: A time-dependent
Poisson model with applications to deviant behavior and occupational
mobility. Journal of Mathematical Sociology, 9, 85–101.
Diggle P, Kenward M (1994) Informative dropout in longitudinal data analy-
sis. Journal of the Royal Statistical Society: Series C, 43, 49–94.
Diggle P, Liang K, Zeger S (1994) Analysis of longitudinal data. Oxford:
Clarendon Press.
Diggle P, Ribeiro P (2001) Bayesian inference in Gaussian model-based geo-
statistics. Geographical and Environmental Modelling, 6, 129–46.
Diggle P, Ribeiro P, Christensen O (2003) An introduction to model based
geostatistics. In J M¨oller (ed.), Spatial statistics and computational meth-
ods. Lecture Notes in Statistics, Vol. 173. New York: Springer, 43–86.
Diggle P, Tawn J, Moyeed R (1998) Model based geostatistics. Applied Statis-
tics, 47, 299–350.
Diggle P, Zeger S (1989) A non-Gaussian model for time series with pulses.
Journal of the American Statistical Association, 84, 354–59.
Disease Mapping Collaborative Group (2000) Disease mapping models: An
empirical evaluation. Statistics in Medicine, 19, 2217–41.
Diserud O, Engen S (2000) A general and dynamic species abundance model,
embracing the lognormal and the gamma models. The American Natu-
ralist, 155, 497–511.
Dorsett R (1999) An econometric analysis of smoking prevalence among lone
mothers. Journal of Health Economics, 18, 429–41.
Draper D (1995) Assessment and propagation of model uncertainty. Journal
of the Royal Statistical Society: Series B, 57, 45–97.
Draper D (1995) Inference and hierarchical modeling in the social sciences.
Journal of Educational and Behavioral Statistics, 20, 115–47.
Droguett E, Groen F, Mosleh A (2006) Bayesian assessment of the variability
of reliability measures. Pesquisa Operacional, 26, 109–127.
DuMouchel W (1996) Predictive cross-validation of Bayesian meta-analyses.
In Bernardo J, Berger J, Dawid A, Smith A (eds), Bayesian Statistics 5.
Oxford: Oxford University Press, 107–27.
DuMouchel W, Waternaux C (1992) Discussion of “Hierarchical models for
combining information and for meta-analysis,” by C Morris and S Nor-
mand. In J Bernardo, J Berger, A Dawid, A Smith (eds), Bayesian Statis-
tics, Vol. 4. Oxford: Clarendon Press, 338–41.
Duan J, Guindani M, Gelfand A (2007) Generalized spatial Dirichlet process
models. Biometrika, 94, 809–25.
Dunson D (2001) Commentary: Practical advantages of Bayesian analysis of
epidemiologic data. American Journal of Epidemiology, 153, 1222–26.
Dunson D (2003) Dynamic latent trait models for multidimensional longitu-
dinal data. Journal of the American Statistical Association, 98, 555–63.

518
References
Dunson D (2006) Bayesian dynamic modeling of latent trait distributions.
Biostatistics, 7, 551–68.
Dunson D (2007) Bayesian methods for latent trait modeling of longitudinal
data. Statistical Methods in Medical Research, 16, 399–415.
Dunson D, Herring A (2005) Bayesian latent variable models for mixed dis-
crete outcomes. Biostatistics, 6, 11–25.
Dunson D, Pillai N, Park J (2007) Bayesian density regression. Journal of the
Royal Statistical Society: Series B, 69, 163–83.
Durban M, Currie I, Eilers P (2006) Multidimensional P-spline mixed models:
A uniﬁed approach to smoothing on large grids. Working Paper.
Durbin J (2000) The Foreman lecture: The state space approach to time series
analysis and its potential for oﬃcial statistics. Australian & New Zealand
Journal of Statistics, 42, 1–24.
Durbin J, Koopman S (2000) Time series analysis of non-Gaussian obser-
vations based on state space models from both classical and Bayesian
perspectives. Journal of the Royal Statistical Society, 62B, 3–56.
Durbin J, Koopman S (2001) Time series analysis by state space methods.
Oxford: Oxford University Press.
Eaton W (1974) Mental hospitalization as a reinforcement process. American
Sociological Review, 39, 252–60.
Edwards Y, Allenby G (2003) Multivariate analysis of multiple response data.
Journal of Marketing Research, 40, 321–34.
Efron B (1986) Double exponential families and their use in generalized linear
regression. Journal of the American Statistical Association, 81, 709–21.
Eid M (1996) Longitudinal conﬁrmatory factor analysis for polytomous item
responses: Model deﬁnition and model selection on the basis of stochastic
measurement. Methods of Psychological Research Online, 1, 65–85.
Eilers P, Marx B (1996) Flexible smoothing with B-splines and penalties.
Statistical Science, 11, 89–121.
Eilers P, Marx B (2004) Splines, knots, and penalties. Working Paper (www.
stat.lsu.edu/faculty/marx/)
Eksler V (2008) Exploring spatial structure behind the road mortality of re-
gions in Europe. Applied Spatial Analysis and Policy, 1, 133–50.
Engle R (1982) Autoregressive conditional heteroscedasticity with estimates
of variance of United Kingdom inﬂation. Econometrica, 50, 987–1008.
Engle R, Granger C, Rice J, Weiss A (1986) Semiparametric estimates of the
relation between weather and electricity sales. Journal of the American
Statistical Association, 81, 310–20.
Epstein D, O’Halloran S (1996) Divided government and the design of ad-
ministrative procedures: a formal model and empirical test. Journal of
Politics, 58, 373–97.
Erbas B, Hyndman R (2005) Sensitivity of the estimated air pollution–
respiratory admissions relationship to statistical model choice. Inter-
national Journal of Environmental Health Research, 15, 437–48.
Erkanli A, Soyer R, Angold A (2001) Bayesian analyses of longitudinal bi-
nary data using Markov regression models of unknown order. Statistics
in Medicine, 20, 755–70.

References
519
Escobar M, West M (1998) Computing nonparametric hierarchical models. In
D Dey, P Muller, D Sinha (eds), Practical Nonparametric and Semipara-
metric Bayesian Statistics. New York: Springer-Verlag, 1–22.
Evans J, Middleton N, Gunnell D (2004) Social fragmentation, severe mental
illness and suicide. Social Psychiatry and Psychiatric Epidemiology, 39,
165–70.
Everitt B (1984) An introduction to latent variable models. London: Chapman
and Hall.
Everitt B, Hand D (1981) Finite Mixture Distributions. London: Chapman &
Hall.
Everson P, Morris C (2000) Inference for multivariate normal hierarchical
models. Journal of the Royal Statistical Society: Series B, 62, 399–412.
Fahrmeir L, Knorr Held L (1997) Dynamic discrete time duration models.
Sociological Methodology, 27, 417–52.
Fahrmeir L, Knorr-Held L (2000) Dynamic and semiparametric models. In
M Schimek (ed.), Smoothing and regression: Approaches, computation
and application. New York: John Wiley, 513–43.
Fahrmeir L, Lang S (2001) Bayesian inference for generalized additive mixed
models based on Markov random ﬁeld priors. Journal of the Royal Sta-
tistical Society: Series C, 50, 201–20.
Fahrmeir L, Osuna L (2003) Structured count data regression. Sonder-
forschungsbereich 386, Discussion Paper 334, University of Munich.
Fahrmeir L, Osuna L (2006) Structured additive regression for overdispersed
and zero-inﬂated count data. Applied Stochastic Models in Business and
Industry, 22, 351–69.
Fahrmeir L, Tutz G (2001) Multivariate statistical modelling based on gen-
eralized linear models, 2nd edn. Springer Series in Statistics. New-York:
Springer Verlag.
Farber S, P´aez A (2007) A systematic investigation of cross-validation in GWR
model estimation: Empirical analysis and Monte Carlo simulations. Jour-
nal of Geographical Systems, 9, 371–96.
Fay R, Herriot R (1979) Estimates of income for small places: An empirical
Bayes application of James-Stein procedures to census data. Journal of
the American Statistical Association, 78, 269–77.
Fernandez C, Green P (2002) Modelling spatially correlated data via mixtures:
A Bayesian approach. Journal of the Royal Statistical Society: Series B,
64, 805–26.
Fernandez C, Ley E, Steel M (2001) Benchmark priors for Bayesian model
averaging. Journal of Econometrics, 100, 381–427.
Fernandez C, Steel M (1998) On Bayesian modeling of fat tails and skewness.
Journal of the American Statistical Association, 93, 359–71.
Fernandez C, Steel M (2000) Bayesian regression analysis with scale mixtures
of normals. Econometric Theory, 16, 80–101.
Ferreira M, Gamerman D (2000) Dynamic generalized linear models. In D Dey,
S Ghosh, B Mallick (eds), Generalized linear models: A Bayesian perspec-
tive. New York: Marcel Dekker, 57–72.

520
References
Fichman M, Cummings J (2003) Multiple imputation for missing data: Making
the most of what you know. Organizational Research Methods, 6, 282–308.
Finkel S (1995) Causal analysis with panel data. Beverly Hills: Sage
Publications.
Finley A, Banerjee S, Carlin B (2006) spBayes: An R package for univari-
ate and multivariate hierarchical point-referenced spatial models. Source:
blue.fr.umn.edu/spatialBayes/.
Flay B, Hansen W, Johnson C, Collins L, Dent C, Dwyer K, Grossman L,
Hockstein G, Rauch J, Sobol J, Sobel D, Sussman S, Ulene A (1987)
Implementation eﬀectiveness trial of a social inﬂuences smoking preven-
tion program using schools and television. Health Education Research, 2,
385–400.
Fleishman J, Lawrence W (2003) Demographic variation in SF-12 scores: True
diﬀerences or diﬀerential item functioning? Medical Care, 41, 75–86.
Fleming T, Harrington D (1991) Counting processes and survival analysis.
Chichester: John Wiley.
Florens J, Fougere D, Mouchart M (1995) Duration models. In L Matyas,
P Sevestre (eds), The econometrics of panel data. Amsterdam: Kluwer,
491–534.
Fokianos K, Kedem B (2003) Regression theory for categorical time series.
Statistical Science, 18, 357–76.
Fokoue E (2004) Stochastic determination of the intrinsic structure in
Bayesian factor analysis. SAMSI Technical Report #2004-17 (http://
www.samsi.info/reports/index.shtml).
Fonseca T, Ferreira M, Migon H (2008) Objective Bayesian analysis for the
Student-t regression model. Biometrika, 95, 325–33.
Fotheringham A, Brunsdon C, Charlton, M (2002) Geographically weighted
regression: the analysis of spatially varying relationships. Chichester, UK:
Wiley.
Fotouhi A (2005) The initial conditions problem in longitudinal binary pro-
cess: A simulation study. Simulation Modelling Practice and Theory, 13,
566–83.
Fotouhi A (2007) The initial conditions problem in longitudinal count pro-
cess: A simulation study. Simulation Modelling Practice and Theory, 15,
589–604.
Fox A (1972) Outliers in time series. Journal of the Royal Statistical Society:
Series B, 34, 350–63.
Fox J, Glas C (2005) Bayesian modiﬁcation indices for IRT models. Statistica
Neerlandica, 59, 95–106.
Franzese R, Hays J (2007) The spatial probit model of interdependent binary
outcomes: Estimation, interpretation, and presentation. The Society for
Political Methodology, Working Papers.
Franzese R, Hays J (2008) Empirical models of spatial interdependence.
In J Box-Steﬀensmeier, H Brady, D Collier (eds), Oxford handbook of
political methodology. Oxford University Press.

References
521
Frees E (2004) Longitudinal and panel data. Cambridge: Cambridge University
Press.
Frees E, Young V, Luo Y (2001) Case studies using panel data models. North
American Actuarial Journal, 5, 24–42.
Frey B, Weck-Hannemann H (1984) The hidden economy as an unobserved
variable. European Economic Review, 26, 33–53.
Friedman J (1991) Multivariate adaptive regression splines. Annals of Statis-
tics, 19, 1–67.
Friel N, Pettitt A (2008) Marginal likelihood estimation via power posteriors.
Journal of the Royal Statistical Society: Series B, 70, 589–607.
Friesen M, MacNab Y, Marion S, Demers P, Davies H, Teschke K (2006)
Mixed models and empirical Bayes estimation for retrospective exposure
assessment of dust exposures in Canadian sawmills. Annals of Occupa-
tional Hygiene, 50, 281–88.
Fruhwirth-Schattner S (2001) Markov Chain Monte Carlo estimation of classi-
cal and dynamic switching and mixture models. Journal of the American
Statistical Association, 96, 194–209.
Fruhwirth-Schnatter S (1994) Data augmentation and dynamic linear models.
Journal of Time Series Analysis, 15, 183–202.
Fruhwirth-Schnatter S (1999) Bayes factors and model selection for random
eﬀect models. Working Paper, Department of Statistics, University of
Business Administration and Economics, Vienna.
Fruhwirth-Schnatter S (2004) Estimating marginal likelihoods for mixture and
Markov switching models using bridge-sampling techniques. The Econo-
metrics Journal, 7, 143–67.
Fruhwirth-Schnatter S (2006) Finite mixture and Markov switching models.
New York: Springer.
Fruhwirth-Schnatter S, Fruhwirth R (2007) Auxiliary mixture sampling
with applications to logistic models. Computational Statistics and Data
Analysis, 51, 3509–28.
Fruhwirth-Schnatter S, Otter T, Tuchler R (2004) Bayesian analysis of the
heterogeneity model. Journal of Business & Economics Statistics, 22,
2–15.
Fruhwirth-Schnatter S, Tuchler R (2008) Bayesian parsimonious covariance
estimation for hierarchical linear mixed models. Statistics & Computing,
18, 1–13.
Fryback D, Stout N, Rosenberg M (2001) An elementary introduction to
Bayesian computing using WinBUGS. International Journal of Technol-
ogy Assessment in Health Care, 17, 96–113.
Fukumoto K (2005) Survival analysis of systematically dependent competing
risks: An application to the U.S. Congressional Careers, 22nd annual
summer meeting of the Society for Political Methodology, Tallahassee,
FL, USA.
Gabriel K (1962) Ante-dependence analysis of an ordered set of variables.
Annals of Mathematical Statistics, 33, 201–12.

522
References
Gail M, Santner T, Brown C (1980) An analysis of comparative carcinogenesis
experiments based on multiple times to tumor. Biometrics, 36, 255–66.
Galler H (2001) On the dynamics of individual wage rates—heterogeneity
and stationarity of wage rates of west german men. In R Friedmann,
L Kn¨uppel, H L¨utkepohl (eds), Econometric studies. A Festschrift in
Honour of Joachim Frohn. M¨unster: LIT, 269–93.
Gamerman D (1991) Dynamic Bayesian models for survival data. Journal of
the Royal Statistical Society C, 40, 63–79.
Gamerman D (1997) Eﬃcient sampling from the posterior distribution in gen-
eralized linear mixed models. Statistics and Computing, 7, 57–68.
Gamerman D (1998) Markov chain Monte Carlo for dynamic generalized linear
models. Biometrika, 85, 215–27.
Gamerman D, Moreira A, Rue H (2003) Space-varying regression models:
Speciﬁcations and simulation. Computational Statistics & Data Analysis,
42, 513–33.
Gao S (2004) Combining binomial data using the logistic normal. The Journal
of Statistical Computation and Simulation, 74, 293–306.
Garner C, Raudenbush S (1991) Neighborhood eﬀects on educational attain-
ment: A multilevel analysis. Sociology of Education, 64, 251–62.
Geisser S, Eddy W (1979) A predictive approach to model selection. Journal
of the American Statistical Association, 74, 153–60.
Gelfand A (1996) Model determination using sampling based methods. In
W Gilks, S Richardson, D Spiegelhalter (eds), Chapter 9 in Markov Chain
Monte Carlo in practice. Boca Raton, FL: Chapman & Hall/CRC.
Gelfand A, Dey D (1994) Bayesian model choice: asymptotics and exact cal-
culations. Journal of the Royal Statistical Society: Series B, 56, 501–14.
Gelfand A, Dey D, Chang H (1992) Model determination using predic-
tive distributions with implementations via sampling-based methods. In
J Bernardo et al., Bayesian statistics 4. Oxford: Oxford University Press,
147–68.
Gelfand A, Ghosh S (1998) Model choice: A minimum posterior predictive
loss approach. Biometrika, 85, 1–11.
Gelfand A, Ghosh S, Christiansen C, Soumerai S, McLaughlin T (2000)
Proportional hazard models: A latent competing risk approach. Applied
Statistics, 49, 385–97.
Gelfand A, Kim H, Sirmans C, Banerjee S (2003) Spatial modelling with
spatially varying coeﬃcient models. Journal of the American Statistical
Association, 98, 387–96.
Gelfand A, Kottas A, MacEachern S (2005b) Bayesian nonparametric spatial
modeling with Dirichlet process mixing. Journal of the American Statis-
tical Association, 100, 1021–35.
Gelfand A, Latimer A, Wu S, Silander J (2005a) Building statistical models
to analyse species distributions. In J Clark, A Gelfand (eds), Hierarchical
modelling for the environmental sciences, statistical methods and appli-
cations. Oxford: Oxford University Press, 33–50.

References
523
Gelfand A, Sahu S (1999) Identiﬁability, improper priors, and Gibbs sam-
pling for generalized linear models. Journal of the American Statistical
Association, 94, 247–53.
Gelfand A, Sahu S, Carlin B (1995) Eﬃcient parameterization for normal
linear mixed models. Biometrika, 82, 479–88.
Gelfand A, Sahu S, Carlin B (1996) Eﬃcient parameterizations for generalised
linear models. In J Bernardo, J Berger, A Dawid, A Smith (eds), Bayesian
Statistics 5. Oxford: Clarendon Press, 165–80.
Gelfand A, Smith A (1990) Sampling-based approaches to calculating
marginal densities. Journal of the American Statistical Association, 85,
398–409.
Gelfand A, Smith A, Lee T (1992) Bayesian analysis of constrained param-
eter and trucated data problems using Gibbs sampling. Journal of the
American Statistical Association, 87, 523–32.
Gelfand A, Vlachos P (2003) On the calibration of Bayesian model choice
criteria. Journal of Statistical Planning and Inference, 111, 223–34.
Gelman A (2006a) Prior distributions for variance parameters in hierarchical
models. Bayesian Analysis, 1, 515–33.
Gelman A (2006b) Multilevel (hierarchical) modeling: What it can and can’t
do. Technometrics, 48, 432–35.
Gelman A, Carlin J, Stern H, Rubin D (2004) Bayesian data analysis. 2nd
ed. Boca Raton, FL: Chapman & Hall/CRC.
Gelman A, Hill J (2006) Data analysis using regression and multilevel/
hierarchical models. Cambridge: Cambridge University Press.
Gelman A, Meng X (1998) Simulating normalizing constants: from importance
sampling to bridge sampling to path sampling. Statistical Science, 13,
163–85.
Gelman A, Meng X, Stern H (1996) Posterior predictive assessment of model
ﬁtness via realized discrepancies. Statistica Sinica, 6, 733–807.
Gelman A, Rubin D (1996) Markov Chain Monte Carlo methods in biostatis-
tics. Statistical Methods in Medical Research, 5, 339–55.
Gelman A, van Dyk D, Huang Z, Boscardin J (2008) Using redundant pa-
rameterizations to ﬁt hierarchical models. Journal of Computational and
Graphical Statistics, 17, 95–12.
Genton M (2004) Skew-elliptical distributions and their applications: A jour-
ney beyond normality, Edited Volume. Boca Raton, FL: Chapman &
Hall/CRC.
George E, McCulloch R (1993) Variable selection via Gibbs sampling. Journal
of the American Statistical Association, 88, 881–89.
George E, Makov U, Smith A (1993) Conjugate likelihood distributions. Scan-
dinavian Journal of Statistics, 20, 147–56.
George E, McCulloch R (1997) Approaches for Bayesian variable selection.
Statistica Sinica, 7, 339–73.
George E, Zhang Z (2001) Posterior propriety in some hierarchical exponen-
tial family models. In A Saleh (ed.), Data Analysis from Statistical Foun-
dations: Festschrift in Honor of Donald A.S. Fraser. New York: Nova
Science Publishers.

524
References
Gerlach R, Bird R, Hall A (2002) Bayesian variable selection in logistic regres-
sion: predicting company earnings direction. Australian & New Zealand
Journal of Statistics, 44, 155–68.
Gerlach R, Carter C, Kohn R (1999) Diagnostics for time series analysis.
Journal of Time Series Analysis, 20, 309–30.
Gerlach R, Carter C, Kohn R (2000) Eﬃcient Bayesian inference for dy-
namic mixture models. Journal of the American Statistical Association,
95, 819–28.
Geweke J (1989) Bayesian inference in econometric models using Monte Carlo
integration. Econometrica, 57, 1317–39.
Geweke J (1992) Evaluating the accuracy of sampling-based approaches to
calculating posterior moments. In J Bernardo, J Berger, A Dawid, A
Smith (eds), Bayesian Statistics. Vol. 4. New York: Oxford University
Press, 169–93.
Geweke J (1993) Bayesian treatment of the Student’s-t linear model. Journal
of Applied Econometrics, 8, S19–S40.
Geweke J (2007) Interpretation and inference in mixture models: Simple
MCMC works. Computational Statistics and Data Analysis, 51, 3529–50.
Geweke J, Keane M (2000) An empirical analysis of earnings dynamics among
men in the PSID: 1968–1989. Journal of Econometrics, 96, 293–56.
Geweke J, Terui N (1993) Bayesian threshold auto-regressive models for non-
linear time series. Journal of Time Series Analysis, 14, 441–54.
Geweke J, Zhou G (1996) Measuring the pricing error of the arbitrage pricing
theory. Review of Financial Studies, 9, 557–87.
Geyer C, Thompson E (1995) Annealing Markov Chain Monte Carlo with
applications to ancestral inference. Journal of the American Statistical
Association, 90, 909-20.
Ghosh J (2008) Eﬃcient Bayesian computation and model search in linear
hierarchical models. PhD thesis ISDS. Duke University.
Ghosh J, Dunson D (2008) Bayesian model selection in factor analytic models.
In D Dunson (ed.), Random eﬀect and latent variable model selection.
New York: Springer, 151–63.
Ghosh K, Tiwari R (2007) Prediction of U.S. cancer mortality counts using
semiparametric Bayesian techniques. Journal of the American Statistical
Association, 102, 7–15.
Ghosh P, Branco M, Chakraborty H (2007) Bivariate random eﬀect model
using skew-normal distribution with application to HIV-RNA. Statistics
in Medicine, 26, 1255–67.
Ghosh S, Kim H (2007) Semiparametric inference based on a class of zero-
altered distributions. Statistical Methodology, 4, 371–83.
Ghosh S, Mukhopadhyay P, Lu J-C (2006) Bayesian analysis of zero-inﬂated
regression models. Journal of Statistical Planning and Inference, 136,
1360–75.
Gilks W (1996) Full conditional distributions. In W Gilks, S Richardson,
D Spiegelhalter (eds), Markov Chain Monte Carlo in practice. Chapman
and Hall: London, 75–88.

References
525
Gilks W, Richardson S, Spielgelhalter D (1996) Introducing Markov Chain
Monte Carlo. In W Gilks, S Richardson, D Spiegelhalter (eds), Markov
chain Monte Carlo in practice. Chapman and Hall: London, 1–19.
Gilks W, Wang C, Yvonnet B, Coursaget P (1993) Random-eﬀects models
for longitudinal data using Gibbs sampling. Biometrics, 38, 963–74.
Gilks W, Wild P (1992) Adaptive rejection sampling for Gibbs sampling.
Applied Statistics, 41, 337–48.
Gill J, Casella G (2009) Nonparametric priors for ordinal Bayesian social
science models: Speciﬁcation and estimation. Journal of the American
Statistical Association, 104, 453–64.
Gilula Z, Haberman S (1994) Conditional log-linear models for analyzing
categorical panel data. Journal of the American Statistical Association,
89, 645–56.
Giminez O, Bonner S, King R, Parker R, Brooks S, Jamieson L, Grosbois
V, Morgan B, Thomas L (2008) WinBUGS for population ecologists:
Bayesian modeling using Markov Chain Monte Carlo methods. In
D Thomson, E Cooch, M Conroy, (eds), Modelling demographic processes
in marked populations. Environmental and ecological statistics. New
York: Springer, 883–916.
Givens G, Hoeting J (2005) Computational statistics. Chichester, Sussex:
Wiley.
Glosten L, Jagannathan R, Runkle D (1994) On the relation between the
expected value and the variance of the nominal excess return on stocks.
Journal of Finance, 48, 1791–801.
Godolphin E, Triantafyllopoulos K (2006) Decomposition of time series
models in state-space form. Computational Statistics & Data Analysis,
50, 2232–46.
Godsill S, Doucet A, West M (2004) Monte Carlo smoothing for nonlinear
time series. Journal of the American Statistical Association, 99, 156–68.
Goldfelfd S, Quandt R (1975) Estimation in a disequilibrium model and the
value of information. Journal of Econometrics, 3, 325–48.
Goldstein H (2005) Heteroscedasticity and complex variation. In B Everrit, D
Howell (eds), Encyclopedia of statistics in behavioral science. Chichester:
Wiley, Vol. 2. 790–95.
Goldstein H, Browne W, Rasbash J (2002) Partitioning variation in multilevel
models. Understanding Statistics, 1, 223–32.
Goldstein H, Spiegelhalter D (1996) League tables and their limitations:
Statistical issues in comparisons of institutional performance. Journal of
the Royal Statistical Society A, 159, 385–443.
G´omez, E, G´omez-Villegas M, Mar´ın J (2002) Continuous elliptical and expo-
nential power linear dynamic models. Journal of Multivariate Analysis,
83, 22–36.
Goodman J, Blum T (1996) Assessing the non-random sampling eﬀects of
subject attrition in longitudinal research. Journal of Management, 22,
627–52.

526
References
Gopalan R, Berry D (1998) Bayesian multiple comparisons using Dirichlet pro-
cess priors. Journal of the American Statistical Association, 93, 1130–39.
Gore S, Pocock S, Kerr G (1984) Regression models and non-proportional
hazards in the analysis of breast cancer survival. Applied Statistics, 33,
176–95.
Gordon S (2002) Stochastic dependence in competing risks. American Journal
of Political Science, 46, 200–17.
Gosoniu L, Vounatsou P, Sogoba N, Smith T (2006) Bayesian modelling of
geostatistical malaria risk data. Geospatial Health, 1, 127–39.
Gotway C, Wolﬁnger R (2003) Spatial prediction of counts and rates.
Statistics in Medicine, 22, 1415–32.
Gourieroux C, Phillips P, Yu J (2006) Indirect Inference for dynamic panel
models. Cowles Foundation Discussion Paper 1550, Yale University.
Gramacy R (2007) tgp: an R package for Bayesian nonstationary, semipara-
metric nonlinear regression and design by reed Gaussian process models.
Journal of Statistical Software, 19(9).
Gramacy R, Lee H (2008) Gaussian processes and limiting linear models.
Computational Statistics & Data Analysis, 53, 123–36.
Granger C, Machina M (2006) Structural attribution of observed volatility
clustering. Journal of Econometrics, 135, 15–29.
Green M, Medley G, Browne W (2009) Use of posterior predictive assess-
ments to evaluate model ﬁt in multilevel logistic regression. Veterinary
Research, 40(4): 30.
Green P, O’Hagan A (1998) Model choice with MCMC on product spaces
without using pseudo priors. Technical Report, Department of Statistics,
University of Nottingham.
Green P, Richardson S (1997) On Bayesian analysis of mixtures with an
unknown number of components Journal of the Royal Statistical Society:
Series B, 59, 731–92.
Green
P,
Richardson
S
(2000)
Spatially
correlated
allocation
models
for
count
data.
Technical
Report.
University
of
Bristol
(http://
en.scientiﬁccommons.org/336472).
Green P, Richardson S (2001) Modelling heterogeneity with and without the
Dirichlet process. Scandinavian Journal of Statistics, 28, 355–75.
Green P, Richardson S (2002) Hidden Markov models and disease mapping.
Journal of the American Statistical Association, 97, 1055–70.
Greene W (2007) Functional form and heterogeneity in models for count
data. Foundations and Trends in Econometrics, 1, 113–218.
Greenland S (2003) Generalized conjugate priors for Bayesian analysis of risk
and survival regressions. Biometrics, 59, 92–99.
Greenland S (2006) Smoothing observational data: A philosophy and im-
plementation for the Health Sciences. International Statistical Review,
74 (1), 31–46.
Greenland S (2007) Bayesian perspectives for epidemiological research. II.
Regression analysis. International Journal of Epidemiology, 36, 195–202.

References
527
Greenland S, Christensen R (2001) Data augmentation priors for Bayesian
and semi-Bayes analyses of conditional-logistic and proportional-hazards
regression. Statistics in Medicine, 20, 2421–28.
Greenland S, Draper, D (1998) Exchangeability. Encyclopedia of Biostatistics,
P Armitage, T Colton (eds), London: Wiley.
Griﬃn J, Steel M (2006) Order-based dependent Dirichlet processes. Journal
of the American Statistical Association, 101, 179–94.
Grunwald
S
(2005)
Environmental soil-landscape modeling: Geographic
information technologies and pedometrics. Boca Raton, FL: CRC Press.
Grunwald G, Hyndman R, Tedesco L, Teeedie R (2000) Non-Gaussian con-
ditional AR(1) models. Australian & New Zealand Journal of Statistics,
42, 479–95.
Gschl¨oßl S, Czado C (2006) Modelling count data with overdispersion and
spatial eﬀects. Technische Universit¨at M¨unchen, Statistical Papers. DOI
10.1007/s00362-006-0031-6.
Gschl¨oßl S, Czado C (2008) Modelling count data with overdispersion and
spatial eﬀects. Statistical Papers, 49, 531–32.
Guha S (2008) Posterior simulation in the generalized linear mixed model
with semiparametric random eﬀects. Journal of Computational and
Graphical Statistics, 17, 410–25.
Gunnell D, Peters T, Kammerling R, Brooks J (1995) Relation between para-
suicide, suicide, psychiatric admissions and socio-economic deprivation.
British Medical Journal, 311, 226–30.
Gustafson P (1996) Local sensitivity of inferences to prior marginals. Journal
of the American Statistical Association, 91, 774–81.
Gustafson P (1996) The eﬀect of mixing-distribution misspeciﬁcation in
conjugate mixture models. Canadian Journal of Statistics, 24, 307–18.
Gustafson P (1997) Large hierarchical Bayesian analysis of multivariate
survival data. Biometrics, 53, 230–42.
Gustafson P (2000) Bayesian regression modelling with interactions and
smooth eﬀects. Journal of the American Statistical Association, 95,
795–806.
Gustafson P, Aeschliman D, Levy A (2003) A simple approach to ﬁtting
Bayesian survival models. Lifetime Data Analysis, 9, 5–19.
Gustafson P, Hossain S, MacNab Y (2006) Conservative priors for hierarchical
models. Canadian Journal of Statistics, 34, 377–90.
Hadjicostas P, Berry S (1999) Improper and proper posteriors with improper
priors in a Poisson-gamma hierarchical model. Test, 8, 147–66.
Hall D (2000) Zero-inﬂated Poisson and binomial regression with random
eﬀects: A case study. Biometrics, 56, 1030–39.
Hamerle A, Ronning G (1995) Panel analysis for qualitative variables. In
G Arminger et al. (eds), Handbook of statistical modeling for social and
behavioral sciences. New York: Plenum Press, 401–51.
Hamilton J (2009) Regime–switching models. In S Durlauf, L Blume (eds),
The New Palgrave Dictionary of Economics. 2nd edn. Basingstoke,
England: Palgrave Macmillan.

528
References
Han C, Carlin B (2001) Markov Chain Monte Carlo methods for computing
Bayes factors: A comparative review. Journal of the American Statistical
Association, 96, 1122–32.
Hanson T, Branscum A, Johnson W (2005) Nonparametric Bayesian data
analysis: An introduction. In C Rao, D Dey (eds), Handbook of Statistics
25. Amsterdam: Elsevier, 245–78.
Hanson T, Johnson W (2002) Modeling regression error with a mixture of
Polya trees. Journal of the American Statistical Association, 97, 1020–33.
Haran M, Hodges J, Carlin B (2003) Accelerating computation in Markov
random ﬁeld models for spatial data via structured MCMC. Journal of
Computational & Graphical Statistics, 12, 249–64.
Harvey A (1989) Forecasting, structural time series models and the Kalman
ﬁlter. Cambridge: Cambridge University Press.
Harvey A, Koopman S (1997) Multivariate structural time series models.
In C Heij, H Schumacher, B Hanzon, C Praagman (eds), Systematic
dynamics in economic and ﬁnancial models. Chichester: Wiley, 269–98.
Harvey A, Ruiz E, Shepherd N (1994) Multivariate stochastic variance
models. Review of Economic Studies, 61, 247–64.
Harvey A, Shephard N (1993) Structural time series models. In G S Maddala
et al. (eds), Handbook of Statistics, Vol. 11. Barking: Elsevier Science.
Harvey A, Todd P (1983) Forecasting economic time series with structural
and Box-Jenkins models: A case study. Journal of Business & Economic
Statistics, 1, 299–307.
Harvey A, Trimbur T, Van Dijk H (2007) Trends and cycles in economic time
series: A Bayesian approach. Journal of Econometrics, 140: 618–49.
Hasegawa H, Chaturvedi A, van Hoa T (2000) Bayesian unit root tests in
nonnormal AR(1) models. Journal of Time Series Analysis, 21, 261–80.
Hastie T, Tibshirani T (1993) Varying coeﬃcient models. Journal of the
Royal Statistical Society: Series B, 55, 757–96.
Hastings W (1970) Monte-Carlo sampling methods using Markov Chains and
their applications. Biometrika, 57, 97–109.
Hausman J, Wise D (1978) A conditional probit model for qualitative choice:
Discrete
decisions
recognizing
interdependence
and
heterogeneous
preferences. Econometrica, 46, 403–26.
Hayashi K, Arav M (2006) Bayesian factor analysis when only a sample co-
variance matrix is available. Educational and Psychological Measurement,
66, 272–84.
Hayashi K, Bentler P, Yuan K-H (2008) Structural equation modelling.
In C Rao, J Miller, D Rao (eds), Epidemiology and medical statistics,
handbook of statistics, Chapter 13, Vol 27. Amsterdam: Elsevier, 395–428.
Heagerty P, Zeger S (2000) Marginalized multilevel models and likelihood
inference. Statistical Science, 15, 1–26.
Heckman J (1976) The common structure of statistical models of truncation,
sample selection, and limited dependent variables and a simple estimator
for such models. Annals of Economic and Social Measurement, 5, 475–92.

References
529
Heckman J (1981) The incidental parameters problem and the problem of
initial conditions in estimating a discrete time-discrete data stochastic
process. In C Manski, D McFadden (eds), Structural analysis of discrete
data with econometric applications. Cambridge: MIT Press, 179–95.
Heckman J, Singer B (1984) A method for minimizing the impact of
distributional assumptions in econometric models for duration data.
Econometrica, 52, 271–320.
Hedeker D (2003) A mixed-eﬀects multinomial logistic regression model.
Statistics in Medicine, 22, 1433–46.
Hedeker D, Gibbons R (1994) A random-eﬀects ordinal regression model for
multilevel analysis. Biometrics, 50, 933–44.
Hedeker D, Gibbons R (1997) Application of random-eﬀects pattern-mixture
models for missing data in longitudinal studies. Psychological Methods,
2, 64–78.
Hedeker D, Gibbons R (2006) Longitudinal data analysis. Hoboken, New
Jersey: Wiley-Interscience.
Hedeker D, Gibbons R, Flay B (1994) Random eﬀects regression models
for clustered data: With an example from smoking research. Journal of
Consulting and Clinical Psychology, 62, 757–65.
Henderson R, Oman P (1999) Eﬀect of frailty on marginal regression
estimates in survival analysis. Journal of the Royal Statistical Society:
Series B, 61, 367–79.
Henderson R, Prince H (2000) Choice of conditional models in bivariate
survival. Statistics in Medicine, 19, 563–74.
Henderson R, Shimakura S, Gorst D (2002) Modeling spatial variation in
leukemia survival data. Journal of the American Statistical Association,
97, 965–72.
Hensher D, Greene W (2003) The mixed logit model: The state of practice.
Transportation, 30, 133–76.
Heringstad B, Rekaya R, Gianola D, Klemetsdal G, Weigel K (2001) Bayesian
analysis of liability of clinical mastitis in Norwegian cattle with a thresh-
old model: Eﬀects of data sampling method and model speciﬁcation.
Journal of Dairy Science, 84, 2337–46.
Herring A, Ibrahim J (2002) Maximum likelihood estimation in random eﬀects
cure rate models with nonignorable missing covariates. Biostatistics, 3,
387–405.
Higdon D (1998) A process-convolution approach to modelling temperatures
in the North Atlantic Ocean. Environmental and Ecological Statistics, 5,
173–90.
Higdon D (2007) A primer on space-time modelling from a Bayesian per-
spective. In Finkelstadt, Held and Isham (eds), Statistical methods for
spatio-temporal systems. Boca Raton, FL: CRC Press, 217–80.
Hildreth C, Houck J (1968) Some estimators for a linear model with random
coeﬃcients. Journal of the American Statistical Association, 63, 584–95.
Hirano K (2002) Semiparametric Bayesian inference in autoregressive panel
data models. Econometrica, 70, 781–99.

530
References
Hirano K (1998) A semiparametric model for labor earnings dynamics. In
D Dey, P Mueller, D Sinha (eds), Practical nonparametric and semipara-
metric Bayesian statistics. New York: Springer–Verlag, 355–67.
Hjellvik V, Tjøstheim D (1999) Modelling panels of intercorrelated autore-
gressive time series. Biometrika, 86, 573–90.
Ho R, Hu I (2008) Flexible modelling of random eﬀects in linear mixed
models- a Bayesian approach. Computational Statistics & Data Analysis,
52, 1347–61.
Hobert J, Casella G (1996) The eﬀect of improper priors on Gibbs sampling
in hierarchical linear mixed models. Journal of the American Statistical
Association, 91, 1461–73.
Hodge R, Evans M, Marshall J, Quigley J, Walls L (2001) Eliciting engineering
knowledge about reliability during design-lessons learnt from implemen-
tation. Quality and Reliability Engineering International, 17, 169–79.
Hodges J, Carlin B, Fan Q (2003) On the precision of the conditionally
autoregressive prior in spatial models. Biometrics, 59, 317–22.
Hoem J (1987) Statistical analysis of a multiplicative model and its ap-
plication to the standardization of vital rates: A review. International
Statistical Review, 55, 119–52.
HoﬀP (2003) Nonparametric modelling of hierarchically exchangeable
data Technical Report 421, Department of Statistics, University of
Washington.
Hogan J, Lin X, Herman B (2004) Mixtures of varying coeﬃcient models
for longitudinal data with discrete or continuous non-ignorable dropout.
Biometrics, 60, 854–64.
Hogan J, Tchernis R (2004) Bayesian factor analysis for spatially correlated
data, with application to summarizing area-level material deprivation
from census data. Journal of the American Statistical Association, 99,
314–24.
Holloway G, Shankar B, Rahman S (2002) Bayesian spatial probit estimation:
A primer with an application to HYV rice adoption. Agricultural
Economics, 27, 383–402.
Holmes C, Held L (2006) Bayesian auxiliary variable models for binary and
multinomial regression. Bayesian Analysis, 1, 145–68.
Hooper P (2001) Flexible regression modeling with adaptive logistic basis
functions. Canadian Journal of Statistics, 29, 343–78.
Hougaard P (1987) Modelling multivariate survival. Scandinavian Journal of
Statistics, 14, 291–304.
Hougaard P (2000) Analysis of multivariate survival data. Springer: New York.
Hougaard P, Myglegaard P, Borch-Johnsen K (1994) Heterogeneity models
of disease susceptibility, with application to diabetic nephropathy.
Biometrics, 50, 1178–88.
Howley P, Gibberd R (2003) Using hierarchical models to analyse clinical
indicators: A comparison of the gamma-Poisson and beta-binomial
models. International Journal for Quality in Health Care, 15, 319–29.

References
531
Hox J (2002) Multilevel analysis: Techniques and applications. Mahwah, NJ:
Lawrence Erlbaum Associates.
Hox J, Bechger T (1998) An introduction to structural equation modeling.
Family Science Review, 11, 354–73.
Hoyle R (ed.) (1995) Structural equation modeling: Concepts, issues, and
applications. Thousand Oaks, California: Sage.
Hsiao C (1996) Random coeﬃcient models. In L Matyas, P Sevestre (eds),
The econometrics of panel data. Dordrecht: Kluwer, 77–99.
Hsiao C (1997) Approximate Bayes factors when a mode occurs on the
boundary. Journal of the American Statistical Association, 92, 656–63.
Huerta G, West M (1999) Priors and component structurres in autoregressive
time series. Journal of the Royal Statistical Society, 61B, 881–99.
Hurn M, Justel A, Robert C (2003) Estimating mixtures of regressions.
Journal of Computational and Graphical Statistics, 12, 1–25.
Hurn M, Justel A, Robert C (2003) Estimating mixtures of regressions.
Journal of Computational and Graphical Statistics, 12, 55–79.
Huster W, Brookmeyer R, Self S (1989) Modeling paired survival data with
covariates. Biometrics, 45, 145–56.
Hyndman R (1996) Computing and graphing highest density regions.
American Statistician, 50, 361–65.
Ibrahim J, Chen M-H (2000) Power prior distributions for regression models.
Statistical Science, 15, 46–60.
Ibrahim J, Chen M-H, MacEachern S (1999) Bayesian variable selection for
proportional hazards models. The Canadian Journal of Statistics, 27,
701–17.
Ibrahim J, Chen M-H, Ryan L (2000a) Bayesian variable selection for time
series count data. Statistica Sinica, 10, 971–87.
Ibrahim J, Chen M-H, Sinha D (2001) Bayesian survival analysis. New York:
Springer-Verlag.
Ibrahim J, Lipsitz S, Chen M-H (1999) Missing covariates in generalized
linear models when the missing data mechanism is non-ignorable.
Journal of the Royal Statistical Society: Series B, 61, 173–90.
Ibrahim, J, Chen M, Sinha D (2001) Criterion-based methods for Bayesian
model assessment. Statistica Sinica, 11, 419–43.
Imai K, Lu Y, Strauss A (2010) eco: R Package for ecological inference in
2 × 2 Tables. Journal of Statistical Software, Forthcoming.
Imai K, Ying L, Strauss A (2008) Bayesian and likelihood inference for 2 × 2
ecological tables: An incomplete data approach. Political Analysis, 16,
41–69.
Ishwaran H, James L (2001) Gibbs sampling methods for stick-breaking
priors. Journal of the American Statistical Association, 96, 161–73.
Ishwaran H, James L (2002) Approximate Dirichlet process computing in
ﬁnite normal mixtures: Smoothing and prior information. Journal of
Computational and Graphical Statistics, 11, 508–32.
Ishwaran H, James L (2003) Generalized weighted Chinese restaurant pro-
cesses for species sampling mixture models. Statistica Sinica, 13, 1211–35.

532
References
Ishwaran H, Zarepour M (2000) Markov chain Monte Carlo in approxi-
mate Dirichlet and beta two-parameter process hierarchical models.
Biometrika, 87, 371–90.
Ishwaran H, Zarepour M (2002) Exact and approximate sum-representations
for the Dirichlet process. Canadian Journal of Statistics, 30, 269–83.
Islam M, Chowdhury R (2006) A higher order Markov model for analyzing
covariate dependence. Applied Mathematical Modelling, 30, 477–88.
Jacquier E, Polson N, Rossi P (2004) Bayesian analysis of stochastic volatility
models with fat-tails and correlated errors. Journal of Econometrics,
122, 185–212.
Jaﬀr´ezic F, Thompson R, Hill G (2003) Structured antedependence models
for genetic analysis of repeated measures on multiple quantitative traits.
Genetics Research, 82, 55–65.
Jaﬀr´ezic F, Venot E, Lalo¨e D, Vinet A, Renand G (2004) Use of structured
antedependence models for the genetic analysis of growth curves. Journal
of Animal Science, 82, 3465–73.
James G, Hastie T, Sugar C (2000) Principal component models for sparse
functional data. Biometrika, 87, 587–602.
Jara A (2007) Applied Bayesian non- and semi-parametric inference using
DP package. R News, 7/3, 17–26.
Jara A, Quintana F, San Martin E (2008) Linear eﬀects mixed models
with skew-elliptical distributions: A Bayesian approach. Interuniversity
Attraction Pole Report TR08010, http://www.stat.ucl.ac.be/IAP/.
Jarque C, Bera A (1980) Eﬃcient tests for normality, homoscedasticity and se-
rial independence of regression residuals. Econometric Letters, 6, 255–59.
Jasra A, Holmes C, Stephens D (2005) MCMC methods and the label switch-
ing problem in Bayesian mixture modelling. Statistical Science, 20, 50–67.
Jedidi K, Jagpal H, DeSarbo W (1997) Finite-mixture structural equation
models for response-based segmentation and unobserved heterogeneity.
Marketing Science, 16, 39–59.
Jerak A, Lang S (2005) Locally adaptive function estimation for binary
regression models. Biometrical Journal, 47, 151–66.
Jin X, Carlin B, Banerjee S (2005) Generalized hierarchical multivariate
CAR models for areal data. Biometrics, 61, 950–61.
Jiruˇse M, Machek J, Beneˇs V, Zeman P (2004) A Bayesian estimate of the
risk of tick-borne diseases. Applications of Mathematics, 49, 389–404.
Johannes M, Polson N (2006) MCMC methods for continuous-time ﬁnancial
econometrics. In Y Ait-Sahalia, L Hansen (eds), Handbook of Financial
Econometrics. Amsterdam: North Holland, 1–72.
Johnson V (2004) A Bayesian χ2 test for goodness-of-ﬁt. Annals of Statistics,
32, 2361–84.
Johnson V, Albert J (1999) Ordinal data modeling. New York: Springer.
Jones G, Haran M, Caﬀo B, Neath R (2006) Fixed-width output analysis
for Markov Chain Monte Carlo. Journal of the American Statistical
Association, 101, 1537–47.

References
533
Jonsen I, Myers R, James M (2006) Robust hierarchical state–space models
reveal diel variation in travel rates of migrating leatherback turtles.
Journal of Animal Ecology, 75, 1046–57.
J¨oreskog K (1973) A general method for estimating a linear structural
equation system. In A Goldberger, O Duncan (eds), New York: Seminar
Press, 85–112.
Joreskog K, Goldberger A (1975) Estimation of a model with multiple
indicators and multiple causes of a single latent variable. Journal of the
American Statistical Association, 70, 631–39.
Jorgensen B, Lundbye-Christensen S, Song P, Sun L (1999) A state space
model for multivariate longitudinal count data. Biometrika, 86, 169–81.
Jowaheer V, Sutradhar B (2002) Analysing longitudinal count data with
overdispersion. Biometrika, 89, 389–99.
Jullion A, Lambert P (2007) Robust speciﬁcation of the roughness penalty
prior distribution in spatially adaptive Bayesian P-splines models.
Computational Statistics & Data Analysis, 51, 2542–58.
Jung R, Kukuk M, Liesenfeld R (2006) Time series of count data: Modeling,
estimation and diagnostics. Computational Statistics & Data Analysis,
51, 2350–64.
Jungbacker B, Koopman S, van der Wel M (2009) Dynamic factor models
with smooth loadings for analyzing the term structure of interest rates.
Tinbergen Institute Discussion Paper, TI 2009-041/4.
Kacker R, Forbes A, Kessel R, Sommer K-D (2008) Bayesian posterior pre-
dictive p-value of statistical consistency in interlaboratory evaluations.
Metrologia, 45, 512–23.
Kahn M, Raftery A (1996) Discharge rates of Medicare stroke patients to
skilled nursing facilities: Bayesian logistic regression with unobserved
heterogeneity. Journal of the American Statistical Association, 91, 29–41.
Kalbﬂeisch J (1978) Non-parametric Bayesian analysis of survival time data.
Journal of the Royal Statistical Society B, 40, 214–21.
Kalbﬂeisch J, Prentice R (1980) The statistical analysis of failure time data.
New York: Wiley.
Karlis D, Meligkotsidou L (2005) Multivariate Poisson regression with
covariance structure. Statistics and Computing, 15, 255–65.
Kashiwagi N, Yanagimoto T (1992) Smoothing serial count data through a
state-space model. Biometrics, 48, 1187–94.
Kass R, Carlin B, Gelman A, Neal R (1998) Markov Chain Monte Carlo in
practice: A round table discussion. The American Statistician, 52, 93–100.
Kass R, Raftery A (1995) Bayes factors. Journal of the American Statistical
Association, 90, 773–95.
Kass R, Steﬀey D (1989) Approximate Bayesian inference in conditionally
independent hierarchical models (parametric empirical Bayes models).
Journal of the American Statistical Association, 84, 717–26.
Kass R, Wasserman L (1996) The selection of prior distributions by formal
rules. Journal of the American Statistical Association, 91, 1343–70.

534
References
Kato B, Hoijtink H (2004) Testing homogeneity in a random intercept model
using asymptotic, posterior predictive and plug-in p-values. Statistica
Neerlandica, 58, 179–96.
Kedem B, Fokianos K (2002) Regression models for time series analysis.
Chichester, UK: Wiley.
Keiding N, Andersen P, Klein J (1997) The role of frailty models and accel-
erated failure time models in describing heterogeneity due to omitted
covariates. Statistics in Medicine, 16, 215–24.
Kelsall J, Wakeﬁeld J (2002) Modelling spatial variation in disease risk: A
geostatistical approach. Journal of the American Statistical Association,
97, 692–770.
Kendall, M (1943) The advanced theory of statistics. London: Griﬃn.
Kenward M (1998) Selection models for repeated measurements with non-
random dropout: An illustration of sensitivity. Statistics in Medicine,
17, 2723–32.
Kettl S (1991) Accounting for heteroscedasticity in the transform both sides
regression model. Journal of Applied Statistics, 40, 261–68.
Key J, Pericchi L, Smith A (1999) Bayesian model choice: what and why?
In J Bernardo, J Berger, A Dawid, A Smith (eds), Bayesian Statistics 6.
Oxford: Oxford Science Publications, 343–70.
Kiefer N (1988) Economic duration data and hazard functions. Journal of
Economic Literature, 26, 646–79.
Kim H, Sun D, Tsutakawa R (2002) Lognormal vs. gamma: Extra variations.
Biometrical Journal, 44, 305–23.
Kim S, Shephard N, Chib S (1998) Stochastic volatility: Likelihood inference
and comparison with ARCH models. The Review of Economic Studies,
65, 361–93.
King G (1997) A solution to the ecological inference problem: Reconstructing
individual behavior from aggregate data. Princeton, NJ: Princeton,
University Press.
King G (2001) Analyzing incomplete political science data: An alternative
algorithm for multiple imputation. American Political Science Review,
95, 49–69.
King G, Rosen O, Tanner M (eds) (2004) Ecological inference: New
methodological strategies. New York: Cambridge University Press.
Kinney S, Dunson D (2007) Fixed and random eﬀects selection in linear and
logistic models. Biometrics, 63, 690–98.
Kinney S, Dunson D (2008) Bayesian model uncertainty in mixed eﬀects
models. In D Dunson (ed.), Random eﬀect and latent variable model
selection. New York: Springer.
Kitagawa G, Gersch W (1985) A smoothness priors time-varying AR
coeﬃcient modeling of nonstationary covariance time series. IEEE
Transactions on Automatic Control, 30, 48–56.
Kitagawa G, Gersch W (1996) Smoothness priors analysis of time series,
lecture notes in statistics 116. New York: Springer-Verlag.

References
535
Kitanidis P (1997) Introduction to geostatistics: Applications in hydrogeology.
Cambridge: Cambridge University Press.
Kleinman K, Ibrahim J (1998) A semi-parametric Bayesian approach to
generalized linear mixed models. Statistics in Medicine, 17, 2579–96.
Kleinman K, Ibrahim J (1998) A semiparametric Bayesian approach to the
random eﬀects model. Biometrics, 54, 921–38.
Kneib T (2006) Mixed model-based inference in geoadditive hazard regression
for interval-censored survival times. Computational Statistics & Data
Analysis, 51, 777–92.
Kneib T, Belitz C, Brezger A, Lang S (2008) BayesX–Bayesian inference in
structured additive regression. Software Highlight in ISBA Bulletin, 15(1):
11–13.
Knorr-Held L (1999) Conditional prior proposals in dynamic models. Scan-
dinavian Journal of Statistics, 26, 129–44.
Knorr-Held L (2000) Bayesian modelling of inseparable space-time variation
in disease risk. Statistics in Medicine, 19, 2555–67.
Knorr-Held L, Becker N (2000) Bayesian modelling of spatial heterogeneity in
disease maps with application to German cancer mortality data. Journal
of the German Statistical Society, 84, 121–40.
Knorr-Held L, Rainer E (2001) Projections of lung cancer mortality in West
Germany: A case study in Bayesian prediction. Biostatistics, 2, 109–29.
Knorr-Held L, Rasser G (2000) Bayesian detection of clusters and disconti-
nuities in disease maps. Biometrics, 56, 13–21.
Kohn R, Schimek M, Smith M (2000) Spline and kernel regression for depen-
dent data. In M Schimek (ed.), Smoothing and regression approaches,
computation and estimation, Chapter 6. Chichester, Sussex: John Wiley,
135–58.
Kohn R, Smith M, Chan D (2001) Nonparametric regression using linear
combinations of basis functions. Statistics and Computing, 11, 313–22.
Konishi S, Ando T, Imoto, S (2004) Bayesian information criteria and smooth-
ing parameter selection in radial basis function networks. Biometrika,
91, 27–43.
Koop G (2003) Bayesian econometrics. Chichester, Sussex: John Wiley.
Koop G, Poirier D (2004) Bayesian variants of some classical semiparametric
regression techniques. Journal of Econometrics, 123, 259–82.
Koop G, Strachan R, van Dijk H, Villani M (2006) Bayesian approaches to
cointegration. In K Patterson, T Mill (eds), The Palgrave handbook of
theoretical econometrics. MacMillan.
Koop G, Tole L (2004) Measuring the health eﬀects of air pollution: To what
extent can we really say that people are dying from bad air? Journal of
Environmental Economics and Management, 47, 30–54.
Koopman S (1993) Disturbance smoother for state space models. Biometrika,
80, 117–26.
Koopman S, Durbin J (2000) Fast ﬁltering and smoothing for multivariate
state space models. Journal of Time Series Analysis, 21, 281–96.

536
References
Koopman S, Shephard N, Doornik J (1999) Statistical algorithms for models
in state space form using SsfPack 2.2. Econometrics Journal, 2, 113–66.
Korn E, Whittemore A (1979) Methods for analyzing panel studies of acute
health eﬀects of air pollution. Biometrics, 35, 795–802.
Kostaki A, Panousis V (2001) Expanding an abridged life table. Demographic
Research, 5, 1, http://www.demographicresearch.org/Volumes/vol5/1/
5–1.pdf.
Kottas A, M¨uller P, Quintana F (2005) A nonparametric Bayesian model
for multivariate ordinal data. Journal of Computational and Graphical
Statistics, 14, 610–25.
Koul H, Schick A (1996) Adaptive estimation in a random coeﬃcient
autoregressive model. The Annals of Statistics, 24, 1025–52.
Kozumi H (2004) Posterior analysis of latent competing risk models by parallel
tempering. Computational Statistics & Data Analysis, 46, 441–58.
Kruijer W, Stein A, Schaafsma W, Heijting S (2007) Analyzing spatial count
data, with an application to weed counts. Environmental and Ecological
Statistics, 14, 399–410.
Kuhn E, Lavielle M (2005) Maximum likelihood estimation in nonlinear mixed
eﬀects models. Computational Statistics & Data Analysis, 49, 1020–38.
Kuhn I (2007) Incorporating spatial autocorrelation may invert observed
patterns. Diversity and Distributions, 13, 66–69.
Kuo L, Mallick B (1997) Bayesian semiparametric inference for the accelerated
failure-time model. Canadian Journal of Statistics, 25, 457–72.
Kuo L, Mallick B (1998) Variable selection for regression models. Sankhya B,
60, 65–81.
Lagazio C, Biggeri A, Dreassi E (2003) Age-period-cohort models and disease
mapping. Environmetrics, 14, 475–90.
Laird N, Louis T (1989) Empirical Bayes ranking methods. Journal of
Educational Statistics, 14, 29–46.
Lambert D (1992) Zero-inﬂated Poisson regression, with an application to
defects in manufacturing. Technometrics, 34, 1–14.
Lambert P, Sutton A, Burton P, Abrams K, Jones D (2005) How vague is
vague? A simulation study of the impact of the use of vague prior distri-
butions in MCMC using WinBUGS. Statistics in Medicine, 24, 2401–28.
Lambert, P (2006) Comment on article by Browne and Draper. Bayesian
Analysis, 1, 543–46.
Lancaster T (1990) The econometric analysis of transition data. Cambridge:
Cambridge University Press.
Lancaster T (2002) Orthogonal parameters and panel data. Review of
Economic Studies, 69, 647–66.
Lang S, Brezger A (2004) Bayesian P-splines. Journal of Computational and
Graphical Statistics, 13, 183–212.
Lang S, Fronk E, Fahrmeir L (2002) Function estimation with locally adaptive
dynamic models. Computational Statistics, 17, 479–500.
Lange K, Little R, Taylor M (1989) Robust statistical modeling using the t
distribution. Journal of the American Statistical Association, 84, 881–96.

References
537
Langford I, Lewis T (1998) Outliers in multilevel data. Journal of the Royal
Statistical Society: Series A, 161, 121–60.
Larch M, Walde J (2008) Lag or error – detecting the nature of spatial cor-
relation. In C Preisach, H Burkhardt, L Schmidt-Thieme (eds), Studies
in classiﬁcation, data analysis, and knowledge organization. New York:
Springer, 301–308.
Larson J, Soule S (2006) Sector Level Dynamics and Collective Action in
the United States, 1965–1975. Working Paper, Department of Sociology,
University of Arizona.
Laud P, Ibrahim J (1995) Predictive model selection. Journal of the Royal
Statistical Society: Series B, 57, 247–62.
Lavine M (1999) Another look at conditionally Gaussian Markov random
ﬁelds. In J Bernardo, J Berger, P Dawid, A Smith (eds), Bayesian
Statistics 6. Oxford: Oxford University Press, 371–87.
Lavori P, Dawson R, Shera D (1995) A multiple imputation strategy for
clinical trials with truncation of patient data. Statistics in Medicine, 14,
1913–25.
Lawless J, Crowder M (2004) Covariates and random eﬀects in a gamma
process model with application to degradation and failure. Lifetime Data
Analysis, 10, 213–27.
Lawson A (2008) Bayesian disease mapping: Hierarchical modeling in spatial
epidemiology. Boca Raton, FL: CRC Press.
Lawson A, Clark A (2002) Spatial mixture relative risk models applied to
disease mapping. Statistics in Medicine, 21, 359–70.
LeSage J (1997) Bayesian estimation of spatial autoregressive models.
International Regional Science Review, 20, 113–29.
LeSage J (1999) Spatial Econometrics. In RW Jackson (ed.), The web book
of regional science (www.rri.wvu.edu/regscweb.htm), Morgantown, WV:
Regional Research Institute, West Virginia University.
LeSage J (1999a) Econometrics toolbox for Matlab. www.spatial-econometrics
.com/.
LeSage J (2004) A family of geographically weighted regression models. In
L Anselin, R Florax, S Rey (eds), Advances in spatial econometrics.
Methodology, tools and applications. New York: Springer, 241–64.
LeSage J, Kelley Pace R (2009) Introduction to spatial econometrics. CRC
Press, Boca Raton, FL: Taylor & Francis.
Lee D, Shaddick G (2005) Time-varying coeﬃcient models for the analysis
of air pollution and health outcome data. University of Bath, Dept of
Statistics, Working Paper 05/09.
Lee H, Higdon D, Calder C, Holloman C (2005) Eﬃcient models for correlated
data via convolutions of intrinsic processes. Statistical Modelling, 5, 53–74.
Lee J, Hwang R (2000) On estimation and prediction for temporally corre-
lated longitudinal data. Journal of Statistical Planning and Inference,
87, 87–104.
Lee J, Sabavala D (1987) Bayesian estimation and prediction for the beta
binomial model. Journal of Business and Economic Statistics, 5, 357–67.

538
References
Lee K, Thompson S (2008) Flexible parametric models for random-eﬀects
distributions. Statistics in Medicine, 27, 418–34.
Lee P (2004) Bayesian statistics: An Introduction. 3rd ed. London: Edward
Arnold.
Lee R, Carter L (1992) Modeling and forecasting U.S. mortality. Journal of
the American Statistical Association, 87, 659–71.
Lee S (1998) Coeﬃcient constancy test in a random coeﬃcient autoregressive
model. Journal of Statistical Planning and Inference, 74, 93–101.
Lee S-Y (2007) Structural equation modelling: A Bayesian approach. New
York: Wiley.
Lee S-Y, Shi J (2000) Joint Bayesian analysis of factor score and struc-
tural parameters in the factor analysis models. Annals of the Institute
of Statistical Mathematics, 52, 722–36.
Lee S-Y, Song X-Y (2003) Bayesian model selection for mixtures of structural
equation models with an unknown number of components. British
Journal of Mathematical and Statistical Psychology, 56, 145–65.
Lee S-Y, Song X-Y (2004) Bayesian model comparison of nonlinear structural
equation models with missing continuous and ordinal categorical data.
British Journal of Mathematical and Statistical Psychology, 57, 131–50.
Lee S-Y, Song X-Y (2008) Bayesian model comparison of structural equation
models. In D Dunson (ed.), Random eﬀect and latent variable model
selection. New York: Springer, 121–49.
Lee S-Y, Tang N (2006) Bayesian analysis of structural equation models with
mixed exponential family and ordered categorical data. British Journal
of Mathematical and Statistical Psychology, 59, 151–72.
Lee Y, Nelder J (2000) Two ways of modelling overdispersion in non-normal
data. Applied Statistics, 49, 591–98.
Lee Y, Nelder J (2001) Modelling and analysing correlated non-normal data.
Statistical Modelling, 1, 3–16.
Lee Y, Nelder J (2004) Conditional and marginal models: Another view.
Statistical Science, 19, 219–38.
Leisch F (2004) FlexMix: A general framework for ﬁnite mixture models
and latent class regression. R. Journal of Statistical Software, 11 (8),
http://www.jstatsoft.org/v11/i08
Lenk P (1988) The logistic normal distribution for Bayesian nonparametric
predictive densities. Journal of the American Statistical Association, 83,
509–16.
Lenk P (1999) Bayesian inference for semiparametric regression using a
Fourier representation. Journal of the Royal Statistical Society: Series B,
61, 863–79.
Lenk P, DeSarbo W (2000) Bayesian inference for ﬁnite mixture models of
generalized linear models with random eﬀects. Psychometrika, 65, 475–96.
Leonard T (1973) A Bayesian method for histograms. Biometrika, 60, 297–308.
Leonte D, Nott D, Dunsmuir W (2003) Smoothing and change point detection
for gamma ray count data. Mathematical Geology, 35, 175–94.

References
539
Leroux B, Lei X, Breslow N (1999) Estimation of disease rates in small areas:
a new mixed model for spatial dependence. In M Halloran, D Berry
(eds), Statistical models in epidemiology, the environment and clinical
trials. New York: Springer-Verlag, 135–78.
Lesaﬀre E, Spiessens B (2001) On the eﬀect of the number of quadrature
points in a logistic random-eﬀects model: An example. Applied Statistics,
50, 325–35.
Leslie D, Kohn R, Nott D (2007) A general approach to heteroscedastic linear
regression. Statistics and Computing, 17, 131–46.
Leung Y, Mei C-L, Zhang W-X (2000) Statistical tests for spatial non-
stationarity based on the geographically weighted regression model.
Environment and Planning A, 32 (1), 9–32.
Levy J, Chemerynski S, Sarnat J (2005) Ozone exposure and mortality: An
empiric Bayes metaregression analysis. Epidemiology, 16, 458–68.
Li K (1999) Bayesian analysis of duration models: An application to Chapter
11 bankruptcy. Economics Letters, 63, 305–12.
Li J, Yang X, Wu Y, Shoptaw S (2007) A random-eﬀects Markov transition
model for Poisson-distributed repeated measures with non-ignorable
missing values. Statistics in Medicine, 26, 2519–32.
Li M (2007) Bayesian proportional hazard analysis of the timing of high
school dropout decisions. Econometric Reviews, 26, 529–56.
Li Q, Stengos T (1994) Adaptive estimation in the panel data error com-
ponent model with heteroskedasticity of unknown form. International
Economic Review, 35, 981–1000.
Li W (1994) Time series models based on generalized linear models: Some
further results. Biometrics, 50, 506–11.
Liang F, Paulo R, Molina G, Clyde M, Berger J (2008) Mixtures of g priors
for Bayesian variable selection. Journal of the American Statistical
Association, 103, 410–23.
Liang, K, Zeger S (1986) Longitudinal data analysis using generalized linear
models. Biometrika, 73, 13–22.
Lichstein J, Simons T, Shriner S, Franzreb K (2002) Spatial autocorrelation
and autoregressive models in ecology. Ecological Monographs, 72, 445–63.
Liechty J, Liechty M, Muller P (2004) Bayesian correlation estimation.
Biometrika, 91, 1–14.
Lillard L, Willis R (1978) Dynamic aspects of earning mobility. Econometrica,
46, 985–1012.
Lin H, McCulloch C, Rosenheck R (2004) Latent pattern mixture models for
informative intermittent missing data in longitudinal studies. Biometrics,
60, 295–305.
Lin T, Lee J, Hsieh W (2007b) Robust mixture modeling using the skew t
distribution. Statistics and Computing, 17, 81–92.
Lin T, Lee J, Ni H (2004) Bayesian analysis of mixture modelling using the
multivariate t distribution. Statistics and Computing, 14, 119–30.
Lin T, Lee J (2006) A robust approach to t linear mixed models applied to
multiple sclerosis data. Statistics in Medicine, 25, 1397–1412.

540
References
Lin T, Lee J, Yen S (2007a) Finite mixture modelling using the skew normal
distribution. Statistica Sinica, 17, 909–27.
Lindgren F, Rue H (2005) A note on the second order random walk model
for irregular locations. Preprint Statistics 6/2005. Norges Teknisk-
Naturvitenskapelige Universite.
Lindley D, Smith A (1972) Bayes estimates for the linear model. Journal of
the Royal Statistical Society: Series B, 34, 1–41.
Lindsey J (1993) Models for repeated measurements. New York: Oxford
University Press.
Lindstrom M, Bates D (1990) Nonlinear mixed eﬀects models for repeated
measures data. Biometrics, 46, 673–87.
Ling S (2004) Estimation and testing stationarity for double-autoregressive
models. Journal of the Royal Statistical Society: Series B, 66, 63–78.
Litterman R (1986) Forecasting with Bayesian vector autoregressions—ﬁve
years of experience. Journal of Business & Economic Statistics, 4, 25–38.
Little R (1993) Pattern-mixture models for multivariate incomplete data.
Journal of the American Statistical Association, 88, 125–34.
Little R (1995) Modeling the drop-out mechanism in repeated-measures
studies. Journal of the American Statistical Association, 90, 1112–21.
Little R, Rubin D (2002) Statistical analysis with missing data, 2nd edn.
Hoboken, NJ: Wiley-Interscience.
Liu L, Hedeker, D (2006) A mixed-eﬀects regression model for longitudinal
multivariate ordinal data. Biometrics, 62, 261–68.
Liu N, Dey D (2007) Hierarchical overdispersed Poisson model with
macrolevel autocorrelation. Statistical Methodology, doi:10.1016/i.stamet
.2006.11.006.
Liu X, Wall M, Hodges J (2005) Generalized spatial structural equation
modeling. Biostatistics, 6, 539–57.
Lockwood J, Doran H, McCaﬀrey D (2003) Using R for estimating longitu-
dinal student achievement models. R Newsletter, 3, 17–23.
Lopes H, Muller P, Ravishanker N (2007) Bayesian computational methods
in biomedical research. In R Khattree, D Naik (eds), Computational
methods in biomedical research. New York: Deccer, 211–59.
Lopes H, West M (2004) Bayesian model assessment in factor analysis.
Statistica Sinica, 14, 41–67.
Lubke G, Muthen B (2005) Investigating population heterogeneity with
factor mixture models. Psychological Methods, 10, 21–39.
Lubrano M (1995) Testing for unit root in a Bayesian framework. Journal of
Econometrics, 69, 81–109.
Lunn D, Spiegelhalter D, Thomas A, Best N (2009) The BUGS project: Evo-
lution, critique and future directions. Statistics in Medicine, 28, 3049–67.
M¨uller P, Rosner G (1997) A Bayesian population model with hierarchical
mixture priors applied to blood count data. Journal of the American
Statistical Association, 92, 1279–92.
Ma G, Troxel A, Heitjan D (2005) An index of local sensitivity to nonignorable
drop-out in longitudinal modelling. Statistics in Medicine, 24, 2129–50.

References
541
Ma Y, Genton M, Davidian M (2004) Linear mixed eﬀects models with
semiparametric generalized skew elliptical random eﬀects. In M Genton
(ed.), Skew-Elliptical distributions and their applications: A journey
beyond normality. Boca Raton, FL: Chapman & Hall/CRC, 339–58.
MacCurdy T (1982) The use of time series processes to model the error struc-
ture of earnings in longitudinal data analysis. Journal of Econometrics,
18, 83–114.
MacNab Y (2007) Mapping disability-adjusted life years: A Bayesian hier-
archical model framework for burden of disease and injury assessment.
Statistics in Medicine 26, 4746–69.
MacNab Y, Gustafson P (2007) Regression B-spline smoothing in Bayesian
disease mapping: With an application to patient safety surveillance,
Statistics in Medicine, 26, 4455–74.
MacNab Y, Kmetic A, Gustafson P, Shaps S (2006) An innovative applica-
tion of Bayesian disease mapping methods to patient safety research.
Statistics in Medicine, 25, 3960–80.
MacNab Y, Qiu Z, Gustafson P, Dean C, Ohlsson A, Lee S (2004) Hierarchical
Bayes analysis of multilevel health services data: A Canadian neonatal
mortality study. Health Services and Outcomes Research Methodology, 5,
5–26.
Madsen L, Dalthorp D (2007) Simulating correlated count data. Environ-
mental and Ecological Statistics, 14, 129–48.
Makuch R, Stephens M, Escobar M (1989) Generalized binomial models to
examine the historical control assumption in active control equivalence
studies. The Statistician, 38, 61–70.
Malaeb Z, Summers K, Pugesek B (2000) Using structural equation modeling
to investigate relationships among ecological variables. Environmental
and Ecological Statistics, 7, 93–111.
Malchow-Moller N, Svarer M (2003) Estimation of the multinomial logit
model with random eﬀects. Applied Economics Letters, 10, 389–92.
Manda S, Gilthorpe M, Tu Y, Blance A, Mayhew M (2005) A Bayesian
analysis of amalgam restorations in the Royal Air Force using the
counting process approach with nested frailty eﬀects, Statistical Methods
in Medical Research, 14, 567–78.
Mantel N, Hankey B (1978) A logistic regression analysis of response time
data where the hazard function is time dependent. Communications in
Statistics A, 7, 333–47.
Mardia K (1988) Multi-dimensional multivariate Gaussian Markov random
ﬁelds with application to image processing. Journal of Multivariate
Analysis, 24, 265–84.
Mardia K, Watkins A (1989) On multimodality of the likelihood in the
spatial linear model. Biometrika, 76, 289–95.
Marin J, Mengersen K, Robert C (2005) Bayesian modelling and inference on
mixtures of distributions. In D Dey, C Rao (eds), Handbook of Statistics
25. Amsterdam: Elsevier, 15840–45.

542
References
Marriott J, Naylor J, Tremayne A (2003) Exploring economic time series: A
Bayesian graphical approach. Econometrics Journal, 6, 124–45.
Marriott J, Ravishanker N, Gelfand A, Pai J (1996) Bayesian analysis
of ARMA processes: Complete sampling based inference under full
likelihoods. In D Barry, K Chaloner, J Geweke (eds), Bayesian analysis
in statistics and econometrics. New York: Wiley, 243–56.
Marsh H, Grayson D (1994) Longitudinal conﬁrmatory factor analysis:
Common, time-speciﬁc, item-speciﬁc, and residual-error components of
variance. Structural Equation Modeling, 1, 116–45.
Marshall C, Best N, Bottle A, Aylin P (2004) Statistical issues in the
prospective monitoring of health outcomes across multiple units. Journal
of the Royal Statistical Society: Series A, 167, 541–59.
Marshall C, Spiegelhalter D (2003) Approximate cross-validatory predictive
checks in disease mapping models. Statistics in Medicine, 22, 1649–60.
Marshall C, Spiegelhalter D (2007) Identifying outliers in Bayesian hierarchi-
cal models: A simulation-based approach. Bayesian Analysis, 2, 1–33.
Marshall E, Spiegelhalter D (1998) Comparing institutional performance using
Markov Chain Monte Carlo methods. In B Everitt, G Dunn (eds), Statisti-
cal analysis of medical data: New developments. London: Arnold, 229–49.
Marshall E, Spiegelhalter D (2003) Approximate cross-validatory predictive
checks in disease mapping models. Statistics in Medicine, 22, 1649–60.
Marshall E, Spiegelhalter D (2007) Simulation-based tests for divergent
behaviour in hierarchical models. Bayesian Analysis, 2, 409–44.
Martin D, Raftery A (1987) Non-Gaussian state-space modeling of non-
stationary time series: Robustness, computation, and non-Euclidean
models. Journal of the American Statistical Association, 82, 1044–50.
Martin T, Wintle B, Rhodes J, Kuhnert P, Field S, Low-Choy S, Tyre
A, Possingham H (2005) Zero tolerance ecology: Improving ecological
inference by modelling the source of zero observations. Ecology Letters,
811, 1235–46.
Martinez-Beneito M, Lopez-Quilez A, Botella-Rocamora P (2008) An au-
toregressive approach to spatio-temporal disease mapping. Statistics in
Medicine, 27, 2874–89.
Mazumdar S, Tang G, Houck P, Dew M, Begley A, Scott J, Mulsant B,
Reynolds C (2007). Statistical analysis of longitudinal psychiatric data
with dropouts. Journal of Psychiatric Research, 41, 1032–41.
McAdam D, Su Y (2002) The war at home: Antiwar protests and congressional
voting, 1965 to 1973. American Sociological Review, 67, 696–721.
McCarthy M (2007) Bayesian methods for ecology. Cambridge: Cambridge
University Press.
McCullagh P, Nelder J (1989) Generalized linear models. 2nd ed. Boca Raton,
FL: Chapman & Hall/CRC.
McCulloch R, Polson N, Rossi P (2000) A Bayesian analysis of the multinomial
probit model with fully identiﬁed parameters. Journal of Econometrics,
99, 173–93.

References
543
McCulloch R, Rossi P (1994) An exact likelihood analysis of the multinomial
probit model. Journal of Econometrics, 64, 207–40.
McCulloch R, Tsay R (1993) Bayesian inference and prediction for mean and
variance shifts in autoregressive time series. Journal of the American
Statistical Association, 88, 968–78.
McCulloch R, Tsay R (1994) Bayesian analysis of autoregressive time series
via the Gibbs sampler. Journal of Time Series Analysis, 15, 235–50.
McFadden D (1974) Conditional logit analysis of qualitative choice behaviour.
In P Zarembka (ed.), Frontiers in econometrics. New York: Academic
Press, 105–42.
McMillen D (1992) Probit with spatial autocorrelation. Journal of Regional
Science, 32, 335–48.
Mebane W, Sekhon J (2004) Robust estimation and outlier detection for
overdispersed multinomial models of count data. American Journal of
Political Science, 48, 391–410.
Mehnert W, Smans M, Muir C, Mohner M, Schon D (1992) Atlas of cancer
incidence in the former German Democratic Republic 1978–1982. New
York: Oxford University Press.
Menard S (2002) Longitudinal research, 2nd edn. London: Sage.
Meng X (1994) Posterior predictive p-values. The Annals of Statistics, 22,
1142–60.
Meng X, Wong H (1996) Simulating ratios of normalizing constants using a
simple identity: A theoretical exploration. Statistica Sinica, 6, 831–60.
Mengersen K, Tweedie R (1996) Rates of convergence of the Hastings and
Metropolis algorithms. The Annals of Statistics, 24, 101–21.
Metropolis N, Rosenbluth A, Teller A, Teller E (1953) Equations of state
calculations by fast computing machines. Journal of Chemical Physics,
21, 1087–92.
Meyer K (2005) Random regression analyses using B-splines to model growth
of Australian Angus cattle. Genetics Selection Evolution, 37, 473–500.
Meyer M, Laud P (2002) Predictive variable selection in generalized linear
models. Journal of the American Statistical Association, 97, 859–71.
Meyer R, Millar B (1998) Bayesian stock assessment using a nonlinear
state-space model. In B Marx, H Friedl (eds), Statistical Modeling.
Proceedings, of the 13th International Workshop on Statistical Modelling.
Thousand Oaks, California: Sage, 284–91.
Meyer R, Yu J (2000) BUGS for a Bayesian analysis of stochastic volatility
models. Econometrics Journal, 3, 198–215.
Mezzetti M (2006) Bayesian correlated factor analysis for spatial data.
Proceedings Compstat 2006, In A Rizzi, M Vichi (eds), International
Association for Statistical Computing. New York: Springer.
Migon H, Gamerman D, Lopes H, Ferreira M (2005) Dynamic models. In
D Dey, C Rao (eds), Handbook of statistics, volume 25: Bayesian thinking,
modeling and computation, Chapter 19, Amsterdam: Elsevier, 553–88.
Migon H, Moreira A (2004) Core inﬂation: Robust common trend model
forecasting. Brazilian Review of Econometrics, 24, 1–19.

544
References
Militino A, Ugarte M, Dean C (2001) The use of mixture models for identi-
fying high risks in disease mapping. Statistics in Medicine, 20, 2035–49.
Millar R (2004) Sensitivity of Bayes estimators to hyper-parameters, with an
application to maximum yield from ﬁsheries. Biometrics, 60, 536–42.
Millar R, Meyer R (2000) State-space modeling of nonlinear ﬁsheries biomass
dynamics using the Gibbs sampler. Applied Statistics, 49, 327–42.
Mira A, Petrone S (1996) Bayesian hierarchical nonparametric inference for
change point problems. In J Bernardo, J Berger, A Dawid, A Smith
(eds), Bayesian Statistics 5. Oxford: Oxford University Press, 693–703.
Mitchell T, Beauchamp J (1988) Bayesian variable selection in linear
regression. Journal of the American Statistical Association, 83, 1023–36.
Moauro P, Savio G (2005) Temporal disaggregation using multivariate
structural time series models. Journal of Econometrics, 8, 214–34.
Mohr D (2006) Bayesian identiﬁcation of clustered outliers in multiple
regression. Computational Statistics and Data Analysis, 51, 3955–67.
Molenberghs
G,
Verbeke
G
(2004)
An
introduction
to
(generalized)
(non)linear mixed models. In P de Boeck (ed.), Explanatory item
response models: A generalized linear and nonlinear approach. New York:
Springer, 111–53.
Molenberghs G, Verbeke G (2006) Models for discrete longitudinal data. New
York: Springer.
Molenberghs G, Verbeke G, Demetrio C (2007) An extended random-eﬀects
approach to modelling repeated, overdispersed count data. Lifetime Data
Analysis, 13, 513–31.
Molli´e A (1996) Bayesian mapping of disease. In W Gilks, S Richard-
son, D Spiegelhalter (eds), Markov Chain Monte Carlo in practice,
Chapter 20. London: Chapman and Hall, 359–79.
Mollie A, Richardson S (1991) Empirical Bayes estimates of cancer mortality
rates using spatial models. Statistics in Medicine, 10, 95–112.
Morgan B (1988) Extended models for quantal response data. Statistica
Neerlandica, 42, 253–72.
Morris C, Norton E, Zhou X (1994) Parametric duration analysis of nursing
home usage, Chapter 12 in Case Studies. In N Lange, L Ryan, L Billard,
D Brillinger, L Conquest, J Greenhouse (eds), Biometry. New York:
John Wiley, 231–48.
Mosler K (2003) Mixture models in econometric duration analysis. Applied
Stochastic Models in Business and Industry, 19, 91–104.
Moustaki I (2000) A review of exploratory factor analysis for ordinal
categorical data. In R Cudeck, S du Toit, D Sorbom (eds), Structural
equation models: Present and future. Lincolnwood, IL: Scientiﬁc Software
International, 461–80.
Muller, P, Erkanli, A, West, M (1996) Bayesian curve ﬁtting using multivariate
normal mixtures. Biometrika, 83, 67–79.
Muth´en B, Asparouhov T (2009) Multilevel regression mixture analysis.
Journal of the Royal Statistical Society: Series A, 172, 639–57.

References
545
Muth´en B, Brown C, Masyn K, Jo B, Khoo S, Yang C, Wang C, Kellam S,
Carlin J, Liao J (2002) General growth mixture modeling for randomized
preventive interventions. Biostatistics, 3, 459–75.
Muthen B (1984) A general structural equation model with dichoto-
mous, ordered categorical, and continuous latent variable indicators.
Psychometrika, 49, 115–32.
Muthen B, Masyn K (2005) Discrete-time survival mixture analysis. Journal
of Educational and Behavioral Statistics, 30, 27–58.
Namboodiri K, Suchindran C (1987) Life table techniques and their applica-
tions. New York: Academic Press.
Nandram B, Kim H (2002) Marginal likelihoods for a class of Bayesian gener-
alized linear models. Journal of Statistical Computation and Simulation,
73, 319–40.
Natarajan R, Kass R (2000) Reference Bayesian methods for generalized
linear mixed models. Journal of the American Statistical Association,
95, 227–37.
Natarajan R, McCulloch C (1995) A note on the existence of the posterior
distribution for a class of mixed models. Biometrika, 82, 639–64.
Natarajan R, McCulloch C (1998) Gibbs sampling with diﬀuse proper priors:
A valid approach to data-driven inference? Journal of Computational
and Graphical Statistics, 7, 267–77.
Natario I, Knorr-Held L (2003) Non-parametric ecological regression and
spatial variation. Biometrical Journal, 45, 670–88.
Neal, R (2000) Markov chain sampling methods for Dirichlet process mixture
models. Journal of Computational and Graphical Statistics, 9, 249–65.
Nelson K, Leroux B (2006) Statistical models for autocorrelated count data.
Statistics in Medicine, 25, 1413–30.
Nerlove M (2002) Essays in panel data econometrics. New York: Cambridge
University Press.
Neuhaus J, Hauck W, Kalbﬂeisch J (1992) The eﬀects of mixture distribution
misspeciﬁcation when ﬁtting mixed-eﬀects logistic models. Biometrika,
79, 755–62.
Neuhaus J, Kalbﬂeisch J, Hauck W (1991) A comparison of cluster-speciﬁc
and population-averaged approaches for analyzing correlated binary
data. International Statistical Review, B59, 25–35.
Neuhaus J, McCulloch C (2006) Separating between- and within-cluster
covariate eﬀects using conditional and partitioning methods. Journal of
the Royal Statistical Society B, 68, 859–72.
Neves C, Migon H (2007) Bayesian graduation of mortality rates: An appli-
cation to reserve evaluation, Insurance. Mathematics and Economics, 40,
424–34.
Ngo L,Wand M (2004) Smoothing with mixed model software. Journal of
Statistical Software, 9(1), http://www.jstatsoft.org/v09/i01
Nicholls D, Quinn B (1980) The estimation of random coeﬃcient autoregres-
sive models I. Journal of Time Series, 1, 37–115.

546
References
Nicholls D, Quinn B (1982) Random coeﬃcient autoregressive models: An
introduction. New York: Springer-Verlag.
Niedermeier K, Von Eye A (1999) Statistical analysis of longitudinal cate-
gorical data in the social and behavioral sciences: An introduction with
computer illustrations. Mahwah, NJ: Lawrence Erlbaum Associates.
Nikolov M, Coull B, Catalano P (2007) An informative Bayesian structural
equation model to assess source-speciﬁc health eﬀects of air pollution.
Biostatistics, 8, 609–24.
Norton J, Niu X (2009) Intrinsically autoregressive spatiotemporal models
with application to aggregated birth outcomes. Journal of the American
Statistical Association, 104, 638–49.
Ntzoufras I (2009) Bayesian modeling using Winbugs. Chichester, Sussex:
Wiley.
Nunez-Anton V, Zimmerman D (2000) Modeling non-stationary longitudinal
data. Biometrics, 56, 699–705.
O’Brien S, Dunson D (2004) Bayesian multivariate logistic regression.
Biometrics, 60, 739–46.
O’Sullivan D, Unwin D (2002) Geographic information analysis. Chichester,
Sussex: Wiley.
Oh M-S, Lim Y (2001) Bayesian analysis of time series Poisson data. Journal
of Applied Statistics, 28, 259–71.
Ohlssen D, Sharples L, Spiegelhalter D (2007) Flexible random-eﬀects models
using Bayesian semi-parametric models: Applications to institutional
comparisons. Statistics in Medicine, 26, 2088–2112.
Oman S, Meir N, Halm N (1999) Comparing two measures of creatinine
clearance: An application of errors-in-variables and bootstrap techniques.
Applied Statistics, 48, 39–52.
Omori Y (2003) Discrete duration model having autoregressive random
eﬀects with application to Japanese diﬀusion index. Journal of the Japan
Statistical Society, 33, 1–22.
Opsomer J, Claeskens G, Ranalli M, Kauermann G, Breidt F (2008)
Non-parametric small area estimation using penalized spline regression.
Journal of the Royal Statistical Society: Series B, 70, 265–86.
Orbe J, N´u˜nez-Ant´on V (2006) Alternative approaches to study lifetime data
under diﬀerent scenarios: From the PH to the modiﬁed semiparametric
AFT model. Computational Statistics & Data Analysis, 50, 1565–82.
Ord J, Snyder R, Koehler A, Hyndman R, Leeds M (2005) Time series
forecasting: the case for the single source of error state space ap-
proach. Working Paper 7/05, Department of Econometrics and Business
Statistics, Monash University.
Osborn J (1975) A multiplicative model for the analysis of vital statistics
rates. Applied Statistics, 24, 75–84.
Osborne P, Foody G, Su´arez-Seoane S (2007) Non-stationarity and local
approaches to modelling the distributions of wildlife. Diversity and
Distributions, 13, 313–23.

References
547
Oud J, Folmer H (2008) A structural equation approach to models with
spatial dependence. Geographical Analysis, 40, 152–66.
Paap R (2002) What are the advantages of MCMC based inference in latent
variable models? Statistica Neerlandica, 56, 2–22.
Paap R, van Dijk H (2003) Bayes estimation of Markov trends in possibly
cointegrated series: An application to U.S. consumption and income.
Journal of Business & Economic Statistics, 21, 547–63.
Paddock S (2007) Bayesian variable selection for longitudinal substance
abuse treatment data subject to informative censoring. Journal of the
Royal Statistical Society: Series C, 56, 293–311.
Palmer J, Pettit L (1996) Risks of using improper priors with Gibbs sampling
and autocorrelated errors. Journal of Computational and Graphical
Statistics, 5, 245–49.
Palomo J, Dunson D, Bollen K (2007) Bayesian structural equation model-
ing. In S-Y Lee (ed.), Handbook of latent variable and related models.
Amsterdam: Elsevier, 163–68.
Panagiotelis A, Smith M (2008) Bayesian identiﬁcation, selection and
estimation of functions in high-dimensional additive models. Journal of
Econometrics, 143, 291–316.
Papaspiliopoulos O, Roberts G, Skold M (2003) Non-centered parameteri-
sations for hierarchical models and data augmentation. In J Bernardo,
S Bayarri, J Berger, A Dawid, D Heckerman, A Smith, M West (eds),
Bayesian statistics 7. Oxford: Oxford University Press, 307–26.
Parmigiani G (2002) Modeling in medical decision making: A Bayesian
approach. New York: Wiley.
Parsons N, Edmondson R, Gilmour S (2006) A generalized estimating
equation method for ﬁtting autocorrelated ordinal score data with an
application in horticultural research. Journal of the Royal Statistical
Society: Series C, 55, 507–24.
Pastor N (2003) Methods for the analysis of explanatory linear regression mod-
els with missing data not at random, Quality and Quantity, 37, 363–376.
Patwardhad A, Small M (1992) Bayesian methods for model uncertainty anal-
ysis with application to future sea level rise. Risk Analysis, 12, 513–23.
Pauler D, Wakeﬁeld J (2000) Modeling and implementation issues in Bayesian
meta-analysis. In D Stangl, D Berry (eds), Bayesian meta-analysis. New
York: Marcel Dekker, 205–30.
Pearlman J (1980) An algorithm for the exact likelihood of a high-order
autoregressive-moving average process. Biometrika, 67, 232–33.
Pedroza C (2006) A Bayesian forecasting model: predicting U.S. male
mortality. Biostatistics, 7, 530–50.
Peng F, Jacobs R, Tanner M (1996) Bayesian inference in mixtures-of-experts
and hierarchical mixtures-of-experts models with an application to speech
recognition. Journal of the American Statistical Association, 91, 953–60.
Penzer J (2006) Diagnosing seasonal shifts in time series using state space
models. Statistical Methodology, 3, 193–210.

548
References
Perperoglou A, van Houwelingen H, Henderson R (2006) A relaxation of the
gamma frailty (Burr) model 2006. Statistics in Medicine, 25, 4253–66.
Perreault L, Berniera J, Bob´eeb B, Parent E (2000) Bayesian change-point
analysis in hydrometeorological time series; comparison of change-point
models and forecasting. Journal of Hydrology, 235, 242–63.
Pettit L, Young K (1990) Measuring the eﬀect of observations on Bayes
factors. Biometrika, 77, 455–66.
Pettitt A, Tran T, Haynes M, Hay J (2006) A Bayesian hierarchical model for
categorical longitudinal data from a social survey of immigrants. Journal
of the Royal Statistical Society: Series A, 127, 97–114.
Pettitt A, Weir I, Hart A (2002) A conditional autoregressive Gaussian process
for irregularly spaced multivariate data with application to modelling
large sets of binary data. Statistics and Computing, 12, 353–67.
Phillips P, Durlauf S (1986) Multiple time series regression with integrated
processes. The Review of Economic Studies, 53, 473–95.
Phillips P (1991) To criticize the critics: An objective Bayesian analysis of
stochastic trends. Journal of Applied Econometrics, 6, 333–64.
Pickles A, Crouchley R (1995) A comparison of frailty models for multivariate
survival data. Statistics in Medicine, 14, 1447–61.
Piegorsch W, Bailer J (2005) Analyzing environmental data. Chichester, UK:
Wiley.
Pinheiro J, Liu C, Wu Y (2001) Eﬃcient algorithms for robust estimation in
linear mixed-eﬀects models using the multivariate t distribution. Journal
of Computational and Graphical Statistics, 10, 249–76.
Pitman J, Yor M (1997) The two-parameter Poisson-Dirichlet distribution
derived from a stable subordinator. Annals of Probability, 25, 855–900.
Pitt M, Shephard N (1999) Time varying covariances: A factor stochastic
volatility approach. In J Bernardo, J Berger, A Dawid, A Smith (eds),
Bayesian statistics 6. Oxford: Oxford University Press, 547–70.
Plummer M (2008) Penalized loss functions for Bayesian model comparison.
Biostatistics, 9, 523–39.
Podlich H, Faddy M, Smyth G (2004) Semi-parametric extended Poisson
process models for count data. Statistics and Computing, 14, 311–21.
Pourahmadi M (1999) Joint mean-covariance models with applications to lon-
gitudinal data: Unconstrained parameterisation. Biometrika, 86, 677–90.
Pourahmadi M (2000) Maximum likelihood estimation of generalized linear
models for multivariate normal covariance matrix. Biometrika, 87,
425–35.
Pourahmadi M (2002) Graphical diagnostics for modeling unstructured
covariance matrices. International Statistical Review, 70, 395–417.
Pourahmadi M, Daniels M (2002) Dynamic conditionally linear mixed models
for longitudinal data. Biometrics, 58, 225–31.
Prado R, Huerta G, West M (2000) Bayesian time-varying autoregres-
sions: Theory, methods and applications. Journal of the Institute of
Mathematics and Statistics of the University of Sao Paolo, 4, 405–22.

References
549
Prado R, West M (1997) Exploratory modelling of multiple non-stationary
time series: Latent process structure and decompositions. In T Gregoire
(ed.), Modelling longitudinal and spatially correlated data. New York:
Springer-Verlag.
Press S, Shigemasu K (1989) Bayesian inference in factor analysis. In
L Gleser, M Perleman, S J Press, A Sampson (eds), Contributions to
probability and statistics. New York: Springer-Verlag, 271–87.
Prevost T, Abrams K, Jones D (2000) Hierarchical models in generalized
synthesis of evidence: An example based on studies of breast cancer
screening. Statistics in Medicine, 19, 3359–76.
Proietti T (2006) Measuring core inﬂation by multivariate structural time
series models. Research Paper Series 83, Tor Vergata University, CEIS.
Qian S, Reckhow K, Zhai J, McMahon G (2005) Nonlinear regression
modeling of nutrient loads in streams: A Bayesian approach. Water
Resources Research, 41, W07012, doi:10.1029/2005WR003986.
Qin Z, Damien P, Walker S (2000) Uniform scale mixture models with
applications to variance regression. Working Paper 14, Univ Michigan
Business School.
Qiu Z, Song P, Tan M (2002) Bayesian hierarchical models for multi-level
repeated ordinal data using WinBUGS. Journal of Biopharmaceutical
Statistics, 12, 121–35.
Quinn K (2004) Bayesian factor analysis for mixed ordinal and continuous
responses. Political Analysis, 12, 338–53.
Quintana F, Tam W (1996) Bayesian estimation of beta-binomial models
by simulating posterior densities. Revista de la Sociedad Chilena de
Estad´ıstica, 13, 43–56.
Quintana, F, M¨uller P, Rosner G (2008) A semiparametric Bayesian model
for repeated binary measurements. Applied Statistics, 57, 419–31.
Rabe-Hesketh S, Skrondal A, Pickles A (2004) GLLAMM manual. U.C.
Berkeley Division of Biostatistics Working Paper 160.
Raftery A (1996) Approximate Bayes factors and accounting for model
uncertainty in generalized linear models. Biometrika, 83, 251–66.
Raftery A, Hout M (1993) Maximally maintained inequality: Expansion, re-
form and opportunity in Irish schools. Sociology of Education, 66, 41–62.
Raftery A, Lewis S (1992). One long run with diagnostics: Implementation
strategies for Markov Chain Monte Carlo. Statistical Science, 7, 493–97.
Raftery A, Lewis S (1996) The number of iterations, convergence diagnos-
tics and generic Metropolis algorithms. In W Gilks, D Spiegelhalter,
S Richardson (eds), Practical Markov Chain Monte Carlo. London:
Chapman & Hall.
Rao J (2003) Small area estimation. New York: Wiley.
Rattanasiri S, Bohning D, Roianavipart P, Athipanyakom S (2004) A mixture
model application in disease mapping of malaria. Southeast Asian
Journal of Tropical Medicine and Public Health, 35, 38–47.
Raudenbush S (1993) A crossed random eﬀects model for unbalanced data
with applications in cross-sectional and longitudinal research. Journal of
Educational Statistics, 18, 321–49.

550
References
Ravishanker N, Dey D (2000) Multivariate survival models with a mixture
of positive stable frailties. Methodology and Computing in Applied
Probability, 2, 293–308.
Redner R, Walker H (1984) Mixture densities, maximum likelihood, and the
EM algorithm. SIAM Review, 26, 195–239.
Reich B, Fuentes M (2007) A multivariate semiparametric Bayesian spatial
modeling framework for hurricane surface wind ﬁelds. Annals of Applied
Statistics, 1, 249–64.
Reich B, Hodges J (2008) Modeling longitudinal spatial periodontal data:
A spatially-adaptive model with tools for specifying priors and checking
ﬁt. Biometrics, 64, 790–99.
Reis E, Salazar E, Gamerman D (2006) Comparison of sampling schemes for
dynamic linear models. International Statistical Review, 74, 203–14.
Ribeiro P, Diggle P (2001) geoR: A package from geostatistical analysis.
R-NEWS, 1 (2), 15–18 June. ISSN 1609-3631. URL http://cran.R-project
.org/doc/Rnews.
Rice K (2005) Bayesian measures of goodness of ﬁt. In P Armitage, T Colton
(eds), Encyclopedia of biostatistics. Chichester: John Wiley.
Rice K, Spiegelhalter D (2006) A simple diagnostic plot connecting robust
estimation, outlier detection, and false discovery rates. Journal of
Applied Statistics, 33, 1131–47.
Richards H, Barry, R (1998) U.S. Life Tables for 1990 by sex, race, and
education. Journal of Forensic Economics, 11, 9–26.
Richardson S, Green P (1997) On Bayesian analysis of mixtures with an
unknown number of components. Journal of the Royal Statistical Society:
Series B, 59, 731–58.
Richardson S, Guihenneuc C, Lasserre V (1992) Spatial linear models with
autocorrelated error structure. The Statistician, 41, 539–57.
Richardson S, Monfort C (2000) Ecological correlation studies. In P Elliott,
J Wakeﬁeld, N Best and D Briggs (eds), Spatial epidemiology methods
and applications. Oxford: Oxford University Press, 205–20.
Richardson S, Thomson A, Best N, Elliott, P (2004) Interpreting posterior
relative risk estimates in disease-mapping studies. Environmental Health
Perspectives, 112, 1016–25.
Rigby R (1997) Bayesian discrimination between two multivariate normal
populations with equal covariance matrices. Journal of the American
Statistical Association, 92, 1151–54.
Riggan W, Manton K, Creason J, Woodbury M, Stallard E (1991) Assessment
of spatial variation of risks in small populations. Environmental Health
Perspectives, 96, 223–38.
Robert C (1996) Mixtures of distributions: Inferences and estimation. In
W Gilks, S Richardson, D Spiegelhalter (eds), Markov Chain Monte
Carlo in Practice, Chapter 24. Boca Raton, FL: Chapman and Hall/CRC,
441–64.
Robert C, Mengersen K (1999) Reparameterisation issues in mixture mod-
elling and their bearing on the Gibbs sampler. Computational Statistics
and Data Analysis, 29, 325–43.

References
551
Robert C, Titterington D (1998) On perfect simulation for some mixtures of
distributions. Statistics and Computing, 8, 145–58.
Roberts G, Gelman A, Gilks W (1997) Weak convergence and optimal
scaling of random walk metropolis algorithms. The Annals of Applied
Probability, 7, 110–20.
Roberts G, Rosenthal J (2004) General state space Markov chains and
MCMC algorithms. Probability Surveys, 1, 20–71.
Roberts G, Sahu S (2001) Approximate predetermined convergence properties
of the Gibbs sampler. Journal of Computational and Graphical Statistics,
10, 216–29.
Roberts G, Tweedie R (1996) Geometric convergence and central limit
theorems for multidimensional Hastings and Metropolis algorithms.
Biometrika, 83, 95–110.
Roberts G, Sahu S (1997) Updating schemes, correlation structures, blocking
and parameterization of the Gibbs sampler. Journal of the Royal
Statistical Society: Series B, 59, 291–317.
Roberts S, Husmeier D, Rezek I, Penny W (1998) Bayesian approaches to
Gaussian mixture modeling. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 20, 1133–42.
Robertson C, Fryer J (1968) Some descriptive properties of normal mixtures.
Skand Aktuar Tidskr, 52, 137–46.
Rodr´ıguez-Avi J, Conde-S´anchez A, S´aez-Castillo A, Olmo-Jim´e nez M (2007)
A generalization of the beta–binomial distribution. Applied Statistics,
56, 51–61.
Rodrigues A, Assuncao R (2008) Propriety of posterior in Bayesian space
varying parameter models with normal data. Statistics & Probability
Letters, 78, 2408–11.
Rodrigues-Motta R, Gianola D, Heringstad B, Rosa G, Chang Y (2007)
A zero-inﬂated Poisson model for genetic analysis of the number of mas-
titis cases in Norwegian red cows. Journal of Dairy Science, 90, 5306–15.
Rodriguez G, Goldman N (2001) Improved estimation procedures for mul-
tilevel models with binary response: A case study. Journal of the Royal
Statistical Society: Series A, 164, 339–55.
Roeder K, Wasserman L (1997) Practical Bayesian density estimation using
mixtures of normals. Journal of the American Statistical Association,
92, 894–902.
Rosenbaum P, Rubin D (1983) The central role of the propensity score in
observational studies for causal eﬀects. Biometrika, 70, 41–55.
Rossi P, Allenby G, McCulloch R (2005) Bayesian statistics and marketing.
Chichester, England: Wiley.
Rousseeuw P (1984) Least median of squares regression. Journal of the
American Statistical Association, 79, 871–80.
Roy J, Lin X (2000) Latent variable models for longitudinal data with
multiple continuous outcomes. Biometrics, 56, 1047–54.

552
References
Roy J, Lin, X (2002) Analysis of multivariate longitudinal outcomes with
non-ignorable dropouts and missing covariates: Changes in methadone
treatment practices. Journal of the American Statistical Association, 97,
40–52.
Roy N (2002) Is adaptive estimation useful for panel models with het-
eroskedasticity in the individual speciﬁc error component? Some Monte
Carlo evidence. Econometric Reviews, 21, 189–203.
Royston P (1993) A toolkit for testing for non-normality in complete and
censored samples. The Statistician, 42, 37–43.
Rubin D (1976) Inference and missing data. Biometrika, 63, 581–92.
Rubin D (1987) Multiple imputation for nonresponse in surveys. New York:
Wiley.
Rubin D, Schenker N (1986) Multiple imputation for interval estimation
from simple random samples with ignorable nonresponse. Journal of the
American Statistical Association, 81, 366–74.
Rue H (2001) Fast sampling of Gaussian Markov random ﬁelds. Journal of
the Royal Statistical Society: Series B, 63, 325–38.
Rue H, Held L (2005) Gaussian Markov Random Fields: Theory and
applications. London: Chapman & Hall.
Rue H, Tjelmeland H (2002) Fitting Gaussian Markov random ﬁelds to
Gaussian ﬁelds. Scandinavian Journal of Statistics, 29, 31–49.
Rupp A, Dey D, Zumbo B (2004) To Bayes or not to Bayes, from whether
to when: Applications of Bayesian methodology to modeling. Structural
Equation Modeling, 11, 424–51.
Ruppert D, Carroll R (2000) Spatially-adaptive penalties for spline ﬁtting.
Australian & New Zealand Journal of Statistics, 42, 205–23.
Ruppert D, Wand M, Carroll R (2003) Semiparametric regression. Cambridge:
Cambridge University Press.
Ruspini E (1999) Longitudinal research and the analysis of social change.
Quality and Quantity, 33, 219–27.
Ryu D, Sinha D, Mallick B, Lipsitz S, Lipshultz S (2007) Longitudinal studies
with outcome-dependent follow-up: Models and Bayesian regression.
Journal of the American Statistical Association, 102, 952–61.
Sahu S (2002) Bayesian estimation and model choice in item response models.
Journal of Statistical Computation and Simulation, 72, 217–32.
Sahu S, Dey D (2000) A comparison of frailty and other models for bivariate
survival data. Lifetime Data Analysis, 6, 207–28.
Sahu S, Dey D (2004) On a Bayesian multivariate survival model with skewed
frailty. In M Genton (ed.), Skew-elliptical distributions and their appli-
cations: A journey beyond normality. Boca Raton, FL: CRC/Chapman
& Hall, 321–38.
Sahu S, Dey D, Aslanidou H, Sinha D (1997) A Weibull regression model with
gamma frailties for multivariate survival data. Lifetime Data Analysis,
3, 123–37.
Sahu S, Dey D, Branco M (2003) A new class of multivariate skew distri-
butions with applications to Bayesian regression models. The Canadian
Journal of Statistics, 31, 129–50.

References
553
Sain S, Cressie N (2007) A spatial model for multivariate lattice data. Journal
of Econometrics, 140, 226–59.
Sala-i-Martin X, Doppelhofer G, Miller R (2004) Determinants of long-term
growth: A Bayesian averaging of classical estimates (BACE) approach.
American Economic Review, 94, 813–35.
Sanchez B, Butdz-Jorgensen E, Ryan L, Hu H (2005) Structural equation
models: A review with applications to environmental epidemiology.
Journal of the American Statistical Association, 100, 1443–55.
Sargent D (1997) A ﬂexible approach to time-varying coeﬃcients in the Cox
regression setting. Lifetime Data Analysis, 3, 13–25.
Schabenberger O, Gotway C (2004) Statistical methods for spatial data
analysis. Boca Raton, FL: Chapman & Hall/CRC.
Schafer J (1997) Imputation of missing covariates under a multivariate
linear mixed model. Technical report, Department of Statistics, The
Pennsylvania State University.
Schafer J, Graham J (2002) Missing data: Our view of the state of the art.
Psychological Methods, 7, 147–77.
Scheines R, Hoijtink H, Boomsma A (1999) Bayesian estimation and testing
of structural equation models. Psychometrika, 64, 37–52.
Schmid V, Held L (2004) Bayesian extrapolation of space-time trends for
cancer registry data. Biometrics, 60, 1034–42.
Schmid
V,
Held
L
(2007)
Bayesian
age-period-cohort
modeling
and
prediction—BAMP. Journal of Statistical Software, 21 (8), http://www
.jstatsoft.org/.
Schmidt P, Witte A (1989) Predicting criminal recidivism using ‘split
population’ survival time models. Journal of Econometrics, 40, 141–59.
Schoen R, Weinick R (1993) The slowing metabolism of marriage: Figures
from 1988 U.S. marital status life tables. Demography, 30, 734–46.
Schotman P, Van Dijk H (1991) On Bayesian routes to unit roots. Journal of
Applied Econometrics, 6, 387–401.
Schwartz J (1993) Air pollution and daily mortality in Birmingham, Alabama.
American Journal of Epidemiology, 137, 1136–47.
Schwarz G (1978) Estimating the dimension of a model. Annals of Statistics,
6, 461–64.
Scollnik D (1995) Bayesian analysis of two overdispersed Poisson models.
Biometrics, 51, 1117–26.
Scollnik D (2002) Implementation of four models for outstanding liabilities in
WinBUGS: A discussion of a paper by Ntzoufras and Dellaportas. North
American Actuarial Journal, 6, 128–36.
Scott S (2002) Bayesian methods for hidden Markov models: Recursive
computing in the 21st century, Journal of the American Statistical
Association, 97, 337–51.
Scott S (2003) Data augmentation for the Bayesian analysis of multinomial
logit model. Proceedings of American Statistical Association Section
on Bayesian Statistical Science. Alexandria, VA: American Statistical
Association.

554
References
Seltzer M (1993) Sensitivity analysis for ﬁxed eﬀects in the hierarchical model:
A Gibbs sampling approach. Journal of Educational Statistics, 18, 207–35.
Seltzer M, Novak J, Choi K, Lim N (2002) Sensitivity analysis for hierarchical
models employing t level-1 assumptions. Journal of Educational and
Behavioral Statistics, 27, 181–222.
Seltzer M, Wong W, Bryk A (1996) Bayesian inference in applications of
hierarchical models: Issues and methods. Journal of Educational and
Behavioral Statistics, 21, 131–67.
Sethuraman J (1994) A constructive deﬁnition of Dirichlet priors. Statistica
Sinica, 4, 639–50.
Shao Q, Zhou X (2004) A new parametric model for survival data with
long-term survivors. Statistics in Medicine, 23, 3525–43.
Sharples L (1990) Identiﬁcation and accommodation of outliers in general
hierarchical models. Biometrika, 77, 445–53.
Shen W, Louis T (1998) Triple-goal estimates in two-stage hierarchical
models. Journal of the Royal Statistical Society: Series B, 60, 455–71.
Shephard N, Pitt M (1997) Likelihood analysis of non-Gaussian measurement
time series. Biometrika, 84, 653–67.
Shi J, Lee S-Y (2000) Latent variable models with mixed continuous and
polytomous data. Journal of the Royal Statistical Society B, 62, 77–87.
Shively T, Kohn R, Wood S (1999) Variable selection and function estimation
in additive nonparametric regression using a data-based prior. Journal
of the American Statistical Association, 94, 777–807.
Shoemaker J, Painter I, We B (1999) Bayesian statistics in genetics: a guide
for the uninitiated. Trends in Genetics, 15, 354–58.
Shumway R, Stoﬀer D (2006) Time series analysis and its applications; with
R examples. New York: Springer.
Silliman N (1997) Hierarchical selection models with applications in meta-
analysis. Journal of the American Statistical Association, 92, 926–36.
Silva G, Dean C, Niyonsenga T, Vanasse A (2008) Hierarchical Bayesian
spatiotemporal analysis of revascularization odds using smoothing
splines. Statistics in Medicine, 27, 2381–401.
Silva R, Lopes H, Migon H (2006) The extended generalized inverse Gaussian
distribution for log-linear and stochastic volatility models. Brazilian
Journal of Probability and Statistics, 20, 67–91.
Sims C, Zha T (1998) Bayesian methods for dynamic multivariate models.
International Economic Review, 39, 949–68.
Sinha D (1993) Semiparametric Bayesian analysis of multiple event time
data. Journal of the American Statistical Association, 88, 979–83.
Sinha D, Chen M-H, Ghosh S (1999) Bayesian analysis and model selection
for interval-censored survival data. Biometrics, 55, 585–90.
Sinha D, Ghosh S (2006) Multiple events time data: A Bayesian recourse.
In D Dey, C Rao (eds), Bayesian thinking: Modeling and computation,
Handbook of Statistics, Vol 25. Amsterdam: Elsevier, 891–906.
Sinha D, Patra K, Dey, D (2003) Modelling accelerated life test data by using a
Bayesian approach. Journal of the Royal Statistical Society C, 52, 249–59.

References
555
Sinharay S (2004) Experiences with Markov Chain Monte Carlo convergence
assessment in two psychometric examples. Journal of Educational and
Behavioral Statistics, 29, 461–88.
Sinharay S, Stern H (2003) Posterior predictive model checking in hierarchical
models. Journal of Statistical Planning and Inference, 111, 209–21.
Sinharay S, Stern H (2005) An empirical comparison of methods for com-
puting Bayes factors in generalized linear mixed models. Journal of
Computational and Graphical Statistics, 14, 415–35.
Siu N, Kelly D (1998) Bayesian parameter estimation in probabilistic risk
assessment. Reliability Engineering and System Safety, 62, 89–116.
Skrondal A, Rabe-Hesketh S (2004) Generalized latent variable modeling:
Multilevel, longitudinal and structural equation models. Boca Raton, FL:
Chapman & Hall/CRC.
Skrondal A, Rabe-Hesketh S (2007) Latent variable modelling: A survey.
Scandinavian Journal of Statistics, 34, 712–45.
Smith A (1973a) A general Bayesian linear model. Journal of the Royal
Statistical Society: Series B, 35, 67–75.
Smith A (1973b) Bayes estimates in one-way and two-way models. Biometrika,
60, 319–29.
Smith A, Gelfand A (1992) Bayesian statistics without tears: A sampling-
resampling perspective. The American Statistician, 46, 84–88.
Smith A, Roberts G (1993) Bayesian computation via the Gibbs sampler
and related Markov chain Monte Carlo methods. Journal of the Royal
Statistical Society: Series B, 55, 3–23.
Smith M, Kohn R (1996) Nonparametric regression using Bayesian variable
selection. Journal of Econometrics, 75, 317–44.
Smith M, Kohn R (1997) A Bayesian approach to nonparametric bivariate
regression. Journal of the American Statistical Association, 92, 1522–35.
Smith M, Kohn R (2002) Parsimonious covariance matrix estimation for
longitudinal data. Journal of the American Statistical Association, 97,
1141–53.
Smith M, Wong C-M, Kohn R (1998) Additive nonparametric regression with
autocorrelated errors. Journal of the Royal Statistical Society: Series B,
60, 311–31.
Smith R, Davis J, Sacks J (2000) Regression models for air pollution and daily
mortality: Analysis of data from Birmingham, Alabama. Environmetrics,
11, 719–43.
Smith T, LeSage J (2004) A Bayesian probit model with spatial dependencies.
In J LeSage, R Kelley Pace (eds), Advances in Econometrics: Vol 18:
Spatial and spatiotemporal econometrics. Amsterdam: Elsevier Science,
127–60.
Smith T, Spiegelhalter D, Thomas A (1995) Bayesian approaches to random-
eﬀects meta-analysis: A comparative study. Statistics in Medicine, 14,
2685–99.
Snijders T, Berkhof J (2002) Diagnostic checks for multilevel models. In J
de Leeuw, I Kreft (eds), Handbook of quantitative multilevel analysis.
Boston: Kluwer, 139–73.

556
References
Snijders T, Bosker R (1999) Multilevel analysis. An introduction to basic and
advanced multilevel modelling. London: Sage.
Sohn Y, Chang I, Moon T (2007) Random eﬀects Weibull regression model
for occupational lifetime. European Journal of Operational Research,
179, 124–31.
Song J, Belin T (2004) Imputation for incomplete high-dimensional multivari-
ate normal data using a common factor model. Statistics in Medicine,
2004, 23, 2827–43.
Song J, Ghosh M, Miaou S, Mallick B (2005) Bayesian multivariate spatial
models for roadway traﬃc crash mapping. Journal of Multivariate
Analysis, 97, 246–73.
Song X, Lee S (2004) A Bayesian model selection method with applications.
Computational Statistics & Data Analysis, 40, 539–57.
Song X-Y, Lee S-Y, Ng M, So W-Y, Chan J (2006) Bayesian analysis of
structural equation models with multinomial variables and an application
to type 2 diabetic nephropathy. Statistics in Medicine, 26, 2348–69.
Speed T, Kiiveri H (1986) Gaussian distributions over ﬁnite graphs. Annals
of Statistics, 14, 138–50.
Spiegelhalter D (1998) Bayesian graphical modelling: A case-study in
monitoring health outcomes. Applied Statistics, 47, 115–33.
Spiegelhalter D (1999) Surgical audit: Statistical lessons from Nightingale and
Codman. Journal of the Royal Statistical Society: Series A, 162, 45–58.
Spiegelhalter D (2004) Incorporating Bayesian ideas into health-care evalu-
ation. Statistical Science, 19, 156–74.
Spiegelhalter D (2005) Handling over-dispersion of performance indicators.
Quality and Safety in Health Care, 14, 347–51.
Spiegelhalter D (2006) Two brief topics on modelling with WinBUGS. Pre-
sented at ICEBUGS Conference, Helsinki 2006 (available from http://
mathstat.helsinki.ﬁ/openbugs/IceBUGS/IceBUGSTimetable.html).
Spiegelhalter D, Abrams K, Myles J (2004) Bayesian approaches to clinical
trials and health-care evaluation. New York: Wiley.
Spiegelhalter D, Best N, Carlin B, van der Linde A (2002) Bayesian measures
of model complexity and ﬁt. Journal of the Royal Statistical Society:
Series B, 64, 583–639.
Spiegelhalter D, Freedman L, Parmar M (1994) Bayesian approaches to
randomised trials. Journal of the Royal Statistical Society: Series A, 157,
357–87.
Spiess M (2006) Estimation of a two-equation panel model with mixed
continuous and ordered categorical outcomes and missing data. Journal
of the Royal Statistical Society: Series C, 55, 525–38.
Staudenmayer J, Lake E, Wand M (2009) Robustness for general design
mixed models using the t distribution. Statistical Modelling, 9, 235–55.
Stephens M (2000) Bayesian analysis of mixture models with an unknown
number of components – An alternative to reversible iump methods.
Annals of Statistics, 28 (1), 40–74.

References
557
Stern H, Sinharay S (2005) Bayesian model checking and model diagnostics.
In D Dey, C Rao (eds), Bayesian thinking: Modeling and computation,
handbook of statistics. vol. 25. Amsterdam: Elsevier, 171–92.
Stock J, Watson M (1998) Median unbiased estimation of coeﬃcient variance
in a time-varying parameter model. Journal of the American Statistical
Association, 93, 349–58.
Strickland C, Turner I, Denham R, Mengersen K (2008) Eﬃcient Bayesian
estimation of multivariate state space models. Source: http://eprints
.qut.edu.au.
Sturtz S, Ligges U, Gelman A (2005) R2WinBUGS: A package for running
WinBUGS from R. Journal of Statistical Software, 12 (3), 1–16.
Subramanian S (2004) The relevance of multilevel statistical methods for
identifying causal neighborhood eﬀects. Social Science & Medicine, 58,
1961–67.
Subramanian S, Jones K, Duncan C (2003) Multilevel methods for public
health research. In I Kawachi, L Berkman (eds), Neighborhoods and
health. New York: Oxford University Press, 65–111.
Sun D, Speckman P, Tsutakawa R (2000) Random eﬀects in generalized linear
mixed models (GLMMs). In D Dey, S Ghosh, B Mallick (eds), Generalized
linear models: A Bayesian perspective. Dekker: New York, 23–39.
Sun D, Tsutakawa R, Kim H, He Z (2000) Spatio-temporal interaction with
disease mapping. Statistics in Medicine, 19, 2015–35.
Sun D, Tsutakawa R, Speckman P (1999) Posterior distribution of hierarchical
models using CAR(1) distributions. Biometrika, 86, 341–50.
Swaminathan H, Rogers H (1990) Detecting diﬀerential item functioning us-
ing logistic regression procedures. Journal of Educational Measurement,
27, 361–70.
Swamy P (1971) Statistical inference in random coeﬃcient regression models.
New York: Springer-Verlag.
Swamy P, Mehta J (1975) Bayesian and non-Bayesian analysis of switching
regressions and random coeﬃcient regression. Journal of the American
Statistical Association, 70, 593–602.
Swanson D, Clauser B, Case S, Nungester R, Featherman C (2002) Analysis
of diﬀerential item functioning (DIF) using hierarchical logistic regression
models. Journal of Educational and Behavioral Statistics, 27, 53–75.
Symanski E, Sallsten G, Chan W (2001) Heterogeneity in sources of exposure
variability among groups of workers exposed to inorganic mercury.
Annals of Occupational Hygiene, 45, 677–87.
Tan M, Qu Y, Mascha E, Schubert A (1999) A Bayesian hierarchical model for
multi-level repeated ordinal data: Analysis of oral practice examinations
in a large anaesthesiology training programme. Statistics in Medicine,
18, 1983–92.
Tanizaki H (2003) Nonlinear and non-Gaussian state-space modeling with
Monte Carlo techniques: A survey and comparative study. In C Rao,
D Shanbhag (eds), Handbook of Statistics. Vol. 21. Stochastic processes:
Modeling and simulation, Amsterdam: Elsevier, Chap. 22, 871–929.

558
References
Tanner M (1996) Tools for statistical inference: Methods for the exploration
of posterior distributions and likelihood functions. 3rd edition. New
York: Springer.
Teather D (1984) The estimation of exchangeable binomial parameters.
Communications in Statistics, Part A, 13, 671–80.
Ten Have T, Kunselman A, Pulkstenis E, Landis R (1998) Mixed eﬀects
logistic regression models for longitudinal binary response data with
informative drop-out. Biometrics, 54, 367–83.
Thall P, Vail S (1990) Some covariance models for longitudinal count data
with overdispersion. Biometrics, 46, 657–71.
Tiao G, Tsay R (1989) Model speciﬁcation in multivariate time series.
Journal of the Royal Statistical Society, 51B, 157–213.
Tierney L (1994) Markov chains for exploring posterior distributions. Annals
of Statistics, 21, 1701–62.
Tierney L, Kadane J (1986) Accurate approximations for posterior moments
and marginal densities. Journal of the American Statistical Association,
81, 82–86.
Toft N, Innocent G, Gettinby G, Reid S (2007) Assessing the convergence
of Markov Chain Monte Carlo methods: An example from evaluation
of diagnostic tests in absence of a gold standard. Preventive Veterinary
Medicine, 79, 244–56.
Tosch T, Holmes P (1980) A bivariate failure model. Journal of the American
Statistical Association, 75, 415–17.
Troughton P, Godsill S (1998) Bayesian model selection for linear and
non-linear time series using the Gibbs sampler. In J Fine McWhirter,
I Prouder (eds), Mathematics in Signal Processing IV. Oxford: Oxford
University Press, 249–61.
Troxel A, Harrington D, Lipsitz S (1998) Analysis of longitudinal data
with non-ignorable non-monotone missing values. Applied Statistics, 47,
425–38.
Troxel A, Ma G, Heitjan D (2004) An index of local sensitivity to nonignor-
ability. Statistica Sinica, 14, 1221–37.
Tsai M-Y, Hsiao C (2008) Computation of reference Bayesian inference for
variance components in longitudinal studies. Computational Statistics,
23, 587–604.
Tsay R (1986) Time series model speciﬁcation in the presence of outliers.
Journal of the American Statistical Association, 81, 132–41.
Tsodikov A, Ibrahim J, Yakovlev A (2003) Estimating cure rates from
survival data: An alternative to two-component mixture models. Journal
of the American Statistical Association, 98, 1063–78.
Tutz G, Kauermann G (2003) Generalized linear random eﬀects models with
varying coeﬃcients. Computational Statistics & Data Analysis, 43 (1),
13–28.
Tutz G, Reithinger F (2007) A boosting approach to ﬂexible semiparametric
mixed models. Statistics in Medicine, 26, 2872–900.

References
559
Tzala E, Best N (2007) Bayesian latent variable modelling of multivariate
spatio-temporal variation in cancer mortality. Statistical Methods in
Medical Research. Sep 13 (epub).
Tzala E, Best N (2008) Bayesian latent variable modelling of multivariate
spatio-temporal variation in cancer mortality. Statistical Methods in
Medical Research, 17, 97-118.
Ulrick S (2007) Using semiparametric methods in an analysis of earnings
mobility. Available at SSRN: http://ssrn.com/abstract=654741.
van Dongen S (2006) Prior speciﬁcation in Bayesian statistics: Three
cautionary tales. Journal of Theoretical Biology, 242, 90–100.
van Duijn M, Jansen M (1995) Modelling repeated count data: Some
extensions of the Rasch Poisson counts model. Journal of Educational
and Behavioral Statistics, 20, 241–58.
van Dyk D (2003) Hierarchical models, data augmentation, and Markov
Chain Monte Carlo. In G Babu, E Feigelson (eds), Statistical challenges
in modern astronomy III. New York: Springer, 41–56.
van Dyk D, Meng X-L (2001) The art of data augmentation. Journal of
Computational and Graphical Statistics, 10, 1–111.
van Houwelingen H, Arends L, Stiinen T (2002) Advanced methods in
meta-analysis: Multivariate approach and meta-regression. Statistics in
Medicine, 21, 589–624.
Van den Berg, G (2001) Duration models: Speciﬁcation, identiﬁcation,
and multiple durations. In J Heckman, E Leamer (eds), Handbook of
Econometrics 5, Amsterdam: North Holland.
Vanhonacker W (1990) On Bayesian estimation of model parameters.
Marketing Science, 9, 54–56.
Vannucci M (2000) Matlab code for Bayesian variable selection. ISBA
Bulletin, 7 (3), 12–13.
Vehtari A, Lampinen J (2002) Expected utility estimation via cross-validation.
In J Bernardo, M Bayarri, J Berger, A Dawid, D Heckerman, A Smith,
M West (eds), Bayesian Statistics 7. Clarendon Press, 701–10.
Venables W, Ripley B (1994) Modern applied statistics with S-plus. New-York:
Springer-Verlag.
Verbeke G, Lesaﬀre E (1996) A linear mixed-eﬀects model with heterogeneity
in the random-eﬀects population. Journal of the American Statistical
Association, 91, 217–21.
Verdinelli I, Wasserman L (1991) Bayesian analysis of outlier problems using
the Gibbs sampler. Statistics and Computing, 1, 105–17.
Viele K, Tong B (2002) Modeling with mixtures of linear regressions.
Statistics and Computing, 12, 315–30.
Vines S, Gilks W, Wild P (1996) Fitting Bayesian multiple random eﬀects
models. Statistics and Computing, 6, 337–46.
Viswanathan B, Manatunga A (2001) Diagnostic plots for assessing the
frailty distribution in multivariate survival data. Lifetime Data Analysis,
7, 143–55.

560
References
Wahba G (1983) Bayesian conﬁdence intervals for the cross validated smooth-
ing spline. Journal of the Royal Statistical Society: Series B, 45, 133–50.
Wakeﬁeld J (2007) Disease mapping and spatial regression with count data.
Biostatistics, 8, 158–83.
Wakeﬁeld J, Gelfand A, Smith A (1991) Eﬃcient generation of random
variates via the ratio-of-uniforms method. Statistics and Computing,
1, 129–33.
Wakeﬁeld J, Smith A, Racine-Poon A, Gelfand A (1994) Bayesian analysis
of linear and non-linear population models using the Gibbs sampler.
Applied Statistics, 43, 201–21.
Wakeﬁeld, J, Walker, S (1997) Bayesian nonparametric population models:
Formulation and comparison with likelihood approaches. Journal of
Pharmacokinetics and Biopharmaceutics, 25, 235–53.
Walker S, Damien P, Laud P, Smith A (1999) Bayesian nonparametric
inference for random distributions and related functions. Journal of the
Royal Statistical Society: Series B, 61, 485–527.
Walker S, Mallick B (1999) A Bayesian semiparametric accelerated failure
time model. Biometrics, 55, 477–83.
Wall M (2004) A close look at the spatial structure implied by the CAR and
SAR models. Journal of Statistical Planning and Inference, 121, 311–24.
Waller L (2002) Hierarchical models for disease mapping. In A El-Shaarawi,
W Piegorsch (eds), Encyclopedia of Environmetrics. Chichester: Wiley,
1004–1007.
Waller L, Gotway C (2004) Applied spatial statistics for public health data.
Chichester: Wiley.
Wand J, Shotts K, Sekhon J, Mebane J, Herron M, Brady H (2001) The
butterﬂy did it: The aberrant vote for Buchanan in Palm Beach County,
Florida. American Political Science Review, 95, 793–810.
Wand M (2003) Smoothing and mixed models. Computational Statistics, 18,
223–49.
Wang D, Lin J-Y, Yu T (2006) A MIMIC approach to modeling the
underground economy in Taiwan. Physica A, 371, 536–42.
Wang F, Wall M (2003) Generalized common spatial factor model. Biostatis-
tics, 4, 569–82.
Wang P, Puterman M (1999a) Markov Poisson regression models for discrete
time series, part 1: Methodology. Journal of Applied Statistics, 26, 855–69.
Wang P, Puterman M (1999b) Markov Poisson regression models, part 2:
Applications. Journal of Applied Statistics, 26, 871–82.
Wang P, Puterman M, Cockburn I, Le N (1996) Mixed Poisson regression
models with covariate dependent rates. Biometrics, 52, 381–400.
Warn D, Thompson S, Spiegelhalter D (2002) Bayesian random eﬀects
meta-analysis of trials with binary outcomes: Methods for the absolute
risk diﬀerence and relative risk scales. Statistics in Medicine, 21, 1601–23.
Warton D (2005) Many zeros does not mean zero inﬂation: Comparing the
goodness-of-ﬁt of parametric models to multivariate abundance data.
Environmetrics, 16, 275–89.

References
561
Wasserman L (2000) Asymptotic inference for mixture models using data-
dependent priors. Journal of the Royal Statistical Society: Series B, 62,
159–80.
Watson T, Christian C, Mason A, Smith M, Meyer R (2002) Bayesian-
based decision support system for water distribution systems. In 5th
International Conference on Hydroinformatics. CardiﬀUniversity, UK.
Webster R, Oliver M, Muir K, Mann J (1994) Kriging the local risk of a rare
disease from a register of diagnoses. Geographical Analysis, 26, 168–85.
Wedel M, Bockenholt U, Kamakura W (2003) Factor models for multivariate
count data. Journal of Multivariate Analysis, 87, 356–69.
Wedel M, Desarbo W, Bult J, Ramaswamy V (1993) A latent class Poisson
regression model for heterogeneous count data. Journal of Applied
Econometrics, 8, 397–411.
Weems K, Smith P (2004) On robustness of maximum likelihood estimates for
Poisson-lognormal models. Statistics & Probability Letters, 66, 189–96.
Wei L (1992) The accelerated failure time model: A useful alternative to
the Cox regression model in survival analysis. Statistics in Medicine, 11,
1871–79.
Weir I, Pettitt N (1999) Spatial modelling for binary data using a hidden
conditional autoregressive Gaussian process: A multivariate extension of
the probit model. Statistics and Computing, 9, 77–86.
Weiss R (1994) Pediatric pain, predictive inference and sensitivity analysis.
Evaluation Review, 18, 651–78.
Weiss R (2005) Modelling longitudinal data. New York: Springer.
Weiss R, Cho M, Yanuzzi M (1999) On Bayesian calculations for mixture
priors and likelihoods. Statistics in Medicine, 18, 1555–70.
West M (1984) Outlier models and prior distributions in Bayesian linear
regression. Journal of the Royal Statistical Society: Series B, 46, 431–39.
West M (1992) Modelling with mixtures. In J Bernardo, J Berger, A Dawid,
A Smith (eds), Bayesian Statistics 4. New York: Oxford University
Press, 503–24.
West M (1996) Bayesian time series: models and computations for the analysis
of time series in the physical sciences. In J Skilling (ed.), Maximum
entropy and bayesian methods, Dordrecht: Kluwer Academic, 23–34.
West M (1998) Bayesian forecasting. In S Kotz, C Read, D Banks (eds),
Encyclopedia of Statistical Sciences. Chichester: Wiley.
West M, Harrison J (1997) Bayesian forecasting and dynamic models. New
York: Springer.
West M, Harrison P, Migon H (1985) Dynamic generalised linear models and
Bayesian forecasting. Journal of the American Statistical Association,
80, 73–97.
West M, Harrison P (1997) Bayesian forecasting and dynamic models, 2nd
edn. New York: Springer-Verlag.
West M, Muller P, Escobar M (1994) Hierarchical priors and mixture models,
with application in regression and density estimation. In P Freeman,
A Smith (eds), Aspects of uncertainty: A tribute to D.V. Lindley.
Chichester: Wiley, 363–86.

562
References
Wheeler D, Calder C (2006) Bayesian spatially varying coeﬃcient models in
the presence of collinearity. Proceedings of the Joint Statistical Meetings.
Seattle, WA. August 6–10, 2006.
Wheeler D, Calder C (2007) An assessment of coeﬃcient accuracy in
linear regression models with spatially varying coeﬃcients. Journal of
Geographical Systems, 9, 145–66.
Wheeler D, Tiefelsdorf M (2005) Multicollinearity and correlation among
local regression coeﬃcients in geographically weighted regression. Journal
of Geographical Systems, 7, 161–87.
Wikle C (2003) Hierarchical models in environmental science. International
Statistical Review, 71, 181–99.
Willink R, Lira I (2005) A united interpretation of diﬀerent uncertainty
intervals. Measurement, 38, 61–66.
Winkelmann R, Zimmermann K (1995) Recent developments in count data
modelling: Theory and application. Journal of Economic Surveys, 9, 1–24.
Winkelmann, R, Boes S (2005) Analysis of microdata. New York: Springer-
Verlag.
Witkovsky V (1996) On variance-covariance components estimation in linear
models with AR(1) disturbances. Acta Mathematicae Universitatis
Comenianae, 65, 129–39.
Wong O (1977) A competing-risk model based on the life table procedure in
epidemiologic studies. International Journal of Epidemiology, 6, 153–59.
Wood S, Jiang W, Tanner M (2002) Bayesian mixture of splines for spatially
adaptive nonparametric regression. Biometrika, 89, 513–28.
Wood S, Kohn R (1998) A Bayesian approach to robust nonparametric binary
regression. Journal of the American Statistical Association, 93, 203–13.
Woodworth G (2004) Biostatistics: A Bayesian introduction. Chichester:
John Wiley & Sons.
Wooldridge J (2005) Simple solutions to the initial conditions problem in
dynamic, nonlinear panel data models with unobserved heterogeneity.
Journal of Applied Econometrics, 20, 39–54.
Wu H, Zhang J-T (2006) Nonparametric regression methods for longitudinal
data analysis. Chichester: John Wiley.
Wu M, Bailey K (1989) Estimation and comparison of changes in the presence
of informative right censoring: Conditional linear model. Biometrics, 45,
939–55.
Xia Y, Weng S, Zhang C, Li S (2005) Mixture random eﬀect model based
meta-analysis for medical data mining. Lecture Notes in Artiﬁcial
Intelligence, 3587, 630–40.
Xie M, He B, Goh T (2001) Zero-inﬂated Poisson model in statistical process
control. Computational Statistics & Data Analysis, 38, 191–201.
Xu S, Jones R, Grunwald G (2007) Analysis of longitudinal count data with
serial correlation. Biometrical Journal, 49, 416–28.
Yang R , Chen M-H (1995) Bayesian analysis for random coeﬃcient regression
models using noninformative priors. Journal of Multivariate Analysis,
55, 283–311.

References
563
Yang X, Shoptaw S (2005) Assessing missing data assumptions in longitudinal
studies: An example using a smoking cessation trial. Drug and Alcohol
Dependence, 77, 213–25.
Yanli Z, Wall M (2004) Investigating the use of the variogram for lattice
data. Journal of Computational and Graphical Statistics, 13, 719–38.
Yashin A, Iachine I, Begun A, Vaupel J (2001) Hidden frailty: Myths
and reality. Department of Statistics and Demography, SDU-Odense
University, Research Report 34.
Yau K (2001) Multilevel models for survival analysis with random eﬀects.
Biometrics, 57, 96–102.
Yau K, Kuk A (2002) Robust estimation in generalized linear mixed models.
Journal of the Royal Statistical Society B, 64, 101–17.
Yau K, Lee A, Ng A (2003) Finite mixture regression model with random
eﬀects: Application to neonatal hospital length of stay. Computational
Statistics and Data Analysis, 41, 359–66.
Yau P, Kohn R (2003) Estimation and variable selection in nonparametric
heteroscedastic regression. Statistics and Computing, 13, 191–208.
Yau P, Kohn R, Wood S (2003) Bayesian variable selection and model
averaging in high-dimensional multinomial nonparametric regression.
Journal of Computational and Graphical Statistics, 12, 23–54.
Yin G (2005) Bayesian cure rate frailty models with application to a root
canal therapy study. Biometrics, 61, 552–58.
Yin G, Ibrahim J (2005) A class of Bayesian shared gamma frailty models
with multivariate failure time data. Biometrics, 61, 208–16.
Yin G, Ibrahim J (2006) Bayesian transformation hazard models. In IMS
monograph series, Vol. 49. Beachwood, OH: Institute of Mathematical
Statistics, 170–82.
Yu J, Meyer A (2006) Multivariate stochastic volatility models: Bayesian
estimation and model comparison. Econometric Reviews, 25, 361–84.
Yuan C, Druzdzel M (2005) How heavy should the tails be? In I Russell,
Z Markov (eds), Proceedings of the Eighteenth International FLAIRS
Conference (FLAIRS-05). Menlo Park, CA: AAAI Press/The MIT
Press, 799–804.
Yuan K-H, Bentler P, Chan W (2004) Structural equation modeling with
heavy tailed distributions. Psychometrika, 69, 421–36.
Zayeri F, Kazemnejad A, Khanafshar N, Nayeri F (2005) Modeling repeated
ordinal responses using a family of power transformations: Application
to neonatal hypothermia data. BMC Medical Research Methodology, 5,
29, http://www.biomedcentral.com/1471-2288/5/29
Zellner A (1983) Applications of Bayesian analysis in econometrics. The
Statistician, 132, 23–34.
Zellner A (1986) On assessing prior distributions and Bayesian regression
analysis with g-prior distributions. In P Goel, A Zellner (eds), Bayesian
inference and decision techniques: Essays in honor of Bruno de Finetti.
Amsterdam: Elsevier, 233–43.

564
References
Zhang H (2002) On estimation and prediction for spatial generalized linear
mixed model. Biometrics, 58, 129–36.
Zhang D, Davidian M (2001) Linear mixed models with ﬂexible distributions
of random eﬀects for longitudinal data. Biometrics, 57, 795–802.
Zhao Y, Staudenmayer J, Coull B, Wand M (2006) General design Bayesian
generalized linear mixed models. Statistical Science 21, 35–51.
Zhu H, Lee S (2001) A Bayesian analysis of ﬁnite mixtures in the LISREL
model. Psychometrika, 66, 133–52.
Zhu L, Gorman D, Horel S (2006) Hierarchical Bayesian spatial models for
alcohol availability, drug “hot spots” and violent crime. International
Journal of Health Geographics, 5, 54.
Zhu M, Lu A (2004) The counter-intuitive non-informative prior for the
Bernoulli family. Journal of Statistics Education [Online], 12 (2), http://
www.amstat.org/publications/jsc/v12n2/zhu.pdf
Zivot E, Wang J (2006) Modeling ﬁnancial time Series with S-PLUS. Berlin:
Springer.
Zuur G, Garthwaite P, Fryer R (2002) Practical use of MCMC methods:
Lessons from a case study. Biometrical Journal, 44, 433–55.

