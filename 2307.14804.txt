Collective behavior from surprise minimization
Conor Heins∗1,2,3,4, Beren Millidge5, Lancelot Da Costa4,6,7,
Richard P. Mann8, Karl Friston4,7, and Iain D. Couzin1,2,3
1Department of Collective Behaviour, Max Planck Institute of Animal Behavior,
2Centre for the Advanced Study of Collective Behaviour, and
3Department of Biology, University of Konstanz, Konstanz D-78457, Germany
4VERSES AI Research Lab, Los Angeles, CA 90016, USA
5MRC Brain Networks Dynamics Unit, University of Oxford, Oxford OX1 3TH, UK
6Department of Mathematics, Imperial College London, London SW7 2AZ, UK
7Wellcome Centre for Human Neuroimaging, University College London, London, WC1N 3AR, UK
8Department of Statistics, School of Mathematics, University of Leeds, Leeds, LS2 9JT, UK
Abstract
Collective motion is ubiquitous in nature; groups of animals, such as fish, birds,
and ungulates appear to move as a whole, exhibiting a rich behavioral repertoire that
ranges from directed movement to milling to disordered swarming.
Typically, such
macroscopic patterns arise from decentralized, local interactions among constituent
components (e.g., individual fish in a school). Preeminent models of this process de-
scribe individuals as self-propelled particles, subject to self-generated motion and ‘social
forces’ such as short-range repulsion and long-range attraction or alignment. However,
organisms are not particles; they are probabilistic decision-makers. Here, we introduce
an approach to modelling collective behavior based on active inference. This cognitive
framework casts behavior as the consequence of a single imperative: to minimize sur-
prise. We demonstrate that many empirically-observed collective phenomena, including
cohesion, milling and directed motion, emerge naturally when considering behavior as
driven by active Bayesian inference — without explicitly building behavioral rules or
goals into individual agents. Furthermore, we show that active inference can recover
and generalize the classical notion of social forces as agents attempt to suppress predic-
tion errors that conflict with their expectations. By exploring the parameter space of
the belief-based model, we reveal non-trivial relationships between the individual be-
liefs and group properties like polarization and the tendency to visit different collective
states. We also explore how individual beliefs about uncertainty determine collective
decision-making accuracy. Finally, we show how agents can update their generative
model over time, resulting in groups that are collectively more sensitive to external
fluctuations and encode information more robustly.
∗cheins@ab.mpg.de
1
arXiv:2307.14804v3  [nlin.AO]  1 Aug 2023

Introduction
The principles underlying coordinated group behaviors in animals have inspired research in
disciplines ranging from zoology to engineering to physics [1–3]. Collective motion in partic-
ular has been a popular phenomenon to study, due in part to its striking visual manifestation
and ubiquity (e.g., swarming locusts, schooling fish, flocking birds and herding ungulates),
and in part to the simplicity of models that can reproduce many of its qualitative features;
like cohesive, directed movement [4–7]. Because of this, collective motion is often cited as a
canonical example of a self-organizing complex system, wherein collective properties emerge
from simple interactions among distributed components.
Popular theoretical models cast collective motion as groups composed of self-propelled
particles (SPPs) that influence one another via simple ‘social forces.’ Early models like the
Vicsek model [6] consider only a simple alignment interaction, where each particle aligns
its direction of travel with the average heading of its neighbors.
While oversimplifying
the biological mechanisms in play, SPP models — like the Vicsek model — are useful for
their amenability to formal understanding, e.g., the computation of universal quantities and
relations through hydrodynamic and mean-field limits [8–11].
Recent research has shifted towards more biologically-motivated, agent-based approaches
that aim to model the specific behavioral circuits and decision-rules that govern individual
behaviors [12–14]. While these models are less analytically-tractable than SPP models, they
are more appealing to domain specialists like biologists, as they can generate predictions
about sensory features in an individual’s environment that are necessary and sufficient for
evoking behavior. Furthermore, these predictions can be tested experimentally [14, 15]. This
data-driven approach can thus provide mechanistic insights into the biological and cognitive
origins of decision-making [13, 16].
In this work, we propose a model class that blends the first-principles, theoretical ap-
proaches of physical models with biological-plausibility, resulting in an ecologically-valid but
theoretically-grounded agent-based model of collective behavior. Our model class is based
on active inference, a framework for designing and describing adaptive systems where all
aspects of cognition — learning, planning, perception, and action — are viewed as a process
of inference [17–19]. Active inference originated in theoretical neuroscience as a normative
account of self-organizing, biological systems as constantly engaged in predictive exchanges
with their sensory environments [20–22].
Collective motion models: from self-propelled particles to
Bayesian agents
In popular self-propelled particle models, an individual’s movement is described as driven
by a combination of social and environmental forces.
These forces are often treated as
vectors that capture various tendencies seen in biological collective motion, such as repulsion,
attraction (to neighbors or external targets), and alignment.
These forces can then be
combined with various nonlinearities and weights to capture mechanisms of interaction.
2

In contrast, the active inference approach forgoes specifying explicit vectorial forces, and
instead starts by modelling all behavior as the solution to an inference problem, namely the
problem of inferring the latent causes of sensations. Perception and action are updated to
ensure that the agent better predicts its sensory inputs, using an internal model of its world
(see Figure 1A). By equipping this internal model with expectations about the environment’s
underlying tendencies, ‘social forces’ can emerge naturally as agents attempt to suppress
sensory data that are mismatched with their expectations. This perspective-shift offers a
unifying modelling ontology for describing adaptive behavior, while also resonating with
cybernetic principles like homeostatic regulation and process theories of neural function like
predictive coding [20, 23, 24].
Active inference blends the construct validity of cognitivist approaches with the first-
principles elegance of physics-based approaches by invoking minimization of a single, all-
encompassing objective function that explains behavior: surprise, or, under certain assump-
tions, prediction error. As an example of this perspective shift, in this work we investigate
a specific class of generative models that can be used to account for the types of collective
behaviors exhibited by animal groups. In doing so, we hope to showcase the benefits of
the framework, while also proposing a testable model class for use in studies of biological
collective motion.
Active inference and generative models of behavior
A common pipeline in the quantitative study of animal behavior involves selecting a can-
didate behavioral algorithm or decision rule that may explain a given behavior, and then
fitting the parameters of the candidate model to experimental or observational data [15, 25].
While these approaches often yield strong quantitative fits to data, the explanatory power of
the models reduces to the interpretation of hard-coded parameters, which often have opaque
relationships to real biological mechanisms or constructs [26].
In the active inference framework we rather ask: what is the minimal model an organism
might have of its environment that is sufficient to explain its behavior? Behavior is then
cast as the process by which the agent minimizes surprise or prediction error, with respect
to this model of the world [20, 27]. The principle of prediction-error minimization enjoys
empirical support in neuroscience [23, 28] and a theoretical basis in the form of the Free
Energy Principle [20, 21], an account of all self-organizing systems that casts them as implicit
models of their environments, ultimately in the service of minimizing the surprise (a.k.a.,
self-information) associated with sensory states [29–31].
What states-of-affairs count as surprising hinges on a generative model that can assign
a likelihood to sensory data. When it comes to modelling behavior driven by this principle,
the challenge then becomes specifying a generative or world model, whereby a particular
pattern of behavior simply emerges by minimizing surprise.
According to active inference, agents minimize surprise by changing their beliefs about
the world (changing which observations are considered surprising) or by acting on the world
to avoid surprising sensory data. The former strategy is thought to correspond to passive
3

Agent
xt
Social forces
Decision rules
Environment
Classical self-propelled particles
yt
Agent
Sensorimotor 
interface
Environment
at
xt
Inference
Control
Active inference agents
yh,1
yh,2
yh,3
yh,4
xh,2
xh,3
xh,4
Focal agent
xh,1
xh,l = 1
Kl ∑
j∈Nl
∥rj −r∥
r = [r1, r2]
0
2
4
6
8
10
12
Observation, yh,l
sz,h
yh,l
xh,l
Observation
xt+1
yt+1
xt
yt
xt−1
yt−1
Dynamic generative model 
 p(˜y, ˜x)
Sector-speciﬁc average distance
Sector-speciﬁc observations  
  are sampled 
from the sector-speciﬁc distance  
yh,l
xh,l
Observation  yh,l
A
B
Figure 1: A: Schematic illustrating the Bayesian perspective in the context of our single
agents, where the hidden states of the environment are segregated from a focal agent by
means of sensory data yt (right panel of A). This contrasts with classic self-propelled particle
models (left panel of A), where environmental or social information manifests in terms
of social forces on the focal individual, who emits its own actions based on hand-crafted
decision-rules (e.g., changes to heading direction). B: Schematic illustration of the sector-
specific distance tracking.
The left panel shows a Bayesian network representation of a
Markovian state space model, that captures time-evolution of a latent variable x1,...,T and
simultaneous observations y1,...T. Note that in practice we represent instantaneous paths of
x using generalized coordinates of motion ˜xt = (xt, x′
t, x′′
t , ...). The middle panel of B shows
how each component of the vectorial hidden state x = (xh,1, ..., xh,L) is computed as the
average nearest-neighbor distance for the neighbors within each visual sector. Observations
are generated as noisy, Gaussian samples centered on the sector-wise distance hidden state
(right panel of B). This requires the agent to estimate the true hidden state xt by performing
inference with respect to a generative model of how sensory data are generated p(˜y, ˜x).
4

processes such as perception and learning, whereas the latter corresponds to processes like
active sensing and movement. Action is thus motivated by the desire to generate sensations
that are as least surprising as possible.
In this paper, we describe the motion of mobile, mutually-sensing agents as emerging
from a process of collective active inference, whereby agents both estimate the hidden causes
of their sensations, while also actively changing their position in space in order to minimize
prediction error. In contrast to models that use pre-specified behavioral rules for generat-
ing behavior, generative models entail collective behavior by appealing to a probabilistic
representation of how an organism’s sensory inputs are generated.
A generative model for a (social) particle
We now consider a sufficient generative model for an individual in a moving group. We equip
this individual, hereafter referred as the focal agent, with a representation of a simple random
variable: the local distance x between itself and its neighbors. For generality, we can expand
this into a multivariate random variable to describe a set of distances x = (x1, x2, ..., xL)
that track the distance between the focal agent and its neighbors within L different sensory
sectors (see Figure 1B). We analogize these L sectors to adjacent visual fields of an agent’s
field of view [32, 33].
The focal agent possesses a model of the distance(s) x and its sensations thereof y.
In particular, our focal agent represents the dynamics of x using a stochastic differential
equation (a.k.a., a state-space model) defined by a drift f and some stochastic forcing ω —
we refer to this component of the generative model as the dynamics model. The stochastic
term ω captures the agent’s uncertainty about paths of x over time. The agent also believes
it can sense x via observations y, mediated by a sensory map, which we call the observation
model. This is defined by some function g with additive noise z. The agent’s generative
model is then fully described by a pair of equations that detail 1) the time-evolution of the
distance and 2) the simultaneous generation of sensory samples of the distance:
D˜x = ˜f + ˜ω
˜y = ˜g + ˜z
(1)
All random variables are described using generalized coordinates of motion with the
convention ˜q = {q, q′, q′′, ...}. Generalized coordinates allow us to represent the trajectory
of a random variable using a vector of local time derivatives (position, velocity, acceleration,
etc.).
The matrix D is a generalized shift operator that moves a vector of generalized
coordinates up one order of motion D(x, x′, x′′, ...)⊤= (x′, x′′, x′′′, ...)⊤.
The generalized
functions ˜f and ˜g therefore operate on vectors of generalized coordinates (see Appendix A
for details on generalized filtering).
Generalized filtering and active inference
An agent equipped with this dynamic generative model then performs active inference by
updating its beliefs (state estimation, or filtering) and control states (action) to minimize
5

surprise.
Inference entails updating a probabilistic belief over hidden states ˜x in the face of sen-
sory data ˜y. Our agents solve this filtering problem using generalized filtering [34, 35], an
approximate algorithm for Bayesian inference and parameter estimation on dynamic state-
space models. This is achieved by minimizing the variational free energy F, a tractable
upper bound on surprise (i.e., negative log evidence or marginal likelihood).
The agent
minimizes the free energy with respect to a belief distribution q(˜x) with parameters ν; this
approximates the true posterior qν(˜x) ≈p(˜x|˜y), which is the optimal solution in the context
of Bayesian inference. The true posterior p(˜x|˜y) is difficult to compute for many generative
models due to the difficult calculation of the marginal (log) likelihood ln p(˜y). Variational
methods circumvent this intractable marginalization problem by replacing it with a tractable
optimization problem: namely, adjusting an approximate posterior to match the true poste-
rior by minimizing F with respect to its (variational) parameters ν.
We parameterize q(˜x) as a Gaussian with mean-vector ˜µ; according to generalized filter-
ing, ˜µ is updated using a weighted sum of prediction errors:
d˜µ
dt ∝−∇˜µF(˜µ, ˜y)
∝˜ξz −˜ξω
where ˜ξz = ˜Πz(˜y −˜g(˜µ))
˜ξω = ˜Πω(D˜µ −˜f(˜µ))
(2)
The ensuing evidence accumulation can also be regarded as a generalisation of predictive
coding [23, 36], where beliefs are updating using a running integration of prediction errors
˜ξz, ˜ξω.
While inference entails changing the approximate posterior means ˜µ to account for sen-
sory data, action entails changing the data itself to better match the data to one’s current
beliefs. Similar to the update scheme in (2), actions are also updated by minimizing free
energy:
da
dt = −∇aF(˜µ, ˜y(a))
= −∇˜yF(˜µ, ˜y(a))∇a˜y(a)
= −˜ξ
⊤
z ∇a˜y(a)
(3)
Actions thus are updated using a product of precision-weighted prediction errors and
˜ξz and a ‘sensorimotor contingency’ ∇a˜y(a) or reflex arc. This sort of ‘reflexive action’ —
where control is simply targeted at minimizing sensory prediction errors — underlies active
inference accounts of motor control [22, 24], and can be formally related to proportional-
integral-derivative (PID) control [37]. In the presence of precise prior beliefs (i.e., ˜Πω ≫˜Πz),
these prediction errors measure how far an agent’s observations are from its expectations; the
6

agent then acts using (3) to minimize this deviation. Active inference agents are thus driven
to act in a way that aligns with their (biased) expectations about the world [38]. In the next
section, we will see how building a particular type of bias into each agent’s generative model
leads to the appearance of social forces-like terms in (3).
Social forces as a consequence of predictive control
In particular, we take the agent’s action to be its heading direction a = v, and examine
the case where the agent observes the distance to its neighbors within a single sensory
sector, i.e., L = 1, x = (x1). We distinguish the agent’s representation of the distance x
from the actual distance using the subscript h. Therefore xh = (xh,1, xh,2, ..., xh,L) denotes
the average distances (and corresponding sensory samplesyh) calculated using the actual
positions of other agents. For the case of L = 1, and assuming the agent observes both the
distance and its rate of change y′
h,1, this is:
xh,1 = 1
K
X
j∈Nin
∥rj −r∥
yh,1 = xh,1 + zh,1
x′
h,1 = dxh,1
dt
y′
h,1 = x′
h,1 + z′
h,1
(4)
Nin is the set of neighbors within the agent’s single sensory sector, K is the size of this
set, r is the focal agent’s position vector, and rj is the position vectors of neighbor j. The
sensory observation of the generalized distance ˜yh = (yh,1, y′
h,1) is a sample of the hidden
state, perturbed by some additive noises ˜z = (zh,1, z′
h,1). By expanding the active inference
control rule in (3), we arrive at the following differential equation for the heading vector:
dv
dt = ξ′
z∆ˆr
∆ˆr = 1
K
X
j∈Nin
∆rj
∥∆rj∥, ∆rj = rj −r
(5)
The average vector ∆ˆr is exactly the (negative) ‘sensorimotor contingency’ term ∇a˜y(a)
from (3) (see Appendix A for detailed derivations):
∇v˜y(v) = ∇ry = 1
K
X
j∈Nin
r −rj
∥r −rj∥= −∆ˆr
(6)
The simple action update in (5) means that the focal agent moves along a vector point-
ing towards the average position of its neighbors. Whether this movement is attractive or
repulsive is determined by the sign of the sensory prediction error ξ′
z, and its magnitude
7

depends on the scale of the prediction error, i.e., how much observations deviate from the
agent’s predictions.
The presence of both attractive and repulsive forces depends on the agent’s model of the
distance dynamics, captured by the functional form of ˜f. In particular, consider forms of ˜f
that relax x to some attracting fixed point η > 0. Equipped with such a stationary model of
the local distance, inference dynamics (c.f., (2)) will constantly bias its predictions µ accord-
ing to the prior belief that the distance is pulled to η. Given this biased dynamics model
and the action update in (3), such an agent will move to ensure that distance observations
˜yh are consistent with the fixed point η.
This action update shows immediate resemblance to the attractive and repulsive vectors
common to social force-based models [4, 5, 7], which often share the following general form:
Fattr ∝
X
j∈ZA
rij
∥rij∥
Frepul ∝−1
K
X
j∈ZR
rij
∥rij∥
(7)
where ZA, ZR refer to distance-defined zones of attraction or repulsion, respectively. In
the active inference framework, these social forces emerge as the derivative of the observations
with respect to action ∇a˜y, where the sign and magnitude of the sensory prediction error
ξ′
z determines whether the vector is attractive (towards neighbors) or repulsive (away from
neighbors). The transition point between attraction and repulsion is therefore given by η,
the point at which prediction errors switch sign.
An important consequence of this formulation is that, unlike the action rule used in social
force-based models, the ‘steady-state’ solution occurs when all social forces disappear (when
prediction errors vanish). In this case, the agent ceases to change its heading direction and
adopts its previous velocity. This occurs when the agent’s sensations align with its (biased)
predictions yh,1 ≈η. In classic SPP models, this is equivalent to the different social force
vectors exactly cancelling each other.
We can therefore interpret social force-based models as limiting cases of distance-inferring
active inference agents, because one can conceive of social forces as just those forces induced
by free energy gradients; namely, the forces that drive belief-updating. In the case of our
active inference agents, attractive and repulsive forces emerge naturally when we assume A)
agents model the local distance dynamics as an attractor with some positive-valued fixed
point η; B) agents can act by changing their heading direction and C) agents observe at least
the first time derivative of their observations (e.g., y′
h,1, but see Appendix A for detailed
derivations).
It is worth highlighting the absence of an explicit alignment force in this model, consistent
with experimental findings in several species of fish [16]. The heading vectors of neighbors
nevertheless implicitly incorporated into the calculation of first-order prediction errors ξ′
z
(c.f., (A.40) in Appendix A). However, alignment forces as seen in the Vicsek model [6]
8

and Couzin model [7] can also be recovered if we assume agents have a generative model
of the average angle between their heading vector and those of their neighbors (see B for
derivations).
Multivariate sensorimotor control
Having recovered social forces as free energy gradients in the case of a single sensory sector
(L = 1), we now revisit the general formulation of the generative model’s state-space, where
the hidden variable x is treated as an L-dimensional vector state: x = (x1, x2, ..., xL), with
correspondingly L-dimensional observations y = (y1, y2, ..., yL).
Specifically, we consider each xl to represent the average distance-to-neighbors within
one of a subset of adjacent sensory sectors, where each sector is offset from the next by
a fixed inter-sector angle (see Figure 1B for a schematic of the multi-sector set-up). The
rest of the generative model is identical; the agents estimate these distances (and their
temporal derivatives x′
l, x′′
l , ...) while changing their heading direction to minimize free energy.
Following the same steps as in the case of a single sector, the resulting update rule for v is
a weighted sum of ‘sector-vectors’, where generalized observations from each sector-specific
modality ˜yl are used to compute the prediction errors that scale the corresponding sector-
vector. This generalizes the scalar-vector product in (3) to a matrix-vector product:
dv
dt = ˜ξ
⊤
z ∆ˆR
∆ˆR = −


∇v˜y1
∇v˜y2
...
∇v˜yL


(8)
where now the (negative) sensorimotor contingency −∇a˜y = ∆ˆR is a matrix whose rows
contain the partial derivatives ∇v˜yl (i.e. the ‘sector-vectors’). Each sector-vector is a vector
pointing towards the average neighbor position within sector l.
Numerical results
Given a group of active inference agents — equipped with the generative models described
in previous sections — it is straightforward to generate trajectories of collective motion by
integrating each agent’s heading vector over time: ˙ri = vi, i ∈{1, 2, ..., N} where N is the
number of agents. We update all heading directions {vi}N
i=1 and beliefs {˜µi}N
i=1 in parallel
via a joint gradient descent on their respective free energies:
9

A
B
log Γz
log Γz
λz
λz
Polarization
Milling probability
Polarized
Milling
Disordered
Figure 2: A: Example snapshots of different collective states in schools of N = 50 active
inference agents. Each line represents the trajectory of one individual, and color gradient
represents time, from earliest (light blue) to latest (purple). The polarized regime in the
left panel was simulated with the default parameters listed in Table E.1 in Appendix E. The
milling regime (middle panel) was achieved by increasing the variance of velocity fluctuations
(encoded in σ2
z′,h) from 0.01 to 0.05 (relative to the default configuration) and increasing λz
from 1.0 to 1.2. The disordered regime was achieved by increasing the sensory smoothness
parameter to 2.0 and decreasing η from 1.0 to 0.5 and α from 0.5 to 0.1 (relative to the
default configuration). B: Average polarization (left) and milling probability (right) shown
as a function of the two factorized components of the sensory precision, Γz (log-transformed)
and λz. For each combination of precision parameters, we ran 500 independent trials of ‘free
schooling,’ and then averaged the quantities of interest across trials. Each ‘free schooling’
trial lasted 15 seconds (1500 time steps with dt = 0.01s); the time-averaged metrics (polar-
ization and milling probability, respectively, were computed from the last 10 seconds of the
trial.
10

˙v1 = −∇v1F(˜µ1, ˜y1)
˙˜µ1 = −∇˜µ1F(˜µ1, ˜y1)
˙v2 = −∇v2F(˜µ2, ˜y2)
˙˜µ2 = −∇˜µ2F(˜µ2, ˜y2)
...
...
˙vN = −∇vNF(˜µN, ˜yN)
˙˜µN = −∇˜µNF(˜µN, ˜yN)
(9)
For the simulation results shown here, each agent tracks the average distance xl within
a total of L = 4 sensory sectors that each subtend 60◦(starting at −120◦and ending
at +120◦, relative to the focal agent’s heading direction) and observe the sector-specific
distances calculated using all neighbors lying within 5.0 units of the focal agent’s position.
Each agent represents the vector of local distances as a generalized state with 3 orders of
motion: ˜x = {x, x′, x′′}, ˜µ = {µ, µ′, µ′′}. Agents can observe the first and second orders
of the distance ˜y = {y, y′}, i.e. the distance itself and its instantaneous rate-of-change. In
the numerical results to follow, we use active inference to study the relationship between the
properties of individual cognition (e.g., the parameters of agent-level generative models) and
collective phenomenology.
Collective regimes
Simulated groups of these distance-inferring agents display robust, cohesive collective motion
(see Figure 2A and Supplemental Movies 1-5). Figure 2A displays examples of different
types of group phenomena exhibited in groups of active inference agents, whose diversity
and types resemble those observed in animal groups [39, 40] and in other collective motion
models [6, 7, 41]. These range from directed, coherent movement with strong inter-agent
velocity correlations (‘polarized motion’) to group rotational patterns, like milling, which
features high angular momentum around the group’s center-of-mass.
Relating individual beliefs to collective outcomes
In all but the most carefully constructed systems [26, 42], the relationship between individ-
ual and collective representations is often opaque. In particular, the relationship between
individual level uncertainty or ‘risk’ and collective behavior is an open area of research. For
instance, increased risk-sensitivity at the level of the individual may lead to to decreased
risk-encoding at the collective level [43]. Inspired by these observations, we use active in-
ference to examine the quantitative relationship between uncertainty at the individual level
and collective phenomenology. We begin by examining common metrics of group motion
like polarization and angular momentum [7]. In Figure 2B we explore how polarization and
angular momentum are affected by two components of agent-level sensory uncertainty (i.e.,
inverse sensory precision): 1) the absolute precision that agents associate to sensory noise,
encoded in the parameter Γz and; 2) the autocorrelation or ‘smoothness’ of that noise, en-
coded in the parameter λz. Intuitively, Γz encodes the variance or amplitude that the agent
11

associates with the noise in each of its L sensory sectors yl, and λz is a how ‘smooth’ the
agent believes the noise i [35, 44]. A higher value of λz implies that the agent believes sen-
sory noise are more serially-correlated (e.g., random fluctuations in optical signals caused by
smooth variations in refraction due to turbulence in water). We refer the reader to Appendix
C for details on how these two parameters Γz and λz jointly the parameterize the precision
matrix of the agent’s observation model.
Figure 2B shows how the different components (amplitude and autocorrelation) of the
agent’s sensory uncertainty determine group behavior, as quantified by average polarization
and milling probability.
Average polarization is defined here as the time average of the
polarization of the group, where the polarization at a given time p(t) measures the alignment
of velocities of agents comprising the group [7, 39]:
ˆp = 1
T
T
X
t=1
p(t)
p(t) = 1
N ∥
N
X
i=1
vi(t)∥
(10)
High average polarization indicates directed, coherent group movement. The left panel
of Figure 2B shows how Γz and λz contribute to the average polarization of the group.
An increase in either parameter causes polarization to decrease and angular momentum to
increase, reflecting the transition from directed motion to a milling regime, where the group
rotates around its center of mass. We calculate the milling probability (c.f. right panel of
Figure 2B) as the proportion of trials where the time-averaged angular momentum surpassed
0.5. The average angular momentum can be used to quantify the degree of rotational motion,
and is calculated as the time- and group-average of the individual angular momenta around
the groups’ center of mass c:
ˆm = 1
T
T
X
t=1
m(t)
m(t) = 1
N ∥
N
X
i=1
ric(t) × vi(t)∥
(11)
where ric is a relative position vector for agent i, defined as the vector pointing from the
group center c to agent i’s position: ri −c.
These collective changes can be understood in light of the magnitude of action updates,
which depend on the how the scale of first-order prediction errors ξ′
z is tuned by Γz and λz:
ξ′
z ∝Γzλ2
z
(12)
In practice, this means that as the group believes in more predictable (less rough) first-
order sensory information y′
z, the group as a whole is more likely to enter rotational, milling-
like regimes. However, the enhancing effect of these first-order prediction errors ξ′
z on rota-
tional motion is bounded; if prediction errors are over-weighted (e.g. high Γz and/or λz), the
group becomes more polarized again and likely to fragment. This fragmentation probability
occurs at both low and high levels of Γz and λz, implying that there is an optimal range
of individual-level sensory precision where cohesive group behavior (whether polarized or
12

A
B
Proportion informed
Accuracy
Average 
accuracy
log  
 
Γz−Target
log  
 
Γz−Social
Figure 3: A: Collective accuracy as a function of proportion informed or pinf for differing
values of the sensory precision assigned to social observations Γz−Social. Average accuracy
for each condition (combination of pinf, ΓzSocial, Γz−Target) was computed as the proportion of
successful hits across 500 trials. Here, the average accuracy is further averaged across all the
values of the Γz−Target parameter, meaning each accuracy here is computed as the average of
15000 total trials (500 trials per condition × 30 different values of Γz−Target). B: Collective
accuracy as a function of both the social and target precisions (Γz−Social, Γz−Target, shown
in log-scale) averaged across values of pinf ranging from pinf = 0.15 to pinf = 0.40. Each
condition’s accuracy was computed as the proportion of accurate decisions from 500 trials.
milling) is stable. Thus, our model predicts that maintaining beliefs about reliable informa-
tion is neither required, or in fact even desirable, for animals in order to facilitate collective
motion.
We have seen how one can use active inference to relate features of individual-level beliefs
(in this case, beliefs about sensory precision) to collective patterns, focusing in the present
case on common metrics for studying collective motion like polarization and the tendency
to mill.
In the following sections, we move from looking at group-level patterns that occur during
free movement, to studying the consequences of individual-level uncertainty for collective
information-processing. We begin by investigating how collective information transfer de-
pends on individual-level beliefs about the relative precisions associated with different types
of sensory information.
13

Collective information transfer
In this section, we take inspiration from the collective leadership and decision-making liter-
ature to investigate how individuals in animal groups can collectively navigate to a distant
target [45–48]. This phenomenon is an example of effective leadership through collective
information transfer and is remarkable for a number of reasons; one that speaks to its emer-
gent nature, is the fact that these collective decisions are possible despite — and indeed even
because of — the presence of uninformed individuals in the group [46]. Figure 3A shows
that active inference agents engaged in this task reproduce a result from earlier work [45] on
the relationship between the proportion of uninformed individuals and collective accuracy.
Namely, as the proportion of informed individuals increases, so does the accuracy of reaching
the majority-preferred target. In the same vein as earlier sections, we also investigated the
dependence of this effect, as well as the average target-reaching accuracy, on individual-level
beliefs.
We operationalize the notion of an agent being ‘informed’ (about an external target) by
introducing a new latent variable to its generative model; this variable xtarget represents the
distance between the informed agent’s position r and a point-mass-like target with position
vector T = [T1, T2].
We thus define this new hidden state and observation as follows:
xtarget = ∥T −r∥, ytarget = xtarget + ztarget. Just like the ‘social’ distance observations yh,
this target distance observation ytarget represents a (potentially-noisy) observation of the
true distance xtarget. As before, the agent s represent both the target distance xtarget and
its observations ytarget using generalized coordinates of motion. Each informed agent has
a dynamics model of ˜xtarget, whereby they assume the target-distance is driven by some
drift function ftarget(xtarget) = −αtxtarget which relaxes to 0. As with the social distances,
we truncate the agent’s generalized coordinates embedding of the target distance to three
orders of motion and the generalized observations to two orders of motion.
Each informed agent maintains a full posterior belief ˜µ = (˜µ1, ˜µ2, ..., ˜µL, ˜µtarget) about
the local distances ˜x1, ˜x2, ..., ˜xL as well as the target distance ˜xtarget.
Using identical reasoning to arrive at the action updates in (5) and (8), one can augment
the matrix-vector product in (8) with an extra sensorimotor contingency and prediction error
that represents target-relevant information:
dv
dt = ˜ξ
⊤
z

∆ˆR
∆T

∆T = −∇v˜ytarget =
T −r
∥T −r∥
(13)
This matrix-vector product can then be seen as a weighted combination of social and
target vectors, with the weights afforded to each equal to their respective precision-weighted
prediction errors:
14

dv
dt = ξsocial∆ˆR
|
{z
}
Social vector
+ ξtarget∆T
|
{z
}
Target vector
(14)
This expression is analogous to the velocity update in Equation (3) of Ref. [45], where
a ‘preferred direction’ vector is integrated into the agent’s action update with some pre-
determined weight. This weight is described as controlling the relative strengths of non-
social vs. social information. For active inference agents, the weighting of target-relevant
information emerges naturally as a precision-weighted prediction error (here represented as
ξtarget), and the target-vector itself is equivalent to a sensorimotor reflex arc, that represents
the agent’s assumptions about how the local flow of the target distance y′
target changes as a
function of the agent’s heading direction v. An important consequence of this construction,
is that, unlike in previous models where this weight is ‘baked-in’ as a fixed parameter, the
weight assigned to the target vector is dynamic, and fluctuates according to how much the
agent’s expectations about the target distance ˜µtarget predict the sensed target distance ytarget.
Using this new construction, we can simulate a group of active inference agents, in which
some proportion pinf of agents represent this extra set of target-related variables as described
above. To generate ˜ytarget observations for these informed individuals, we placed a spatial
target at a fixed distance away from the group’s center-of-mass and then allowed the informed
individuals to observe the generalized target distance ˜ytarget = (ytarget, y′
target).
We then
integrated the collective dynamics over time and measured the accuracy with which the group
was able to navigate to the target (see Materials and Methods for details). By performing
hundreds of these trials for different values of pinf, we reproduced the results of Ref. [45] in
Figure 3. We see that as the number of informed individuals increases, collective accuracy
increases.
However, this performance gain depends on the agents‘ beliefs about sensory
precision, which we now dissociate into two components: Γz-Social ( the precision assigned
to the social distance observations) and Γz-Target (the precision assigned to target distance
observations). By varying these two precisions independently, which respectively scale ξsocial
and ξtarget in (14), we can investigate the dependence of collective accuracy on the beliefs of
individual agents about the uncertainty attributed to different sources of information.
Figure 3A shows the average collective accuracy as a function of pinf, for different levels
of the social distance precision ΓzSocial. The pattern that emerges is that the social preci-
sion, that optimizes collective decision-making, sits within a bounded range. The general
effect of social precision is to essentially balance the amplification of target-relevant infor-
mation throughout the school, with the need for the group to maintain cohesion. When
social precision is too high, agents over-attend to social information and are not sensitive
to the information provided by informed individuals; when it is too low, the group is likely
to fragment and will not accurately share target-relevant information; meaning only the in-
formed individuals will successfully reach the target. Figure 3B shows that a similar optimal
precision-balance exists for ΓzTarget. Here, we show average collective accuracy (averaged
across values of pinf as a function of social- and target-precision.
Maximizing collective
accuracy appears to rely on agents balancing the sensory precision they assign to different
15

sources of information; under the active inference model proposed here, this balancing act
can be exactly formulated in terms of the variances (inverse precisions) afforded to different
types of sensory cues.
Online plasticity through parameter learning
The ability of groups to tune their response to changing environmental contexts, such as
rapid perturbations or informational changes, is a key feature of natural collective behavior
[43, 49]. However, many self-propelled particle models lack a generic way to incorporate this
behavioral sensitivity [45] and exhibit damped, ‘averaging’-like responses to external inputs
[50]. This results from classical models usually equipping individuals with fixed interaction
rules and constant weights for integrating different information sources. While online weight-
updating rules and evolutionary algorithms have been used to adaptively tune single-agent
parameters in some cases [45, 48, 51], these approaches are often not theoretically principled
(with some exceptions [52, 53]) and driven by specific use-cases.
Active inference offers an account of tune-able sensitivity, using the same principle used
to derive action and belief-updating in previous sections: minimizing surprise. In practice,
this sensitivity emerges when we allow agents to update their generative models in real-
time. Updating generative model parameters over time is often referred to as "learning"
in the active inference literature [54], since it invokes the notion of updating beliefs about
parameters rather than states, where parameters and states distinguish themselves by the
fast and slow timescales of updating, respectively. We leverage this idea to allow agents to
adapt their generative models and thus adapt their behavioral rules, referring to this process
as plasticity, in-line with the notion of short-term plasticity in neural circuits [55]. To enable
agents to update generative model parameters, we can simply augment the coupled gradient
descent in (9) with an additional dynamical equation, this time by minimizing free energy
with respect to model parameters, which we subsume into a set θ:
˙θ = −∇θF(˜µ, ˜y, θ)
(15)
The generative model parameters θ represent the statistical contingencies or regularities
agents believes govern their sensory world; this includes the various precisions associated
with sensory and process noises ˜Πz, ˜Πω and the parameters of the dynamics and observation
models, ˜f, ˜g. Since the free energy is a smooth function of all the generative model parame-
ters, in theory learning can be done with respect to any parameter using procedure entailed
by (15).
In practice, combining parameter-learning with active inference usually implies a separa-
tion of timescales, whereby learning or plasticity occurs concurrently to state inference and
action but at a slower update rate. In all the results shown here, agents update parameters
an order of magnitude more slowly than they update beliefs or actions. To furnish a inter-
pretable example of plasticity, in the simulations described here, we enabled agents to update
their beliefs about the sensory smoothness parameter λz. We chose sensory smoothness due
16

y2
y3
y4
y1
μ1
μ2
μ3
μ4
Stimulated
agent
Pseudo-motion 
stimulus
Stimulus-evoked 
neural activity
y1 y2 y3 y4
``
A
B
C
Stimulus time 
+1
-1
0
Figure 4: A: Schematic of the sensory perturbation protocol. The ‘pseudo-motion’ stim-
ulus consists of repetitively perturbing the agent’s sensory sectors with a moving wave of
prediction errors in the agent’s velocity-observation modality y′
h. The top panel shows stim-
ulus pattern as a heatmap over (amplitude over time) with two repetitions, starting from
negative (red, sectors 1 and 2) and transitioning to positive (blue, sectors 3 and 4) prediction
errors. The sign-switch in the stimulus (from negative to positive) mimics a moving object
that first moves towards focal individual and then moves away. The temporal order of the
stimulus across the sectors can be used to selectively emulate a right-moving vs. left-moving
object, relative to the focal individual’s heading-direction. The bottom panel shows how the
stimulated agent’s beliefs about the distance hidden state µ changes over the course of the
motion stimulus. B: Response magnitude to a perturbation in presence or absence of pa-
rameter learning. Left panel: example pair of 2-D trajectories of active inference agents with
matched pre-perturbation histories, in response to an individual perturbation. The ability to
perform parameter-learning is left on in one stochastic realization (green) and turned off in
the other (blue), following the perturbation. Right panel: initialization-averaged collective
responses (group turning angle) to perturbation of active inference agents when learning is
enabled or disabled. The perturbation response of a 2-zone self-propelled particle model
(purple line) based on [45] is also shown for reference. C: Collective response as a function
of the number of perturbed individuals, comparing simulations where parameter-learning
is enabled to those where it’s disabled. Shown is the mean response with highest density
regions (HDRs) of integrated turning magnitude (left) and response probability (right) com-
puted from Ni = 200 independent initializations of each condition. For each initialization,
the average metric is computed across Nr = 50 independent realizations that were run for-
ward from the same point in time, following a sensory prediction error perturbation (to a
randomly-chosen set of perturbed agents). Response probability is computed as the propor-
tion of independent realizations, per initialization, where the group turning rate exceeded π
radians within the first 10 seconds of the perturbation.
17

to its straightforward relationship to the magnitude of sensory prediction errors (c.f. the
relation in (12) and Appendix C). As agents tune λz to minimize free energy, belief updating
and action will at the same time become quadratically more or less responsive to sensory
information.
One example of where behavioral plasticity is crucial for collective information processing
is a group’s ability to rapidly amplify behaviorally-relevant information, e.g., detecting the
presence of a predator [43, 56, 57]. To study the effect of behavioral plasticity on collec-
tive responsiveness, we perturbed single agents in groups of active inference agents while
enabling or disabling online plasticity. We perturbed groups by inducing transient ‘phan-
tom’ prediction errors in random subsets of agents and measuring the resulting turning
response of the group (see Materials and Methods for details). These prediction errors were
structured (see Figure 4A) to mimic a transient visual stimulus, e.g., a loom stimulus or
approaching predator [58], which reliably induces a sustained turning response in the chosen
individual [50]. Figure 4 shows the effect of enabling plasticity on the size and sensitivity of
collective responses to these perturbations. Not only do plasticity-enabled groups respond
more strongly to perturbations of single-agents, compared to their plasticity-disabled coun-
terparts (4B), but the magnitude of the collective response is also more sensitive to the size
of the perturbation (4C). As has been measured in biological collectives [59], the plasticity-
enabled groups collectively encode the size of perturbations with higher dynamic range than
plasticity-disabled controls. This can be interpreted as an enhanced ability to collectively
discriminate between inputs of different magnitude
By updating generative models over time, the active inference framework provides a
flexible and theoretically-principled approach to modeling adaptive, collective behavior with
tuneable sensitivity, that eschews ad-hoc update rules or expensive simulations driven by
evolutionary algorithms. Recall that the plasticity mechanism proposed here is not limited
to updating beliefs about sensory smoothness: it can be extended to update beliefs about
any model parameter in a similar manner. The ability to adapt generative model parameters,
and hence individual-level behavioral rules, in real-time represents a promising avenue for
future research in active inference and collective behavior, and may lead to more biologically-
plausible hypotheses about the mechanisms underlying collective behavior in the natural
world.
Discussion
In this work, we proposed active inference as a flexible, cognitively-inspired model class that
can both be used in the theoretical study of collective motion, and in an empirical setting as
an individual-level model of collective animal behaviors. By framing behavior as the conse-
quence of prediction-error minimization — with respect to an individual’s world model — we
offer examples of how naturalistic collective motion emerges in, where individual behavior is
driven by the imperative to minimize the surprisal associated with sensory signals. Under
mild distributional assumptions, this surprise is scored by an interpretable proxy; namely,
prediction error. In the particular case of collective motion, we equipped a group of active in-
18

ference agents with a simple generative model of local social information, operationalized as
the average distance-to-neighbors and its rates-of-change. Using this individual-level model,
we recovered and generalized the social forces that have been the core mechanism in classical
SPP models of collective motion. The active inference framework also provides a probabilis-
tic interpretation of ad-hoc ‘weight’ parameters that are often used in these models, in terms
of the precisions that agents associate to different types of sensory information.
We have also shown how the active inference framework can be used to characterize
the relationship between generative model parameters and emergent information-processing
capacities, as measured by collective information transfer and responsiveness to external
perturbations. Active inference’s generality allows us to relax the typically-static behavioral
rules of SPP models, by enabling agents to flexibly tune their sensitivity to prediction errors.
This is achieved via principled processes like parameter learning (i.e., ‘plasticity’), and can
be used to model naturalistic features of collective behavior, such as the tendency to amplify
salient (i.e., precise) information, that have largely evaded modelling in the SPP paradigm,
except in cases where adaptation rules are explicitly introduced [45, 48]. However, when
we simply allow agents to update parameters, in addition to beliefs and agents, using the
principle of surprise-minimization, many hallmarks of these naturalistic behaviors can be
easily obtained.
By providing a flexible modeling approach that casts perception, action, and learning as
manifestations of the single drive to minimize surprise, we have highlighted active inference as
a novel toolbox for studying collective behavior in natural systems. Future work in this area
could explore how the framework can be used to investigate other forms of collective behavior
(not just collective motion), like multi-choice decision-making and social communication [60].
The results shown in the current work serve primarily as a proof of concept: we started
by writing down a specific, hypothetical active inference model of agents engaged in group
movement, and then generated naturalistic behaviors by integrating the resulting equations of
motion for this particular model. Taking inspiration from fields like computational psychiatry
[61, 62], we emphasize the ability to move from simple forward modelling of behavior to
data-driven model inversion, whereby one hopes to infers the values of parameters that
best explain empirical data (of e.g. behavioral movement data). Both the selection of model
structure and the fitting of model parameters can be performed through methods of Bayesian
model inversion and system identification methods like Bayesian model selection, averaging
or reduction.
Materials and Methods
For all simulations, we randomly initialized the positions and (unit-magnitude) velocities of
N particles, and integrated the equations of motion for active inference and generalized fil-
tering using a forwards Euler-Maruyama scheme with an integration window of ∆t = 0.01s.
Group size N the length of the simulation T (in seconds) varied based on the experiment.
At any timestep τ of a simulation, we integrate the active inference equations for percep-
tion (filtering) and control (action) for one timestep each before using the updated ve-
19

locity to displacement the positions of all particles using the following discrete equation:
r(τ +∆t) = r(τ)+∆tv(τ)+za where za is normally-distributed ‘action noise’ with statistics
za ∼N(za; 0, σ2
a∆t), where σ2
a = 0.01 unless stated otherwise. Detailed background on gen-
eralized filtering, active inference, and derivations specific to the generative model we used
for collective motion can be found in Appendix A. All other parameters used for simulations,
unless stated otherwise, are listed in Table E.1 of Appendix E. The code (written in JAX
and Julia) used to perform simulations can be found in the following open-source repository:
https://github.com/conorheins/collective_motion_actinf.
Collective information transfer experiments
For each trial of collective target-navigation, we initialized a group of N = 30 agents with
random positions and velocities (centered on the origin) and augmented the generative mod-
els of a fixed proportion pinf of the total number of agents, where pinf ranged from 0.05
to 1.0, with an extra sensory modality and hidden state that represents the distance to the
target with position vector T, where distance of the target was always 10 units from the
origin. We measured collective accuracy as follows: we count a given trial as successful if the
group is able to navigate to within 0.25 units of the target without losing cohesion within
T = 15 seconds (the length of each trial). The accuracy for a given experimental condition
was then computed as the proportion of successes observed in 500 total trials.
Perturbation experiments
For the perturbation experiments, we simulated Ni = 200 independent runs of N = 50
agents, which we term independent initializations. Each initialization is distinguished by
the agents‘ random starting positions, velocities, and seeds used to sample trajectories of
action and observation noise. For each initialization, we integrated the collective dynamics
until a steady state dynamic was reached (the pre-perturbation period) We chose this to be
T = 100 seconds, a point at which metrics like average polarization, angular momentum, and
median nearest-neighbor distance were highly likely to have stopped changing and fluctuate
around a stationary value. At the end of each initialization’s pre-perturbation period, we
then split each initialization into two further sets of Nr = 50 parallel runs, each of which we
deem a realization. Each realization is distinguished from the others based on the random
seed used to A) generate the noises on the actions and noises for that realization; and B)
select the candidate agent(s) for perturbation. Note that the splitting of seeds at the end of
the pre-perturbation period means that each realization has an identical history up for its
first 100 seconds. In the first set of Nr = 50 realizations, we enabled plasticity (parameter
learning of λz), and in the second set, we left it disabled. After enabling learning in one set of
realizations, we included an additional ‘burn-in’ period of 12 seconds of continued dynamics,
to account for any transient group effects introduced by enabling learning per se. After
the burn-in period ended, we perturbed random subsets of agents in both learning-enabled
and -disabled realizations (2% - 50% of the group, i.e., 1 to 25 agents). We added to the
ongoing zeroth-order prediction errors ξ′
z of the perturbed individuals, two sequential waves
20

of negative (−1) to positive values (+1), each lasting 0.8s and moving from left to right,
relative to the perturbed agent’s heading vector. We tracked the group turning angle, relative
to its initial heading direction at the beginning of the perturbation for 20s to generate the
plots in Figure 4B and C.
Acknowledgements:
The authors would like to thank Brennan Klein, Jake Graving, and
Armin Bahl for helpful comments and discussion during the writing of this manuscript.
CH would like to thank Dimitrije Markovic, Thomas Parr, and Manuel Baltieri for helpful
discussions related to generalized filtering and continuous-time and -space active inference,
and Maya Polovitskaya for creating the fish schematic used in the figures. CH and IDC
acknowledge support from the Office of Naval Research Grant N0001419-1-2556, Germany’s
Excellence Strategy-EXC 2117-422037984 (to IDC) and the Max Planck Society, as well as
the European Union’s Horizon 2020 research and innovation programme under the Marie
Skłodowska-Curie Grant agreement (to IDC; #860949). CH acknowledges the support of
a grant from the John Templeton Foundation (61780). LD is supported by the Fonds Na-
tional de la Recherche, Luxembourg (Project code: 13568875). This publication is based
on work partially supported by the EPSRC Centre for Doctoral Training in Mathematics of
Random Systems: Analysis, Modelling and Simulation (EP/S023925/1). RPM is supported
by UK Research and Innovation Future Leaders Fellowship MR/S032525/1 and the Tem-
pleton World Charity Foundation Inc. TWCF-2021-20647. KF is supported by funding for
the Wellcome Centre for Human Neuroimaging (Ref: 205103/Z/16/Z), a Canada-UK Arti-
ficial Intelligence Initiative (Ref: ES/T01279X/1) and the European Union’s Horizon 2020
Framework Programme for Research and Innovation under the Specific Grant Agreement
No. 945539 (Human Brain Project SGA3).
References
[1]
Peter F Major and Lawrence M Dill. “The three-dimensional structure of airborne bird
flocks”. In: Behavioral Ecology and Sociobiology 4.2 (1978), pp. 111–122.
[2]
Scott Camazine, Jean-Louis Deneubourg, Nigel R Franks, James Sneyd, Eric
Bonabeau, and Guy Theraulaz. Self-organization in biological systems. Princeton uni-
versity press, 2003.
[3]
Michael Rubenstein, Christian Ahler, and Radhika Nagpal. “Kilobot: A low cost scal-
able robot system for collective behaviors”. In: 2012 IEEE International Conference
on Robotics and Automation. IEEE. 2012, pp. 3293–3298.
[4]
Ichiro AOKI. “A Simulation Study on the Schooling Mechanism in Fish”. In: NIPPON
SUISAN GAKKAISHI 48.8 (1982), pp. 1081–1088. doi: 10.2331/suisan.48.1081.
[5]
Craig W Reynolds. “Flocks, herds and schools: A distributed behavioral model”. In:
Proceedings of the 14th annual conference on Computer graphics and interactive tech-
niques. 1987, pp. 25–34.
21

[6]
Tamás Vicsek, András Czirók, Eshel Ben-Jacob, Inon Cohen, and Ofer Shochet. “Novel
type of phase transition in a system of self-driven particles”. In: Physical review letters
75.6 (1995), p. 1226.
[7]
Iain D Couzin, Jens Krause, Richard James, Graeme D Ruxton, and Nigel R Franks.
“Collective memory and spatial sorting in animal groups”. In: Journal of theoretical
biology 218.1 (2002), pp. 1–12.
[8]
David JT Sumpter. “The principles of collective animal behaviour”. In: Philosophical
transactions of the royal society B: Biological Sciences 361.1465 (2006), pp. 5–22.
[9]
John Toner and Yuhai Tu. “Flocks, herds, and schools: A quantitative theory of flock-
ing”. In: Physical review E 58.4 (1998), p. 4828.
[10]
Eric Bertin, Michel Droz, and Guillaume Grégoire. “Boltzmann and hydrodynamic
description for self-propelled particles”. In: Physical Review E 74.2 (2006), p. 022101.
[11]
Pierre Degond and Sébastien Motsch. “Continuum limit of self-driven particles with
orientation interaction”. In: Mathematical Models and Methods in Applied Sciences
18.supp01 (2008), pp. 1193–1215.
[12]
James E Herbert-Read, Andrea Perna, Richard P Mann, Timothy M Schaerf, David
JT Sumpter, and Ashley JW Ward. “Inferring the rules of interaction of shoaling fish”.
In: Proceedings of the National Academy of Sciences 108.46 (2011), pp. 18726–18731.
[13]
Daniel S Calovi, Ugo Lopez, Sandrine Ngo, Clément Sire, Hugues Chaté, and Guy
Theraulaz. “Swarming, schooling, milling: phase diagram of a data-driven fish school
model”. In: New journal of Physics 16.1 (2014), p. 015026.
[14]
Andrew M Hein, Michael A Gil, Colin R Twomey, Iain D Couzin, and Simon A Levin.
“Conserved behavioral circuits govern high-speed decision-making in wild fish shoals”.
In: Proceedings of the National Academy of Sciences 115.48 (2018), pp. 12224–12228.
[15]
Jacques Gautrais, Francesco Ginelli, Richard Fournier, Stéphane Blanco, Marc So-
ria, Hugues Chaté, and Guy Theraulaz. “Deciphering interactions in moving animal
groups”. In: PLoS computational biology 8.9 (2012), e1002678.
[16]
Yael Katz, Kolbjørn Tunstrøm, Christos C Ioannou, Cristián Huepe, and Iain D
Couzin. “Inferring the structure and dynamics of interactions in schooling fish”. In:
Proceedings of the National Academy of Sciences 108.46 (2011), pp. 18720–18725.
[17]
Karl J Friston, Jean Daunizeau, and Stefan J Kiebel. “Reinforcement learning or active
inference?” In: PloS one 4.7 (2009), e6421.
[18]
Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and Gio-
vanni Pezzulo. “Active inference: a process theory”. In: Neural computation 29.1 (2017),
pp. 1–49.
[19]
Thomas Parr, Giovanni Pezzulo, and Karl J Friston. Active inference: the free energy
principle in mind, brain, and behavior. MIT Press, 2022.
22

[20]
Karl Friston. “A theory of cortical responses”. In: Philosophical transactions of the
Royal Society B: Biological sciences 360.1456 (2005), pp. 815–836.
[21]
Karl Friston, James Kilner, and Lee Harrison. “A free energy principle for the brain”.
In: Journal of Physiology-Paris 100.1-3 (2006), pp. 70–87.
[22]
Karl Friston. “What is optimal about motor control?” In: Neuron 72.3 (2011), pp. 488–
498.
[23]
Rajesh PN Rao and Dana H Ballard. “Predictive coding in the visual cortex: a func-
tional interpretation of some extra-classical receptive-field effects”. In: Nature neuro-
science 2.1 (1999), pp. 79–87.
[24]
Rick A Adams, Stewart Shipp, and Karl J Friston. “Predictions not commands: active
inference in the motor system”. In: Brain Structure and Function 218.3 (2013), pp. 611–
643.
[25]
Kevin N Laland. “Social learning strategies”. In: Animal Learning & Behavior 32.1
(2004), pp. 4–14.
[26]
Peter M Krafft, Erez Shmueli, Thomas L Griffiths, Joshua B Tenenbaum, et al.
“Bayesian collective learning emerges from heuristic social learning”. In: Cognition 212
(2021), p. 104469.
[27]
Manuel Baltieri and Christopher L Buckley. “Generative models as parsimonious de-
scriptions of sensorimotor loops”. In: arXiv preprint arXiv:1904.12937 (2019).
[28]
Cem Uran, Alina Peter, Andreea Lazar, William Barnes, Johanna Klon-Lipok,
Katharine A. Shapcott, Rasmus Roese, Pascal Fries, Wolf Singer, and Martin Vinck.
“Predictive coding of natural images by V1 firing rates and rhythmic synchronization”.
In: Neuron 110.7 (2022), 1240–1257.e8. issn: 0896-6273. doi: https://doi.org/10.
1016/j.neuron.2022.01.002. url: https://www.sciencedirect.com/science/
article/pii/S0896627322000022.
[29]
Karl Friston. “The free-energy principle: a rough guide to the brain?” In: Trends in
cognitive sciences 13.7 (2009), pp. 293–301.
[30]
Jakob Hohwy. “The self-evidencing brain”. In: Noûs 50.2 (2016), pp. 259–285.
[31]
Karl Friston. “A free energy principle for a particular physics”. In: arXiv preprint
arXiv:1906.10184 (2019).
[32]
Bertrand Collignon, Axel Séguret, and José Halloy. “A stochastic vision-based model
inspired by zebrafish collective behaviour in heterogeneous environments”. In: Royal
Society open science 3.1 (2016), p. 150473.
[33]
Renaud Bastien and Pawel Romanczuk. “A model of collective behavior based purely
on vision”. In: Science advances 6.6 (2020), eaay0792.
[34]
Karl Friston, Klaas Stephan, Baojuan Li, and Jean Daunizeau. “Generalised filtering”.
In: Mathematical Problems in Engineering 2010 (2010).
23

[35]
Karl Friston, Jérémie Mattout, Nelson Trujillo-Barreto, John Ashburner, and Will
Penny. “Variational free energy and the Laplace approximation”. In: Neuroimage 34.1
(2007), pp. 220–234.
[36]
Karl Friston and Stefan Kiebel. “Predictive coding under the free-energy principle”. In:
Philosophical Transactions of the Royal Society B: Biological Sciences 364.1521 (2009),
pp. 1211–1221.
[37]
Manuel Baltieri and Christopher L Buckley. “PID control as a process of active infer-
ence with linear generative models”. In: Entropy 21.3 (2019), p. 257.
[38]
Christopher L Buckley, Chang Sub Kim, Simon McGregor, and Anil K Seth. “The
free energy principle for action and perception: A mathematical review”. In: Journal
of Mathematical Psychology 81 (2017), pp. 55–79.
[39]
Jerome Buhl, David JT Sumpter, Iain D Couzin, Joe J Hale, Emma Despland, Edgar R
Miller, and Steve J Simpson. “From disorder to order in marching locusts”. In: Science
312.5778 (2006), pp. 1402–1406.
[40]
Kolbjørn Tunstrøm, Yael Katz, Christos C Ioannou, Cristián Huepe, Matthew J Lutz,
and Iain D Couzin. “Collective states, multistability and transitional behavior in school-
ing fish”. In: PLoS computational biology 9.2 (2013), e1002915.
[41]
Irene Giardina. “Collective behavior in animal groups: theoretical models and empirical
studies”. In: HFSP journal 2.4 (2008), pp. 205–219.
[42]
Conor Heins, Brennan Klein, Daphne Demekas, Miguel Aguilera, and Christopher L
Buckley. “Spin glass systems as collective active inference”. In: Active Inference: Third
International Workshop, IWAI 2022, Grenoble, France, September 19, 2022, Revised
Selected Papers. Springer. 2023, pp. 75–98.
[43]
Matthew MG Sosna, Colin R Twomey, Joseph Bak-Coleman, Winnie Poel, Bryan C
Daniels, Pawel Romanczuk, and Iain D Couzin. “Individual and collective encoding
of risk in animal groups”. In: Proceedings of the National Academy of Sciences 116.41
(2019), pp. 20556–20561.
[44]
Thomas Parr, Jakub Limanowski, Vishal Rawji, and Karl Friston. “The computational
neurology of movement under active inference”. In: Brain (2021).
[45]
Iain D Couzin, Jens Krause, Nigel R Franks, and Simon A Levin. “Effective leader-
ship and decision-making in animal groups on the move”. In: Nature 433.7025 (2005),
pp. 513–516.
[46]
Iain D Couzin, Christos C Ioannou, Güven Demirel, Thilo Gross, Colin J Torney, An-
drew Hartnett, Larissa Conradt, Simon A Levin, and Naomi E Leonard. “Uninformed
individuals promote democratic consensus in animal groups”. In: science 334.6062
(2011), pp. 1578–1580.
[47]
Ariana Strandburg-Peshkin, Damien R Farine, Iain D Couzin, and Margaret C Cro-
foot. “Shared decision-making drives collective movement in wild baboons”. In: Science
348.6241 (2015), pp. 1358–1361.
24

[48]
Vivek H Sridhar, Liang Li, Dan Gorbonos, Máté Nagy, Bianca R Schell, Timothy
Sorochkin, Nir S Gov, and Iain D Couzin. “The geometry of decision-making in indi-
viduals and collectives”. In: Proceedings of the National Academy of Sciences 118.50
(2021).
[49]
Ashkaan K Fahimipour, Michael A Gil, Maria Rosa Celis, Gabriel F Hein, Benjamin T
Martin, and Andrew M Hein. “Wild animals suppress the spread of socially transmitted
misinformation”. In: Proceedings of the National Academy of Sciences 120.14 (2023),
e2215428120.
[50]
Allison Kolpas, Michael Busch, Hong Li, Iain D Couzin, Linda Petzold, and Jeff
Moehlis. “How the spatial position of individuals affects their influence on swarms:
a numerical comparison of two popular swarm dynamics models”. In: PloS one 8.3
(2013), e58525.
[51]
Andrew M Hein, Sara Brin Rosenthal, George I Hagstrom, Andrew Berdahl, Colin
J Torney, and Iain D Couzin. “The evolution of distributed sensing and collective
computation in animal populations”. In: Elife 4 (2015), e10955.
[52]
Heiko Hamann. “Evolution of collective behaviors by minimizing surprise”. In: Artificial
Life Conference Proceedings. MIT Press One Rogers Street, Cambridge, MA 02142-
1209, USA journals-info . . . 2014, pp. 344–351.
[53]
Tanja Katharina Kaiser and Heiko Hamann. “Innate Motivation for Robot Swarms by
Minimizing Surprise: From Simple Simulations to Real-World Experiments”. In: IEEE
Transactions on Robotics 38.6 (2022), pp. 3582–3601.
[54]
Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, Giovanni
Pezzulo, et al. “Active inference and learning”. In: Neuroscience & Biobehavioral Re-
views 68 (2016), pp. 862–879.
[55]
Matthias H Hennig. “Theoretical models of synaptic short term plasticity”. In: Frontiers
in computational neuroscience 7 (2013), p. 45.
[56]
Ariana Strandburg-Peshkin, Colin R Twomey, Nikolai WF Bode, Albert B Kao, Yael
Katz, Christos C Ioannou, Sara B Rosenthal, Colin J Torney, Hai Shan Wu, Simon
A Levin, et al. “Visual sensory networks and effective information transfer in animal
groups”. In: Current Biology 23.17 (2013), R709–R711.
[57]
Jacob D Davidson, Matthew MG Sosna, Colin R Twomey, Vivek H Sridhar, Simon
P Leblanc, and Iain D Couzin. “Collective detection based on visual information in
animal groups”. In: Journal of the Royal Society Interface 18.180 (2021), p. 20210142.
[58]
Roy Harpaz, Minh Nguyet Nguyen, Armin Bahl, and Florian Engert. “Precise visuo-
motor transformations underlying collective behavior in larval zebrafish”. In: Nature
communications 12.1 (2021), p. 6578.
25

[59]
Luis Gómez-Nava, Robert T Lange, Pascal P Klamser, Juliane Lukas, Lenin Arias-
Rodriguez, David Bierbach, Jens Krause, Henning Sprekeler, and Pawel Romanczuk.
“Fish shoals resemble a stochastic excitable system driven by environmental perturba-
tions”. In: Nature Physics (2023), pp. 1–7.
[60]
Mahault Albarracin, Daphne Demekas, Maxwell JD Ramstead, and Conor Heins.
“Epistemic communities under active inference”. In: Entropy 24.4 (2022), p. 476.
[61]
P Read Montague, Raymond J Dolan, Karl J Friston, and Peter Dayan. “Computa-
tional psychiatry”. In: Trends in cognitive sciences 16.1 (2012), pp. 72–80.
[62]
Ryan Smith, Paul Badcock, and Karl J Friston. “Recent advances in the application of
predictive coding and active inference models within clinical neuroscience”. In: Psychi-
atry and Clinical Neurosciences (2020). url: https://onlinelibrary.wiley.com/
doi/abs/10.1111/pcn.13138.
26

A
An active inference model of collective motion
Each agent within our model of collective motion maintains an internal model of its local envi-
ronment represented by average distances to its neighbours. These distances are partitioned
into L sensory sectors x = x1, x2, ..., xL, with each agent observing noisy versions of these
distances through a corresponding sensory channel y = y1, y2, ..., yL. Each agent estimates
the hidden distance variable(s) x over time using its observed sensory states y. In practice,
each agent implements this through a form of variational Bayesian inference developed for
continuous data-assimilation in dynamic environments called generalized filtering, which can
be seen as a variational, more flexible version of Kalman filters. This dynamic inference
process entails updating posterior beliefs about x using a gradient descent on variational
free energy. In the case of Gaussian assumptions about observation and state noise, these
free energy gradients resemble a precision-weighted average of sensory and state prediction
errors. This comprises the state-estimation component of active inference and is unpacked
in detail in Section A.1.
In addition to estimating the hidden distance variable with generalized filtering, each
agent also changes its heading direction v in order to minimize the same variational free
energy functional. When the agent’s model of the distance dynamics is strongly ‘biased’
by a prior belief that the steady-state value of the distance variable(s) ˜x hovers around a
particular value η, then agents will change their heading in a way that appears like they
‘want’ to maintain this target distance between them and their neighbours. Concretely, this
means they move closer to neighbors when the sensed distance y is larger than expected,
and move away from neighbors when y is smaller than expected.
This symmetry between belief updating and action, as both following the gradients of
the same loss function, is what theoretically distinguishes active inference from other con-
tinuous control schemes, which often use different objectives for estimation and control. In
the following sections we detail the processes of state-estimation and action under active
inference.
A.1
Generalized filtering overview
Agents estimate hidden states x as the variational solution to a Bayesian inference problem;
they achieve this in practice using an online-filtering algorithm known as generalized filtering
[1, 2]. Generalized filtering is a generic Bayesian filtering scheme for non-linear state-space
models formulated in generalized coordinates of motion [3]. It subsumes, as special cases,
variational filtering [4], dynamic expectation maximization [5] and generalized predictive
coding. This inversion scheme relies on a simple dynamical generative specification of hidden
states x and how they relate to observations y. The generative model starts by postulating
that the time evolution of a variable x is given by a stochastic differential equation with the
following form:
dxt
dt = f(xt) + ωt
(A.1)
27

where f is some deterministic flow function (i.e., a vector field) that depends on the
current state xt, and ωt is a (smooth) additive Gaussian noise process. Under generalized
filtering, we successively differentiate (A.1), to finesse the difficult computation of the paths
or trajectories of xt locally in time, by instead focusing on the much easier problem of
computing the serial derivatives of xt.
This allows one to express a local trajectory of
⃗x = {xt, xt+1, . . . , xt+T} in terms of the derivatives of xt, i.e., ˜xt = (x′
t, x′′
t , x′′′
t , . . . , x[n]
t , . . .),
where x[n]
t
:=
dn
dtnxt.
We used the notation ˜xt to denote a vector of these higher orders
of motion at time t, a representation known as generalized coordinates. The equivalence
between generalized coordinates and paths follows from Taylor’s theorem, where the path of
x around some time t can be expressed as a combination of its higher order derivatives:
xt+h = x[0]
t +
∞
X
n=1
x[n]
n! hn
(A.2)
Note that the (local in time) equality between a path ⃗x and its Taylor series only holds
when the sample paths of xt are analytic functions, which itself requires f to be analytic
and the noise process ωt to be analytic (in particular non-white noise fluctuations) [6].
Successively differentiating the base equation in (A.1) (and ignoring contributions of the
flow of order higher than one) yields a series of stochastic differential equations that describe
the evolution of each order of motion x[n]
t
as depending on its own state and the nth derivative
of the noise [3]:
˙x = f(x) + ω
˙x′ = fxx′ + ω′
˙x′′ = fxx′′ + ω′′
...
⇒D˜x = ˜f + ˜ω
where, following the notation used in [1–3], we use the notation fx for the Jacobian
(i.e., matrix of first order partial derivatives) of the flow function f evaluated at x, i.e.,
Jf(x), and omit the time variable from our notation for conciseness. Note that the above
construction assumes a local linearization of f around x, thus ignoring the contribution of
higher order terms to the flow. When f is itself a linear function, this approximation is exact
because contributions of the higher orders vanish [3]. The D is the time derivative operator
in generalised coordinates, with identity matrices along the first leading (block) diagonal and
˜f, ˜ω are the generalized flow function and generalized noises, respectively:
D =


0
I
...
...
...
I
0


˜f =


f(x[0])
fxx[1]
...
fxx[n]


˜ω =


ω[0]
ω[1]
...
ω[n]


28

Here, n is some chosen order at which to truncate the derivatives. This truncation means
that the Taylor expansion of a path ⃗x in (A.2) is rendered an approximation. Having specified
a dynamics over x (and its reformulation in generalized coordinates), we are in a position
to specify the observation model.
In generalized filtering, the generative model of state
dynamics is supplemented with an observation model that maps hidden states x to their
sensory consequences y via some (differentiable) sensory map g(x) and additive Gaussian
smooth fluctuations z:
yt = g(xt) + zt
(A.3)
Like the states, we can similarly express observations in generalized coordinates by succes-
sively differentiating (A.3) to obtain a similar single expression for the generalized observation
equation:
y = g(x) + z
y′ = gxx′ + z′
y′′ = gxx′′ + z′′
...
⇒˜y = ˜g + ˜z
where here the ith motion of observations y[i] is not a function of itself but rather that of
the motion of the (generalized) hidden states x[i] and fluctuations z[i]. In other words, the
motion of observations tracks the simultaneous motion of the states, subject to any nonlin-
earities in the sensory map g and the motion of the noise z. Given Gaussian assumptions on
the generalised noises ˜ω and ˜z, we can then write down the full hidden state and observation
model p(˜y, ˜x) as a joint Gaussian density:
D˜x = ˜f + ˜ω
˜ω ∼N(˜ω; 0, ˜Σω)
˜y = ˜g + ˜z
˜z ∼N(˜z; 0, ˜Σz)
=⇒p(˜y, ˜x) = p(˜y|˜x)p(D˜x|˜x)
= N(˜y; ˜g, ˜Σz)N(D˜x; ˜f, ˜Σω)
(A.4)
This joint Gaussian specification of the generative model enables derivation of efficient,
online update rules for the sufficient statistics of approximate posterior beliefs that track the
expected value of the generalised hidden state ˜x. This relies on a simple expression for the
variational free energy of this Gaussian state-space model; as we will see in the following
sections, this not only enables efficient state estimation (a.k.a, updating beliefs about hidden
states ˜x), but also algorithms for inferring generative model parameters.
29

A.2
State estimation under generalized filtering
Generalized filtering relies on optimizing posterior beliefs in order to minimize variational
free energy F, an upper bound on the surprise associated with observations y under some
generative model m:
F ≥−ln p(y; m)
|
{z
}
surprise
(A.5)
where the model m defines a joint distribution over observations and latent variables
p(y, ϑ). The latent variables themselves ϑ are often split into hidden states x and parameters
θ. Exact Bayesian inference entails obtaining the posterior distribution over latent variables
p(ϑ|y), which can be expressed using Bayes rule:
p(ϑ|y) = p(y, ϑ)
p(y)
(A.6)
p(y) ≜
Z
p(y, ϑ)dϑ
(A.7)
where hereafter we leave out the dependence on the model m.
In order to compute the posterior exactly, one has to compute the marginal probability of
observations p(y), also known as the marginal likelihood or model evidence. Computing the
marginal likelihood is often intractable or difficult in practice, motivating the introduction
of the variational bound, the free energy F, also known as the (negative) evidence lower-
bound or ELBO. This can be shown by writing F as the Kullback-Leibler divergence between
some "variational" distribution q(ϑ; ν) over latent variables with parameters ν and the true
posterior p(ϑ|y):
F = Eq [ln q(ϑ) −ln p(y, ϑ)]
= DKL (q(ϑ; ν)||p(ϑ|y)) −ln p(y)
|
{z
}
surprise
(A.8)
=⇒F ≥−ln p(y)
(A.9)
The upper bound holds because the Kullback-Leibler divergence is always non-negative
DKL(p||q) ≥0. Intuitively, as the variational distribution q(ϑ; ν) better approximates the
true posterior distribution p(ϑ|y), where the (in)accuracy of the approximation is measured
by the KL divergence, then the tighter the free energy bounds the surprise. This decom-
position also makes clear why minimizing F with respect to variational parameters ν is a
way to update the variational distribution q to approximate the true posterior p(ϑ|y). The
variational distribution is thus often referred to as an approximate posterior, where the ex-
act posterior obtained by applying Bayesian rule as in Equation (A.6) corresponds to the
variational posterior that minimises F.
30

Now we turn to deriving the Laplace-approximation to the variational free energy (VFE)
for the Gaussian state-space models used in generalised filtering. The Laplace approxima-
tion is an analytically tractable way to approximate the true posterior with a Gaussian
distribution, which simplifies inference to an online filtering algorithm that corresponds to
minimizing a sum of squared prediction errors.
Recall that our goal is to perform inference on the latent variables ϑ by optimizing an
approximate posterior distribution q(ϑ; ν). In our case, we let ϑ = {x, θ} where x are hidden
states and θ encompass other generative model parameters (e.g., hyperparameters of the
generative model like ˜f, ˜g, ˜Σz, ˜Σω). For now we focus on inference over hidden states x and
treat parameter inference later. The approximate posterior distribution q(x; ν). Under the
Laplace approximation we use a Gaussian distribution for the approximate posterior:
q(x; ν) = N(x; µ, Σν
| {z }
ν
)
(A.10)
where the variational parameters ν are comprised of the sufficient statistics of a Gaussian
distribution: the mean µ and covariance Σν. We add the subscript ν to the variational
variance to distinguish it from generative model covariances, e.g. ˜Σz, ˜Σω.
We can now arrive at a more specific expression for the variational free energy using the
Gaussian form of the variational distribution. We start by decomposing the free energy into
the sum of an expected energy term and a (negative) entropy, where the energy is defined
as the negative log joint density over states and observations: −ln p(x, y) and the negative
entropy is that of the variational posterior i.e., Eq[ln q(x; ν)]:
F = Eq [−ln p(x, y)] −1
2 [ln |Σ| + d ln 2π]
(A.11)
where d is the dimensionality of x and the full term on the right follows from the entropy
of a multivariate Gaussian: H[N(x; µ, Σ)] = 1
2 [ln |Σ| + d ln 2π].
Additional assumptions allow one to further simplify the expected energy term Eq [−ln p(x, y)];
namely, if we assume that the posterior is tightly peaked around the mean µ and that p(x, y)
is twice-differentiable in x, we can motivate a 2nd-order Taylor expansion of the expected
energy term around its mode, i.e. when x = µ:
Eq [−ln p(x, y)] ≈Eq
"
−ln p(µ, y) −∇x ln p(x, y)

x=µ
(x −µ) −1
2(x −µ)⊤∇2
x ln p(x, y)

x=µ
(x −µ)
#
= −ln p(µ, y) −1
2 tr
 
Σ∇2
x ln p(x, y)

x=µ
!
(A.12)
Combining this approximation of the expected energy with the remaining terms in the
variational free energy, we can now write the full expression of the Laplace-approximated
free energy FL:
31

FL = −ln p(µ, y) −1
2 tr
 
Σ∇2
x ln p(x, y)

x=µ
!
−1
2 (ln |Σ| + d ln 2π)
(A.13)
A useful feature of this expression is that the optimal variational covariance Σν can
obtained by setting the derivative of FL with respect to the covariance Σ equal to 0 and
solving for Σ, i.e. finding the values of the covariance that minimize the FL:
∂FL
∂Σ = 0 ⇐⇒Σν = −
 
∇2
x ln p(x, y)

x=µ
!−1
(A.14)
i.e., the optimal variance of the variational distribution is the curvature of the Laplace
energy around its mode. Substituting this expression back into the full free energy, we can
then write an expression that only depends on the mean vector µ of the variational density,
since the variatonal variance Σν is now expressed as a function of the mean:
FL = −ln p(µ, y) + 1
2 tr
 Σν(Σν)−1
|
{z
}
=d
−1
2 (ln |Σν| + d ln 2π)
= −ln p(µ, y) −1
2 (ln |Σν| + d ln 2π)
(A.15)
This means that the Laplace approximation to the variational free energy is a function of
only the variational mean µ and sensory observations y, because the variational variance Σν is
itself a function of µ. Belief updating then consists in minimizing the Laplace-approximated
free energy FL with respect to µ:
˙µ ∝−∇µFL(µ, y)
(A.16)
When the generative model p(x, y) is Gaussian, then the Laplace-approximated varia-
tional free energy is quadratic in µ and y, meaning that the updates to µ can be written
in terms of precision-weighted prediction errors, which score the difference between the ex-
pected observations (given the current value of µ) and the actual observations y. This notion
of using prediction errors to estimate hidden quantities is also known as predictive coding
[7–9]. The simple form of the belief updates derives from the fact that the energy term of the
Laplace-approximated free energy −ln p(µ, y) can be written as a precision-weighted sum of
(squared) prediction errors. To show this, we can consider a simple, static generative model
where the prior over hidden states p(x) is a Gaussian density with mean η and covariance Σω,
and the observation model p(x|y) is a Gaussian density with mean g(x), i.e., some function
of the hidden state:
32

y ∼N(g(x), Σz),
x ∼N(η, Σω).
(A.17)
Because the variational mean µ only depends on the expected energy term of FL, we
leave out the entropy term and can write out −ln p(y, µ) as a sum of precision-weighted
prediction errors:
−ln p(µ, y) = −ln p(y|µ) −ln p(µ)
= 1
2

εT
z Πzεz + εT
ωΠωεω −ln (|Πz||Πω|)

where Πz = (Σz)−1, Πω = (Σω)−1
and εz = y −g(µ), εω = µ −η
(A.18)
We can write out gradients of this quadratic energy function to yield the update equation
for the means µ as in (A.16), and see that µ changes as a precision-weighted sum of ‘sensory‘
and ‘model’ prediction errors:
˙µ = −∇µFL(µ, y)
= −∇µ
1
2
 εT
z Πzεz + εT
ωΠωεω

= −
∂g
∂µΠzεz + Πωεω

(A.19)
Note that the variational means only depend on the terms of FL containing εz and εω, so
that the update reduces to a gradient descent on a sum of squared prediction errors. This
belief update scheme illustrates the key principles of predictive coding under the Laplace
approximation: conditional means, denoted as µ, change as a function of precision-weighted
prediction errors. The concept of precision-weighting in belief updating is intuitive: if the
generative model attributes higher variance to sensory fluctuations as compared to state
variance (i.e., Πz < Πω), then sensory data is relatively unreliable and consequently makes
a smaller impact on posterior beliefs.
Therefore, the adjustment to the posterior mean
µ in (A.19) is primarily influenced by the state prediction error term Πωεω or the prior.
Conversely, when sensory information is allocated higher precision (lower variance) relative
to prior beliefs (i.e., Πz > Πω), belief updates will strongly rely on sensory data.
We apply the above steps to derive the Laplace-approximated free energy with a Gaussian
posterior q(x; ν) to the dynamical generative model in (A.4), which is by construction a joint
Gaussian density. Note that we use the tilde notation to now indicate that all variables are
vectors of generalised coordinates, e.g., ˜y, ˜x, etc. Showing only the µ-dependent terms of
Laplace energy term −ln p(˜µ, ˜y) ≈Eq [−ln p(˜x, ˜y)]:
33

FL ∝˜εT
z ˜Πz˜εz + ˜εT
ω ˜Πω˜εω
(A.20)
˜εz ≜˜y −˜g
˜εω ≜D˜µ −˜f
Here, the so-called ‘generalised errors’ ˜εz and ˜εω encapsulate sensory and state prediction
errors across orders of motion. Belief updating is again performed using a gradient descent
on free energy, but the dynamic nature of inference necessitates an additional ’motion’ term:
d˜µ
dt = D˜µ −∇˜µFL
= D˜µ + ∂g
∂˜µ
˜ξz + ∂f
∂˜µ
˜ξω −D⊤˜ξω
where ˜ξz = ˜Πz˜εz
˜ξω = ˜Πω˜εω
(A.21)
The additional term D˜µ places the gradient descent within the context of the expected
movement of the conditional means ˜µ, and hence of the free energy minimum. This concept
has been referred to as ’gradient descent in a moving frame of reference’ [1]. This implies
that free energy minimization does not occur when the beliefs cease moving, but rather when
the belief update rate d˜µ
dt is identical to the beliefs about the motion itself D˜µ, in other words
when ∂F
∂˜µ = 0 ⇐⇒D˜µ = d˜µ
dt . This additional temporal correction proves beneficial in a
dynamic data assimilation regime, where incoming observations are integrated online with
beliefs that are evolving according to their own prior dynamics [1].
A.3
Active inference for continuous control
Active inference casts action or control as issuing from the same process of free energy min-
imization as used for state estimation; the only difference is that we now have an additional
set of variables, actions a, that can be changed to minimize free energy as well. The update
equation for actions a closely resembles that used to update the variational mean µ, i.e., a
gradient descent on the (Laplace-encoded) variational free energy:
da
dt = −∂FL(µ, y(a))
∂a
= −∂FL
∂y(a)
∂y(a)
∂a
(A.22)
where we have now introduced a dependence between of observations y on actions a.
This allows us to express the free energy gradient with respect to action as the product
34

of the derivative of the free energy with respect to observations ∇yFL(µ, y(a)) and the
derivative of the function mapping from actions to observations
∂y(a)
∂a .
The free energy
gradient with respect to observations is exactly the sensory prediction error ∇yFL(µ, y(a)) =
ξz = Π(y −g(x)). This assumed dependence of observations on actions underwrites the
notion that active inference agents cannot directly measure how their actions affect hidden
states, but may only do so via their sensory consequences. This has been speculated to
explain the architecture of descending motor pathways in corticospinal systems, where motor
commands are ‘unpacked’ into proprioceptive predictions at the level of spinal circuits and
other lower motor nuclei. Action is thus realized by minimizing proprioceptive prediction
errors via classical reflex arcs [10]. The reflex arc term ∂y(a)
∂a
of (A.22) is analogous to a
forward model in motor control [11], because it reflects the agent’s implicit assumptions
about how the agent’s own actions lead to their (anticipated) sensory consequences. This
sort of update rule leads active inference agents to minimize sensory prediction errors via
these ‘baked-in’ sensorimotor contingencies. In this way active inference has been referred
to as ‘action by self-fulfilling prophecy’ [12]. In other words, the agent generates top-down
expectations of ‘preferred’ sensory inputs, which then generates prediction errors which can
then be suppressed through low-level motoric reflexes [10].
A.4
Filtering and control for a self-propelled particle
Having derived a routine for state estimation and action through a generalized gradient
flow on the Laplace-approximated variational free energy FL, we can now apply this to
the simulation of collective motion. In what follows, we write down a sufficient generative
model for a single self-propelled agent and unpack the corresponding free energy gradients
((A.20) and (A.22)) using the structure and parameters of the chosen generative model. In
this section we unpack the per-agent generative model of local distances described in the
main text and demonstrate how a more parametric, unconstrained version of social forces
are reproduced by minimizing free energy with respect to the distance-tracking generative
model.
A.4.1
A generalised filter for local distances and their time evolution
As described in the main text, each agent represents a an L-dimensional vector x where
x = (x1, x2, ..., xL).1 The agent not only represents the instantaneous value (or ‘position’) of
x but also its generalized motion, which we truncate at 3rd order:
˙x = f(x) + ω
˙x′ = fxx′ + ω′
˙x′′ = fxx′′ + ω′′
⇒D˜x = ˜f + ˜ω
1We use the bold notation x to represent a vector-valued variable
35

The flow at the first order f is a linear dynamical system with drift matrix A and fixed
point with value η:
f(x) = −A(x −η)
(A.23)
The eigenvalues of the L×L matrix A determine the rate at which the hidden states x are
assumed to relax to their expected value of η. In general, this matrix can be parameterized
arbitrarily to encode different kinds of linear couplings among the different hidden states
x1, x2, ..., xL. In the present work we parameterize A simply as a diagonal matrix with a
single diagonal value α > 0, which can also be expressed as an α-scaled version of the identity
matrix L × L identity matrix IL:
A = −αIL
(A.24)
In combination with the amplitude of random fluctuations Σω, α determines how quickly
the hidden states relax to their mean value of η.2 The generalised flow function ˜f can thus
be written as a linear function of the generalised state ˜x:
˜f =


f(x)
fxx′
fxx′′

= −


A
0
0
0
A
0
0
0
A




x −η
x′
x′′


=


−αIL
0
0
0
−αIL
0
0
0
−αIL




x −η
x′
x′′

= −α


x −η
x′
x′′


(A.25)
where 0 are L × L matrices of zeros. We assume a multivariate Gaussian form for the
generalized noises ˜ω, meaning the density over the generalized motion D˜x is a Gaussian
density, which we hereafter refer to as the ‘dynamics model’ or ‘dynamical prior’:
P(D˜x|˜x) = N(D˜x;˜f, ˜Σω)
(A.26)
Consistent with the block diagonal form of the generalised flow function ˜f, we also assume
the covariance of the generalized noises ˜Σω factorizes into a Kronecker product of ‘spatial’
and ‘temporal’ covariance matrices, i.e.,
˜Σω = Σω ⊗˜Σω
(A.27)
where the spatial covariance Σω (note the bold superscript ω) represents covariance
between L noise processes at the zero-th order ω[0], i.e., Σω = E[ω[0] ⊗ω[0]], and ˜Σω encodes
2Heuristically, it is an exponential decay rate.
36

covariance between different derivatives of the first order noise, i.e., ∀m, n :

˜Σω
nm =
E[ω[n] · ω[m]]. The entries of this covariance matrix can be written in terms of the derivatives
of the autocorrelation function of the random fluctuations evaluated at lag 0, ρ(0):
ρ(h) ≜(Σω)−1E[ω[0](τ) · ω[0](τ + h)]
⇒˜Σω =


1
0
¨ρ(0)
0
−¨ρ(0)
0
¨ρ(0)
0
¨¨ρ(0)
...


(A.28)
The checkerboard structure in the matrix reflects the fact that fluctuations at the first
order are orthogonal to their motion (first derivative), but anti-correlated with their 2nd,
4th, ..., etc. derivatives. A derivation of the temporal covariance matrix from the autocor-
relation function of the first-order fluctuations can be found in Appendix A.5.3 of [13]. In
the generative models of our agents, we assume a Gaussian autocorrelation function with
"smoothness" parameter λω, which yields a simple parameterization of ˜Σω:
ρ(h) = e−
h
2λω
2
(A.29)
⇒˜Σω =


1
0
−1
2λ2ω
. . .
0
1
2λ2ω
0
−1
2λ2ω
0
3
4λ4ω
...
...


(A.30)
A higher value of λω dampens the variance of the generalised fluctuations at higher orders
of differentiation. The correspondence of increasing λω to an increasingly-autocorrelated
process at the first order becomes intuitive once we consider the case of standard white
noise, i.e., the derivative of the Wiener process, whose higher orders of motion have infinite
variance (the state of the process at a given time changes infinitely quickly). This ability to
handle differentiable noise goes beyond the usual Markovian assumptions made in standard
state space models (e.g., Kalman-Bucy filters), which assume that the driving noise is white.
We parameterize the L × L spatial covariance Σω through its precision matrix Πω, as a
diagonal matrix whose entries are given by a single precision (inverse variance) Γω:
Σω = (Πω)−1 =


Γω
0
0
. . .
0
Γω
0
0
0
Γω
...
...


−1
(A.31)
37

The observation likelihood describes sensory observations y = {y1, y2, ..., yL} as noise-
perturbed copies of the hidden states x. We truncate generalized observations at second
order, i.e., agents can sense the first order hidden state x and its motion x′:
y = x + z
y′ = x′ + z′
(A.32)
This can be equivalently expressed as a linear function ˜g of the full generalised state
˜x = {x, x′, x′′}, where ˜g represents multiplication with a non-invertible matrix that discards
acceleration information x′′:
˜y = ˜g + ˜z
y
y′

=
IL
0
0
0
IL
0
 

x
x′
x′′

+
z
z′

(A.33)
We leverage the same assumptions about the sensory noises ˜z as we did for the state
noises ˜ω to end up with the following multivariate Gaussian form for the observation model:
p(˜y|˜x) = N(˜y; ˜g, ˜Σz)
(A.34)
We parameterize the likelihood model’s sensory noises ˜z identically to the state noises ˜ω,
namely using a spatial precision parameter Γz and temporal smoothness parameter λz.
Having specified the dynamics and observation models in terms of Gaussian distributions,
we can write out the full generative model as a joint Gaussian density over (generalized)
hidden states and observations. We can furthermore define an approximate posterior over
the hidden states ˜x that has a multivariate Gaussian form Q(˜x) = N(˜x; ˜µ; Σν), which can be
summarized entirely in terms of its posterior mean vector ˜µ, due to the fact that under the
Laplace approximation the variational covariance depends directly on the mean. From here,
we can define the Laplace-approximated variational free energy for this generative model as
proportional to a sum of squared prediction errors:
p(˜y, ˜x) = p(˜y|˜x)p(D˜x|˜x)
= N(˜y; ˜g, ˜Σz)N(D˜x; ˜f, ˜Σω)
(A.35)
FL = 1
2
h
˜ε⊤
z ˜Πz˜εz + ˜ε⊤
ω ˜Πω˜εω −ln

|˜Πz||˜Πω||Πν|

+ 3L ln 2π
i
where Πν ≜(Σν)−1
˜εz = ˜y −˜g(˜µ) =
 y −µ
y′ −µ′

, ˜εω = D˜µ −˜f(˜µ) =


µ′ + α(µ −η)
µ′′ + αµ′
αµ′′


(A.36)
38

where the sensory prediction errors ˜εz score the difference between the generalized ob-
servations y, y′ and their expected values µ, µ′, and the model or process prediction errors
˜εω score the difference between the motion of the generalized means D˜µ and their expected
motion ˜f(˜µ), which has been expanded above using the linear form of the flow function de-
tailed in (A.25). Note that here, due to the Laplace approximation, the generative model’s
expectation functions ˜g,˜f are evaluated at the variational mean ˜µ, rendering the variational
beliefs a moving point-estimate of the hidden states ˜x.
Filtering consists of updating ˜µ as a generalized gradient flow on this energy functional
FL as in (A.21).
To be explicit, below we expand these free energy gradients using the
particular forms of ˜g,˜f used by our self-propelled particle agent:
d˜µ
dt = D˜µ −∇˜µFL
= D˜µ + ∇˜µ˜g · ˜ξz + ∇˜µ˜f · ˜ξω −D⊤˜ξω
where ˜ξz = ˜Πz
 y −µ
y′ −µ′

˜ξω = ˜Πω


µ′ + α(µ −η)
µ′′ + αµ′
αµ′′


∇˜µ˜g =
IL
0
0
0
IL
0
⊤
, ∇˜µ˜f =


−αIL
0
0
0
−αIL
0
0
0
−αIL


⊤
(A.37)
This sort of filtering scheme means that the agent’s beliefs ˜µ will evolve as a moving
average of incoming sensory data ˜y subject to a dynamical bias or "drag", which is a con-
sequence of the latent belief that hidden states x continuously relax towards a fixed point
at η. Specifically, the beliefs are constantly pulled closer to the data in order to minimize
sensory prediction errors ˜ξz; however, this process itself incurs state prediction errors ˜ξω
that will pull the beliefs back towards the fixed point. This constant tug of war between
sensory and process prediction errors can be shifted disproportionately in one direction by
adjusting the relative precisions of the likelihood vs. dynamical models, respectively. If the
process precision ˜Πω is high relative to the observation precision ˜Πz, then the beliefs will
tend to their expected fixed point of η. A similar enhancement of prior bias can be achieved
by increasing the drift rate α of the dynamics model, which increases the force driving µ
towards η — this was the approach taken in [14], for example.
Note that when numerically integrating the differential equation in (A.37) with a forwards
Euler scheme, one uses a finite number of iterations to update the variational means ˜µ, which
we term nInferIter, and a step-size κµ which scales the size of the increment to ˜µ [12]. In all
simulations shown here, we set nInferIter = 1, κµ = 0.1 (see Table E.1 for details).
39

A.4.2
Closing the loop with observations and action
In order to interpret the random variables of the generative model as representing behaviorally-
relevant features of an agent’s world, we now turn to specfiying the generative process, i.e.,
the actual physics of the world that our self-propelled particle agents will inhabit. In this
section we detail how the observations ˜y for a single agent are generated from the positions
and velocities of other active inference agents, and how actions can be generated through
active inference, which in this contexts means changing continuous control variables using a
gradient descent on the same free energy used to derive the belief update equations of the
previous section.
We now shift our perspective to that of a single agent, hereafter referred to as the focal
individual or focal agent, and specify how its sensory data ˜y are generated. We start by
describing univariate hidden states and corresponding observations, where the true hidden
variable is an average nearest-neighbor distance xh. We add the h subscript to distinguish
these ‘real’ variables (hidden states, observations, noise terms) from their representations in
the generative model (e.g., ˜x, ˜y).
We indicate the focal individual with index i; so the agent i-relative hidden state xh,i
denotes the average nearest-neighbor distance from the perspective of agent i. This average
distance xh,i is calculated from the K neighbors that form the interaction set Nin of the ith
focal individual. How to define the interaction set Nin is a choice to make in each simulation,
but for the case of recapitulating classical, distance-dependent social forces models, we define
Nin as those neighbors that are within a fixed distance R0 of the focal individual’s position:
xh,i ≜1
K
X
j∈Nin
∥∆rij∥
where Nin ≜{j ̸= i : ∥∆rij∥≤R0}
(A.38)
K ≜|Nin|
∆rij ≜rj −ri
(A.39)
An additional filter on Nin that is common to self-propelled particle models, is to only
include neighbors that subtend some angular extent (also known as a ‘vision cone’ or ‘visual
field’) relative to the focal agent’s velocity vector vi. This is the approach taken in [15], for
instance, and in the simulations examined in the main text we do the same.
The vector ri denotes the 2-D coordinate of the focal agent, and rj is that of neighbor j.
rij thus represents the relative displacement vector of neighbour j, from the perspective of
the focal agent i.
We also define the first temporal derivative of the local average distance x′
h,i:
˜xh,i ≜(xh,i, x′
h,i)
x′
h,i ≜dxh,i
dt
= ∇rixh,i · vi +
X
j∈Nin
 ∇rjxh,i · vj

(A.40)
40

where vj is the velocity or heading vector of neighbour j. The expression in (A.40) means
that we can compute the first derivative or velocity of the distance x′
h,i as a function of the
positions and velocities of all agents, as opposed to some discrete-time approximation, e.g.,
x′
h,i ≈xh,i(t+∆t)−xh,i(t)
∆t
for some small ∆t. Note that this expression for x′
h,i assumes a local
linearization of xh,i at the radius defined by R0, i.e., this linearization will be a poor predictor
of the actual change in the state xh,i(t + ∆t) −xh,i(t) when neighbors are instantaneously
leaving or entering the interaction set Nin. Observations ˜yh,i are perturbed versions of the
hidden states with additive generalised fluctuations ˜zh,i:
yh,i = xh,i + zh,i
y′
h,i = x′
h,i + z′
h,i
where
p(˜zh,i) = N(˜zh,i; 0, ˜Σz,h)
(A.41)
In all simulations we parameterize the ˜zh,i as independent Gaussian variables, i.e.,
˜Σz,h =
σ2
z,h
0
0
σ2
z′,h

(A.42)
where the two variances σ2
z,h and σ2
z′,h can be set independently. The ‘perception’ step
of our active inference process proceeds by providing these observations to the filtering
equations in (A.37). The result is that posterior means ˜µ appears to track ˜xh,i over time,
while additionally estimating its higher-order motion (acceleration) via µ′′′.
Finally, we now furnish a scheme for updating actions by mapping the control variables
a and sensorimotor contingency terms of (A.22) to the case of our distance-tracking self-
propelled agent.
We let actions be identifiable with the heading vector vi of the focal individual, i.e.,
a = vi. For the simulations presented in the current paper, we always asserted that this
heading have unit magnitude, but in general this constraint is not necessary.
Given this definition of actions, we can unpack the sensorimotor contingency term ∂y(a)
∂a
that appeared in the active inference control equation of (A.22), now letting a = v and
turning partial derivatives into Jacobians to account for vectorial nature of actions (being a
velocity in 2-D) and observations (being comprised of two generalized coordinates):
dvi
dt = −∇vi˜yh,i(vi)⊤∇˜yh,i(vi)FL
(A.43)
Note here that observations ˜yh,i are a function of actions; this is because observations are
a linear function of hidden states, which themselves are linear in the velocity vector of the
focal individual vi via the relation in (A.40). Importantly, however, the distance observation
yh,i does not directly depend on the vi — only the distance velocity y′
h,i does. This means
the sensorimotor contingency in (A.43) is comprised of non-zero partial derivatives only for
y′
h,i:
41

∇vi˜yh,i(vi) =
∇viyh,i(vi)
∇viy′
h,i(vi)

=

0
∇rixh,i

(A.44)
This has an important consequence for action, when we consider the form of the second
part of the action update in (A.43), the free energy gradient term ∇˜yh,iFL:
∇˜yh,iFL = ˜ξz = ˜Πz˜εz =

Γz(yh,i −µ)
2Γzλ2
z(y′
h,i −µ′)

(A.45)
The free energy gradient with respect to observations is simply the generalized (precision-
weighted) sensory error ˜ξz, which we have written in terms of the observations ˜yh,i, posterior
beliefs ˜µ and precision parameters Γz, λz. The sparse form of the sensorimotor contingency
in (A.44) means that the 0th-order prediction error ξz will have no effect on behavior and
only the velocity prediction errors ξ′
z will be relevant for the update to vi, i.e.,
dvi
dt = −

ξz ∇viyh,i(vi)
|
{z
}
=0
+ξ′
z∇viy′
h,i(vi)


= −ξ′
z∇rixh,i
= 2Γzλ2
z(y′
h,i −µ′)∆ˆr
where ∆ˆr = 1
K
X
j∈Nin
∆rij
∥∆rij∥
(A.46)
Note that, as for the inference update in (A.37), we update vi using a fixed number
of action iterations nActionIter and step-size κa, where here we set nActionIter = 1, κa = 0.1.
This action update equation has a few key implications for the behavior of active inference
agents equipped with this type of generative model, and its relationship to ‘classical’ self-
propelled particle models like the Couzin-Aoki model and the Reynolds or BOIDS model
[15–17]. The first is the fact that the sensorimotor contingency is identical to the ‘social
force’ vector used to drive interactions in self-propelled particle models ∆ˆr; this the average
of the vectors pointing from each neighbor in the interacting set to the focal agent’s position
ri.
The sign of the precision-weighted prediction error ϵ′
z determines whether the social
force is attractive (pointing towards other agents) or repulsive (pointing away from other
agents). Secondly, the fact that actions only depend on velocity observations, rather than
state observations, means that agents will adjust their heading according to how the (sensed)
distance is instantaneously changing (its velocity), rather than its value. This lends action
a predictive, anticipatory power and accounts for why we observe robust polarized motion
in the absence of an explicit alignment term like in classic self-propelled particle models [15,
18]. The alignment-like forces emerges from the fact that the velocity vectors of other agents
42

vj, j ∈Nin are integrated into the computation of y′
h,i via the relation in the second line of
(A.40).
One of the defining features of other self-propelled particle models like the Couzin-Aoki
model [15, 16] is the presence and priorization of interaction zones. The two main zones
used in these models, and which on their own are sufficient for group cohesion, are a narrow
repulsion zone defined by some radius rr and a wider attraction zone with radius ra, where
ra > rr. Neighboring agents within the repulsive radius exert repulsive forces on the focal
agent, while those beyond the repulsion radius but within the attraction zone exert attrac-
tive forces, where the difference between attraction and repulsion is given by the sign of the
force vector ∆ˆr. The active inference model leads to an effective notion of zones, but rather
than being explicitly encoded, these zones emerge through the fixed-point attractor η pa-
rameterizing the generative model’s dynamics model f. This is made clear when we examine
the precision-weighted prediction error ξ′
z, which itself is a function of velocity observations
y′
h,i and velocity beliefs µ′. Consider the limiting case of when inference is strongly biased
by the dynamics model f (i.e., in the case that Γω > Γz or large α); the generalised beliefs
˜µ will be strongly drawn to the setpoint η of the dynamics prior, i.e.,
˜µ =


µ
µ′
µ′′

≈


η
0
0


Under this assumption, the precision-weighted prediction error ξ′
z approximates 2Γzλ2
zy′
h,i,
and thus signals whether neighbors are instantaneously approaching or moving away from
the focal agent, where ξ′
z < 0 indicates they are approaching and ξ′
z > 0 indicates they are
moving away. This in turn determines whether the update to the focal agent’s action vi
is repulsive or attractive, as its sign determines the direction of the social force vector ∆ˆr.
Although the first order distance yh,i does not directly drive action, it does so indirectly
through its effect on inference of µ′. If we consider the case when the sensed distance yh,i
drops below the setpoint η, then one can reason through the cascade of prediction errors
that ultimately lead to a repulsive force. As a direct consequence of a drop in yh,i below
µ, sensory prediction errors ξz will become negative, whose minimization will require µ to
move below η. This process in turn incurs slower-moving (negative) model prediction errors
ξω, whose minimization drives µ back to its fixed point of η, given the dynamic constraint
for the beliefs to relax to their fixed point. In order to accomplish this upward movement
of µ, either the rate of change of µ or the sensed distance itself must be positive, i.e., ˙µ > 0
or yh,i > 0. In the absence of positive yh,i, model prediction errors will drive µ′ (and hence
˙µ) above 0. This temporarily sets a larger radius of repulsion, i.e., a larger range of y′
h,i for
which ξ′
z is negative and for which repulsive forces impact the focal agent’s velocity. This
causes the agent to move away from its neighbors and thus further increase yh,i, under the
assumption that the agent’s prediction of the distance dynamics are correlated with the true
change in xh,i. Belief updating and action thus work together to accelerate the return of
µ towards η and ˜ξz, ˜ξω towards 0; for this reason active inference is often described as an
account of action and perception driven by ‘self-fulfilling prophecy’ [12].
43

In order to imbue action with a more direct coupling to the neighbors‘ distances as is done
in the classical self-propelled particle models, rather than the velocity of the distance, one
could hand-craft the sensorimotor contingency term ∇vi˜yh,i to enforce a coupling between
yh,i and vi. This would render the action rule equivalent to a ‘soft’-form of PD control
[14], where errors on both the first order state (yh,i −µ) ≈(yh,i −η) and its derivative
(y′
h,i −µ′) ≈y′
h,i would drive changes to the velocity.
A.5
Extending to multiple sensory sectors
The results of the previous sections can be straightforwardly extended to the multivariate
case as explored in the main text. The focal agent now senses the local distance computed
across a set of distinct sensory sectors. For the model explored in the current work, we split
up the computation of the local distance variable into a set of L sensory adjacent sectors
that comprise an arc of a given angle, relative to the agent’s heading vector vi. We define
the multivariate distance hidden state as follows (dropping the focal agent index i from the
sector-specific hidden states to avoid subscript overload):
xh,i =


xh,1
xh,2
...
xh,L


(A.47)
where xh,l ≜1
Kl
X
j∈Nl
∥∆rij∥
where Nl is the set of neighbors in the lth sensory sector, and Kl = |Nl| (c.f., (A.39)). As
with the scalar hidden state defined above, we also equip the vector of sector distances xh,i
with corresponding sector-specific, generalized observations ˜yh,i, i.e.
yh,i = xh,i + zh,i
(A.48)
y′
h,i = x′
h,i + z′
h,i
where
p(˜zh,i) = N(˜zh,i; 0, ˜Σz,h)
(A.49)
such that the focal individual now observes a vector of local (noise-perturbed) distances
and their first orders of motion. Note that the generalized covariance matrix here ˜Σz,h is now
a 2L × 2L size matrix, that encodes the covariance structure between sector-specific noise
and their generalized orders.
For all simulations we generated uncorrelated noise across
the different sectors, although spatially-smooth noise could be modelled by introducing off
diagonal elements in ˜Σz,h, i.e., E[zh,lzh,k] ̸= 0.
The agent’s generative model is also extended to the multivariate state-space formulation
we began with, using a vector of generalised hidden states ˜x = (˜x1, ˜x2, ..., ˜xL) to estimate
44

the local distance within each sensory sector. Belief-updating consists in updating a vector
of generalised means ˜µ through integration of (A.37).
The action update has an identical form as before, except now the sensorimotor con-
tingency term ∇vi˜yh,i(vi) is a collection of partial derivative vectors, one for each sensory
sector:
dvi
dt = −∇vi˜yh,i(vi)⊤∇˜yh,iFL
∇vi˜yh,i(vi) =
∇viyh,i(vi)
∇viy′
h,i(vi)

=


0
...
0
∇rixh,1
∇rixh,2
...
∇rixh,L


(A.50)
The last L rows of this Jacobian matrix encode the gradients of the sector-specific distance
velocities y′
h,l with respect to the focal agent’s action; these partial derivatives are vectors
pointing from the average position of the neighbors in sector l towards the focal individual.
When we combine the Jacobian matrix in (A.50) with the sensory prediction error term
˜yh,i (i.e., the free energy gradients ∇˜yh,iFL), we are left with the following update for the
velocity:
dvi
dt = ξ′
z · ∆ˆR =
ξ′
z,1
ξ′
z,2
. . .
ξ′
z,L

·


∆ˆr1
∆ˆr2
...
∆ˆrL


=
L
X
l=1
ξ′
z,l∆ˆrl = 2Γzλ2
z
L
X
l=1
(y′
h,l −µ′
l)∆ˆrl
(A.51)
where ∆ˆrl = 1
Kl
X
j∈Nl
∆rij
||∆rij||
The action thus becomes a weighted sum of ‘sector-vectors’ ∆ˆrl, which are vectors point-
ing from the focal agent’s position ri towards the average position of the neighbors in Nl.
The weights that scale each ∆ˆrl are the precision-weighted prediction errors associated with
velocity observations emanating from the appropriate sector ξ′
z,l ∝(y′
h,l −µ′
l). The fact we
can pull the spatiotemporal precision terms 2Γzλ2
z outside the sum over sector-vectors, inher-
its from a between-sector independence assumption, built into the agent’s sensory likelihood
model P(˜y|˜x) (see (A.31)). If the generative model allowed for between-sector correlations
45

(i.e. Σz was not diagonal), then the action update would include cross-terms that couple
prediction errors from one sector to the sector-vector from another sector.
An active inference agent equipped with such a multivariate representation of the local
neighbor-distances thus engages in a sort of ‘predictive balancing-act’, differentially respond-
ing more or less to each part of its sensory field in accordance with how much sensations
deviate from their posterior expectations µ′
l, where the sign and degree of this deviation is
scored by ξ′
z,l.
B
Alignment forces from active inference on angles
In previous sections we have shown how repulsive and attractive forces emerge from active
inference models in which the agent entertains a latent representation of the average local
distance between itself and its neighbors, and how its heading direction couples to (the
derivative of) that variable.
In this section we derive alignment-based social forces, like
those that appear in the Reynolds, Couzin, and Vicsek models [15, 17, 18], as a special case
of active inference, where an agent infers the (cosine) angle between its own heading and
that of its neighbors, and acts under the prior belief that this angle tends to 0.
As before, we start with a generative model that represents a generalised latent variable
˜xϕ that evolves in time with Gaussian additive fluctuations ˜ωϕ. We use the ϕ subscript
to distinguish this angle-tracking latent variable from the distance-tracking variable of the
previous section. We truncate the generalized representation of this state at second order,
i.e.
˜xϕ = {xϕ, x′
ϕ}, leading to a dynamical equation and corresponding likelihood of the
following form:
˙xϕ = −αϕ(xϕ −1) + ωϕ
˙x′
ϕ = −αϕx′
ϕ + ω′
ϕ
=⇒p(D˜xϕ|˜xϕ) = N(D˜xϕ; ˜fϕ, ˜Σωϕ)
(B.52)
where ˜fϕ =
−αϕ(xϕ −1)
−αϕx′
ϕ

, ˜Σωϕ =
"
σ2
ωϕ
0
0
σ2
ω′
ϕ
#
(B.53)
The observation model describes a mapping from the 0th-order state to a corresponding
observation thereof, perturbed again by Gaussian innovations:
yϕ = xϕ + zϕ
=⇒p(yϕ|xϕ) = N(yϕ; xϕ, σ2
zϕ)
(B.54)
Following the same steps as we did previously for the multivariate, distance-tracking
generative model, we can write down the Laplace-approximated variational free energy of
this model as a quadratic function of the observations and generalized means ˜µϕ:
46

FL ∝ε⊤
zϕΠzϕεzϕ + ˜ε⊤
ωϕ ˜Πωϕ˜εωϕ
where εzϕ ≜yϕ −µϕ
˜εωϕ ≜D˜µϕ −˜fϕ
The agent performs a gradient descent on FL to infer the value of ˜xϕ in light of sensory
observations. This inference is encoded by a Gaussian variational posterior with mean ˜µϕ. As
before, we can tune model parameters such that inference is strongly biased by the dynamics
model ˜fϕ, where the zeroth-order of motion µϕ ≈1. The reason we set the set-point at 1
becomes evident when we consider the generation of sensory data and actions.
Assume that the focal agent with index i observes the local average cosine angle between
its own heading vector vi and those of its neighbors vj, j ∈Nin, where neighbors are once
again defined by membership in some interaction zone3:
yϕ = 1
K
X
j∈Nin
v⊤
i vj = ⟨cos(θij⟩Nin
(B.55)
where the equivalence between the dot products and the cosine angle is assured when we
assume all vk, k ∈{i} ∪Nin have unit magnitude. Recall that if two unit-magnitude vectors
vi, vj are parallel, their dot product (cosine angle) is 1. When we once again assume that
agents act by adjusting their heading direction, then the action update given the continuous
active inference rule in (A.22) has the following form:
dvi
dt = −1
σ2
zϕ
(yϕ −µϕ)ˆv ≈(1 −yϕ)ˆv
(B.56)
where ˆv = 1
K
X
j∈Nin
vj
(B.57)
The approximation in the first line holds when we assume the sensory variance σ2
zϕ is
1 and the dynamics prior (either via increasing α or decreasing σ2
ωϕ) dominates inference
such that µϕ ≈1. In this case, the focal agent i then updates its velocity using the average
neighbor velocity. This is proportional to the alignment force in e.g. [15, 18], except that
it is also scaled by how unaligned the focal individual is with its neighbourhood, scored by
1 −yϕ.
C
Online parameter estimation
In this section we derive update rules for the generative model parameters using a simple
gradient descent scheme on the Laplace-approximated variational free energy. In the active
3For notational convenience and because it doesn’t change the derivations, we omit observation noise on
yϕ.
47

inference literature this process of updating parameters, as opposed to beliefs about states,
is often analogized to online learning or neural plasticity [19, 20].
C.1
Updating sensory smoothness
In this section we derive an update equation for the sensory smoothness parameter λz, which
captures the generative model’s assumptions about the temporal autocorrelation structure
of sensory noise z.
Recall the formulation of state space models in generalized coordinates of motion in
Section A.1. In addition to providing a concise description of local paths of the state ⃗xt in
terms of its higher derivatives x′, x′′, ..., x[n], stochastic differential equations in generalized
coordinates also allow one to express serial correlations in the noises at the first order z, by
assuming that it can be differentiated (has non-zero, smooth autocovariance) and represented
in terms of hierarchical or generalized noises z′, z′′, z′′′, ..., z[n].
Recall the parameterization of the generalized sensory precision ˜Πz as a factorization
into two precision matrices, that respectively represent agent’s beliefs about the ‘spatial’ and
‘temporal’ covariance structure. We parameterize these with the two precision parameters
Γz and λz. Γz encodes the agent’s belief about the overall magnitude of the fluctuations, and
λz encodes beliefs about their their serial correlations in time, assuming a Gaussian form for
their autocorrelation:
˜Πz = S(λz) ⊗Π(Γz)
Π(Γz) =


Γ11
Γ22
...
ΓLL


S(λz) =


1
0
−1
2λ2z
. . .
0
1
2λ2z
0
−1
2λ2z
0
3
4λ4z
...
...


−1
(C.58)
We implement a form of behavioral plasticity by allowing agents to update λz using
observations. We accomplish this using a gradient descent on variational free energy:
dλz
dt = −κθ
∂F
∂λz
(C.59)
where the ‘learning rate’ κθ is typically set to be at least an order of magnitude lower
than the update rate of inference κµ; in all simulations we use κθ = 0.001 and nLearnIter = 1
iteration. This enforces a separation of timescales that is typical in generalized filtering and
state-space models that perform simultaneous state- and parameter-estimation [3, 5, 14].
48

To compute the gradients of the variational free energy with respect to λz, we can start
by expressing those components of the (Laplace-approximated) variational free energy that
depend on λz:
F(λz) = ˜ε⊤
z ˜Πz˜εz −ln

det ˜Πz
(C.60)
where we only have included the terms that depend on the sensory precision ˜Πz due to
its dependence on λz. The full gradient is then simply:
∂F
∂λz
= ˜ε⊤
z ˜Πz˜εz
∂λz
−
∂ln

det ˜Πz
∂λz
(C.61)
Starting with the case of a single sensory sector L = 1, then the generalized prediction
error ˜εz is a vector of prediction errors, one for each order of motion: ˜εz = {εz, ε′
z, ε′′
z, ...}
where a sensory prediction error at a given order of motion is simply: ε[n]
z
= y[n] −˜g[n], where
the n subscript refers to an order of differentiation. In the case of 3 generalized coordinates
for the simple scalar case:
∂F
∂λz
= 4Γzλz(ε′
z)2 + ε′′
z(8Γzε′′
zλ3
z + 2Γzεzλz) + 2Γzλzεzε′′
z −6
λz
= 4Γzλz(εzε′′
z + (ε′
z)2 + 2λ2
z(ε′′
z)2) −6
λz
(C.62)
Meaning that the update for the λz parameter can be simplified to (omitting the learning
rate κθ):
dλz
dt = −4Γzλz(εzε′′
z + (ε′
z)2 + 2λ2
z(ε′′
z)2) + 6
λz
(C.63)
In the case of the distance-tracking generative model we explore in the main text, we
assume that the agents can only observe the 0th (position, y) and 1st (velocity, y′) orders of
motion of the hidden states ˜x. This means there are no longer 2nd-order prediction errors ε′′
z
and the update becomes even simpler:
dλz
dt = −4Γzλz(ε′
z)2 + 6
λz
≈−4Γzλz(y′
h,i)2 + 6
λz
(C.64)
where approximation in the second line results in the case of ‘biased’ inference, i.e.,
µ ≈η =⇒µ′ ≈0, allowing us to replace the velocity prediction error y′
h,i −µ′ with y′
h,i.
49

Given that spatial and temporal precisions are independent from each other due to the
factorization of the generalized precision matrix, and further given the diagonal structure of
the spatial precision Πz (i.e., independence in random fluctuations across sensory sectors),
we can write an update for λz that is a sum of squared prediction errors across sensory
sectors:
dλz
dt ≈−4Γzλz
L
X
l=1
(y′
h,l)2 −6L
λz
(C.65)
The quadratic form of this update means that the update to the smoothness parameter
decays in proportion with the overall magnitude of the velocity prediction errors, regardless
of its sign. This means that if the distance is fluctuating quickly in any direction, then the
agent will infer that fluctuations are slightly-less serially-correlated at the 0th order, reflected
by a decrease in λz.
D
Adding a target representation into the generative model
As described in the main text, it is straightforward to add an additional observation model
and dynamics model to an agent’s generative model to represent the distance between itself
and some abstract spatial target, which in the context of the collective information transfer
experiments, we represent with T:
˙xtarget = −αtargetxtarget + ωtarget
ytarget = xtarget + ztarget
˙x′
target = −αtargetx′
target + ω′
target
y′
target = x′
target + z′
target
(D.66)
We truncate the generalized hidden states at third order ˜xtarget = (xtarget, x′
target, x′′
target)
and the observations at second order ˜ytarget = (ytarget, y′
target). When the agent assumes the
generalized noises ˜ωtarget and ˜ztarget are zero-mean and normally-distributed with covariances
˜Σωtarget and ˜Σztarget and leverage the Laplace approximation exactly as we did in the previ-
ous section, then we can supplement the Laplace-approximated free energy in (A.35) with
additional terms corresponding to target-related prediction errors:
FL ∝1
2
h
˜ε⊤
z-Soc ˜Πz-Soc˜εz-Soc + ˜ε⊤
ω-Soc ˜Πω-Soc˜εω-Soc + ˜ε⊤
z-Tar ˜Πz-Tar˜εz-Tar + ˜ε⊤
ω-Tar ˜Πω-Tar˜εω-Tar
i
+ C
(D.67)
Here we use the suffixes "-Soc" or "-Tar" to indicate ‘social’ relevant information (re-
lated to the average neighbor distance) and the ‘target’ prediction errors. C captures all
the additional terms (log determinants of precision matrices, etc.) that are constant with
respect to the posterior means ˜µ = (˜µSocial, ˜µTarget). Following the same reasoning as used
to derive the inference and action rules for the case of the social distance hidden states
50

and observations(˜xSocial, ˜ySocial), we can do the same to derive active inference rules for the
target-relevant hidden states and observations ˜xtarget, ˜ytarget:
d˜µSocial
dt
= D˜µSocial −∇˜µSocialFL(˜µSocial, ˜ySocial)
dv
dt = −(∇vFL(˜µSocial, ˜ySocial) + ∇vFL(˜µTarget, ˜yTarget))
d˜µTarget
dt
= D˜µTarget −∇˜µTargetFL(˜µTarget, ˜yTarget)
(D.68)
Where expanding the free energy gradients on the right equation leads to an expression
for the action update in terms of a precision-weighted sum of vectors, appearing in (14) in
the main text.
E
Numerical methods
We used a forwards Euler-Maruyama scheme to the integrate a (Itô-style) stochastic differ-
ential equation for the positions of all agents over time:
drt = vtdt + σadWt
(E.69)
where the variance of ‘action noise’ σ2
a was set to 0.01 for all experiments unless explicitly
stated otherwise. We used a step size of ∆t = 0.01s in the integration. For the current
timestep τ in ‘simulation time’, we used a simple forwards Euler scheme to integrate the
differential equations used for belief updating (see (A.37)) and action (see (A.43)) for each
agent in parallel. We use the positions and heading vectors of all agents from the previous
integration timestep (τ −∆t) to generate the observations for the current timestep.
The collective information transfer experiments were performed using custom Julia code,
and all other simulations were implemented in JAX using custom code. To accelerate the
parameter scans over pinf, Γz-Social, and Γz-Target to create the results in Figure 3 in the main
text, we used the high-performance computing clusters (Cobra and Draco) provided by the
Max Planck Computing and Data Facility.
Supplemental References
[1]
Karl Friston, Klaas Stephan, Baojuan Li, and Jean Daunizeau. “Generalised filtering”.
In: Mathematical Problems in Engineering 2010 (2010).
[2]
Karl Friston. “Hierarchical models in the brain”. In: PLoS computational biology 4.11
(2008).
[3]
Bhashyam Balaji and Karl Friston. “Bayesian state estimation using generalized coor-
dinates”. In: Signal Processing, Sensor Fusion, and Target Recognition XX 8050 (2011),
pp. 716–727.
51

Table E.1: Default parameter configuration used in numerical simulations (unless otherwise
stated). First column denotes the name of the parameter, second column denotes its default
value and third column indicates whether the parameter concerns the generative process (the
physics of the simulation environment), the generative model used for active inference, or a
hyperparameter (e.g., used in the active inference algorithm).
Parameter
Value
Type
∆t (Euler integration step, in seconds)
0.01
generative process
Number of sensory sectors
4
generative process
Sector angle (in degrees ◦)
60
generative process
R0 (interaction radius, in arbitrary units)
5
generative process
σ2
a
0.01
generative process
σ2
z,h
0.01
generative process
σ2
z′,h
0.01
generative process
Γz
1.0
generative model
Γω
1.0
generative model
λz
1.0
generative model
λω
1.0
generative model
α
0.5
generative model
αtarget
0.5
generative model
η
1.0
generative model
Number of generalised coordinates (x)
3
hyperparameter
Number of generalised coordinates (y)
2
hyperparameter
κµ
0.1
hyperparameter
nInferIter
1
hyperparameter
κa
0.1
hyperparameter
nActionIter
1
hyperparameter
κθ
0.001
hyperparameter
nLearnIter
1
hyperparameter
52

[4]
Karl J Friston. “Variational filtering”. In: NeuroImage 41.3 (2008), pp. 747–766.
[5]
Karl J Friston, N Trujillo-Barreto, and Jean Daunizeau. “DEM: a variational treatment
of dynamic systems”. In: Neuroimage 41.3 (2008), pp. 849–885.
[6]
Karl Friston, Lancelot Da Costa, Noor Sajid, Conor Heins, Kai Ueltzhöffer, Grigorios
A Pavliotis, and Thomas Parr. “The free energy principle made simpler but not too
simple”. In: arXiv preprint arXiv:2201.06387 (2022).
[7]
Karl Friston. “A theory of cortical responses”. In: Philosophical transactions of the
Royal Society B: Biological sciences 360.1456 (2005), pp. 815–836.
[8]
Karl Friston and Stefan Kiebel. “Predictive coding under the free-energy principle”. In:
Philosophical Transactions of the Royal Society B: Biological Sciences 364.1521 (2009),
pp. 1211–1221.
[9]
Yanping Huang and Rajesh PN Rao. “Predictive coding”. In: Wiley Interdisciplinary
Reviews: Cognitive Science 2.5 (2011), pp. 580–593.
[10]
Rick A Adams, Stewart Shipp, and Karl J Friston. “Predictions not commands: active
inference in the motor system”. In: Brain Structure and Function 218.3 (2013), pp. 611–
643.
[11]
Karl Friston. “What is optimal about motor control?” In: Neuron 72.3 (2011), pp. 488–
498.
[12]
Christopher L Buckley, Chang Sub Kim, Simon McGregor, and Anil K Seth. “The
free energy principle for action and perception: A mathematical review”. In: Journal
of Mathematical Psychology 81 (2017), pp. 55–79.
[13]
Thomas Parr, Giovanni Pezzulo, and Karl J Friston. Active inference: the free energy
principle in mind, brain, and behavior. MIT Press, 2022.
[14]
Manuel Baltieri and Christopher L Buckley. “PID control as a process of active infer-
ence with linear generative models”. In: Entropy 21.3 (2019), p. 257.
[15]
Iain D Couzin, Jens Krause, Richard James, Graeme D Ruxton, and Nigel R Franks.
“Collective memory and spatial sorting in animal groups”. In: Journal of theoretical
biology 218.1 (2002), pp. 1–12.
[16]
Ichiro AOKI. “A Simulation Study on the Schooling Mechanism in Fish”. In: NIPPON
SUISAN GAKKAISHI 48.8 (1982), pp. 1081–1088. doi: 10.2331/suisan.48.1081.
[17]
Craig W Reynolds. “Flocks, herds and schools: A distributed behavioral model”. In:
Proceedings of the 14th annual conference on Computer graphics and interactive tech-
niques. 1987, pp. 25–34.
[18]
Tamás Vicsek, András Czirók, Eshel Ben-Jacob, Inon Cohen, and Ofer Shochet. “Novel
type of phase transition in a system of self-driven particles”. In: Physical review letters
75.6 (1995), p. 1226.
53

[19]
Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, Giovanni
Pezzulo, et al. “Active inference and learning”. In: Neuroscience & Biobehavioral Re-
views 68 (2016), pp. 862–879.
[20]
Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita Neacsu,
and Karl Friston. “Active Inference on Discrete State-Spaces: A Synthesis”. In: Journal
of Mathematical Psychology 99 (Dec. 2020), p. 102447. issn: 0022-2496. doi: 10.1016/
j.jmp.2020.102447. (Visited on 01/27/2021).
Supplemental Movie Legends
Movie 1
Example of a simulation of N = 96 agents that includes a dynamic transition
from polarized to milling regime. Parameters: σ2
z′,h = 0.05; Sector angle = 80◦; R0 = 10
units; κa = 0.2; λω = 0.5; λz = 2.0. Unless specified, all remaining parameters are as listed
in Table E.1.
Movie 2
Example of a polarized group of N = 64 agents. Parameters: Sector angle = 80◦;;
κa = 0.2; λω = 0.5; λz = 1.5.
Movie 3
Example of a milling regime observed in N = 64 agents. Parameters: σ2
z′,h = 0.04;
Sector angle = 80◦; α = 1.0; κa = 0.2; λω = 0.8; λz = 1.8.
Movie 4
Example of a disordered regime observed in N = 96 agents. Parameters: Number
of sensory sectors = 2; Sector angle = 160◦; R0 = 10.0 units; α = 0.2; η = 0.5, κa = 0.2;
λω = 0.1; λz = 1.787.
Movie 5
Metastable ‘snaking’ configuration observed in N = 64 agents.
Parameters:
σ2
z′,h = 0.04; Sector angle = 80◦; α = 0.1; κa = 0.2; λω = 0.5; λz = 2.2.
54

