
BAYESIAN SIGNAL
PROCESSING

Wiley Series on
Adaptive and Cognitive Dynamic Systems
Editor: Simon Haykin
A complete list of titles in this series appears at the end of this volume.

BAYESIAN SIGNAL
PROCESSING
Classical, Modern, and
Particle Filtering Methods
SECOND EDITION
James V. Candy
Lawrence Livermore National Laboratory
University of California, Santa Barbara

Copyright © 2016 by John Wiley & Sons, Inc. All rights reserved.
Published by John Wiley & Sons, Inc., Hoboken, New Jersey.
Published simultaneously in Canada.
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or
by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as
permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior
written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax
(978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should
be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ
07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permission.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in
preparing this book, they make no representations or warranties with respect to the accuracy or
completeness of the contents of this book and speciically disclaim any implied warranties of
merchantability or itness for a particular purpose. No warranty may be created or extended by sales
representatives or written sales materials. The advice and strategies contained herein may not be suitable
for your situation. You should consult with a professional where appropriate. Neither the publisher nor
author shall be liable for any loss of proit or any other commercial damages, including but not limited to
special, incidental, consequential, or other damages.
For general information on our other products and services or for technical support, please contact our
Customer Care Department within the United States at (800) 762-2974, outside the United States at (317)
572-3993 or fax (317) 572-4002.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may
not be available in electronic formats. For more information about Wiley products, visit our web site at
www.wiley.com.
Library of Congress Cataloging-in-Publication Data
Names: Candy, James V., author.
Title: Bayesian signal processing : classical, modern, and particle iltering methods / James V. Candy.
Description: Second edition. | Hoboken, New Jersey : John Wiley & Sons Inc., [2016] | Includes index.
Identiiers: LCCN 2016019012 | ISBN 9781119125457 (cloth) | ISBN 9781119125488 (epub)
Subjects: LCSH: Signal processing–Mathematics. | Bayesian statistical decision theory.
Classiication: LCC TK5102.9 .C3187 2016 | DDC 621.382/201519542–dc23
LC record available at https://lccn.loc.gov/2016019012
Printed in the United States of America
10 9 8 7 6 5 4 3 2 1

“…no mere man has ever seen, heard or even
imagined what wonderful things God has ready for
those who love the Lord” (1 Cor. 2:9)

CONTENTS
Preface to Second Edition
xiii
References
xv
Preface to First Edition
xvii
References
xxiii
Acknowledgments
xxvii
List of Abbreviations
xxix
1
Introduction
1
1.1
Introduction
1
1.2
Bayesian Signal Processing
1
1.3
Simulation-Based Approach to Bayesian Processing
4
1.3.1
Bayesian Particle Filter
8
1.4
Bayesian Model-Based Signal Processing
9
1.5
Notation and Terminology
13
References
15
Problems
16
2
Bayesian Estimation
20
2.1
Introduction
20
2.2
Batch Bayesian Estimation
20
2.3
Batch Maximum Likelihood Estimation
23
2.3.1
Expectation–Maximization Approach to Maximum
Likelihood
27
2.3.2
EM for Exponential Family of Distributions
30
2.4
Batch Minimum Variance Estimation
34
vii

viii
CONTENTS
2.5
Sequential Bayesian Estimation
37
2.5.1
Joint Posterior Estimation
41
2.5.2
Filtering Posterior Estimation
42
2.5.3
Likelihood Estimation
45
2.6
Summary
45
References
46
Problems
47
3
Simulation-Based Bayesian Methods
52
3.1
Introduction
52
3.2
Probability Density Function Estimation
54
3.3
Sampling Theory
58
3.3.1
Uniform Sampling Method
60
3.3.2
Rejection Sampling Method
64
3.4
Monte Carlo Approach
66
3.4.1
Markov Chains
71
3.4.2
Metropolis–Hastings Sampling
74
3.4.3
Random Walk Metropolis–Hastings Sampling
75
3.4.4
Gibbs Sampling
79
3.4.5
Slice Sampling
81
3.5
Importance Sampling
83
3.6
Sequential Importance Sampling
87
3.7
Summary
90
References
91
Problems
94
4
State–Space Models for Bayesian Processing
98
4.1
Introduction
98
4.2
Continuous-Time State–Space Models
99
4.3
Sampled-Data State–Space Models
103
4.4
Discrete-Time State–Space Models
107
4.4.1
Discrete Systems Theory
109
4.5
Gauss–Markov State–Space Models
115
4.5.1
Continuous-Time/Sampled-Data Gauss–Markov Models
115
4.5.2
Discrete-Time Gauss–Markov Models
117
4.6
Innovations Model
123
4.7
State–Space Model Structures
124
4.7.1
Time Series Models
124
4.7.2
State–Space and Time Series Equivalence Models
131
4.8
Nonlinear (Approximate) Gauss–Markov State–Space Models
137
4.9
Summary
142
References
142
Problems
143

CONTENTS
ix
5
Classical Bayesian State–Space Processors
150
5.1
Introduction
150
5.2
Bayesian Approach to the State–Space
151
5.3
Linear Bayesian Processor (Linear Kalman Filter)
153
5.4
Linearized Bayesian Processor (Linearized Kalman Filter)
162
5.5
Extended Bayesian Processor (Extended Kalman Filter)
170
5.6
Iterated-Extended Bayesian Processor (Iterated-Extended Kalman
Filter)
179
5.7
Practical Aspects of Classical Bayesian Processors
185
5.8
Case Study: RLC Circuit Problem
190
5.9
Summary
194
References
195
Problems
196
6
Modern Bayesian State–Space Processors
201
6.1
Introduction
201
6.2
Sigma-Point (Unscented) Transformations
202
6.2.1
Statistical Linearization
202
6.2.2
Sigma-Point Approach
205
6.2.3
SPT for Gaussian Prior Distributions
210
6.3
Sigma-Point Bayesian Processor (Unscented Kalman Filter)
213
6.3.1
Extensions of the Sigma-Point Processor
222
6.4
Quadrature Bayesian Processors
223
6.5
Gaussian Sum (Mixture) Bayesian Processors
224
6.6
Case Study: 2D-Tracking Problem
228
6.7
Ensemble Bayesian Processors (Ensemble Kalman Filter)
234
6.8
Summary
245
References
247
Problems
249
7
Particle-Based Bayesian State–Space Processors
253
7.1
Introduction
253
7.2
Bayesian State–Space Particle Filters
253
7.3
Importance Proposal Distributions
258
7.3.1
Minimum Variance Importance Distribution
258
7.3.2
Transition Prior Importance Distribution
261
7.4
Resampling
262
7.4.1
Multinomial Resampling
267
7.4.2
Systematic Resampling
268
7.4.3
Residual Resampling
269
7.5
State–Space Particle Filtering Techniques
270
7.5.1
Bootstrap Particle Filter
270
7.5.2
Auxiliary Particle Filter
274

x
CONTENTS
7.5.3
Regularized Particle Filter
281
7.5.4
MCMC Particle Filter
283
7.5.5
Linearized Particle Filter
286
7.6
Practical Aspects of Particle Filter Design
290
7.6.1
Sanity Testing
290
7.6.2
Ensemble Estimation
291
7.6.3
Posterior Probability Validation
293
7.6.4
Model Validation Testing
304
7.7
Case Study: Population Growth Problem
311
7.8
Summary
317
References
318
Problems
321
8
Joint Bayesian State/Parametric Processors
327
8.1
Introduction
327
8.2
Bayesian Approach to Joint State/Parameter Estimation
328
8.3
Classical/Modern Joint Bayesian State/Parametric Processors
330
8.3.1
Classical Joint Bayesian Processor
331
8.3.2
Modern Joint Bayesian Processor
338
8.4
Particle-Based Joint Bayesian State/Parametric Processors
341
8.4.1
Parametric Models
342
8.4.2
Joint Bayesian State/Parameter Estimation
344
8.5
Case Study: Random Target Tracking Using a Synthetic Aperture
Towed Array
349
8.6
Summary
359
References
360
Problems
362
9
Discrete Hidden Markov Model Bayesian Processors
367
9.1
Introduction
367
9.2
Hidden Markov Models
367
9.2.1
Discrete-Time Markov Chains
368
9.2.2
Hidden Markov Chains
369
9.3
Properties of the Hidden Markov Model
372
9.4
HMM Observation Probability: Evaluation Problem
373
9.5
State Estimation in HMM: The Viterbi Technique
376
9.5.1
Individual Hidden State Estimation
377
9.5.2
Entire Hidden State Sequence Estimation
380
9.6
Parameter Estimation in HMM: The EM/Baum–Welch
Technique
384
9.6.1
Parameter Estimation with State Sequence Known
385
9.6.2
Parameter Estimation with State Sequence Unknown
387
9.7
Case Study: Time-Reversal Decoding
390

CONTENTS
xi
9.8
Summary
395
References
396
Problems
398
10
Sequential Bayesian Detection
401
10.1
Introduction
401
10.2
Binary Detection Problem
402
10.2.1
Classical Detection
403
10.2.2
Bayesian Detection
407
10.2.3
Composite Binary Detection
408
10.3
Decision Criteria
411
10.3.1
Probability-of-Error Criterion
411
10.3.2
Bayes Risk Criterion
412
10.3.3
Neyman–Pearson Criterion
414
10.3.4
Multiple (Batch) Measurements
416
10.3.5
Multichannel Measurements
418
10.3.6
Multiple Hypotheses
420
10.4
Performance Metrics
423
10.4.1
Receiver Operating Characteristic (ROC) Curves
424
10.5
Sequential Detection
440
10.5.1
Sequential Decision Theory
442
10.6
Model-Based Sequential Detection
447
10.6.1
Linear Gaussian Model-Based Processor
447
10.6.2
Nonlinear Gaussian Model-Based Processor
451
10.6.3
Non-Gaussian Model-Based Processor
454
10.7
Model-Based Change (Anomaly) Detection
459
10.7.1
Model-Based Detection
460
10.7.2
Optimal Innovations Detection
461
10.7.3
Practical Model-Based Change Detection
463
10.8
Case Study: Reentry Vehicle Change Detection
468
10.8.1
Simulation Results
471
10.9
Summary
472
References
475
Problems
477
11
Bayesian Processors for Physics-Based Applications
484
11.1
Optimal Position Estimation for the Automatic Alignment
484
11.1.1
Background
485
11.1.2
Stochastic Modeling of Position Measurements
487
11.1.3
Bayesian Position Estimation and Detection
489
11.1.4
Application: Beam Line Data
490
11.1.5
Results: Beam Line (KDP Deviation) Data
492
11.1.6
Results: Anomaly Detection
494

xii
CONTENTS
11.2
Sequential Detection of Broadband Ocean Acoustic Sources
497
11.2.1
Background
498
11.2.2
Broadband State–Space Ocean Acoustic Propagators
500
11.2.3
Discrete Normal-Mode State–Space Representation
504
11.2.4
Broadband Bayesian Processor
504
11.2.5
Broadband Particle Filters
505
11.2.6
Broadband Bootstrap Particle Filter
507
11.2.7
Bayesian Performance Metrics
509
11.2.8
Sequential Detection
509
11.2.9
Broadband BSP Design
512
11.2.10 Summary
520
11.3
Bayesian Processing for Biothreats
520
11.3.1
Background
521
11.3.2
Parameter Estimation
524
11.3.3
Bayesian Processor Design
525
11.3.4
Results
526
11.4
Bayesian Processing for the Detection of Radioactive Sources
528
11.4.1
Physics-Based Processing Model
528
11.4.2
Radionuclide Detection
531
11.4.3
Implementation
535
11.4.4
Detection
539
11.4.5
Data
540
11.4.6
Radionuclide Detection
540
11.4.7
Summary
541
11.5
Sequential Threat Detection: An X-ray Physics-Based Approach
541
11.5.1
Physics-Based Models
543
11.5.2
X-ray State–Space Simulation
547
11.5.3
Sequential Threat Detection
549
11.5.4
Summary
554
11.6
Adaptive Processing for Shallow Ocean Applications
554
11.6.1
State–Space Propagator
555
11.6.2
Processors
562
11.6.3
Model-Based Ocean Acoustic Processing
565
11.6.4
Summary
572
References
572
Appendix: Probability and Statistics Overview
576
A.1
Probability Theory
576
A.2
Gaussian Random Vectors
582
A.3
Uncorrelated Transformation: Gaussian Random Vectors
583
References
584
Index
585

PREFACE TO
SECOND EDITION
The second edition of Bayesian Signal Processing incorporates a chapter on “Sequen-
tial Bayesian Detection” (Chapter 10) and a section on “Ensemble Kalman Filters”
(Section 6.7), as well as an expansion of case studies in the inal chapter (Chap-
ter 11). These new “physics-based” studies detail Bayesian approaches to problem
solving in real-world applications incorporating detailed particle ilter designs, adap-
tive particle ilters, and sequential Bayesian detection. In addition to these major
developments, a variety of sections are expanded to “ill in the gaps” of the irst
edition. Here, metrics for particle ilter (PF) designs with emphasis on classical
“sanity tests,” introduced earlier in model-based processors, led to ensemble tech-
niques as a basic requirement for performance analysis. Next, the expansion of
information theory metrics (Kullback–Leibler divergence (KD), Hellinger distance
(HD)) and their application to PF designs is discussed. These “ill-in-the-gap” expan-
sions provide a more cohesive discussion with examples and applications enabling
the comprehension of these alternative approaches to solving estimation/detection
problems.
Detection theory, and more speciically sequential detection theory, is closely
coupled to sequential estimation techniques presented in this text and is often the
primary reason for constructing the estimators in the irst place [1]–[14]. Sequential
techniques ind application in many technical application areas such as radar, sonar
(detection/tracking), biomedical (anomaly detection/localization), speech (recogni-
tion/tracking), communications (real-time/obstructed environments), the sciences
(e.g., seismology (earthquakes), structures (vibrations), materials (additive manu-
facturing/threat detection), radiation (threat detection, etc.), and of course, a huge
variety of military applications [3], [7]. By incorporating a new chapter on sequential
detection techniques primarily aimed at the binary decision problem, we enable the
extension of these estimation methods to an entire class of problems especially when
a physical model is available that can be incorporated into the algorithm [4], [6]. This
new chapter, in itself, will provide wider application, since sequential detection is
such a natural extension to sequential estimation and vice versa.
xiii

xiv
PREFACE TO SECOND EDITION
The ensemble Kalman Filter (EnKF) addition to the second edition is an area
that has been neglected in most non-specialized texts. The EnKF is basically a lit-
tle known hybrid in the engineering area, but well-known in the sciences. It is a
hybrid of a regression-based processor (e.g., unscented Kalman ilter (UKF)) and a
particle-like (PF) “sampling” ilter. The EnKF is well known in science areas where
large-scale computations are required such as seismology, energy systems (wind,
ocean waves, etc.), weather prediction, climatology (global warming), computational
biology, large structures (vibrations), and more because of its computational eficiency
for very large-scale computational problems (super-computer applications). Here, the
coupling of model-based Bayesian techniques to these large-scale problems is unique.
With this in mind, let us consider the construct of the new chapter entitled “Sequen-
tial Bayesian Detection.” Here, we develop the Bayesian approach to decision the-
ory primarily aimed at a coupling of sequential Bayesian estimation to sequential
decision-making. We start with the binary decision problem for multi-channel mea-
surements and develop the usual Bayesian solutions based on probability-of-error
minimization leading to the well-known Bayes’ risk criterion. Next, the Neyman–
Pearson detection approach (maximize detection probability for ixed false-alarm
probability) is developed and compared to the classical Bayesian schemes illustrat-
ing their similarity and differences. Once these “batch schemes” are developed, we
introduce the Wald sequential approach to solving these problems in pseudo real time
[3], [7]. Once developed, we then investigate a variety of performance criteria based
on the receiver operating characteristic (ROC) curve and its variants that provide the
foundations for classical analysis [9], [10]. Other metrics (e.g., area-under-curve, and
so on) associated with the ROC curve are introduced and applied as well. With the
sequential detection theory developed, we investigate the basic linear Gaussian case
and demonstrate that a sequential scheme easily follows when coupled to the model-
based (Kalman) processor. Next, we generalize this approach to nonlinear models and
again under Gaussian-like approximations develop the sequential detection scheme
[7]. Finally, we remove the Gaussian assumptions and show how, using an MCMC
(particle ilter), sequential detection schemes can be developed and applied. A variety
of applications are included in case studies on anomaly/change detection.
Finally, sequential detection enables the inclusion of more relevant case studies
(Chapter 11) in ocean acoustics and physics-based radiation detection as well as X-
ray threat material detection offering a completely different perspective on classical
problem solving incorporating these physics-based approaches from the sequential
Bayesian framework.
James V. Candy
Danville, CA

PREFACE TO SECOND EDITION
xv
REFERENCES
1. S. Kay, Fundamentals of Statistical Signal Processing: Detection Theory (Englewood
Cliffs, NJ: Prentice-Hall, 1998).
2. C. Therrien, Decision, Estimation, and Classiication: An Introduction to Pattern Recog-
nition and Related Topics (New York: John Wiley & Sons, 1989).
3. J. Melsa and D. Cohn, Detection and Estimation Theory (New York: McGraw-Hill, 1978).
4. M. Basseville and I. Nikiforov, Detection of Abrupt Changes: Theory and Application
(Englewood Cliffs, NJ: Prentice-Hall, 1993).
5. F. Gustafasson, Adaptive Filtering and Change Detection (Hoboken, NJ: John Wiley &
Sons, 2000).
6. K. Burnham and D. Anderson, Model Selection and Multimodal Inference (New York:
Springer, 1998).
7. A. Sage and J. Melsa, Estimation Theory with Applications to Communications and
Control (New York: McGraw-Hill, 1971).
8. L. Scharf, Statistical Signal Processing: Detection, Estimation, and Time Series Analysis
(Reading, MA: Addison-Wesley, 1990).
9. H. Van Trees, Detection, Estimation and Modulation Theory, Part 1 (New York: John
Wiley & Sons, 1968).
10. R. Duda, P. Hart, and D. Stork, Pattern Classiication, 2nd Ed. (Hoboken, NJ: John Wiley
& Sons, 2001).
11. A. Gelman, J. Carlin, H. Stern, and D. Rubin, Bayesian Data Analysis (New York:
Chapman & Hall, 2004).
12. J. Hancock and P. Wintz, Signal Detection Theory (New York: McGraw-Hill, 1966).
13. D. Middleton, Introduction to Statistical Communication Theory (New York: McGraw-
Hill, 1960).
14. S. Kassam, Signal Detection in Non-Gaussian Noise (New York: Springer-Verlag, 1988).

PREFACE TO FIRST EDITION
In the real world, systems designed to extract signals from noisy measurements are
plagued by errors evolving from constraints of the sensors employed, random dis-
turbances and noise, and probably, most common, the lack of precise knowledge
of the underlying physical phenomenology generating the process in the irst place!
Methods capable of extracting the desired signal from hostile environments require
approaches that capture all of the a priori information available and incorporate them
into a processing scheme. This approach is typically model-based [1], employing
mathematical representations of the component processes involved. However, the
actual implementation providing the algorithm evolves from the realm of statistical
signal processing using a Bayesian approach based on Bayes’ rule. Statistical sig-
nal processing is focused on the development of processors capable of extracting the
desired information from noisy, uncertain measurement data. This is a text that devel-
ops the “Bayesian approach” to statistical signal processing for a variety of useful
model sets. It features the next generation of processors which have recently been
enabled with the advent of high-speed/high-throughput computers. The emphasis is
on nonlinear/non-Gaussian problems, but classical techniques are included as special
cases to enable the reader familiar with such methods to draw a parallel between the
approaches. The common ground is the model sets. Here, the state–space approach
is emphasized because of its inherent applicability to a wide variety of problems
both linear and nonlinear as well as time invariant and time-varying problems includ-
ing what has become popularly termed “physics-based” models. This text brings
the reader from the classical methods of model-based signal processing including
Kalman iltering for linear, linearized and approximate nonlinear processors as well
as the recently developed unscented or sigma-point ilters to the next generation of
processors that will clearly dominate the future of model-based signal processing for
years to come. It presents a unique viewpoint of signal processing from the Bayesian
perspective in contrast to the pure statistical approach found in many textbooks.
Although designed primarily as a graduate textbook, it will prove very useful to the
practicing signal processing professional or scientist, since a wide variety of appli-
cations are included to demonstrate the applicability of the Bayesian approach to
real-world problems. The prerequisites for such a text is a melding of undergraduate
xvii

xviii
PREFACE TO FIRST EDITION
work in linear algebra, random processes, linear systems, and digital signal process-
ing as well as a minimal background in model-based signal processing illustrated in
the recent text [1]. It is unique in the sense that few texts cover the breadth of its topics,
whereas, the underlying theme of this text is the Bayesian approach that is uniformly
developed and followed throughout in the algorithms, examples, applications, and
case studies. It is this theme coupled with the hierarchy of physics-based models
developed that contribute to its uniqueness. This text has evolved from three previ-
ous texts, Candy [1–3] coupled with a wealth of practical applications to real-world
Bayesian problems.
The Bayesian approach has existed in statistical physics for a long time and can
be traced back to the 1940s with the evolution of the Manhattan project and the
work of such prominent scientists as Ulam, von Neumann, Metropolis, Fermi, Feyn-
man, and Teller. Here the idea of Monte Carlo (MC) techniques to solve complex
integrals evolved [4]. Since its birth, Monte Carlo related methods have been the
mainstay of many complex statistical computations. Many applications have evolved
from this method in such areas as physics, biology, chemistry, computer science, eco-
nomics/inance, material science, statistics and more recently in engineering. Thus,
statisticians have known for a long time about these methods, but their practicali-
ties have not really evolved as a working tool until the advent of high-speed super
computers around the 1980s. In signal processing, it is hard to pinpoint the actual
initial starting point but clearly the work of Handschin and Mayne in the late 1960s
and early 1970s [5, 6] was the initial evolution of Monte Carlo techniques for signal
processing and control. However, from the real-time perspective, it is probably the
development of the sequential Bayesian processor made practical by the work of
Gordon, Salmond, and Smith in 1993 [7] enabling the evolution and the explosion
of the Bayesian sequential processor that is currently being researched today. To put
this text in perspective, we must discuss the current signal processing texts available
on Bayesian processing. Since its evolution much has been published in the statistical
literature on Bayesian techniques for statistical estimation; however, the earliest texts
are probably those of Harvey [8], Kitigawa and Gersch [9], and West [10] which
emphasize the Bayesian model-based approach incorporating dynamic linear or non-
linear models into the processing scheme for additive Gaussian noise sources leading
to the classical approximate (Kalman) iltering solutions. These works extend those
results to nonGaussian problems using Monte Carlo techniques for eventual solu-
tion laying the foundation for works to follow. Statistical MC techniques were also
available, but not as accessible to the signal processor due to statistical jargon and
abstractness of the discussions. Many of these texts have evolved during the 1990s
such as Gilks [11], Robert [12], Tanner [13], Tanizaki [14], with the more up-to-date
expositions evolving in the late 1990s and currently such as Liu [4], Ruanaidh [15],
Haykin [16], Doucet [17], Ristic [18], and Cappe [19]. Also during the last period a
sequence of tutorials and special IEEE issues evolved exposing the MC methods to the
signal processing community such as Godsill [20], Arulampalam [21], Djuric [22],
Haykin [23], Doucet [24], Candy [25], as well as a wealth of signal processing papers
(see references for details). Perhaps the most complete textbook from the statistical

PREFACE TO FIRST EDITION
xix
researcher’s perspective is that of Cappe [19]. In this text, much of the statistical
MC sampling theory is developed along with all of the detailed mathematics—ideal
for an evolving researcher. But what about the entry level person—the engineer, the
experimentalist, and the practitioner? This is what is lacking in all of this literature.
Questions like, how do the MC methods relate to the usual approximate Kalman
methods? How does one incorporate models (model-based methods) into a Bayesian
processor? How does one judge performance compared with classical methods?
These are all basically pragmatic questions that the proposed text will answer in a
lucid manner through coupling the theory to real-world examples and applications.
Thus, the goal of this text is to provide a bridge for the practitioners with enough
theory and applications to provide the basic background to comprehend the Bayesian
framework and enable the application of these powerful techniques to real-world
problem solving. Next, let us discuss the structure of the proposed text in more detail
to understand its composition and approach.
We irst introduce the basic ideas and motivate the need for such processing while
showing that they clearly represent the next generation of processors. We discuss
potential application areas and motivate the requirement for such a generalization.
That is, we discuss how the simulation-based approach to Bayesian processor design
provides a much needed capability, while well known in the statistical community,
not very well known (until recently) in the signal processing community. After intro-
ducing the basic concepts in Chapter 1, we begin with the basic Bayesian processors
in Chapter 2. We start with the Bayesian “batch” processor and establish its con-
struction by developing the fundamental mathematics required. Next we discuss
the well-known maximum likelihood (ML) and minimum (error) variance (MV) or
equivalently minimum mean-squared error (MMSE) processors. We illustrate the
similarity and differences between the schemes. Next, we launch into sequential
Bayesian processing schemes which forms the foundation of the text. By examining
the “full” posterior distribution in both dynamic variables of interest as well as the full
data set, we are able to construct the sequential Bayesian approach and focus on the
usual iltered or iltering distribution case of highest interest demonstrating the fun-
damental prediction/update recursions inherent in the sequential Bayesian structure.
Once establishing the general Bayesian sequential processor (BSP), the schemes that
follow are detailed depending on the assumed distribution with a variety of model
sets.
We briely review simulation-based methods starting with sampling methods,
progressing to Monte Carlo approaches leading to the basic iterative methods of
sampling using the Metropolis, Metropolis-Hastings, Gibb’s, and slice samplers.
Since one of the major motivations of recursive or sequential Bayesian processing
is to provide a real-time or pseudo real-time processor, we investigate the idea of
importance sampling as well as sequential importance sampling techniques leading
to the generic Bayesian sequential importance sampling algorithm. Here we show
the solution can be applied, once the importance sampling distribution is deined.
In order to be useful, Bayesian processing techniques must be speciied through
a set of models that represent the underlying phenomenology driving the particular

xx
PREFACE TO FIRST EDITION
application. For example, in radar processing, we must investigate the propagation
models, tracking models, geometric models, and so forth. In Chapter 4, we develop the
state–space approach to signal modeling which forms the basis of many applications
such as speech, radar, sonar, acoustics, geophysics, communications, control, etc.
Here, we investigate continuous, sampled-data and discrete state–space signals and
systems. We also discuss the underlying systems theory and extend the model-set to
include the stochastic case with noise driving both process and measurements leading
the well-known Gauss–Markov (GM) representation which forms the starting point
for the classical Bayesian processors to follow. We also discuss the equivalence of the
state–space model to a variety of time series (ARMA, AR, MA, etc.) representations
as well as the common engineering model sets (transfer functions, all-pole, all-zero,
pole-zero, etc.). This discussion clearly demonstrates why the state–space model
with its inherent generality is capable of capturing the essence of a broad variety of
signal processing representations. Finally, we extend these ideas to nonlinear state–
space models leading to “approximate” Gauss-Markov representation evolving from
nonlinear, perturbed and linearized systems.
In the next chapter, we develop classical Bayesian processors by irst motivating
the Bayesian approach to the state–space where the required conditional distributions
use the embedded state–space representation. Starting with the linear, time-varying,
state–space models, we show that the “optimum” classical Bayesian processor under
multivariate Gaussian assumptions leads to minimum (error) variance (MV) or equiv-
alently minimum mean-squared error (MMSE), which is the much heralded Kalman
ilter of control theory [1]. That is, simply substituting the underlying Gauss-Markov
model into the required conditional distributions leads directly to the BSP or Kalman
ilter in this case. These results are then extended to the nonlinear state–space repre-
sentation which are linearized using a known reference trajectory through perturbation
theory and Taylor-series expansions. Starting with the linearized or approximate GM
model of Chapter 4, we again calculate the required Bayesian sequential proces-
sor from the conditionals which lead to the “linearized” BSP (or linearized Kalman
ilter) algorithm. Once this processor is developed, it is shown that the “extended”
Bayesian processor follows directly by linearizing about the most currently available
estimate rather than the reference trajectory. The extended Bayesian processor (XBP)
or equivalently extended Kalman ilter (EKF) of nonlinear processing theory evolves
quite naturally from the Bayesian perspective, again following the usual development
by deining the required conditionals, making nonlinear approximations and devel-
oping the posterior distributions under multivariate Gaussian assumptions. Next, we
briely investigate an iterative version of the XBP processor, again from the Bayesian
perspective which leads directly to the iterative version of the extended Bayesian pro-
cessor (IX-BP) algorithm—an effective tool when nonlinear measurements dominate
the uncertain measurements required.
Chapter 6 focuses on statistical linearization methods leading to the modern
unscented Bayesian processor (UBP) or equivalently sigma-point Bayesian processor
(SPBP). Here we show how statistical linearization techniques can be used to trans-
form the underlying probability distribution using the sigma-point or unscented non-
linear transformation technique (linear regression) leading to the unscented Bayesian

PREFACE TO FIRST EDITION
xxi
processor or equivalently the unscented Kalman ilter (UKF). Besides developing the
fundamental theory and algorithm, we demonstrate its performance on a variety of
example problems. We also briely discuss the Gaussian–Hermite quadrature (G-H)
and Gaussian sum (G-S) techniques for completeness.
We reach the heart of the particle iltering methods in Chapter 7, where we discuss
the Bayesian approach to the state–space. Here the ideas of Bayesian and model-based
processors are combined through the development of Bayesian state–space particle
ilters. Initially, it is shown how the state–space models of Chapter 4 are incorporated
into the conditional probability distributions required to construct the sequential
Bayesian processors through importance sampling constructs. After investigating
a variety of importance proposal distributions, the basic set of state-space particle
ilters (SSPF) are developed and illustrated through a set of example problems and
simulations. The techniques including the Bootstrap, auxiliary, regularized MCMC
and linearized particle ilters are developed and investigated when applied to the set
of example problems used to evaluate algorithm performance.
In Chapter 8, the important joint Bayesian SSPF are investigated by irst developing
the joint ilter popularly known as the parametrically adaptive processor [1]. Here
both states and static as well as dynamic parameters are developed as solutions to
this joint estimation problem. The performance of these processors are compared to
classical and modern processors through example problems.
In Chapter 9, the hidden Markov models (HMM) are developed for event-
related problems (e.g., Poisson point processes). This chapter is important in order
to place purely discrete processes into perspective. HMM evolve for any type
of memoryless, counting processes and become important in inancial applica-
tions, communications, biometrics, as well as radiation detection. Here we briely
develop the fundamental ideas and discuss them in depth to develop a set of tech-
niques used by the practitioner while applying them to engineering problems of
interest.
In the inal chapter, we investigate a set of physics-based applications focusing
on the Bayesian approach to solving real-world problems. By progressing through
a step-by-step development of the processors, we see explicitly how to develop and
analyze the performance of such Bayesian processors. We start with a practical laser
alignment problem followed by a broadband estimation problem in ocean acoustics.
Next, the solid-state microelectromechanical (MEM) sensor problem for biothreat
detection is investigated followed by a discrete radiation detection problem based
on counting statistics. All of these methods invoke Bayesian techniques to solve
the particular problems of interest enabling the practitioner the opportunity to track
“real-world” Bayesian model-based solutions.
The place of such a text in the signal processing textbook community can best
be explained by tracing the technical ingredients that comprise its contents. It can
be argued that it evolves from the digital signal processing area primarily from
those texts that deal with random or statistical signal processing or possibly more
succinctly “signals contaminated with noise.” The texts by Kay [26–28], Therrien
[29], and Brown [30] all provide the basic background information in much more
detail than this text, so there is little overlap at the detailed level with them.

xxii
PREFACE TO FIRST EDITION
This text, however, possesses enough theory for the graduate or advanced graduate
student to develop a fundamental basis to go onto more rigorous texts like Jazwinski
[31], Sage [32], Gelb [33], Anderson [34], Maybeck [35], Bozic [36], Kailath [37,
38], and more recently, Mendel [39], Grewel [40], Bar-Shalom [41], and Simon [42].
These texts are rigorous and tend to focus on Kalman iltering techniques ranging
from continuous to discrete with a wealth of detail on all of their variations. The
Bayesian approach discussed in this text certainly includes the state–space models
as one of its model classes (probably the most versatile), but the emphasis is on
various classes of models and how they may be used to solve a wide variety of signal
processing problems. Some of the more recent texts about the same technical level,
but again, with a different focus are Widrow [43], Orfanidis [44], Sharf [45], Haykin
[46], Hayes [47], Brown [30], and Stoica [48]. Again, the focus of these texts is not
the Bayesian approach but the narrow set of speciic models and the development
of a variety of algorithms to estimate these sets. The system identiication literature
and texts therein also provide some overlap with this text, but again the approach is
focused on estimating a model from noisy data sets and not really aimed at developing
a Bayesian solution to a particular signal processing problem. The texts in this area
are Ljung [49, 50], Goodwin [51], Norton [52], and Soderstrom [53].
The recent particle iltering texts of Ristic [18] and Cappe [19] are useful as
references to accompany this text, especially if more details are required on the
tracking problem and the fundamental theorems governing statistical properties and
convergence proofs. That is, Ristic’s text provides an introduction that closely follows
the 2002 tutorial paper by Arulampalam [21] but provides little of the foundational
material necessary to comprehend this approach. It focuses primarily on the tracking
problem. Cappe’s text is at a much more detailed technical level and is written
for researchers in this area not speciically aimed at the practitioner’s viewpoint.
The proposed text combines the foundational material, some theory along with the
practice and application of PF to real-world applications and examples.
The approach we take is to introduce the basic idea of Bayesian signal processing
and show where it its in terms of signal processing. It is argued that BSP is a natural
way to solve basic processing problems. The more a priori information we know about
data and its evolution, the more information we can incorporate into the processor
in the form of mathematical models to improve its overall performance. This is
the theme and structure that echoes throughout the text. Current applications (e.g.,
structures, tracking, equalization, biomedical) and simple examples are incorporated
to motivate the signal processor. Examples are discussed to motivate all of the models
and prepare the reader for further developments in subsequent chapters. In each case,
the processor, along with accompanying simulations, is discussed and applied to
various data sets demonstrating the applicability and power of the Bayesian approach.
The proposed text is linked to the MATLAB (signal processing standard software)
software package providing notes at the end of each chapter.
In summary, this Bayesian signal processing text will provide a much needed
“down-to-earth” exposition of modern MC techniques. It is coupled with well-known
signal processing model sets along with examples and problems that can be used
to solve many real-world problems by practicing engineers and scientists along

PREFACE TO FIRST EDITION
xxiii
with entry-level graduate students as well as advanced undergraduates and post-
doctorates requiring a solid introduction to the “next generation” of model-based
signal processing techniques.
James V. Candy
Danville, CA
REFERENCES
1. J. Candy, Model-Based Signal Processing (Hoboken, NJ: John Wiley & Sons/IEEE Press,
2006).
2. J. Candy, Signal Processing: The Model-Based Approach (New York: McGraw-Hill,
1986).
3. J. Candy, Signal Processing: The Modern Approach (New York: McGraw-Hill, 1988).
4. J. Liu, Monte Carlo Strategies in Scientiic Computing (New York: Springer-Verlag, 2001).
5. J. Handschin and D. Mayne, “Monte Carlo techniques to estimate the conditional expec-
tation in multi-stage nonlinear iltering,” Intl. J. Control, 9, 547–559, 1969.
6. J. Handschin, “Monte Carlo techniques for prediction and iltering of nonlinear stochastic
processes,” Automatica, 6, 555–563, 1970.
7. N. Gordon, D. Salmond, and A. F. M. Smith, “Novel approach to nonlinear/non-Gaussian
Bayesian state estimation,” IEEE Proc. F, 140, 107–113, 1993.
8. A. Harvey, Forecasting, Structural Time Series Models and the Kalman Filter (Cambridge,
UK: Cambridge University Press, 1989).
9. G. Kitagawa and W. Gersch, Smoothness Priors Analysis of Time Series (New York:
Springer-Verlag, 1996).
10. M. West and J. Harrison, Bayesian Forecasting and Dynamic Models, 2nd Ed. (New York:
Springer-Verlag, 1997).
11. W. Gilks, S. Richardson, and D. Spiegelhalter, Markov Chain Monte Carlo in Practice
(New York: Chapman & Hall/CRC Press, 1996).
12. C. Robert and G. Casella, Monte Carlo Statistical Methods (New York: Springer, 1999).
13. M. Tanner, Tools for Statistical Inference: Methods for the Exploration of Posterior Dis-
tributions and Likelihood Functions, 2nd Ed. (New York: Springer-Verlag, 1993).
14. H. Tanizaki, “Nonlinear ilters: estimation and applications,” in Lecture Notes in Eco-
nomics and Mathematical Systems, No. 400, (New York: Springer, 1993).
15. J. Ruanaidh and W. Fitzgerald, Numerical Bayesian Methods Applied to Signal Processing
(New York: Springer-Verlag, 1996).
16. S. Haykin, Kalman Filtering and Neural Networks (Hoboken, NJ: John Wiley & Sons:
2001).
17. A. Doucet, N. de Freitas, and N. Gordon, Sequential Monte Carlo Methods in Practice
(New York: Springer-Verlag, 2001).
18. B. Ristic, S. Arulampalam, and N. Gordon, Beyond the Kalman Filter: Particle Filters for
Tracking Applications (Boston, MA: Artech House, 2004).

xxiv
PREFACE TO FIRST EDITION
19. O. Cappe, E. Moulines, and T. Ryden, Inference in Hidden Markov Models (New York:
Springer-Verlag, 2005).
20. S. Godsill and P. Djuric, “Special Issue: Monte Carlo methods for statistical signal pro-
cessing,” IEEE Trans. Signal Proc., 50, 173–499, 2002.
21. M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp “A tutorial on particle ilters
for online nonlinear/non-gaussian Bayesian tracking,” IEEE Trans. Signal Proc., 50, 2,
174–188, 2002.
22. P. Djuric, J. Kotecha, J. Zhang, Y. Huang, T. Ghirmai, M. Bugallo, and J. Miguez, “Particle
iltering,” IEEE Signal Proc. Mag.20, 5, 19–38, 2003.
23. S. Haykin and N. de Freitas, “Special Issue: sequential state estimation: from Kalman
ilters to particle ilters,” Proc. IEEE, 92, 3, 399–574, 2004.
24. A. Doucet and X. Wang, “Monte Carlo methods for signal processing,” IEEE Signal Proc.
Mag., 24, 5, 152–170, 2005.
25. J. Candy, “Bootstrap particle iltering for passive synthetic aperture in an uncertain ocean
environment,” IEEE Signal Proc. Mag., 24, 4, 63–75, 2007.
26. S. Kay, Modern Spectral Estimation: Theory and Applications (Englewood Cliffs, NJ:
Prentice-Hall, 1988).
27. S. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory (Englewood
Cliffs, NJ: Prentice-Hall, 1993).
28. S. Kay, Fundamentals of Statistical Signal Processing: Detection Theory (Englewood
Cliffs, NJ: Prentice-Hall, 1998).
29. C. Therrian, Random Signal Processing: Detection Theory (Englewood Cliffs, NJ:
Prentice-Hall, 1991).
30. R. Brown and P. Hwang, Introduction to Random Signals and Applied Kalman Filtering
(New York: John Wiley & Sons, 1997).
31. A. Jazwinski, Stochastic Processes and Filtering Theory (New York: Academic Press,
1970).
32. A. Sage and J. Melsa, Estimation Theory with Applications to Communcations and Control
(New York: McGraw-Hill, 1971).
33. A. Gelb, Applied Optimal Estimation (Cambridge, MA: MIT Press, 1974).
34. B. Anderson and J. Moore, Optimum Filtering (Englewood Cliffs, NJ: Prentice-Hall,
1979).
35. P. Maybeck, Stochastic Models, Estimation and Control (New York: Academic Press,
1979).
36. M. S. Bozic, Linear Estimation Theory (Englewood Cliffs, NJ: Prentice-Hall, 1979).
37. T. Kailath, Lectures on Kalman and Wiener Filtering Theory (New York: Springer-Verlag,
1981).
38. T. Kailath, A. Sayed, and B. Hassibi, Linear Estimation (Englewood Cliffs, NJ: Prentice-
Hall, 2000).
39. J. Mendel, Lessons in Estimation Theory for Signal Processing, Communications, and
Control (Englewood Cliffs, NJ: Prentice-Hall, 1995).
40. M. Grewal and A. Andrews, Kalman Filtering: Theory and Practice (Englewood Cliffs,
NJ: Prentice-Hall, 1993).
41. Y. Bar-Shalom and X. Li, Estimation and Tracking: Principles, Techniques and Software
(Boston, MA: Artech House, 1993).

PREFACE TO FIRST EDITION
xxv
42. D. Simon, Optimal State Estimation: Kalman, H∞and Nonlinear Approaches (Hoboken,
NJ: John Wiley & Sons, 2006).
43. B. Widrow and S. Stearns, Adaptive Signal Processing (Englewood Cliffs, NJ: Prentice-
Hall, 1985).
44. S. Orfanidis, Optimal Signal Processing (New York: MacMillan, 1988).
45. L. Sharf, Statistical Signal Processing: Detection, Estimation and Time Series Analysis
(Reading, MA: Addison-Wesley, 1991).
46. S. Haykin, Adaptive Filter Theory (Englewood Cliffs, NJ: Prentice-Hall, 1993).
47. M. Hayes, Statistical Digital Signal Processing and Modeling (Hoboken, NJ: John Wiley
& Sons, 1996).
48. P. Stoica and R. Moses, Introduction to Spectral Analysis (Englewood Cliffs, NJ: Prentice-
Hall, 1997).
49. L. Ljung, System Identiication: Theory for the User (Englewood Cliffs, NJ: Prentice-Hall,
1987).
50. L. Ljung and T.Soderstrom, Theory and Practice of Recursive Identiication (Cambridge,
MA: MIT Press, 1983).
51. G. Goodwin and K. S. Sin, Adaptive Filtering, Prediction and Control (Englewood Cliffs,
NJ: Prentice-Hall, 1984).
52. J. Norton, An Introduction to Identiication (New York: Academic Press, 1986).
53. T. Soderstrom and P. Stoica, System Identiication (New York: Academic Press, 1989).

ACKNOWLEDGMENTS
The unwavering support and encouragement by my wife is the motivational drive
needed to undertake this endeavor, thank you with love to Patricia. My family and
extended family and friends having endured the many regrets, thanks folks. Of course,
the constant support of my great colleagues and friends, especially Drs. M. Horsley,
E. Sullivan, Prof. H. Medeiros, Mr. John Breneman, and Mr. B. Beachamp who
carefully reviewed the manuscript and suggested many improvements cannot go
without a strong acknowledgement.
xxvii

LIST OF ABBREVIATIONS
ABSP
adaptive Bayesian processor
ACC
accuracy
ACS
attenuation coeficient sequence
ADC
analog-to-digital conversion
AIC
Akaike information criterion
ALE
adaptive line enhancer
AMBP
adaptive model-based processor
AR
autoregressive (model)
ARMA
autoregressive moving average (model)
ARMAX
autoregressive moving average exogenous input (model)
AROC
average receiver operating characteristic (curve)
ARX
autoregressive exogenous input (model)
ASIR
auxiliary sequential importance resampling
AUC
area-under-curve (ROC curve)
BP
Bayesian processing
B-R
Bayes’ risk (detector)
BSP
Bayesian signal processing
BW
bandwidth
CD
central difference
CDF
cumulative distribution
CM
conditional mean
CRLB
Cramer–Rao lower bound
C-Sq
Chi-squared (distribution or test)
CT
continuous-time
CTD
concentration-temperature-density (measurement)
EKF
extended Kalman ilter
EM
expectation-maximization
EnBP
ensemble Bayesian processor
EnKF
ensemble Kalman ilter
FN
false negatives
FP
false positives
xxix

xxx
LIST OF ABBREVIATIONS
FPE
inal prediction error
G-H
Gauss–Hermite
GLRT
generalized likelihood-ratio test
G-M
Gaussian mixture
GM
Gauss–Markov
G-S
Gaussian sum
HD
Hellinger distance
HMM
hidden Markov model
HPR
high probability region
IEKF
iterated extended Kalman ilter
i.i.d.
independent-identically distributed (samples)
IXBP
iterated extended Bayesian processor
KD
Kullbach divergence
KL
Kullbach–Leibler
K-S
Kolmogorov–Smirnov statistical test
KSP
Kalman–Szego–Popov (equations)
LBP
linear Bayesian processor
LD
lower-diagonal (matrix) decomposition
LKF
linear Kalman ilter
LMS
least mean square
LS
least-squares
LTI
linear time-invariant (system)
LWR
Levinson–Wiggins–Robinson (algorithm)
LZ-BP
linearized Bayesian processor
LZKF
linearized Kalman ilter
LZ-MBP
linearized model-based processor
MA
moving average (model)
MAICE
minimum Akaike information criterion
MAP
maximum a posteriori
MATLAB®
mathematical software package
MBMFP
model-based matched-ield processor
MBP
model-based processor
MBSP
model-based signal processing
MC
Monte Carlo
MCEM
Monte Carlo expectation-maximization
MCMC
Markov chain Monte Carlo
MDL
minimum data length (description)
MEM
micro-electro-mechanical
M-H
Metropolis–Hastings (sampling)
MIMO
multiple input/multiple output (system)
MinE
minimum probability-of-error
ML
maximum likelihood
MMSE
minimum mean-squared error
MSE
mean-squared error
MV
minimum variance

LIST OF ABBREVIATIONS
xxxi
NETLAB
neural network software package
NMSE
normalized mean-squared error
N-P
Neyman–Pearson (detector)
NPV
negative predictive value
ODP
optimal decision (threshold) point
PDF
probability density function (continuous)
P-E
probability-of-error (detector)
PEM
prediction error method
PF
particle ilter
PHS
pulse height spectrum
PMF
probability mass function (discrete)
PPV
positive predictive value
PRTools
pattern recognition software package
PSD
power spectral density
RC
resistor capacitor (circuit)
REBEL
recursive Bayesian estimation library
RLC
resistor–inductor–capacitor (circuit)
RLS
recursive least-squares
RMS
root mean squared
RMSE
root minimum mean-squared error
ROC
receiver operating characteristic (curve)
RPE
recursive prediction error
RPEM
recursive prediction error method
RPF
regularized particle ilter
SBP
sequential Bayesian processor
SENS
sensitivity
SIG®
signal processing software package
SIR
sequential importance sampling–resampling
SIS
sequential importance sampling
SMC
sequential Markov chain
SNR
signal-to-noise ratio
SPBP
sigma-point Bayesian processor
SPEC
speciicity
SPKF
sigma-point Kalman ilter
SPRT
sequential probability ratio test
SPT
sigma-point transformation
SRBP
square root Bayesian processor
SSIS
sequential sampling importance sampling
SSP
state-space processor
SSPACK®
state-space systems software package
SSPF
state-space particle ilter
SSQE
sum-squared error
SVD
singular value (matrix) decomposition
TN
true negatives
TNR
true negative rate

xxxii
LIST OF ABBREVIATIONS
TP
true positives (detection)
TPR
true positive rate
T/R
time-reversal
UBP
unscented Bayesian processor
UBSP
unscented Bayesian signal processor
UD
upper-diagonal matrix decomposition
UKF
unscented Kalman ilter
UMBP
unscented model-based processor
UT
unscented transform
WSSR
weighted sum-squared residual statistical test
W-Test
whiteness test
XBP
extended Bayesian processor
Z
Z-transform
Z-M
zero-mean statistical test

1
INTRODUCTION
1.1
INTRODUCTION
In this chapter we motivate the philosophy of Bayesian processing from a probabilistic
perspective. We show the coupling between model-based signal processing (MBSP)
incorporating the a priori knowledge of the underlying processes and the Bayesian
framework for specifying the distribution required to develop the processors. The idea
of the sampling approach evolving from Monte Carlo (MC) and Markov chain Monte
Carlo (MCMC) methods is introduced as a powerful methodology for simulating the
behavior of complex dynamic processes and extracting the embedded information
required. The main idea is to present the proper perspective for the subsequent
chapters and construct a solid foundation for solving signal processing problems.
1.2
BAYESIAN SIGNAL PROCESSING
The development of Bayesian signal processing has evolved in a manner proportional
to the evolution of high performance/high throughput computers. This evolution
has led from theoretically appealing methods to pragmatic implementations capable
of providing reasonable solutions for nonlinear and highly multi-modal (multiple
distribution peaks) problems. In order to fully comprehend the Bayesian perspective,
especially for signal processing applications, we must be able to separate our thinking
and in a sense think more abstractly about probability distributions without worrying
about how these representations can be “applied” to realistic processing problems.
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
1

2
INTRODUCTION
Our motivation is to irst present the Bayesian approach from a statistical viewpoint
and then couple it to useful signal processing implementations following the well-
known model-based approach [1, 2]. Here we show that when we constrain the
Bayesian distributions in estimation to Markovian representations using primarily
state–space models, we can construct sequential processors capable of “pseudo real-
time” operations that can easily be utilized in many physical applications. Bayes’
rule provides the foundation of all Bayesian estimation techniques. We show how it
can be used to both theoretically develop processing techniques based on a speciic
distribution (e.g., Poisson, Gaussian, etc.) and then investigate properties of such
processors relative to some of the most well-known approaches discussed throughout
texts in the ield.
Bayesian signal processing is concerned with the estimation of the underlying
probability distribution of a random signal in order to perform statistical inferences
[3]. These inferences enable the extraction of the signal from noisy uncertain mea-
surement data. For instance, consider the problem of extracting the random variate,
say X, from the noisy data, Y. The Bayesian approach is to irst estimate the under-
lying conditional probability distribution, Pr(X|Y), and then perform the associated
inferences to extract ̂X, that is,
̂Pr(X|Y) ⇒̂X = arg max
X
̂Pr(X|Y)
where the caret, ̂X denotes an estimate of X. This concept of estimating the underlying
distribution and using it to extract a signal estimate provides the foundation of
Bayesian signal processing developed in this text.
Let us investigate this idea in more detail. We start with the previous problem of
trying to estimate the random parameter, X, from noisy data Y = y. Then the associ-
ated conditional distribution Pr(X|Y = y) is called the posterior distribution because
the estimate is conditioned “after (post) the measurements” have been acquired.
Estimators based on this a posteriori distribution are usually called Bayesian because
they are constructed from Bayes’ rule, since Pr(X|Y) is dificult to obtain directly.
That is,
Pr(X|Y) = Pr(Y|X) × Pr(X)
Pr(Y)
(1.1)
where Pr(X) is called the prior distribution (before measurement), Pr(Y|X) is called
the likelihood (more likely to be true), and Pr(Y) is called the evidence (scales the
posterior to assure its integral is unity). Bayesian methods view the sought-after
parameter as random possessing a “known” a priori distribution. As measurements
are made, the prior is transformed to the posterior distribution function adjusting the
parameter estimates. Thus, the result of increasing the number of measurements is
to improve the a posteriori distribution resulting in a sharper peak closer to the true
parameter as shown in Fig. 1.1.

1.2
BAYESIAN SIGNAL PROCESSING
3
Prob (X)
Estimated distributions 
Posterior: Pr (X ⎪Y )
Prior: Pr (X)
X-(random parameter)
FIGURE 1.1
Bayesian estimation of the random variate X transforming the prior, Pr(X)
to the posterior, Pr(X|Y) using Bayes’ rule.
When the variates of interest are dynamic, they are functions of time and therefore,
Xt →X and Yt →Y. Bayes’ rule for the joint dynamic distribution is
Pr(Xt|Yt) = Pr(Yt|Xt) × Pr(Xt)
Pr(Yt)
(1.2)
In Bayesian theory, the posterior deined by Pr(Xt|Yt) is decomposed in terms
of the prior Pr(Xt), its likelihood Pr(Yt|Xt), and the evidence or normalizing factor,
Pr(Yt). Bayesian signal processing in this dynamic case follows the identical path,
that is,
̂Pr(Xt|Yt) ⇒̂Xt = arg max
Xt
̂Pr(Xt|Yt)
So we begin to see the versatility of the Bayesian approach to random signal pro-
cessing. Once the posterior distribution is determined, all statistical inferences or
estimates are made. For instance, suppose we would like to obtain the prediction
distribution. Then it can be obtained as
Pr(Xt+1|Yt) = ∫Pr(Xt+1|Xt, Yt) × Pr(Xt|Yt) dXt
and a point estimate might be the conditional mean of this distribution, that is,
E{Xt+1|Yt} = ∫Xt+1Pr(Xt+1|Yt) dXt+1
This relation shows how information that can be estimated from the extracted distri-
bution is applied in the estimation context by performing statistical inferences.

4
INTRODUCTION
Again, even though the Bayesian signal processing concept is simple, conceptually,
the real problem to be addressed is that of evaluating the integrals which is very
dificult because they are only analytically tractable for a small class of priors and
likelihood distributions. The large dimensionality of the integrals causes numerical
integration techniques to break down, which leads to the approximations we discuss
subsequently for stabilization. Next let us consider the various approaches taken
to solve the probability distribution estimation problems using non-parametric or
parametric representations. This will eventually lead to the model-based approach [4].
1.3
SIMULATION-BASED APPROACH TO BAYESIAN PROCESSING
The simulation-based approach to Bayesian processing is founded on MC methods
that are stochastic computational techniques capable of eficiently simulating highly
complex systems. Historically motivated by games of chance and encouraged by the
development of the irst electronic computer (ENIAC), the MC approach was con-
ceived by Ulam (1945), developed by Ulam, Metropolis and von Neumann (1947)
and coined by Metropolis (1949) [5–9]. The method evolved in the mid-1940s dur-
ing the Manhattan project by scientists investigating calculations for atomic weapon
designs [10]. It evolved further from such areas as computational physics, biology,
chemistry, mathematics, engineering, materials and inance to name a few. Monte
Carlo methods offer an alternative approach to solving classical numerical integra-
tion and optimization problems. Inherently, as the dimensionality of the problem
increases, classical methods are prone to failure while MC methods tend to increase
their eficiency by reducing the error—an extremely attractive property. For example,
in the case of classical grid-based numerical integration or optimization problems, as
the number of grid points increase along with the number of problem-deining vector
components, there is an accompanying exponential increase in computational time
[10–15]. The stochastic MC approach of selecting random samples and averaging
over a large number of points actually reduces the computational error by the Law of
Large Numbers irrespective of the problem dimensionality. It utilizes Markov chain
theory as its underlying foundation establishing the concept that through random
sampling the resulting “empirical” distribution converges to the desired posterior
called the stationary or invariant distribution of the chain. MCMC techniques are
based on sampling from probability distributions based on a Markov chain, which
is a stochastic system governed by a transition probability, having the desired pos-
terior distribution as its invariant distribution. Under certain assumptions the chain
converges to the desired posterior through proper random sampling as the number
of samples become large—a crucial property (see Ref. [10] for details). Thus, the
Monte Carlo approach has evolved over a long time period and is well understood
by scientists and statisticians, but it must evolve even further to be useful for signal
processors to become an effective tool in their problem solving repertoire.
Perhaps the best way to visualize the MC methods follows directly from the
example of Frenkel [11]. Suppose that a reasonable estimate of the depth of the Mis-
sissippi river is required. Using numerical quadrature techniques the integrand value is

1.3
SIMULATION-BASED APPROACH TO BAYESIAN PROCESSING
5
Mississippi
Numerical integration
Monte Carlo sampling
Mississippi
FIGURE 1.2
Monte Carlo sampling compared with numerical grid-based integration
for depth of Mississippi estimation.
measured at prespeciied grid points. We also note that the grid points may not be in
regions of interest and, in fact, the integrand may vanish as shown in Fig. 1.2. On the
other hand, the surveyor is in the Mississippi and performing a (random) walk within
the river measuring the depth of the river directly. In this sampling approach mea-
surements are accepted as long as the surveyor is in the river and rejected if outside.
Here the “average” depth is simply the sample average of the measurements much
the same as a sampling technique might perform. So we see that a reinement of the
brute force integration approach is to use random points or samples that “most likely”
come from regions of high contribution to the integral rather than from low regions.
Modern MC techniques such as in numerical integration seek to select random
samples in high regions of concentration of the integrand by drawing samples from
a proposed function very similar to the integrand. These methods lead to the well-
known importance sampling approaches (see Chapter 3). Besides numerical integra-
tion problems that are very important in statistical signal processing for extracting
signals/parameters of interest, numerical optimization techniques (e.g., genetic algo-
rithms and simulated annealing) beneit directly from sampling technology. This
important discovery has evolved ever since and become even more important with
the recent development of high-speed/high-throughput computers.
Consider the following simple example of estimating the area of a circle to illustrate
the MC approach.
Example 1.1
Deine a sample space bounded by a square circumscribing (same center) a circle
of radius r. Draw uniform random samples say z := (X, Y) such that z ∼U(−r, +r);
therefore, the number of random samples drawn from within the circle of radius r to
the number of total samples drawn (bounded by the square) deines the probability
Pr(Z = z) =
No. of circle samples
Total no. of (square) samples

6
INTRODUCTION
From geometry we know that the probability is simply the ratio of the two areas
(circle-to-square), that is,
Pr(Z = z) = �r2
4r2 = �∕4
Let r = 1, then a simple computer code can be written that
r draws the X,Y-coordinates from z ∼U(−1, +1);
r calculates the range function, �=
√
X2 + Y2;
r counts the number of samples that are less than or equal to �;
r estimates the probability, ̂Pr(Z = z).
The area is determined by multiplying the estimated probability by the area of the
square. The resulting sample scatter plot is shown in Fig. 1.3 for a 10,000 sample
realization resulting in �≈3.130. As the number of samples increase the estimate of
the area (�) gets better and better demonstrating the MC approach.
△△△
In signal processing, we are usually interested in some statistical measure of a
random signal or parameter usually expressed in terms of its moments [16–23]. For
example, suppose we have some signal function, say f(X), with respect to some
Area = 3.130
FIGURE 1.3
Area of a circle of unit radius using a Monte Carlo approach (area is esti-
mated as 3.130 using 10, 000 samples).

1.3
SIMULATION-BASED APPROACH TO BAYESIAN PROCESSING
7
underlying probabilistic distribution Pr(X). Then a typical measure to seek is its
performance “on the average” which is characterized by the expectation
EX{f(X)} = ∫f(X) Pr(X) dX
(1.3)
Instead of attempting to use direct numerical integration techniques, stochastic sam-
pling techniques or Monte Carlo integration is an alternative. As mentioned, the key
idea embedded in the MC approach is to represent the required distribution as a set of
random samples rather than a speciic analytic function (e.g., Gaussian). As the num-
ber of samples becomes large, they provide an equivalent (empirical) representation
of the distribution enabling moments to be estimated directly (inference).
MC integration draws samples from the required distribution and then forms
sample averages to approximate the sought after distributions. That is, MC integration
evaluates integrals by drawing samples, {X(i)} from the designated distribution Pr(X).
Assuming perfect sampling, this produces the estimated or empirical distribution
given by
̂Pr(X) ≈1
N
N
∑
i=1
�(X −X(i))
which is a probability mass distribution with weights
1
N and random variable or
sample X(i). Substituting the empirical distribution into the integral gives
EX{f(X)} = ∫f(X) ̂Pr(X) dX ≈1
N
N
∑
i=1
f(X(i)) ≡f
(1.4)
which follows directly from the sifting property of the delta or impulse function. Here
f is said to be a Monte Carlo estimate of EX{f(X)}.
As stated previously, scientists (Ulam, von Neumann, Metropolis, Fermi, Teller,
etc. [7]) created statistical sampling-based or equivalently simulation-based meth-
ods for solving problems eficiently (e.g., neutron diffusion or eigenvalues of the
Schrodinger relation). The MC approach to problem solving is a class of stochastic
computations to simulate the dynamics of physical or mathematical systems captur-
ing their inherent uncertainties. The MC method is a powerful means for generating
random samples used in estimating conditional and marginal probability distributions
required for statistical estimation and therefore signal processing. It offers an alter-
native numerical approach to ind solutions to mathematical problems that cannot
easily be solved by integral calculus or other numerical methods. As mentioned, the
eficiency of the MC method increases (relative to other approaches) as the problem
dimensionality increases. It is useful for investigating systems with a large number of
degrees of freedom (e.g., energy transport, materials, cells, genetics) especially for
systems with input uncertainty [5].

8
INTRODUCTION
Processor
Probability
Data
Particles
Particles
(a)
Particle
(b)
Particle cloud
(c)  Particle filter
(d)  Particle coalescence
(e)  Posterior distribution
FIGURE 1.4
Particle iltering: (a) particle; (b) particle cloud; (c) particle ilter processor;
(d) particle coalescence; (e) posterior distribution.
1.3.1
Bayesian Particle Filter
Before we leave this section, let us introduce the evolution of these ideas to a sequential
version of the sampling approach that is very important in the signal processing area—
the particle ilter. Referring to Fig. 1.4, we start with a single particle or equivalently a
discrete random sample and realize that it is not suficient, so the particle can migrate
into a group or so-called cloud or swarm of particles that can be utilized to develop
a nonparametric characterization of a probability mass function. The key, of course,
is to select particles to drive a model of the underlying process that generates the
parameters of interest. The particle ilter itself is a processor that has data on input
and produces an estimate of the corresponding posterior distribution on output as
depicted in Fig. 1.4 c. These random samples or particles are actually the “location”
parameters along with their associated weights that gather or coalesce in the regions
of highest probabilities (mean, mode, etc.) providing the nonparametric estimate of
the empirical posterior distribution. With these particles generated, the appropriate
weights based on Bayes’ rule are estimated from the data and lead to the desired result

1.4
BAYESIAN MODEL-BASED SIGNAL PROCESSING
9
as illustrated in Fig. 1.4 d. The resulting posterior can be observed through probability
mass function estimation (histogram, kernel density, etc.) as shown in Fig. 1.4 e. Once
the posterior is estimated, then inferences can be performed to extract a wealth of
descriptive statistics characterizing the underlying process.
These concepts have recently evolved to the signal processing area and are of high
interest in nonlinear estimation problems especially in model-based signal processing
applications [16] as discussed next.
1.4
BAYESIAN MODEL-BASED SIGNAL PROCESSING
The estimation of probability distributions required to implement Bayesian proces-
sors is at the heart of this approach. How are these distributions obtained from data or
simulations? Nonparametric methods of distribution estimation ranging from simple
histogram estimators to sophisticated kernel smoothing techniques rooted in classi-
ication theory [3] offer reasonable approaches when data are available. However,
these approaches usually do not take advantage of prior knowledge about the under-
lying physical phenomenology generating the data. An alternative is to parameterize
the required distributions by prior knowledge of their actual form (e.g., exponential,
Poisson, etc.) and it their parameters from data using optimization techniques [3].
Perhaps the ideal realization is the parameterization of the evolution dynamics associ-
ated with the physical phenomenology using underlying mathematical representation
of the process combined with the data samples. This idea provides the essence of the
model-based approach to signal processing which (as we shall see) when combined
with the Bayesian processors provide a formidable tool to attack a wide variety of
complex processing problems in a uniied manner. An alternative view of the underly-
ing processing problem is to decompose it into a set of steps that capture the strategic
essence of the processing scheme. Inherently, we believe that the more a priori knowl-
edge about the measurement and its underlying phenomenology we can incorporate
into the processor, the better we can expect the processor to perform—as long as the
information that is included is correct! One strategy called the model-based approach
provides the essence of model-based signal processing [1].
Simply stated, the model-based approach is “incorporating mathematical models
of both physical phenomenology and the measurement process (including noise) into
the processor to extract the desired information.” This approach provides a mecha-
nism to incorporate knowledge of the underlying physics or dynamics in the form of
mathematical process models along with measurement system models and accom-
panying noise as well as model uncertainties directly into the resulting processor.
In this way the model-based processor (MBP) enables the interpretation of results
directly in terms of the problem physics. It is actually a modeler’s tool enabling the
incorporation of any a priori information about the problem to extract the desired
information. The idelity of the model incorporated into the processor determines
the complexity of the model-based processor with the ultimate goal of increas-
ing the inherent signal-to-noise ratio (SNR). These models can range from simple,
implicit, non-physical representation of the measurement data such as the Fourier

10
INTRODUCTION
or wavelet transforms to parametric black-box models used for data prediction, to
lumped mathematical representation characterized by ordinary differential equations,
to distributed representations characterized by partial differential equation models to
capture the underlying physics of the process under investigation. The dominating
factor of which model is the most appropriate is usually determined by how severe
the measurements are contaminated with noise and the underlying uncertainties. If
the SNR of the measurements is high, then simple non-physical techniques can be
used to extract the desired information; however, for low SNR measurements more
and more of the physics and instrumentation must be incorporated for the extraction.
For instance, consider the example of detecting the presence of a particular species
in a test solution using a microcantilever sensor measurement system [4].
Example 1.2
The model-based processing problem is characterized in Fig. 1.5 representing the
process of estimating the presence of a particular species of material in solution using
the multichannel microcantilever sensor system. Here the microcantilever sensor is
pre-conditioned by depositing attractor material on its levers to attract molecules of
the target species. Once calibrated, the test solution lows along the levers with the
target molecules attracted and deposited on each “tuned” microcantilever creating a
delection that is proportional to the concentration. This delection is measured using
a laser interferometric technique and digitized for processing. The process model is
derived directly from the luidics, while the measurement model evolves from the
dynamics of the microcantilever structure. The resulting processor is depicted in
Fig. 1.6, where we note the mathematical models of both the process dynamics and
Signal extraction
Cantilever
model
Chemistry
model 
Noise
models
MBP
Noise
Raw data 
Chemistry
dynamics
Cantilever
array
measurement  
FIGURE
1.5
Model-based
approach
to
signal
processing: process
(chemistry
and physics), measurement (microcantilever sensor array), and noise (Gaussian)
representations.

500 µm
for l = 1,..,L
Model-based
processor
Raw data 
MB signal
extraction
Parameter fit
( )
( ;
)
( )
( )
( )
T
y t
t
G t
z
t
t
v
=
Γ
Δ
+ Δ
+
l
l
ˆ
ˆ(t–1|t –1) [Free Energy]
ˆ
ˆ
ˆ
ˆ
( ; )
( |
1)
(t)
[Delection]
T
G
t
βl
βl
G t t
= Δ
=
Γ
Δ
–
+ Δz
yl(t|t –1)
ΔG(t |t –1)
ˆ
{1–exp[–(kac (t)+kd)(t–tON)]},
1
,
t<tON
t >tOFF
c(t )+ka/kd
Γ(t ) =
c(t )
tON≤ t ≤tOFF
0,
2kd (t–tOFF)
Concentration 
Chemistry/Physics
Measurements
Noise 
Θ
Θ
Θ
FIGURE 1.6
Model-based processor representation of species detection problem: process (concentration model), measurement
(microcantilever sensor array), raw data, parameter estimator (coeficients), and model-based processor (enhancement).

12
INTRODUCTION
microcantilever measurement system. Since parameters Θ of the model are unknown
a priori calibration data are used to estimate them directly and then they are employed
in the MBP to provide the enhanced signal estimate shown in the igure. Even though
nonlinear and non-Gaussian, the processor appears to yield reasonable estimates. See
Ref. [4] for details.
△△△
The above example demonstrates that incorporating reasonable mathematical mod-
els of the underlying phenomenology can lead to improved processing capability;
however, even further advantages can be realized by combining the MBP concepts in
conjunction with Bayesian constructs to generalize solutions.
Combining Bayesian and model-based signal processing can be considered a
parametric representation of the required distributions using mathematical models of
the underlying physical phenomenology and measurement (sensor) system. Certainly,
if we assume the distribution is Gaussian and further constrain the processes to be
Markovian (only depending on the previous sample), then the multivariate Gaussian
can be completely characterized using state–space models resulting in the well-known
Kalman ilter in the linear model case [2].
Since we are primarily concerned with pseudo real-time techniques in this text, we
introduce the notion of a recursive form leading to the idea of sequential processing
techniques. That is, we investigate “recursive” or equivalently “sequential” solutions
to the estimation problem. Recursive estimation techniques evolved quite naturally
during the advent of the digital computer in the late ifties, since both are sequential
processes. It is important to realize the recursive solution is identical to the batch
solution after it converges, so there is no gain in estimator performance properties;
however, the number of computations is signiicantly less than the equivalent batch
technique. It is also important to realize that the recursive approach provides the
underlying theoretical and pragmatic basis of all adaptive estimation techniques;
thus, they are important in their own right [2]!
Many processors can be placed in a recursive form with various subtleties emerging
in the calculation of the current estimate ( ̂Xold). The standard technique employed
is based on correcting or updating the current estimate as a new measurement data
sample becomes available. The estimates generally take the recursive form:
̂Xne�= ̂Xold + KEne�
(1.5)
where
Ene�= Y −̂Yold = Y −C ̂Xold
Here we see that the new estimate is obtained by correcting the old estimate with
a K-weighted error. The error term Ene�is the new information or innovation—the
difference between the actual and the predicted measurement ( ̂Yold) based on the old
estimate ( ̂Xold). The computation of the weight matrix K depends on the criterion
used (e.g., mean-squared error and absolute error).
Consider the following example, which shows how to recursively estimate the
sample mean.

1.5
NOTATION AND TERMINOLOGY
13
Example 1.3
The sample mean estimator can easily be put in recursive form. The estimator is
given by
̂X(N) = 1
N
N
∑
t=1
y(t)
Extracting the Nth term from the sum, we obtain
̂X(N) = 1
N y(N) + 1
N
N−1
∑
t=1
y(t)
Identify ̂X(N −1) from the last term,
̂X(N) = 1
N y(N) + N −1
N
̂X(N −1)
The recursive form is given by
̂X(N)
⏟⏟⏟
Ne�
= ̂X(N −1)
⏟⏞⏟⏞⏟
Old
+
1
N
⏟⏟⏟
WT
[y(N) −̂X(N −1)]
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
Error
This procedure to develop the “recursive form” is very important and can be applied
to a multitude of processors. Note the steps in determining the form.
1. Remove the Nth term from the summation;
2. Identify the previous estimate in terms of the N −1 remaining terms; and
3. Perform the algebra to determine the gain factor and place the estimator in the
recursive form of Eq. 1.5 for a scalar measurement.
△△△
1.5
NOTATION AND TERMINOLOGY
The notation used throughout this text is standard in the literature. Where necessary,
vectors are represented by boldface, lowercase, x, and matrices by boldface, upper-
case, A. We denote the real part of a signal by Re x and its imaginary part by Im x.
We deine the notation N to be a shorthand way of writing 1, 2, … , N. It will be
used in matrices, A(N) to mean there are N-columns of A. As mentioned previously,
estimators are annotated by the caret, such as ̂x. We also deine partial derivatives at
the component level by
�
��i , the N�- gradient vector by ∇�and higher order partials
by ∇2
�.
The most dificult notational problem will be with the “time” indices. Since this
text is predominantly discrete-time, we will use the usual time symbol, t to mean a

14
INTRODUCTION
discrete-time index, that is, t ∈for the set of integers. However, and hopefully
not too confusing, t will also be used for continuous-time, that is, t ∈for the set
of real numbers denoting the continuum. When used as a continuous-time variable,
t ∈it will be represented as a subscript to distinguish it, that is, xt. This approach of
choosing t ∈primarily follows the system identiication literature and for the ease
of recognizing discrete-time variable in transform relations (e.g., discrete Fourier
transform). The rule-of-thumb is therefore to “interpret t as a discrete-time index
unless noted by a subscript as continuous in the text.” With this in mind we will
deine a variety of discrete estimator notations as ̂x(t|t −1) to mean the estimate
at time (discrete) t based upon all of the previous data up to t −1. We will deine
these symbols prior to their use within the text to assure no misunderstanding of its
meaning.
With a slight abuse of notation, we will use the terminology distribution of X,
Pr(X) in general, so as not to have to differentiate between density for continuous
random variables or processes and mass for discrete variates. It will be obvious from
the context which is meant. In some cases, we will be required to make the distinction
between cumulative distribution function (CDF) and density (PDF) or mass (PMF)
functions. Here we use the uppercase notation, PX(x) for the CDF and lower case
pX(x) for the PDF or PMF.
Subsequently, we will also need to express a discrete PMF as a continuous PDF
using impulse or delta functions as “samplers” much the same as in signal process-
ing when we assume there exists an impulse sampler that leads to the well-known
Nyquist sampling theorem [2]. Thus, corresponding to a discrete PMF we can deine
a continuous PDF through the concept of an impulse sampler, that is, given a discrete
PMF deined by
pX(x) ≈p(X = xi) =
∑
i
pi�(x −xi)
(1.6)
then we deine the equivalent continuous PDF as pX(x). Moments follow from the
usual deinitions associated with a continuous PDF, for instance, consider the dei-
nition of the expectation or mean. Substituting the equivalent PDF and utilizing the
sifting property of the impulse function gives
E{x} = ∫
∞
−∞
xpX(x) dx = ∫
∞
−∞
x
(
∑
i
pi �(x −xi)
)
dx =
∑
i
xipi
(1.7)
which is precisely the mean of the discrete PMF.
Also, as mentioned, we will use the symbol ∼to mean “distributed according to”
as in x ∼(m, �) deining the random variable x as Gaussian distributed with mean
m and variance �. We may also use the extended notation: (x : m, �) to include
the random variable x as well. When sampling we use the non-conventional right
arrow “action” notation →to mean “draw a sample from” a particular distribution
such as xi →Pr(x)—this again will be clear from the context. When resampling, that
is, replacing samples with new ones we use the “block” right arrow such as xj ⇒xi
meaning new sample xj replaces current sample xi.

REFERENCES
15
Finally in a discrete (inite) probabilistic representation, we deine a purely discrete
variate as xk(t) := Pr(x(t) = k) meaning that x can only take on values (integers) k
from a known set = {1, … , k, … , N} at time t. We also use the symbol, △△△
to mark the end of an Example.
MATLAB NOTES
MATLAB is a command-oriented vector-matrix package with a simple yet effec-
tive command language featuring a wide variety of embedded C language con-
structs making it ideal for signal processing applications and graphics. Most of
the algorithms we have applied to the examples and problems in this text are
MATLAB-based in solution ranging from simple simulations to complex appli-
cations. We will develop these notes primarily as a summary to point out to the
reader many of the existing commands that already perform the signal processing
operations discussed in the presented chapter and throughout the text.
REFERENCES
1. J. Candy, Signal Processing: The Model-Based Approach (New York: McGraw-Hill,
1986).
2. J. Candy, Model-Based Signal Processing (Hoboken, NJ: John Wiley & Sons, Inc./IEEE
Press, 2006).
3. R. Duda, P. Hart, and D. Stork, Pattern Classiication (Hoboken, NJ: John Wiley & Sons,
Inc./IEEE Press, 2001).
4. J. Tringe, D. Clague, J. Candy, and C. Lee, “Model-based signal processing of multichannel
cantilever arrays,” IEEE J. Micromech. Syst., 15, 5, 1371–1391, 2006.
5. S. Ulam, R. Richtmyer, and J. von Neumann, “Statistical methods in neutron diffusion,”
Los Alamos Scientiic Laboratory Report, LAMS-551, 1947.
6. N. Metropolis and S. Ulam, “The Monte Carlo method,” J. American Stat. Assoc., 44,
335–341, 1949.
7. N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller, “Equations of state
calculations by fast computing,” J. Chem. Phys., 21, 6, 1087–1091, 1953.
8. W. Hastings, “Monte Carlo sampling methods using Markov chains and their applications,”
Biometrika, 57, 1, 97–109, 1970.
9. N. Metropolis, “The beginning of the Monte Carlo method,” Los Alamos Sci., Special
Issue, 125–130, 1987.
10. J. Liu, Monte Carlo Strategies in Scientiic Computing (New York: Springer-Verlag,
2001).
11. D. Frenkel, “Introduction to Monte Carlo methods,” in Computational Soft Matter: From
Synthetic Polymers to Proteins, edited by N. Attig, K. Binder, H. Grubmuller, and
K. Kremer (John von Neumann Institute for Computing, 2004), NIC Series, Vol. 23,
pp. 29–60.
12. C. Robert and G. Casella, Monte Carlo Statistical Methods (New York: Springer, 1999).

16
INTRODUCTION
13. M. Tanner, Tools for Statistical Inference: Methods for the Exploration of Posterior Dis-
tributions and Likelihood Functions, 2nd Ed. (New York: Springer-Verlag, 1993).
14. J. Ruanaidh and W. Fitzgerald, Numerical Bayesian Methods Applied to Signal Processing
(New York: Springer-Verlag, 1996).
15. W. Gilks, S. Richardson, and D. Spiegelhalter, Markov Chain Monte Carlo in Practice
(New York: Chapman & Hall/CRC Press, 1996).
16. A. Doucet, N. de Freitas, and N. Gordon, Sequential Monte Carlo Methods in Practice
(New York: Springer-Verlag, 2001).
17. B. Ristic, S. Arulampalam, and N. Gordon, Beyond the Kalman Filter: Particle Filters for
Tracking Applications (Boston: Artech House, 2004).
18. O. Cappe, E. Moulines, and T. Ryden, Inference in Hidden Markov Models (New York:
Springer-Verlag, 2005).
19. S. Godsill and P. Djuric, “Special issue: Monte Carlo methods for statistical signal pro-
cessing.” IEEE Trans. Signal Proc., 50, 173–499, 2002.
20. P. Djuric, J. Kotecha, J. Zhang, Y. Huang, T. Ghirmai, M. Bugallo, and J. Miguez, “Particle
iltering,” IEEE Signal Proc. Mag., 20, 5, 19–38, 2003.
21. S. Haykin and N. de Freitas, “Special issue: sequential state estimation: from Kalman
ilters to particle ilters.” Proc. IEEE, 92, 3, 399–574, 2004.
22. A. Doucet and X. Wang, “Monte Carlo methods for signal processing,” IEEE Signal Proc.
Mag., 24, 5, 152–170, 2005.
23. J. Candy, “Bootstrap particle iltering for passive synthetic aperture in an uncertain ocean
environment.” IEEE Signal Proc. Mag., 24, 4, 73–85, 2007.
PROBLEMS
1.1
Estimate the number of times a needle when dropped between two parallel lines
intersects a line. One way to accomplish this is experimentally by setting up
the experiment and doing it—this is the famous Buffon’s needle experiment
performed in 1725.
(a) Set up the experiment and perform the measurements for 100 samples.
Estimate the underlying probabilities.
(b) Analyze the experiment using a “closed form” approach.
(c) How do your answers compare?
Note that this is one of the irst Monte Carlo approaches to problem solving.
1.2
Suppose we have three loaded dice with the following six “face” probabilities
(each):
D1 =
{ 1
12, 1
6, 1
12, 1
3, 1
6, 1
6
}
D2 =
{1
6, 1
6, 1
6, 1
12, 1
12, 1
3
}
D3 =
{1
6, 1
6, 1
6, 1
12, 1
12, 1
3
}

PROBLEMS
17
Applying Bayes’ rule, answer the following questions:
(a) Selecting a die at random from the three, what is the probability of rolling
a 6?
(b) What is the probability that die two (D = D2) was selected, if a six (R = 6)
is rolled with the chosen die?
1.3
A binary communication transmitter (T) sends either a 0 or a 1 through a channel
to a receiver (R) with the following probabilities for each as:
Pr(T1) = 0.6
Pr(T0) = 0.4
Pr(R1|T1) = 0.9
Pr(R0|T1) = 0.1
Pr(R1|T0) = 0.1
Pr(R0|T0) = 0.9
(a) What is the probability that R1 is received?
(b) What is the probability that R0 is received?
(c) What is the probability that the true transmitted signal was a 1, when a 1
was received?
(d) What is the probability that the true transmitted signal was a 0, when a
0 was received?
(e) What is the probability that the true transmitted signal was a 1, when a
0 was received?
(f) What is the probability that the true transmitted signal was a 0, when a 1
was received?
(g) Draw a probabilistic directed graph with nodes being the transmitters
and receivers and links being the corresponding prior and conditional
probabilities?
1.4
We are asked to estimate the displacement of large vehicles (semi-trailers)
when parked on the shoulder of a freeway and subjected to wind gusts created
by passing vehicles. We measure the displacement of the vehicle by placing an
accelerometer on the trailer. The accelerometer has inherent inaccuracies which
is modeled as
y = Kax + n
with y, x, n the measured and actual displacement and white measurement noise
of variance Rnn and Ka the instrument gain. The dynamics of the vehicle can be
modeled by a simple mass-spring-damper.
(a) Construct and identify the measurement model of this system.
(b) Construct and identify the process model and model-based estimator for
this problem.

18
INTRODUCTION
1.5
Think of measuring the temperature of a liquid in a beaker heated by a burner.
Suppose we use a thermometer immersed in the liquid and periodically observe
the temperature and record it.
(a) Construct a measurement model assuming that the thermometer is linearly
related to the temperature, that is, y(t) = k △T(t). Also model the uncertainty
of the visual measurement as a random sequence �(t) with variance R��.
(b) Suppose we model the heat transferred to the liquid from the burner as
Q(t) = CA △T(t)
where C is the coeficient of thermal conductivity, A is the cross-sectional area,
and △T(t) is the temperature gradient with assumed random uncertainty �(t)
and variance R��. Using this process model and the models developed above,
identify the model-based processor representation.
1.6
We are given an RLC series circuit driven by a noisy voltage source Vin(t) and
we use a measurement instrument that linearly ampliies by K and measures the
corresponding output voltage. We know that the input voltage is contaminated
by an additive noise source �(t) with covariance R��and the measured output
voltage is similarly contaminated with noise source �(t) with R��.
(a) Determine the model for the measured output voltage Vout(t) (measurement
model).
(b) Determine a model for the circuit (process model).
(c) Identify the general model-based processor structures. In each scheme,
specify the models for the process, measurement, and noise.
1.7
A communications satellite is placed into orbit and must be maneuvered using
thrusters to orientate its antennas. Restricting the problem to the single axis
perpendicular to the page, the equations of motion are
J d2�
dt2 = Tc + Td
where J is the moment of inertia of the satellite about its center of mass, Tc is
the thruster control torque, Td is the disturbance torque, and �is the angle of the
satellite axis with respect to the inertial reference (no angular acceleration) A.
Develop signal and noise models for this problem and identify each model-based
processor component.
1.8
Consider a process described by a set of linear differential equations
d2c
dt2 + dc
dt + c = Km

PROBLEMS
19
The process is to be controlled by a proportional-integral-derivative (PID) con-
trol law governed by the equation
m = Kp
(
e + 1
Ti ∫e dt + Td
de
dt
)
and the controller reference signal r is given by
r = e + c
Suppose the reference is subjected to a disturbance signal and the measurement
sensor, which is contaminated with additive noise, measures the “square” of the
output. Develop the model-based signal and noise models for this problem.
1.9
The elevation of a tracking telescope is controlled by a DC motor. It has a
moment of inertia J and damping B due to friction, the equation of motion is
given by
J d2�
dt2 + Bd�
dt = Tm + Td
where Tm and Td are the motor and disturbance torques and �is the elevation
angle. Assume a sensor transforms the telescope elevation into a proportional
voltage that is contaminated with noise. Develop the signal and noise models
for the telescope and identify all of the model-based processor components.
1.10 Suppose we have a two-measurement system given by
y =
[
3
4
]
+ �
where R��= diag[1, 0.1].
(a) What is the batch least-squares estimate (W = I) of the parameter x, if
y = [7
21]′?
(b) What is the batch weighted least-squares estimate of the parameter x with
W selected for minimum variance estimation?
1.11 Calculate the batch and sequential least-squares estimate of the parameter vector
x based on two measurements y(1) and y(2) where
y(1) = C(1)x + �(1) =
[
2
1
]
y(2) = c′x + �(2) = 4
C =
[
1
1
0
1
]
,
c′(1) = [1
2],
W = I

2
BAYESIAN ESTIMATION
2.1
INTRODUCTION
In this chapter we motivate the idea of Bayesian estimation from probabilistic per-
spective, that is, we perform the required estimation using the underlying densities
or mass functions. We start with the “batch” approach and evolve to the Bayesian
sequential techniques. We discuss the most popular formulations: maximum a pos-
teriori (MAP), maximum likelihood (ML), minimum variance (MV) or equivalently
minimum mean-squared error (MMSE) and least-squares (LS) methods. Bayesian
sequential techniques are then developed. The main idea is to develop the proper
perspective for the subsequent chapters and construct a solid foundation for the
techniques to follow.
2.2
BATCH BAYESIAN ESTIMATION
Suppose we are trying to estimate a random parameter X from data Y = y. Then the
associated conditional density Pr(X|Y = y) is called the posterior density because
the estimate is conditioned “after (post) the measurements” have been acquired.
Estimators based on this a posteriori density are usually called Bayesian because they
are constructed from Bayes’ theorem, since Pr(X|Y) is dificult to obtain directly.
That is, Bayes’ rule is deined,
Pr(X|Y) := Pr(Y|X)Pr(X)
Pr(Y)
(2.1)
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
20

2.2
BATCH BAYESIAN ESTIMATION
21
where Pr(X) is called the prior density (before measurement), Pr(Y|X) is called the
likelihood (more likely to be true) and Pr(Y) is called the evidence (normalizes the
posterior to assure its integral is unity). Bayesian methods view the sought-after
parameter as random possessing a “known” a priori density. As measurements are
made, the prior is converted to the posterior density function adjusting the parameter
estimates. Thus, the result of increasing the number of measurements is to improve
the a posteriori density resulting in a sharper peak closer to the true parameter as
depicted in Fig. 1.1.
To solve the estimation problem, the irst step requires the determination of the
a posteriori density. A logical solution to this problem leads us to ind the “most
probable” value of Pr(X|Y)—its maximum [1]. The MAP estimate is the value of x
that maximizes the posterior density, that is,
max
X
Pr(X|Y)
(2.2)
The optimization is carried out in the usual manner by differentiating, setting the
result to zero and solving to obtain the MAP equation
∇XPr(X|Y)|||X= ̂XMAP
= 0
(2.3)
with the gradient vector ∇X ∈RNX×1 deined by
∇X :=
[
�
�X1
⋯
�
�XNX
]′
(2.4)
Because many problems are based on the exponential class of densities, the
ln Pr(X|Y) is considered instead. Since the logarithm is a monotonic function,
the maximum of Pr(X|Y) and ln Pr(X|Y) occur at the same value of X. Therefore, the
logarithmic MAP equation is
∇X ln Pr(X|Y)|||X= ̂XMAP
= 0
(2.5)
Now, if we apply Bayes’ rule to Eq. 2.5, then
ln Pr(X|Y) = ln Pr(Y|X) + ln Pr(X) −ln Pr(Y)
(2.6)
Since Pr(Y) is not a function of the parameter X, the MAP equation can be written
succinctly as
∇X ln Pr(X|Y)|||X= ̂XMAP = ∇X(ln Pr(Y|X) + ln Pr(X))|||X= ̂XMAP = 0
(2.7)

22
BAYESIAN ESTIMATION
With a variety of estimators available, we must construct some way of ascertaining
performance. The quality of an estimator is usually measured in terms of its estimation
error,
̃X = X −̂X
(2.8)
A common measure of estimator quality is called the Cramer–Rao lower bound
(CRLB). The CRLB offers a means of assessing estimator quality prior to processing
the measured data. We restrict discussion of the CRLB to the case of unbiased
estimates ̂X of a “nonrandom” parameter X. The bound is easily extended to more
complex cases for biased estimates as well as random parameters [2, 3]. The Cramer–
Rao lower bound1 for any unbiased estimate ̂X of X based on the measurement Y is
given by
R ̃X|X = cov(X −̂X(Y)|X = x) ≥−1
(2.9)
where , the NX × NX information matrix, is deined by
:= −Ey{∇X(∇X ln Pr(Y|X))′}
(2.10)
with the gradient vector deined above. Any estimator satisfying the CRLB with
equality is called eficient. The bound is easily calculated using the chain rule from
vector calculus [4] deined by
∇X(a′b) := (∇Xa′)b + (∇Xb′)a
a, b ∈RNX×1
(2.11)
where a, b are functions of X. Consider the following example illustrating the calcu-
lation of the CRLB.
Example 2.1
Suppose we would like to estimate a nonrandom but unknown parameter X from a
measurement y contaminated by additive Gaussian noise, that is,
y = X + �
where �∼(0, R��) and X is unknown. Thus, we have that
E{Y|X} = E{X + �|X} = X
and
var(Y|X) = E{(y −E{Y|X})2|X} = E{�2|X} = R��
1 We choose the matrix-vector version, since parameter estimators are typically vector estimates.

2.3
BATCH MAXIMUM LIKELIHOOD ESTIMATION
23
which gives
Pr(Y|X) ∼(X, R��)
and therefore
ln Pr(Y|X) = −1
2 ln(2�R��) −1
2
(y −X)2
R��
Differentiating according to the chain rule of Eq. 2.11 and taking the expectation, we
obtain
= −E
{
�2
�X2 ln Pr(Y|X)
}
= −E
{
�
�X
(y −X)
R��
}
=
1
R��
and therefore the CRLB is
R ̃X|X ≥R��
△△△
The utility of the CRLB is twofold: (1) it enables us to measure estimator quality
because it indicates the “best” (minimum error covariance) that any estimator can
achieve, and (2) it allows us to decide whether or not a designed estimator is eficient,
that is, any estimator achieving the CRLB with equality is eficient—a desirable
statistical property.
In summary, the properties of an estimator can be calculated prior to estimation
(in some cases), and these properties can be used to answer the question “how well
does this estimator perform?” Next, we consider the case when the parameter X is
not random, leading to the maximum likelihood estimator.
2.3
BATCH MAXIMUM LIKELIHOOD ESTIMATION
In contrast to the Bayesian approach, the likelihood method views the parameter
as deterministic but unknown. We include it in the Bayesian discussion because as
we will show, both estimators are in fact intimately linked. Maximum likelihood
produces the “best” estimate as the value which maximizes the probability of the
measurements given that the parameter value is “most likely” true. In the estimation
problem, the measurement data are given along with the underlying structure of
the probability density function (as in the Bayesian case), but the parameters of the
density are unknown and must be determined from the measurements; therefore,
the maximum likelihood estimate can be considered heuristically as that value of the
parameter that best “explains” the measured data giving the most likely estimation.
More formally, let X be a vector of unknown parameters, X ∈RNX×1 and the corre-
sponding set of N-conditionally independent measurements, Y(N) := {y(1) ⋯y(N)}
for y ∈RNy×1. The likelihood of X given the measurements is deined to be

24
BAYESIAN ESTIMATION
proportional to the value of the probability density of the measurements given the
parameters, that is,
(Y(N); X) ∝Pr(Y(N)|X) = Pr(y(1) ⋯y(N)|X) =
N
∏
i=1
Pr(y(i)|X)
(2.12)
where is the likelihood function and Pr(Y|X) is the joint probability density func-
tions of the measurements given the unknown parameters. This expression indicates
the usefulness of the likelihood function in the sense that in many applications,
measurements are available and are assumed drawn as a sample from a “known” or
assumed known probability density function with unknown parameters (e.g., Poisson
with unknown mean). Once we have the measurements (given) and the likelihood
function, we would like to ind the best estimate of the parameters. If we search
through the parameter space over various values of X, say Xi, then we select the value
of ̂X that most likely speciies the underlying probability function that the measure-
ment sample was drawn from, that is, suppose we have two estimates, ̂Xi and ̂Xj for
which
Pr(Y|Xi) > Pr(Y|Xj)
(2.13)
Thus, it is “more likely” that the Y(N) were drawn for parameter value ̂Xi than ̂Xj,
since, equivalently, (Y; ̂Xi) > (Y; ̂Xj). Searching over all X and selecting that value
of X that is maximum (most probable) leads to the maximum likelihood estimate
(ML) given by
̂XML(Y) = arg max
X
Pr(Y|X)
(2.14)
As noted previously, many problems are characterized by the class of exponential
densities for the Bayesian estimator making it more convenient to use the natural
logarithm function; therefore, we deine the log-likelihood function as
Λ(Y(N)|X) := ln(Y; X) = lnPr(Y(N)|X)
(2.15)
Since the logarithm is monotonic, it preserves the maximum of the likelihood pro-
viding the identical result,
̂XML(Y) = arg max
X
ln Pr(Y|X)
(2.16)
What makes the ML estimator popular is the fact that it enjoys some very desirable
properties that we list without proof (see Ref. [2] for details).
1. ML estimates are consistent.
2. ML estimates are asymptotically eficient with R ̃X|X = −1.

2.3
BATCH MAXIMUM LIKELIHOOD ESTIMATION
25
3. ML estimates are asymptotically Gaussian with (X, R ̃X ̃X).
4. ML estimates are invariant, that is, if ̂XML, then any function of the ML estimate
is the ML estimate of the function, ̂fML = f( ̂XML).
5. ML estimates of the suficient statistic are equivalent to the ML estimates over
the original data.
These properties are asymptotic and therefore imply that a large amount of data must
be available for processing.
Mathematically, the relationship between the MAP and ML estimators is clear
even though philosophically they are quite different in construct. If we take the MAP
relation of Eq. 2.6 and ignore the a priori distribution Pr(X) (assume X is unknown
but deterministic), then the ML estimator is only a special case of MAP. Using the
same arguments as before, we use the ln Pr(X|Y) instead of Pr(X|Y). We obtain the
ML estimate by solving the log-likelihood equation and checking for the existence
of a maximum; that is,
∇X ln Pr(X|Y)|||X= ̂XML = 0
(2.17)
Of course, to check for a maximum we have that ∇X(∇X ln Pr(X|Y)′) < 0. Again
applying Bayes’ rule as in Eq. 2.1 and ignoring Pr(X), we have
∇X ln Pr(X|Y) = ∇X ln Pr(Y|X)|||X= ̂XML
= 0.
(2.18)
Consider the following example to demonstrate this relationship between MAP
and ML.
Example 2.2
Consider estimating an unknown constant, from a noisy measurement as in the
previous example. Further, assume that the noise is an independent Gaussian random
variable such that �∼N(0, R��) and the measurement model is given by
y = X + �
(2.19)
First, we assume no a priori statistical knowledge of X just that it is an unknown,
nonrandom constant. Thus, we require the ML estimate, since no prior information
is assumed about Pr(X). The associated conditional density is
Pr(Y|X) =
1
√
2�R��
e
−1
2
( y−X)2
R��
(2.20)
The ML estimate of X is found by solving the log-likelihood equation
∇X ln Pr(Y|X)|||X= ̂XML = 0
(2.21)

26
BAYESIAN ESTIMATION
or
�
�X ln Pr(Y|X) = �
�X
{
−1
2 ln 2�R��−
1
2R��
(y −X)2
}
=
1
R��
(y −X)
Setting this expression to zero and solving for X, we obtain
̂XML = y
(2.22)
The best estimate of X in a maximum likelihood sense is the raw data y. The corre-
sponding error variance is easily calculated (as before),
R ̃X|X = R��
(2.23)
Next, we model X as a random variable with Gaussian prior, that is, X ∼N(X, RXX)
and desire the MAP estimate. The MAP equation is
MAP = ∇X(ln Pr(Y|X) + ln Pr(X))
MAP = �
�X
{
−1
2 ln 2�R��−
1
2R��
(y −X)2 −1
2 ln 2�RXX −
1
2(X −X)2
RXX
}
or
MAP =
1
R��
(y −X) −
1
RXX
(X −X)
Setting this expression to zero and solving for X = ̂XMAP, we obtain
̂XMAP =
y + R��
RXX X
1 + R��
RXX
It can be shown from Eq. 2.9 that the corresponding error variance is
R ̃X|X =
R��
1 + R��
RXX
Examining the results of this example, we see that when the parameter variance is
large (RXX ≫R��), the MAP and ML estimates perform equivalently. However, when
the variance is small, the MAP estimator performs better because the corresponding
error variance is smaller.
△△△

2.3
BATCH MAXIMUM LIKELIHOOD ESTIMATION
27
The main point to note is that the MAP estimate provides a mechanism to incor-
porate the a priori information, while the ML estimate does not. Therefore, for some
problems, MAP is the eficient estimator. In the above example, if X were actually
Gaussian, then the ML solution, which models X as an unknown parameter, is not
an eficient estimator, while the MAP solution that incorporates this information by
using the prior Pr(X) is eficient.
This completes the introduction to batch Bayesian estimation using the MAP and
ML estimation. Next, we consider a very popular approach to solving ML estimation
problems.
2.3.1
Expectation–Maximization Approach
to Maximum Likelihood
Solving maximum likelihood parameter estimation problems is a formidable task
especially when the underlying probability distribution functions are unknown.
Therefore, we must resort to numerical approaches that will successfully converge
to the parameters of interest. Expectation–maximization (EM) is a general method
of determining the ML estimate of parameters of the underlying distribution from
a given set of data which is incomplete, that is, having “missing” (data) values [5].
Missing data could be considered a misnomer; however, if we include “hidden vari-
ables” (not directly measured) as missing, then a wide variety of state/parameter
estimation problems can be incorporated into these problem classes. Probably the
most popular applications of the EM technique occur in tomographic image recon-
struction, pattern recognition, communications and the training of hidden Markov
models (see Chapter 9) for speech recognition [6, 7].
The EM technique produces maximum likelihood parameter estimates in two
steps: an expectation step followed by a maximization step. The expectation step
with respect to the unknown parameters uses the most recently available parameter
estimate conditioned on the measurements, while the maximization step provides an
updated estimate of the parameters.
To be more precise, we mathematically formulate the general “missing data”
problem by irst deining the unknown parameters or variables to be estimated as
�∈N�×1 with �∈Θ, the parameter space. We further deine three distinct spaces
for our problem: (1) the complete data space, ; (2) the incomplete data space, ; and
(3) the missing data space, , where the complete space is the union: = (, ).
Analogously, we deine the corresponding complete, incomplete, and missing/hidden
vectors as: z ∈Nz×1, y ∈Ny×1, and x ∈Nx×1, respectively.
With this in mind, we can now deine the underlying distributions as the joint or
complete distribution along with its Bayesian decompositions as
Pr(z|�) = Pr(x, y|�) = Pr(x|y, �) × Pr(y|�) = Pr(y|x, �) × Pr(x|�)
(2.24)
or taking logarithms, we have the complete (data) log-likelihood
ΛCD(z|�) = ln Pr(z|�) = ln Pr(x, y|�) = ln Pr(x|y, �) + ΛID(y|�)
(2.25)

28
BAYESIAN ESTIMATION
where ΛID(y|�) = ln Pr(y|�) is the corresponding incomplete (data) log-likelihood
and the missing data is random with x ∼Pr(x). Since x is random, then so is ΛCD(z|�)
with y and �assumed ixed (constant). Thus, the basic maximum likelihood parameter
estimation problem for the complete data is to ind the value of the parameter such that
̂�i = arg max
�
ΛCD(z|�)
given the measured or observed (incomplete) data y and the previous parameter
estimate �= ̂�. However, since ΛCD is random, we must search for the parameter
vector that maximizes its expectation (over x), that is, we seek
̂�i = arg max
�
Ex{ΛCD(z|�)}
(2.26)
given the measured data y and the current parameter estimate �. Multiplying both
sides of Eq. 2.25 by the underlying marginal posterior distribution of the missing
data, Pr(x|y, �) and summing over x, we obtain
∑
x
ΛCD(z|�) × Pr(x|y, �) =
∑
x
ln Pr(z|�) × Pr(x|y, �)
=
∑
x
ln Pr(x|y, �) × Pr(x|y, �)
+
∑
x
ΛID(y|�) × Pr(x|y, �)
Using the deinition of the conditional expectation and recognizing that the last term
is not a function of the random vector x, we obtain
Ex{ΛCD(z|�)|y, ̂�} = Ex{ln Pr(x|y, ̂�)} + ΛID(y| ̂�)
(2.27)
Since we do not know the complete data, we cannot calculate the exact log-
likelihood for this problem. But, given the measured data y, we can estimate the
posterior probability for the missing (data) variables x. For each x, there exists a ̂�,
and therefore we can calculate an expected value of the complete log-likelihood.
The basic EM principle is to ind the �that maximizes Pr(z|�) using the available
data y and current parameter estimate. Let ̂�i−1 be the current parameter estimate,
then the complete log-likelihood is given by the expectation step:
E-step:
Q(�, ̂�i−1) := Ex{ΛCD(z|�)|y, ̂�i−1}
(2.28)
for �the new parameter vector to be optimized in the next step. In this expression
the y and ̂�are assumed ixed (constant) and x is the random vector such that
x ∼Pr(x|y, ̂�i−1) so that
Ex{ΛCD(z|�)|y, ̂�i−1} =
∑
x
ln Pr(x|y, �)Pr(x|y, ̂�i−1)
(2.29)

2.3
BATCH MAXIMUM LIKELIHOOD ESTIMATION
29
where Pr(x|y, ̂�i−1) is the marginal of the missing data (hidden variable) based on the
measured data and current parameter estimate (as shown).
The maximization step is to ind the parameter vector update, ̂�i that will maximize
the computed expectation, that is,
M-step:
̂�i = arg max
�
Q(�, ̂�i−1)
(2.30)
Each iteration is guaranteed to increase the log-likelihood eventually converging
to a local maximum at an exponential rate [8, 9]. Different forms of the EM have
evolved with the “generalized” EM (GEM) method by inding an alternative (simpler)
expectation function and using the updated parameter vector such that Q( ̂�i, ̂�i−1) >
Q(�, ̂�i−1) which is also guaranteed to converge. The Monte Carlo EM (MCEM) is
another form that is used when a closed form distribution for the E-step is replaced
by simulation-based methods (sampling) [10]. Consider the following example from
Snyder [11].
Example 2.3
Suppose we would like to estimate the rate or intensity parameter �s of a signal
contaminated in Poisson noise with known mean ��. We measure the counts from a
photodetector characterized by
yn = sn + �n
where yn is the observation with Poisson distribution
yn ∼(�y) = (�y)yn e−�y∕yn!
The respective signal and noise counts during the measurement period are indepen-
dent of each other with sn ∼(�s) and �n ∼(��). We have that the log-likelihood
of the incomplete data is
ΛID(yn|�y) = ln (yn|�y) = yn ln �y −�y −ln yn!
Differentiating ΛID with respect to �s, setting to the result to zero and solving for
the rate parameter, that is,
d
d�s
(yn ln(�s + ��) −(�s + ��) −ln yn!) =
yn
�s + ��
−1 = 0
which yields the maximum likelihood parameter estimate
̂�s = yn −��> 0
Here we have used the fact that the superposition of Poisson processes is Poisson
with intensity parameter, �y = �s + ��. Next, let us investigate the EM approach to

30
BAYESIAN ESTIMATION
this problem. Here the complete data space is zn = (sn, �n) and yn is the incomplete
(observed) data. Therefore, we have that the complete log-likelihood is
ΛCD(zn|�s) = −(�s + ��) + sn ln �s + �n ln ��−ln sn! −ln �n!
because sn and �n are independent. Thus, the expectation step is given by
E-step:
Q(�s| ̂�s(i −1)) = −�s + ̂sn(i −1) ln �s −��+ ̂�n(i −1) ln ��
with
̂sn(i −1) = E{sn|yn, ̂�s(i −1)} =
̂�s(i −1)
̂�s(i −1) + ��
yn
and
̂�n(i −1) = E{�n|yn, ̂��(i −1)} = yn −̂sn(i −1)
Since the maximization step does not depend on ��or ̂�n(i −1), we have
̂�s(i) = arg max
�s
(−�s + ̂sn(i −1) ln �s)
giving
M-step:
̂�s(i) = ̂sn(i −1)
which completes the EM algorithm.
We simulated a sequence of Poisson counts for 500 samples composed of the
additive signal (�s = 14) and noise (�N = 3.5). The estimated signal intensity at
each measurement is shown in Fig. 2.1a along with the estimated probability mass
functions in 2.1b of the true signal, EM-estimated signal, measurement and noise.
Here we see the estimated signal PDF closely matches the true PDF and the average
intensity is very close to the true signal intensity at �s = 14.02.
△△△
In summary, the EM approach is a two-step, iterative technique to solve the
maximum likelihood parameter estimation problem when missing data or hidden
variables (states) are present. Clearly, we have just discussed the generic form of
the EM approach, the actual algorithm is problem-speciic, based on the knowledge
of the underlying distributions; however, we can consider a class of distributions to
develop a more speciic algorithm such as the so-called exponential family [12].
2.3.2
EM for Exponential Family of Distributions
In this subsection we apply the EM technique to the exponential class of distribu-
tion functions, many of which are well-known forms like the Gaussian, Poisson,

2.3
BATCH MAXIMUM LIKELIHOOD ESTIMATION
31
0
50
100
150
200
250
300
350
400
450
500
0
5
10
15
20
25
30
Sample No.
Intensity estimate
–5
0
5
10
15
20
25
30
35
40
0
0.05
0.1
0.15
0.2
0.25
Signal
Noise
Intensity
Probability
Measurement
EM Est
PDF estimates 
Estimated signal intensity: mean = 14.02
(a)
(b)
FIGURE 2.1
EM estimation for Poisson intensity: (a) signal intensity estimate (mean =
14.02);(b) PDF estimation of Poisson processes:noise,signal,EM estimate,measurement.
exponential, Raleigh, binomial, and more. The exponential family is deined by the
generic form:
Pr(z|�) = b(z) exp(c′(�)s(z))∕a(�)
(2.31)
with �∈N�, the parameters deining the class [5, 13, 14] and s(z), the suficient
statistic providing all of the information necessary about the underlying process for
estimation with s, c ∈Ns×1. Since the complete log-likelihood can be written as
ΛCD(z|�) = ln Pr(z|�) = ln b(z) + c′(�)s(z) −ln a(�)
(2.32)

32
BAYESIAN ESTIMATION
taking the conditional expectations, we obtain the expectation step as:
E-step:
Q(�, ̂�i−1) = Ex{ln b(z)|y, �) + c′(�)E{s(z)|y, ̂�i−1} −ln a(�)
(2.33)
Deining ̂si := E{s(z)|y, ̂�i−1}, the maximization step with respect to �, is performed
on
E{ln b(z)|y, �) + c′(�)̂si −ln a(�)
(2.34)
Since the irst term is not a function of �, it need not be included. The EM technique
for the exponential family is:
E-step:
̂si
M-step:
̂�i = arg max
�
c′(�)̂si −ln a(�)
(2.35)
completing the method.
For instance, in the previous example, we have b(z) = (�y)yn; exp(c′s) = e−�y and
a(�) = yn!. Consider the following example of producing an image by estimating the
intensity of a Poisson process discussed in McLachlan [15].
Example 2.4
Photons emitted from a radioactive tracer are injected into tissue in order to create a
single photon emission computed tomography (SPECT) image for medical diagnosis
[11, 13–15]. The basic idea is to create an image that represents the photon emitted,
counted by photon detectors and displayed as an image based on pixel counts. For
simplicity, we assume all photons are counted by the instrument. The emissions are
assumed to be Poisson-distributed with unknown intensities or emission densities
corresponding to the Poisson rate parameters �. Thus, the basic problem is:
GIVEN a set of incomplete measurements (counts), {yn}, FIND the maximum
likelihood estimate of the unknown emission densities, �, (rate parameter vector)
assuming that each of these component intensities is constant within a pixel, that is,
�m is constant for m = 1, … , Mp.
Let yn; n = 1, … , Nd be the number of counts measured by the nth detector, so
mathematically the problem is to estimate the Mp-intensity vector of emission densi-
ties, ̂�, from the Nd-measurement vector y assuming that the counts are conditionally
independent such that Pr(yn|�y(n)) is Poisson, that is,
yn ∼(�y(n)) =
(�y(n))yn e−�y(n)
yn!
For imaging considerations, it is assumed that individual photons are emitted
within a given pixel and detected; therefore, we deine xnm as the unobservable

2.3
BATCH MAXIMUM LIKELIHOOD ESTIMATION
33
counts (missing data), assuming �is known and conditionally independent of x, such
that,
xmn ∼(�x(m, n)) = (�x(m, n))xnm e−�x(m,n)
xnm!
where �x(m, n) = �mpmn, the emission density corresponding to the number of pho-
tons emitted in the mth pixel detected by the nth detector with emission probability
pmn—a marked Poisson process [11, 16, 17].
The photon counter measurement at the nth detector is the superposition of the
photons emitted by the radionuclide at the mth pixel; therefore, we have
yn =
Mp
∑
m=1
xmn
which is the sum of Poisson variates, so that
�y(n) =
Mp
∑
m=1
�x(m, n) =
Mp
∑
m=1
�mpmn
It has been shown [15] that the conditional probability of the missing data is binomial
with parameter yn and probability Pr(�mpmn), that is,
xmn ∼(yn, Pr(�mpmn))
with Pr(�mpmn) = �mpmn
/ Mp
∑
j=1
�ipjn
The EM approach for this problem is straightforward, since the underlying distri-
butions are all in the exponential family [15]. The suficient statistic is the data xmn
which can be estimated. That is, since xmn is binomial, the conditional mean (Q-step)
is given by
̂xmn(i −1) := E{xmn|yn, ̂�m(i −1)} = yn
⎛
⎜
⎜⎝
̂�x(m, n)
/ Mp
∑
j=1
̂�x(j, n)
⎞
⎟
⎟⎠
where ̂�x(m, n) = ̂�m(i −1)pmn. Next, deine the likelihood based on z = (x, y) assum-
ing �is known and conditionally independent. Therefore, the complete likelihood is
given by
(x, y|�) =
∏
m,n
e−�x(m,n) (�x(m, n))xmn∕xmn!

34
BAYESIAN ESTIMATION
and
Λ(x, y|�) =
∑
m,n
−�x(m, n) + xnm ln �x(m, n) −ln xnm!
or substituting for �x(m, n) and expanding, we have
Λ(x, y|�) =
Mp
∑
m=1
Nd
∑
n=1
−�mpnm + xnm ln(�mpnm) −ln xnm!
Differentiating this expression with respect to �m, setting to the result zero and
solving gives the maximization step as
̂�m(i) =
Nd
∑
n=1
̂xmn(i −1)
Summarizing the E- and M-steps for this problem,
E-step:
Q(�m, ̂�m(i −1) = Ex{Λ(x, y)|y, ̂�m(i −1))}
= yn ̂�m(i −1)pmn
/ Mp
∑
j=1
̂�j(i −1)pjn
M-step: ̂�m(i) = ̂�m(i −1)
Nd
∑
n=1
⎛
⎜
⎜⎝
ynpmn
∑Mp
j=1 ̂�j(i −1)pjn
⎞
⎟
⎟⎠
More details can be found in Refs. [11], [13], and [15].
△△△
This completes our discussion of the EM approach to parameter estimation
problems with incomplete data/parameters. Next, we briely describe one of the
most popular approaches to the estimation problem—MV or equivalently MMSE
estimation.
2.4
BATCH MINIMUM VARIANCE ESTIMATION
To complete this discussion evolving from the batch Bayesian perspective, we discuss
the development of the minimum (error) variance (MV) or equivalently MMSE
estimator. The general techniques developed in this section can be applied to develop
various model-based processors [1].
Suppose we are asked to obtain an estimate of a Nx-parameter vector X from a set
of noisy measurements characterized by the Ny-measurement vector Y. We would
like to construct an estimate that is best or optimal in some sense. The most natural

2.4
BATCH MINIMUM VARIANCE ESTIMATION
35
criterion to consider is one that minimizes the error between the true parameter and
its estimate based on the measured data. The error variance criterion is deined by
J(X) = EX{[X −̂X(Y)]′[X −̂X(Y)]|Y}
(2.36)
where
X
is the true random Nx-vector
Y
is the measured random Ny-vector (data)
̂X
is the estimate of X given Y
whose minimization leads to the minimum variance estimator [1]. Thus, if we mini-
mize J(X) using the chain rule of Eq. 2.11, then we have
∇̂XJ(X) = Ex{∇̂X(X −̂X(Y))′(X −̂X(Y))|Y}
= Ex{−(X −̂X(Y)) −(X −̂X(Y))|Y}
= −2[Ex{X −̂X(Y)|Y}]
performing the conditional expectation operation gives
∇̂XJ(X) = −2[Ex{X|Y} −̂X(Y)]
(2.37)
and setting this equation to zero and solving yields the minimum variance estimate
as
̂XMV = ̂X(Y) = Ex{X|Y}
(2.38)
We check for the global minimum by examining the sign (positive) of the second
derivative, and since
∇̂X(∇̂XJ(X))′ = 2I
(2.39)
a unique minimum exists. Thus, the minimum variance estimator is the conditional
mean. The associated error variance is determined by substituting for ̂X(Y) into
Eq. 2.36 giving
JMV = R ̃X|Y = Ex{(X −E{X|Y})′(X −E{X|Y})|Y}
= Ex{X′X|Y} −E2
x{X|Y}
(2.40)
This estimator is linear, unconditionally and conditionally unbiased and possesses
general orthogonality properties. To see this, we investigate the estimation error
deined by
̃X = X −̂X(Y)
(2.41)

36
BAYESIAN ESTIMATION
Taking expectations, we have the fact that the estimator is unconditionally unbiased,
Ex{ ̃X} = Ex{X −̂X(Y)} = Ex{X} −Ex{Ex{X|Y}} = Ex{X} −Ex{X} = 0
(2.42)
as well as conditionally unbiased, since
Ex{ ̃X|Y} = Ex{X −̂X(Y)|Y} = Ex{X|Y} −Ex{Ex{X|Y}|Y}
= Ex{X|Y} −Ex{X|Y} = 0
(2.43)
Another important property of the minimum variance estimator is that the estimation
error is orthogonal to any function, say f(⋅), of the data vector Y [18], that is,
ExY{ f(Y) ̃X′} = 0
(2.44)
Also,
Ex{f(Y) ̃X′|Y} = 0
(2.45)
This is the well-known orthogonality condition. To see this we substitute for the error
Ex{ f(Y) ̃X′|Y} = Ex{f(Y)(X −̂X(Y))′|Y}
= f(Y)Ex{(X −̂X(Y))′|Y}
= f(Y)(Ex{X|Y} −̂X(Y)′) = 0
Taking the expectation over Y proves the unconditional result as well. Thus, the
estimation error is orthogonal to any function of Y, a fact that is used in proofs
throughout the literature for both linear and nonlinear estimators.
Let us now investigate the special case of the linear minimum variance estimator.
The estimation error is orthogonal to all past data Y, that is,
EXY{Y ̃X′} = 0
(2.46)
or as before
EX{Y ̃X′|Y} = 0
(2.47)
This is the well-known minimum variance estimator that results in the linear case [1].
For a linear function of the parameter, we have that
y = CX + �
(2.48)
where y, �, ∈RNy×1, X ∈RNx×1, C ∈RNy×Nx and �is zero-mean, white with R��. The
mean-squared error criterion
J(X) = E{ ̃X′ ̃X}
(2.49)

2.5
SEQUENTIAL BAYESIAN ESTIMATION
37
is minimized to determine the estimate. The minimization results in the orthogonality
condition of Eq. 2.47 which we write as
E{y ̃X′} = E{yX′} −E{y ̂X′
MV} = 0
(2.50)
for ̂XMV = KMVy, a linear function of the data vector. Substituting for y and ̂X in this
equation,
KMV = RXXC′(CRXXC′ + R��)−1
(2.51)
where RXX is the covariance matrix of X. The corresponding quality is obtained as
R ̃X ̃X = (R−1
XX + C′R−1
��C)−1
(2.52)
It is also interesting to note that the fundamental Wiener result [1] is easily obtained
from the orthogonality condition of Eq. 2.47, that is,
E{y ̃X′} = E{yX′} −E{yy′}K′
MV = RyX −RyyK′
MV = 0
(2.53)
which is called the discrete Wiener equation. Solving for KMV, we obtain the Wiener
solution for a linear (batch) estimation scheme, that is,
KMV = RXyR−1
yy
(2.54)
Note that least-squares estimation is similar to that of minimum variance except that
no statistical information (expectation removed) is assumed known about the process,
that is, the least-squares estimator, ̂yLS minimizes the sum-squared error criterion
min
̂y J = ̃y′̃y =
∑
i
̃y2
i
(2.55)
for ̃y = y −̂yLS.
This completes the introduction to batch minimum variance, maximum a posteriori
and maximum likelihood estimation. Next, we consider the sequential problem.
2.5
SEQUENTIAL BAYESIAN ESTIMATION
Modern statistical signal processing techniques evolve directly from a Bayesian per-
spective, that is, they are cast into a probabilistic framework using Bayes’ theorem
as the fundamental construct. More speciically, the information about the random
signal, x(t), required to solve a vast majority of estimation/processing problems is
incorporated in the underlying probability distribution generating the process. For
instance, the usual signal enhancement problem is concerned with providing the

38
BAYESIAN ESTIMATION
“best” (in some sense) estimate of the signal at time t based on all of the data avail-
able at that time. The iltering distribution provides that information directly in terms
of its underlying statistics. That is, by calculating the statistics of the process directly
from the iltering distribution, the enhanced signal can be extracted using a variety of
estimators like MAP, ML or MMSE, accompanied by a set of performance statistics
such as error covariances and bounds. Sequential methods to calculate these distribu-
tions become extremely important in pragmatic problems where implementation and
speed are an issue. Therefore from an engineering perspective, they are our primary
focus.
The roots of this theory are based on Bayesian estimation—in fact, sequential
Bayesian estimation. We will see that many of our well-known techniques are easily
cast into this unifying framework, especially in the nonlinear signal processing area.
The Bayesian algorithms that provide posterior distribution estimates are optimal;
however, they are impossible to implement directly because they require integrations
or summations with an ininite number of terms. We will develop the optimal Bayesian
algorithms mathematically and perform the required calculations in a sequential
manner, but it must be realized that only under certain restricted circumstances
can these actually be realized (e.g., the linear Gaussian case). Starting with Bayes’
theorem, it is possible to show how this leads directly to a recursive or sequential
estimation framework that is the foundation of these new approaches.
We cast this discussion into a dynamic variable/parameter structure by dein-
ing the “unobserved” signal or equivalently “hidden” variables as the set of Nx-
vectors, {x(t)}, t = 0, … , N. On the other hand, we deine the observables or equiv-
alent measurements as the set of Ny-vectors, {y(t)}, t = 0, … , N considered to be
conditionally independent of the signal variables. The goal in recursive Bayesian
estimation is to sequentially (in-time) estimate the joint posterior distribution,
Pr(x(0), … , x(N); y(0), … , y(N)). Once the posterior is estimated, many of the inter-
esting statistics characterizing the process under investigation can be exploited to
extract meaningful information.
We start by deining two sets of random (vector) processes: Xt := {x(0), … , x(t)}
and Yt := {y(0), … , y(t)}, as before. Here we can consider Xt to be the set of dynamic
random variables or parameters of interest and Yt as the set of measurements or
observations of the desired process as before.2 In any case, we start with Bayes’
theorem for the joint posterior distribution as
Pr(Xt|Yt) = Pr(Yt|Xt) × Pr(Xt)
Pr(Yt)
(2.56)
In Bayesian theory (as before), the posterior deined by Pr(Xt|Yt) is decomposed
in terms of the prior Pr(Xt), its likelihood Pr(Yt|Xt) and the evidence or normalizing
factor Pr(Yt). Each has a particular signiicance in this construct which we shall
discuss subsequently.
2 In Kalman iltering theory, the Xt are considered the states or hidden variables not necessarily observable
directly, while the Yt are observed or measured directly.

2.5
SEQUENTIAL BAYESIAN ESTIMATION
39
We can replace the evidence by realizing that it is the total probability given by
Pr(Yt) = ∫Pr(Yt|Xt)Pr(Xt) dXt
(2.57)
which is integrated over the entire Xt-dimensional parameter space. Substituting this
into Eq. 2.56 we obtain
Pr(Xt|Yt) =
Pr(Yt|Xt) × Pr(Xt)
∫Pr(Yt|Xt)Pr(Xt) dXt
(2.58)
Once the posterior distribution is determined, all statistical inferences or estimates
are made by integration or equivalently summation. For example, suppose we would
like to obtain a prediction distribution, then it is obtained as
Pr(Xt+1|Yt) = ∫Pr(Xt+1|Xt, Yt) × Pr(Xt|Yt) dXt
and a point estimate might be the conditional mean of this distribution, that is,
E{Xt+1|Yt} = ∫Xt+1Pr(Xt+1|Yt) dXt+1
while the variance of the distribution can be calculated similarly and used for perfor-
mance evaluation. This calculation illustrates how information that can be estimated
from the extracted distribution is applied in the estimation context.
Again, even though simple conceptually, the real problem to be addressed is that
of evaluating these integrals which is very dificult because they are only analyt-
ically tractable for a small class of priors and likelihood distributions. The large
dimensionality of the integrals cause numerical integration techniques to break down
which leads to the approximations we discuss subsequently for stabilization. Let us
investigate further to consider posing problems of signal processing interest. First,
we review some of the basics.
Many of the derivations and algorithms to follow are based on the simple, but
sometimes not so obvious, manipulations of Bayes’ theorem; therefore, we develop
these variants here irst. Starting with a joint distribution of variables indexed by t,
we apply Bayes’ rule3 in steps to expose some of the manipulations:
Pr(y(t), y(t −1), y(t −2)) = Pr(y(t), y(t −1)|y(t −2)) × Pr(y(t −2))
(2.59)
Applying the rule again to the irst term in this expression gives
Pr(y(t), y(t −1)|y(t −2)) = Pr(y(t)|y(t −1), y(t −2)) × Pr(y(t −1)|y(t −2))
(2.60)
3 In set notation, we have (simply) that
Pr(ABC) = Pr(AB|C) × Pr(C) = [Pr(A|BC) × Pr(B|C)] × Pr(C)

40
BAYESIAN ESTIMATION
Combining these results, we have
Pr(y(t), y(t −1), y(t −2)) = Pr(y(t)|y(t −1), y(t −2))
× Pr(y(t −1)|y(t −2)) × Pr(y(t −2))
(2.61)
Additionally, if {y(t)} is considered irst-order Markov, then Eq. 2.61 simpliies
even further to
Pr(y(t), y(t −1), y(t −2)) = Pr(y(t)|y(t −1)) × Pr(y(t −1)|y(t −2))
× Pr(y(t −2))
(2.62)
Generalizing these expansions, we can obtain the chain rule of probability which
states that the joint distribution Yt can be decomposed using Bayes’ rule as
Pr(Yt) = Pr(y(t)|Yt−1) × Pr(Yt−1) = Pr(y(t)|Yt−1) × Pr(y(t −1)|Yt−2) × Pr(Yt−2)
or expanding this expression, we obtain
Pr(Yt) =
t∏
k=0
Pr(y(t −k)|Yt−k−1)
= Pr(y(t)|Yt−1) × ⋯× Pr(y(1)|Y0) × Pr(y(0))
(2.63)
Further assuming that the process is Markov,
Pr(y(t)|Yt−1) = Pr(y(t)|y(t −1))
and the chain rule simpliies even further to
Pr(Yt) =
t∏
k=0
Pr(y(t −k)|Yt−k−1) =
t∏
k=0
Pr(y(t −k)|y(t −k −1))
(2.64)
Marginal distributions are used throughout these derivations and they follow
directly from the Chapman–Kolmogorov evolution equation [17], that is,
Pr(y(t)|y(t −2)) = ∫Pr(y(t)|y(t −1)) × Pr(y(t −1)|y(t −2)) dy(t −1)
(2.65)
Before we close this section, we must mention that the derivations to follow rely
on the following two fundamental assumptions:
r the dynamic variable x(t) is Markov; and
r the data y(t) are conditionally independent of the past dynamic variables, {x(t −
k)}∀k > 0.
Next, we proceed with the development of generic Bayesian processors.

2.5
SEQUENTIAL BAYESIAN ESTIMATION
41
2.5.1
Joint Posterior Estimation
With this information in mind, we develop the sequential Bayesian solution to the joint
posterior estimation problem. Starting with Eq. 2.56, we decompose this expression
by irst extracting the tth term from the joint distributions, that is,
Pr(Yt|Xt) = Pr(y(t), Yt−1|x(t), Xt−1)
and applying Bayes’ rule to obtain
Pr(Yt|Xt) = Pr(y(t)|Yt−1, x(t), Xt−1) × Pr(Yt−1|x(t), Xt−1)
(2.66)
The data at time t, y(t), is assumed independent of Xt−1 and Yt−1; therefore, the
irst term of Eq. 2.66 simpliies to
Pr(y(t)|x(t), Yt−1, Xt−1) ⟶Pr(y(t)|x(t))
(2.67)
The second term also simpliies based on the independence of the past data and
x(t) to give
Pr(Yt−1|x(t), Xt−1) ⟶Pr(Yt−1|Xt−1)
(2.68)
We now have the inal expression for the likelihood as
Pr(Yt|Xt) = Pr(y(t)|x(t)) × Pr(Yt−1|Xt−1)
(2.69)
Similarly, for the prior, extracting the tth term and applying the rule, we obtain
Pr(Xt) = Pr(x(t), Xt−1) = Pr(x(t)|Xt−1) × Pr(Xt−1)
Assuming x(t) is a irst-order Markov process, this expression simpliies to
Pr(Xt) = Pr(x(t)|x(t −1)) × Pr(Xt−1)
(2.70)
Finally the evidence is obtained in a similar manner to give
Pr(Yt) = Pr(y(t), Yt−1) = Pr(y(t)|Yt−1) × Pr(Yt−1)
(2.71)
Therefore, substituting these results into Eq. 2.56, we obtain
Pr(Xt|Yt) =
Pr(Yt|Xt)
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
[Pr(Yt−1|Xt−1) × Pr(y(t)|x(t))]
Pr(Xt)
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
[Pr(x(t)|x(t −1)) × Pr(Xt−1)]
Pr(y(t)|Yt−1) × Pr(Yt−1)
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
Pr(Yt)
(2.72)

42
BAYESIAN ESTIMATION
but the posterior at the previous time, t −1, is given by
Pr(Xt−1|Yt−1) = Pr(Yt−1|Xt−1) × Pr(Xt−1)
Pr(Yt−1)
(2.73)
Identifying the terms on the right-hand side of Eq. 2.72 and grouping them together
enables the joint sequential Bayesian posterior estimator to be expressed as
Pr(Xt|Yt) =
[Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
Pr(y(t)|Yt−1)
]
× Pr(Xt−1|Yt−1)
(2.74)
This result is satisfying in the sense that we need only know the joint posterior
distribution at the previous stage, t −1, scaled by a weighting function to sequentially
propagate the posterior to the next stage, that is,
Ne�
⏞⏞⏞⏞⏞
Pr(Xt|Yt) =
Weight
⏞⏞⏞⏞⏞⏞⏞⏞⏞
(t, t −1) ×
Old
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(Xt−1|Yt−1)
(2.75)
where the weight is deined by
(t, t −1) :=
[Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
Pr(y(t)|Yt−1)
]
The sequential Bayesian processor is shown diagrammatically in Fig. 2.2. Even
though this expression provides the full joint posterior solution, it is not physically
realizable unless the distributions are known in closed form and the underlying
multiple integrals or sums can be analytically determined. In fact, a more useful
solution is the marginal posterior distribution.
2.5.2
Filtering Posterior Estimation
In this subsection, we develop a more realizable Bayesian processor for the posterior
distribution of the random x(t). Instead of requiring that the posterior possess the
Pr[X0|Y0]
Pr[X1|Y1]
Pr[Xt–1|Yt–1]
Pr[Xt|Yt]
Pr[y(t) | x(t)] × Pr[x(t) | x(t–1)]
Pr[Xt | Yt ] = W (t,t –1) × Pr[Xt–1|Yt–1]
Pr[y(t)|Yt–1]
;  t = 1,...,N
W(t,t–1) : =
where the Baye,s operator is deined at each stage by
W(1,0)
W(t – 1,t – 2)
W(t,t – 1)
⇒
⇒
⇒
⇒
⇒
⇒
FIGURE 2.2
Sequential Bayesian processor for joint posterior distribution.

2.5
SEQUENTIAL BAYESIAN ESTIMATION
43
entire set of dynamic variables, Xt, we need only restrict our attention to the current
variable at time t. That is, for signal enhancement, we would like to estimate
Pr(x(t)|Yt) where we restrict our attention to the value of the parameter based on
all of the available measurements at time t. We start with the prediction recursion
“marginalizing” the joint posterior distribution
Pr(x(t)|Yt−1) = ∫Pr(x(t), x(t −1)|Yt−1) dx(t −1)
Applying Bayes’ rule to the integrand yields
Pr(x(t), x(t −1)|Yt−1) = Pr(x(t)|x(t −1), Yt−1) × Pr(x(t −1)|Yt−1)
or
Pr(x(t), x(t −1)|Yt−1) = Pr(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1)
(2.76)
where the inal expression evolves from the irst-order Markovian assumption. Apply-
ing the Chapman–Kolmogorov equation, the prediction recursion can be written as
Pr(x(t)|Yt−1) = ∫Pr(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1) dx(t −1)
(2.77)
Examining the update or correction equation based on the iltering relation and
applying Bayes’ rule, we have
Pr(x(t)|Yt) = Pr(x(t), Yt)
Pr(Yt)
= Pr(x(t), y(t), Yt−1)
Pr(y(t), Yt−1)
Again applying the rule to this relation gives
Pr(x(t)|Yt) = Pr(y(t)|x(t), Yt−1) × Pr(x(t)|Yt−1) × Pr(Yt−1)
Pr(y(t)|Yt−1) × Pr(Yt−1)
(2.78)
Canceling like terms in numerator and denominator and applying the Markov
assumption, we obtain the inal expression for the update recursion4 as
Posterior
⏞⏞⏞⏞⏞⏞⏞
Pr(x(t)|Yt) =
Likelihood
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(y(t)|x(t)) ×
Prior
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(x(t)|Yt−1)
Pr(y(t)|Yt−1)
⏟⏞⏞⏞⏞⏟⏞⏞⏞⏞⏟
E�idence
(2.79)
4 Note that this expression precisely satisies Bayes’ rule as illustrated in the equation.

44
BAYESIAN ESTIMATION
Predict:
Correct:         
∫
Pr[x(t–1)|Yt–1]
Pr[x(t)|x(t–1)]Pr[x(t –1)|Yt–1]dx (t –1)
Pr[y(t) | x(t)]
Pr[x(t)|Yt–1]
Pr[x(t)|Yt–1] =
WC(t t
Pr[x t )|
(
–1)
Yt–1]
Pr
,
[x(t)|Yt] =
Pr[y(t)|Yt–1]
Pr[x(t )|Yt]
Predict
∫
∫
Predict
Correct
WC(t, t –1)
Correct
WC(t, t –1)
WC(t, t–1) :=
y(t)
y(t–1)
FIGURE 2.3
Sequential Bayesian processor for iltering posterior distribution.
where we can consider the update or iltering distribution as a weighting of the
prediction distribution as in the full joint case above, that is,
Update
⏞⏞⏞⏞⏞⏞⏞
Pr(x(t)|Yt) =
Weight
⏞⏞⏞⏞⏞⏞⏞⏞⏞
c(t, t −1) ×
Prediction
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(x(t)|Yt−1)
(2.80)
where the weight in this case is deined by
c(t, t −1) := Pr(y(t)|x(t))
Pr(y(t)|Yt−1)
The resulting processor is shown diagrammatically in Fig. 2.3.
We summarize the sequential Bayesian processor in Table 2.1.
TABLE 2.1
Sequential Bayesian (Filtering) Processor
Prediction
Pr(x(t)|Yt−1) = ∫Pr(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1) dx(t −1)
[Prediction]
where
Pr(x(t)|x(t −1))
[Transition probabliity]
Correction/Update
Pr(x(t)|Yt) = Pr(y(t)|x(t)) × Pr(x(t)|Yt−1)∕Pr(y(t)|Yt−1)
[Posterior]
where
Pr(y(t)|x(t))
[Likelihood]
Initial Conditions
x(0)
P(0)
Pr(x(0)|Y0)

2.6
SUMMARY
45
2.5.3
Likelihood Estimation
For a variety of applications, the “data” or “measurement” likelihood is a critical
distribution function that is required. For instance, in the sequential detection of both
Gaussian and non-Gaussian processes, the data likelihood is the essential ingredient
required to make a timely decision (see Chapter 10 for more details).
We note from Bayes’ rule for the iltering posterior of Eq. 2.79 that the data
likelihood is given by the Chapman–Kolmogorov relation
Pr(y(t)|Yt−1
) = ∫Pr(y(t)|x(t))
⏟⏞⏞⏞⏞⏟⏞⏞⏞⏞⏟
Likelihood
× Pr(x(t)|Yt−1
)
⏟⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏟
Prediction
dx(t)
(2.81)
Substituting for the prediction distribution of Eq. 2.77, we can also express the
likelihood in terms of the iltering distribution as
Pr(y(t)|Yt−1
) = ∫∫Pr(y(t)|x(t))
⏟⏞⏞⏞⏞⏟⏞⏞⏞⏞⏟
Likelihood
× Pr(x(t)|x(t −1))
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏟
Transition
× Pr(x(t −1)|Yt−1
)
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏟
Filtered
× dx(t −1)dx(t)
(2.82)
This completes the description of the data likelihood distribution that will prove
critical in developments to follow in subsequent chapters.
2.6
SUMMARY
In this chapter, we have developed the idea of statistical signal processing from the
Bayesian perspective. We started with the foundations of Bayesian processing by
developing the “batch” solutions to the dynamic variable (state) or parameter estima-
tion problem. These discussions led directly to the generic Bayesian processor—the
maximum a posteriori solution evolving from Bayes’ theorem. We showed the rela-
tionship of MAP to the popular maximum likelihood estimator demonstrating the
ML is actually a special case when the dynamic variable is assumed deterministic
but unknown and therefore not random. We also included the minimum variance
estimator (MV, MMSE) and mentioned the least-squares (LS) approach. After dis-
cussing some of the basic statistical operations required (chain rule, performance
(CRLB), etc.), we developed the idea of Bayesian sequential or recursive processing.
We started with the full or joint posterior distribution assuming all of the information
about the dynamic variable and observations was available. The solution to this prob-
lem led to a sequential Bayesian processor. Lastly, we followed with the development
of a solution to the more practical marginal posterior or “iltering” distribution and
illustrated the similarity to the previous processor.

46
BAYESIAN ESTIMATION
MATLAB NOTES
MATLAB is a command oriented vector-matrix package with a simple yet effective
command language featuring a wide variety of embedded C language constructs
making it ideal for statistical operations and graphics. Least-squares problems
are solved with the pseudo-inverse (pinv). When the covariance is known (min-
imum variance) the (lscov) command can be applied. Individual linear alge-
braic techniques including the singular-value decomposition, QR-decomposition
(Gram–Schmidt) and eigenvalue/vector-decomposition techniques (svd, qr, eig,
etc.) are available. The Statistics toolbox offers a wide variety of commands to
perform estimation. For instance, “it” tools are available to perform parameter
estimation for a variety of distributions: exponential (expit), Gaussian or normal
(normit), Poisson (poissit), etc., as well as the generic maximum likelihood esti-
mation (mle), as well as speciic likelihood estimator for negative Gaussian/normal
(normlike), and negative exponential (explike).
REFERENCES
1. A. Sage and J. Melsa, Estimation Theory with Applications to Communications and
Control (New York: McGraw-Hill, 1971).
2. H. Van Trees, Detection, Estimation and Modulation Theory (New York: John Wiley &
Sons, Inc., 1968).
3. J. Candy, “The Cramer– Rao bound: A measure of estimator quality,” Lawrence Livermore
National Laboratory Report, UCID-17660, 1977.
4. J. Candy, Model-Based Signal Processing (Hoboken, NJ: John Wiley & Sons/IEEE Press,
2006).
5. A. Dempster, N. Laird, and D. Rubin, “Maximum likelihood from incomplete data via the
EM algorithm,” J. R. Statist. Soc.B, 39, 1, 1–38, 1977.
6. R. Duda and P. Hart, Pattern Classsiication (New York: John Wiley & Sons, Inc., 2000).
7. I. Nabney, NETLAB: Algorithms for Pattern Recognition (New York: Springer, 2002).
8. C. Wu, “On the convergence properties of the EM algorithm,” Ann. Statist., 11, 1, 95–103,
1983.
9. R. Redner and H. Walker, “Mixture densities, maximum likelihood and the EM algorithm,”
SIAM Rev., 26, 2, 195–239, 1984.
10. W. Gilks, S. Richardson, and D. Spiegelhalter, Markov Chain Monte Carlo in Practice
(New York: Chapman & Hall, 1996).
11. D. Snyder and M. Miller, Random Point Processes in Time and Space, 2nd Ed. (New York:
Springer, 1991).
12. M. Tanner, Tools for Statistical Inference, 2nd Ed. (New York: Springer-Verlag, 1993).
13. T. Moon, “The expectation-maximization algorithm,” IEEE Sig. Proc. Mag., 13, 6, 47–60,
1996.

PROBLEMS
47
14. J. Bilmes, “A gentle tutorial of the EM algorithm and its application to parameter estimation
for Gaussian mixture and hidden Markov models,” U. C. Berkeley Report, TR-97-021,
1998.
15. G. McLachlan and T. Krishnan, The EM Algorithm and Extensions (New York: John
Wiley & Sons, Inc., 1997).
16. A. Gelman, J. Carlin, H. Stern and D. Rubin, Bayesian Data Analysis, 2nd Ed. (New York:
Chapman & Hall, 2004).
17. A. Papoulis and S. Pillai, Probability, Random Variables, and Stochastic Processes, 4th
Ed. (New York: McGraw-Hill, 2002).
18. I. Rhodes, “A tutorial introduction to estimation and iltering,” IEEE Trans. Autom. Contr.,
16, 6, 688–706, 1971.
PROBLEMS
2.1
Derive the following properties of conditional expectations:
(a) Ex{X|Y} = E{X} , if X and Y are independent.
(b) E{X} = Ey{E{X|Y}}.
(c) Ex{g(Y) X} = Ey{g(Y) E{X|Y}}.
(d) Exy{g(Y) X} = Ey{g(Y) E{X|Y}}.
(e) Ex{c|Y} = c.
(f) Ex{g(Y)|Y} = g(Y).
(g) Exy{cX + dY|Z} = cE{X|Z} + dE{Y|Z}.
2.2
Verify the following properties:
(a) ∇x(a′b) = (∇xa′)b + (∇xb′)a, for a, b ∈Rn and functions of x.
(b) ∇x(b′x) = b.
(c) ∇x(x′C) = C, C ∈Rn×m.
(d) ∇x(x′) = I.
(e) ∇x(x′x) = 2x.
(f) ∇x(x′Ax) = Ax + A′x, for A not a function of x.
2.3
Show that for any unbiased estimate of ̂x(y) of the parameter vector x the
Cramer–Rao bound is
Cov(̃x|x) ≥−1
for ̃x = x = ̂x(y) and x ∈n, ∈n×n
where the information matrix is deined by
:= −Ey{∇x(∇x ln Pr(Y|X))′}
2.4
The sample mean, �= 1∕N ∑N
t=1 �(t), is a very important statistic in data pro-
cessing.

48
BAYESIAN ESTIMATION
(a) Show that the sample mean is an unbiased estimator of �∼xp(1∕�).
(b) Estimate the corresponding variance of �.
(c) Show that the sample mean is a consistent estimator of �.
(d) Construct the two standard deviation conidence interval about the sample
mean estimator. (Hint: Let �∼N(�, �2), �2 known.)
(e) Show that �is a minimum variance estimator. (Hint: Show it satisies the
Cramer–Rao bound with equality).
(f) If ̂�is an estimator or �, calculate the corresponding mean-squared error.
2.5
Let x(t) be an unknown dynamic parameter obtained from the linear measure-
ment system
y(t) = C(t) x(t) + �(t)
where �∼(0, R��(t)) with y, �∈p and x is governed by the state transition
mechanism
x(t + 1) = Φ(t + 1, t) x(t)
for Φ ∈n×n
Calculate the Cramer–Rao bound for the case of estimating the initial state x(0).
2.6
Suppose we have the following signal in additive Gaussian noise:
y = x + n
with n ∼N(0, Rnn)
(a) Find the Cramer–Rao bound if x is assumed unknown.
(b) Find the Cramer–Rao bound if p(x) = xe−x2∕Rnn, x ≥0.
2.7
Suppose we have two jointly distributed random vectors x and y with known
means and variances. Find the linear minimum variance estimator. That is, ind
̂xMV = ̂Ay + ̂b
and the corresponding error covariance cov ̃x, ̃x = x −̂x.
2.8
We would like to estimate a vector of unknown parameters p�Rn from a sequence
of N-noisy measurements given by
y = Cp + n
where C�Rp×n, y, n�Rp, and �is zero-mean and white with covariance Rnn.
(a) Find the minimum variance estimate ̂pMV.
(b) Find the corresponding quality cov(p −̂pMV).

PROBLEMS
49
2.9
Suppose we have N samples {x(0), … , x(N −1)} of a process x(t) to be esti-
mated by N complex sinusoids of arbitrary frequencies { f0, … , fn−1}. Then
x(k △T) =
N−1
∑
m=0
amexp( j2�fmk △T)
for k = 0, … , N −1
Find the least-squares estimate ̂aLS of {am}.
2.10 Suppose we are given a measurement modeled by
y(t) = s + n(t)
where s is random and zero-mean with variance �2
s = 4, and n is zero-mean and
white with a unit variance. Find the two-weight minimum variance estimate of
s, that is,
̂sMV =
2
∑
i=1
�iy(i)
that minimizes
J = E{(s −̂s)2}
2.11 Find the maximum likelihood and maximum a posteriori estimates of the para-
meter x :
p(x) = �e−�x
x ≥0, �≥0
and
p(y|x) = xe−xy
x ≥0, y ≥0
2.12 Suppose we have two classes of objects, black and white, with shape subclasses,
circle and square, and we deine the random variables as:
X1 = number of black circular objects
X2 = number of black square objects
X3 = number of white objects
Assume that these objects are trinomially distributed such that
Pr(x|Θ) =
((x1 + x2 + x3)!
x1!x2!x3!
) (1
4
)x1 (1
4 + Θ
4
)x2 (1
2 −Θ
4
)x3

50
BAYESIAN ESTIMATION
Suppose a person with blurred vision cannot distinguish shape (circle or square),
but can distinguish between black and white objects. In a given batch of objects,
the number of objects detected by this person is: y = [y1y2]′ with
y1 = x1 + x2
y2 = x3
(a) What is the probability, Pr(y1|Θ)?
(b) What is the expression for the E-step of the EM algorithm assuming ̂Θk is
the current parameter estimate, that is, ind the expression for E{x1|y1, ̂Θk}
with x3 known?
(c) What is the corresponding M-step?
(d) Take the EM solution (a)–(c) above based on 100 samples with y1 = 100
and start iterating with Θ0 = 0 for 10-steps; what is your inal estimate of
the parameter ̂Θ10? (Θtrue = 0.5) for simulation x1 = 25, x2 = 38.
2.13 Suppose we have a bimodal distribution consisting of a Gaussian mixture
with respective means, variances and mixing coeficients: {�1, �2
1, p1} and
{�2, �2
2, p2} such that pX(x) = ∑2
i=1 pi(�i, �2
i ) with p2 = 1 −p1. We would
like to it the parameters Θ = (p1, �1, �2
1, �2, �2
2) to data. Develop the EM algo-
rithm for this problem.
2.14 Suppose we are given a measurement system
y(t) = x(t) + �(t)
t = 1, … , N
where �(t) ∼N(0, 1).
(a) Find the maximum likelihood estimate of x(t), that is, ̂xML(t), for t =
1, … , N.
(b) Find the maximum a posteriori estimate of x(t) that is, ̂xMAP(t), if p(x) = e−x.
2.15 Suppose we have a simple AM receiver with signal
y(t) = Θs(t) + �(t)
t = 1, … , N
where Θ is a random amplitude, s is the known carrier, and �∼N(0, R��).
(a) Find the maximum likelihood estimate ̂ΘML.
(b) Assume Θ ∼N(Θ0, RΘΘ). Find the maximum a posteriori estimate ̂ΘMAP.
(c) Assume Θ is Rayleigh-distributed (a common assumption). Find ̂ΘMAP.
2.16 We would like to estimate a signal from a noisy measurement
y = s + �

PROBLEMS
51
where �∼N(0, 3) and s is Rayleigh-distributed.
p(s) = se−s2∕2
with
p(y|s) =
1
√
6�
e−(y−s)2
6
(a) Find the maximum likelihood estimate.
(b) Find the maximum a posteriori estimate.
(c) Calculate the Cramer–Rao bound (ignoring p(s)).
2.17 Assume that a planet travels an elliptical orbit centered about a known point.
Suppose we make M observations.
(a) Find the best estimate of the orbit and the corresponding quality, that is, for
the elliptical orbit (Gaussian problem)
�1x2 + �2y2 = 1
Find ̂�= [ ̂�1 ̂�2]′.
(b) Suppose we are given the following measurements: (x, y) = {(2, 2), (0, 2),
(−1, 1), and (−1, 2)}, ind ̂�and ̂J, the cost function.
2.18 Find the parameters, �1, �2, and �3 such that
f(t) = �1t + �2t2 + �3 sin t
its (t, f(t)): = {(0, 1), (�∕4, 2), (�∕2, 3), and (�, 4)} with corresponding quality
estimate ̂J.

3
SIMULATION-BASED
BAYESIAN METHODS
3.1
INTRODUCTION
In this chapter, we investigate the idea of Bayesian estimation [1–13] using approx-
imate sampling methods to obtain the desired solutions. We irst motivate the
simulation-based Bayesian processors and then review much of the basics required
for comprehension of this powerful methodology. Next, we develop the idea of
simulation-based solutions using the Monte Carlo (MC) approach [14–21] and intro-
duce importance sampling as a mechanism to implement this methodology from a
generic perspective [22–28]. Finally, we consider the class of iterative processors
founded on Markov chain concepts leading to eficient techniques such as the foun-
dational Metropolis–Hastings approach and the Gibbs sampler [29–37].
Starting from Bayes’ rule and making assertions about the underlying probabil-
ity distributions enables us to develop reasonable approaches to design approximate
Bayesian processors. Given “explicit” distributions, it is possible to develop analytic
expressions for the desired posterior distribution. Once the posterior is estimated,
the Bayesian approach allows us to make inferences based on this distribution and
its associated statistics (e.g., mode, mean, median). For instance, in the case of a
linear Gauss–Markov (GM) model, calculation of the posterior distribution leads to
the optimal minimum variance solution [11]. But again this was based completely on
the assertion that the dynamic processes were strictly constrained to Gaussian distri-
butions and a linear GM model therefore leading to a Gaussian posterior. When the
dynamics become nonlinear, approximate methods evolve based on “ linearization”
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
52

3.1
INTRODUCTION
53
techniques either model-based (Taylor series transformations) or statistical (sigma-
point transformations). In both cases, these are fundamentally approximations that
are constrained to unimodal distributions. What happens when both the dynamics
and statistics are nonstationary and non-Gaussian? Clearly, these approaches can be
applied, but with little hope of success under most conditions. Therefore, we must
resort to other less conventional (in signal processing) ways of attacking this class
of problems that have dominated the science and engineering literature for a long
time [38–61]. This question then leads us directly to statistical simulation-based tech-
niques invoking random sampling theory and the Monte Carlo (MC) method—well
known in statistics for a long time [14]. This method is essentially a collection of
techniques to estimate statistics based on random sampling and simulation. It can
be thought of simply as “performing estimation through sampling.” The goal of
Bayesian techniques using MC methods is to generate a set of independent sam-
ples from the target posterior distribution with enough samples to perform accurate
inferences [21]. Monte Carlo techniques have been applied to a large variety of appli-
cations in science and engineering [56, 57, 61]. In this chapter, we start out with the
simple idea of random sampling with the underlying motive of developing Monte
Carlo simulation techniques to solve nonlinear/non-Gaussian signal processing
problems.
MC methods involve techniques to estimate the posterior distribution of interest
using either numerical integration-based methods (when possible) or sample-based
simulation methods which attempt to produce independent identically distributed
(i.i.d.) samples from a targeted posterior distribution and use them to make statistical
inferences. Following Smith [18], we develop this idea further starting out with
Bayes’ rule for the variable or parameter X and the corresponding data Y, that is, the
posterior distribution is given by
Pr(X|Y) = Pr(Y|X) × Pr(X)
Pr(Y)
=
Pr(Y|X) × Pr(X)
∫Pr(Y|X) × Pr(X) dX
(3.1)
with the usual deinitions of likelihood, prior, and evidence (normalization) distribu-
tions. Once the posterior is estimated, the inferences follow immediately. For instance,
the conditional mean is given by
E{X|Y} = ∫X Pr(X|Y) dX
(3.2)
In the continuous (random variable) case, the explicit evaluation of these inte-
grals is required, yet rarely possible, leading to sophisticated numerical or analytical
approximation techniques to arrive at a solution. These methods rapidly become
intractable or computationally intensive to be of any real value in practice. Thus an
alternative method is necessary.
Just as we can use the distribution to generate a set of random samples, the samples
can be used to generate (approximately) the underlying distribution (e.g., histogram).
The idea of using samples generated from the prior through the likelihood to obtain

54
SIMULATION-BASED BAYESIAN METHODS
the posterior parallels that of using analytic distributions. For example, ignoring the
evidence we use the method of composition [16] to sample
Pr(X|Y) ∝Pr(Y|X) × Pr(X)
(3.3)
so that we can
r Generate samples from the prior: Xi →Pr(X); i = 1, … , N;
r Calculate the likelihood: Pr(Y|Xi); and
r Estimate the posterior: ̂Pr(X|Y) ≈Pr(Y|Xi) × Pr(Xi).
Unfortunately, this methodology is not realistic unless we can answer the following
questions: (1) How do we generate samples from distributions for simulations? and
(2) How do we guarantee that the samples generated are i.i.d. from the targeted
posterior distribution?
However, before we develop the idea of sampling and simulation-based methods,
we must have some mechanism to evaluate the performance of these samplers. In the
next section, we briely describe techniques to estimate the underlying probability
distributions from data samples.
3.2
PROBABILITY DENSITY FUNCTION ESTIMATION
One of the requirements of Bayesian signal processing is to generate samples from
an estimated posterior distribution. If the posterior is of a known closed form
(e.g., Gaussian), then it is uniquely characterized by its particular parameters (e.g.,
mean and variance) that can be “it” to the samples directly using parameter esti-
mation techniques. But, if the probability density1 is too complex or cannot readily
be represented in closed form, then nonparametric techniques must be employed to
perform the estimation.
Since most parametric forms rarely it the underlying posterior distribution encoun-
tered in the real world, especially if they are multimodal (multiple peaks) distribu-
tions, we investigate the so-called kernel (smoothing) method of probability density
function (PDF) estimation. The basic idea is to it a simple model individually at
each target sample (random variate) location, say ̂x, using the observations close to
the target p(̂x). This estimate can be accomplished by using a weighting function or
equivalently kernel function (̂x; xi) that assigns a weight to xi based on its proximity
to ̂x [4]. Different kernels lead to different estimators. For instance, the classical
histogram can be considered a rectangular or box kernel PDF estimator [5], while
1 In this section, we introduce more conventional notation for both the cumulative and density or mass
functions, since it is required. The CDF of the random variable X with realization x is deined by PX(x),
while the PDF or PMF is pX(x). In instances where it is obvious, we do not use the subscript X to identify
the random variable.

3.2
PROBABILITY DENSITY FUNCTION ESTIMATION
55
the fundamental Parzen-window multidimensional estimator is based on a hypercube
kernel [3]. Some of the popular kernel smoothing functions include the triangle,
Gaussian, Epanechnikov, and others [4]. In any case, kernel density estimation tech-
niques [6] provide the basic methodology required to estimate the underlying PDF
from random data samples and subsequently evaluate sampler performance—one of
the objectives of this chapter.
Theoretically, the underlying principle of distribution estimation is constrained by
the properties of the PDF itself, that is,
r pX(x) ≥0 ∀x ∈X; and
r ∫x pX(x) dx = 1.
Formally, the probability that the random variate x will fall within the interval
xi ≤X ≤xj for i < j is given by [3]
Pr(xi < X < xj) = ∫
xj
xi
pX(x) dx ≈pX(x) × Δx
for Δx ≪1(small)
(3.4)
which is simply the area under the PDF in the interval (xi, xj). Thus, the probability
that X is in a small interval of length Δx is proportional to its PDF pX(x).
Therefore, it follows that the probability at a point, say ̂x, can be approximated by
allowing xi = x and xj = x + Δx, then
Pr(x < ̂x < x + Δx) = ∫
x+Δx
x
pX(x)dx
for x ∈x
(3.5)
demonstrating that
pX(x) = lim
Δx→0
Pr(x < ̂x < x + Δx)
Δx
(3.6)
Consider a random draw of N i.i.d. (total) samples according to pX(x) above. The
probability that nN of these reside within x is binomial and can be approximated
by the frequency ratio nN∕N leading to a relative frequency interpretation of the
probability. That is, it follows that
pX(x) × Δx = nN
N
(3.7)
But this is just the well-known [1] histogram estimator given by
̂pX(x) := ̂pX(̂x) = 1
Δx
× nN
N
|x −̂x| ≤Δx
2
(3.8)

56
SIMULATION-BASED BAYESIAN METHODS
0
−2
−4
−6
2
4
6
8
10
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
Samples
Histogram
Kernel 
Probability
ˆx
ˆ
ˆ
p ( )
X x
True
x
Δ
Bin 
Estimated PDF: 
Histogram and Kernel (Gaussian) 
FIGURE 3.1
Estimated PDF using both histogram and kernel (Gaussian window
(0,10)) methods for random samples generated from a Gaussian mixture 1(0, 2.5)
and 2(5,1) and mixing coeficients P1 = 0.3 and P2 = 0.7.
Here ̂x is located at the midpoint of the interval (bin) ̂x −Δx
2 ≤x ≤̂x + Δx
2
and
the corresponding probability is assumed constant throughout the bin as shown in
Fig. 3.1. If
pN(x) ≈nN∕N
Δx
(3.9)
then as N →∞, histogram estimator converges to the true PDF, that is, pN(x) →pX(x)
and the following three conditions must hold
1. lim
N→∞Δx →0;
2. lim
N→∞nN →∞; and
3. lim
N→∞
nN
N →0.
The irst condition must hold to achieve the limit in Eq. 3.6, while the second
condition indicates how nN is to grow to guarantee convergence. Thus, at all nonzero
points of the PDF by ixing the size of the interval, the probability of samples
falling within this interval is inite and therefore nN ≈Pr(x) × N and nN →∞as
N →∞. The inal condition arises because as the interval size shrinks Δx →0, the

3.2
PROBABILITY DENSITY FUNCTION ESTIMATION
57
corresponding probability Pr(x) →0. These conditions indicate the manner in which
the parameters should be chosen: N large, Δxsmall with nN large. Satisfaction of all of
these conditions imply convergence to pX(x) (see Refs. [3] and [5] for more details).
There are two common ways of ensuring convergence: (1) “shrink” the region
by selecting the interval as a function of the number of samples such as Δx =
1
√
N
(Parzen-window method)2; and (2) “increase” the number of samples within the
interval which can be done as nN =
√
N. Here the local region grows until it encloses
nN neighbors of x (nearest-neighbor method). Both methods converge in probability.
This is the principle theoretical result in PDF estimation [3, 5, 6]. Next, consider the
kernel density estimator as a “generalized” histogram.
Let x1, … , xN be a set of i.i.d. samples of the random variate x then the kernel
density estimator approximation of the underlying probability density at x is given
by
̂pX(x) = 1
Δx
(
1
N
N
∑
i=1

(x −xi
Δx
))
=
1
N Δx
N
∑
i=1

(x −xi
Δx
)
(3.10)
where is deined as the kernel density (nonnegative and integrates to unity) with
Δx the corresponding smoothing parameter or bandwidth used to “tune” the estimate.
The classic bias–variance tradeoff arises here. That is, smaller Δx (high resolution)
yields smaller bias, but higher variance. However, a larger Δx (low resolution) gives
a larger bias with smaller variance [5]. We demonstrate the application of kernel
techniques in the following example of estimating a multimodal distribution.
Example 3.1
Suppose we would like to estimate the PDF of a set of 1000 samples generated
from a mixture of two Gaussian densities such that (�x, �2
x) →1(0, 2.5) and
2(5, 1) with mixing coeficients P1 = 0.3 and P2 = 0.7. We use both the histogram
and kernel density estimators. For the histogram we choose N = 20 bins to illustrate
(graphically) the bin estimates, while for the kernel density estimator we choose
a Gaussian window speciied by K(x) =
1
√
20�e
−x2
20 with an optimal bandwidth of
Δx = �x ×
(
4
3N
) 1
5 [3].
The results are shown in Fig. 3.1 for 100 bins or points where we see the estimated
PDF using both methods along with the “true” Gaussian density. Clearly the Gaussian
kernel estimator provides a much “smoother” estimate of the true density. A smoother
histogram estimate can be obtained by decreasing the bin-width. Both techniques
capture the general shape of the bimodal distribution.
△△△
2 It has been shown that the “optimal” bin (interval) size can be obtained by searching for the bin that
minimizes the cost function C(Δx) = (2x−�2x )
Δ2x
[7].

58
SIMULATION-BASED BAYESIAN METHODS
This completes the section on PDF estimation techniques. Note such details as
selecting the appropriate bin-size for the histogram and the bandwidth for the kernel
density estimator as well as its structure (Gaussian, Box, etc.) is discussed in detail in
Refs. [3] and [5–7]. These relations enable “tuning” of the estimators for improved
performance.
Next, we consider the simulation-based methods in an effort to answer the ques-
tions posed previously: (1) How do we generate samples from distributions for
simulations? and (2) How do we guarantee that the samples generated are i.i.d. from
the targeted posterior distribution?
3.3
SAMPLING THEORY
The generation of random samples from a known distribution is essential for simu-
lation. If the distribution is standard and has a closed analytic form (e.g., Gaussian,
exponential, Rayleigh), then it is usually possible to perform this simulation easily.
This method is called the direct method because it evolves “directly” from the analytic
form. An alternative is the “ inversion” method which is based on uniform variates and
is usually preferred. Thus, the uniform distribution becomes an extremely important
distribution in sampling because of its inherent simplicity and the ease with which
samples can be generated [15].
Many numerical sample generators evolve by irst generating a set of random
numbers that are uniformly distributed on the interval [a, b] such that all of the
subintervals are of equal length and have “equal probability.” Thus, X is said to be a
uniform random variable
X ∼U(a, b)
(3.11)
that has a cumulative distribution function (CDF) deined by
PX(x) = Pr(X ≤x) =
⎧
⎪
⎨
⎪⎩
0
x < a
x−a
b−a
a ≤x < b
1
x ≥b
(3.12)
along with the corresponding probability density
pX(x) =
1
b −a
a ≤x ≤b
(3.13)
with mean and variance �x = b+a
2
and �2
x = (b−a)2
12
.
Because of its simplicity and ease of numerical generation, the uniform variate is
the starting point of many simulation schemes. For instance, to generate a binomial
random number (e.g., coin tossing with Pr(heads) = p), we irst generate uniform

3.3
SAMPLING THEORY
59
random variates and then count the number of times they are greater than p. The result
is a set of binomial variates with trial parameter N and success (heads) probability p.
Since statistical sampling techniques are based on the generation of random sam-
ples from a given distribution, we must understand the relationship between an input
PDF, pX(x) and an output PDF, pY(y) when there exists a relationship between the
random variables x and y deined by y = y(x). The problem is
GIVEN x and pX(x) FIND the output PDF, pY(y) deining the probability of y.
When we have functions of random variables with known analytic distributions,
then the usual transformation method applies. That is, given the known distribu-
tion PX(x) or density pX(x) and the monotonic, one-to-one, invertible transformation
y = T(x), then the distribution or density of y is found by the using the transformation
relation [1]
pY(y) = pX(x) × ||||
�y
�x
||||
−1
= pX(x = T−1(y)) × ||||
�x
�y
||||
(3.14)
where |||
�y
�x
||| is the Jacobian of the transformation and T−1 is its inverse. The derivation
of this relationship follows directly from the deinitions of CDF [2]. Although simple,
this relation establishes one of the basic concepts in random sampling.
Perhaps the most fundamental relation is obtained by applying the transformation
directly to the CDF deined by
y(x) = PX(x) = ∫
∞
−∞
pX(�)d�
(3.15)
That is, applying the transformation of Eq. 3.14 and taking the required derivatives
gives
dy
dx = dPX(x)
dx
= pX(x)
(3.16)
which follows from the fundamental theorem of calculus. Therefore, we have
pY(y) = y(x) = pX(x)
||pX(x)||
= 1
(3.17)
yielding a uniformly distributed random variable y ∼U(0, 1), that is,
pY(y) = y(x) = 1
for 0 ≤y ≤1
(3.18)
Thus, the CDF of any random variable is always uniformly distributed on the interval
[0, 1] independently of pX(x)! This important result enables us to “sample” from
any arbitrary pX(x), since the random variable x can be sampled by irst generating

60
SIMULATION-BASED BAYESIAN METHODS
samples from y ∼U(0, 1) and then performing the inversion x = P−1
X (y). This is
called the inversion method in sampling theory that simply entails generating random
samples from U(0, 1) and determining the samples x by inversion of its (known) CDF.
Note that the CDF can be known analytically or just in tabular form to perform the
inversion. We discuss this theorem more formally in the next section. First, consider
the following example to illustrate this idea.
Example 3.2
Suppose we have a uniform random variable x ∼U(0, 1) and a transformation y =
T(x) = −1
�ln x. We would like to know the analytic form of the density pY(y). Since x
is uniform, the density is pX(x) =
1
b−a = 1, the inverse transformation is x = T−1(y) =
e−�y; therefore, taking the derivative and substituting its absolute value into Eq. 3.14
gives
pY(y) = (1) × | −�e−�y| = �e−�y
an exponential distribution with parameter �.
△△△
Transformations of discrete random variables are much simpler where we use the
probability mass and discrete CDFs in place of their continuous counterparts. In this
case the transformation is still continuous with the identical conditions (invertible,
etc.), that is,
yi = T(xi)
i = 1, … , N
(3.19)
and therefore we have the discrete CDF as
PY(y) = Pr(Y ≤yi) = Pr(X ≤xi) = Pr(X ≤xi = T−1(yi));
i = 1, … , N
(3.20)
3.3.1
Uniform Sampling Method
As noted, the uniform distribution plays a vital role in simulating random variates
and is applied heavily in sample-based simulation schemes. We formally present two
fundamental theorems and a corollary [1] to justify the theoretical foundation of this
approach and motivate their use through some simple examples.
Uniform Transformation Theorem
Given a random variable X with distribution
PX(x), there exists a unique, monotonic transformation T(X) such that the random
variable U = T(X) is distributed as U(0, 1), that is, if T(X) is selected as
T(X) = U

3.3
SAMPLING THEORY
61
then
U ∼U(0, 1)
The proof of this theorem follows directly [1] from the properties of the CDF.
Suppose x is arbitrary and u = PX(x). Then with a monotonic PX(x), we have U ≤u
iff X ≤x and therefore it follows that
PU(u) = Pr(U ≤u) = Pr(X ≤x) = PX(x) = u
giving the desired result. This is a strong result stating that any CDF can be represented
in terms of a set of uniform random variates as discussed before.
The second theorem [1] provides the basis of most sample-based simulations and
is reliant on the existence of the “inverse” of the CDF.
Inverse Transformation Theorem
Given a uniform random variable U ∼U(0, 1)
and a distribution (target) PX(x), there exists a unique, monotonic transformation
T(U), such that the random variable X = T(U) is distributed as PX(x), that is, if T(U)
is selected as
T(U) = X = P−1
X (U)
then
X ∼PX(x)
Again the proof of this theorem follows directly from the properties of the CDF
[1]. From the Uniform Transformation Theorem above, we know that U is uniform
and PX(X) is arbitrary; therefore, U = PX(X) ⟶X = P−1
X (U) and it follows that
PX(X ≤x) = PX(X ≤P−1
X (U)) = PX(P−1
X (U)) = u = PX(X)
providing the proof. We illustrate this technique with the following example.
Example 3.3
Suppose we would like to generate a random variable X exponentially distributed
with parameter �, X ∼Exp(�). From the Uniform Transformation Theorem, we have
u = PX(x) = 1 −e−�x
and
x = P−1
X (U) = −1
�ln(1 −u)

62
SIMULATION-BASED BAYESIAN METHODS
To generate exponential random variables
r Generate uniform samples: ui ⟶U(0, 1)
r Transform to exponential: xi = −1
�ln(1 −ui)
Also since ln(1 −ui) ∼U(0, 1), then the exponential variates are generated more
eficiently from xi = −1
�ln(ui).
△△△
To further illustrate the inverse CDF method, we apply it to a discrete problem
that occurs quite frequently in nonlinear processing.
Example 3.4
Suppose we have estimated a discrete empirical distribution representing a posterior
density given by
̂pX(x) =
N
∑
i=1
Wi�(x −xi)
with corresponding CDF
̂PX(x) =
N
∑
i=1
Wi�(x −xi)
where �(x) is a unit step function, Wi := Pr(X = xi) and of course, ∑N
i=1 Wi = 1.
The CDF is shown in Fig. 3.2a. Using the inverse CDF method, we can generate
x
( )
X
P
x
( )
)
−1
−1
X
P
u
(
X
P
u
u
ix
iu
ix
1
1
0
0
Pr(xi)
Pr(xi)
x =
(a)
(b)
FIGURE 3.2
Empirical distribution:(a) estimated CDF;(b) estimated inverse cumulative
distribution function (ICDF).

3.3
SAMPLING THEORY
63
realizations of X = xi by
r Generate uniform samples: uk ∼U(0, 1)
r Simulate samples: xi = P−1
X (u) or
xi = xk
for PX(xk−1) ≤uk < PX(xk)
or using the empirical distribution
xi = xk
for
k−1
∑
j=1
Wj ≤uk <
k
∑
j=1
Wj
This transformation is illustrated in Fig. 3.2b.
△△△
Summarizing, we irst generate a uniform random variate ui and then “bracket”
its probability to determine the desired random variable xi. So we see from these
examples that using the inverse CDF method enables us to generate continuous
and discrete random variates from both the analytic function as well as discrete
samples from an empirical distribution. We will apply this technique frequently in
the simulation-based processor. This approach is also used heavily in the resampling
algorithms to follow (e.g., uniform, systematic). Numerical methods can also be used
to perform the inversion by solving PX(X) −U =0 for X [5, 15].
Before we close this section, let us note that the above theorems can be generalized
to simulate any distribution from any other distribution using the uniform variates as
an intermediate step leading to the following corollary.
Corollary
Given a distribution PX(X) and a corresponding target distribution PY(Y),
there exists a unique, monotonic transformation T(X), such that the random variable
Y = T(X) is distributed as PY(y), that is, if T(X) is selected as
T(X) = Y = P−1
Y (PX(x))
then
PY(Y ≤y) = PY(y)
The proof of this corollary follows by applying the results of the previous theorems
with U = PX(x) and Y = P−1
Y (U) for U ∼U(0, 1). Consider the following example to
demonstrate this approach to simulation.

64
SIMULATION-BASED BAYESIAN METHODS
Example 3.5
Consider a random variable X distributed as X ∼PX(x) = 1 −e−x −x e−x. We would
like to generate a random variable Y exponentially distributed with parameter �,
Y ∼Exp(�). Then from the Corollary, we have
u = PY(y) = 1 −e−�y
and
y = P−1
Y (U) = −1
�ln(1 −u)
Thus, it follows that
P−1
Y (PX(x)) = −1
�ln(1 −PX(x)) = −1
�ln(e−x + x e−x)
Therefore, we have
yi = −1
�ln(e−xi + xi e−xi)
Sampling from the uniform (as before), we irst generate {xi} and then the desired
set of random variates {yi}.
△△△
We complete this subsection by stating the Golden Rule of Sampling [22] given
by
r Generate uniform samples: ui →U(0, 1); i = 1, … , N;
r Deine the transformation: ui = PX(xi); and
r Apply the inverse transformation: xi = P−1
X (ui).
Next, we investigate a more general approach.
3.3.2
Rejection Sampling Method
In order to use the uniform sampling simulation methods of the previous section,
we require the inverse CDF, which is not a simple task, even when the distribution
is known in closed form. The rejection sampling method offers an alternative that
not only eliminates the inversion problem, but also becomes an integral part of many
of the sophisticated sampling algorithms to follow because of its simplicity and
generality. In principle, the rejection method can be applied to any distribution with
a density given up to a normalization constant [32].
The basic sampling problem in this context is that we are trying to generate
samples from a density (or distribution) that is capable of being evaluated and we
have a function
pX(x) = c × Pr(X)

3.3
SAMPLING THEORY
65
p(x)
   then ACCEPT
Mq(x)
k
u ≤
(x,u)
x
Accept
Reject
Sampling PDF: Mq(x) 
Target PDF: p(x)
FIGURE 3.3
Rejection sampling method.
where Pr(X) is the target distribution and pX(x) is related and computable up to
the normalization constant c which is not known. Suppose we select a sampling
distribution, say q(x), such that there exists a “ covering” constant M with
pX(x) ≤Mq(x)
∀x
The rejection sampling method is illustrated in Fig. 3.3 (c =1) and summarized as
r Generate a sample: xk ⟶q(x)
r Generate a uniform sample: uk ⟶U(0, 1)
r ACCEPT the sample: xi = xkif uk ≤pX(x)
M×q(x)
r Otherwise, REJECT the sample and generate the next trial sample: xi
The proof of this method is given in Liu [32] using an indicator function (x)
deined by
(x) =
{
1
if x accepted
0
if x rejected
(3.21)
Proceeding
Pr((x) = 1) = ∫Pr((x) = 1|X = x) q(x) dx = ∫
(cPr(x)
Mq(x)
)
q(x)dx = c
M
and
Pr(x|(x) = 1) =
(
cPr(x)
Mq(x)
)
q(x)
Pr((x) = 1) = Pr(x)
which shows that the acceptance of the sample corresponds to sampling directly from
the target distribution Pr(x).
The expected number of samples to accept an x ∼Pr(x) is M and therefore the key
to using this approach is to select a good proposal distribution q(x) with a low M—a

66
SIMULATION-BASED BAYESIAN METHODS
nontrivial problem. Note that Example 1.1 in which the area of a circle was estimated
using sampling methods is a simple geometric illustration of this methodology. The
following example from Papoulis [1] demonstrates the method in an analytic form.
Example 3.6
Suppose we are given a random variable x ∼Exp(1) and we would like to simulate
the random variable with truncated Gaussian y ∼(0, 1), that is, we have
p(x) =
2
√
2�
e
−x2
2 × �(x)
and
q(x) = e−x
where �(x) is a unit step function as before, then for x > 0, we have
p(x)
q(x) =
√
2e
�e
−(x−1)2
2
× e1 ≤
√
2e
�
Setting M =
√
�
2e, we have the acceptance/rejection sampling rule:
xi = xk
if uk < e−(xk−1)2
2
(Accept)
△△△
This completes the background on sampling theory; next we consider the Monte
Carlo approach.
3.4
MONTE CARLO APPROACH
The Monte Carlo approach to solving Bayesian estimation problems is to replace com-
plex analytic or unknown probability distributions with sample-based representations
to solve a variety of “unsolvable” problems in inference (integration, normalization,
marginalization, expectation, etc.), optimization (parameter, maximum a-posteriori
(MAP), maximum likelihood (ML) estimation), statistical mechanics (Boltzmann
equation), and nuclear physics (ission, diffusion, etc.) [32, 35]. The key to the MC
approach is to generate independent random samples from a probability distribution
Pr(X) usually known only up to a normalizing constant (evidence) [32]. Typically,
generating independent samples from this distribution is not feasible implying sam-
ple dependencies or using a proposal distribution q(X), that is, similar to but not the
exact target distribution Pr(X). Independent (i.i.d.) samples are important because
both strong and weak Laws of Large Numbers (mean converges in distribution to
population mean) ensure that the inferences (e.g., mean, variance) can be made as
accurate as desired by increasing the number of samples. However, the samples can be
dependent and still properly relect the probability of the target distribution, opening
the possibility of Markov chain methods (see Section 3.4.1).

3.4
MONTE CARLO APPROACH
67
The rejection method, just discussed, [22], importance sampling [16], and
sampling-importance-resampling [26] are methodologies that do employ a proposal
distribution. The Metropolis technique and its variants provide the foundation for
this approach using Markov chain concepts generating dependent samples from a
chain with Pr(X) as its invariant or stationary distribution. In this section, we develop
the idea of the MC simulation-based approach to Bayesian estimation using iterative
rather than sequential Monte Carlo techniques.
Theoretically, the Monte Carlo approach to sampling is based on the following
principles [10, 27, 29, 30, 35]. Here N i.i.d. samples {X(i)}N
i=1 are drawn from the
target density p(X) to produce an estimate of the empirical distribution (density)
̂Pr(X) = ̂pN(X) = 1
N
N
∑
i=1
�(X −X(i))
(3.22)
which can be used to approximate integrals (PDFs, areas, etc.) with sums, that is,
IN(f) = 1
N
N
∑
i=1
f(X) �(X −X(i)) = 1
N
N
∑
i=1
f(X(i)) a.s.
⟶
N→∞I(f) = ∫f(X) p(X) dX
(3.23)
Here IN(f) is unbiased and converges (almost surely) to I(f) according to the strong
Law of Large Numbers. Its corresponding variance is bounded (�2
f < ∞) and
var(IN(f)) =
�2
f
N
(3.24)
A central limit theorem argument shows that the error converges in-distribution as
√
N(IN(f) −I(f))
N→∞
⟶(0, �2
f )
(3.25)
The main advantage of MC over deterministic integration is that it positions its
samples over regions of high probability.
In signal processing, we are usually interested in some statistical measure of a
random signal or parameter expressed in terms of its moments. Let us take a slightly
more detailed look at just how MC concepts can be applied with this perspective
in mind. Suppose we have some signal function, say f(X), with respect to some
underlying probabilistic distribution Pr(X). Then a typical measure to seek is its
performance “on the average” which is characterized by the expectation
EX{f(X)} = ∫f(X) Pr(X) dX
(3.26)
From the Bayesian perspective, the embedded distribution can be thought of as
the “posterior” of the signals/parameters. The Bayesian approach must integrate

68
SIMULATION-BASED BAYESIAN METHODS
over high-dimensional probability distributions to make inferences about parameters
or predictions about signals. Unless the integral is analytically tractable, the usual
method of evaluation is through numerical integration (deterministic) techniques.
Unfortunately, the number of points to evaluate both f(⋅) and Pr(⋅) increases expo-
nentially with the dimensionality of the signal/parameter space. Also it is not possible
to evaluate this integral over the entire space in practice; therefore, we concentrate on
speciic regions where the integrand is dense (not null). Instead of attempting to use
numerical integration techniques, stochastic sampling techniques known as Monte
Carlo (MC) integration have evolved as an alternative (see Fig. 1.2 for concept). As
mentioned, the key idea embedded in the MC approach is to represent the required
distribution as a set of random samples rather than a speciic analytic function (e.g.,
Gaussian). As the number of samples becomes large, they provide an equivalent rep-
resentation of the distribution enabling moments to be estimated directly. A functional
estimate of the distribution could also be it to the samples, if desired.
Integration has been used throughout statistics to evaluate probabilities and expec-
tations. However, with Monte Carlo techniques the process is reversed and expecta-
tions are used to calculate integrals [1, 16, 28, 32]. Suppose we are asked to evaluate
a multidimensional integral
I = ∫X
g(x) dx
(3.27)
Then an MC approach would be to factorize the integrand as
g(x) ⟶f(x) p(x) ∋p(x) ≥0
and
∫p(x) dx = 1
where p(x) is interpreted as a probability distribution in which samples can be drawn.
This is the foundation of sampling techniques based on MC integration. Monte
Carlo approaches draw samples from the required distribution and then form sample
averages to approximate the sought after distributions, that is, they map integrals to
discrete sums. Thus, MC integration evaluates Eq. 3.26 by drawing samples {X(i)}
from Pr(X). Assuming perfect sampling, this produces the estimated or empirical
distribution given by
̂Pr(X) ≈1
N
N
∑
i=1
�(X −X(i))
N→∞
⟶(0, �2
f )
which is a probability distribution of mass or weights 1
N and random variable or
location X(i). Substituting the empirical distribution into the integral gives
EX{f(X)} = ∫f(X) ̂Pr(X) dX ≈1
N
N
∑
i=1
f(X(i)) ≡f
(3.28)

3.4
MONTE CARLO APPROACH
69
which follows directly from the sifting property of the delta function. Here f is said
to be a Monte Carlo estimate of EX{f(X)}. Clearly, it is unbiased, since
E{f} = 1
N
N
∑
i=1
E{f(X(i))} = EX{f(X)}
with variance given by
var(f) = 1
N ∫[f(X) −EX{f(X)}]2 Pr(X) dX
Additionally, if the variance is inite, then the central limit theorem holds and the
error in estimation converges to a zero-mean Gaussian with (0, var(f)). Consider
the following examples to illustrate these concepts. First we discuss an analytic case,
then a numerical case to solidify both MC approaches.
Example 3.7
Suppose we would like to solve for the integral
I = ∫
1
0
f(x) dx
using the MC approach. Let u be deined as a random variate drawn from a uniform
distribution u ∼U(0, 1), then we can express the integral in terms of an expectation
as
I = E{f(u)} = ∫
1
0
f(u) Pr(u) du
Generating a set of i.i.d. uniform samples u1, … , uN, the corresponding set of func-
tions {f(ui)} are also i.i.d. with mean I as deined above. Therefore, the uniform
sampling distribution is given by (equally likely)
Pr(u = ui) = 1
N
N
∑
i=1
�(u −ui)
for 0 ≤ui ≤1
Substituting this expression into the expectation relation, we obtain
I = E{f(u)} = ∫
1
0
f(u)
[
1
N
N
∑
i=1
�(u −ui)
]
du = 1
N
N
∑
i=1
f(ui)

70
SIMULATION-BASED BAYESIAN METHODS
From the Law of Large Numbers3 as N →∞, it follows that
N
∑
i=1
f(ui) ⟶E{f(u)} = I
Therefore, we can approximate the integral by generating a large number of random
variables drawn from a uniform sampling distribution, transform them according
to some functional relationship, and calculate the sample mean to approximate the
desired integral.
△△△
This simple example illustrates the basic MC concept that will be applied through-
out this text. Consider another example that illustrates this approach further by devel-
oping a simulation-based solution to a familiar statistical estimation problem.
Example 3.8
Suppose we have a Gaussian random variable and we would like to estimate its mean
and variance. Knowledge that it is Gaussian enables us to write the closed form
expression for the distribution
x ∼(mx, �2
x)
or
Pr(x) =
1
√
2��2
x
exp
{
−(x −mx)2
2�2
x
}
and the mean and the variance can be calculated analytically as
mx = ∫x Pr(x) dx
�2
x = ∫(x −mx)2 Pr(x)dx
In contrast, the Monte Carlo approach is to generate N samples from a Gaussian.
Assuming perfect sampling xi ⟶(mx, �2
x) and we have that
̂Pr(x) ≈1
N
N
∑
i=1
�(x −xi)
Now the mean and variance can be estimated from the samples directly using
̂mx = ∫x ̂Pr(x)dx = ∫x
(
1
N
N
∑
i=1
�(x −xi)
)
dx = 1
N
N
∑
i=1
xi
3 The Law of Large Numbers states simply that the mean converges with probability one to the population
mean as the number of samples become large.

3.4
MONTE CARLO APPROACH
71
with variance
̂�2
x = ∫(x −mx)2 ̂Pr(x) dx = ∫(x −mx)2
(
1
N
N
∑
i=1
�(x −xi)
)
dx = 1
N
N
∑
i=1
(xi −̂mx)2
Summarizing the MC approach for this example, we must
r Generate N samples from a Gaussian: xi ⟶(mx, �2
x);
r Estimate the desired statistics of the distribution from its samples as ̂mx and ̂�2
x.
We performed a simulation in MATLAB to generate Gaussian variates with mx = 2
and �2
x = 4. The results are shown in Fig. 3.4. In Fig. 3.4a, we see a simulation for
N = 1000 samples (+) with corresponding estimated mean (solid line) and upper and
lower 95%-conidence limits about the mean (mx ± 1.96�x). The sample mean and
variance for this MC realization were at ̂mx = 1.97 and ̂�2
x = 4.01. The distribution
was estimated using a histogram with 100 bins and is shown in Fig. 3.4b with a
near-perfect MC solution using N = 106 samples shown in the inset.
△△△
So we see from this example how MC methods can be used to approximate
(estimate) distributions and their associated statistics from simulated samples.
These methods are acceptable as long as high accuracy is not required. Monte
Carlo techniques tend to perform a “divide and conquer” approach to integration by
breaking the integral up into distinct regions around the integrand consisting of strong
local peaks at known locations. They are typically very time consuming methods, of
the order of tens and hundreds of thousands of points, and have only recently gained
notable prominence in the signal processing literature due to the major advances in
fast computers [28]. Next, let us consider the extension of Monte Carlo techniques
using Markov chains.
3.4.1
Markov Chains
In MC integration, the population mean of f(X) is estimated by the sample mean.
When the samples {Xi(t) = i} are independent, the Law of Large Numbers ensures
that the approximation can be made as accurately as required by increasing the
number of samples N. Generally, however, drawing samples from Pr(X) is not feasible
especially when it is a nonstandard distribution. However, dependent samples can be
generated by any process that draws samples throughout the support (range) of
the distribution. One eficient technique to accomplish this sampling is through a
Markov chain having Pr(X) as its unique stationary or invariant distribution—this
methodology is termed Markov chain Monte Carlo (MCMC). This technique is
basically MC integration where the random samples are produced using a Markov
chain. Recall that a Markov chain is a discrete random process possessing the property

72
SIMULATION-BASED BAYESIAN METHODS
0
200
400
600
800
1000
−5
0
5
10
Sample No.
(a)
(b)
Amplitude
−5
0
5
10
0
0.01
0.02
0.03
0.04
Sample No.
Probability
Estimated distribution
Sampling realization
FIGURE 3.4
Monte Carlo approach for estimation of the statistics of a Gaussian
random process: (a) simulation (mx = 2, �2
x = 4, N = 1000) with 95%-conidence limits
(dashed line) about ̂mx (solid line); (b) estimated distribution (histogram) from sam-
ples. Inset is estimate for N = 1 × 106 samples.

3.4
MONTE CARLO APPROACH
73
that the conditional distribution at the present sample (given all of the past samples)
depends only on the previous sample (irst order), that is,
Pr(Xi(t)|Xj(t −1), … , Xk(0)) = Pr(Xi(t)|Xj(t −1))
Summarizing, the Markov chain dynamics are represented by the transition prob-
ability ij(t −1, t) := Pr(X(t) = i|X(t −1) = j) denoting the probability that the
state at time t will be i, given that it is currently in state j at time t −1. Further,
if the chain is also homogeneous in time, then ij(t −1, t) depends only on the time
difference (in general) and therefore the transition probability is stationary such that
ij(t −1, t) →ij with ij ≥0 and ∑Nx
i=1 ij = 1 [1].
Thus, the basic requirement in Monte Carlo techniques is to generate random
samples from a probability distribution or target distribution only known up to a
normalizing constant. Typically, it is not possible to generate the samples from the
target but generating from a known trial distribution that is similar to the target
distribution, just as in rejection sampling, is applied. In order to understand the
MCMC approach, we must irst deine critical properties of the Markov chain.
Markov chains possess certain crucial properties that must exist for them to be
useful in MC simulations [32, 33]. A Markov chain begins with an initial distribution
Pr(Xi(0)) and evolves to another indexed variable Xi(t) determined by a transition
kernel, that is, at index t we have
Pr(Xi(t)) =
∑
j
Transition kernel
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(Xi(t)|Xj(t −1)) ×Pr(Xj(t −1))
(3.29)
An invariant distribution is a ixed point solution to Eq. 3.29. For distribution
estimation the constraint is even more stringent, since we require time reversible
chains which must satisfy a detailed balance as (ignoring the index)
Pr(Xi(t)) × Pr(Xi(t)|Xj(t)) = Pr(Xj(t)) × Pr(Xj(t)|Xi(t))
∀Xi(t), Xj(t)
(3.30)
which means that the transition probability from Xi(t) to Xj(t) is identical to the
probability from Xj(t) to Xi(t) implying invariance [28, 32]. The chain is also required
to be ergodic which means that regardless of the initial distribution, the probability
at t converges to the invariant distribution as t →∞, that is,
lim
t→∞Pr(Xi(t)) ⟶Pr(Xi(t))
(3.31)
Thus, MCMC method for the simulation of a distribution is any technique produc-
ing an ergodic or reversible chain with invariant distribution being the desired target
distribution. Armed with this information we can now discuss the most powerful
and eficient MCMC methods: the Metropolis–Hastings and Gibbs sampler and their
variants.

74
SIMULATION-BASED BAYESIAN METHODS
3.4.2
Metropolis–Hastings Sampling
Markov chain simulation is essentially a general technique based on generating
samples from proposal distributions and then correcting (acceptance or rejection)
those samples to approximate a target posterior distribution. Here we must know
both the target pX(x) (up to a normalizing constant) and the proposal q(x), a priori.
The samples are sequentially generated forming a Markov chain with properties
deined in the previous section. Typically, in Markov chain simulation, samples are
generated from the transition kernel or distribution. The key, however, is not really
the chain itself, but the fact that the approximate distribution improves sequentially
as it converges to the target posterior.
In this subsection, we discuss the basic Metropolis–Hastings sampling method.
We start with the original Metropolis algorithm [24] and then introduce the Hastings
generalization [23]. The fundamental idea is similar to the rejection method discussed
previously. The Metropolis–Hastings (M-H) technique deines a Markov chain such
that a new sample xi is generated from the previous sample xi−1 by irst drawing a “can-
didate” sample ̂xi from a proposal distribution q(x) and then making a decision whether
this candidate should be accepted and retained, or rejected and discarded using the pre-
vious sample as the new. If accepted, ̂xi replaces xi (̂xi →xi) otherwise the old sample
xi−1 is saved (xi−1 →xi). This is the heart of the M-H approach in its simplest form.
We start with the basic Metropolis technique to describe the method
r Initialize: xo →pX(xo)
r Generate a candidate sample from proposal: ̂xi →q(x)
r Calculate the acceptance probability: (xi−1, ̂xi) = min
{ pX(̂xi)
pX(xi−1), 1
}
r ACCEPT candidate sample with probability, (xi−1, ̂xi) according to
xi =
{ ̂xi
if pX(̂xi) > pX(xi−1)
xi−1
otherwise
(3.32)
We see from this technique that when the candidate sample probability is greater
than the previous sample’s probability, it is accepted with probability
pX(xi) =
{
(xi, ̂xi)
if accepted
1 −(xi, ̂xi)
if rejected
(3.33)
The idea is that we can detect when the chain has converged to its invariant dis-
tribution (posterior), when pX(xi) = pX(xi−1). It is clear from this discussion that for
the chain to converge to the posterior it must be reversible and therefore q(x) must
be a symmetric distribution. This was the original Metropolis assumption. Hastings
[23] generalized this technique by removing the symmetry constraint enabling asym-
metric proposals. The basic algorithm remains the same except that the acceptance
probability becomes (pX →p)
(xi, ̂xi) = min
{p(̂xi) × q(xi|̂xi)
p(xi) × q(̂xi|xi), 1
}
(3.34)

3.4
MONTE CARLO APPROACH
75
This process continues until the desired N samples of the Markov chain have been
generated. The critical step required to show that the M-H converges to the invariant
distribution or equivalently the posterior pX(x) evolves directly from the detailed
balance of Eq. 3.30 given by
p(xi+1|xi) × p(xi) = p(xi|xi+1) × p(xi+1)
(3.35)
where p(xi+1|xi) is the Markov chain transition probability. If we assume that the ith
sample was generated from the posterior xi ∼pX(x) then it is also assumed that the
chain has converged and all subsequent samples have the same posterior. Thus, we
must show that the next sample xi+1 is also distributed p(xi) = pX(x). Starting with the
detailed balance deinition above and integrating (summing) both sides with respect
to xi, it follows that
∫p(xi+1|xi) p(xi) dxi = ∫p(xi|xi+1) p(xi+1) dxi
= p(xi+1) ∫p(xi|xi+1) dxi = p(xi+1)
(3.36)
which shows that the relation on the left side of Eq. 3.36 gives the marginal distribution
of xi+1 assuming xi is from p(xi). This implies that if the assumption that xi is from
p(xi) is true, then xi+1 must also be from p(xi) and therefore p(xi) →pX(x) is the
invariant distribution of the chain. Thus, once a sample is obtained from the invariant
distribution, all subsequent samples will be from that distribution as well, proving that
the invariant distribution is p(xi). A full proof of the M-H technique requires a proof
that p(xi|x0) will converge to the invariant distribution (see Ref. [19] for details).
For the M-H technique, the transition from xi+1 ≠xi to xi occurs with probability
p(xi+1|xi) = q(xi+1|xi) × min
{ p(̂xi) × q(xi|̂xi)
p(xi) × q(̂xi+1|xi), 1
}
= (xi, xi+1) × q(xi+1|xi)
(3.37)
This completes the basic M-H theory.
3.4.3
Random Walk Metropolis–Hastings Sampling
Next, we consider another version of the M-H technique based on a random walk
search through the parameter space. The idea is to perturb the current sample xi with
an addition of a random error, that is,
xi+1 = xi + �i
for �i ∼pE(�)
(3.38)
where �is i.i.d. A reasonable choice for this distribution is a symmetric Gaussian,
that is, pE(�) ∼(0, �2
�). Thus, the random walk M-H method is:

76
SIMULATION-BASED BAYESIAN METHODS
Given the current sample xi
r Draw a random sample: �→pE(�)
r Generate the candidate sample: ̂xi = xi + �i
r Draw a uniform random sample: ui →U(0, 1)
r Calculate the acceptance probability from the known densities: (xi, ̂xi)
r Update the sample:
xi+1 =
{̂xi
if ui < (xi, ̂xi)
xi
otherwise
(3.39)
r Select the next sample
With this algorithm, we must use both the (known) proposal and target distri-
butions to calculate the acceptance probability and then generate samples (random
walk) from the proposal. It is important to realize that a “good” proposal distri-
bution can assure generating samples from the desired target distribution, but the
samples must still be generated to “cover” its range. This is illustrated in Fig. 3.5
where our target distribution is a Gaussian mixture with mixing coeficients as
(0.3, (0, 2.5); 0.5, (5, 1); 0.2, (10, 2.5)). In the igure, we see the results from
Second-order mixture
Third-order mixture
(a)
(b)
FIGURE 3.5
Metropolis–Hastings for Gaussian mixture distribution PDF estimates: (a)
inadequate proposal: (0,10) at a 59.2% acceptance rate (light gray); (b) adequate
proposal: (0,100) at a 34.0% acceptance rate (dark gray).

3.4
MONTE CARLO APPROACH
77
choosing a reasonable proposal ((0, 100)) in the dark color generating enough
samples to cover the range of the target distribution and a proposal ((0, 10)) that
does not sample the entire space adequately leading to an erroneous target distribu-
tion characterizing the sampler output. Consider the following example of applying
a variety of proposals and M-H techniques.
Example 3.9
Suppose we would like to generate samples from a unit Gaussian distribution
(0, 1) using the various M-H simulation techniques: (i) symmetric proposal using
U(−10, 10); (ii) symmetric proposal using a Student T distribution (1); (iii) random
walk using uniform noise U(−5, 5); and (iv) uniform proposal using U(−4, 9). To start
we specify the “target” distribution as pX(x) ∼(0, 1) and we choose the following
proposals
r Case (i): q1(x) ∼U(−10, 10) ⇒1
20 for −10 < x < 10
r Case (ii): q2(x) ∼(1)
r Case (iii): xi = xi−1 + ui where ui ∼U(−5, 5) ⇒1
10 for −5 < ui < 5
r Case (iv): q4(x) ∼U(−4, 9) ⇒1
13 for −4 < x < 9
To implement the Metropolis, Metropolis–Hastings, random walk Metropolis–
Hastings techniques we must
1. Draw a random sample from the proposal: xi →qi(x)
2. Calculate the acceptance ratio: (xi, xi−1)
3. Draw a uniform sample: ui →U(0, 1)
4. Accept or reject sample: ui ≤(xi, xi−1)
5. Update sample: xi
6. Generate next sample: xi+1
The results of these 105 sample simulations are shown in Figs. 3.6a–d using the
M-H sampler in MATLAB. We see the results of using the various proposals. All
of the estimated densities give reasonably close estimates of the target posterior
(0, 1). We estimated the corresponding posterior distribution from the samples
using both histogram and kernel density estimators of Section 3.2 with all of the
results reasonable. The standard deviation estimates were very close to unity in all
cases; however, the means differed slightly from zero. It is interesting to note the
corresponding acceptance rates (see Fig. 3.5 caption) with the most Gaussian-like,
proposal distribution had the highest acceptance rate of 57.8%. The true target
distribution is superimposed for comparison purposes. Acceptance rates provide an
indication of how “probable” a sample from the proposal is accepted as a sample
in the target (posterior). When the proposal provides good coverage of the target

−5
−4
−3
−2
−1
0
1
2
3
4
5
Samples
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.01
0.02
0.03
0.04
Samples
(b)
−5
−4
−3
−2
−1
0
1
2
3
4
5
Samples
−5
−4
−3
−2
−1
0
1
2
3
4
5
Samples
0
0.01
0.02
0.03
0.04
0
0.01
0.02
0.03
0.04
0.01
0.02
0.03
0.04
0.05
0
True
PROP: Student T 
Est. Posterior
Est. Posterior
True
PROP: Shifted Uniform 
True
PROP: Random walk 
Est. Posterior
PROP: Uniform 
True
Est. Posterior
(d)
(c)
(a)
Probability
Probability
Probability
Probability
FIGURE 3.6
Metropolis–Hastings sampler posterior distribution estimates (105 samples): (a) M-H symmetric proposal:
U(−10,10) with mean and standard deviation estimates (−0.02,0.998) at a 16.2% acceptance rate;(b) M-H symmetric
proposal: (1) with mean and standard deviation estimates (−0.004, 0.72) at a 57.8% acceptance rate; (c) M-H
random walk: U(−5, 5) with mean and standard deviation estimates (−0.005,1.006) at a 31.7% acceptance rate; (d)
Uniform proposal: U(−4, 9) with mean and standard deviation estimates (−0.03, 1.004) at a 24.2% acceptance rate.

3.4
MONTE CARLO APPROACH
79
TABLE 3.1
Metropolis–Hastings Sampling Algorithm
xo →pX(xo)
Initialize
[Draw sample]
̂xi →q(x)
Proposal
[Draw sample]
Acceptance Probability
(xi, ̂xi) = min
{p(̂xi)×q(xi|̂xi)
p(xi)×q(̂xi|xi), 1
}
uk ⟶U(0, 1)
Uniform Sample
[Draw sample]
Decision
xi =
{̂xi
if uk < (xi, ̂xi)
xi−1
otherwise
xi+1 ⟶xi
Next Sample
[Draw sample]
distribution, then many samples are accepted at a high rate, if not the rate is low.
Clearly, the M-H sampling technique and its variants provide a very robust method
for generating samples from a target distribution especially when the proposal covers
the entire range of the target sample space.
△△△
There are a variety of M-H sampling techniques such as the independence sampler,
the hybrid or dynamic (Hamiltonian) sampler, the multipoint samplers, etc. [32]. Also
note that many of these methods are available in freeware (e.g. language-based BUGS
[38] and the MATLAB-based NETLAB [39], PRTools [40]). We summarize the M-H
sampling technique in Table 3.1. Next, we discuss a popular special case of this
approach—the Gibbs sampler.
3.4.4
Gibbs Sampling
The Gibbs simulation-based sampler (G-S), one of the most lexible of the sampling
techniques available. It is a special case of the Metropolis–Hastings approach in which
the acceptance probability (xi, ̂xi) is unity, that is, all samples are accepted [27].
Theoretically, the G-S is based on the fact that the targeted joint posterior distribution
can be determined completely by a set of underlying conditional distributions evolv-
ing directly from Bayes’ rule (joint = conditional×marginal) [29]. It falls into the
class of sampling algorithms termed block-at-a-time or variable-at-a-time methods
[23]. Proof of these methods have a signiicant practical implication, since it can be
shown that the product of the transition distribution of the Markov chain is a product
of conditional transitions which converge to joint posterior as its invariant distri-
bution [30]. It is for this reason that the G-S is called “sampling-by-conditioning”
[28], which will become obvious after we investigate its underlying structure. As
before, it should be realized that both target and proposal distributions must be
known (approximately) and samples must be easily generated from the proposal to be
effective.

80
SIMULATION-BASED BAYESIAN METHODS
Gibbs sampling can be considered an implementation of the M-H technique on
a component-by-component basis of a random vector. It is more restrictive than the
M-H method, but can be more eficient leading to a simpler implementation. The
G-S is especially important in Bayesian problems, since it is uniquely designed for
multivariate problems, that is, it replaces sampling from a high-dimensional vector
with sampling from low-order component blocks [67]. It can be considered a concate-
nation of M-H samplers, one for each component variable of the random vector. This
decomposition has individual target distributions representing a conditional density
or mass for each component given values for all of the other variables. Thus, the
proposal for the component variable of the vector is the conditional density of that
variable given the most recent values for all of the others.
More formally, suppose the random vector X ∈Nx×1 is decomposed into its
components Xk for k = 1, … , Nx. Therefore, the idea is to generate, say X1(i), based
on the conditional distribution Pr(X1|X2(i −1), … , XNx(i −1), Y) and the next sample
drawn X2(i) uses it and the samples available from the previous iteration to sample
from Pr(X2|X1(i) ∪X3(i −1), … , XNx(i −1), Y) and so forth so that at the ith iteration,
we have the kth component sample generated from
Xk(i) ⟶Pr(Xk|{Xn(i)} ∪{Xm(i −1)} ∋m > k; n < k, Y)
(3.40)
If we expand this relation, then we observe the underlying structure of the Gibbs
sampler.
Given the sample set {X(i −1)} then
r Generate the irst sample: X1 →Pr(X1|X2(i −1), … , XNx(i −1), Y) and then
r Generate the next sample: X2 →Pr(X2|X1(i) ∪X3(i −1), … , XNx(i −1), Y)
r Generate the kth sample: Xk →Pr(Xk|{Xn−k, … , Xn(i)}, {XNm+k(i −1), … ,
Xm+k−Nx} ∋m > k; n < k, Y)
So we see that the vector is decomposed component wise and the corresponding
conditional distributions evolve creating the vector sequence of iterates which are the
realization of a Markov chain with transition distribution. We assume that we would
like to go from X′ →X giving the transition probability
Pr(X′, X) = Pr(X1|X′
2, … , X′
Nx, Y) × Pr(X2|X1, X′
3, … , X′
Nx, Y) × ⋯
× Pr(XNx|X1, … , |XNx−1, … , X′
Nx, Y)
(3.41)
The G-S can be shown to satisfy the detailed balance. As a result it converges to
the invariant distribution of the Markov chain which in this case is the joint posterior
distribution [28, 32]. Consider the following example from [20].

3.4
MONTE CARLO APPROACH
81
Example 3.10
Suppose we have a measurement vector y from a bivariate Gaussian with unknown
mean and known covariance, that is,
Pr(X|Y) = (Y, Rxx)
for Rxx =
[
1
�
�
1
]
(3.42)
To apply the G-S to X, we require the conditional posterior from the well-known
properties of the bivariate Gaussian [1] given by
Pr(X1|X2, Y) ∼(y1 + �(x2 −y2), 1 −�2)
Pr(X2|X1, Y) ∼(y2 + �(x1 −y1), 1 −�2)
Thus, the G-S proceeds by alternating samples from these Gaussian distributions,
given (x1(0), x2(0))
Let i = 1, 2, …
r Draw x1(i) →Pr(x1|x2(i −1), Y)
r Draw x2(i) →Pr(x2|x1(i), Y)
So we generate the pairs: (x1(1), x2(1)), (x1(2), x2(2)), … , (x1(i), x2(i)) from the
sampling distribution converging to the joint bivariate Gaussian Pr(X) as the invariant
distribution of the Markov chain.
△△△
Next, we consider a generalized variant of the Gibbs’s sampler—the slice sampler.
3.4.5
Slice Sampling
Slice sampling (S-S) is an MCMC sampling technique based on the premise of
sampling uniformly from the region under the target distribution Pr(X) [19, 31, 32,
36, 37]. Therefore, like all of the previous sampling methods, it can be applied
to any problem for which the target distribution can be evaluated at a point, say
x. It has an advantage over Metropolis methods, being more robust to step-size
variations especially since it performs adaptive adjustments. Slice sampling (S-S) is
a generalized case of the Gibbs sampler based on iterative simulations of the uniform
distribution consisting of one-dimensional transitions. It is also similar to rejection
sampling, in that it draws samples from under the target distribution. However, in
all of these cases the S-S is not bound by their restriction [37]. It is based on the
following proposition proven in Cappe [36].
Proposition:
Let x ∼Pr(X) and u ∼U(0, M), then the pair of random variables
(x, u) are distributed uniformly as (x, u) ∼U(0, M × Pr(X)). Conversely, if (x, u) is
uniformly distributed, then x admits Pr(X) as its marginal distribution.

82
SIMULATION-BASED BAYESIAN METHODS
In its simplest form, the slice sampler technique generates uniform intervals that
capture the samples
r Initialize: xi−1
r Draw uniform samples: ui ⟶U(0, Pr(xi−1))
r Draw uniform samples: xi ⟶U(0, S(ui)) where S(ui) = {x : Pr(xi) ≥ui}
The actual implementation of the algorithm is much more complex and we refer
the interested reader to Neal [31] or MacKay [37] for more details. We merely state
important features of the slice sampler technique.
The S-S involves establishing intervals to ensure the sample points of the target
distribution are included by using an adaptive step size (interval size) applying two
techniques: (1) step-out technique; and (2) shrinking technique. The step-out tech-
nique is used to increase the size of the interval until the new sample xi is included,
while the shrinking technique does the opposite, it decreases the interval size to assure
the original sample xi−1 is included. Consider the following example from Ref. [19]
to illustrate the S-S.
Example 3.11
Suppose we would like to generate samples from a unit Gaussian distribution
x ∼(0, 1) using the slice sampling technique
r Initialize: xi−1 = 0 (Random draw)
r Draw uniform samples: ui ⟶U(0, Pr(xi−1)) = U
(
0,
1
√
2�e−x2∕2
)
r Draw uniform samples: xi ⟶U(−�, �) where �=
√
−ln
√
2�ui
Simulations can now be performed and analyzed.
△△△
We conclude this section with a signal processing example. We are given an
autoregressive (all-pole) model and we would like to generate samples from the
corresponding posterior distribution.
Example 3.12
We have the following all-pole (AR(1)) model
x(t) = −ax(t −1) + �(t −1)
for �∼(0, R��)
Suppose we choose the following parameters for the model: N = 105 samples, a =
0.1, R��= 0.1 and we would like to develop samples from the posterior. Analytically,
we know that the posterior distribution is given by x ∼
(
0, R��
1−a2
)
= (0, 0.101).
We generate the samples using the slice (Gibbs) sampler with the proposal

3.5
IMPORTANCE SAMPLING
83
0
1
2
3
4
5
6
7
8
9
10
11
× 104
−1.5
−1
−0.5
0
0.5
Amplitude
Probability
1
1.5
−1.5
−1
−0.5
0
0.5
1
1.5
0
0.01
0.02
0.03
0.04
Samples
Samples
Slice (Gibbs) samples
Estimated posterior: N(0.002, 0.1003)
AR model:
A=0.1; Rww=0.1
Samples
Burn in
(a)
(b)
FIGURE 3.7
Gibbs (slice) sampler for autoregressive (AR(1)) model:(a) simulated sam-
ples (N = 105); (b) estimated posterior distribution: (0.002, 0.1003) with 10% burn-in
(N = 104) samples.
q(x) ∼(0, 0.1). The results are shown in Fig. 3.7. Using MATLAB we synthesized
the set of samples and estimated their underlying distribution using both histogram
and kernel density with a Gaussian window estimator. The samples including a 10%
burn-in period are shown in Fig. 3.7a along with the estimated distribution in Fig. 3.7b.
The sampler has a 100%-acceptance rate and the estimates are quite good with the
posterior estimated at (0.002, 0.1003).
△△△
This concludes the section on sampling theory and iterative sampling techniques.
Next, we investigate the importance sampler that will lead to the sequential approaches
required to construct Bayesian model-based processors.
3.5
IMPORTANCE SAMPLING
One way to mitigate dificulties with the inability to directly sample from a posterior
distribution is based on the concept of importance sampling. Importance sampling
is a method to compute expectations with respect to one distribution using random
samples drawn from another. That is, it is a method of simulating samples from a
proposal distribution to be used to approximate a targeted (posterior) distribution by

84
SIMULATION-BASED BAYESIAN METHODS
appropriate weighting. Importance sampling is a generalization of the MC approach
which evolves by rewriting Eq. 3.27 as
I = ∫X
f(x) dx = ∫X
( f(x)
q(x)
)
× q(x) dx
for ∫q(x) dx = 1
(3.43)
Here q(x) is referred to as the sampling distribution or more appropriately the impor-
tance sampling distribution, since it samples the target distribution f(x) nonuniformly
giving “more importance” to some values of f(x) than others. We say that the support
of q(x) covers that of f(x), or the samples drawn from q(⋅) overlap the same region
(or more) corresponding to the samples of f(⋅) as illustrated previously in Fig. 3.3.
That is, we say that f(x) and q(x) have the same support if
f(x) > 0 ⇒q(x) > 0
∀x ∈RNx×1
a necessary condition for importance sampling to hold. If we interpret the prior of
Fig. 1.1 as the proposal q(x) and the posterior as the target f(x), then this igure
provides a visual example of coverage.
The integral in Eq. 3.43 can be estimated by
r Drawing N samples from q(x): X(i) ∼q(x) and ̂q(x) ≈1
N
∑N
i=1 �(x −X(i)); and
r Computing the sample mean [28],
I = Eq
{ f(x)
q(x)
}
≈∫
( f(x)
q(x)
)
× 1
N
N
∑
i=1
�(x −X(i)) dx = 1
N
N
∑
i=1
f(X(i))
q(X(i))
with corresponding error variance
Var
[
Eq
{ f(x)
q(x)
}]
= ∫
( f(x)
q(x) −I
)2
× q(x) dx
It is interesting to note that the MC approach provides an unbiased estimator with the
corresponding error variance easily calculated from the above relation.
Consider the case where we would like to estimate the expectation of the function
of X given by f(X). Then choosing an importance distribution q(x) that is similar to
f(x) with covering support gives the expectation estimator
Ep{f(x)} = ∫X
f(x) × p(x) dx = ∫X
f(x)
(p(x)
q(x)
)
× q(x) dx
(3.44)

3.5
IMPORTANCE SAMPLING
85
If we draw samples {X(i)}, i = 0, 1, … , N from the importance distribution q(x) and
compute the sample mean, then we obtain the importance sampling estimator. That
is, assume the perfect sampler ̂q(x) ≈1
N
∑N
i=1 �(x −X(i)) and substitute
Ep{f(x)} = ∫X
f(x)
(p(x)
q(x)
)
× ̂q(x) dx ≈1
N
N
∑
i=1
f(X(i)) ×
(p(X(i))
q(X(i))
)
(3.45)
demonstrating the concept.
The “art” in importance sampling is in choosing the importance distribution q(⋅)
that approximates the target distribution p(⋅) as closely as possible. This is the princi-
pal factor affecting performance of this approach, since variates must be drawn from
q(x) that cover the target distribution. Using the concepts of importance sampling,
we can approximate the posterior distribution with a function on a inite discrete
support. Since it is usually not possible to sample directly from the posterior, we use
importance sampling coupled with an easy to sample proposal distribution q(Xt|Yt)—
this is the crucial choice and design step required in Bayesian importance sampling
methodology. Here Xt = {x(0), … , x(t)} represents the set of dynamic variables and
Yt = {y(0), … , y(t)}, the set of measured data. Therefore, starting with a function of
the set of variables, say f(Xt), we would like to estimate its mean using the importance
concept. That is, using the MC approach, we would like to sample from this posterior
directly and then use sample statistics to perform the estimation. Therefore, we insert
the proposal importance distribution q(Xt|Yt) as before
̂f(t) := E{f(Xt)} = ∫f(Xt)
[Pr(Xt|Yt)
q(Xt|Yt)
]
× q(Xt|Yt) dXt
(3.46)
Now applying Bayes’ rule to the posterior target distribution, and deining a weighting
function as
̃W(t) := Pr(Xt|Yt)
q(Xt|Yt) = Pr(Yt|Xt) × Pr(Xt)
Pr(Yt) × q(Xt|Yt)
(3.47)
Unfortunately, ̃W(t) is not useful because it requires knowledge of the evidence or
normalizing constant Pr(Yt) given by
Pr(Yt) = ∫Pr(Yt|Xt) × Pr(Xt) dXt
(3.48)
which is usually not available. But by substituting Eq. 3.47 into Eq. 3.46 and deining
a new weight W(t) as
W(t) ∝Pr(Xt|Yt)
q(Xt|Yt) = Pr(Yt|Xt) × Pr(Xt)
q(Xt|Yt)
(3.49)

86
SIMULATION-BASED BAYESIAN METHODS
we obtain
̂f(t) =
1
Pr(Yt) ∫f(Xt)
[Pr(Yt|Xt) × Pr(Xt)
q(Xt|Yt)
]
q(Xt|Yt)dXt
=
1
Pr(Yt) ∫W(t) f(Xt) q(Xt|Yt)dXt
(3.50)
which is simply the expectation of the weighted function Eq{W(t)f(Xt)} scaled by
the normalizing constant. From this deinition of the new weighting function in Eq.
3.49, we have
W(t) × q(Xt|Yt) = Pr(Yt|Xt) × Pr(Xt)
(3.51)
Thus, we can now replace the troublesome normalizing constant of Eq. 3.48 using
Eq. 3.51, that is,
̂f(t) =
Eq{W(t) f(Xt)}
Pr(Yt)
=
Eq{W(t) f(Xt)}
∫W(t) × q(Xt|Yt) dXt
=
Eq{W(t) f(Xt)}
Eq{W(t)}
(3.52)
Now drawing samples from the proposal Xt(i) ∼q(Xt|Yt) and using the MC
approach leads to the desired result. That is, from the “perfect” sampling distribution,
we have that
̂q(Xt|Yt) ≈1
N
N
∑
i=1
�(Xt −Xt(i))
(3.53)
and therefore substituting, applying the sifting property of the Dirac delta function,
and deining the “normalized” weights
i(t) :=
Wi(t)
∑N
i=1 Wi(t)
for Wi(t) = Pr(Yt|Xt(i)) × Pr(Xt(i))
q(Xt(i)|Yt)
(3.54)
we obtain the inal estimate
̂f(t) ≈
N
∑
i=1
i(t) × f(Xt(i))
(3.55)

3.6
SEQUENTIAL IMPORTANCE SAMPLING
87
The importance estimator is biased being the ratio of two sample estimators (as in
Eq. 3.52), but it can be shown that it asymptotically converges to the true statistic
and the central limit theorem holds [32, 49]. Thus, as the number of samples increase
(N →∞), an asymptotically optimal estimate of the posterior is
̂Pr(Xt|Yt) ≈
N
∑
i=1
i(t) × �(Xt −Xt(i))
(3.56)
which is the goal of Bayesian estimation. Note that the new weight is W(t) ∝̃W(t),
where ∝is deined as “ proportional to” up to a normalizing constant.
3.6
SEQUENTIAL IMPORTANCE SAMPLING
Suppose we would like to develop a sequential version [41–67] of the batch Bayesian
importance sampling estimator of the previous section. The importance distribution
can be modiied to enable a sequential estimation of the desired posterior distribution,
that is, we estimate the posterior ̂Pr(Xt−1|Yt−1) using importance weights (t −1).
As a new sample becomes available, we estimate the new weight (t) leading to
an updated estimate of the posterior ̂Pr(Xt|Yt). This means that to obtain the new
set of samples Xt(i) ∼q(Xt|Yt) sequentially, we must use the previous set of samples
Xt−1(i) ∼q(Xt−1|Yt−1). Thus, with this in mind, the importance distribution q(Xt|Yt)
must admit a marginal distribution q(Xt−1|Yt−1) implying the following Bayesian
factorization
q(Xt|Yt) = q(Xt−1|Yt−1) × q(x(t)|Xt−1, Yt)
(3.57)
which satisies the probability chain rule decomposition
q(Xt|Yt) =
t∏
k=0
q(x(k)|Xt−k, Yk)
(3.58)
Now let us see how this type of importance distribution choice can lead to the
desired sequential solution [58]. We start with the deinition of the unnormalized
weight of Eq. 3.49 and substitute into Eq. 3.57 while applying Bayes’ rule to the
numerator. The resulting weighting function is
W(t) =
Pr(Yt|Xt) × Pr(Xt)
q(Xt−1|Yt−1) × q(x(t)|Xt−1, Yt)
(3.59)

88
SIMULATION-BASED BAYESIAN METHODS
Motivated by the deinition of W(t −1), we multiply and divide by the Bayesian
factor Pr(Yt−1|Xt−1) × Pr(Xt−1) and group to obtain
W(t) =
[Pr(Yt−1|Xt−1) × Pr(Xt−1)
q(Xt−1|Yt−1)
]
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
Previous weight
×
Pr(Yt|Xt) × Pr(Xt)
[Pr(Yt−1|Xt−1) × Pr(Xt−1)] × q(x(t)|Xt−1, Yt)
Therefore, we can write
W(t) = W(t −1) ×
Pr(Yt|Xt) × Pr(Xt)
Pr(Yt−1|Xt−1) × Pr(Xt−1) × q(x(t)|Xt−1, Yt)
(3.60)
Using the probabilistic chain rule of Eq. 2.63 for each of the conditionals and
imposing the Markov property of the dynamic variable along with the conditional
independence conditions of the measurements, we obtain
Pr(Yt|Xt) =
t∏
k=0
Pr(y(k)|x(k)) = Pr(y(t)|x(t))
t−1
∏
k=0
Pr(y(k)|x(k))
Pr(Xt) =
t∏
k=0
Pr(x(k)|x(k −1)) = Pr(x(t)|x(t −1))
t−1
∏
k=0
Pr(x(k)|x(k −1))
(3.61)
Therefore, recognizing the relationship between these expansions as well as those at
t −1 and factoring the tth term (as shown above), we can cancel both numerator and
denominator chains to extract the inal recursions, that is,
W(t) = W(t −1) ×
Pr(y(t)|x(t))
[∏t−1
k=0 Pr(y(k)|x(k))
]
[∏t−1
k=0 Pr(y(k)|x(k))
]
×
Pr(x(t)|x(t −1))
[∏t−1
k=0 Pr(x(k)|x(k −1))
]
[∏t−1
k=0 Pr(x(k)|x(k −1))
]
×
1
q(x(t)|Xt−1, Yt)
(3.62)
which gives the inal recursion
W(t) = W(t −1) × Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
q(x(t)|Xt−1, Yt)
(3.63)

3.6
SEQUENTIAL IMPORTANCE SAMPLING
89
Another way of developing this relationship is to recall the Bayesian solution to
the batch posterior estimation problem in Eq. 2.79. We have
Pr(Xt|Yt) =
[Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
Pr(y(t)|Yt−1)
]
× Pr(Xt−1|Yt−1)
or recognizing the denominator as just the evidence or normalizing distribution and
not a function of Xt, we have
Pr(Xt|Yt) = C × Pr(y(t)|x(t)) × Pr(x(t)|x(t −1)) × Pr(Xt−1|Yt−1)
(3.64)
or simply
Pr(Xt|Yt) ∝Pr(y(t)|x(t)) × Pr(x(t)|x(t −1)) × Pr(Xt−1|Yt−1)
(3.65)
Substituting this expression for the posterior in the weight relation as before, we have
W(t) ∝Pr(Yt|Xt)
q(Xt|Yt) = Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
q(x(t)|Xt−1, Yt)
× Pr(Xt−1|Yt−1)
q(Xt−1|Yt−1)
⏟⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏟
Previous weight
(3.66)
giving the desired expression of Eq. 3.63.
These results enable us to formulate a generic Bayesian sequential importance
sampling algorithm
1. Draw
samples
from
the
proposed
importance
distribution:
xi(t) →
q(x(t)|Xt−1, Yt);
2. Determine
the
required
conditional
distributions:
Pr(xi(t)|x(t −1)),
Pr(y(t)|xi(t));
3. Calculate the unnormalized weights: Wi(t) using Eq. 3.63 with x(t) →xi(t);
4. Normalize the weights: i(t) in Eq. 3.54; and
5. Estimate the posterior distribution: ̂Pr(Xt|Yt) = ∑N
i=1 i(t)�(x(t) −xi(t))
Once the posterior is estimated, the desired statistics evolve directly. We summarize
the generic sequential importance sampling in Table 3.2.
Introducing these ideas of Bayesian importance sampling, we are now ready to
consider applying this approach to a variety of models which we discuss in the next
chapter.

90
SIMULATION-BASED BAYESIAN METHODS
TABLE 3.2
Bayesian Sequential Importance Sampling Algorithm
Initialize
xi(0) ∼q(x(0)|y(0));
i = 1, … , Np
[Sample prior]
Wi(0) = Pr(y(0)|xi(0))×Pr(xi(0))
Pr(xi(0)|y(0))
[Weights]
i(0) =
Wi(0)
∑Np
i=1 Wi(0)
[Normalize]
Importance Sampling
Sample
xi(t) ∼q(x(t)|Xt−1, Yt);
i = 1, … , Np
[Sample]
Weight Update
Wi(t) = Wi(t −1) × Pr(y(t)|xi(Pr(x(t)|xi(t−1)))×Pr(x(t)|xi(t−1))
q(xi(t)|Xi(t−1),Yt)
[Weights]
Weight Normalization
i(t) =
Wi(t)
∑Np
i=1 Wi(t)
Distribution
̂Pr(Xt|Yt) ≈
Np
∑
i=1
i(t)�(x(t) −xi(t))
[Posterior distribution]
3.7
SUMMARY
In this chapter we discussed the importance of simulation-based sampling methods for
nonlinear signal processing. Starting with the basics of PDF estimation and statistical
sampling theory, we motivated statistical approaches to sampling both when we
have analytical expressions for the distributions and when we do not have them and
must resort to pure sampling methodologies. We discussed the uniform sampling and
rejection sampling methods examining their inherent advantages and disadvantages.
We showed how these approaches led to more sophisticated techniques evolving from
Markov chain theory and leading to the Metropolis–Hastings sampler. In certain cases
the Gibbs sampler, a variant of the Metropolis–Hastings approach, was developed and
discussed along with its variant—the slice sampler. All of these methods fall into the
general class of iterative methods. Next, we concentrated on the importance sampling
approach leading to its recursive version—the sequential importance sampler which
is the workhorse of this text.
MATLAB NOTES
MATLAB is a command oriented vector-matrix package with a simple yet effec-
tive command language featuring a wide variety of embedded C language con-
structs making it ideal for signal processing applications and graphics. MAT-
LAB has a Statistics Toolbox that incorporates a large suite of PDFs and CDFs
as well as “inverse” CDF functions ideal for simulation-based algorithms. The

REFERENCES
91
mhsample command incorporates the Metropolis, Metropolis–Hastings, and
Metropolis independence samplers in a single command while the Gibbs sam-
pling approach is adequately represented by the more eficient slice sampler
(slicesample). There are even speciic “tools” for sampling as well as the inverse
CDF method captured in the randsample command. PDF estimators include
the usual histogram (hist) as well as the sophisticated kernel density estimator
(ksdensity) offering a variety of kernel (window) functions (Gaussian, etc.) and
ICDF techniques. As yet, no sequential algorithms are available. Type help stats
in MATLAB to get more details or go to the MathWorks website.
REFERENCES
1. A. Papoulis and S. Pillai, Probability, Random Variables and Stochastic Processes
(New York: McGraw-Hill, 2002).
2. P. Peebles, Probability, Random Variables and Random Signal Parameters, 4th Ed.
(New York: McGraw-Hill, 2001).
3. R. Duda and P. Hart, Pattern Classsiication (New York: John Wiley & Sons, Inc., 2000).
4. T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical Learning (New York:
John Wiley & Sons, Inc., 2001).
5. S. Theodoridis and K. Koutroumbas, Pattern Recognition (New York: Academic Press,
1999).
6. E. Parzen, “On estimation of a probability density function and mode,” Ann. Math. Stat.,
33, 1065–1076, 1962.
7. H. Shimazaki and S. Shinomoto, “A method for selecting the bin size of a time histogram,”
Neural Comput., 19, 1503–1527, 2007.
8. A. Jazwinski, Stochastic Processes and Filtering Theory (New York: Academic Press,
1970).
9. A. Sage and J. Melsa, Estimation Theory with Applications to Communications and
Control (New York: McGraw-Hill, 1971).
10. B. Anderson and J. Moore, Optimal Filtering (Englewood Cliff, NJ: Prentice-Hall, 1979).
11. J. Candy, Model-Based Signal Processing (Hoboken, NJ: John Wiley & Sons, Inc./IEEE
Press, 2006).
12. H. Tanizaki, Nonlinear Filters (New York: Springer-Verlag, 1994).
13. I. Rhodes, “A tutorial introduction to estimation and iltering,” IEEE Trans. Autom. Contr.,
AC-16, 1971.
14. J. Hammersley and K. Morton, “Poor man’s Monte Carlo,” Symposium on Monte Carlo
Methods, Royal Statistical Society, pp. 23–38, 1954.
15. S. Ross, A Short Course in Simulation (New York: McMillan, 1990).
16. M. Tanner, Tools for Statistical Inference, 2nd Ed. (New York: Springer-Verlag, 1993).
17. W. Gilks, S. Richardson, and D. Spiegelhalter, Markov Chain Monte Carlo in Practice
(New York: Chapman & Hall/CRC, 1996).
18. A. Smith and A. Gelfand, “Bayesian statistics without tears: a sampling-resampling per-
spective,” Am. Statistician, 44, 4, 84–88, 1992.

92
SIMULATION-BASED BAYESIAN METHODS
19. C. Robert and G. Casella, Monte Carlo Statistical Methods (New York: Springer, 1999).
20. A. Gelman, J. Carlin, H. Stern, and D. Rubin, Bayesian Data Analysis, 2nd Ed.
(New York: Chapman & Hall/CRC, 2004).
21. M. Mitzenmacher and E. Upfal, Probability and Computing: Randomized Algorithms and
Probabilistic Analysis (Cambridge: Cambridge University Press, 2005).
22. J. von Neumann, “Various techniques used in connection with random digits,” Nat. Bureau
Standards Applied Math. Series, 12, 36–38, 1951.
23. W. Hastings, “Monte Carlo sampling methods using Markov chains and their applications,”
Biometrika, 57, 97–109, 1970.
24. N. Metropolis, N. Rosenbutt, A. Rosenbutt, M. Teller, and A. Teller, “Equations of state
calculations by fast computing machines,” J. Chem. Phys., 21, 1087–1092, 1953.
25. S. Geman and D. Geman, “Stochastic relaxation: Gibbs distributions and Bayesian
restoration of images,” IEEE Trans. Patten Analy. and Mach. Intell., 6, 721–741,
1984.
26. D. Rubin, “A noniterative sampling/importance resampling alternative to the data aug-
mentation algorithm for creating a few imputations when fractions of missing information
are modest: the SIR algorithm,” J. Amer. Stat. Assoc., 52, 543–546, 1987.
27. A. Gelfand and A. Smith, “Sampling-based approaches to calculating marginal densities,”
J. Amer. Stat. Assoc., 85, 410, 398–409, 1990.
28. J. Ruanaidh and W. Fitzgerald, Numerical Bayesian Methods Applied to Signal Processing
(New York: Springer-Verlag, 1996).
29. G. Casella and E. George, “Explaining the Gibbs sampler,” Am. Statistician, 46, 3, 167–
174, 1992.
30. S. Chib and E. Greenberg, “Understanding the Metropolis–Hastings algorithm,” Am.
Statistician, 49, 4, 327–335, 1995.
31. R. Neal, “Slice sampling,” Ann. Stat., 31, 3, 705–767, 2003.
32. J. Liu, Monte Carlo Strategies in Scientiic Computing (New York: Springer-Verlag, 2001).
33. W. Fitzgerald, “Markov chain Monte Carlo methods with applications to signal process-
ing,” Signal Proc., 81, 3–18, 2001.
34. C. Andrieu, N. de Freitas, A. Doucet, and M. Jordan, “An introduction to MCMC for
machine learning,” Mach. Learn., 50, 5–43, 2003.
35. D. Frenkel, “Introduction to Monte Carlo methods,” J. von Neumann Inst. Comput. NIC
series, 23, 29–60, 2004.
36. O. Cappe, E. Moulines and T. Ryden, Inference in Hidden Markov Models (New York:
Springer-Verlag, 2005).
37. D. MacKay, Information Theory, Inference and Learning Algorithms (Cambridge, UK:
Cambridge University Press, 2006).
38. D. Spiegelhalter, A. Thomas, N. Best, and D. Lunn, WinBUGS User Manual (London,
UK: Imperial College, 2003). Available at: http://www.mrc-bsu.cam.ac.uk
39. I. Nabney, NETLAB Algorithms for Pattern Recognition (New York: Springer, 2001).
40. R. Duin, P. Juszczak, P. Paclik, E. Pekalska, D. de Ridder, and D. Tax, PRTools4: A
MATLAB Toolbox for Pattern Recognition (Delft, The Netherlands: Delft University,
2004) Available at: http://prtools.org
41. A. Doucet and X. Wang, “Monte Carlo methods for signal processing,” IEEE Signal Proc.
Mag.24, 5, 152–170, 2005.

REFERENCES
93
42. G. Kitagawa, “Non-Gaussian modeling of nonstationary time series,” J. Am. Stat. Assoc.,
82, 400, 1032–1063, 1987.
43. G. Kitagawa, “A nonlinear smoothing method for time series analysis,” Statistica Sinica,
1, 2, 371–388, 1991.
44. N. Gordon, D. Salmond, and A. Smith, “A novel approach to nonlinear non-Gaussian
Bayesian state estimation,” IEE Proc. F., 140, 107–113, 1993.
45. A. Kong, J. Liu, and W. Wong, “Sequential imputations and Bayesian missing data
problems,” J. Am. Stat. Assoc., 89, 425, 278–288, 1994.
46. J. Liu and R. Chen, “Blind deconvolution via sequential imputations,” J. Am. Stat. Assoc.,
90, 430, 567–576, 1995.
47. G. Kitagawa, “Monte Carlo ilter and smoother for non-Gaussian nonlinear state-space
models,” J. Comput. Graphical Stat., 5, 1, 1–25, 1996.
48. G. Kitagawa and W. Gersch, Smoothness Priors Analysis of Time Series (New York:
Springer-Verlag, 1996).
49. M. West and J. Harrison, Bayesian Forcasting and Dynamic Models, 2nd Ed. (New York:
Springer-Verlag, 1997).
50. J. Liu and R. Chen, “Sequential Monte Carlo methods for dynamic systems,” J. Am.
Statistical Assoc., 93, 443, 1032–1044, 1998.
51. G. Kitagawa, “Self-organizing state space model,” J. Am. Stat. Assoc., 93, 443, 1203–1215,
1998.
52. M. Isard and A. Blake, “Condensation–conditional density propagation for visual track-
ing,” Int. J. Comput. Vis., 29, 1, 5–28, 1998.
53. J. Liu, R. Chen, and W. Wong, “Rejection control and sequential importance sampling,”
J. Am. Stat. Assoc., 93, 443, 1022–1031, 1998.
54. M. Pitt and N. Shephard, “Filtering via simulation: Auxiliary particle ilters,” J. Am. Stat.
Assoc., 94, 446, 590–599, 1999.
55. A. Doucet, S. Godsill, and C. Andrieu, “On sequential Monte Carlo sampling methods for
Bayesian iltering,” Stat. Comput., 10, 3, 197–208, 2000.
56. A. Doucet, N. de Freitas, and N. Gordon, Sequential Monte Carlo Methods in Practice
(New York: Springer-Verlag, 2001).
57. S. Godsill and P. Djuric, “Special issue: Monte Carlo methods for statistical signal pro-
cessing.” IEEE Trans. Signal Proc., 50, 2002.
58. M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp “A tutorial on particle ilters
for online nonlinear/non-Gaussian Bayesian tracking.” IEEE Trans. Signal Proc., 50, 2,
174–188, 2002.
59. P. Djuric, J. Kotecha, J. Zhang, Y. Huang, T. Ghirmai, M. Bugallo, and J. Miguez, “Particle
iltering.” IEEE Signal Proc. Mag., 20, 5, 19–38, 2003.
60. B. Ristic, S. Arulampalam, and N. Gordon, Beyond the Kalman Filter: Particle Filters for
Tracking Applications (Boston, MA: Artech House, 2004).
61. S. Haykin and N. de Freitas, “Special issue: Sequential state estimation: from Kalman
ilters to particle ilters.” Proc. IEEE, 92, 3, 2004.
62. C. Andrieu, A. Doucet, S. Singh, and V. Tadic, “Particle methods for change detection,
system identiication and control,” Proc. IEEE, 92, 3, 423–438, 2004.
63. A. Harvey, S. Koopman, and N. Shephard, State Space and Unobserved Component
Models (Cambridge: Cambridge University Press, 2004).

94
SIMULATION-BASED BAYESIAN METHODS
64. H. Sorenson and D. Alspach, “Recursive Bayesian estimation using Gaussian sums,”
Automatica, 7, 465–479, 1971.
65. R. van der Merwe, A. Doucet, N. de Freitas, and E. Wan, “The unscented particle ilter,”
in Advances in Neural Information Processing Systems 13 (Cambridge, MA: MIT Press,
2000).
66. S. Haykin, Kalman Filtering and Neural Networks (Hoboken, NJ: John Wiley & Sons,
Inc., 2001).
67. J. Spall, “Estimation via Markov chain Monte Carlo,” IEEE Control Sys. Magz., 4, 34–45,
2003.
PROBLEMS
3.1
Let x be a discrete random variable with probability mass function (PMF)
pX(x) =
3!
x! (3 −x)!
(2
3
)x (1
3
)3−x
x = 0, 1, 2, 3
What is the PMF of y, pY(y), when y = x2?
3.2
Let z be the distance from the origin to a random point selected within the unit
circle (x2 + y2 < 1). Let z = x2 + y2, then
(a) What is the probability of the selected point lying within the unit circle?
(b) What is the CDF of z? What is its PDF?
(c) Suppose �= z2, what is pW(�)? PW(�)?
3.3
Let x ∼U(0, 1) and y = −2 ln x, what is pY(y)?
3.4
Suppose we have a bivariate distribution with point (X,Y) from a unit square
such that
pXY(x, y) = 1,
0 < x < 1,
0 < y < 1
Let z = x + y, what is the CDF of z? PDF of z?
3.5
A source emits particles that decay at a distance x (x ∼xp(�)) from the
source. The measurement instrument can only observe these events in a win-
dow of length 20 cm (x = 1 −20 cm). N decays are observed at locations
{xi} = {1, … , N}. Using Bayes’ rule [37]
(a) What is the characteristic length �?
(b) Plot the distributions for {xi} = {1.5, 2, 3, 4, 5, 12}.
3.6
For a particular television show, a contestant is given the following instructions:
r There are three doors labeled 1, 2, 3 with a prize hidden behind one of them.
Select one of the doors, but it will NOT be opened.
r The host will open one of the other two doors, but will NOT reveal if the
prize is there.

PROBLEMS
95
r The contestant must now make a decision to keep his original choice or
choose another door.
r All the doors will then be opened and the prize revealed
What should the contestant do?
(a) Stay with the original choice?
(b) Switch to the remaining door?
(c) Does it make any difference?
(Hint: Use Bayes’ rule to answer these questions)
3.7
Suppose we would like to simulate a random variable X such that Pr(X = i) =
{0.2, 0.15, 0.25, 0.40}.
(a) Sketch out an algorithm using the inverse transform method to generate
realizations of X choosing an ascending approach for X = 1, X = 2, X = 3,
and X = 4.
(b) Sketch out an algorithm using the inverse transform method to generate
realizations of X choosing a descending approach for X = 4, X = 3, X = 1,
and X = 2.
(c) Which approach is more eficient? Why?
3.8
We would like to simulate the value of a discrete random variable X with
associated probabilities: Pr(X = i) = {0.11, 0.12, 0.09, 0.08, 0.12, 0.10, 0.09,
0.09, 0.10, 0.10}. Using the rejection method with M = max Pr(X=i)
Pr(ui)
for ui ∼
U(0, 10)
(a) Sketch out rejection sampling algorithm for this problem.
(b) Using this approach synthesize 1000 samples and estimate the histogram?
Estimate the kernel density? (Hint: MATLAB has the commands hist and
ksdensity to perform these operations)
(c) Does the estimated distribution appear to be any classical closed form (e.g.,
Poisson)? If so which one?
3.9
Suppose the continuous random variable X has cumulative distribution PX(x) =
xk. Using the inverse transform approach, sketch the methodology to synthesize
X. How would you do this using the rejection approach? Generate 1000 samples
and estimate the distributions.
3.10 Use the rejection sampling method to generate the continuous random variable
x with density pX(x) = 20x(1 −x)3, 0 < x < 1. (Hint: Select q(x) = 1 and ind
the maximum ratio of the densities to obtain M)
3.11 We would like to compute the solution to the integral
= ∫
b
a
f(x)dx
Using the results of Example 3.7, develop the more general MC solution.

96
SIMULATION-BASED BAYESIAN METHODS
3.12 Suppose we have a bivariate Gaussian distribution with unknown mean �=
[�1�2]′ and known covariance matrix
C =
[
1
p
p
1
]
and a uniform prior on �. A single observation (y1, y2) then has Gaussian
posterior
Pr(�|Y) ∼(Y, C)
for Y = [y1y2]′
Sketch out the Gibbs sampler algorithm for this problem.
3.13 Develop the Metropolis algorithm for a bivariate unit Gaussian target distribu-
tion (Θ : 0, I) with prior Pr(Θo) (e.g., U(0, 1)). The proposal distribution is
bivariate Gaussian also, (Θ∗: 0, (1∕5)2I).
3.14 We would like to use MATLAB to simulate the Metropolis–Hastings sampler
(mhsample) for the following case with the target distribution being a standard
Gaussian (5, 1) and the proposal Rayleigh distributed with parameter b =
1.5. Use a 10% sample burn-in. Compare these results to the slice sampler
(slicesample). Use (ksdensity) to estimate the distribution of the resulting
samples for each algorithm for the comparison.
3.15 Develop the Metropolis–Hastings sampler for a second-order autoregressive
model (AR(2)) with known coeficients {a1, a2} = {1, −0.5} driven by Gaussian
noise with �∼(0, 1).
(a) Develop the exact likelihood for the parameters Pr(Y|a, �2).
(b) What is the posterior distribution for the parameters Pr(a, �2|Y)? (Hint:
Assume the prior is just an indicator function)
(c) Develop the M-H-sampler for this problem.
3.16 Suppose we would like to generate samples from a bivariate Gaussian with
mean vector zero and covariance
C =
[
1
0.5
0.5
1
]
(a) Choose a uniform proposal U(−3, 3) and develop the M-H-sampler algo-
rithm with a 5% burn-in and N = 10,000 samples. (Hint: Use MATLAB
mhsample command)

PROBLEMS
97
(b) Using the MC approach, estimate the expected value E{f(X)} = [1
1]X
(c) Compare these results to those obtained using the slice sampler. (Hint: Use
MATLAB slicesample command)
3.17 Set up the Gibbs sampler (G-S) for a joint (X, Y) exponential distribu-
tion on an interval of length (0, I). Estimate the marginal distribution of X,
Pr(X), and compare the results to a simulated data set based on N = 500
samples.

4
STATE–SPACE MODELS FOR
BAYESIAN PROCESSING
4.1
INTRODUCTION
In this chapter we investigate the development of models for Bayesian estimation
[1–16] using primarily the state–space representation—a versatile and robust model
especially for random signals. We start with the deinition of state and the basic
principles underlying these characterizations and then show how they are incorporated
as propagation distributions for Bayesian processors in the following chapter. We
review the basics of state–space model development with all of their associated
properties starting with the continuous-time processes, then sampled-data systems,
and inally proceeding to the discrete-time state–space. Next we develop the stochastic
version leading to Gauss–Markov representations when the models are driven by
white noise and then proceed to the nonlinear case [6–15]. Here we again drive
the models with white Gaussian noise, but the results are not necessarily Gaussian.
We develop linearization techniques based on Taylor-series expansions to arrive at
linearized Gauss–Markov models.
State–space models are easily generalized to multichannel, nonstationary, and non-
linear processes. They are very popular for model-based signal processing primarily
because most physical phenomena modeled by mathematical relations naturally occur
in state–space form (see Ref. [13] for details). With this motivation in mind, let us pro-
ceed to investigate the state–space representation in a more general form to at least
“touch” on its inherent richness. We start with continuous-time systems and then
proceed to sampled-data followed by the discrete-time representation—the primary
focus of this text. We begin by formally deining the concept of state [1].
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
98

4.2
CONTINUOUS-TIME STATE–SPACE MODELS
99
4.2
CONTINUOUS-TIME STATE–SPACE MODELS
The state of a system at time t is the “minimum” set of variables (state variables)
along with the input suficient to uniquely specify the dynamic system behavior for all
t over the interval t ∈[t0, ∞). The state vector is the collection of state variables into a
single vector. The idea of a minimal set of state variables is critical and all techniques
to deine them must ensure that the smallest number of “independent” states have
been deined in order to avoid possible violation of some important system theoretic
properties [2, 3].
Let us consider a general deterministic formulation of a nonlinear dynamic system
including the output (measurement) model in state–space form (continuous time)1
̇xt = A(xt, ut) = a(xt) + b(ut)
yt = C(xt, ut) = c(xt) + d(ut)
for xt, yt, and ut the respective Nx-state, Ny-output, and Nu-input vectors with corre-
sponding system (process), input, measurement (output), and feedthrough functions.
The Nx-dimensional system and input functions are deined by a(⋅) and b(⋅), while
the Ny-dimensional output and feedthrough functions are given by c(⋅) and d(⋅).
In order to specify the solution of the Nxth order differential equations completely,
we must specify the above noted functions along with a set of Nx-initial conditions
at time t0 and the input for all t ≥t0. Here Nx is the dimension of the “minimal” set
of state variables.
If we constrain the state–space representation to be linear in the states, then we
obtain the generic continuous-time, linear time-varying state–space model given by
̇xt = Atxt + Btut
yt = Ctxt + Dtut
(4.1)
where xt ∈Nx×1, ut ∈Nu×1, yt ∈Ny×1 and the respective system, input, output,
and feedthrough matrices are A ∈Nx×Nx, B ∈Nx×Nu, C ∈Ny×Nx and D ∈Ny×Nu.
The interesting property of the state–space representation is to realize that these
models represent a complete generic form for almost any physical system. That is, if
we have an RLC-circuit or a MCK-mechanical system, their dynamics are governed
by the identical set of differential equations, but only their coeficients differ. Of
course, the physical meaning of the states are different, but this is the idea behind state–
space—many physical systems can be captured by this generic form of differential
equations, even though the systems are physically different. Systems theory, which is
essentially the study of dynamic systems, is based on the study of state–space models
and is rich with theoretical results exposing the underlying properties of the dynamic
system under investigation. This is one of the major reasons why state–space models
are employed in signal processing, especially when the system is multivariable having
1 We separate xt and ut for future models, but it is not really necessary.

100
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
multiple inputs and multiple outputs. Next we develop the relationship between the
state–space representation and input–output relations—the transfer function.
For this development we constrain the state–space representation above to be a
(deterministic) linear time-invariant (LTI) state–space model given by
̇xt = Acxt + Bcut
yt = Ccxt + Dcut
(4.2)
where At →Ac, Bt →Bc, Ct →Cc, and Dt →Dc are their time-invariant counterparts
with the subscript “c’ annotating continuous-time matrices.
This LTI model corresponds to the constant coeficient differential equation solu-
tions which can be solved using Laplace transforms. Taking the Laplace transform
of these equations, we have
sX(s) −xt0 = AcX(s) + BcU(s)
and solving for X(s)
X(s) = (sI −Ac)−1xt0 + (sI −Ac)−1BcU(s)
(4.3)
where I ∈Nx×Nx is the identity matrix. The corresponding output is
Y(s) = CcX(s) + DcU(s)
(4.4)
Therefore, combining these relations, we obtain
Y(s) = [Cc(sI −Ac)−1Bc + Dc]U(s) + Cc(sI −Ac)−1xt0
(4.5)
From the deinition of transfer function (zero initial conditions), we have the desired
result
H(s) = Cc(sI −Ac)−1Bc + Dc
(4.6)
Taking the inverse Laplace transform of this equation gives us the corresponding
impulse response matrix of the LTI system as [1]
H(t, �) = CceAc(t−�)Bc + Dc�(t −�)
for t ≥�
(4.7)
So we see that the state–space representation enables us to express the input–output
relations interms of theinternal variables or states. Notealsothat this is amultivariable
representation as compared to the usual single input–single output (scalar) systems
models that frequently appear in the signal processing literature.
Now that we have the multivariable transfer function representation of our LTI
system, we can solve the state equations directly using inverse transforms to obtain

4.2
CONTINUOUS-TIME STATE–SPACE MODELS
101
the time-domain solutions. First we simplify the notation by deining the Laplace
transform of the state-transition matrix or the so-called resolvent matrix of systems
theory [1, 3] as
Φc(s) := (sI −Ac)−1
(4.8)
Therefore we can rewrite the transfer function matrix as
H(s) = CcΦc(s)Bc + Dc
(4.9)
and the corresponding state–input transfer matrix by
X(s) = Φc(s)xt0 + Φc(s)BcU(s)
(4.10)
Taking the inverse Laplace transformation gives the time domain solution
xt = −1[X(s)] = Φc(t, t0)xt0 + Φc(t, t0)Bc ∗ut
or
xt = Φc(t, t0)xt0
⏟⏞⏞⏞⏟⏞⏞⏞⏟
Zero input
+ ∫
t
t0
Φc(t, �)Bcu�d�
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
Zero state
(4.11)
with corresponding output solution
yt = CcΦc(t, t0)xt0 + ∫
t
t0
CcΦc(t, �)Bcu�d�
(4.12)
The state-transition matrix Φc(t, t0) is the critical component in the solution of the
state equations. Ignoring the input (zero state) of the LTI state–space system, we have
the set of (homogeneous) vector-matrix state equations
̇xt = Acxt
(4.13)
It is well known from linear algebra [1] that this equation has the matrix exponential
as its solution
xt = Φc(t, t0)xt0 = eAc(t−t0)xt0
(4.14)
The meaning of “transition” is now clear since knowledge of the transition matrix
Φc(t, t0) enables us to calculate the transition of the state vector from time t0 to any
t > t0. Taking the Laplace transform of this equation gives
X(s) = Φc(s)xt0 = (sI −Ac)−1xt0
with
eAct = −1[(sI −Ac)−1]
(4.15)

102
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
We have that the state-transition matrix for an LTI system is
Φc(t, t0) = eAc(t−t0),
t ≥t0
(4.16)
Revisiting the continuous-time system of Eq. 4.11 and substituting the matrix expo-
nential for the state-transition matrix gives the LTI solution as
xt = eAc(t−t0)xt0 + ∫
t
t0
eAc(t−�)Bcu�d�
(4.17)
with corresponding measurement system
yt = Ccxt
(4.18)
In general, the state-transition matrix satisies the following properties [1, 2]:
1. Φc(t, t0) is uniquely deined for t, t0 ∈[0, ∞)
[Unique]
2. Φc(t, t) = I
[Identity]
3. Φc(t) satisies the matrix differential equation:
̇Φc(t, t0) = AtΦc(t, t0),
Φc(t0, t0) = I,
t ≥t0
(4.19)
4. Φc(t, t0) = Φc(t, �) × Φc(�, �) × ⋯× Φc(�, t0)
[Semigroup]
5. Φc(t, �)−1 = Φc(�, t)
[Inverse]
Thus, the transition matrix plays a pivotal role in LTI systems theory for the
analysis and prediction of the response of linear time-invariant and time-varying
systems [2]. For instance, the poles of an LTI govern such important properties as
stability and response time. The poles are the roots of the characteristic (polynomial)
equation of Ac, which is found by solving for the roots of the determinant of the
resolvent, that is,
|Φc(s)| = |(sI −Ac)|s=pi = 0
(4.20)
Stability is determined by assuring that all of the poles lie within the left half of the
S-plane. The poles of the system determine its response as
yt =
Nx
∑
i=1
Ki e−pit
(4.21)
where Ac is diagonal which in this case is given by Ac = diag[p1, p2, … , pNx], the
eigenvalues of Ac. Next we consider the sampled-data, state–space representation.

4.3
SAMPLED-DATA STATE–SPACE MODELS
103
4.3
SAMPLED-DATA STATE–SPACE MODELS
Sampling a continuous-time system is commonplace with the advent of high speed
analog-to-digital converters (ADC) and modern computers. A sampled-data sys-
tem lies somewhere between the continuous analog domain (physical system) and
the purely discrete domain (stock market prices). Since we are strictly sampling a
continuous-time process, we must assure that all of its properties are preserved. The
well-known Nyquist sampling theorem precisely expresses the required conditions to
achieve “perfect” reconstruction of the process from its samples [13].
Thus, if we have a physical system governed by continuous-time dynamics and we
“sample” it at given time instants, then a sampled-data model can be obtained directly
from the solution of the continuous-time state–space model. That is, we know from
the previous section that
xt = Φc(t, t0)xt0 + ∫
t
t0
Φc(t, �)Bc(�)u�d�
where Φc(⋅, ⋅) is the continuous-time state-transition matrix that satisies the matrix
differential equation
̇Φc(t, t0) = AtΦc(t, t0),
Φc(t0, t0) = I,
t ≥t0
Sampling this system such that t →tk over the interval (tk, tk−1], we have the
corresponding sampling interval deined by Δtk := tk −tk−1. Note this representation
need not necessarily be equally spaced—another important property of the state–
space representation. Thus the sampled solution becomes (with notation change)
x(tk) = Φ(tk, tk−1)x(tk−1) + ∫
tk
tk−1
Φ(tk, �)Bc(�)u�d�
(4.22)
and therefore from the differential equation above, we have the solution
Φ(tk, tk−1) = ∫
tk
tk−1
A(�)Φ(tk, �) d�
for
Φ(t0, t0) = I
(4.23)
where Φ(tk, tk−1) is the sampled-data state-transition matrix—the critical component
in the solution of the state equations enabling us to calculate the state evolution in
time.
If we further assume that the input excitation is piecewise constant (u�→u(tk−1))
over the interval (tk, tk−1], then it can be removed from under the superposition
integral in Eq. 4.22 to give
x(tk) = Φ(tk, tk−1)x(tk−1) +
(
∫
tk
tk−1
Φ(tk, �)Bc(�) d�
)
× u(tk−1)
(4.24)

104
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
Under this assumption, we can deine the sampled input transmission matrix as
B(tk−1) := ∫
tk
tk−1
Φ(tk, �)Bc(�) d�
(4.25)
and therefore the sampled-data state–space system with equally or unequally sampled
data is given by
x(tk) = Φ(tk, tk−1)x(tk−1) + B(tk−1)u(tk−1)
y(tk) = C(tk)x(tk)
(4.26)
Computationally, sampled-data systems pose no particular problems when care is
taken, especially since reasonable approximation and numerical integration methods
exist [17]. For instance, the following three methods of solving for the state transition
and input transmission matrices can be quite effective. If we constrain the system to be
LTI, then we have that the matrix exponential can be represented by the Taylor-series
expansion
eAcΔtk =
∞
∑
i=0
(Ac Δtk)i
i!
(4.27)
Truncating the series is possible at an acceptable error magnitude [17]. This is called
the series approach to estimating the state-transition matrix and can be determined
for a inite sum. For example, a simple irst-order approximation uses the relations
Φ(tk, tk−1) ≈(I + ΔtkAc)
B(tk) ≈ΔtkBc
(4.28)
This direct approach can yield unsatisfactory results; however, one improved
solution is based on the Pad´e approximation incorporating a scaling and squaring
technique [17, 18]. This scaling and squaring property of the matrix exponential is
given by
eAcΔtk = (eAcΔtk∕m)m
(4.29)
and is based on choosing the integer m to be a power of two such that the exponential
term can reliably and eficiently be calculated followed by repeated squaring. A
typical criterion is to choose ‖A‖∕m ≪1 yielding a very effective numerical technique
for either Taylor or Pad´e approximants.
Ordinary differential equation methods using numerical integration techniques
(e.g., Runge–Kutta, Gear’s method) offer another practical approach to solving for the
state-transition matrix and the corresponding input matrices as given by Eqs. 4.23 and
4.25, respectively. The advantages of numerical integration techniques are reliability
and accuracy as well as applicability to time-varying and nonlinear systems. The
major disadvantage is computational time which can be very high for stiff (large
eigenvalue spread) differential equations and variable integration step sizes [17]. In
any case, the sampled-data system has the property that it has evolved from a system

4.3
SAMPLED-DATA STATE–SPACE MODELS
105
with continuous dynamics and must be accurately approximated or numerically
integrated to produce reliable solutions.
The inal class of methods we discuss briely are the matrix decomposition methods
[18]. These methods are based on similarity transformations, that is,
̃Ac = TAcT−1
and
ẽAcΔt = TeAcΔtT−1
(4.30)
where Δt := t −�in the continuous-time case. If the similarity transformation matrix
is chosen to be an eigenvalue–eigenvector transformation say T = V, then
ẽAcΔt = VeΛcΔtV−1
(4.31)
with Λc diagonal. The matrix exponential operation becomes a simple scalar compu-
tation
eΛcΔt = diag(e�1Δt, … , e�NΔt)
(4.32)
In fact, using the eigendecomposition and applying the ordinary differential equation
approach, we have that
̇x(t) = Acx(t)
and therefore the solution is given in terms of the eigenvectors �i
x(t) =
N
∑
i=0
�i e�iΔt�i
(4.33)
where the coeficients �i are the solution of the linear equations V × �= x(0). This
approach works well when Ac is symmetric leading to an orthogonal set of eigenvec-
tors, but can be plagued with a wealth of numerical issues that need reconciliation
and sophisticated numerical techniques [18].
Consider the following example to demonstrate these approaches.
Example 4.1
Suppose we are given the following system
̇xt = −0.303xt + ut
yt = 2xt
with sampling interval Δt = 0.1 initial state xt0 = 2 and input ut a sequence of irregu-
larly spaced step functions. Using a irst-order approximation, we obtain
x(tk) = (1 −0.303Δtk)x(tk−1) + Δtku(tk−1) = 0.97x(tk−1) + 0.1u(tk−1)
y(tk) = 2x(tk)

106
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
0
10
20
30
40
50
60
70
80
90
100
0
0.05
0.1
0.15
0.2
0.25
0
10
20
30
40
50
60
70
80
90
100
0
0.02
0.04
0.06
0.08
0.1
0.12
0
20
40
60
80
100
0
0.2
0.4
0.6
0.8
1
1.2
1.4
(c)
(b)
(a)
States 
Output
Input
Time (s)
Time (s)
Time (s)
Continuous
Sampled
Continuous
Sampled
FIGURE 4.1
Sampled-data simulation (unequally spaced) of irst-order continuous
process: (a) states: continuous (numerical integration) and sampled (series approxi-
mation); (b) outputs: continuous (numerical integration) and sampled (series approxi-
mation); (c) input: continuous (numerical integration).
We performed numerical integration on the differential equations and a Taylor-
series approximation using 25 terms to achieve an error tolerance of �= 10−12. The
simulations of the state, output, and input are shown in Figs. 4.1a, 4.1b, and 4.1c.
The true continuous-time solution is shown in the igure as the solid line, while the
sampled-data (discrete) solution is shown with the dotted lines. The plots reasonably
overlay each another, but it is apparent that there is some truncation error evolving
which can be observed at the peak amplitudes of the simulation. Thus we see that the
continuous-time system in some cases can be reasonably approximated even by the
Taylor-series approach.
△△△

4.4
DISCRETE-TIME STATE–SPACE MODELS
107
This completes the discussion of sampled-data systems and approximations, next
we consider the discrete-time systems.
4.4
DISCRETE-TIME STATE–SPACE MODELS
Discrete state–space models evolve in two distinct ways: naturally from the problem
or from sampling a continuous-time dynamical system. An example of a natural
discrete system is the dynamics of balancing our own checkbook. Here the state is
the evolving balance given the past balance and the amount of the previous check.
There is “no information” between time samples and so this model represents a
discrete-time system that evolves naturally from the underlying problem. On the other
hand, if we have a physical system governed by continuous-time dynamics, then we
“sample” it at given time instants as discussed in the previous section. So we see that
discrete-time dynamical systems can evolve from a wide variety of problems both
naturally (checkbook) or physically (circuit). In this text we are primarily interested in
physical systems (physics-based models), so we will concentrate on sampled systems
reducing them to a discrete-time state–space model.
We can use a irst-difference approximation2 and apply it to the general LTI
continuous-time state–space model to obtain a discrete-time system, that is,
̇xt ≈x(t) −x(t −1)
ΔT
≈Acx(t −1) + Bcu(t −1)
yt ≈y(t) = Ccx(t) + Dcu(t)
Solving for x(t), we obtain
x(t) = (I + Ac ΔT)x(t −1) + Bc ΔTu(t −1)
y(t) = Ccx(t) + Dcu(t)
(4.34)
Recognizing that the irst-difference approximation is equivalent to a irst-order
Taylor-series approximation of Ac gives the discrete system, input, output, and
feedthrough matrices as
A ≈I + Ac ΔT + O(ΔT2)
B ≈Bc ΔT
C ≈Cc
D ≈Dc
(4.35)
We deine the nonlinear discrete-time state–space representation by its process or
system model
x(t) = A(x(t −1), u(t −1)) = a[x(t −1)] + b[u(t −1)]
(4.36)
2 This approximation is equivalent to a irst-order Taylor-series approximation.

108
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
and corresponding measurement or output model by
y(t) = C(x(t), u(t)) = c[x(t)] + d[u(t)]
(4.37)
where x(t), u(t), y(t) are the respective discrete-time, Nx-state, Nu-input, and Ny-output
vectors with corresponding system (process), input, output, and feedthrough func-
tions: the Nx-dimensional system and input functions a[⋅], b[⋅] and the Ny-dimensional
output and feedthrough functions c[⋅], d[⋅].
The discrete linear time-varying state–space representation is given by the system
or process model as
x(t) = A(t −1)x(t −1) + B(t −1)u(t −1)
(4.38)
and the corresponding discrete output or measurement model as
y(t) = C(t)x(t) + D(t)u(t)
(4.39)
where x, u, y are the respective Nx-state, Nu-input, Ny-output and A, B, C, D are
the (Nx × Nx)-system, (Nx × Nu)-input, (Ny × Nx)-output, and (Ny × Nu)-feedthrough
matrices.
The state–space representation for linear, time-invariant discrete systems is char-
acterized by constant system, input, output, and feedthrough matrices, that is,
A(t) = A,
B(t) = B,
and
C(t) = C,
D(t) = D
and is given by the LTI system
x(t) = Ax(t −1) + Bu(t −1)
y(t) = Cx(t) + Du(t)
(4.40)
The discrete system representation replaces the Laplace transform with the Z-
transform deined by the transform pair
X(z) :=
∞
∑
t=0
x(t)z−t
x(t) = ∫
∞
−∞
X(z)z−1 dz
(4.41)
Time-invariant state–space discrete systems can also be represented in input–
output or transfer function form using the Z-transform to give
H(z) = C(zI −A)−1B + D
(4.42)
Also taking inverse Z-transforms we obtain the discrete impulse response matrix
as
H(t, k) = CAt−kB + D
for t ≥k
(4.43)

4.4
DISCRETE-TIME STATE–SPACE MODELS
109
The solution to the state-difference equations can easily be derived by induction
[3] or using the transfer function approach of the previous subsection. In any case it
is given by the relations
x(t) = Φ(t, k)x(k) +
t∑
i=k+1
Φ(t, i)B(i −1)u(i −1)
for t > k
(4.44)
where Φ(t, k) is the discrete-time state-transition matrix. For time-varying systems,
it can be shown (by induction) that the state-transition matrix3 satisies
Φ(t, k) = A(t −1) ⋅A(t −2) ⋯A(k)
while for time-invariant systems the state-transition matrix is given by
Φ(t, k) = At−k
for t > k
The discrete state-transition matrix possesses properties analogous to its
continuous-time counterpart, that is,
1. Φ(t, k) is uniquely deined
[Unique]
2. Φ(t, t) = I
[Identity]
3. Φ(t, k) satisies the matrix-difference equation
Φ(t, k) = A(t −1)Φ(t −1, k),
Φ(k, k) = I,
t ≥k + 1
(4.45)
4. Φ(t, k) = Φ(t, t −1) × Φ(t −1, t −2) × ⋯× Φ(k + 1, k)
[Semigroup]
5. Φ−1(t, k) = Φ(k, t)
[Inverse]
As in the continuous case, the discrete-time transition matrix has the same impor-
tance in discrete systems theory which we discuss next.
4.4.1
Discrete Systems Theory
In this subsection we investigate the discrete state–space model from a systems
theory viewpoint. There are certain properties that a dynamic system must possess in
order to assure a consistent representation of the dynamics under investigation. For
instance, it can be shown [2] that a necessary requirement of a measurement system
is that it is observable, that is, measurements of available variables or parameters
of interest provide enough information to reconstruct the internal variables or states.
Mathematically, a system is said to be completely observable if for any initial state,
3 Recall that for a sampled-data system, the state-transition matrix is Φ(t, tk) = eA(t−tk) where A is the
sampled-data system or process matrix.

110
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
say x(0), in the state–space there exists a inite t > 0 such that knowledge of the
input u(t) and the output y(t) is suficient to specify x(0) uniquely. Recall that the
deterministic linear state–space representation of a discrete system is deined by the
following set of equations:
State model :
x(t) = A(t −1)x(t −1) + B(t −1)u(t −1)
with corresponding measurement system or output deined by
Measurement model :
y(t) = C(t)x(t)
Using this representation, the simplest example of an observable system is one in
which each state is measured directly, and the measurement matrix C is an Nx × Nx
matrix. Thus, from the measurement system model, we have that in order to recon-
struct x(t) from its measurements y(t), then C must be invertible. In this case the
system is said to be completely observable; however, if C is not invertible, then the
system is said to be unobservable. The next level of complexity involves the solution
to this same problem when C is an Ny × Nx matrix, then a pseudoinverse must be
performed instead [1, 2]. In the general case the solution gets more involved because
we are not just interested in reconstructing x(t), but x(t) over all inite values of t,
therefore, we must include the state model, that is, the dynamics as well.
With this motivation in mind, we now formally deine the concept of observability.
The solution to the state representation is governed by the state-transition matrix,
Φ(t, 0), where recall that the state equation is [3]
x(t) = Φ(t, 0)x(0) +
t−1
∑
k=0
Φ(t, k + 1)B(t, k)u(k)
Therefore, premultiplying by the measurement matrix, the output relations are
y(t) = C(t)Φ(t, 0)x(0) +
t−1
∑
k=0
C(t)Φ(t, k + 1)B(k)u(k)
(4.46)
or rearranging we deine
̃y(t) := y(t) −
t−1
∑
k=0
C(t)Φ(t, k + 1)B(k)u(k) = C(t)Φ(t, 0)x(0)
(4.47)
The problem is to solve this resulting equation for the initial state; therefore,
multiplying both sides by Φ′C′, we can infer the solution from the relation
Φ′(t, 0)C′(t)C(t)Φ(t, 0)x(0) = Φ′(t, 0)C(t)̃y(t)
Thus, the observability question now becomes under what conditions can this equation
uniquely be solved for x(0)? Equivalently, we are asking if the null space of C(t)Φ(t, 0)

4.4
DISCRETE-TIME STATE–SPACE MODELS
111
is 0 ∈Nx×1. It has been shown [2, 4] that the following Nx × Nx observability
Gramian has the identical null space, that is,
(0, t) :=
t−1
∑
k=0
Φ′(k, 0)C′(k)C(k)Φ(k, 0)
(4.48)
which is equivalent to determining that (0, t) is nonsingular or rank Nx. Further
assuming that the system is LTI leads to the NNy × Nx observability matrix [4] given
by
(N) :=
⎡
⎢
⎢
⎢
⎢
⎢⎣
C
−−−
⋮
−−−
CAN−1
⎤
⎥
⎥
⎥
⎥
⎥⎦
(4.49)
It can be shown that a necessary and suficient condition for a system to be
completely observable is that the rank of or �[(N)] must be Nx. Thus, for the
LTI case, checking that all of the measurements contain the essential information to
reconstruct the states for an LTI system reduces to that of checking the rank of the
observability matrix. Although this is a useful mathematical concept, it is primarily
used as a rule-of-thumb in the analysis of complicated measurement systems.
Analogous to the system theoretic property of observability is that of controllabil-
ity, which is concerned with the effect of the input on the states of the dynamic system.
A discrete system is said to be completely controllable if for any x(t), x(0) ∈Nx there
exists an input sequence {u(t)}, t = 0, … , N −1 such that the solution to the state equa-
tions with initial condition x(0) is x(t) for some inite t. Following the same approach
as for observability, we obtain that the controllability Gramian deined by
(0, t) :=
t−1
∑
k=0
Φ(0, k)B(k)B′(k)Φ′(0, k)
(4.50)
is nonsingular or �[(0, t)] = Nx
Again for the LTI system, the Nx × NNu controllability matrix deined by
(N) := [B|AB| … |AN−1B]
(4.51)
must satisfy the rank condition �[] = Nx to be completely controllable [4].
If we continue with the LTI system description, we know from Z-transform theory
that the discrete transfer function can be represented by an ininite power series, that
is,
H(z) = C(zI −A)−1B =
∞
∑
k=1
H(k)z−k
for H(k) = CAk−1B
(4.52)

112
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
where H(k) is the Ny × Nu unit impulse response matrix which may also be viewed
as a Markov sequence with (A, B, C) deined as the Markov parameters.
The problem of determining the internal description (A, B, C) from the external
description (H(z) or {H(k)}) of Eq. 4.43 is called the realization problem. Out
of all possible realizations (A, B, C) having the same Markov parameters, those
of smallest dimension are deined as minimal realizations. It will subsequently
be shown that the dimension of the minimal realization is identical to the degree
of the characteristic polynomial (actually the minimal polynomial for multivari-
able systems) or equivalently the degree of the transfer function (number of system
poles).
In order to develop these relations, we deine the (N × NyNu) × (N × NyNu) Hankel
matrix by
(N) :=
⎡
⎢
⎢
⎢
⎢⎣
H(1)
H(2)
⋯
H(N)
H(2)
H(3)
⋯
H(N + 1)
⋮
⋮
⋯
⋮
H(N)
H(N + 1)
⋯
H(2N)
⎤
⎥
⎥
⎥
⎥⎦
(4.53)
Suppose the dimension of the system is Nx. Then the Hankel matrix could be
constructed such that N = Nx using 2Nx impulse response matrices which tells us
the minimum number of terms we require to extract the Markov parameters. Also
�[(N)] = Nx which is the dimension of the minimal realization. If we do not know
the dimension of the system, then we would let (in theory) N →∞and determine the
rank of (∞). Therefore, the minimal dimension of an “unknown” system is the rank
of the Hankel matrix. In order for a system to be minimal it must be completely con-
trollable and completely observable. This can be seen from the fact that the Hankel
matrix factors as
(N) =
⎡
⎢
⎢
⎢⎣
CB
⋯
CAN−1B
⋮
⋮
CAN−1B
⋯
CA2N−2B
⎤
⎥
⎥
⎥⎦
=
⎡
⎢
⎢
⎢⎣
C
⋮
CAN−1
⎤
⎥
⎥
⎥⎦
[B| ⋯|AN−1B]
(4.54)
or more simply
(N) = (N)(N)
(4.55)
From this factorization it follows that �[(N)] = min[�((N)), �((N))] = Nx. There-
fore, we see that the properties of controllability and observability are carefully woven
into that of minimality, and testing the rank of the Hankel matrix yields the dimen-
sionality of the underlying dynamic system. This fact will prove crucial when we
must “identify” a system Σ = {A, B, C} from noisy measurement data. For instance,

4.4
DISCRETE-TIME STATE–SPACE MODELS
113
many of the classical realization techniques [19, 20] rely on the factorization of
Eq. 4.55 to extract the system or process matrix, that is,
(N) × A =
⎡
⎢
⎢
⎢
⎢
⎢⎣
C
⋮
CAN−2
−−−
CAN−1
⎤
⎥
⎥
⎥
⎥
⎥⎦
A =
⎡
⎢
⎢
⎢
⎢
⎢⎣
CA
⋮
CAN−1
−−−
CAN
⎤
⎥
⎥
⎥
⎥
⎥⎦
=: ↑
(4.56)
Solving for A using the pseudoinverse [18] gives
̂A = #(N)↑
where #(N) := (′(N)(N))−1′(N)
(4.57)
An eficient realization technique for a scalar (single input/single output) system
can be obtained by performing a singular value decomposition (SVD) of the Hankel
matrix constructed from the impulse response sequence H(k); k = 1, … , N, that is,
(N) = U × Λ × V with �((N)) = Nx
(4.58)
where Λ = diag[�i]; i = 1, … , N∗; N∗:= N × NyNu, {�i} is the set of singular values,
and U and V the corresponding left and right singular vector matrices [18]. A variety of
techniques can be used to estimate the rank of a matrix, perhaps the simplest (given
the SVD) being the best rank approximation�(%) based on the ratio of singular
values
�( ̂Nx) :=
⎛
⎜
⎜⎝
∑̂Nx
i=1 �i
∑N∗
i=1 �i
⎞
⎟
⎟⎠
× 100
(4.59)
Here �(%) is the percentage of the original matrix (Hankel) approximated by choos-
ing ̂Nx. A threshold, �x (%) can be selected to search over i for that particular ̂Nx that
“best” approximates up to the threshold, that is,
�n( ̂Nx) ≥�x(%)
for n = 1, … , ̂Nx
(4.60)
Once the rank is estimated, then
≑
(N) = UΛV = U
⎡
⎢
⎢⎣
Λ
|
0
−−−| −−−
0
|
0
⎤
⎥
⎥⎦
V = UΛV
(4.61)
for U ∈NYNu×Nx, Λ ∈Nx×Nx, V ∈Nx×NYNu.

114
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
When the decomposition and rank ( ̂Nx) are determined, the system triple (scalar)
Σ = (A, b, c) is identiied by [21]
A = Λ
−1
2 U
′U
↑Λ
1
2 ;
b = Λ
1
2 V;
and
c = UΛ
1
2
(4.62)
where (as before) U
↑is the eigenvector matrix U shifted up one row with a row of
zeros (0′) appended [21]. Here A1∕2(A1∕2)′ are the square-root matrices of A. It has
been shown that this method results in a stable realization such that the eigenvalues
of A, �(A ≤1).
Example 4.2
Consider the following scalar example with impulse response H(k) = {1, 1∕2, 1∕4,
1∕8 1∕16} with N = 5. Using the SVD approach, we would like to extract the
realization Σ = (A, b, c). Creating the Hankel matrix and performing the SVD, we
obtain
H(5) =
⎡
⎢
⎢⎣
1
1∕2
1∕4
1∕2
1∕4
1∕8
1∕4
1∕8
1∕16
⎤
⎥
⎥⎦
= UΛV
Λ = diag[1.31, 0, 0] yielding a rank ̂Nx = 1; the singular vectors are
U =
⎡
⎢
⎢⎣
−0.8729
−0.4364
−0.2182
−0.4364
0.8983
−0.0509
−0.2182
−0.0509
0.9746
⎤
⎥
⎥⎦
;
V =
⎡
⎢
⎢⎣
−0.8729
−0.4364
−0.2182
0.4880
−0.7807
−0.3904
0
−0.4472
0.8944
⎤
⎥
⎥⎦
Thus the best rank approximants are Λ = 1.3125 and
U =
⎡
⎢
⎢⎣
−0.8729
−0.4364
−0.2182
⎤
⎥
⎥⎦
;
U
↑=
⎡
⎢
⎢⎣
−0.4364
−0.2182
0
⎤
⎥
⎥⎦
;
V
′ =
⎡
⎢
⎢⎣
−0.8729
−0.4364
−0.2182
⎤
⎥
⎥⎦
Therefore, we obtain the realizations
A = Λ
−1
2 U
′U
↑Λ
1
2
= (0.873)[−0.8729 −0.4364 −0.2182]
⎡
⎢
⎢⎣
−0.4364
−0.2182
0
⎤
⎥
⎥⎦
(1.1456)
= 0.48 ≈1∕2; b′ = Λ
1
2 V = [1 0 0]; c = U Λ
1
2 = [−1 0 0]
△△△

4.5
GAUSS–MARKOV STATE–SPACE MODELS
115
This completes the subsection on discrete systems theory. It should be noted that
all of the properties discussed in this section exist for continuous-time systems (see
Ref. [2] for details).
4.5
GAUSS–MARKOV STATE–SPACE MODELS
In this section we extend the state–space representation to incorporate random
inputs or noise sources along with random initial conditions. We briely discuss
the continuous-time representation evolving to the sampled-data model and then pro-
vide a detailed discussion of the discrete-time Gauss–Markov model which will be
used extensively throughout this text.
4.5.1
Continuous-Time/Sampled-Data Gauss–Markov Models
We start by deining the continuous-time Gauss–Markov model. If we constrain
the state–space representation to be linear in the states, then we obtain the generic
continuous-time, linear time-varying Gauss–Markov state–space model given by
̇xt = Atxt + Btut + Wt�t
yt = Ctxt + �t
(4.63)
where xt ∈Nx×1, ut ∈Nu×1, �t ∈N�×1, yt ∈Ny×1, �t ∈Ny×1
are the
continuous-time state, input (deterministic), process noise, measurement, and mea-
surement noise4 vectors with corresponding system (process), input, output, and
feedthrough matrices: A ∈Nx×Nx, B ∈Nx×Nu, W ∈Nx×N�, and C ∈Ny×Nx.
The continuous-time Gaussian stochastic processes are �t ∼(0, R�c�c(t)) and
�t ∼(0, R�c�c(t)) with initial state deined by x0 ∼(x0, P0). The corresponding
statistics of this model follow with the dynamic mean derived directly from Eq. 4.63
(see Refs. [6–8] for details) as
̇mxt = Atmxt + Btut
(4.64)
and the variance (continuous-time Lyapunov equation)
̇Pt = AtPt + PtA′
t + WtR�c�c(t)W′
t
(4.65)
with corresponding covariance
Pt,�=
{
Φc(t, �)P�,�
for t ≥�
Pt,tΦ′
c(t, �)
for t ≤�
(4.66)
where Φc(t, �) is the continuous state-transition matrix.
4 Note that process and measurement noise sources are different. The process noise term is used primarily
to model uncertainties in the input, state, or even possibly unknown model parameters and it is “iltered” or
colored (correlated) by the system dynamics, while measurement noise is uncorrelated and used to model
instrumentation or extraneous environmental noise.

116
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
As before, for the deterministic case, the stochastic sampled-data system follows
from the continuous-time state solution
xt = Φc(t, t0)xt0 + ∫
t
t0
Φc(t, �)B�u�d�+ ∫
t
t0
Φc(t, �)W���d�
(4.67)
Sampling this system with t →tk over the interval (tk, tk−1], the sampled solution
becomes (with notational change)5
x(tk) = Φ(tk, tk−1)x(tk−1) + ∫
tk
tk−1
Φ(tk, �)B�u�d�+ ∫
tk
tk−1
Φ(tk, �)W���d�
(4.68)
If we further assume that the input excitation is piecewise constant (u�→u(tk−1))
over the interval (tk, tk−1], then it can be removed from under the superposition
integral in Eq. 4.68 to give
x(tk) = Φ(tk, tk−1)x(tk−1) +
(
∫
tk
tk−1
Φ(tk, �)B�d�
)
× u(tk−1)
+ ∫
tk
tk−1
Φ(tk, �)W���d�
(4.69)
We deine the sampled-data input transmission matrix as
B(tk−1) := ∫
tk
tk−1
Φ(tk, �)B�d�
(4.70)
with the sampled-data process noise covariance matrix given by
R��(tk−1) := ∫
tk
tk−1
Φ(tk, �)W�R�c�c(�)W′
�Φ′(tk, �) d�
(4.71)
and therefore the sampled-data state–space system with equally or unequally sampled
data is given by
x(tk) = Φ(tk, tk−1)x(tk−1) + B(tk−1)u(tk−1) + W(tk−1)�(tk−1)
y(tk) = C(tk)x(tk) + �(tk)
(4.72)
5 We note in passing that this solution is conceptual and must actually follow a much more rigorous
framework embedded in stochastic integrals and is beyond the scope of this text (see Ref. [6–8] for
details).

4.5
GAUSS–MARKOV STATE–SPACE MODELS
117
for �tk ∼(0, R��(tk)) and �tk ∼(0, R��(tk)) with initial state deined by
x(t0) ∼(x(t0), P(t0)). Recall from the deterministic solution that if we use a irst-
order Taylor-series approximation we have that
Φ(tk, tk−1) ≈I + Δtk × A(tk−1)
B(tk−1) ≈Δtk × Btk−1
R��(tk−1) ≈Δtk × Wtk−1R�c�c(tk−1)W′
tk−1
R��(tk) ≈R�c�c(tk)∕Δtk
(4.73)
The corresponding mean and covariance of the sampled-data process are
mx(tk) = A(tk−1)mx(tk−1) + B(tk−1)u(tk−1)
(4.74)
and the measurement mean vector my is
my(tk) = C(tk)mx(tk)
(4.75)
The state variance is given by
P(tk) = A(tk−1)P(tk−1)A′(tk−1) + W(tk−1)R��(tk−1)W′(tk−1)
(4.76)
and the measurement variance is
Ryy(tk) = C(tk)P(tk)C′(tk) + R��(tk)
(4.77)
This completes the development of the sampled-data Gauss–Markov representa-
tion evolving from a continuous-time stochastic process, next we consider the more
pragmatic discrete-time model.
4.5.2
Discrete-Time Gauss–Markov Models
Here we investigate the case when random inputs are applied to a discrete state–space
system with random initial conditions. If the excitation is a random signal, then the
state is also random. Restricting the input to be deterministic u(t −1) and the noise to
be zero-mean, white, random Gaussian �(t −1), the Gauss–Markov model evolves
as
x(t) = A(t −1)x(t −1) + B(t −1)u(t −1) + W(t −1)�(t −1)
(4.78)
where �∼(0, R��(t −1)) and x(0) ∼(x(0), P(0)).

118
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
u(t)
w(t)
x(t)
v(t)
y(t)
B
A
C
W
+
+
z−1l
FIGURE 4.2
Gauss–Markov model of a discrete process.
The solution to the Gauss–Markov equations can easily be obtained by induction
to give
x(t) = Φ(t, k)x(k) +
t−1
∑
i=k
Φ(t, i + 1)B(i)u(i) +
t−1
∑
i=k
Φ(t, i + 1)W(i)�(i)
(4.79)
which is irst-order Markov depending only on the previous state. Since x(t) is just
a linear transformation of Gaussian processes it is also Gaussian. Thus, we can
represent a Gauss–Markov process easily using the state–space models.
When the measurement model is also included, we have
y(t) = C(t)x(t) + �(t)
(4.80)
where �∼(0, R��(t)). The model is shown diagrammatically in Fig. 4.2.
Since the Gauss–Markov model of Eq. 4.78 is characterized by a Gaussian distri-
bution, it is completely speciied statistically by its mean and variance. Therefore, if
we take the expectation of Eqs. 4.78 and 4.80, respectively, we obtain the state mean
vector mx as
mx(t) = A(t −1)mx(t −1) + B(t −1)u(t −1)
(4.81)
and the measurement mean vector my as
my(t) = C(t)mx(t)
(4.82)
The state variance6 P(t) := var{x(t)} is given by the discrete Lyapunov equation
P(t) = A(t −1)P(t −1)A′(t −1) + W(t −1)R��(t −1)W′(t −1)
(4.83)
6 We use the shorthand notation P(k) := Pxx(k, k) = cov{x(k), x(k)} = var{x(k)} throughout this text.

4.5
GAUSS–MARKOV STATE–SPACE MODELS
119
TABLE 4.1
Gauss–Markov Representation
State Propagation
x(t) = A(t −1)x(t −1) + B(t −1)u(t −1) + W(t −1)�(t −1)
State Mean Propagation
mx(t) = A(t −1)mx(t −1) + B(t −1)u(t −1)
State Variance/Covariance Propagation
P(t) = A(t −1)P(t −1)A′(t −1) + W(t −1)R��(t −1)W′(t −1)
P(t, k) =
{
Φ(t, k)P(k)
t ≥k
P(t)Φ′(t, k)
t ≤k
Measurement Propagation
y(t) = C(t)x(t) + �(t)
Measurement Mean Propagation
my(t) = C(t)mx(t)
Measurement Variance/Covariance Propagation
Ryy(t) = C(t)P(t)C′(t) + R��(t)
Ryy(t, k) = C(t)P(t)C′(t) + R��(t, k)
and the measurement variance Ryy(t) := var{y(t)} is
Ryy(t) = C(t)P(t)C′(t) + R��(t)
(4.84)
Similarly, it can be shown that the state covariance propagates according to the
following equations
P(t, k) =
{Φ(t, k)P(k)
for t ≥k
P(t)Φ′(t, k)
for t ≤k
(4.85)
We summarize the Gauss–Markov and corresponding statistical models in
Table 4.1.
If we restrict the Gauss–Markov model to the stationary case, then
A(t) = A, B(t) = B, C(t) = C, W(t) = W, R��(t) = R��,
and
R��(t) = R��
and the variance equations become
P(t) = AP(t −1)A′ + WR��W′
and
Ryy(t) = CP(t)C′ + R��
(4.86)
At steady state (t →∞), we have
P(t) = P(t −1) = ⋯= Pss := P

120
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
and therefore, the measurement covariance relations become
Ryy(0) = CPC′ + R��
for lag k = 0
(4.87)
By induction, it can be shown that
Ryy(k) = CA|k|PC′
for k ≠0
(4.88)
The measurement power spectrum is easily obtained by taking the Z-transform of
this equation to obtain
Syy(z) = CSxx(z)C′ + S��(z)
(4.89)
where
Sxx(z) = T(z)S��(z)T′(z−1)
for T(z) = (zI −A)−1W
with
S��(z) = R��
and
S��(z) = R��
Thus, using H(z) = CT(z), the spectrum is given by
Syy(z) = H(z)R��H′(z−1) + R��
(4.90)
So we see that the Gauss–Markov state–space model enables us to have a more
general representation of a multichannel stochastic signal. In fact, we are able to easily
handle the multichannel and nonstationary statistical cases within this framework.
Generalizations are also possible with the vector models, but the forms become
quite complicated and require some knowledge of multivariable systems theory and
canonical forms (see Ref. [1] for details). Before we leave this subject, let us consider
a simple input–output example with Gauss–Markov models.
Example 4.3
Consider the following difference equation driven by random (white) noise
y(t) = −ay(t −1) + e(t −1)
The corresponding state–space representation is obtained as
x(t) = −ax(t −1) + �(t −1)
and
y(t) = x(t)
Taking Z-transforms (ignoring the randomness), we obtain the transfer function
H(z) =
1
1 −az−1

4.5
GAUSS–MARKOV STATE–SPACE MODELS
121
Using Eq. 4.83, the variance equation for the above model is
P(t) = a2P(t −1) + R��
Assume the process is stationary, then P(t) = P for all t and solving for P it follows
that
P = R��
1 −a2
Therefore,
Ryy(k) = CA|k|PC′ = a|k|R��
1 −a2
and
Ryy(0) = CPC′ + R��= R��
1 −a2
Choosing R��= 1 −a2 gives Ryy(k) = a|k|. Taking Z-transforms the discrete power
spectrum is given by
Syy(z) = H(z)R��H′(z−1) + R��=
1
1 −az−1 R��
1
1 −az
Therefore, we conclude that for stationary processes these models are equivalent.
Now
if
we
assume
a
nonstationary
process
and
let
a = −0.75, x(0) ∼
(1, 2.3), �∼(0, 1), and �∼(0, 4), then the Gauss–Markov model is given
by
x(t) = 0.75x(t −1) + �(t −1)
and
y(t) = x(t) + �(t)
The corresponding statistics are given by the mean relations
mx(t) = 0.75mx(t −1)
mx(0) = 1
my(t) = mx(t)
my(0) = mx(0)
and the variance equations
P(t) = 0.5625P(t −1) + 1
and
Ryy(t) = P(t) + 4
We apply the simulator available in SSPACK_PC [13] to obtain a 100-sample realiza-
tion of the process. The results are shown in Figs. 4.3a, 4.3b, 4.3c. In Figs. 4.3a and
4.3b we see the mean and simulated states with corresponding conidence interval
about the mean, that is,
[mx(t) ± 1.96
√
P(t)]

122
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
0
0
.20
.40
.60
.80
1.00
mx, my
10 20 30 40 50
Time
(a)
x
60 70 80 90 100
0
−4.0
−2.0
0
2.0
4.0
2 out = 2.00%
10 20 30 40 50
Time
(b)
60 70 80 90 100
y
0
−6
−4
−2
0
2
4
6
2 out = 2.00%
10 20 30 40 50
Time
(c)
60 70 80 90 100
FIGURE 4.3
Gauss–Markov simulation of irst-order process.
and
P = R��
1 −a2 = 2.286
Using the above conidence interval, we expect 95% of the samples to lie within (mx →
0) ±3.03(1.96 ×
√
2.286). From the igure we see that only 2 of the 100 samples
exceed this bound, indicating a statistically acceptable simulation. We observe similar
results for the simulated measurements. The steady-state variance is given by
Ryy = P + R��= 2.286 + 4 = 6.286
Therefore, we expect 95% of the measurement samples to lie within (my →0)
±5.01(1.96 ×
√
6.286) at steady state. This completes the example.
△△△

4.6
INNOVATIONS MODEL
123
4.6
INNOVATIONS MODEL
In this Section we briely develop the innovations model which is related to the
Gauss–Markov representation just discussed. The signiicance of this model will be
developed throughout the text, but we take the opportunity now to show its relationship
to the basic Gauss–Markov representation. We start by extending the original Gauss–
Markov representation to the correlated process and measurement noise case and
then showing how the innovations model is a special case of this structure.
The standard Gauss–Markov model for correlated process and measurement noise
is given by
x(t) = Ax(t −1) + Bu(t −1) + W(t −1)�∗(t −1)
y(t) = Cx(t) + �∗(t)
(4.91)
where R∗(t, k) := R∗�(t −k) and
R∗:=
⎡
⎢
⎢⎣
R�∗�∗| R�∗�∗
−−−|−−−
R�∗�∗| R�∗�∗
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣
WR��W′| WR��
−−−−|−−−
R��W′ | R��
⎤
⎥
⎥⎦
Here we observe that in the standard Gauss–Markov model the (Nx + N�) ×
(Nx + N�) block covariance matrix R∗is full with cross-covariance matrices R�∗�∗on
its off-diagonals. The standard model assumes that they are null (uncorrelated). To
simulate a system with correlated �(t) and �(t) is more complicated using this form
of the Gauss–Markov model because R∗must irst be factored such that
R∗=
[
R∗
1
R∗
2
]
[R∗′
1
R∗′
2 ]
(4.92)
where R∗
i are matrix square roots [6, 7]. Once the factorization is performed, the
correlated noise is synthesized “coloring” the uncorrelated noise sources �(t) and
�(t) as
[�∗(t)
�∗(t)
]
=
[
R∗′
1 �(t)
R∗′
2 �(t)
]
(4.93)
The innovations model is a constrained version of the correlated Gauss–Markov
characterization. If we assume that {e(t)} is a zero-mean, white Gaussian sequence,
that is, e ∼(0, Ree), then the innovations model [9–13] evolves as
x(t) = A(t −1)x(t −1) + B(t −1)u(t −1) + K(t −1)e(t −1)
y(t) = C(t)x(t) + D(t)u(t) + e(t)
(4.94)

124
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
where e(t) is the Ny-dimensional innovations vector and K(t −1) is the (Nx × Ny)
weighting matrix7
R∗
ee := cov
([Ke(t)
e(t)
])
=
⎡
⎢
⎢⎣
KReeK′ | KRee
−−−−|−−−
ReeK′ | Ree
⎤
⎥
⎥⎦
�(t −k)
It is important to note that the innovations model has implications in Wiener–
Kalman iltering (spectral factorization) because Ree can be represented in factored
or square-root form (R :=
√
R
√
R
′) directly in terms of the gain and innovation
covariance matrix, that is,
R∗
ee :=
[
K
√
Ree
√
Ree
] [√
ReeK′
√
Ree
]
�(t −k)
(4.95)
Comparing the innovations model to the Gauss–Markov model, we see that they
are both equivalent to the case when �and �are correlated. This completes the
discussion of the innovations model. Next we show the equivalence of the various
model sets to this family of state–space representations.
4.7
STATE–SPACE MODEL STRUCTURES
In this section we discuss special state–space structures usually called “canonical
forms” in the literature, since they represent unique state constructs that are particu-
larly useful. We will conine the models to single input/single output forms because
the multivariable structures are too complicated for this discussion [4]. Here we will
irst investigate the most popular “time series” models and then their equivalent rep-
resentation in the state–space. We start with the ARMAX model and then progress
to the special cases of this generic structure.
4.7.1
Time Series Models
Time series models are particularly useful representations used frequently by statisti-
cians and signal processors to represent time sequences when no physics is available
to use directly. They form the class of black box or gray box models [13] which
are used in predicting data. These models have an input–output structure, but they
can be transformed to an equivalent state–space representation. Each model set has
its own advantages: the input–output models are easy to use, while the state–space
models are easily generalized and usually evolve when physical phenomenology can
be described in a model-based sense [13].
7 Actually K is called the Kalman gain matrix, which will be discussed in detail when we develop the
model-based processor in a subsequent chapter.

4.7
STATE–SPACE MODEL STRUCTURES
125
The input–output or transfer function model is familiar to engineers and scientists
because it is usually presented in the frequency domain with Laplace transforms.
Similarly in the discrete-time case, it is called the pulse transfer function model and
is expressed as
H(z) = B(z−1)
A(z−1)
(4.96)
where A and B are polynomials in z or z−1,
A(z−1) = 1 + a1z−1 + ⋯+ aNaz−Na
(4.97)
B(z−1) = b0 + b1z−1 + ⋯+ bNbz−Nb
(4.98)
If we consider the equivalent time domain representation, then we have a difference
equation relating the output sequence {y(t)} to the input sequence {u(t)}.8 We use
the backward shift operator q with the property that q−ky(t) = y(t −k).
A(q−1)y(t) = B(q−1)u(t)
(4.99)
or
y(t) + a1y(t −1) + ⋯+ aNay(t −Na) = b0u(t) + ⋯+ bNbu(t −Nb)
(4.100)
When the system is excited by random inputs the models are given by the
autoregressive-moving average model with exogenous inputs (ARMAX)9
A(q−1)y(t)
⏟⏞⏞⏟⏞⏞⏟
AR
= B(q−1)u(t)
⏟⏞⏞⏟⏞⏞⏟
X
+ C(q−1)e(t)
⏟⏞⏞⏟⏞⏞⏟
MA
(4.101)
where A, B, C, are polynomials, and {e(t)} is a white noise source, and
C(q−1) = c0 + c1q−1 + ⋯+ cNcq−Nc
The ARMAX model usually abbreviated by ARMAX(Na, Nb, Nc) represents the
general form for many popular time series and digital ilter models. A summary of
these models follows:
r Pulse transfer function or ininite impulse response (IIR) model: C(⋅) = 0, or
ARMAX(Na, Nb, 0), that is,
A(q−1)y(t) = B(q−1)u(t)
8 We change from the common signal processing convention of using x(t) for the deterministic excitation
to u(t) and we include the b0 coeficient for generality.
9 The ARMAX model can be interpreted in terms of the Wold decomposition of stationary times series,
which states that a time series can be decomposed into a predictable or deterministic component (u(t)) and
nondeterministic or random component (e(t)) [10].

126
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
r Finite impulse response (FIR) model: A(⋅) = 1, C(⋅) = 0, or ARMAX(1, Nb, 0),
that is,
y(t) = B(q−1)u(t)
r Autoregressive (AR) model: B(⋅) = 0, C(⋅) = 1, or ARMAX(Na, 0, 1), that is,
A(q−1)y(t) = e(t)
r Moving average (MA) model: A(⋅) = 1, B(⋅) = 0, or ARMAX(1, 0, Nc), that is,
y(t) = C(q−1)e(t)
r Autoregressive-moving average (ARMA) model: B(⋅) = 0, or ARMAX(Na, 0,
Nc), that is,
A(q−1)y(t) = C(q−1)e(t)
r Autoregressive model with exogenous input (ARX): C(⋅) = 1, or ARMAX(Na,
Nb, 1), that is,
A(q−1)y(t) = B(q−1)u(t) + e(t)
The ARMAX model is shown in Fig. 4.4. ARMAX models can easily be used
for signal processing purposes, since they are basically digital ilters with known
deterministic (u(t)) and random (e(t)) excitations.
u(t )
e(t )
y(t )
B(q−1)
C(q−1)
1−A(q−1)
+
FIGURE 4.4
ARMAX input–output model.

4.7
STATE–SPACE MODEL STRUCTURES
127
Since the ARMAX model is used to characterize a random signal, we are interested
in its statistical properties. The mean value of the output is easily determined by
A(q−1)E{y(t)} = B(q−1)E{u(t)} + C(q−1)E{e(t)}
or
A(q−1)my(t) = B(q−1)u(t) + C(q−1)me(t)
(4.102)
Because the irst term in the A-polynomial is unity, we can write the mean propagation
recursion for the ARMAX model as
my(t) = (1 −A(q−1))my(t) + B(q−1)u(t) + C(q−1)me(t)
(4.103)
my(t) = −
Na
∑
i=1
aimy(t −i) +
Nb
∑
i=0
biu(t −i) +
Nc
∑
i=0
cime(t −i)
(4.104)
We note that the mean of the ARMAX model is propagated using a recursive digital
ilter requiring Na, Nb, Nc past input and output values.
The corresponding variance of the ARMAX model is more complex. First, we
note that the mean must be removed, that is,
y(t) −my(t) = [(1 −A(q−1))y(t) + B(q−1)u(t) + C(q−1)e(t)]
−[(1 −A(q−1))my(t) + B(q−1)u(t) + C(q−1)me(t)]
(4.105)
or
y(t) −my(t) = (1 −A(q−1))(y(t) −my(t)) + C(q−1)(e(t) −me(t))
or inally
A(q−1)(y(t) −my(t)) = C(q−1)(e(t) −me(t))
(4.106)
that is, y −my is characterized by an ARMAX(Na, 0, Nb) or equivalently an ARMA
model.
The covariance of the ARMAX model can be calculated utilizing the fact that it
is essentially an IIR system, that is,
Y(z)
E(z) = H(z) =
∞
∑
t=0
h(t)z−t
(4.107)
Using this fact and the commutativity of the convolution operator, we have (assuming
the mean has been removed)
Ryy(k) = E{y(t)y(t + k)} = E
{ ∞
∑
i=0
h(i)e(t −i)
∞
∑
j=0
h(j + k)e(t −j + k)
}

128
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
or
Ryy(k) =
∞
∑
i=0
h(i)h(i + k)E{e(t −i)e(t −i + k)}
+
∑
i≠j
∑
h(i)h(j + k)E{e(t −i)e(t −j + k)}
The whiteness of {e(t)} gives
Ree(k) =
{
Ree
k = 0
0
elsewhere
therefore, applying this property above we have the covariance of the ARMAX model
given by
Ryy(k) = Ree
∞
∑
i=0
h(i)h(i + k)
for k ≥0
(4.108)
with corresponding variance
Ryy(0) = Ree
∞
∑
t=0
h2(t)
(4.109)
We note that one property of a stationary signal is that its impulse response is
bounded which implies from Eq. 4.108 that the variance is bounded [14]. Clearly,
since the variance is characterized by an ARMA model (ARMAX(Na, 0, Nc)),
we have
A(z−1)H(z) = C(z−1)E(z),
E(z) =
√
Ree
or taking the inverse Z-transform
h(t) = (1 −A(q−1))h(t) + C(q−1)�(t)
or
h(t) = −
Na
∑
i=1
aih(t −i) +
Nc
∑
i=0
ci�(t),
c0 = 1
(4.110)
where �(t) is an impulse of weight
√
Ree. So we see that this recursion coupled with
Eq. 4.108 provides a method for calculating the variance of an ARMAX model. We
summarize these results in Table 4.2 and the following example.

4.7
STATE–SPACE MODEL STRUCTURES
129
TABLE 4.2
ARMAX Representation
Output Propagation
y(t) = (1 −A(q−1))y(t) + B(q−1)u(t) + C(q−1)e(t)
Mean Propagation
my(t) = (1 −A(q−1))my(t) + B(q−1)u(t) + C(q−1)me(t)
Impulse Propagation
h(t) = (1 −A(q−1))h(t) + C(q−1)�(t)
Variance/Covariance Propagation
Ryy(k) = Ree
∞
∑
i=0
h(i)h(i + k)
k ≥0
y = output or measurement sequence
u = input sequence
e = process (white) noise sequence with variance Ree
h = impulse response sequence
�= impulse input of amplitude
√
Ree
my = mean output or measurement sequence
me = mean process noise sequence
Ryy = stationary output covariance at lag k
A = Nath order system characteristic (poles) polynomial
B = Nbth order input (zeros) polynomial
C = Ncth order noise (zeros) polynomial
Example 4.4
Consider the difference equation of the previous example with a = 0.5 which is an AR
model with A(z) = 1 + 0.5z−1 and Ree = 1. We would like to calculate the variance.
From Eq. 4.110, we have
h(t) = −0.5h(t −1) + �(t) ⟶(−0.5)t
and
Ryy(0) =
∞
∑
i=0
h2(i) = [12 −0.52 + .252 −1.252 + .08752 −⋯] →1.333
△△△
Let us consider a more complex example to illustrate the use of the ARMA model.
Example 4.5
Suppose we would like to investigate the structure of an ARMAX(2, 1, 1) model with
the following difference equation and calculate its underlying mean and variance
propagation relations
(1 + 3∕4q−1 + 1∕8q−2)y(t) = (1 + 1∕8q−1)u(t) + (1 + 1∕16q−1)e(t)

130
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
where u(t) = sin 2�(0.025)t and e ∼(1, 0.01). Then the corresponding mean prop-
agation equation is
(1 + 3∕4q−1 + 1∕8q−2)my(t) = (1 + 1∕8q−1)u(t) + (1 + 1∕16q−1)me(t)
for me(t) = 1 for all t. The impulse propagation model is
(1 + 3∕4q−1 + 1∕8q−2)h(t) = (1 + 1∕16q−1)
√
Ree�(t)
for
√
Ree = 0.1
and the variance/covariance propagation model is
Ryy(k) = Ree
∞
∑
t=0
h(t)h(t + k)
k ≥0
This completes the example.
△△△
It should be noted that for certain special cases of the ARMAX model, it is
particularly simple to calculate the mean and covariance. For instance, the MA
model (ARMAX(1, 0, Nc)) has mean
my(t) = E{C(q−1)e(t)} = C(q−1)me(t)
(4.111)
and covariance (directly from Eq. 4.108 with h →c)
Ryy(k) = Ree
Nc
∑
i=0
cici+k
for k ≥0
(4.112)
Another special case of interest is the AR (ARMAX(Na, 0, 1)) model with mean
my(t) = (1 −A(q−1))my(t) + me(t)
(4.113)
and covariance which is easily derived by direct substitution
Ryy(k) = E{y(t)y(t + k)} = (1 −A(q−1))Ryy(k) = −
Na
∑
i=1
aiRyy(k −i)
for k > 0
(4.114)
In fact, the AR covariance model of Eq. 4.114 is essentially a recursive (all-pole)
digital ilter which can be propagated by exciting it with the variance Ryy(0) as initial
condition. In this case the variance is given by
Ryy(0) = E{y2(t)} = E
{(
−
Na
∑
i=1
aiy(t −i) + e(t)
)
y(t)
}
= −
Na
∑
i=1
aiRyy(i) + Ree
(4.115)

4.7
STATE–SPACE MODEL STRUCTURES
131
So combining Eqs. 4.114 and 4.115, we have that the covariance propagation equa-
tions for the AR model are given by
Ryy(k) =
⎧
⎪
⎨
⎪⎩
−∑Na
i=1 aiRyy(i) + Ree
k = 0
−∑Na
i=1 aiRyy(k −i)
k > 0
Consider the following example of calculating the statistics of the AR model.
Example 4.6
Consider the AR model of the previous two examples. We would like to determine
the corresponding mean and variance using the recursions of Eqs. 4.113 and 4.114
with A(q−1) = 1 + 0.5q−1. The mean is
my(t) = −0.5my(t −1)
and the covariance is
Ryy(k) =
{−0.5Ryy(1) + 1
k = 0
−0.5Ryy(k −1)
k > 0
The variance is obtained directly from these recursions, since
Ryy(1) = −0.5Ryy(0)
and therefore
Ryy(0) = −0.5Ryy(1) + 1
Substituting for Ryy(1) we obtain
Ryy(0) = −0.5(−0.5Ryy(0)) + 1
or
Ryy(0) = 1.333
as before.
△△△
This completes the section on ARMAX models.
4.7.2
State–Space and Time Series Equivalence Models
In this section we show the equivalence between the ARMAX and state–space models
(for scalar processes). That is, we show how to obtain the state–space model given

132
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
the ARMAX models by inspection. We choose particular coordinate systems in the
state–space (canonical forms) and obtain a relationship between entries of the state–
space system to coeficients of the ARMAX model. An example is presented that
shows how these models can be applied to realize a random signal. First, we consider
the ARMAX to state–space transformation.
Recall from Eq. 4.101 that the general difference equation form of the ARMAX
model is given by
y(t) = −
Na
∑
i=1
aiy(t −i) +
Nb
∑
i=0
biu(t −i) +
Nc
∑
i=0
cie(t −i)
(4.116)
or equivalently in the frequency domain as
Y(z) =
(bo + b1z−1 + ⋯+ bNbz−Nb
1 + a1z−1 + ⋯+ aNaz−Na
)
U(z) +
(co + c1z−1 + ⋯+ cNcz−Nc
1 + a1z−1 + ⋯+ aNaz−Na
)
E(z)
(4.117)
where Na ≥Nb and Nc and {e(t)} is a zero-mean white sequence with spectrum given
by Ree.
It is straightforward but tedious to show (see Ref. [5]) that the ARMAX model
can be represented in observer canonical form
x(t) = A0x(t −1) + B0u(t −1) + W0e(t −1)
y(t) = C′
0x(t) + b0u(t) + c0e(t)
(4.118)
where x, u, e, and y are the Na-state vector, scalar input, noise, and output with
A0 :=
[
0
| −aNa
−−−|
⋮
INa−1 | −a1
]
B0 :=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢⎣
−aNab0
⋮
−aNb+1b0
−−−
bNb −aNbb0
⋮
b1 −a1b0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥⎦
W0 :=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢⎣
−aNac0
⋮
−aNc+1c0
−−−
cNc −aNcc0
⋮
c1 −a1c0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥⎦
C′
0 := [0 ⋯0 1]
Noting this structure we see that each of the matrix or vector elements
{Ai,Na, Bi, Wi, Ci} i = 1, … , Na can be determined from the relations
Ai,Na = −ai
i = 1, … , Na
Bi = bi −aib0
Wi = ci −aic0
Ci = �(Na −i)
(4.119)

4.7
STATE–SPACE MODEL STRUCTURES
133
where
bi = 0
for i > Nb
ci = 0
for i > Nc
�(i −j)
is the Kronecker delta
Consider the following example to illustrate these relations.
Example 4.7
Let Na = 3, Nb = 2, and Nc = 1; then the corresponding ARMAX model is
y(t) = −a1y(t −1) −a2y(t −2) −a3y(t −3) + b0u(t)
+ b1u(t −1) + b2u(t −2) + c0e(t) + c1e(t −1)
(4.120)
Using the observer canonical form of Eq. 4.118 we have
x(t) =
⎡
⎢
⎢
⎢⎣
0
0 | −a3
−−−−−|
1
0 | −a2
0
1 | −a1
⎤
⎥
⎥
⎥⎦
x(t −1) +
⎡
⎢
⎢
⎢⎣
−a3b0
−−−
b2 −a2b0
b1 −a1b0
⎤
⎥
⎥
⎥⎦
u(t −1)
+
⎡
⎢
⎢
⎢⎣
−a3c0
−a2c0
−−−
c1 −a1c0
⎤
⎥
⎥
⎥⎦
e(t −1)
y(t) = [0 0 1]x(t) + b0u(t) + c0e(t)
This completes the example.
△△△
It is important to realize that if we assume that {e(t)} is Gaussian, then the ARMAX
model is equivalent to the innovations representation of the previous section, that is,
x(t) = Ax(t −1) + Bu(t −1) + We(t −1)
y(t) = C′x(t) + b0u(t) + c0e(t)
(4.121)
where in this case K →W, D →b0, and 1 →c0. Also, the corresponding covariance
matrix becomes
R∗
ee := cov
([
We(t)
c0e(t)
])
=
⎡
⎢
⎢⎣
WReeW′ | WReec0
−−−−−
c0ReeW′ | c0Reec0
⎤
⎥
⎥⎦
�(t −k)
This completes the discussion on the equivalence of the general ARMAX to
state–space.

134
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
Next let us develop the state–space equivalent model for some special cases of the
ARMAX model presented in the previous subsection. We begin with the MA
y(t) =
Nc
∑
i=1
cie(t −i)
or
Y(z) = C(z)E(z) = (1 + c1z−1 + ⋯+ cNcz−Nc)E(z)
Deine the state variable as
xi(t −1) := e(t −i −1),
i = 1, … , Nc
(4.122)
and therefore,
xi(t) = e(t −i) = xi−1(t −1),
i = 1, … , Nc
(4.123)
Expanding this expression, we obtain
x1(t) = e(t −1)
x2(t) = e(t −2)
= x1(t −1)
x3(t) = e(t −3)
= x2(t −1)
⋮
⋮
⋮
xNc(t) = e(t −Nc) = xNc−1(t −1)
(4.124)
or in vector-matrix form
⎡
⎢
⎢
⎢⎣
x1(t)
x2(t)
⋮
xNc(t)
⎤
⎥
⎥
⎥⎦
=
⎡
⎢
⎢
⎢
⎢⎣
0
⋯
0
|
0
−−−
−−−
−−−|
1
⋯
0
|
0
⋮
⋱
⋮
|
⋮
0
⋯
1
|
0
⎤
⎥
⎥
⎥
⎥⎦
⎡
⎢
⎢
⎢⎣
x1(t −1)
x2(t −1)
⋮
xNc(t −1)
⎤
⎥
⎥
⎥⎦
+
⎡
⎢
⎢
⎢⎣
1
0
⋮
0
⎤
⎥
⎥
⎥⎦
e(t −1)
y(t) = [c1
c2 ⋯cNc]
⎡
⎢
⎢
⎢⎣
x1(t −1)
x2(t −1)
⋮
xNc(t −1)
⎤
⎥
⎥
⎥⎦
+ c0e(t)
(4.125)
Thus the general form for the MA state–space is given by
x(t) =
⎡
⎢
⎢
⎢
⎢
⎢⎣
0
⋯
0
|
0
−−−
−−−
−−−
|
INc−1
|
⋮
|
0
⎤
⎥
⎥
⎥
⎥
⎥⎦
x(t −1) + b1e(t −1)
y(t) = c′x(t) + c0e(t)
(4.126)
with Nx = Nc, b1, c ∈RNx×1, b1 a unit vector.

4.7
STATE–SPACE MODEL STRUCTURES
135
Example 4.8
Suppose we have the following MA model
y(t) = c0e(t) + c1e(t −1) + c2e(t −2)
and we would like to construct the equivalent state–space representation. Then we
have Nx = 2, and therefore,
x(t) =
[
0
0
1
0
]
x(t −1) +
[
1
0
]
e(t −1)
y(t) = [c1
c2] x(t) + c0e(t)
△△△
Consider the AR model (all-pole) given by
Na
∑
i=1
aiy(t −i) = �e(t)
or
Y(z) =
�E(z)
1 + a1z−1 + ⋯+ aNaz−Na
(4.127)
Here the state vector is deined by xi(t −1) = y(t −i −1) and therefore,
xi(t) = y(t −i) = xi+1(t −1); i = 1, … , Na −1 with xNa(t) = y(t). Expanding over i, we
obtain the vector-matrix state–space model
⎡
⎢
⎢
⎢
⎢
⎢⎣
x1(t)
x2(t)
⋮
xNa(t)
⎤
⎥
⎥
⎥
⎥
⎥⎦
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢⎣
0
|
1
0
⋯
0
0
|
0
1
⋯
0
⋮
|
⋮
⋮
⋱
⋮
0
|
0
0
⋯
1
−−−| −−−
−−−−−−
−aNa
−aNa−1 −aNa−2
⋯
−a1
⎤
⎥
⎥
⎥
⎥
⎥
⎥⎦
⎡
⎢
⎢
⎢
⎢
⎢⎣
x1(t −1)
x2(t −1)
⋮
xNa(t −1)
⎤
⎥
⎥
⎥
⎥
⎥⎦
+
⎡
⎢
⎢
⎢
⎢
⎢⎣
0
0
⋮
�
⎤
⎥
⎥
⎥
⎥
⎥⎦
e(t −1)
y(t) = [0
0
⋯
1]
⎡
⎢
⎢
⎢⎣
x1(t −1)
x2(t −1)
⋮
xNa(t −1)
⎤
⎥
⎥
⎥⎦
(4.128)
In general, we have the AR (all-pole) state–space model
x(t) =
⎡
⎢
⎢
⎢
⎢⎣
0
|
⋮
|
INa−1
0
|
−−−| −−−
−−−
−−−
−aNa
−aNa−1
−aNa−2
⋯
−a1
⎤
⎥
⎥
⎥
⎥⎦
x(t −1) + be(t −1)
y(t) = c′x(t)
(4.129)
with Nx = Na, b, c ∈RNx×1. Consider the following example to demonstrate this form.

136
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
Example 4.9
Given the AR model with Na = 2 and �=
√
2, ind the equivalent state–space form.
We have
y(t) = −a1y(t −1) −a2y(t −2) +
√
(2)e(t)
and therefore,
x1(t −1) = y(t −2)
x2(t −1) = y(t −1)
which gives
x1(t) = y(t −1) = x2(t −1)
x2(t) = y(t) = −a1y(t −1) −a2y(t −2) = −a1x2(t −1) −a2x1(t −1)
or more succinctly
x(t) =
[
0
1
−a2
−a1
]
x(t −1) +
[ 0
√
2
]
e(t −1)
y(t) = [0
1]x(t)
△△△
Another useful state–space representation is the normal form which evolves by
performing a partial fraction expansion of a rational discrete transfer function model
(ARMA) to obtain
h(t) =
Np
∑
i=1
Ri(pi)−t
or
H(z−1) = Y(z−1)
E(z−1) =
Np
∑
i=1
Ri
1 −piz−1
(4.130)
for {Ri, pi}; i = 1, … , Np the set of residues and poles of H(z−1). Note that the normal
form model is the decoupled or parallel system representation based on the following
set of relations
yi(t) −piyi(t −1) = e(t),
i = 1, … , Np
Deining the state variable as xi(t) := yi(t), then equivalently
xi(t) −pixi(t −1) = e(t),
i = 1, … , Np
(4.131)
and therefore the output is given by
y(t) =
Np
∑
i=1
Riyi(t) =
Np
∑
i=1
Rixi(t),
i = 1, … , Np
(4.132)

4.8
NONLINEAR (APPROXIMATE) GAUSS–MARKOV STATE–SPACE MODELS
137
Expanding these relations over i, we obtain
⎡
⎢
⎢
⎢⎣
x1(t)
x2(t)
⋮
xNp(t)
⎤
⎥
⎥
⎥⎦
=
⎡
⎢
⎢
⎢⎣
p1
0
⋯
0
0
p2
⋯
0
⋮
⋮
⋱
⋮
0
0
⋯
pNp
⎤
⎥
⎥
⎥⎦
⎡
⎢
⎢
⎢⎣
x1(t −1)
x2(t −1)
⋮
xNa(t −1)
⎤
⎥
⎥
⎥⎦
+
⎡
⎢
⎢
⎢⎣
1
1
⋮
1
⎤
⎥
⎥
⎥⎦
e(t −1)
y(t) = [R1
R2
⋯
RNp]
⎡
⎢
⎢
⎢⎣
x1(t −1)
x2(t −1)
⋮
xNp(t −1)
⎤
⎥
⎥
⎥⎦
(4.133)
Thus, the general decoupled form of the normal state–space model is given by
x(t) =
⎡
⎢
⎢
⎢⎣
p1
0
⋯
0
0
p2
⋯
0
⋮
⋮
⋱
⋮
0
0
⋯
pNp
⎤
⎥
⎥
⎥⎦
x(t −1) + be(t −1)
y(t) = c′x(t)
(4.134)
for b ∈Np×1 with b = 1, a Np-vector of unit elements. Here c ∈1×Np and
c′ = [R1
R2
⋯
RNp].
Example 4.10
Consider the following set of parameters and model with Nx = Np = 3 and
yi(t) = piyi(t −1) + e(t −1)
y(t) =
3
∑
i=1
Riyi(t)
Using the normal state–space form structure above, we obtain by inspection
x(t) =
⎡
⎢
⎢⎣
p1
0
0
0
p2
0
0
0
p3
⎤
⎥
⎥⎦
x(t −1) +
⎡
⎢
⎢⎣
1
1
1
⎤
⎥
⎥⎦
e(t −1)
y(t) = [R1
R2
R3] x(t)
△△△
4.8
NONLINEAR (APPROXIMATE) GAUSS–MARKOV STATE–SPACE
MODELS
Many processes in practice are nonlinear rather than linear. Coupling the nonlin-
earities with noisy data makes the signal processing problem a challenging one. In

138
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
Time
0
Deterministic state trajectory, xt
xt
t
xt
∗
FIGURE 4.5
Linearization of a deterministic system using the reference trajectory
deined by (x∗(t), u∗(t)).
this section we develop an approximate solution to the nonlinear modeling problem
involving the linearization of the nonlinear process about a chosen or “known” ref-
erence trajectory. We limit our discussion to discrete nonlinear systems. Continuous
solutions to this problem are developed in Refs. [6–13].
Suppose we model a process by a set of nonlinear stochastic vector difference
equations in state–space form as
x(t) = a[x(t −1)] + b[u(t −1)] + �(t −1)
(4.135)
with the corresponding measurement model
y(t) = c[x(t)] + �(t)
(4.136)
where a[⋅], b[⋅], c[⋅] are nonlinear vector functions of x, u with x, a, b, �∈RNx×1,
y, c, �∈RNy×1 and �∼(0, R��(t −1)), �∼(0, R��(t)).
Ignoring the additive noise sources, we “linearize” the process and measurement
models about a known deterministic reference trajectory deined by [x∗(t), u∗(t)] as
illustrated in Fig. 4.5,10 that is,
x∗(t) = a[x∗(t −1)] + b[u∗(t −1)]
(4.137)
10 In practice, the reference trajectory is obtained either by developing a mathematical model of the
process or by simulating about some reasonable operating conditions to generate the trajectory using the
state–space model.

4.8
NONLINEAR (APPROXIMATE) GAUSS–MARKOV STATE–SPACE MODELS
139
Deviations or perturbations from this trajectory are deined by
�x(t) := x(t) −x∗(t)
�u(t) := u(t) −u∗(t)
Substituting the previous equations into these expressions, we obtain the perturbation
trajectory as
�x(t) = a[x(t −1)] −a[x∗(t −1)] + b[u(t −1)] −b[u∗(t −1)] + �(t −1)
(4.138)
The nonlinear vector functions a[⋅] and b[⋅] can be expanded into a irst-order
Taylor series about the reference trajectory [x∗(t), u∗(t)] as11
a[x(t −1)] = a[x∗(t −1)] + da[x∗(t −1)]
dx∗(t −1) �x(t −1) + H.O.T.
b[u(t −1)] = b[u∗(t −1)] + db[u∗(t −1)]
du∗(t −1) �u(t −1) + H.O.T.
(4.139)
We deine the irst-order Jacobian matrices as
A[x∗(t −1)] := da[x∗(t −1)]
dx∗(t −1) ,
and
B[u∗(t −1)] := db[u∗(t −1)]
du∗(t −1)
(4.140)
Incorporating the deinitions of Eq. 4.140 and neglecting the higher-order terms
(H.O.T.) in Eq. 4.139, the linearized process model in Eq. 4.138 can be expressed as
�x(t) = A[x∗(t −1)]�x(t −1) + B[u∗(t −1)]�u(t −1) + �(t −1)
(4.141)
Similarly, the measurement system can be linearized by using the reference measure-
ment
y∗(t) = c[x∗(t)]
(4.142)
and applying the Taylor-series expansion to the nonlinear measurement model
c[x(t)] = c[x∗(t)] + dc[x∗(t)]
dx∗(t) �x(t) + H.O.T.
(4.143)
The corresponding measurement perturbation is deined by
�y(t) := y(t) −y∗(t) = c[x(t)] −c[x∗(t)] + �(t)
(4.144)
11We use the shorthand notation d(⋅)
d�∗to mean d(⋅)
d�
|||||�=�∗
.

140
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
Substituting the irst-order approximation for c[x(t)] leads to the linearized measure-
ment perturbation as
�y(t) = C[x∗(t)]�x(t) + �(t)
(4.145)
where C[x∗(t)] is deined as the measurement Jacobian as before.
Summarizing, we have linearized a deterministic nonlinear model using a irst-
order Taylor-series expansion for the functions a, b, and c and then developed a
linearized Gauss–Markov perturbation model valid for small deviations given by
�x(t) = A[x∗(t −1)]�x(t −1) + B[u∗(t −1)]�u(t −1) + �(t −1)
�y(t) = C[x∗(t)]�x(t) + �(t)
(4.146)
with A, B, and C the corresponding Jacobian matrices and �, �zero-mean Gaussian.
We can also use linearization techniques to approximate the statistics of the process
and measurements. If we use the irst-order Taylor-series expansion and expand about
the mean mx(t) rather than x∗(t), then taking expected values
mx(t) = E{a[x(t −1)]} + E{b[u(t −1)]} + E{�(t −1)}
(4.147)
gives
mx(t) = a[mx(t −1)] + b[u(t −1)]
(4.148)
which follows by linearizing a[⋅] about mx and taking the expected value to obtain
E{a[x(t −1)]} = E{a[mx(t −1)] + da[mx(t −1)]
dmx(t −1) [x(t −1) −mx(t −1)]}
= a[mx(t −1)] + da[mx(t −1)]
dmx(t −1) [E{x(t −1)} −mx(t −1)]
= a[mx(t −1)]
The variance equations P(t) := cov(x(t)) can also be developed in a similar manner
(see Ref. [2] for details) to give
P(t) = A[mx(t −1)]P(t −1)A′[mx(t −1)] + R��(t −1)
(4.149)
Using the same approach, we arrive at the accompanying measurement statistics
my(t) = c[mx(t)]
and
Ryy(t) = C[mx(t)]P(t)C′[mx(t)] + R��(t)
(4.150)
We summarize these results in an “approximate” Gauss–Markov model of Table 4.3.
Before we conclude consider the following example to illustrate the approximation.

4.8
NONLINEAR (APPROXIMATE) GAUSS–MARKOV STATE–SPACE MODELS
141
TABLE 4.3
Approximate Nonlinear Gauss–Markov Model
State Propagation
x(t) = a[x(t −1)] + b[u(t −1)] + �(t −1)
State Mean Propagation
mx(t) = a[mx(t −1)] + b[u(t −1)]
State Covariance Propagation
P(t) = A[mx(t −1)]P(t −1)A′[mx(t −1)] + R��(t −1)
Measurement Propagation
y(t) = c[x(t)] + �(t)
Measurement Mean Propagation
my(t) = c[mx(t)]
Measurement Covariance Propagation
Ryy(t) = C[mx(t)]P(t)C′[mx(t)] + R��(t)
Initial Conditions
x(0) and P(0)
Jacobians
A[x∗(t −1)] ≡
da[x(t−1)]
dx(t−1)
|||x=x∗(t−1)
C[x∗(t)] ≡
dc[x(t)]
dx(t)
|||x=x∗(t) x∗→mx
Example 4.11
Consider the discrete nonlinear process given by
x(t) = (1 −0.05ΔT)x(t −1) + 0.04ΔTx2(t −1) + �(t −1)
with corresponding measurement model
y(t) = x2(t) + x3(t) + �(t)
where �(t) ∼(0, R��), �(t) ∼(0, R��), and x(0) ∼(x(0), P(0)). Performing the
differentiations we obtain the following Jacobians
A[x(t −1)] = 1 −0.05ΔT + 0.08ΔTx(t −1)
and
C[x(t)] = 2x(t) + 3x2(t)
△△△
Although the linearization approach discussed here seems somewhat extraneous
relative to the previous sections, it becomes a crucial ingredient in the classical
approach to (approximate) nonlinear estimation of the subsequent chapters. We
discuss the linear state–space approach (Kalman ilter) to the estimation problem
in great detail in the next chapter and then show how these linearization concepts can
be used to solve the nonlinear estimation problem in the following chapter. There
the popular “extended” Kalman ilter processor relies heavily on the linearization
techniques developed in this section for its development.

142
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
4.9
SUMMARY
In this chapter we have discussed the development of continuous-time, sampled-data,
and discrete-time state–space models. The stochastic variants of these three types of
models were presented leading to the Gauss–Markov representations for both linear
and (approximate) nonlinear systems. The discussion of both the deterministic and
stochastic state–space models included a brief development of their second-order
statistics. We also discussed the underlying discrete systems theory as well as a
variety of time series models (ARMAX, AR, MA, etc.) and showed that can easily be
represented in state–space form through the use of canonical forms (models). These
models form the embedded structure incorporated into the majority of the Bayesian
processors that will be discussed in subsequent chapters.
MATLAB NOTES
MATLAB has many commands to convert to/from state–space models to other
forms useful in signal processing. Many of them reside in the Signal Processing
and Control Systems toolboxes. The matrix exponential invoked by the expm
command is determined from Taylor/Pad´e approximants using the scaling and
squaring approach of Section 4.2. Also the commands expmdemo1, expmdemo2,
and expmdemo3 demonstrate the trade-offs of the Pad´e, Taylor and eigenvector
approaches to calculating the matrix exponential. The ordinary differential equa-
tion method is available using the wide variety of numerical integrators available
(ode∗). Converting to/from transfer functions and state–space is accomplished
using the ss2tf and tf2ss commands, respectively. ARMAX simulations are eas-
ily accomplished using the ilter command with a variety of options converting
from ARMAX-to/from transfer functions. The Identiication Toolbox converts
polynomial-based models to state–space and continuous parameters including
Gauss–Markov to discrete parameters (th2ss, thc2thd, thd2thc). The the Third
Party Toolbox SSPACK_PC converts continuous-time models to discrete (SSC-
TOD) performs Gauss–Markov (linear and nonlinear) simulations as well as
innovations-based simulations (SSISIM and conversions from GM to innovations
models (INVTOGM, GMTOINV)). See http://www.techni-soft.net for details.
REFERENCES
1. T. Kailath, Linear Systems (Englewood Cliffs, NJ: Prentice-Hall, 1980).
2. F. Szidarovszky and A. Bahill, Linear Systems Theory (Boca Raton, FL: CRC Press,
1980).
3. R. DeCarlo, Linear Systems: A State Variable Approach (Englewood Cliffs, NJ: Prentice-
Hall, 1989).
4. C. Chen, Introduction to Linear System Theory (New York: Holt, Rhinehart, and Winston,
1984).

PROBLEMS
143
5. S. Tretter, Introduction to Discrete-Time Signal Processing (New York: John Wiley &
Sons, Inc., 1976).
6. A. Jazwinski, Stochastic Processes and Filtering Theory (New York: Academic Press,
1970).
7. A. Sage and J. Melsa, Estimation Theory with Applications to Communications and
Control (New York: McGraw-Hill, 1971).
8. P. Maybeck, Stochastic Models, Estimation and Control, Vol. 1 (New York: Academic
Press, 1979).
9. G. Goodwin and R. L. Payne, Dynamic System Identiication (New York: Academic Press,
1976).
10. G. Goodwin and K. Sin, Adaptive Filtering, Prediction and Control (Englewood Cliffs,
NJ: Prentice-Hall, 1984).
11. J. Mendel, Lessons in Estimation Theory for Signal Processing, Communications, and
Control (Englewood Cliffs, NJ: Prentice-Hall, 1995).
12. R. Brown and P.C. Hwang, Introduction to Random Signals and Applied Kalman Filtering
(New York: John Wiley & Sons, Inc., 1997).
13. J. Candy, Model-Based Signal Processing (Hoboken, NJ: John Wiley & Sons, Inc./IEEE
Press, 2006).
14. E. Robinson and M. Silvia, Digital Foundations of Time Series Analysis, Vol. 1 (San
Francisco, CA: Holden-Day, 1979).
15. D. Simon, Optimal State Estimation Kalman, H∞and Nonlinear Approaches (Hoboken,
NJ: John Wiley & Sons, Inc., 2006).
16. M. Grewal and A. Andrews, Kalman Filtering: Theory and Practice (Englewood Cliffs,
NJ: 1993).
17. C. Moler and C. Van Loan, “Nineteen dubious ways to compute the exponential of a
matrix, twenty-ive years later,” SIAM Review, 45, 1, 3–49, 2003.
18. G. Golub and C. Van Loan, Matrix Computation (Baltimore, MD: Johns Hopkins Univer-
sity Press, 1989).
19. B. Ho and R. Kalman, “Effective reconstruction of linear state variable models from
input/output data,” Regelungstechnik, 14, 545–548, 1966.
20. J. Candy, M. Warren, and T. Bullock, “Realization of an invariant system description from
Markov sequences,” IEEE Trans. Auto. Control, AC-23, 12, 93–96, 1977.
21. S. Kung, K. Arun, and D. Bhaskar Rao, “State–space and singular-value decomposition-
based approximation methods for the harmonic retrieval problem,” J. Opt. Soc. Am., 73,
12, 1799–1811, 1983.
PROBLEMS
4.1
Suppose the stochastic process {y(t)} is generated by
y(t) = a exp(−t) + bt,
a, b random, then
(a) What is the mean of the process?
(b) What is the corresponding covariance?
(c) Is the process stationary if E{a} = E{b} = 0 and E{ab} = 0.

144
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
4.2
Suppose x, y, z are jointly Gaussian random variables with corresponding means
mx, my, mz and variances Rxx, Ryy, Rzz show that:
(a) If y = ax + b, a, b constants, then y ∼N(amx + b, a2Rxx).
(b) If x and y are uncorrelated then they are independent.
(c) If x(i) are Gaussian with mean m(i) and variance Rxx(i), then for
y =
∑
i
Kix(i),
y ∼N
(
∑
i
Kim(i),
∑
i
K2
i Rxx(i)
)
(d) If x and y are jointly (conditionally) Gaussian, then
E{x|y} = mx + RxyR−1
yy (y −my), and
Rx|y = Rxx + RxyR−1
yy Ryx
(e) The random variable x −E{x|y} is orthogonal to y.
(f) If y and z are independent, then
E{x|y, z} = E{x|y} + E{x|z} −mx
(g) If y and z are not independent, show that
E{x|y, z} = E{x|y, e} = E{x|y} + E{x|e} −mx
for e = z −E{z|y}.
4.3
Assume y(t) is a zero-mean ergodic process with covariance Ryy(k), calculate
the corresponding power spectra Syy(z) if
(a) Ryy(k) = Ca|k|.
(b) Ryy(k) = Ccos(�|k|), |k| < �
2 .
(c) Ryy(k) = Cexp(−a|k|).
(Hint: Recall the sum decomposition: Syy(z) = S+
yy(z) + S−
yy(z) −Ryy(0) with
S+
yy the one-sided Z-transform and S−
yy(z) = S+
yy(z−1))
4.4
Develop a MATLAB program to simulate the ARMA process
y(t) = −ay(t −1) + e(t)
where a = 0.75, e ≈N(0, 0.1) for 100 data points.
(a) Calculate the analytic covariance Ryy(k).
(b) Determine an expression to “recursively” calculate Ryy(k).
(c) Plot the simulated results and construct the ±2√Ryy(0) bounds.
(d) Do 95% of the samples fall within these bounds?

PROBLEMS
145
4.5
Develop the digital ilter to simulate a sequence y(t) with covariance
Ryy(k) = 4e−3|k|. Perform the simulation using MATLAB.
(Hint: Recall the spectral factorization (Wiener): Syy(z) = H(z) × H(z−1)
where the poles and zeros of H(z) lie inside the unit circle)
Using the “realized” digital ilter perform a simulation as in the previous
example and check the validity of the samples lying within bounds.
4.6
Suppose we are given a zero-mean process with covariance
Ryy(k) = 10exp(−0.5|k|)
(a) Determine the digital ilter which when driven by white noise will yield a
sequence with the above covariance.
(b) Develop a computer program to generate y(t) for 100 points.
(c) Plot the results and determine if 95% of the samples fall within
±2√Ryy(0).
4.7
Suppose we are given the factored power spectrum Syy(z) = H(z)H(z−1)
with
H(z) = 1 + �1z−1 + �2z−2
1 + �1z−1 + �2z−2
(a) Develop the ARMAX model for the process.
(b) Develop the corresponding Gauss–Markov model for both the standard and
innovations representation of the process.
4.8
Suppose we are given a causal LTI system characterized by its impulse
response h(t). If this system is excited by zero-mean, unit variance white noise,
then
(a) Determine the output variance Ryy(0);
(b) Determine the covariance Ryy(k) for k > 0;
(c) Suppose the system transfer function is given by
H(z) =
1 + b0z−1
1 + a1z−1 + a2z−2
ind a method to recursively calculate h(t) and therefore Ryy(0).
4.9
Given the covariance function
Ryy(k) = e−1∕2|k| cos �|k|,
ind the digital ilter when driven by unit variance white noise produces a
sequence {y(t)} with these statistics.

146
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
4.10 Suppose we have a process characterized by the difference equation
y(t) = x(t) + 1∕2x(t −1) + 1∕3x(t −2)
(a) Determine a recursion for the output covariance Ryy(k).
(b) If x(t) is white with variance �2
xx, determine Ryy(k).
(c) Determine the output PSD, Syy(z).
4.11 We are given a linear system characterized by the difference equation
y(t) −1∕5y(t −1) =
1
√
3
x(t)
and the system is excited by:
1. white Gaussian noise x ∼N(0, 3);
2. exponentially correlated noise Ree(k) = (1∕2)|k|.
In both cases ind:
(a) Output PSD Syy(z);
(b) Output covariance Ryy(k);
(c) Cross-spectrum Sye(k);
(d) Cross-covariance Rye(k).
4.12 We are given the following Gauss–Markov model
x(t) = 1∕3x(t −1) + 1∕2�(t −1)
y(t) = 5x(t) + �(t)
�∼N(0, 3)
�∼N(0, 2)
(a) Calculate the state power spectrum Sxx(z).
(b) Calculate the measurement power spectrum Syy(z).
(c) Calculate the state covariance recursion P(t).
(d) Calculate the steady-state covariance P(t) = ⋯= P = Pss.
(e) Calculate the output covariance recursion Ryy(t).
(f) Calculate the steady-state output covariance Ryy.
4.13 Suppose we are given the Gauss–Markov process characterized by the state
equations
x(t) = 0.97x(t −1) + u(t −1) + �(t −1)
for u(t) a step of amplitude 0.03 and �∼N(0, 10−4) and x(0) ∼N(2.5, 10−12).
(a) Calculate the covariance of x, that is, P(t) = Cov(x(t)).

PROBLEMS
147
(b) Since the process is stationary, we know that
P(t + k) = P(t + k −1) = ⋯= P(0) = P
What is the steady-state covariance P of this process?
(c) Develop a MATLAB program to simulate this process.
(d) Plot the process x(t) with the corresponding conidence limits ±2
√
P(t)
for
100
data
points,
do
95%
of
the
samples
lie
within
the
bounds?
4.14 Suppose we are given the ARMAX model
y(t) = −0.5y(t −1) −0.7y(t −2) + u(t) + 0.3u(t −1)
+ e(t) + 0.2e(t −1) + 0.4e(t −2)
(a) What is the corresponding innovations model in state–space form for
e ∼N(0, 10)?
(b) Calculate the corresponding covariance matrix R∗
ee.
4.15 Given the following ARMAX model
A(q−1)y(t) = B(q−1)u(t) + C(q−1)
D(q−1)�(t)
for q−1 the backward shift (delay) operator such that
A(q−1) = 1 + 1.5q−1 + 0.7q−2
B(q−1) = 1 + 0.5q−1
C(q−1) = 1 + 0.7q−1
D(q−1) = 1 + 0.5q−1
(a) Find the pulse transfer representation of this process (C = D = 0). Convert
it to the following equivalent pole-zero and normal state–space forms. Is
the system controllable? Is it observable? Show your calculations.
(b) Find the pole-zero or ARX representation of this process (C = 1, D = 0).
Convert it to the equivalent state–space form.
(c) Find the pole-zero or ARMAX representation of this process (D = 0). Con-
vert it to the equivalent state–space form.
(d) Find the all-zero or FIR representation of this process (A = 1, C = D = 0).
Convert it to the equivalent state–space form.
(e) Find the all-pole or IIR representation of this process (B = 0, C = 0, D = 0).
Convert it to the equivalent state–space form.

148
STATE–SPACE MODELS FOR BAYESIAN PROCESSING
(f) Find the all-zero or MA representation of this process (A = 1, B = 0, D = 0).
Convert it to the equivalent state–space form.
(g) Using the full model above with A, B, C, D polynomials, is it possible to
ind an equivalent Gauss–Markov representation? If so, ind it and convert
it to the equivalent state–space form. (Hint: Consider the C∕D polynomials
to be a coloring ilter with input �(t) and output e(t))
4.16 Given a continuous–discrete Gauss–Markov model
̇xt = �xt + ut + �t
y(tk) = �x(tk) + �(tk)
where �t and �(tk) are zero-mean and white with respective covariances R��
and R��along with a piecewise constant input ut.
(a) Develop the continuous–discrete mean and covariance propagation models
for this system.
(b) Suppose �(t) is processed by a coloring ilter that exponentially correlates it
R��(�) = Ge−|�|�. Develop the continuous–discrete Gauss–Markov model
in this case.
4.17 Develop the continuous–discrete Gauss–Markov models for the following sys-
tems:
(a) Wiener process: ̇zt = �t; z0 = 0, �is zero-mean, white with R��.
(b) Random bias: ̇zt = 0; z0 = zo, where zo ∼(0, Rzozo).
(c) Random ramp: ̈zt = 0; ̇z0 = z1; z0 = zo.
(d) Random oscillation: ̈zt + �2
ozt = 0; ̇z0 = z1; z0 = zo.
(e) Random second order: ̈zt + 2��n ̇z + �2
nzt = �2
n�t; ̇z0 = z1; z0 = zo.
4.18 Develop the continuous–discrete Gauss–Markov model for correlated process
noise, that is,
̇�t = Ac��t + Bc�ut + Wc��∗
t
for �∗∼(0, R�∗�∗).
4.19 Develop the approximate Gauss–Markov model for the following nonlinear
state transition and measurement model given by
x(t) = 1
2x(t −1) +
25x(t −1)
1 + x2(t −1) + 8 cos(1.2(t −1)) + �(t −1)
y(t) = x2(t)
20 + �(t)
where �∼(0, R��(t −1)) and �∼(0, R��(t)). The initial state is Gaussian
distributed with x(0) ∼(0, P(0)).

PROBLEMS
149
4.20 Consider the discrete nonlinear process given by
x(t) = (1 −0.05ΔT)x(t −1) + 0.04ΔTx2(t −1) + �(t −1)
with corresponding measurement model
y(t) = x2(t) + x3(t) + �(t)
where �∼(0, R��(t −1)) and �∼(0, R��(t)). The initial state is Gaussian
distributed with x(0) ∼(0, P(0)).
Develop the approximate Gauss–Markov process model for this nonlinear
system.

5
CLASSICAL BAYESIAN
STATE–SPACE PROCESSORS
5.1
INTRODUCTION
In this chapter, we introduce the concepts of statistical signal processing from
the Bayesian perspective using state–space models. We irst develop the Bayesian
paradigm using the generic state–space representation of the required conditional
distributions and show how they propagate within the Bayesian framework. Next, we
start with the linear (time-varying) Gauss–Markov model and develop the required
conditional distributions leading to the well-known Kalman ilter processor [1]. Based
on this fundamental theme, we progress to the idea of linearization of the nonlinear
state–space system developed in the previous chapter, where we derive the linearized
Bayesian processor (LZ-BP). It is shown that the resulting processor provides a solu-
tion (time-varying) to the nonlinear state estimation. We then develop the extended
Bayesian processor (XBP), or equivalently the extended Kalman ilter (EKF), as a
special case of the LZ-BP linearizing about the most currently available estimate.
Next, we investigate a further enhancement of the XBP by introducing a local itera-
tion of the nonlinear measurement system. Here the processor is called the iterated-
extended Bayesian processor (IX-BP) and is shown to produce improved estimates
at a small computational cost in most cases. We summarize the results with a case
study implementing a 2D-tracking ilter.
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
150

5.2
BAYESIAN APPROACH TO THE STATE–SPACE
151
5.2
BAYESIAN APPROACH TO THE STATE–SPACE
In the previous chapter, we briely developed deterministic and stochastic (Gauss–
Markov) state–space models and demonstrated how the states propagate through
the state transition mechanism for both continuous and discrete systems and their
variants. Here we again take a Bayesian perspective and assume that the state or
dynamic variables evolve according to a “probabilistic” transition mechanism.
Bayesian estimation relative to the state–space models is based on extracting
the unobserved or hidden dynamic (state) variables from noisy measurement data.
The Markovian state vector with initial distribution, Pr(x(0)), propagates tempo-
rally throughout the state–space according to the probabilistic transition distribution,
Pr(x(t)|x(t −1)), while the conditionally independent measurements evolve from the
likelihood distribution, Pr(y(t)|x(t)). We see that the dynamic state variable at time
t is obtained through the transition probability based on the previous state (Marko-
vian property), x(t −1), and the knowledge of the underlying conditional probability.
Once propagated to time t, the dynamic state variable is used to update or correct
based on the likelihood probability and the new measurement y(t). Note that it is the
knowledge of these conditional distributions that enable the Bayesian processor (BP).
Returning to the usual model-based constructs of the dynamic state variables dis-
cussed in the previous chapter, we see that there is an implied equivalence between the
probabilistic distributions and the underlying state/measurement transition models.
Recall from Chapter 4 that the functional discrete state representation is given by
x(t) = A(x(t −1), u(t −1), �(t −1))
y(t) = C(x(t), u(t), �(t))
(5.1)
where �and �are the respective process and measurement noise sources, with u a
known input. Here A(⋅) is the nonlinear (or linear) dynamic state transition function
and C(⋅), the corresponding measurement function. Both conditional probabilistic
distributions embedded within the Bayesian framework are completely speciied by
these functions and the underlying noise distributions: Pr(�(t −1)) and Pr(�(t)). That
is, we have the (implied) equivalence1
A(x(t −1), u(t −1), �(t −1)) ⇒Pr(x(t)|x(t −1)) ⇔(x(t)|x(t −1))
C(x(t), u(t), �(t)) ⇒Pr(y(t)|x(t))
⇔(y(t)|x(t))
(5.2)
Thus, the state–space model along with the noise statistics and prior distributions
deine the required Bayesian representation or probabilistic propagation model which
deines the evolution of the states and measurements through the transition proba-
bilities. This is sometimes a subtle point that must be emphasized. As illustrated in
Fig. 5.1, the dynamic state variables propagate throughout state–space speciied by
1 We use this notation to emphasize the inluence of both process () and measurement () representations
on the conditional distributions.

152
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
(
)
( ) (
1)
x t x t −
(
)
(
1) ( )
x t
x t
+
(
)
(
1) (
1)
y t
x t
−
−
(
)
( ) ( )
y t x t
(
)
(
1) (
1)
y
C
C
C
A
A
t
x t
+
+
(
1)
x t −
( )
x t
(
1)
x t +
(
1)
y t −
( )
y t
(
1)
y t +
1
t −
t
1
t +
FIGURE 5.1
Bayesian state–space probabilistic evolution.
the transition probability (x(t)|x(t −1)) using the embedded process model. That
is, the “unobserved” state at time (t −1) requires the transition probability distribu-
tion to propagate to the state at time t. Once evolved, the state combines under the
corresponding measurement at time t through the conditional likelihood distribution
(y(t)|x(t)) using the embedded measurement model to obtain the required likelihood
distribution. These events continue to evolve throughout, with the states propagating
through the state transition probability using the process model, and the measure-
ments generated by the states and likelihood using the measurement model. From the
Bayesian perspective, the broad prior is scaled by the evidence and “narrowed” by
the likelihood to estimate the posterior.
With this in mind we can now return to the original Bayesian estimation problem,
deine it and show (at least conceptually) the optimal solution based on the state–space
representation.
The basic dynamic state estimation (signal enhancement) problem can now be
stated in the Bayesian framework as
GIVEN a set of noisy uncertain measurements Yt = {y(t)}, and known inputs {u(t)},
t = 0, … , N, along with the corresponding prior distributions for the initial state and
process and measurement noise sources: Pr(x(0)), Pr(�(t −1)), Pr(�(t)), as well as
the conditional transition and likelihood probability distributions: Pr(x(t)|x(t −1)),
Pr(y(t)|x(t)) characterized by the state and measurement models: (x(t)|x(t −1)),
(y(t)|x(t)), FIND the “best” estimate of the iltering posterior ̂Pr(x(t)|Yt) and its
associated statistics.
It is interesting to note that the entire Bayesian system can be deined by the set Σ
as
Σ := [{y(t)}, {u(t)}, Pr(x(0)), Pr(�(t −1)), Pr(�(t)), (x(t)|x(t −1)), (y(t)|x(t))]

5.3
LINEAR BAYESIAN PROCESSOR (LINEAR KALMAN FILTER)
153
Compare this to the model-based solutions to follow where we obtain closed-form
analytic expressions for these distributions.
Analytically, to generate the model-based version of the sequential BP, we replace
the transition and likelihood distributions with the conditionals of Eq. 5.2. The solu-
tion to the signal enhancement or equivalently state estimation problem is given by
the iltering distribution Pr(x(t)|Yt) which was solved previously in Section 2.5 (see
Table 2.1). We start with the prediction recursion characterized by the Chapman–
Kolmogorov equation replacing the transition probability with the implied model-
based conditional, that is,
Pr(x(t)|Yt−1) = ∫
Embedded process model
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
(x(t)|x(t −1))
×
Prior
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(x(t −1)|Yt−1) dx(t −1)
(5.3)
Next, we incorporate the model-based likelihood into the posterior equation with
the understanding that the process model has been incorporated into the prediction
Pr(x(t)|Yt) =
Embedded measurement model
⏞⏞⏞⏞⏞⏞⏞⏞⏞
(y(t)|x(t))
×
Predicition
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(x(t)|Yt−1)
/
Pr(y(t)|Yt−1)
(5.4)
So we see from the Bayesian perspective that the sequential BP employing the
state–space representation of Eq. 5.1 is straightforward. Next let us investigate a more
detailed development of the processor resulting in a closed-form solution—the linear
Kalman ilter.
5.3
LINEAR BAYESIAN PROCESSOR (LINEAR KALMAN FILTER)
In this section, we constrain the state–space model to be linear (time-varying) and
apply the Bayesian approach to obtain the optimal processor assuming additive
Gaussian noise.
Suppose we are given the linear discrete Gauss–Markov model of the previous
section (ignoring u with W = I for notational simplicity) and we would like to
develop the BP. Since we know the processes are linear and Gaussian, we know that
the required distributions will also be Gaussian. To develop the processor for this
case, we start with the prediction equation2 and use the process model of Eq. 4.78,
that is,
Pr(x(t)|Yt−1) = ∫(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1) dx(t −1)
2 We have changed Gaussian distribution notation to include the random process, that is, (mz, Rzz) →
(z : mz, Rzz).

154
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
where the iltered conditional3 is:
Pr(x(t −1)|Yt−1) ∼(x(t) : ̂x(t −1|t −1), ̃P(t −1|t −1))
Now using the process model, we have that
(x(t)|x(t −1)) ∼(x(t) : A(t −1)̂x(t −1|t −1), A(t −1)̃P(t −1|t −1)
× A′(t −1) + R��(t −1))
which follows directly from the linearity of the conditional expectation operator, that
is,
̂x(t|t −1) = E{x(t)|Yt−1} = E{A(t −1)x(t −1) + �(t −1)|Yt−1}
= A(t −1)̂x(t −1|t −1)
(5.5)
Using this result, the predicted state estimation error can be obtained as
̃x(t|t −1) = x(t) −̂x(t|t −1)
= [A(t −1)x(t −1) + �(t −1)] −A(t −1)̂x(t −1|t −1)
= A(t −1)̃x(t −1|t −1) + �(t −1)
(5.6)
and the corresponding state error covariance ̃P(t|t −1) = E{̃x(t|t −1)̃x′(t|t −1)} is
easily derived. Summarizing, the conditional means and covariances that completely
characterize the current (Gaussian) state evolve according to the following equations:
̂x(t|t −1) = A(t −1)̂x(t −1|t −1)
[Prediction]
̃P(t|t −1) = A(t −1)̃P(t −1|t −1)A′(t −1) + R��(t −1)
[Prediction covariance]
Substituting these multivariate Gaussian distributions (transition and iltered) into
the prediction equation, we have
Pr(x(t)|Yt−1) ∼(x(t) : ̂x(t|t −1), ̃P(t|t −1))
With the prediction distribution available, we require the correction or update
distribution obtained from the likelihood and the measurement model of Eq. 5.4, that
is,
Pr(x(t)|Yt) = (y(t)|x(t)) × Pr(x(t)|Yt−1)
Pr(y(t)|Yt−1)
3 This notation is deined in terms of conditional means and covariances by: ̂x(t|t) := E{x(t)|Yt} and
̃P(t|t) := cov(̃x(t|t)) for the state estimation error, ̃x(t|t) := x(t) −̂x(t|t).

5.3
LINEAR BAYESIAN PROCESSOR (LINEAR KALMAN FILTER)
155
Under the Gauss–Markov model assumptions, we know that each of the condi-
tional distributions can be expressed in terms of the Gaussian distribution as
(y(t)|x(t)) ∼(y(t) : C(t)x(t), R��(t))
Pr(x(t)|Yt−1) ∼(x(t) : ̂x(t|t −1), ̃P(t|t −1))
Pr(y(t)|Yt−1) ∼(y(t) : ̂y(t|t −1), Ree(t))
for Ree(t) the innovations covariance with innovations deined by e(t) := y(t) −̂y
(t|t −1) and predicted or iltered measurement given by ̂y(t|t −1) = C(t)̂x(t|t −1).
Substituting these probabilities into Eq. 5.4 and combining all constants into a
single constant �, we obtain
Pr(x(t)|Yt) = �× exp
[
−1
2(y(t) −C(t)x(t))′R−1
��(t)(y(t) −C(t)x(t))
]
× exp
[
−1
2(x(t) −̂x(t|t −1))′ ̃P−1(t|t −1)(x(t) −̂x(t|t −1))
]
× exp
[
+1
2(y(t) −̂y(t|t −1))′R−1
ee (t)(y(t) −̂y(t|t −1))
]
Recognizing the measurement noise, state estimation error and innovation in the
above terms, we have that the posterior probability is given in terms of the Gauss–
Markov model by
Pr(x(t)|Yt) = �× exp
[
−1
2�′(t)R−1
��(t)�(t)
]
× exp
[
−1
2 ̃x′(t|t −1)̃P−1(t|t −1)̃x(t|t −1)
]
× exp
[
+1
2e′(t)R−1
ee (t)e(t)
]
(5.7)
So we see that the posterior distribution can be estimated under the multivariate
Gaussian assumptions and the corresponding linear (time-varying) Gauss–Markov
model. This is the optimal BP under these assumptions. In most cases we are not
able to characterize the distributions in closed form and must resort to numerical
(simulation-based) solutions.
We realize at this point that we have the optimal Bayesian predictor and posterior,
but we still have not extracted the optimal state estimates explicitly and its associated
performance metric. Recall from the batch Bayesian solutions of Section 2.1 that
once we have the posterior, we can estimate a variety of statistics using it as the basis.
In this case, the optimal BP will be the one that maximizes the posterior; therefore,
we continue the development of the linear ilter by deriving the Bayesian maximum
a posteriori (MAP) estimator.

156
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
Starting with the MAP equation of Eq. 2.3 and taking natural logarithms of each
side gives
ln Pr(x(t)|Yt) = ln Pr(y(t)|x(t)) + ln Pr(x(t)|Yt−1) −ln Pr(y(t)|Yt−1)
In terms of multivariate Gaussian, the posterior is given by
ln Pr(x(t)|Yt) = ln �−1
2�′(t)R−1
��(t)�(t) −1
2 ̃x′(t|t −1)̃P−1(t|t −1)̃x(t|t −1)
+ 1
2e′(t)R−1
ee (t)e(t)
(5.8)
with
̃x(t|t −1) = x(t) −̂x(t|t −1)
[State error]
e(t) = y(t) −C(t)̂x(t|t −1) = C(t)̃x(t|t −1) + �(t)
[Innovation]
The MAP estimate is then obtained by differentiating Eq. 5.8, setting it to zero
and solving, that is,
∇x ln Pr(x(t)|Yt)|||x= ̂Xmap = 0
(5.9)
Using the chain rule of the gradient operator (see Eq. 2.11), we obtain the following
expression. Note that the last term of Eq. 5.8 is not a function of x(t), but just the
data; therefore, its gradient is null.
∇x ln Pr(x(t)|Yt) = C′(t)R−1
��(t)[y(t) −C(t)x(t)] −̃P−1(t|t −1)̃x(t|t −1)
(5.10)
Setting Eq. 5.10 to zero and solving for x(t) gives the Bayesian MAP estimate
̂Xmap(t) = [C′(t)R−1
��(t)C(t) + ̃P−1(t|t −1)]−1
× [̃P−1(t|t −1)̂x(t|t −1) + C′(t)R−1
��(t)y(t)]
(5.11)
This relation can be simpliied by using a form of the matrix inversion lemma [1]
deined by the following equation
(A + BD′)−1 = A−1 −A−1B(I + D′A−1B)−1)D′A−1
(5.12)
Deining the following terms for the lemma, A = ̃P−1(t|t −1), B = C′(t)R−1
��(t)
and setting D′ = C(t), we ind that
[̃P−1(t|t −1) + C′(t)R−1
��(t)C(t)]−1
= ̃P(t|t −1) −̃P(t|t −1)C′(t)R−1
��(t)(I + C(t)̃P(t|t −1)C′(t)R−1
��(t))−1
× C(t)̃P(t|t −1)
(5.13)

5.3
LINEAR BAYESIAN PROCESSOR (LINEAR KALMAN FILTER)
157
Making the observation that the term in parenthesis on the right-hand side of Eq. 5.13
can be rewritten by factoring out R−1
��(t) as
(I + C(t)̃P(t|t −1)C′(t)R−1
��(t))−1 = R��(t)(R��(t) + C(t)̃P(t|t −1)C′(t))−1
(5.14)
then Eq. 5.13 can also be expressed as
[̃P−1(t|t −1) + C′(t)R−1
��(t)C(t)]−1
= ̃P(t|t −1) −̃P(t|t −1)C′(t)(R��(t) + C(t)̃P(t|t −1)C′(t))−1C(t)̃P(t|t −1)
(5.15)
The innovations covariance can be expressed as
Ree(t) = Cov(e(t)) = C(t)̃P(t|t −1)C′(t) + R��(t)
and substituting, Eq. 5.15 becomes
[̃P−1(t|t −1) + C′(t)R−1
��(t)C(t)]−1
= ̃P(t|t −1) −̃P(t|t −1)C′(t)R−1
ee (t)C(t)̃P(t|t −1) = (I −K(t)C(t))̃P(t|t −1)
(5.16)
where K(t) = ̃P(t|t −1)C′(t)R−1
ee (t) is the gain. We see that Eq. 5.16 is simply the
updated error covariance ̃P(t|t) equivalent to
̃P(t|t) ≡[̃P−1(t|t −1) + C′(t)R−1
��(t)C(t)]−1
(5.17)
Thus we can eliminate the irst bracketed term in Eq. 5.11 to give
̂Xmap(t) = ̃P(t|t) × [̃P−1(t|t −1)̂x(t|t −1) + C′(t)R−1
��(t)y(t)]
Solving Eq. 5.17 for ̃P(t|t −1), we can substitute the result into the above equation
to give
̂Xmap(t) = ̃P(t|t) × [(̃P−1(t|t) −C′(t)R−1
��(t)C(t))̂x(t|t −1) + C′(t)R−1
��(t)y(t)] (5.18)
Multiplying out, regrouping terms and factoring, this relation can be rewritten as
̂Xmap(t) = ̂x(t|t −1) + (̃P(t|t)C′(t)R−1
��(t))[y(t) −C(t)̂x(t|t −1)]
(5.19)
or inally
̂Xmap(t) = ̂x(t|t) = ̂x(t|t −1) + K(t)e(t)
(5.20)

158
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
Now we only need to show the equivalence of the gain expression using the updated
instead of predicted error covariance, that is,
K(t) = ̃P(t|t −1)C′(t)R−1
ee (t) = ̃P(t|t)̃P−1(t|t)(̃P(t|t −1)C′(t)R−1
ee (t))
= ̃P(t|t)[C′(t)R−1
��(t)C(t) + ̃P−1(t|t −1)]̃P(t|t −1)C′(t)R−1
ee (t)
= ̃P(t|t)C′(t)R−1
��(t)[C(t)̃P(t|t −1)C′(t) + R��(t)]R−1
ee (t)
(5.21)
which gives the desired result from the deinition of innovations covariance. We now
have two equivalent expressions in terms of the updated or predicted error covariances
that can be used to calculate the gain
K(t) = ̃P(t|t)C′(t)R−1
��(t) ≡̃P(t|t −1)C′(t)R−1
ee (t)
(5.22)
which completes the Bayes’ approach to signal enhancement or equivalently state
estimation problem yielding the optimum linear BP (Kalman ilter). A summary of
the linear BP algorithm is shown in Table 5.1.
The design of linear BPs under the Gauss–Markov assumptions is well-understood
[1–9]. Based on a variety of properties both theoretically well-founded and pragmat-
ically applied with high success, the minimum (error) variance design procedure has
evolved [10–14]. We summarize the design-steps below and subsequently using the
notation of the BP algorithm in Table 5.1.
It is important to realize that a necessary and suficient condition that the linear
BP (under the Gauss-Markov (GM) constraints) is optimal is that the innovation
sequence is zero-mean and white or uncorrelated! This is the irst and most important
step in BP design. If this condition does not hold, then the underlying model and
GM assumptions are invalid. Therefore, we briely mention the minimum variance
TABLE 5.1
Linear BP (Kalman Filter) Algorithm
Prediction
̂x(t|t −1) = A(t −1)̂x(t −1|t −1) + B(t −1)u(t −1)
[State prediction]
̃P(t|t −1) = A(t −1)̃P(t −1|t −1)A′(t −1) + R��(t −1)
[Covariance prediction]
Innovation
e(t) = y(t) −̂y(t|t −1) = y(t) −C(t)̂x(t|t −1)
[Innovation]
Ree(t) = C(t)̃P(t|t −1)C′(t) + R��(t)
[Innovation covariance]
Gain
K(t) = ̃P(t|t −1)C′(t)R−1
ee (t)
[Gain or weight]
Update
̂x(t|t) = ̂x(t|t −1) + K(t)e(t)
[State update]
̃P(t|t) = [I −K(t)C(t)]̃P(t|t −1)
[Covariance update]
Initial Conditions
̂x(0|0)
̃P(0|0)

5.3
LINEAR BAYESIAN PROCESSOR (LINEAR KALMAN FILTER)
159
design procedure here and provide more details in Section 5.7 where pragmatic
statistical tests are developed. We will apply the procedure to the following processors
(linear and nonlinear) in the example problems and then provide the design details
subsequently.
The minimum (error) variance design procedure is
1. Check that the innovations sequence is zero-mean.
2. Check that the innovations sequence is white.
3. Check that the innovations sequence is uncorrelated in time with input u.
4. Check that the innovations sequence lies within the conidence limits con-
structed from Ree predicted by the BP.
5. Check that the innovations sequence variance is reasonably close to the esti-
mated (sample) variance ̂Ree.
6. Check that the state estimation error ̃x(t|t) lies within the conidence limits
constructed from ̃P(t|t) predicted by the BP.
7. Check that the state error variance is reasonably close to the estimated (sample)
variance ̂̃P(t|t).
This is the basic “cookbook” approach to linear BP design. Before we close this
section, let us consider a simple linear example to demonstrate the ideas.
Example 5.1
Suppose we have the RC circuit as shown in Fig. 5.2. We measure the voltage across
the capacitor with a high-impedance voltmeter as shown. Since these measurements
are noisy and the component values are imprecise (±△), we require an improved
estimate of the output voltage. We develop a BP to solve this problem from irst
Volts
Uncertainty
∑
Eout
Ein
C
R
FIGURE 5.2
RC-circuit problem diagram.

160
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
principles—a typical approach. Writing the Kirchoff’s current equations at the node,
we have
Iin(t) −e(t)
R −Cde(t)
dt
= 0
where eo is the initial voltage, R the resistance, and C the capacitance. The measure-
ment equation for a voltmeter of gain Ke is simply
eout(t) = Kee(t)
We choose to use the discrete BP formulation; therefore, approximating the deriva-
tives with irst differences and substituting, we have
Ce(t) −e(t −1)
△T
= −e(t −1)
R
+ Iin(t −1)
or
e(t) =
(
1 −△T
RC
)
e(t −1) + △T
C Iin(t −1)
where the measurement is given above. Suppose that for this circuit the parameters are:
R = 3.3 kΩ and C = 1000 �F, △T = 100 ms, eo = 2.5 V, Ke = 2.0, and the voltmeter
is precise to within ±4 V. Then, transforming the physical circuit model into state–
space form by deining x = e, y = eout, and u = Iin, we obtain
x(t) = 0.97x(t −1) + 100u(t −1) + �(t −1)
y(t) = 2x(t) + �(t)
The process noise covariance is used to model the circuit parameter uncertainty
with R��= 0.0001, since we assume standard deviations, △R, △C of 1%. Also,
R��= 4, since two standard deviations are △V = 2( 1
2 4V). We also assume initially
that the state is x(0) ∼(2.5, 10−12), and that the input current is a step function
of u(t) = 300 �A. SSPACK PC is used to simulate this system [8]. The results are
shown in Fig. 5.3. The simulated and true (mean) states (voltages) are shown in
Fig. 5.3a along with the corresponding conidence limits. We see that the process
samples (state and process noise) lie within the bounds (3.5% out). Therefore, the
data statistically satisfy the underlying Gauss–Markov model assumptions. If it does
not, then choose another simulation. That is, we perform another realization (different
seed in random number generator) until the samples lie within the bounds. Similarly,
the simulated and true (mean) measured voltages are shown in Fig. 5.3b. Again the
data (measurement and noise) statistically satisfy the underlying models with only
4.5% of the samples exceeding the prescribed bounds. The state and measurement
variances used to construct the conidence intervals about the means, that is, [mx(t) ±
1.96
√
P(t)] and [my(t) ± 1.96√Ryy(t)], are shown in Fig. 5.3c.

5.3
LINEAR BAYESIAN PROCESSOR (LINEAR KALMAN FILTER)
161
(a)
(b)
(c)
FIGURE 5.3
RC circuit problem Gauss–Markov simulation: (a) simulated and true
(mean) output voltage; (b) simulated and true (mean) measurement; (c) simulated
state and measurement variances.
With the data simulated, we now consider the design of the BP. In the ideal BP
problem, we are given the model set Σ := {A, B, C, R��, R��, x(0), P(0)}, the known
input {u(t)}, and the set of noisy measurements {y(t)} to construct the processor. The
RC model-based processor for this problem can simply be written as
̂x(t|t −1) = 0.97̂x(t −1|t −1)) + 100u(t −1)
[Predicted state]
̃P(t|t −1) = 0.94̃P(t −1|t −1) + 0.0001
[Predicted covariance]
e(t) = y(t) −2̂x(t|t −1)
[Innovation]
Ree(t) = 4̃P(t|t −1) + 4
[Innovations covariance]

162
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
K(t) = 2
̃P(t|t −1)
4̃P(t|t −1) + 4
[Gain]
̂x(t|t) = ̂x(t|t −1) + K(t)e(t)
[Updated state]
̃P(t|t) =
̃P(t|t −1)
̃P(t|t −1) + 1
[Updated covariance]
The estimator is also designed using SSPACK PC and the results are shown in
Fig. 5.4. In Fig. 5.4a, we see the estimated state (voltage) and estimation error as
well as the corresponding conidence bounds. Note that the processor “optimally”
estimates the voltage, since our models are exact. That is, it provides the minimum
error variance estimate in the Gaussian case. Also since we have the true (mean) state,
we can calculate the estimation error and use the corresponding error covariance to
specify the bounds as shown. Note that the error is small and no samples exceed
the bound as indicated by the overestimation of the variance compared with the
sample variance (0.0017 > 0.0002). In Fig. 5.4b, we see the iltered measurement
(̂y(t|t −1)) and corresponding innovation sequence along with the conidence limits
provided by the processor. Here only 4.5% of the samples exceed the bounds and the
variance predicted by the ilter is close to the sample variance estimate (4.0 ∼3.7).
The weighted sum-squared residual (WSSR) statistic, zero-mean, and whiteness tests
are shown in Fig. 5.4c. Here we see that using a window of 75 samples, the threshold
is not exceeded, indicating a statistically white sequence. The innovation mean is
small and well within the bound (0.11 < 0.27). The sequence is statistically white,
since 0% of the normalized sample covariances exceed the bound. Finally, we see the
gain and updated error covariance as monotonically decreasing functions that reach
a steady-state (constant) value at approximately 8 sec. This completes the example
of an ideally “tuned” BP.
△△△
5.4
LINEARIZED BAYESIAN PROCESSOR (LINEARIZED KALMAN FILTER)
In this section, we develop an approximate solution to the nonlinear processing
problem involving the linearization of the nonlinear process about a “known” ref-
erence trajectory followed by the development of a BP based on the underly-
ing linearized state–space model. Many processes in practice are nonlinear rather
than linear. Coupling the nonlinearities with noisy data makes the signal process-
ing problem a challenging one. In this section, we limit our discussion to dis-
crete nonlinear systems. Continuous solutions to this problem are developed in
Refs. [1–7].
Recall from the previous chapter that our process is characterized by a set of
nonlinear stochastic vector difference equations in state–space form as
x(t) = a[x(t −1)] + b[u(t −1)] + �(t −1)
(5.23)

5.4
LINEARIZED BAYESIAN PROCESSOR (LINEARIZED KALMAN FILTER)
163
(a)
(b)
(c)
(d)
FIGURE 5.4
BP design for RC circuit problem: (a) estimated state (voltage) and
error; (b) iltered voltage measurement and error (innovations); (c) WSSR and zero-
mean/whiteness tests; (d) gain and updated error covariance.

164
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
with the corresponding measurement model
y(t) = c[x(t)] + �(t)
(5.24)
where a[⋅], b[⋅], c[⋅] are nonlinear vector functions of x, u, with x, a, b, �∈RNx×1,
y, c, �∈RNy×1 and �∼(0, R��(t)), �∼(0, R��(t)).
In Chapter 4, we linearized a deterministic nonlinear model using a irst-order
Taylor series expansion for the functions, a, b, and c, and developed a linearized
Gauss–Markov perturbation model valid for small deviations given by
�x(t) = A[x∗(t −1)]�x(t −1) + B[u∗(t −1)]�u(t −1) + �(t −1)
�y(t) = C[x∗(t)]�x(t) + �(t)
(5.25)
where A, B, and C are the corresponding Jacobian matrices, and �, �are zero-mean,
Gaussian.
We used linearization techniques to approximate the statistics of Eqs. 5.23 and
5.24 and summarized these results in an “approximate” Gauss–Markov model of
Table 4.3. Using this perturbation model, we will now incorporate it to construct a
BP that embeds the (A[⋅], B[⋅], C[⋅]) Jacobians linearized about the reference trajec-
tory [x∗, u∗]. Each of the Jacobians are deterministic and time-varying, since they are
updated at each time-step. Replacing the (A, B) matrices and ̂x(t|t −1) in Table 5.1,
respectively, by the Jacobians and �̂x(t|t −1), we obtain the state perturbation pre-
dicted estimate
�̂x(t|t −1) = A[x∗(t −1)]�̂x(t −1|t −1) + B[u∗(t −1)]�u(t −1)
(5.26)
For the Bayesian estimation problem, we are interested in the state estimate ̂x(t|t −1)
and not its deviation �̂x(t|t −1). From the deinition of the perturbation in Section
4.8, we have
̂x(t|t −1) = �̂x(t|t −1) + x∗(t)
(5.27)
where the reference trajectory x∗(t) was deined previously as
x∗(t) = a[x∗(t −1)] + b[u∗(t −1)]
(5.28)
Substituting this relation and Eq. 5.26 in Eq. 5.27 gives
̂x(t|t −1) = a[x∗(t −1)] + A[x∗(t −1)][̂x(t −1|t −1) −x∗(t −1)]
+ b[u∗(t −1)] + B[u∗(t −1)][u(t −1) −u∗(t −1)]
(5.29)
The corresponding perturbed innovation can also be found directly
�e(t) = �y(t) −�̂y(t|t −1) = (y(t) −y∗(t)) −(̂y(t|t −1) −y∗(t))
= y(t) −̂y(t|t −1) = e(t)
(5.30)

5.4
LINEARIZED BAYESIAN PROCESSOR (LINEARIZED KALMAN FILTER)
165
Using the linear BP with deterministic Jacobian matrices results in
�̂y(t|t −1) = C[x∗(t)]�̂x(t|t −1)
(5.31)
and therefore using this relation and Eq. 4.142 for the reference measurement, we
have
̂y(t|t −1) = y∗(t) + C[x∗(t)]�̂x(t|t −1) = c[x∗(t)] + C[x∗(t)]�̂x(t|t −1)
(5.32)
Therefore, it follows that the innovation is
e(t) = y(t) −c[x∗(t)] −C[x∗(t)][̂x(t|t −1) −x∗(t)]
(5.33)
The updated estimate is easily found by substituting Eq. 5.27 to obtain
�̂x(t|t) = �̂x(t|t −1) + K(t)e(t)
[̂x(t|t) −x∗(t)] = [̂x(t|t −1) −x∗(t)] + K(t)e(t)
(5.34)
which yields the identical update equation of Table 5.1. Since the state perturbation
estimation error is identical to the state estimation error, the corresponding error
covariance is given by �̃P(t|⋅) = ̃P(t|⋅) and therefore,
�̃x(t|⋅) = �x(t) −�̂x(t|⋅) = [x(t) −x∗(t)] −[̂x(t|⋅) −x∗(t)] = x(t) −̂x(t|⋅)
(5.35)
The gain is just a function of the measurement linearization, C[x∗(t)] completing the
algorithm. We summarize the discrete LZ-BP (Kalman ilter) in Table 5.2.
In a more formal framework, the LZ-BP can be developed under (approximate)
Gaussian assumptions using the Bayesian approach as before in the linear case. We
briely outline the derivation by carefully following the steps in Section 5.3.
The a posteriori probability is given by
Pr(x(t)|Yt) = Pr(y(t)|x(t)) × Pr(x(t)|Yt−1)
Pr(y(t)|Yt−1)
(5.36)
Under the Gauss–Markov model assumptions, we know that each of the condi-
tional expectations can be expressed in terms of the conditional Gaussian distributions
as:
1. Pr(y(t)|x(t)):
(c[x(t)], R��(t))
2. Pr(x(t)|Yt−1):
(̂x(t|t −1), ̃P(t|t −1))
3. Pr(y(t)|Yt−1):
(̂y(t|t −1), Ree(t))
Using the nonlinear models developed earlier, substituting the Gaussian prob-
abilities and taking logarithms, we obtain the logarithmic a posteriori probability

166
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
TABLE 5.2
Linearized BP (Kalman Filter) Algorithm
Prediction
̂x(t|t −1) = a[x∗(t −1)] + A[x∗(t −1)][̂x(t −1|t −1) −x∗(t −1)]
+ b[u∗(t −1)] + B[u∗(t −1)][u(t −1) −u∗(t −1)]
[State prediction]
̃P(t|t −1) = A[x∗(t −1)]̃P(t −1|t −1)A′[x∗(t −1)] + R��(t −1)
[Covariance prediction]
Innovation
e(t) = y(t) −c[x∗(t)] −C[x∗(t)][̂x(t|t −1) −x∗(t)]
[Innovation]
Ree(t) = C[x∗(t)]̃P(t|t −1)C′[x∗(t)] + R��(t)
[Innovation covariance]
Gain
K(t) = ̃P(t|t −1)C′[x∗(t)]R−1
ee (t)
[Gain or weight]
Update
̂x(t|t) = ̂x(t|t −1) + K(t)e(t)
[State update]
̃P(t|t) = [I −K(t)C[x∗(t)]]̃P(t|t −1)
[Covariance update]
Initial Conditions
̂x(0|0)
̃P(0|0)
Jacobians
A[x∗(t −1)] ≡da[x(t−1)]
dx(t−1)
|||x=x∗(t−1) B[u∗(t −1)] ≡db[u(t−1)]
du(t−1)
|||u=u∗(t−1)
C[x∗(t)] ≡dc[x(t)]
dx(t)
|||x=x∗(t)
as
ln Pr(x(t)|Yt) = ln �−1
2�′(t)R−1
��(t)�(t) −1
2 ̃x′(t|t −1)̃P−1(t|t −1)̃x(t|t −1)
+ 1
2e′(t)R−1
ee (t)e(t)
(5.37)
The MAP estimate is then obtained by differentiating this equation, setting the
result to zero and solving for x(t), that is,
∇x ln Pr(x(t)|Yt)|x= ̂Xmap = 0
(5.38)
Before we attempt to derive the MAP estimate, we irst linearize about a reference
trajectory, x∗→x with the nonlinear measurement model approximated by a irst-
order Taylor series
c[x(t)] ≈c[x∗(t)] + dc[x∗(t)]
dx∗(t) �x(t) = c[x∗(t)] + C[x∗(t)](x(t) −x∗(t))
Substituting this result into Eq. 5.37, we obtain
ln Pr(x(t)|Yt) = ln �−1
2(y(t) −c[x∗(t)] −C[x∗(t)](x(t) −x∗(t)))′R−1
��(t)

5.4
LINEARIZED BAYESIAN PROCESSOR (LINEARIZED KALMAN FILTER)
167
× (y(t) −c[x∗(t)] −C[x∗(t)](x(t) −x∗(t))) −1
2 ̃x′(t|t −1)̃P−1(t|t −1)̃x(t|t −1)
+ 1
2(y(t) −̂y(t|t −1))′R−1
ee (t)(y(t) −̂y(t|t −1))
(5.39)
Applying the chain rule and the gradient operator (see Chapter 3), we obtain the
following expression. Note that the last term of Eq. 5.39 is not a function of x(t), but
just the data, so it is null.
∇x ln Pr(x(t)|Yt) = −C′[x∗(t)]R−1
��(t)(y(t) −c[x∗(t)] −C[x∗(t)](x(t) −x∗(t)))
−̃P−1(t|t −1)[x(t) −̂x(t|t −1)] = 0
(5.40)
Multiplying through and grouping like terms in x(t) gives
C′[x∗(t)]R−1
��(t)(y(t) −c[x∗(t)] + C[x∗(t)]x∗(t))
−[̃P−1(t|t −1) + C′[x∗(t)]R−1
��(t)C[x∗(t)]]x(t) + ̃P−1(t|t −1)̂x(t|t −1) = 0
(5.41)
Solving for x(t) = ̂Xmap(t) gives
̂Xmap(t) = [̃P−1(t|t −1) + C′[x∗(t)]R−1
��(t)C[x∗(t)]]−1
× [̃P−1(t|t −1)̂x(t|t −1) + C′[x∗(t)]R−1
��(t)
× (y(t) −c[x∗(t)] + C[x∗(t)]x∗(t))]
(5.42)
Using the matrix inversion manipulations of Eqs. 5.12–5.17 with C(t) ⟶
C[x∗(t)], the irst term in Eq. 5.42 becomes
[̃P−1(t|t −1) + C′[x∗(t)]R−1
��(t)C[x∗(t)]]−1
= (I −̃P(t|t −1)C′[x∗(t)]R−1
ee (t)C[x∗(t)])̃P−1(t|t −1)
= (I −K(t)C[x∗(t)])̃P(t|t −1) ≡̃P(t|t)
(5.43)
where K is the Kalman gain, Ree is the innovations covariance of the LZ-BP with this
expression precisely the updated error covariance ̃P(t|t) as in Table 5.2.
Solving this equation for the inverse of the predicted error covariance gives
̃P−1(t|t −1) = ̃P−1(t|t) −C′[x∗(t)]R−1
��(t)C[x∗(t)]
(5.44)
and substituting into Eq. 5.42 using the results of Eq. 5.43 yields
̂Xmap(t) = ̃P(t|t)[(̃P−1(t|t)̂x(t|t −1) −C′[x∗(t)]R−1
��(t)C[x∗(t)]̂x(t|t −1))
+ C′[x∗(t)]R−1
��(t)(y(t) −c[x∗(t)] + C[x∗(t)]x∗(t))]
(5.45)

168
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
Multiplying through by the updated error covariance and recognizing the expression
for the Kalman gain gives
̂Xmap(t) = ̂x(t|t −1) −K(t)C[x∗(t)]̂x(t|t −1) + K(t)C[x∗(t)]x∗(t)
+ K(t)(y(t) −c[x∗(t)])
(5.46)
which leads to the inal expression for the linearized MAP estimate as
̂Xmap(t) = ̂x(t|t) = ̂x(t|t −1) + K(t)(y(t) −c[x∗(t)] −C[x∗(t)](̂x(t|t −1) −x∗(t))
(5.47)
Compare this result to Table 5.1. The error covariances and predicted estimates follow
as in the linear case. This completes the derivation. Next let us consider a discrete
version of the nonlinear system example given in Jazwinski [1].
Example 5.2
Consider the discrete nonlinear process given by
x(t) = (1 −0.05ΔT)x(t −1) + 0.04ΔTx2(t −1) + �(t −1)
with corresponding measurement model
y(t) = x2(t) + x3(t) + �(t)
where �(t) ∼(0, 0.09), x(0) = 2.3, P(0) = 0.01, ΔT = 0.01 sec, and R��= 0. The
simulated measurement using SSPACK PC [8] is shown in Fig. 5.5c. The LZ-BP is
designed from the following Jacobians:
A[x(t −1)] = 1 −0.05ΔT + 0.08ΔTx(t −1)
and
C[x(t)] = 2x(t) + 3x2(t)
Observing the mean state, we develop a reference trajectory by itting a line to the
simulated state which is given by
x∗(t) = 0.067t + 2.0
0 ≤t ≤1.5 and u∗(t) = u(t) = 0.0 ∀t
The LZ-BP algorithm is then given by
̂x(t|t −1) = (1 −0.05ΔT)x∗(t −1)
+ (1 −0.05ΔT + 0.08ΔTx∗(t −1))[̂x(t −1|t −1) −x∗(t −1)]
̃P(t|t −1) = [1 −0.05ΔT + 0.08ΔTx∗(t −1)]2 ̃P(t −1|t −1)
e(t) = y(t) −(x∗2(t) −x∗3(t)) −(2x∗(t) + 3x∗2(t))[̂x(t|t −1) −x∗(t)]
Ree(t) = [2̂x(t|t −1) + 3̂x2(t|t −1)]2 ̃P(t|t −1) + 0.09

5.4
LINEARIZED BAYESIAN PROCESSOR (LINEARIZED KALMAN FILTER)
169
0
0.5
1
1.5
1.95
2
2.05
2.1
Time (s)
0
0.5
1
1.5
Time (s)
0
0.5
1
1.5
Time (s)
x
−0.04
−0.02
0
0.02
0.04
x
0
0.5
1
1.5
11.5
12
12.5
13
13.5
14
14.5
Time (s)
0
0.5
1
1.5
Time (s)
y
−2
−1
0
1
2
e
11.5
12
12.5
13
13.5
14
14.5
y
0
0.2
0.4
0.6
0.8
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Ree
Lag time (s)
(a)
(b)
(c)
^
^
^
~
FIGURE 5.5
Linearized BP simulation: (a) estimated state (0% out) and error (0% out);
(b) iltered measurement (1% out) and error (innovation) (2.6% out);(c) simulated mea-
surement and zero-mean/whiteness test (3.9 × 10 −�<10.1 × 10−�and 0% out).
K(t) =
̃P(t|t −1)[2x∗(t) + 3x∗2(t)]
Ree(t)
̂x(t|t) = ̂x(t|t −1) + K(t)e(t)
̃P(t|t) = (1 −K(t)[2x∗(t) + 3x∗2(t)])̃P(t|t −1)
̂x(0|0) = 2.3
and
̃P(0|0) = 0.01
A LZ-BP run is depicted in Fig. 5.5. Here we see that the state estimate begins
tracking the true state after the initial transient. The estimation error is good (0%
lie outside conidence limits) indicating the ilter is performing properly for this
realization. The iltered measurement and innovations are shown in Fig. 5.5b with
their corresponding predicted conidence limits. Both estimates lie well within
these bounds. The innovations are zero-mean (3.9 × 10−2 < 10.1 × 10−2) and white

170
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
(0% lie outside limits) as shown in Fig. 5.5c indicating proper tuning. This completes
the nonlinear iltering example.
△△△
5.5
EXTENDED BAYESIAN PROCESSOR (EXTENDED KALMAN FILTER)
In this section, we develop the extended Bayesian processor (XBP) or equivalently
the extended Kalman ilter (EKF). The XBP is ad hoc in nature, but has become one of
the workhorses of (approximate) nonlinear iltering [1–11]. It has found applicability
in a wide variety of applications such as tracking [15], navigation [1, 5], chemical
processing [17], ocean acoustics [18], and seismology [19] (see Ref. [20] for a
detailed list). The XBP evolves directly from the linearized processor of the previous
section in which the reference state x∗(t) used in the linearization process is replaced
with the most recently available state estimate ̂x(t|t)—this is the step that makes the
processor ad hoc. We must realize that the Jacobians used in the linearization process
are deterministic (but time-varying), when a reference or perturbation trajectory is
used. However, using the current state estimate is an approximation to the conditional
mean, which is random, making these associated Jacobians and subsequent relations
random. Therefore, although popularly ignored, most XBP designs should be based
on ensemble operations to obtain reasonable estimates of the underlying statistics.
With this in mind, we develop the processor directly from the LZ-BP. Thus, if instead
of using the reference trajectory, we choose to linearize about each new state estimate
as soon as it becomes available, then the XBP algorithm results. The reason for
choosing to linearize about this estimate is that it represents the best information we
have about the state and therefore most likely results in a better reference trajectory
(state estimate). As a consequence, large initial estimation errors do not propagate;
therefore, linearity assumptions are less likely to be violated. Thus, if we choose to
use the current estimate ̂x(t|�), where �is t −1 or t, to linearize about instead of the
reference trajectory x∗(t), then the XBP evolves. That is, let
x∗(t) ≡̂x(t|�)
for t −1 ≤�≤t
(5.48)
Then, for instance, when �= t −1, the predicted perturbation is
�̂x(t|t −1) = ̂x(t|t −1) −x∗(t)|x∗=̂x(t|t−1) = 0
(5.49)
Thus, it follows immediately that when x∗(t) = ̂x(t|t), then �̂x(t|t) = 0 as well.
Substituting the current estimate, either prediction or update into the LZ-BP algo-
rithm, it is easy to see that each of the difference terms [̂x −x∗] are null-resulting in the
XBP algorithm. That is, examining the prediction phase of the linearized algorithm,
substituting the current available updated estimate ̂x(t −1|t −1) for the reference and
using the fact that (u∗(t) = u(t)∀t), we have
̂x(t|t −1) = a[̂x(t −1|t −1)] + A[̂x(t −1|t −1)][̂x(t −1|t −1) −̂x(t −1|t −1)]
+ b[u(t −1)] + B[u(t −1)][u(t −1) −u(t −1)]

5.5
EXTENDED BAYESIAN PROCESSOR (EXTENDED KALMAN FILTER)
171
giving the prediction of the XBP
̂x(t|t −1) = a[̂x(t −1|t −1)] + b[u(t −1)]
(5.50)
Now with the predicted estimate available, substituting it for the reference in Eq. 5.33,
gives the innovation sequence as
e(t) = y(t) −c[̂x(t|t −1)] −C[̂x(t|t −1)]
× [̂x(t|t −1) −̂x(t|t −1)] = y(t) −c[̂x(t|t −1)]
(5.51)
where we have the new predicted or iltered measurement expression
̂y(t|t −1) ≡c[̂x(t|t −1)]
(5.52)
The updated state estimate is easily obtained by substituting the predicted estimate
for the reference (̂x(t|t −1) →x∗(t)) in Eq. 5.34
�̂x(t|t) = �̂x(t|t −1) + K(t)e(t)
[̂x(t|t) −̂x(t|t −1)] = [̂x(t|t −1) −̂x(t|t −1)] + K(t)e(t)
̂x(t|t) = ̂x(t|t −1) + K(t)e(t)
(5.53)
The covariance and gain equations are identical to those in Table 5.2, but with
the Jacobian matrices A, B, and C linearized about the predicted state estimate,
̂x(t|t −1). Thus, we obtain the discrete XBP or equivalently the EKF algorithm
summarized in Table 5.3. Note that the covariance matrices ̃P and the gain K are now
functions of the current state estimate, which is the approximate conditional mean
estimate, and therefore a single realization of a stochastic process. Thus, ensemble
(Monte Carlo) techniques should be used to evaluate estimator performance, that is,
for new initial conditions selected by a Gaussian random number generator (either
̂x(0|0) or ̃P(0|0)), the algorithm is executed generating a set of estimates which
should be averaged over the entire ensemble using this approach to get an “expected”
state, etc. Note also in practice that this algorithm is usually implemented using
sequential processing and UD (upper diagonal/square root) factorization techniques
(see Ref. [21]).
The XBP can also be developed under (approximate) Gaussian assumptions using
the Bayesian approach as before in the linear case. We briely outline the derivation.
The a posteriori probability is given by
Pr(x(t)|Yt) = Pr(y(t)|x(t)) × Pr(x(t)|Yt−1)
Pr(y(t)|Yt−1)
(5.54)

172
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
TABLE 5.3
Extended BP (Kalman Filter) Algorithm
Prediction
̂x(t|t −1) = a[̂x(t −1|t −1)] + b[u(t −1)]
[State prediction]
̃P(t|t −1) = A[̂x(t|t −1)]̃P(t −1|t −1)A′[̂x(t|t −1)] + R��(t −1)
[Covariance prediction]
Innovation
e(t) = y(t) −c[̂x(t|t −1)]
[Innovation]
Ree(t) = C[̂x(t|t −1)]̃P(t|t −1)C′[̂x(t|t −1)] + R��(t)
[Innovation covariance]
Gain
K(t) = ̃P(t|t −1)C′[̂x(t|t −1)]R−1
ee (t)
[Gain or weight]
Update
̂x(t|t) = ̂x(t|t −1) + K(t)e(t)
[State update]
̃P(t|t) = [I −K(t)C[̂x(t|t −1)]]̃P(t|t −1)
[Covariance update]
Initial Conditions
̂x(0|0)
̃P(0|0)
Jacobians
A[x(t|t −1)] ≡da[x(t−1)]
d̂x(t−1)
|||x=̂x(t|t−1)
C[̂x(t|t −1)] ≡dc[x(t)]
dx(t)
|||x=̂x(t|t−1)
Under the Gauss–Markov model assumptions, we know that each of the condi-
tional expectations can be expressed in terms of the conditional Gaussian distributions
as:
1. Pr(y(t)|x(t)):
(c[x(t)], R��(t))
2. Pr(x(t)|Yt−1):
(̂x(t|t −1), ̃P(t|t −1))
3. Pr(y(t)|Yt−1):
(̂y(t|t −1), Ree(t))
Using the nonlinear models developed earlier, substituting the Gaussian prob-
abilities and taking logarithms, we obtain the logarithmic a posteriori probability
as
ln Pr(x(t)|Yt) = ln �−1
2�′(t)R−1
��(t)�(t) −1
2 ̃x′(t|t −1)̃P−1(t|t −1)̃x(t|t −1)
+ 1
2e′(t)R−1
ee (t)e(t)
(5.55)
The MAP estimate is then obtained by differentiating Eq. 5.55, setting it to zero
and solving; that is,
∇x ln Pr(x(t)|Yt)|x= ̂Xmap = 0
(5.56)
Applying the chain rule and the gradient operation (see Chapter 3), we obtain
the expression. Note that the last term of Eq. 5.55 is not a function of x(t),

5.5
EXTENDED BAYESIAN PROCESSOR (EXTENDED KALMAN FILTER)
173
but just the data.
∇x ln Pr(x(t)|Yt) = ∇xc′[x(t)]R−1
��(t)(y(t) −c[x(t)])
−̃P−1(t|t −1)(x(t) −̂x(t|t −1))
(5.57)
Using a irst-order Taylor series approximation for c[x(t)] linearized about the
predicted estimate ̂x(t|t −1) and the usual deinition for the Jacobian matrix C[̂x(t|t −
1)], we have
∇x ln Pr(x(t)|Yt) = C′[̂x(t|t −1)]R−1
��(t)[y(t) −c[̂x(t|t −1)]
−C[̂x(t|t −1)](x(t) −̂x(t|t −1))] −̃P−1(t|t −1)[x(t) −̂x(t|t −1)]
(5.58)
Identifying the innovation vector and grouping like-terms gives the expression
∇x ln Pr(x(t)|Yt) = C′[̂x(t|t −1)]R−1
��(t)e(t)
−[C′[̂x(t|t −1)] R−1
��(t) C[̂x(t|t −1)] + ̃P(t|t −1)] x(t)
+ [C′[̂x(t|t −1)] R−1
��(t) C[̂x(t|t −1)] + ̃P(t|t −1)] ̂x(t|t −1)
Setting this equation to zero and solving for x(t) = ̂Xmap(t) gives
̂Xmap(t) = [C′[̂x(t|t −1)]R−1
��(t)C[̂x(t|t −1)] + ̃P(t|t −1)]−1
× [C′[̂x(t|t −1)]R−1
��(t)C[̂x(t|t −1)] + ̃P(t|t −1)] ̂x(t|t −1)
+ [C′[̂x(t|t −1)]R−1
��(t)C[̂x(t|t −1)]
+ ̃P(t|t −1)]−1C′[̂x(t|t −1)]R−1
��(t)e(t)
(5.59)
or
̂Xmap(t) = ̂x(t|t −1) + [C′[̂x(t|t −1)]R−1
��(t)C[̂x(t|t −1)]
+ ̃P(t|t −1)]−1C′[̂x(t|t −1)]R−1
��(t)e(t)
(5.60)
Recognizing the similarity of this expression to the linear case with C[̂x(t|t −1)] →
C(t) and using the matrix inversion lemma, it is easy to show (see Eqns. 5.13–5.17)
that our approximate updated error covariance satisies
̃P(t|t) = [C′[̂x(t|t −1)]R−1
��(t)C[̂x(t|t −1)] + ̃P−1(t|t −1)]−1
(5.61)

174
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
and therefore Eq. 5.60 can be simpliied to give
̂Xmap(t) = ̂x(t|t −1) + ̃P(t|t)C′[̂x(t|t −1)]R−1
��(t)e(t)
(5.62)
Now recognizing the alternate form for the gain as in Eq. 5.21 gives the desired
updated estimate as
̂x(t|t) = ̂Xmap(t) = ̂x(t|t −1) + K(t)e(t)
(5.63)
This completes the derivation. Consider the following discrete nonlinear example
of the previous section.
Example 5.3
Consider the discrete nonlinear process and measurement system described in the
previous example. The simulated measurement using SSPACK PC [8] is shown in
Fig. 5.6c. The XBP is designed from the following Jacobian:
A[x(t −1)] = 1 −0.05ΔT + 0.08ΔTx(t −1)
and
C[x(t)] = 2x(t) + 3x2(t)
The XBP algorithm is then given by
̂x(t|t −1) = (1 −0.05ΔT)̂x(t −1|t −1) + 0.04ΔT̂x2(t −1|t −1)
̃P(t|t −1) = [1 −0.05ΔT + 0.08ΔTx(t −1)]2 ̃P(t −1|t −1)
e(t) = y(t) −̂x2(t|t −1) −̂x3(t|t −1)
Ree(t) = [2̂x(t|t −1) + 3̂x2(t|t −1)]2 ̃P(t|t −1) + 0.09
K(t) = (̃P(t|t −1)[2̂x(t|t −1) + 3̂x2(t|t −1)])R−1
ee (t)
̂x(t|t) = ̂x(t|t −1) + K(t)e(t)
̃P(t|t) = (1 −K(t)[2̂x(t|t −1) + 3̂x2(t|t −1)])̃P(t|t −1)
̂x(0|0) = 2.3
and
̃P(0|0) = 0.01
An XBP run is depicted in Fig. 5.6. Here we see that the state estimate begins
tracking the true state after the initial transient. The estimation error is reasonable
(∼1% lie outside limits) indicating the ilter is performing properly for this realiza-
tion. The iltered measurement and innovations are shown in Fig. 5.6b and lie within
the predicted limits. The innovations are zero-mean (6.3 × 10−2 < 11.8 × 10−2) and
white (0% lie outside limits) as shown in Fig. 5.6c indicating proper tuning. Com-
paring the XBP to the LZ-BP of the previous section shows that it performs slightly
worse in terms of predicted covariance limits for the estimated measurement and
innovations. Most of this error is caused by the initial conditions of the processor.
Running an ensemble of 101 realizations of this processor yields similar results
for the ensemble estimates: state estimation error increased (∼2% outside limits),

5.5
EXTENDED BAYESIAN PROCESSOR (EXTENDED KALMAN FILTER)
175
0
0.5
1
1.5
1.95
2
2.05
2.1
Time (s)
0
0.5
1
1.5
Time (s)
0
0.5
1
1.5
Time (s)
x
−0.06
−0.04
−0.02
0
0.02
0.04
x
0
0.5
1
1.5
11.5
12
12.5
13
13.5
14
14.5
Time (s)
0
0.5
1
1.5
Time (s)
y
−2
−1
0
1
2
e
11.5
12
12.5
13
13.5
14
14.5
y
0
0.2
0.4
0.6
0.8
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Ree
Lag time (s)
(c)
(b)
(a)
^
^
^
~
FIGURE 5.6
XBP (EKF) simulation: (a) estimated state (1% out) and error (1% out); (b)
iltered measurement (1.3% out) and error (innovation) (3.3% out); (c) simulated mea-
surement and zero-mean/whiteness test (6.3 × 10−�<11.8 × 10−�and 0% out).
innovations zero-mean test increased slightly (6.7 × 10−2 < 12 × 10−2), and white-
ness was identical. This completes the example.
△△△
Next we consider one of the most popular applications of XBP approach—the
tracking problem [1, 5, 15, 20]. The choice of the coordinate system for the tracker
determines whether the nonlinearities occur either in the state equations (polar coor-
dinates [22]) or in the measurement equations (Cartesian coordinates [23]). The
following application depicts typical XBP performance in Cartesian coordinates.
Example 5.4
Consider the following passive localization and tracking problem that frequently
arises in sonar and navigation applications [15]. A maneuvering observer O monitors
noisy “bearings-only” measurements from a target t assumed to be traveling at a

176
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
O
O
R
Y
X
t
t
FIGURE 5.7
Observer (O) and target (t) geometry illustrating bearing angle (�) and
slant range (R) at an instant for XBP tracking application.
constant velocity. These measurements are to be used to estimate target position r
and velocity �. The problem is geometrically depicted in Fig. 5.7. The velocity and
position of the target relative to the observer are deined by
�x(t) := �tx(t) −�ox(t)
rx(t) := rtx(t) −rox(t)
�y(t) := �ty(t) −�oy(t)
ry(t) := rty(t) −roy(t)
The velocity is related to position by
�(t) = d
dtr(t) ≈r(t) −r(t −1)
ΔT
for ΔT, the sampling interval
or
r(t) = r(t −1) + ΔT�(t −1)
and
�(t) = �(t −1) + [�(t) −�(t −1)]
�(t) = [�t(t −1) −�o(t −1)] −[�o(t) −�o(t −1)] = �(t −1) −Δ�o(t −1)
for a constant velocity target �t(t) = �t(t −1) = ⋯= �t and Δ�is the incremental
change in observer velocity. Using these relations, we can easily develop a Gauss–
Markov model of the equations of motion in two dimensions by deining the state
vector as x′ := [rxry�x�y] and input u′ := [−Δ�ox −Δ�oy], but irst let us consider the
measurement model.

5.5
EXTENDED BAYESIAN PROCESSOR (EXTENDED KALMAN FILTER)
177
For this problem, we have the bearing relation given by
�(x, t) := arctan rx(t)
ry(t)
The entire system can be represented as a Gauss–Markov model with the noise
sources representing uncertainties in the states and measurements. Thus, we have the
equations of motion given by
x(t) =
⎡
⎢
⎢
⎢⎣
1
0
ΔT
0
0
1
0
ΔT
0
0
1
0
0
0
0
1
⎤
⎥
⎥
⎥⎦
x(t −1) +
⎡
⎢
⎢
⎢⎣
0
0
0
0
1
0
0
1
⎤
⎥
⎥
⎥⎦
⎡
⎢
⎢⎣
−Δ�ox(t −1)
−Δ�oy(t −1)
⎤
⎥
⎥⎦
+ �(t −1)
with the nonlinear sensor model given by
y(t) = arctan x1(t)
x2(t) + �(t)
for �∼(0, R��) and �∼(0, R��). The SSPACK PC software [8] was used to
simulate this system which is depicted in Fig. 5.8 for two legs of a tracking scenario.
An impulse-incremental-step change (Δ�ox = +24 knots and Δ�oy = −10 knots) was
initiated at 0.5 h, resulting in a change of observer position and velocity depicted in
the igure. The simulated bearing measurements are shown in Fig. 5.6d, The initial
conditions for the run were x′(0) := [0 15 nm 20 k −10 k] and R��= diag 10−6 with
the measurement noise covariance given by R��= 3.05 × 10−4rad2 for ΔT = 0.33 h.
The XBP algorithm of Table 5.3 is implemented using this model and the following
Jacobian matrices are derived from the Gauss–Markov model :
A[x] = A
and
C[x] =
[x2(t)
R2
−x1(t)
R2
0
0
]
where
R =
√
x2
1(t) + x2
2(t)
The results of this run are shown in Fig. 5.8. In Figs. 5.8a–b, we see the respective
x and y position estimates (velocity estimates are not shown) and corresponding
tracking errors. Here we see that it takes approximately 1.8 h for the estimator to
converge to the true target position (within ±1 nm). The innovations sequence appears
statistically zero-mean and white in Figs. 5.8c–d, indicating satisfactory performance.
The iltered measurement in Fig. 5.8c is improved considerably over the unprocessed
data in Fig. 5.8d. This completes the example.
△△△

178
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
0
5
.90
.80
.70
.60
.50
.40
.30
.20
.10
0
−.10
.10
.20
.30
.40
.50
.60
.70
.80
.90
0
−.10
1.0
1 = start (time = 0.000E + 00)
mean: sample = −3.201E − 03
            bound = 6.094E − 03 
   out: 0.00% (0)
4 out = 6.56%
var: estimator = 4.071E − 04
          sample = 5.896E − 04
51 out = 83.61%
variance = 4.705E + 01
57 out = 93.44%
variance = 8.544E + 00
−.4
−.2
0
.2
.4
.6
.8
−.08
−.06
−.04
−.02
0
.02
.04
.06
10
15
20
25
30
35
40
45
50
.2
.4
.6
.8 1.0 1.2
Time (h)
1.4 1.6 1.8 2.0
0
(a)
(b)
(c)
(d)
.2
.4
.6
.8 1.0 1.2
Time (h)
1.4 1.6 1.8 2.0
0
.2
.4
.6
.8 1.0 1.2
Time (h)
1.4 1.6 1.8 2.0
0
.2
.4
.6
.8 1.0 1.2
Time (h)
1.4 1.6 1.8 2.0
0
.2
.4
.6
.8 1.0 1.2
Time (h)
1.4 1.6 1.8 2.0
0
.2
.4
.6
.8 1.0 1.2
Time (h)
1.4 1.6 1.8 2.0
0
.10 .20 .30 .40 .50 .60
Lag time (h)
.70 .80 .90 1.00
0
.2
.4
.6
.8 1.0 1.2
Time (h)
1.4 1.6 1.8 2.0
21
18
15
12
9
x^1
x1
x^2
y^
y
R^
ee
6
3
0
−3
−10
−10
−5
0
5
10
−15
−20
−25
−30
−35
−8
−6
−4
−2
0
2
e
~
x2
~
FIGURE 5.8
Extended BP (EKF) simulation for bearings-only tracking problem: (a) X-
position estimate and error; (b) Y-position estimate and error; (c) iltered measurement
and error (innovation); (d) simulated measurement and zero-mean/whiteness test (3.2
× 10−�<6.1 × 10−�and 0% out).

5.6
ITERATED-EXTENDED BAYESIAN PROCESSOR (ITERATED-EXTENDED KALMAN FILTER)
179
This completes the section on the extension of the BP to nonlinear problems. Next,
we investigate variants of the XBP for improved performance.
5.6
ITERATED-EXTENDED BAYESIAN PROCESSOR
(ITERATED-EXTENDED KALMAN FILTER)
In this section, we discuss an extension of the XBP of the previous section to the
iterated-extended (IX-BP). We heuristically motivate the design and then discuss a
more detailed approach using Bayesian MAP estimation coupled with numerical opti-
mization techniques to develop the processor. This algorithm is based on performing
“local” iterations (not global) at a point in time t to improve the reference trajectory
and therefore the underlying estimate in the presence of signiicant measurement
nonlinearities [1]. A local iteration implies that the inherent recursive structure of the
processor is retained providing new estimates as the new measurements are made
available.
To develop the iterated-extended processor, we start with the linearized processor
update relation substituting the “linearized” innovation of Eq. 5.33 of the LZ-BP, that
is,
̂x(t|t) = ̂x(t|t −1) + K(t; x∗(t)) [y(t) −c[x∗(t)] −C[x∗(t)] (̂x(t|t −1) −x∗(t))]
(5.64)
where we have explicitly shown the dependence of the gain (through the measurement
Jacobian) on the reference trajectory x∗(t). The XBP algorithm linearizes about
the most currently available estimate, x∗(t) = ̂x(t|t −1) in this case. Theoretically,
the updated estimate ̂x(t|t) is a better estimate and closer to the true trajectory.
Suppose we continue and relinearize about ̂x(t|t) when it becomes available and then
recompute the corrected estimate and so on. That is, deine the (i + 1)th iterated
estimate as ̂xi+1(t|t), then the updated iterator equation becomes
̂xi+1(t|t) = ̂x(t|t −1) + K(t; ̂xi(t|t))
× [y(t) −c[̂xi(t|t)] −C[̂xi(t|t)](̂x(t|t −1) −̂xi(t|t))]
(5.65)
Now, if we start with the 0th iterate as the predicted estimate, that is, ̂xo ≡̂x(t|t −1),
then the XBP results for i = 0. Clearly, the updated estimate in this iteration is given
by
̂x1(t|t) = ̂x(t|t −1) + Ko(t)[y(t) −c[̂x(t|t)] −C[̂x(t|t −1)](̂x(t|t −1) −̂x(t|t −1))]
(5.66)
where the last term in this expression is null leaving the usual innovation. Note also
that the gain is reevaluated on each iteration as are the measurement function and
Jacobian. The iterations continue until there is little difference in consecutive iterates.
The last iterate is taken as the updated estimate. The complete (updated) iterative

180
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
loop is given by
ei(t) = y(t) −c[̂xi(t|t)]
Reiei(t) = C[̂xi(t|t)]̃P(t|t −1)C′[̂xi(t|t)] + R��(t)
Ki(t) = ̃P(t|t −1)C′[̂xi(t|t)]R−1
eiei(t)
̂xi+1(t|t) = ̂x(t|t −1) + Ki(t)[ei(t) −C[̂xi(t|t)](̂x(t|t −1) −̂xi(t|t))]
̃Pi(t|t) = (I −Ki(t)C[̂xi(t|t)])̃P(t|t −1)
(5.67)
A typical stopping rule is:
∥̂xi+1(t|t) −̂xi(t|t)∥< �
and
̂xi(t|t) →̂x(t|t)
(5.68)
The IX-BP algorithm is summarized in Table 5.4.
The IX-BP can be useful in reducing the measurement function nonlinearity
approximation errors, improving processor performance. It is designed for measure-
ment nonlinearities and does not improve the previous reference trajectory, but it
will improve the subsequent one. Next, we take a slightly more formal approach to
developing the IX-BP from the Bayesian perspective, that is, we irst formulate a
parametric optimization problem to develop the generic structure of the iterator, then
apply it to the underlying state estimation problem. Let us assume that we have a
nonlinear cost function, J(Θ), that we would like to maximize relative to the param-
eter vector, Θ ∈RNΘ×1. We begin by expanding the cost in terms of a Taylor series
TABLE 5.4
Iterated Extended BP (Kalman Filter) Algorithm
Prediction
̂x(t|t −1) = a[̂x(t −1|t −1)] −b[u(t −1)]
[State prediction]
̃P(t|t −1) = A[̂x(t|t −1)]̃P(t −1|t −1)A′[̂x(t|t −1)] −R��(t −1)
[Covariance prediction]
LOOP: i = 1, … , Niterations
Innovation
ei(t) = y(t) −c[̂xi(t|t)]
[Innovation]
Reiei(t) = C[̂xi(t|t)]̃P(t|t −1)C′[̂xi(t|t)] −R��(t)
[Innovation covariance]
Gain
Ki(t) = ̃P(t|t −1)C′[̂xi(t|t)]R−1
eiei(t)
[Gain or weight]
Update
̂xi+1(t|t) = ̂x(t|t −1) + Ki(t)[ei(t) −C[̂xi(t|t)](̂x(t|t −1) −̂xi(t|t))]
[State update]
̃Pi(t|t) = [I −Ki(t)C[̂xi(t|t)]]̃P(t|t −1)
[Covariance update]
Initial Conditions
̂x(0|0),
̃P(0|0),
̂xo(t|t) = ̂x(t|t −1)
Jacobians
A[̂x(t|t −1)] ≡da[x(t−1)]
dx(t−1)
|||x=̂x(t|t−1) C[̂xi(t|t)] ≡dc[x(t)]
dx(t)
|||x=̂xi(t|t)

5.6
ITERATED-EXTENDED BAYESIAN PROCESSOR (ITERATED-EXTENDED KALMAN FILTER)
181
about the Θi, that is,
J(Θ) = J(Θi) + (Θ −Θi)′[∇ΘJ(Θi)] + 1
2(Θ −Θi)′[∇ΘΘJ(Θi)](Θ −Θi) + H.O.T.
(5.69)
where ∇Θ is the NΘ-gradient vector deined by
∇ΘJ(Θi) := �J(Θ)
�Θ
|||||Θ=Θi
(5.70)
with the corresponding NΘ × NΘ Hessian matrix deined by
∇ΘΘJ(Θi) := �2J(Θ)
�Θ2
|||||Θ=Θi
(5.71)
Now if we approximate this expression by neglecting the H.O.T. and assume that
Θi is close to the true parameter vector (Θi ≈Θtrue), then differentiating Eq. 5.69
using the chain rule, we obtain
∇ΘJ(Θi) = 0 + ∇ΘΘ′[∇ΘJ(Θi)] + 1
2(2[∇ΘΘJ(Θi)](Θ −Θi)) = 0
or
[∇ΘΘJ(Θi)](Θ −Θi) = −[∇ΘJ(Θi)]
Solving for Θ and letting Θ →Θi+1 we obtain the well-known Newton–Rhapson
iterator (NRI) as [1, 15, 16]
Θi+1 = Θi −[∇ΘΘJ(Θi)]−1[∇ΘJ(Θi)]
(5.72)
This is the form that our IX-BP will assume. Now let us return to the basic problem
of improved state estimation using the NRI.
Under the usual Gaussian assumptions, we would like to calculate the MAP
estimate of the state at time t based on the data up to time t, therefore, the a posteriori
probability (see Section 4) is given by
Pr(x(t)|Yt) = 1
�× Pr(y(t)|x(t)) × Pr(x(t)|Yt−1)
(5.73)
where �is a normalizing probability (not a function of the state) and can be ignored
in this situation. As in the linear case, we have
1. Pr(y(t)|x(t)):
(c[x(t)], R��(t))
2. Pr(x(t)|Yt−1):
(̂x(t|t −1), ̃P(t|t −1))

182
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
Maximizing the a posteriori probability is equivalent to minimizing its logarithm,
therefore, we have that
J(x(t)) = ln Pr(y(t)|x(t)) + ln Pr(x(t)|Yt−1)
= −1
2(y(t) −c[x(t)])′R−1
��(t)(y(t) −c[x(t)])
−1
2(x(t) −̂x(t|t −1))′ ̃P−1(t|t −1)(x(t) −̂x(t|t −1))
(5.74)
Minimizing this expression, we differentiate with respect to x(t) using the gradient
operator as before to obtain
∇xJ(x(t)) = [∇xc′[x(t)]]R−1
��(t)(y(t) −c[x(t)]) −̃P−1(t|t −1)(x(t) −̂x(t|t −1))
(5.75)
With a slight abuse, we can simplify the notation by deining the relations
C[xi(t)] := �c[x(t)]
�x(t) |x(t)=xi(t), ei(t) := y(t) −c[xi(t)], and ̃xi(t) := xi(t) −̂x(t|t −1)
Therefore, letting x →xi, we can write Eq. 5.75 as
∇xJ(xi(t)) = C′[xi(t)]R−1
��(t)ei(t) −̃P−1(t|t −1)̃xi(t|t −1)
(5.76)
which is the same form of the linear MAP estimator of Eq. 5.10 with C[xi(t)] →C(t).
Continuing with the NRI derivation, we differentiate Eq. 5.76 again to obtain the
Hessian
∇xxJ(xi(t)) = C′[xi(t)]R−1
��(t)C[xi(t)] + ̃P−1(t|t −1)
(5.77)
but applying the matrix inversion lemma as in Section 5.4 (see Eq. 5.13 for details),
it is shown that
[∇xxJ(xi(t))]−1 = (I −Ki(t)C[xi(t)])̃P(t|t −1) ≡̃Pi(t|t)
(5.78)
for
Ki(t) := Ki(t; xi(t)) = ̃P(t|t −1)C′[xi(t)]R−1
eiei(t)
(5.79)
with
Reiei(t) = C[xi(t)]̃P(t|t −1)C′[xi(t)] + R��(t)
(5.80)

5.6
ITERATED-EXTENDED BAYESIAN PROCESSOR (ITERATED-EXTENDED KALMAN FILTER)
183
Now equating Eqs. 5.76 and 5.78, and solving for ̃P−1(t|t −1), we obtain
̃P−1(t|t −1) = ̃P−1(t|t) −C′[xi(t)]R−1
��(t)C[xi(t)]
(5.81)
which can be substituted back into Eq. 5.76 to give
∇xJ(xi(t)) = C′[xi(t)]R−1
��(t)ei(t) −[̃P−1(t|t) −C′[xi(t)]R−1
��(t)C[xi(t)]]̃xi(t|t −1)
(5.82)
The NRI can now be written in terms of the iterated state at time t as
xi+1(t) = xi(t) −[∇xxJ(xi(t))]−1∇xJ(xi(t))
(5.83)
Using the expressions for the Hessian and gradient, we have
xi+1(t) = xi(t) + ̃Pi(t|t)
×(C′[xi(t)]R−1
��(t)ei(t) −[̃P−1(t|t) −C′[xi(t)]R−1
��(t)C[xi(t)]]̃xi(t|t −1))
(5.84)
Multiplying through by the Hessian and recognizing the alternate expression for
the gain (see Eq. 5.22), we obtain the expression
xi+1(t) = xi(t) + Ki(t)ei(t) −(I −Ki(t)C[xi(t)])̃xi(t|t −1)
(5.85)
Now multiplying through by ̃x(t|t −1), factoring out the gain and performing the
additions, we have
xi+1(t) = ̂x(t|t −1) + Ki(t)[ei(t) −C[xi(t)](̂x(t|t −1) −xi(t))]
(5.86)
Deining the iterate in terms of the corrected state estimate, that is, xi(t) →̂xi(t|t),
gives the NRI iterator of Eq. 5.67 and Table 5.4.
So we see that, for strong measurement of nonlinearities, the IX-BP can be used
for little cost to the XBP. A further extension of these results is called the iterator-
smoother XBP in which the entire processor is iterated to mitigate strong nonlin-
earities in the predicted estimates [1]. Here the measurement is relinearized and
then a “smoothed” state estimate is calculated and used in the prediction loop. This
completes the discussion of the processor; next, we demonstrate its performance.
Example 5.5
Consider the discrete nonlinear process and measurement system described in the
previous example. The simulated measurement using SSPACK PC [8] is shown in
Fig. 5.9c. The IX-BP is designed from the following Jacobian
A[x(t −1)] = 1 −0.05ΔT + 0.08ΔTx(t −1)
and
C[x(t)] = 2x(t) + 3x2(t)

184
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
0
0.5
1
1.5
1.95
2
2.05
2.1
Time (s)
0
0.5
1
1.5
Time (s)
0
0.5
1
1.5
Time (s)
x
−0.04
−0.02
0
0.02
0.04
x
0
0.5
1
1.5
11.5
12
12.5
13
13.5
14
14.5
Time (s)
0
0.5
1
1.5
Time (s)
y
−2
−1
0
1
2
e
11.5
12
12.5
13
13.5
14
14.5
y
0
0.2
0.4
0.6
0.8
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Ree
Lag time (s)
(c)
(b)
(a)
^
^
^
~
FIGURE 5.9
Iterated-extended BP (IEKF) simulation: (a) estimated state (∼0% out) and
error (∼0% out); (b) iltered measurement (∼1% out) and error (innovation) (∼2.6% out);
(c) simulated measurement and zero-mean/whiteness test (4 × 10−�<10.7 × 10−�and
0% out).
The IX-BP algorithm is then given by
̂x(t|t −1) = (1 −0.05ΔT)̂x(t −1|t −1) + 0.04ΔT̂x2(t −1|t −1)
̃P(t|t −1) = [1 −0.05ΔT + 0.08ΔTx(t −1)]2 ̃P(t −1|t −1)
ei(t) = y(t) −̂x2
i (t|t) −̂x3
i (t|t)
Reiei(t) = [2̂xi(t|t) + 3̂x2
i (t|t)]2 ̃P(t|t −1) + 0.09
Ki(t) = ̃P(t|t −1)[2̂xi(t|t) + 3̂x2
i (t|t)]∕Reiei(t)
̂xi+1(t|t) = ̂x(t|t −1) + Ki(t)[ei(t) −[2̂xi(t|t) + 3̂x2
i (t|t)](̂x(t|t −1) −̂xi(t|t))
̃Pi(t|t) = (1 −Ki(t)[2̂xi(t|t) + 3̂x2
i (t|t)])̃P(t|t −1)
̂x(0|0) = 2.3
and
̃P(0|0) = 0.01

5.7
PRACTICAL ASPECTS OF CLASSICAL BAYESIAN PROCESSORS
185
An IX-BP run is depicted in Fig. 5.9. Here we see that the state estimate (∼0%
lie within limits) begins tracking the true state instantaneously. The estimation error
is reasonable (∼0% out) indicating that the ilter is performing properly for this
realization. The iltered measurement (∼1% out) and innovations (∼2.6% out) are
shown in Fig. 5.9b. The innovations are zero-mean (4 × 10−2 < 10.7 × 10−2) and
white (0% lie outside limits) as shown in Fig. 5.9c indicating proper tuning and
matching the LZ-BP result almost exactly.
Running an ensemble of 101 realizations of this processor yields similar results for
the ensemble estimates: innovations zero-mean test decreased slightly (3.7 × 10−2 <
10.3 × 10−2) and whiteness was identical. So the overall effect of the IX-BP was to
decrease the measurement nonlinearity effect especially in the initial transient of the
algorithm. These results are almost identical to those of the LZ-BP. This completes
the nonlinear iltering example.
△△△
Next, we consider some more practical approaches to designing estimators.
5.7
PRACTICAL ASPECTS OF CLASSICAL BAYESIAN PROCESSORS
In this section, we heuristically provide an intuitive feel for the operation of the BP
using the state–space model and GM assumptions. These results coupled with the
theoretical points developed in Ref. [10] lead to the proper adjustment or “tuning”
of the BP. Tuning the processor is considered an art, but with proper statistical tests,
the performance can readily be evaluated and adjusted. As mentioned previously,
this approach is called the minimum (error) variance design. In contrast to the
standard ilter design procedures in signal processing, the minimum variance design
adjusts the statistical parameters (e.g., covariances) of the processor and examines the
innovations sequence to determine if the BP is properly tuned. Once tuned, all of the
statistics (conditional means and variances) are valid and may be used as reasonable
estimates. Here we discuss how the parameters can be adjusted and what statistical
tests must be performed to evaluate BP performance.
Heuristically, the sequential BP can be viewed simply by its update equation
̂Xnew =
Prediction
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
̂Xold
⏟⏟⏟
State–space model
+
Update
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
K × Enew
⏟⏞⏟⏞⏟
Measurement
where ̂Xold ≈f(model) and Enew ≈f(measurement).
Using this model of the BP, we see that we can view the old, or predicted estimate
̂Xold as a function of the state–space model (A, B) and the prediction error or inno-
vation E as a function primarily of the new measurement, as indicated in Table 5.1.

186
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
Parameter
Gain
Condition
P  small (model adequate)
P  large (model inadequate)
Rvv  large (measurement noisy)
Rvv  small (measurement good)
Small
Believe model
Large
Believe measurement
~
~
FIGURE 5.10
Bayesian processor heuristic notions.
Consider the new estimate under the following cases:
K ⟶small
̂Xnew = ̂Xold = f (model)
K ⟶large
̂Xnew = KEnew = f (measurement)
So we can see that the operation of the processor is pivoted about the values of the
gain or weighting matrix K. For small K, the processor “believes” the model, and for
large K, the processor believes the measurement (Fig. 5.10).
Let us investigate the gain matrix and see if its variations are consistent with these
heuristic notions. First, it was shown in Eq. 5.22 that the alternate form of the gain
equation is given by
K(t) = ̃P(t|t)C′(t)R−1
��(t)
Thus, the condition where K is small can occur in two cases: (1) ̃P is small (ixed
R��) which is consistent because small ̃P implies that the model is adequate; and
(2) R��is large (̃P ixed), which is also consistent because large R��implies that the
measurement is noisy, so again believe the model.
For the condition where K is large, two cases can also occur: (1) K is large
when ̃P is large (ixed R��), implying that the model is inadequate, so believe the
measurement; and (2) R��is small (̃P ixed), implying the measurement is good
(high SNR). So we see that our heuristic notions are based on speciic theoretical
relationships between the parameters in the BP algorithm of Table 5.1.
Summarizing, a BP (Kalman ilter) is not functioning properly when the gain
becomes small and the measurements still contain information necessary for the
estimates. The ilter is said to diverge under these conditions. In this case, it is
necessary to detect how the ilter is functioning and how to adjust it if necessary, but
irst we consider the tuned BP.
When the processor is “tuned”, it provides an optimal or minimum (error) variance
estimate of the state. The innovations sequence, which was instrumental in deriving
the processor, also provides the starting point to check the BP operation. A necessary
and suficient condition for a BP to be optimal is that the innovation sequence is
zero-mean and white (see Ref. [4] for the proof). These are the irst properties that
must be evaluated to ensure that the processor is operating properly. If we assume
that the innovation sequence is ergodic and Gaussian, then we can use the sample

5.7
PRACTICAL ASPECTS OF CLASSICAL BAYESIAN PROCESSORS
187
mean as the test statistic to estimate me, the population mean. The sample mean for
the ith component of ei is given by
̂me(i) = 1
N
N
∑
t=1
ei(t)
for i = 1, … , Ny
(5.87)
where ̂me(i) ∼(me, Ree(i)∕N) and N is the number of data samples. We perform a
statistical hypothesis test to “decide” if the innovation mean is zero [10]. We test that
the mean of the ith component of the innovation vector ei(t) is
Ho :
me(i) = 0
H1 :
me(i) ≠0
As our test statistic we use the sample mean. At the �-signiicance level, the proba-
bility of rejecting the null hypothesis Ho is given by
Pr
(||||||
̂me(i) −me(i)
√
Ree(i)∕N
> �i −me(i)
√
Ree(i)∕N
||||||
)
= �
(5.88)
Therefore, the zero-mean test [10] on each component innovation ei is given by
̂me(i)
> Reject Ho
< Accept Ho
�i
(5.89)
Under the null hypothesis Ho, each me(i) is zero. Therefore, at the 5% signiicance
level (�= 0.05), we have that the threshold is
�i = 1.96
√
̂Ree(i)
N
(5.90)
where ̂Ree(i) is the sample variance (assuming ergodicity) estimated by
̂Ree(i) = 1
N
N
∑
t=1
e2
i (t)
(5.91)
Under the same assumptions, we can perform a whiteness test [10], that is, check
statistically that the innovations covariance corresponds to that of an uncorrelated
(white) sequence. Again assuming ergodicity of the innovations sequence, we use

188
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
the sample covariance function as our test statistic with the ith component covariance
given by
̂Ree(i, k) = 1
N
N
∑
t=k+1
(ei(t) −̂me(i))(ei(t + k) −̂me(i))
(5.92)
We actually use the normalized covariance test statistic
̂�ee(i, k) =
̂Ree(i, k)
̂Ree(i)
(5.93)
Asymptotically for large N, it can be shown that (see Refs. [10–14]) that
̂�ee(i, k) ∼(0, 1∕N)
Therefore, the 95% conidence interval estimate is
I�ee = ̂�ee(i, k) ± 1.96
√
N
for N > 30
(5.94)
Hence, under the null hypothesis, 95% of the ̂�ee(i, k) values must lie within this
conidence interval, that is, for each component innovation sequence to be considered
statistically white. Similar tests can be constructed for the cross-covariance properties
of the innovations [13] as well, that is,
Cov(e(t), e(k)) = 0
and
Cov(e(t), u(t −1)) = 0
The whiteness test of Eq. 5.94 is very useful for detecting model inaccuracies from
individual component innovations. However, for complex systems with a large num-
ber of measurement channels, it becomes computationally burdensome to investigate
each innovation component-wise. A statistic capturing all of the innovation informa-
tion is the WSSR [14]. It aggregates all of the innovation vector information over
some inite window of length N. It can be shown that the WSSR is related to a
maximum likelihood estimate of the normalized innovations variance [10, 14]. The
WSSR test statistic is given by
̂�(�) :=
�
∑
k=�−N+1
e′(k)R−1
ee (k)e(k)
for �≥N
(5.95)
and is based on the hypothesis test
Ho : �(�) is white
H1 : �(�) is not white

5.7
PRACTICAL ASPECTS OF CLASSICAL BAYESIAN PROCESSORS
189
given by
̂�(�)
> Reject Ho
< Accept Ho
�
(5.96)
Under the null hypothesis, the WSSR is chi-squared distributed, �(�) ∼�2(NyN).
However, for NyN > 30, �(�) is approximately Gaussian (NyN, 2NyN) (see Ref. [4]
for more details). At the �-signiicance level, the probability of rejecting the null
hypothesis is given by
Pr
(||||||
�(�) −NyN
√2NyN
>
�−NyN
√2NyN
||||||
)
= �
(5.97)
For a level of signiicance of �= 0.05, we have
�= NyN + 1.96
√
2NyN
(5.98)
Thus, the WSSR can be considered a “whiteness test” of the innovations vector
over a inite window of length N. Note that since [{e(t)}, {Ree(t)}] are obtained from
the state–space BP algorithm directly, they can be used for both stationary as well
as nonstationary processes. In fact, in practice for a large number of measurement
components, the WSSR is used to “tune” the ilter and then the component innovations
are individually analyzed to detect model mismatches. Note also that the adjustable
parameter of the WSSR statistic is the window length N, which essentially controls
the width of the window sliding through the innovations sequence.
Other sets of “reasonableness” tests can be performed using the covariances esti-
mated by the BP algorithm and sample variances estimated using Eq. 5.92. The BP
provides estimates of the respective processor covariances Ree and ̃P from the relations
given in Table 5.1. Using sample variance estimators, when the ilter reaches steady
state (process is stationary), that is, ̃P is constant, the estimates can be compared to
ensure that they are reasonable. Thus we have
̂Ree(i) ≈Ree(i)
and
̂̃P(i) ≈̃P(i)
(5.99)
Plotting the ±1.96
√
Reiei(t) and ±1.96
√̃Pi(t|t) about the component innovations
{ei(t)} and component state estimation errors {̃xi(t|t)}, when the true state is known
provides an accurate estimate of the BP performance especially when simulation is
used. If the covariance estimates of the processor are reasonable, then 95% of the
sequence samples should lie within the constructed bounds. Violation of these bounds
clearly indicate inadequacies in modeling the processor statistics. We summarize
these results in Fig. 5.11 and examine an RLC-circuit design problem in the following
section to demonstrate the approach in more detail.

190
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
Data
Innovation
Covariances
Sample mean
Zero mean
Ergodic, gaussian
Sample covariance
Whiteness
Ergodic, gaussian
WSSR
Whiteness
Gaussian
Sample cross-
Cross-covariance
Cross-covariance
Confidence interval
Ergodic, gaussian
Ergodic, gaussian
Ergodic
known
Ergodic, X true
X true known
Property
me = 0
Ree(t)
Ree(t,k)
Reu(t,k)
(l)
Statistic
Test
Assumptions
Innovation
Innovation
Estimation
error
Estimation
error
covariance
Sample cross-
Sample variance
Sample variance
covariance
Ree
about {e(t )}
Confidence interval
about {x(t  t)}
~
P = P
Ree = Ree
~
P
~
^
^
FIGURE 5.11
State–space BP tuning tests.
5.8
CASE STUDY: RLC CIRCUIT PROBLEM
Consider the design of an estimator for a series RLC circuit (second-order system)
excited by a pulse train. The circuit diagram is shown in Fig. 5.12. Using Kirchhoff’s
voltage law, we can obtain the circuit equations with i = C(de∕dt):
d2e
dt2 + R
L
de
dt + 1
LCe = 1
LCein
where ein is a unit pulse train. This equation is that of a second-order system that char-
acterizes the electrical RLC circuit, or a mechanical vibration system, or a hydraulic
Volts
Noise
R  +  ∆R
L  +  ∆L
C  +  ∆C
e0
ein
i
∑
FIGURE 5.12
RLC circuit problem.

5.8
CASE STUDY: RLC CIRCUIT PROBLEM
191
low system, etc. The dynamic equations can be placed in state–space form by choos-
ing x := [e | de∕dt]′ and u = ein:
dx
dt =
[
0
1
−1
LC
−R
L
]
x +
[
0
−1
LC
]
u +
[
0
−1
LC
]
�
where �∼N(0, R��) is used to model component inaccuracies.
A high-impedance voltmeter is placed in the circuit to measure the capacitor
voltage e. We assume that it is a digital (sampled) device contaminated with noise of
variance R��; that is,
y(t) = e(t) + �(t)
where �∼N(0, R��). For our problem we have the following parameters: R =
5 kΩ, L = 2.5 H, C = 0.1 �F, and T = 0.1 ms (the problem will be scaled in millisec-
onds). We assume that the component inaccuracies can be modeled using R��= 0.01,
characterizing a deviation of ±0.1 V uncertainty in the circuit representation. Finally,
we assume that the precision of the voltmeter measurements are (e ± 0.2 V), the two
standard deviation value, so that R��= 0.01 (V)2. Summarizing the circuit model, we
have the continuous-time representation
dx
dt =
[
0
1
−4
−2
]
x +
[
0
−4
]
u +
[
0
−4
]
�
and the discrete-time measurements
y(t) = [1
0]x(t) + �(t)
where
R��= (0.1)2
T
= 0.01(V)2
and
R��= 0.01(V)2
Before we design the discrete BP, we must convert the system or process model
to a sampled-data (discrete) representation. Using SSPACK PC [8], this is accom-
plished automatically with the Taylor series approach to approximating the matrix
exponential. For an error tolerance of 1 × 10−12, a 15-term series expansion yields
the following discrete-time Gauss–Markov model:
x(t) =
[
0.98
0.09
−0.36
0.801
]
x(t −1) +
[
−0.019
−0.36
]
u(t −1) +
[
−0.019
−0.36
]
�(t −1)
y(t) = [1 | 0]x(t) + �(t)
where
R��= 0.01(V)2
and
R��= 0.01(V)2

192
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
x1
x2
1.5
0 out = 0.00%
4 out = 1.99%
0 out = 0.00%
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
x1true
x2true
ytrue
y
u
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
(c)
(d)
(b)
(a)
2
4
6
8
10 12
Time (ms)
14 16 18 20
FIGURE 5.13
Gauss–Markov simulation of RLC circuit problem: (a) simulated and true
state (voltage); (b) simulated true state (current); (c) simulated and true measurement;
(d) pulse-train excitation.
Using SSPACK PC with initial conditions x(0) = 0 and P = diag(0.01, 0.04), the
simulated system is depicted in Fig. 5.13. In Figs. 5.13a–c, we see the simulated
states and measurements with corresponding conidence limits about the mean (true)
values. In each case, the simulation satisies the statistical properties of the GM
model. The corresponding true (mean) trajectories are also shown along with the

5.8
CASE STUDY: RLC CIRCUIT PROBLEM
193
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
(a)
(b)
(c)
(d)
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
1.5
1.0
.5
0
−.5
−1.0
−1.5
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
.6
.4
.2
0
−.2
−.4
−.6
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
.6
.4
.2
0
−.2
−.4
−.6
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
.6
.4
.2
0
−.2
−.4
−.6
0
2
4
6
8
10 12
Time (ms)
14 16 18 20
0
0
5
10
15
20
25
30
35
40
45
50
2
4
6
8
10 12
Time (ms)
14 16 18 20
0
−.2
0
.2
.4
.6
.8
1.0
1.0 2.0 3.0 4.0 5.0 6.0
Lag time (ms)
7.0 8.0 9.010.0
True
Estimated
True
True
Estimated
Estimated
29 out = 14.43%
mean = −6.649E − 00
var: estimator = 2.391E − 00
sample = 4.389E − 00
6 out = 2.99%
mean = 1.179E − 02
var: estimator = 2.786E − 02
sample = 1.542E − 02
I = start (time = 0.000E + 00)
mean: sample = 4.550E − 03
threshold = 3.086E + 01
window = 25
bound = 1.429E − 02
out: 5.05% (5)
7 out = 3.48%
var: estimator = 1.314E − 02
sample = 1.069E − 02
x^
1
x~
1
x^
2
y^
^
x~
2
R^
ee
e
FIGURE 5.14
Bayesian processor design for RLC circuit problem: (a) estimated state
(voltage) and error; (b) estimated state (current) and error; (c) iltered and true mea-
surement (voltage) and error (innovation); (d) WSSR and whiteness test.
pulse train excitation. Note that the measurements are merely a noisier (process and
measurement noise) version of the voltage x1.
A discrete BP was designed using SSPACK PC to improve the estimated voltage
̂x1. The results are shown in Fig. 5.14. In Fig. 5.14a–c we see the iltered states and
measurements as well as the corresponding estimation errors. The true (mean) states

194
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
are superimposed as well to indicate the tracking capability of the estimator. The
estimation errors lie within the bounds (3% out) for the second state, but the error
covariance is slightly underestimated for the irst state (14% out). The predicted and
sample variances are close (0.002 ≈0.004 and 0.028 ≈0.015) in both cases. The
innovations lie within the bounds (3% out) with the predicted sample variances close
(0.011 ≈0.013). The innovations are statistically zero-mean (0.0046 ≪0.014) and
white (5% out, WSSR below threshold),4 indicating a well-tuned estimator. This
completes the RLC problem.
5.9
SUMMARY
In this chapter, we have introduced the concepts of classical linear and nonlinear
Bayesian signal processing using state–space models. After developing the idea
of linearizing a nonlinear state–space system, we developed the linearized Bayesian
processor (LZ-BP). It was shown that the resulting processor provides an approximate
solution (time-varying) to the nonlinear state estimation problem. We then developed
the extended Bayesian processor (XBP) or equivalently the extended Kalman ilter
(EKF), as a special case of the LZ-BP linearizing about the most currently available
estimate. Next, we investigated a further enhancement of the XBP by introducing
a local iteration of the nonlinear measurement system using the Newton–Rhapson
method. Here the processor is called the iterated-extended Bayesian processor (IX-
BP) and is shown to produce improved estimates at a small computational cost in
most cases. Examples were developed throughout to demonstrate the concepts (see
http://www.techni-soft.net for more details).
MATLAB NOTES
SSPACK PC [8] is a third-party toolbox in MATLAB that can be used to design
classical Bayesian processors. This package incorporates the major nonlinear
BP algorithms discussed in this chapter—all implemented in the UD-factorized
form [21] for stable and eficient calculations. It performs the discrete approxi-
mate Gauss–Markov simulations using (SSNSIM) and both extended (XBP) and
iterated-extended (IX-BP) processors using (SSNEST). The linearized Bayesian
processor (LZ-BP) is also implemented (SSLZEST). Ensemble operations are
seamlessly embodied within the GUI-driven framework where it is quite eficient
to perform multiple design runs and compare results. Of course, the heart of the
package is the command or GUI-driven post-processor (SSPOST) which is used
to analyze and display the results of the simulations and processing.
REBEL is a recursive Bayesian estimation package in MATLAB available on
the web which performs similar operations including the new statistical-based
4 WSSR is the weighted-sum squared residual statistic which aggregates the innovation vector information
over a window to perform a vector-type whiteness test (see Ref. [2] for details).

REFERENCES
195
unscented algorithms including the UBP (Chapter 6) including the unscented
transformations [24]. It also includes the new particle ilter designs (Chapter 7)
discussed in Ref. [25].
REFERENCES
1. A. Jazwinski, Stochastic Processes and Filtering Theory (New York: Academic Press,
1970).
2. A. Sage and J. Melsa, Estimation Theory with Applications to Communications and
Control (New York: McGraw-Hill, 1971).
3. A. Gelb, Applied Optimal Estimation (Boston, MA: MIT Press, 1975).
4. B. Anderson and J. Moore, Optimal Filtering (Englewood Cliffs, NJ: Prentice-Hall, 1979).
5. P. Maybeck, Stochastic Models, Estimation, and Control (New York: Academic Press,
1979).
6. M. Grewal and A. Andrews, Kalman Filtering: Theory and Practice (Englewood Cliffs,
NJ: Prentice-Hall, 1993).
7. J. Mendel, Lessons in Estimation Theory for Signal Processing, Communications and
Control (Englewood Cliffs, NJ: Prentice-Hall, 1995).
8. J. Candy and P. Candy, “SSPACK_PC: A model-based signal processing package on
personal computers,” DSP Applications, 2, 3, 33–42, 1993 (see http://www.techni-soft.net
for more details).
9. J. Candy, Signal Processing: The Model-Based Approach (New York: McGraw-Hill,
1986).
10. J. Candy, Model-Based Signal Processing (Hoboken, NJ: John Wiley & Sons, Inc./IEEE
Press, 2006).
11. D. Simon, Optimal State Estimation: Kalman, H∞and Nonlinear Approaches (Hoboken,
NJ: John Wiley & Sons, Inc., 2006).
12. T. Kailath, A. Sayed, and B. Hassibi, Linear Estimation (Englewood Cliffs, NJ: Prentice-
Hall, 2000).
13. R. Mehra and J. Peschon, “An innovations approach to fault detection and diagnosis in
dynamic systems,” Automatica, 7, 637–640, 1971.
14. A. Wilsky, “A survey of failure detection in dynamic systems,” Automatica, 12, 601–611,
1976.
15. Y. Bar-Shalom and X. Li, Estimation and Tracking: Principles, Techniques, and Software
(Norwood, MA: Artech House, 1993).
16. B. Bell and F. Cathey, “The iterated Kalman ilter update as a Gauss-Newton method,”
IEEE Trans. Autom. Contr., AC-38, 2, 294–297, 1993.
17. J. Candy and R. Rozsa, “Safeguards for a plutonium-nitrate concentrator-an applied esti-
mation approach,”Automatica, 16, 615–627, 1980.
18. J. Candy and E. Sullivan, “Ocean acoustic signal processing: A model-based approach,”
J. Acoust. Soc. Am., 92, 3185–3201, 1992.
19. J. Mendel, J. Kormylo, J. Lee, and F. Ashirai, “A novel approach to seismic signal
processing and modeling,” Geophysics, 46, 1398–1414, 1981.

196
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
20. H. Sorenson Ed., “Special Issue on Applications of Kalman Filtering,” IEEE Trans. Auto.
Contr., AC-28, 3, 253–427, 1983.
21. G. Bierman, Factorization Methods of Discrete Sequential Estimation (New York: Aca-
demic Press, 1977).
22. V. Aidala and S. Hammel, “Utilization of modiied polar-coordinates for bearings-only
tracking,” IEEE Trans. Autom. Contr., AC-28, 283–294, 1983.
23. V. Aidala, “Kalman ilter behavior in bearings-only velocity and position estimation,”
IEEE Trans. Aerosp. Electron. Syst., AES-15, 29–39, 1979.
24. R. van der Merwe and E. Wan, REBEL: Recursive Bayesian Estimation Library University
of Oregon , 2002.
25. S. Haykin and N. de Freitas (editors), “Sequential state estimation: From Kalman ilters
to particle ilters,” Proc. IEEE, 92, 3, 399–574, 2004.
PROBLEMS
5.1
Derive the continuous-time BP by starting with the discrete equations of
Table 5.1 and using the following sampled-data approximations:
A = eAcΔt ≈I + AcΔt
B = BcΔt
W = WcΔt
R��= R�c�cΔt
5.2
Suppose we are given a continuous-time Gauss–Markov model characterized
by
˙x(t) = Ac(t)x(t) + Bc(t)u(t) + Wc(t)�(t)
and discrete (sampled) measurement model such that t →tk then
y(tk) = C(tk)x(tk) + �(tk)
where the continuous process, �(t) ∼(0, R��), and �(tk) ∼(0, R��) with
Gaussian initial conditions.
(a) Determine the state mean (mx(t)) and covariance (P(t)).
(b) Determine the measurement mean (my(tk)) and covariance (Ryy(tk)).
(c) Develop the relationship between the continuous and discrete Gauss–
Markov models based on the solution of the continuous state equations
and approximation using a irst-order Taylor series for the state transition
matrix, Φ(t, to) and the associated system matrices.

PROBLEMS
197
(d) Derive the continuous-discrete BP using irst difference approximations
for derivatives and the discrete (sampled) system matrices derived above.
5.3
The covariance correction equation of the BP algorithm is seldom used directly.
Numerically, the covariance matrix ̃P(t|t) must be positive semideinite, but in
the correction equation we are subtracting a matrix from a positive semideinite
matrix and cannot guarantee that the result will remain positive semideinite
(as it should be) because of roundoff and truncation errors. A solution to
this problem is to replace the standard correction equation with the stabilized
Joseph form, that is,
̃P(t|t) = [I −K(t)C(t)]̃P(t|t −1)[I −K(t)C(t)]′ + K(t)R��(t)K′(t)
(a) Derive the Joseph stabilized form.
(b) Demonstrate that it is equivalent to the standard correction equation.
5.4
Prove that a necessary and suficient condition for a linear BP to be optimal is
that the corresponding innovations sequence is zero-mean and white.
5.5
A bird watcher is counting the number of birds migrating to and from a
particular nesting area. Suppose the number of migratory birds, m(t) is modeled
by a irst-order ARMA model:
m(t) = −0.5m(t −1) + �(t)
for �∼(10, 75)
while the number of resident birds is static, that is,
r(t) = r(t −1)
The number of resident birds is averaged leading to the expression
y(t) = 0.5r(t) + m(t) + �(t)
for �∼(0, 0.1)
(a) Develop the two-state Gauss–Markov model with initial values r(0) = 20
birds, m(0) = 100 birds, cov r(0) = 25.
(b) Use the MBP algorithm to estimate the number of resident and migrating
birds in the nesting area for the data set y(t) = {70, 80}, that is, what is
̂x(2|2)?
5.6
Suppose we are given a measurement device that not only acquires the current
state but also the state delayed by one time-step (multipath) such that
y(t) = Cx(t) + Ex(t −1) + �(t)
Derive the recursive form for this associated MBP. (Hint: Recall from the
properties of the state transition matrix that x(t) = Φ(t, �)x(�) and Φ−1(t, �) =
Φ(�, t)

198
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
(a) Using the state transition matrix for discrete-systems, ind the relationship
between x(t) and x(t −1) in the Gauss–Markov model.
(b) Substitute this result into the measurement equation to obtain the usual
form
y(t) = ̃Cx(t) + ̃�(t)
What are the relations for ̃C and ̃�(t) in the new system?
(c) Derive the new statistics for ̃�(t) ∼N(�̃�, R ̃�̃�).
(d) Are �and �correlated? If so, use the prediction form to develop the MBP
algorithm for this system.
5.7
Develop the discrete linearized (perturbation) models for each of the following
nonlinear systems [7]:
r Synchronous (unsteady) motor: ̈x(t) + C ̇x(t) + p sin x(t) = L(t)
r Dufing equation: ̈x(t) + �x(t) + �x3(t) = F(cos �t)
r Van der Pol equation: ̈x(t) + �̇x(t)[1 −̇x2(t)] + x(t) = m(t)
r Hill equation: ̈x(t) −�x(t) + �p(t)x(t) = m(t)
(a) Develop the LZ-BP.
(b) Develop the XBP.
(c) Develop the IX-BP.
5.8
Suppose we are given the following discrete system
x(t) = −�2x(t −1) + sin x(t −1) + �u(t −1) + �(t −1)
y(t) = x(t) + �(t)
with �and �zero-mean, white Gaussian with usual covariances, R��and
R��.
(a) Develop the LZ-BP for this process.
(b) Develop the XBP for this process.
(c) Develop the IX-BP for this process.
(d) Suppose the parameters �and �are unknown develop the XBP such that
the parameters are jointly estimated along with the states. (Hint: Augment
the states and parameters to create a new state vector).
5.9
Assume that we have the following nonlinear continuous-discrete Gauss–
Markov model:
x(t) = f[x(t)] + g[u(t)] + �(t)
z(tk) = h[x(tk)] + �(tk)
with �and �zero-mean, white Gaussian with usual covariances, Q and R.
(a) Develop the perturbation model for �x(t) := x(t) −x∗(t) for x∗(t) the given
reference trajectory.

PROBLEMS
199
(b) Develop the LZ-BP for this process.
(c) Choose x∗(t) = ̂x(t) whenever ̂x(t) is available during the recursion. There-
fore, develop the continuous-discrete XBP.
5.10
Suppose we assume that a target is able to maneuver, that is, we assume that
the target velocity satisies a irst-order AR model given by:
��(t) = −���(t −1) + ��(t −1)
for �∼(0, R����)
(a) Develop the Cartesian tracking model for this process.
(b) Develop the corresponding XBP assuming all parameters are known a
priori.
(c) Develop the corresponding XBP assuming �is unknown.
5.11
Nonlinear processors (LZ-BP, XBP, IX-BP) can be used to develop neural
networks used in many applications. Suppose we model a generic neural
network behavior by
x(t) = x(t −1) + �(t −1)
y(t) = c[x(t), u(t), �(t)] + �(t)
where x(t) is the network weights (parameters), u(t) is the input or training
sequence, �(t) is the node activators with �and �zero-mean, white Gaussian
with covariances, R��and R��.
(a) Develop the LZ-BP for this process.
(b) Develop the XBP for this process.
(c) Develop the IX-BP for this process.
5.12
The Mackey–Glass time delay differential equation is given by
˙x(t) =
�x(t −�)
1 + x(t −�)N −�x(t) + �(t)
y(t) = x(t) + �(t)
where �, �are constants, N is a positive integer with �and �zero-mean,
white Gaussian with covariances, R��and R��. For the parameter set: �= 0.2,
�= 0.1, �= 7, and N = 10 with x(0) = 1.2
(a) Develop the LZ-BP for this process.
(b) Develop the XBP for this process.
(c) Develop the IX-BP for this process.
5.13
Consider the problem of estimating a random signal from an AM modulator
characterized by
s(t) =
√
2Pa(t) sin �ct
r(t) = s(t) + �(t)

200
CLASSICAL BAYESIAN STATE–SPACE PROCESSORS
where a(t) is assumed to be a Gaussian random signal with power spectrum
Saa(�) = 2kaPa
�2 + k2
a
also assume that the processes are contaminated with the usual additive noise
sources: �and �zero-mean, white Gaussian with covariances, R��and R��.
(a) Develop the continuous-time Gauss–Markov model for this process.
(b) Develop the corresponding discrete-time Gauss–Markov model for this
process using irst differences.
(c) Develop the BP.
(d) Assume the carrier frequency, �c is unknown. Develop the XBP for this
process.

6
MODERN BAYESIAN
STATE–SPACE PROCESSORS
6.1
INTRODUCTION
In this chapter, we discuss an extension of the approximate nonlinear Bayesian suite
of processors that takes a distinctly different approach to the nonlinear Gaussian
problem. Instead of attempting to improve on the linearized approximation in the
nonlinear XBP (EKF) schemes discussed in the previous chapter or increasing the
order of the Taylor series approximations [1–11], a modern statistical (linearization)
transformation approach is developed. It is founded on the idea that “it is easier to
approximate a probability distribution, than to approximate an arbitrary nonlinear
function of transformation” [3, 12–21]. The classical nonlinear Bayesian processors
discussed so far are based on linearizing nonlinear functions of the state and mea-
surements to provide estimates of the underlying statistics (using Jacobians), while
the statistical transformation approach is based on selecting a set of sample points
that capture certain properties of the underlying distribution. This transformation is
essentially a “statistical linearization” technique that incorporates the uncertainty of
the prior random variable when linearizing [12]. This set of sample points is then
nonlinearly transformed or propagated to a new space. The statistics of the new
samples are then calculated to provide the required estimates. Note that this method
differs from the sampling–resampling approach, in which random samples are drawn
from the prior distribution and updated through the likelihood function to produce
a sample from the posterior distribution [22]. Here the samples are not drawn at
random, but according to a speciic deterministic algorithm. Once this transformation
is performed, the resulting processor, the sigma-point Bayesian processor (SPBP) or
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
201

202
MODERN BAYESIAN STATE–SPACE PROCESSORS
equivalently the unscented Kalman ilter (UKF) evolves. It is a recursive processor
that resolves some of the approximation issues [14] and deiciencies of the XBP of
the previous sections. We irst develop the idea of nonlinearly transforming a random
vector with known probability distribution and then apply it to a Gaussian problem
leading to the SPBP algorithm. We then apply the modern processor to the previous
nonlinear state estimation problem and compare its performance to the classical.
Another approach to Bayesian processing problem is the ensemble Bayesian pro-
cessor (EnBP) popularly called the ensemble Kalman ilter (EnKF) approximation for
large-scale computational problems. It has been shown that the EnKF provides a sim-
ple implementation along with numerical stability because of its properties [23–32].
It provides an alternative mechanism to estimate the required posterior distribution
based on generating an ensemble of model state estimates along with associated
uncertainties.
6.2
SIGMA-POINT (UNSCENTED) TRANSFORMATIONS
A completely different approach to nonlinear estimation evolves from the concept of
statistical linearization [3, 16, 19, 33]. Instead of approximating the nonlinear process
and measurement dynamics of the underlying system using a truncated Taylor series
representation that leads to the classical forms of estimation (LZKF, EKF, IEKF,
etc.), the statistical approximation or equivalently statistical linearization method
provides an alternative that takes into account the uncertainty or probabilistic spread
of the prior random vector. The basic idea is to approximate (linearize) a nonlinear
function of a random vector while preserving its irst and second moments; therefore,
this approach requires a priori knowledge of its distribution resulting in a more
statistically accurate transformation.
6.2.1
Statistical Linearization
Following Gelb [3], statistical linearization evolves from the idea of propagating
an Nx-dimensional random vector x with PDF pX(x) through an arbitrary nonlinear
transformation a[⋅] to generate a new random vector,
y = a[x]
(6.1)
Expanding this function in a Taylor series about xi gives
a[x] = a[xi] + (x −xi)′∇xa[xi] + H.O.T.
(6.2)
where ∇x is the Nx-gradient vector deined by
∇xa[xi] := �a[x]
�x
||||x=xi
(6.3)

6.2
SIGMA-POINT (UNSCENTED) TRANSFORMATIONS
203
Neglecting the H.O.T and simplifying with the appropriate deinitions, we obtain
the “regression form” of y regressing on x
y = a[x] ≈Ax + b
(6.4)
where both A, b are to be determined, given x ∼pX(x). Estimation of A, b follows
from the traditional linear algebraic perspective by deining the approximation or
linearization error as
�:= y −Ax −b = a[x] −Ax −b
(6.5)
along with the corresponding cost function
J�:= E{�′�}
(6.6)
that is minimized with respect to the unknowns A, b. Performing the usual differ-
entiation of the cost function, J�→J�(A, b), with respect to the unknowns, setting
the results to zero and solving generates the MMSE result discussed previously in
Chapter 2. That is, we irst minimize with respect to b
∇bJ�(A, b) = ∇bE{�′�} = E{∇b(y −Ax −b)′�} = 0
(6.7)
Now using the chain rule of Eq. 2.11 with a′ = (y −Ax −b)′ and b = �, we obtain
∇bJ�(A, b) = E{∇b(y −Ax −b)′�} = −2E{(y −Ax −b)} = 0
Solving for b, we obtain
b = �y −A�x
(6.8)
Furthermore, substituting for b into the cost and differentiating with respect to A,
setting the result to zero and solving yields
∇AJ�(A, b)||b=�y−A�x = E{A(x −�x)(x −�x)′ + (y −�y)(x −�x)′} = 0
giving
AE{(x −�x)(x −�x)′} = E{(y −�y)(x −�x)′}
or
ARxx = Ryx

204
MODERN BAYESIAN STATE–SPACE PROCESSORS
that has the MMSE solution
A = RyxR−1
xx = R′
xyR−1
xx
(6.9)
Now suppose we linearize the function through this relation by constructing a linear
regression between a selected set of Nx-points and the nonlinear transformation a[x]
at these selected points. That is, deine the set of the selected points as {i, i} with
i = a[i]
Following the same approach as before by deining the “pointwise” linearization
error as gives
�i = i −Ai −b = a[i] −Ai −b
(6.10)
with
��= 0,
and
R��= Ryy −ARxxA′
(6.11)
Performing a weighted minimization (as above) on the pointwise linearization error
with a set of regression weights, {Wi}; i = 1, … , Nx yields the following solution:
A = R′
xyR−1
xx ,
b = �y −A�x
(6.12)
where the weighted statistics are given by
�x =
Nx
∑
i=1
Wii
Rxx =
Nx
∑
i=1
Wi(i −�x)(i −�x)′
(6.13)
and for the posterior
�y =
Nx
∑
i=1
Wii
Ryy =
Nx
∑
i=1
Wi(i −�y)(i −�y)′
(6.14)
with the corresponding cross-covariance
Rxy =
Nx
∑
i=1
Wi(i −�x)(i −�y)′
(6.15)

6.2
SIGMA-POINT (UNSCENTED) TRANSFORMATIONS
205
Nonlinear
transformation  
Sigma points
FIGURE 6.1
Unscented transformation: A set of distribution points shown on an error
ellipsoid are selected and transformed into a new space where their underlying statistics
are estimated.
With this underlying regression and pointwise transformation in place, the next step
is to determine the corresponding set of regression (sigma) points {i} and their
corresponding weights, {Wi}.
6.2.2
Sigma-Point Approach
The sigma-point transformation (SPT), or equivalently unscented transformation
(UT), is a technique for calculating the statistics of a random vector that has been
nonlinearly transformed. The approach is illustrated in Fig. 6.1. Here the set of sam-
ples or so-called sigma points are chosen so that they capture the speciic properties
of the underlying distribution. In the igure, we consider pX(x) to be a 2D-Gaussian,
then the �-points are located along the major and minor axes of the covariance ellipse
capturing the essence of this distribution. In general, the goal is to construct a set
of �-points possessing the same statistics as the original distribution such that when
nonlinearly transformed to the new space, the new set of points suficiently capture
the posterior statistics. The transformation occurs on a point-by-point basis, since
it is simpler to match statistics of individual points rather than the entire PDF. The
statistics of the transformed points are then calculated to provide the desired estimates
of the transformed distribution.
Following the development of Julier [15], consider propagating an Nx-dimensional
random vector x through an arbitrary nonlinear transformation a[⋅] to generate a new
random vector,
y = a[x]
(6.16)
The set of �-points {i} consists of N�+ 1 vectors with appropriate weights {Wi}
given by Σ = {i, Wi; i = 0, … , N�}. The weights can be positive or negative but must
satisfy the normalization constraint
N�
∑
i=0
Wi = 1

206
MODERN BAYESIAN STATE–SPACE PROCESSORS
so that the estimate of the statistics remains unbiased. The problem then becomes:
GIVEN the �-points Σ = {i, Wi; i = 0, … , N�} and the nonlinear transformation
a[x], FIND the statistics of the transformed samples,
�y = E{y}
and
Ryy = Cov(y)
The sigma-point (unscented) transformation (SPT) approach to approximate the
statistics, (�y, Ryy) is
1. Determine the number, weights, and locations of the �-point set, Σ, based on
the unique characteristics of the prior distribution.
2. Nonlinearly transform each point to obtain the set of new (posterior) �-points,
{i}:
i = a[i]
(6.17)
3. Estimate the posterior mean by its weighted average1
�y =
N�
∑
i=0
Wii
(6.18)
4. Estimate the posterior covariance by its weighted outer product
Ryy =
N�
∑
i=0
Wi(i −�y)(i −�y)′
(6.19)
One set of �-points that satisies the above conditions consists of a symmetric set
of N�+ 1 points that lie on the
√
Nx-th covariance contour [13]:
o = �x,
Wo = 1
Nx
i = �x +
√
Nx�i,
Wi =
1
2Nx
i+Nx = �x −
√
Nx�i,
Wi+Nx =
1
2Nx
where
√
Nx �i is the ith standard deviation scaled by
√
Nx and Wi is the weight
associated with the ith �-point.
1 Note that this estimate is actually a weighted statistical linear regression (WSLR) of the random variable
[19].

6.2
SIGMA-POINT (UNSCENTED) TRANSFORMATIONS
207
Thus, the SPT can be considered a statistical linearization method that provides an
optimal (MMSE) linear approximation to a general nonlinear transformation taking
into account the prior second-order statistics of the underlying random variable, that
is, its mean and covariance [19]. It can be accomplished using the weighted statistical
linear regression approach (WSLR) [16, 19], resulting in the weight-constrained
estimates above.
Therefore, in contrast to random sampling, selection of the “deterministic” �-
points requires resolving the following critical issues:
r N�+ 1, the number of �-points;
r Wi, the weights assigned to each �-point; and
r i, the location of the �-points.
That is, we must answer the questions of: How many (points)?, What (weights)? and
Where (located)?
The �-points should be selected or constrained to capture the “most important”
statistical properties of the random vector x. Let the underlying prior pX(x) be its
density function, then the �-points capture the properties by satisfying the necessary
(constraint) condition
g[Σ, pX(x)] = 0
(6.20)
Since it is possible to meet this constraint condition and still have some degree of
freedom in the choice of �-points, assigning a penalty function
p[Σ, pX(x)]
(6.21)
resolves any ambiguity in the choice. This function is to incorporate desirable features
that do not necessarily have to be satisied. Decreasing the penalty function leads to
more and more desirable solutions. In general, the �-point set relative to this problem
that is the most desirable is the set that conforms to the necessary conditions of Eqs.
6.20 and 6.21. The �-points must satisfy
min
Σ p[Σ, pX(x)] ∋g[Σ, pX(x)] = 0
(6.22)
The decision as to which properties of the random vector x to capture precisely or
approximate depends on the particular application. For our problems, we wish to
match the moments of the underlying distribution of �-points with those of x.
Summarizing, to apply the SPT approach, (1) a set of �-points Σ are constructed
that are “deterministically” constrained to possess the identical statistics of the prior;
(2) each �-point is nonlinearly transformed to the new space i; and (3) the statistics
of the transformed set are approximated using WSLR techniques. The following
example illustrates this approach.

208
MODERN BAYESIAN STATE–SPACE PROCESSORS
Example 6.1
Consider a scalar random variable x for which we would like to propagate its irst two
moments (�x,Rxx) through a nonlinear transformation, i = a[i]. The corresponding
set of constraint equations are deined by
g(Σ, pX(x)) =
⎡
⎢
⎢
⎢
⎢⎣
∑N�
i=0 Wi −1
∑N�
i=0 Wii −�x
∑N�
i=0 Wi(i −�x)(i −�x)′ −Rxx
⎤
⎥
⎥
⎥
⎥⎦
= 0
with posterior
�y =
N�
∑
i=0
Wii
Ryy =
N�
∑
i=0
Wi(i −�y)(i −�y)′
Suppose x ∼(0, 1), then the set of �-points are deined by N�+ 1 = 2 + 1
or three points with 0 = �0 = 0, 1 = −�1, and 2 = �2. The constraint equations
become
W0 + W1 + W2 −1 = 0
−W1�1 + W2�2 −0 = 0
W1�2
1 + W2�2
2 −1 = 0
for W0, a free parameter whose value affects the fourth and higher moments. These
relations are not uniquely satisied (four unknowns, three equations); therefore, we
must add another constraint to the set based on the property that the skew is zero for
the Gaussian
−W1�3
1 + W2�3
2 = 0
Solving these equations and using the symmetry property of the Gaussian gives
�1 = 1∕2
√
W1,
W1 = (1 −W0)∕2,
�2 = �1,
W2 = W1
△△△
This example illustrates the use of the constraint equations to determine the
�-points from properties of the prior. Next, let us incorporate the nonlinear transfor-
mation and penalty function to demonstrate the entire selection procedure. Following
Julier [13], consider the following one-dimensional example.

6.2
SIGMA-POINT (UNSCENTED) TRANSFORMATIONS
209
Example 6.2
As before, suppose we have a scalar random variable x, Gaussian distributed with
mean �x and variance �2
x, and we would like to know the statistics (mean and variance)
of y which nonlinearly transforms x according to
y = a[x] = x2
Here the true mean and variance are
�y = E{y} = E{x2} = �2
x + �2
x
and
�2
y = E{y2} −�2
y = E{x4} −�2
y = (3�4
x + 6�2
x�2
x + �4
x) −(�4
x + 2�2
x�2
x + �4
x)
= 2�4
x + 4�2
x�2
x
According to SPT of Eqs. 6.17– 6.19, the number of �-points is N�+ 1 = 3. Since
this is a scalar problem (Nx = 1) only three points are required: the two �-points and
the mean, therefore, we have
{0, 1, 2} = {�x, �x −
√
1 + ��x, �x +
√
1 + ��x}
{W0, W1, W2} = {1∕(1 + �), 1∕2(1 + �), 1∕2(1 + �)}
and �is chosen as a scaling factor to be determined. Propagating these samples
through a[⋅] gives the transformed samples, say ′
i , that lie at
{′
0, ′
1, ′
2} =
{
�2
x, (�x −
√
1 + ��x)2, (�x +
√
1 + ��x)2}
The mean of y is given by
�y =
1
2(1 + �)(2��2
x + 2�2
x + 2(1 + �)�2
x) = �2
x + �2
x
which is precisely the true mean. Next, the covariance is given by
�2
y =
1
2(1 + �)
( 2
∑
i=1
((′
i −�y)2 + 2��4
x)
)
= ��4 + 4�2
x�2
x
To ind the solution, �must be speciied. The kurtosis of the true distribution is 2�4
x
and that of the �-points is �2
x. Since the kurtosis of the points is scaled by an amount
(1 + �), the kurtosis of both distributions only agree when �= 2 which gives the exact
solution. This completes the Gaussian example.
△△△

210
MODERN BAYESIAN STATE–SPACE PROCESSORS
Covariance
Mean
True mean  
True covariance   
Sigma points 
Transformed sigma points   
Sigma point covariance   
Sigma point mean    
Sigma point transformation
Sampling
FIGURE 6.2
Sigma-point (unscented) transformation approximation of the original dis-
tribution moments after nonlinear transformation.
Next using the underlying principles of the SPT, we develop the multivariate
Gaussian case in more detail.
6.2.3
SPT for Gaussian Prior Distributions
To be more precise and parallel the general philosophy, we choose “to approximate
the underlying Gaussian distribution rather than approximate its underlying nonlinear
transformation,” in contrast to the XBP (EKF). This parameterization captures the
prior mean and covariance and permits the direct propagation of this information
through the arbitrary set of nonlinear functions. Here we accomplish this (approxi-
mately) by generating the discrete distribution having the same irst and second (and
potentially higher) moments where each point is directly transformed. The mean and
covariance of the transformed ensemble can then be computed as the estimate of
the nonlinear transformation of the original distribution. As illustrated in Fig. 6.2,
we see samples of the true prior distribution of x and the corresponding nonlinearly
transformed distribution of y. Using the same transformation, the selected �-points
are transformed as well closely preserving the dominant moments of the original
distribution (see Julier [13] for more details).
It is important to recognize that the SPT has speciic properties when the underlying
distribution is Gaussian [16]. The Gaussian has two properties which play a signiicant
role in the form of the �-points selected. First, since the distribution is symmetric, the
�-points can be selected with this symmetry. Second, the problem of approximating x
with an arbitrary mean and covariance can be reduced to that of a standard zero-mean,
unit variance Gaussian, since
x = �x + Us
for U the matrix square root of Rxx
(6.23)

6.2
SIGMA-POINT (UNSCENTED) TRANSFORMATIONS
211
where s ∼(0, I). Therefore, in the Gaussian case, the second-order SPT uses a set
of �-points which captures the irst two moments of s correctly; that is, they must
capture the mean, covariance and symmetry. Let si be the ith component of s, then its
covariance is given by
E{s2
i } = 1
∀i
(6.24)
Also from the symmetry properties of the distribution, all odd-ordered moments are
zero.
The minimum number of points whose distribution obeys these conditions has
two types of �-points: (1) a single point at the origin of the s-axis with weight Wo
and (2) 2Nx symmetrically distributed points on the coordinate s-axis at a distance r
from the origin all having the same weight W1. Thus, there are 2Nx + 1 �-points for a
two-dimensional distribution. The values of Wo, W1, and r are selected to ensure that
their covariance is the identity. Therefore, due to their symmetry, it is only necessary
to specify one direction on the s-axis, say s1. The constraint function will consist of
the moment for E{s2
1} and the normalization condition must be satisied. Therefore,
we have
g[�, pX(s)] =
(
2W1r2 −1
Wo + 2NxW1 −1
)
= 0
(6.25)
The solution to these equations is given by
r =
1
√
2W1
and
Wo = 1 −2NxW1,
Wofree
(6.26)
By reparameterizing W1 :=
1
2(Nx + �), it can be shown that after pre-multiplying by U,
the matrix square root of Rxx, that the �-points for x are
o = �x,
Wo =
�
(Nx + �)
i = �x + (
√
(Nx + �)Rxx)i,
Wi =
1
2(Nx + �)
i+Nx = �x −(
√
(Nx + �)Rxx)i,
Wi+Nx =
1
2(Nx + �)
where �is a scalar, (
√
(Nx + �)Rxx)i is the ith row or column of the matrix square root
of (Nx + �)Rxx and Wi is the weight associated with the ith �-point. The parameter �is
free; however, it can be selected to minimize the mismatch between the fourth-order
moments of the �-points and the true distribution [16]. From the properties of the
Gaussian, we have
E{s4
i } = 3
∀i
(6.27)

212
MODERN BAYESIAN STATE–SPACE PROCESSORS
The penalty function penalizes the discrepancy between the �-points and the true
value along one direction (s1), in this case, due to the symmetry. Therefore, we have
p[�, pX(s)] = |2W1r4 −3|
giving W1 =
3
2r4 = 1
6
or
�= 3 −Nx (6.28)
It is clear that the ability to minimize p depends on the number of degrees of freedom
that are available after the constraint g is satisied for the given set of �-points;
the kurtosis cannot be matched exactly without developing a larger set of �-points
(see Julier [16] for details).
We summarize the sigma-point processor under the multivariate Gaussian assump-
tions: Given an Nx-dimensional Gaussian distribution having covariance Rxx, we can
generate a set of O(N�)�-points having the same sample covariance from the columns
(or rows) of the matrices ±
√
(Nx + �)Rxx. Here �is the scaling factor discussed pre-
viously. This set is zero-mean, but if the original distribution has mean �x, then
simply adding �x to each of the �-points yields a symmetric set of 2Nx + 1 samples
having the desired mean and covariance. Since the set is symmetric, its odd central
moments are null; so its irst three moments are identical to those of the original
Gaussian distribution. This is the minimal number of �-points capable of captur-
ing the essential statistical information. The basic SPT technique for a multivariate
Gaussian distribution [16] is therefore
1. Determine the set of 2Nx + 1 �-points from the rows or columns of
±
√
(Nx + �)Rxx. For the nonzero-mean case, compute i = �+ �x;
o = �x,
Wo =
�
(Nx + �)
i = �x +
(√
(Nx + �)Rxx
)
i ,
Wi =
1
2(Nx + �)
i+Nx = �x −
(√
(Nx + �)Rxx
)
i ,
Wi+Nx =
1
2(Nx + �)
where �is a scalar,
(√
(Nx + �)Rxx
)
i is the ith row or column of the matrix
square root of (Nx + �)Rxx, and Wi is the weight associated with the ith �-point;
2. Nonlinearly transform each point to obtain the set of new �-points: i = a[i]
3. Estimate the posterior mean of the new samples by its weighted average (regres-
sion)
�y =
2Nx
∑
i=0
Wii

6.3
SIGMA-POINT BAYESIAN PROCESSOR (UNSCENTED KALMAN FILTER)
213
4. Estimate the posterior covariance of the new samples by its weighted outer
product (regression)
Ryy =
2Nx
∑
i=0
Wi(i −�y)(i −�y)′
There is a wealth of properties of this processor:
1. The transformed statistics of y are captured precisely up to the second order.
2. The �-points capture the identical mean and covariance regardless of the choice
of matrix-square-root method.
3. The posterior mean and covariance are calculated using standard linear alge-
braic methods (WSLR) and it is not necessary to evaluate any Jacobian as
required by the XBP methods.
4. �is a “tuning” parameter used to tune the higher order moments of the approxi-
mation that can be used to reduce overall prediction errors. For x, a multivariate
Gaussian, �= 3 −Nx is a useful heuristic.
5. A modiied form for �→�= �2(Nx + �) −Nx (scaled transform) can be used
to overcome a nonpositive deiniteness of the covariance. Here �controls the
spread of the �-points around �x and is typically set to a value 0.01 ≤�≤1 with
�, a secondary scaling parameter, set to 0 or 3 −Nx and �is an extra degree
of freedom to incorporate any extra prior knowledge of the pX(x) with �= 2
for Gaussian distributions. In this case, the weights change and are given by
W(m)
0
=
�
Nx+�, W(c)
0 =
�
Nx + �+ (1 −�2 + �), and W(m)
i
=
1
(Nx+�) [17, 21, 33].
6. Note that although statistical linearization offers a convenient way to interpret
the subsequent sigma-point approach, it does not indicate some of its major
advantages, especially since it is possible to extend the approach to incorporate
more points capturing and accurately propagating higher order moments [33].
Next, we apply the �-point approach to the nonlinear iltering problem by deining
the terms in the SPT and showing where the statistical approximations are utilized.
6.3
SIGMA-POINT BAYESIAN PROCESSOR (UNSCENTED
KALMAN FILTER)
The SPBP or UKF is a recursive processor developed to eliminate some of the dei-
ciencies created by the failure of the irst- order (Taylor series) linearization process in
solving the state estimation problem. Different from the XBP (EKF), the sigma-point
processor does not approximate the nonlinear process and measurement models; it
employs the true nonlinear models and approximates the underlying Gaussian distri-
bution function of the state variable using a statistical linearization approach leading
to a set of regression equations for the states and measurements. In the sigma-point

214
MODERN BAYESIAN STATE–SPACE PROCESSORS
processor, the state is still represented as Gaussian, but it is speciied using the min-
imal set of deterministically selected samples or �-points. These points completely
capture the true mean and covariance of the prior Gaussian distribution. When they
are propagated through the nonlinear process, the posterior mean and covariance
are accurately captured for any nonlinearity with errors introduced only in the third-
and higher order moments. This is the statistical linearization using the weighted
(statistical) linear regression approximation (WSLR) discussed previously [16].
We use the XBP (EKF) formulation and its underlying statistics as our prior
distribution speciied by the following nonlinear model with the conditional Gaussian
distributions. Recall that the original discrete nonlinear process model is given by
x(t) = a[x(t −1)] + b[u(t −1)] + �(t −1)
(6.29)
with the corresponding measurement model
y(t) = c[x(t)] + �(t)
(6.30)
for �∼(0, R��) and �∼(0, R��). It was demonstrated previously (Section 5.3)
that the critical conditional Gaussian distribution for the state variable statistics was
the prior
Pr(x(t)|Yt−1) = (̂x(t|t −1), ̃P(t|t −1))
with the measurement statistics speciied by
Pr(y(t)|Yt−1) = (̂y(t|t −1), R��(t|t −1))
where ̂x(t|t −1), and ̃P(t|t −1) are the respective predicted state and error covariance
based upon the data up to time (t −1) and ̂y(t|t −1), R��(t|t −1) are the predicted
measurement and residual covariance. The idea is to use the “prior” statistics and
perform the SPT (under Gaussian assumptions) using both the process and mea-
surement nonlinear transformations (models) as speciied above yielding the corre-
sponding set of �-points in the new space. The predicted means are weighted sums
of the transformed �-points and the covariances are merely weighted sums of their
mean-corrected, outer products, that is, they are speciically the WSLR discussed in
Section 6.2.
To develop the sigma-point processor we must:
r PREDICT the next state and error covariance, (̂x(t|t −1), ̃P(t|t −1)), by SPT-
transforming the prior, (̂x(t −1|t −1), ̃P(t −1|t −1)), including the process
noise using the �-points, i(t|t −1) and i(t −1|t −1), respectively;
r PREDICT the measurement and residual covariance, [̂y(t|t −1), R��(t|t −1)] by
using the SPT-transformed �-points i(t|t −1), and performing the weighted
regressions; and

6.3
SIGMA-POINT BAYESIAN PROCESSOR (UNSCENTED KALMAN FILTER)
215
r PREDICT the cross-covariance, R̃x�(t|t −1) in order to calculate the correspond-
ing gain for the subsequent update step.
We use these steps as our road map to develop the sigma-point processor depicted
in the block diagram of Fig. 6.3. We start by deining the set Σ and selecting the
corresponding 2Nx + 1 �-points and weights according to the multivariate Gaussian
distribution selection procedure developed in the previous section. That is, the points
are deined by substituting the �-points for the SPT transformation of the “prior”
state information speciied by �x = ̂x(t −1|t −1) and Rxx = ̃P(t −1|t −1). We deine
the set of �-points and weights as
o = �x = ̂x(t −1|t −1),
Wo =
�
(Nx + �)
i = �x +
(√
(Nx + �)Rxx
)
i
= ̂x(t −1|t −1) +
(√
(Nx + �)̃P(t −1|t −1)
)
i
,
Wi =
1
2(Nx + �)
i+Nx = �x −
(√
(Nx + �)Rxx
)
i
= ̂x(t −1|t −1) −
(√
(Nx + �)̃P(t −1|t −1)
)
i
,
Wi+Nx =
1
2(Nx + �)
Next, we perform the state prediction step to obtain, {i(t|t −1), ̂x(t|t −1)}, trans-
forming each �-point using the nonlinear process model to the new space, that is, to
obtain the one-step state prediction as
i(t|t −1) = a[i(t −1|t −1)] + b[u(t −1)]
(6.31)
The WSLR approximation step to obtain the predicted mean follows from the
statistical linearization transformation model using the following relations: y →x(t),
x →x(t −1), A →A(t −1), b →b(t −1) and �→�(t −1) of Eq. 6.4
x(t) = A(t −1)x(t −1) + b(t −1)
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
Linear approximation
+
�(t −1)
⏟⏟⏟
Linearization error
(6.32)
Conditioning Eq. 6.32 on Yt−1 and taking expectations, we have
̂x(t|t −1) = E{x(t)|Yt−1} = E{A(t −1)x(t −1)|Yt−1} + E{b(t −1)|Yt−1}
+ E{�(t −1)|Yt−1}
or
̂x(t|t −1) = A(t −1)̂x(t −1|t −1) + b(t −1)
(6.33)

216
MODERN BAYESIAN STATE–SPACE PROCESSORS
Using this linearized form, with the conditional means replacing the unconditional,
that is, �y →̂x(t|t −1) and �x →̂x(t −1|t −1), we have from Eq. 6.8 that
b(t −1) →̂x(t|t −1) −A(t −1)̂x(t −1|t −1)
=
2Nx
∑
i=0
Wii(t|t −1) −A(t −1)̂x(t −1|t −1)
(6.34)
where we substituted the regression of Eq. 6.14 for �y. Substituting this expression
for b above gives the required regression relation
̂x(t|t −1) = A(t −1)̂x(t −1|t −1) +
2Nx
∑
i=0
Wii(t|t −1) −A(t −1)̂x(t −1|t −1)
=
2Nx
∑
i=0
Wii(t|t −1)
(6.35)
yielding the predicted state estimate using the WSLR approach shown in Fig. 6.3.
Next let us deine the predicted state estimation error as
̃i(t|t −1) := i(t|t −1) −̂x(t|t −1)
(6.36)
Initialize
STATE
(Sigma Points & Weights)
STATE PREDICTION
(NL Process & State Regression)
STATE ERROR 
PREDICTION
(Covariance Regression)
MEASUREMENT
(Sigma Points & Weights)
MEASUREMENT 
PREDICTION
(NL Measurement & Regression
RESIDUAL 
PREDICTION
(Covariance Regression)
GAIN
(Cross-Covariance Regression)
UPDATE
(Innovations, State, Error Covariance)
FIGURE
6.3
Sigma-point Bayesian processor block diagram with �-points and
regressions.

6.3
SIGMA-POINT BAYESIAN PROCESSOR (UNSCENTED KALMAN FILTER)
217
therefore, the corresponding predicted state error covariance
̃P(t|t −1) := cov[ ̃i(t|t −1)] = cov[i(t|t −1) −̂x(t|t −1)]
can be calculated from
̃P(t|t −1) = cov[(A(t −1)i(t −1|t −1) + b(t −1) + �i(t −1))
−(A(t −1)̂x(t −1|t −1) + b(t −1))]
= cov[A(t −1) ̃i(t −1|t −1) + �i(t −1)]
Performing this calculation gives the expression
̃P(t|t −1) = A(t −1)̃P(t −1|t −1)A′(t −1) + R��(t −1)
(6.37)
which can also be written in the regression form by using the relations from Eq. 6.11
with y →i, Ryy →̃P. Therefore, substituting for ÃPA′ above, we have
̃P(t|t −1) = ̃P(t|t −1) −R��(t −1) + R��(t −1)
=
2Nx
∑
i=0
Wi ̃i(t|t −1) ̃′
i (t|t −1)
(6.38)
In the case of additive, zero-mean, white Gaussian noise with covariance,
R��(t −1), we have the inal WSLR
̃P(t|t −1) =
2Nx
∑
i=0
Wi ̃i(t|t −1) ̃′
i (t|t −1) + R��(t −1)
(6.39)
completing the state error prediction step of Fig. 6.3.
Here, the Bayesian processor approximates the predicted density, (̂x(t|t −1),
̃P(t|t −1)), where
pX(x(t)|Yt−1) = ∫pX(x(t)|x(t −1))pX(x(t −1)|Yt−1)dx(t −1)
(6.40)
Next, we calculate a new set of �-points to relect the prediction step and perform
the SPT in the measurement space as
̂i(t|t −1) = {i(t|t −1), i(t|t −1) + �
√
R��(t −1), i(t|t −1) −�
√
R��(t −1)}
(6.41)
We linearize the measurement function similar to the nonlinear process function in
the previous steps. We use the nonlinear measurement model to propagate the “new”

218
MODERN BAYESIAN STATE–SPACE PROCESSORS
�-points to the transformed space producing the measurement prediction step shown
in Fig. 6.3.
i(t|t −1) = c[ ̂i(t|t −1)]
(6.42)
The WSLR is then performed to obtain the predicted measurement, that is,
y(t) = C(t)x(t) + b(t) + �(t)
(6.43)
Conditioning on Yt−1, as before, and taking expectations of Eq. 6.43 gives
̂y(t|t −1) = E{y(t)|Yt−1} = C(t)̂x(t|t −1) + b(t)
(6.44)
Using this linearized form with the conditional means replacing the unconditional,
that is, �y →̂y(t|t −1), A →C, b →b and �x →̂x(t|t −1), we have from Eq. 6.8 that
b(t) →̂y(t|t −1) −C(t)̂x(t|t −1) =
2Nx
∑
i=0
Wii(t|t −1) −C(t)̂x(t|t −1) (6.45)
where we substituted the regression of Eq. 6.14 for �y. Substituting this expression
for b above gives the WSLR relation
̂y(t|t −1) = C(t)̂x(t|t −1) +
2Nx
∑
i=0
Wii(t|t −1) −C(t)̂x(t|t −1)
=
2Nx
∑
i=0
Wii(t|t −1)
(6.46)
yielding the predicted measurement estimate of Fig. 6.3.
Similarly, the residual (measurement) error is deined by
�i(t|t −1) := i(t|t −1) −̂y(t|t −1)
(6.47)
and therefore the residual (predicted) covariance can be expressed as
R��(t|t −1) = cov[�i(t|t −1)] = cov[i(t|t −1) −̂y(t|t −1)]
Substituting the linearized model above, we obtain
R��(t|t −1) = cov[(C(t)i(t|t −1) + b(t) + �i(t))
−(C(t)̂x(t|t −1) + b(t))]
= cov[C(t −1) ̃i(t|t −1) + �i(t)]

6.3
SIGMA-POINT BAYESIAN PROCESSOR (UNSCENTED KALMAN FILTER)
219
Performing this calculation gives the expression
R��(t|t −1) = C(t)̃P(t|t −1)C′(t) + R��(t)
(6.48)
which can also be written in the regression form by using the relations from Eq. 6.11
with y →�i, Ryy →̃P��. Therefore, substituting for C ̃PC′ above, we have
R��(t|t −1) = ̃P��(t|t −1) −R��(t) + R��(t) =
2Nx
∑
i=0
Wi�i(t|t −1)�′
i(t|t −1)
(6.49)
In the case of additive, zero-mean, white Gaussian noise with covariance, R��(t)
we have the inal WSLR
R��(t|t −1) =
2Nx
∑
i=0
Wi�i(t|t −1)�′
i(t|t −1) + R��(t)
(6.50)
completing the measurement residual prediction step of Fig. 6.3.
The gain is estimated from
(t) = R̃x�(t|t −1)R−1
��(t|t −1)
(6.51)
where the cross error covariance is approximated using the WSLR as (above)
R̃x�(t|t −1) =
2Nx
∑
i=0
Wi ̃i(t|t −1)�′
i(t|t −1)
(6.52)
With this in mind, it is clear that the posterior distribution can be calculated from
pX(x(t)|Yt) ∼(̂x(t|t), ̃P(t|t)) = ∫pX(x(t)|x(t −1))
× pX(x(t −1)|Yt)dx(t −1)
(6.53)
where we have the “usual” (Kalman) update relations of Fig. 6.3 starting with the
innovations
e(t) = y(t) −̂y(t|t −1)
(6.54)
and the state update
̂x(t|t) = ̂x(t|t −1) + (t)e(t)
(6.55)
along with the corresponding state error covariance update given by
̃P(t|t) = ̃P(t|t −1) −(t)R��(t|t −1)′(t)
(6.56)

220
MODERN BAYESIAN STATE–SPACE PROCESSORS
This completes the SPBP algorithm which is summarized in Table 6.1. We have
shown how the SPT coupled with the WSLR can be used to develop this technique in
its “plain vanilla” form. We note in passing that there are no Jacobians calculated and
the nonlinear models are employed directly to transform the �-points to the new space.
Also in the original problem deinition (see Section 2) both process and noise sources
(�, �) were assumed additive. The SPT enables us to “generalize” the noise terms to
also be injected in a nonlinear manner (e.g., multiplication). Thus, the noise is not
treated separately, but can be embedded into the problem by deining an augmented
state vector, say x(t) = [x(t) �(t −1) �(t)]′. We chose to ignore the general case to
keep the development of the sigma-point processor simple. For more details of the
general process, see Refs. [17], [21], and [33]. Let us apply the sigma-point processor
to the nonlinear trajectory estimation problem and compare its performance to the
other nonlinear processors discussed previously.
Example 6.3
We revisit the nonlinear trajectory estimation problem of the previous examples with
the dynamics speciied by the discrete nonlinear process given by
x(t) = (1 −0.05ΔT)x(t −1) + 0.04ΔTx2(t −1) + �(t −1)
and corresponding measurement model
y(t) = x2(t) + x3(t) + �(t)
Recall that �(t) ∼(0, 0.09), x(0) = 2.0, P(0) = 0.01, ΔT = 0.01 sec and R��= 0. The
simulated measurement is shown in Fig. 6.4b. The sigma-point processor (SPBP) and
XBP ( EKF) and IX-BP (IEKF) (three iterations) were applied to this problem. We
used the square-root implementations of the XBP and IX-BP in SSPACK_PC [10],
and compared them to the sigma-point processor in REBEL [33]. The results are
shown in Fig. 6.4 where we see the corresponding trajectory (state) estimates in (a)
and the “iltered” measurements in (b). From the igures, it appears that all of the
estimates are quite reasonable with the sigma-point processor estimate (thick solid
line) converging most rapidly to the true trajectory (dashed line). The XBP (thick
dotted line) appears slightly biased while the IX-BP (thin dotted line) converges
rapidly, but then wanders slightly from the truth. The measurements also indicate a
similar performance. The zero-mean/whiteness tests conirm these observations. The
XBP and IX-BP perform similarly with respective zero-mean/whiteness values of
(1.04 × 10−1 < 1.73 × 10−1∕1% out) and (3.85 × 10−2 < 1.73 × 10−1∕0% out), while
the sigma-point processor is certainly comparable at (5.63 × 10−2 < 1.73 × 10−1∕0%
out). This completes the example.
△△△

6.3
SIGMA-POINT BAYESIAN PROCESSOR (UNSCENTED KALMAN FILTER)
221
TABLE 6.1
Discrete Sigma-Point Bayesian Processor (Unscented Kalman Filter)
Algorithm
State: Sigma Points and Weights
o = ̂x(t −1|t −1),
Wo =
�
(Nx + �)
i = ̂x(t −1|t −1) +
(√
(Nx + �)̃P(t −1|t −1)
)
i ,
Wi =
1
2(Nx + �)
i+Nx = ̂x(t −1|t −1) −
(√
(Nx + �)̃P(t −1|t −1)
)
i ,
Wi+Nx =
1
2(Nx + �)
State Prediction
i(t|t −1) = a[i(t −1|t −1)] + b[u(t −1)]
[Nonlinear state process]
̂x(t|t −1) =
2Nx
∑
i=0
Wii(t|t −1)
[State regression]
State Error Prediction
̃i(t|t −1) = i(t|t −1) −̂x(t|t −1)
[State error]
̃P(t|t −1) =
2Nx
∑
i=0
Wi ̃i(t|t −1) ̃′
i (t|t −1) + R��(t −1)
[Error covariance prediction]
Measurement: Sigma Points and Weights
̂i(t|t −1) = {i(t|t −1), i(t|t −1) + �
√
R��(t −1), i(t|t −1) −�
√
R��(t −1)}
Measurement Prediction
i(t|t −1) = c[ ̂i(t|t −1)]
[Nonlinear measurement]
̂y(t|t −1) =
2Nx
∑
i=0
Wii(t|t −1)
[Measurement regression]
Residual Prediction
�i(t|t −1) = i(t|t −1) −̂y(t|t −1)
[Predicted residual]
R��(t|t −1) =
2Nx
∑
i=0
Wi�i(t|t −1)�′
i(t|t −1) + R��(t)
[Residual covariance regression]
Gain
R̃x�(t|t −1) =
2Nx
∑
i=0
Wi ̃i(t|t −1)�′
i(t|t −1)
[Cross-covariance regression]
(t) = R̃x�(t|t −1)R−1
��(t|t −1)
[Gain]
State Update
e(t) = y(t) −̂y(t|t −1)
[Innovation]
̂x(t|t) = ̂x(t|t −1) + (t)e(t)
[State update]
̃P(t|t) = ̃P(t|t −1) −(t)R��(t|t −1)′(t)
[Error covariance update]
Initial Conditions
̂x(0|0)
̃P(0|0)

222
MODERN BAYESIAN STATE–SPACE PROCESSORS
20
40
60
80
100
120
140
11.5
12
12.5
13
13.5
14
Sample No.
1.98
2
2.02
2.04
2.06
2.08
2.1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
-0.2
0
0.2
0.4
0.6
0.8
1
SRUKF
Lags
0
0.2
0.4
0.6
0.8
1
IEKF
0
0.2
0.4
0.6
0.8
1
1.2
EKF
(a)
(b)
(c)
(d)
(e)
FIGURE 6.4
Nonlinear trajectory estimation: (a) trajectory (state) estimates using
the XBP (thick dotted), IX-BP (thin dotted) and SPBP (thick solid); (b) iltered mea-
surement estimates using the XBP (thick dotted), IX-BP (thin dotted), and SPBP
(thick solid); (c) zero-mean/whiteness tests for XBP (1.04 × 10−�< 1.73 × 10−�/1% out);
(d) zero-mean/whiteness tests for IX-BP (3.85 × 10−�< 1.73 × 10−�/0% out); (e) zero-
mean/whiteness tests for SPBP (5.63 × 10−�< 1.73 × 10−�/0% out).
6.3.1
Extensions of the Sigma-Point Processor
Recently there have been a number of developments in the nonlinear estimation area
that are based on the sigma-point (or similar) transformation [34, 35, 36]. Next,
we briely mention these approaches keeping in mind that they are members of the
“sigma-point family”.
The central difference Bayesian processor (CDBP) or unscented Kalman ilter
(UKF) is based on the Stirling approximation interpolation formula that is essentially
a second-order Taylor series expansion of the nonlinear random function about its
mean. The central differences are used to approximate the irst- and second- order
terms of the series. In this sense, the processor implicitly employs the WSLR used
to derive the SPBP as before. The resulting �-points are dependent on the half-step
size △x rather than the other parameters discussed previously. The CDBP is slightly
more accurate than the SPBP, and also has the advantage of only requiring a single
parameter △x to adjust the spread of the �-points. For more details, see Ref. [34].
Just as with the Kalman ilter implementations [10], the SPBP also admits the
numerically stable “square-root” forms for prediction and updated state covariance

6.4
QUADRATURE BAYESIAN PROCESSORS
223
matrices. These methods are based on employing the QR decomposition and Cholesky
updating. Again, this approach offers a slightly more accurate processor as well as
reduced computational costs while maintaining their numerical stability. See Ref.
[34] for further details.
6.4
QUADRATURE BAYESIAN PROCESSORS
The grid-based quadrature Bayesian processor ( QBP) or equivalently quadrature
Kalman ilter (QKF) is another alternative �-point approach [35–37]. It uses the
Gauss–Hermite numerical integration rule as its basic building block to precisely
calculate the sequential Bayesian recursions of Chapter 2 under the Gaussian assump-
tions. For scalars, the Gauss–Hermite rule is given by
1
√
2�∫
∞
−∞
f(x)e−x2dx =
M
∑
i=1
Wi × f(Δxi)
(6.57)
where equality holds for all polynomials f(⋅) of degree up to 2M −1 and the quadrature
(grid) points Δxi with corresponding weights Wi are determined according to the rule.
The QBP uses the WSLR to linearize the nonlinear transformations through a set of
Gauss–Hermite quadrature points rather than introducing the set of �-points. Details
of this approach can be found in Ref. [36]. We briely show the approach following the
usual recursive forms of the BP of the previous chapter. For our nonlinear estimation
problem, we have both nonlinear process (a[⋅]) and measurement (c[⋅]) equations that
can be expressed in terms of the Gauss–Hermite rule above.
Suppose we have the conditional mean and covariance at time (t −1) based on all
of the data up to the same time step. Then the corresponding conditional distribution
is Pr(x(t −1)|Yt−1) ∼(̂x(t −1|t −1), ̃P(t −1|t −1)). The QBP is then given by the
following set of recursive Bayesian equations:
xi =
√
̃P(t −1|t −1)
′
Δxi + ̂x(t −1|t −1)
(6.58)
where
√
̃P is the matrix square root (Cholesky factor: ̃P =
√
̃P
′√
̃P). The prediction
step: Pr(x(t)|Yt−1) ∼(̂x(t|t −1), ̃P(t|t −1)) is given by
̂x(t|t −1) =
M
∑
i=1
Wia[xi]
̃P(t|t −1) =
M
∑
i=1
Wi(a[xi] −̂x(t|t −1))(a[xi] −̂x(t|t −1))′ + R��(t −1)
(6.59)

224
MODERN BAYESIAN STATE–SPACE PROCESSORS
The update step: Pr(x(t)|Yt) ∼(̂x(t|t), ̃P(t|t)) follows a similar development
xi =
√
̃P(t|t −1)
′
Δxi + ̂x(t|t −1)
(6.60)
and
̂x(t|t) = ̂x(t|t −1) + (t)(y(t) −y(t))
for y(t) =
M
∑
i=1
Wic[xi]
̃P(t|t) = ̃P(t|t −1) −(t)XY
(6.61)
where
(t) = XY(YY + R��(t))−1
XY =
M
∑
i=1
Wi(̂x(t|t −1) −xi)(y(t) −c[xi])′
YY =
M
∑
i=1
Wi(y(t) −c[xi])(y(t) −c[xi])′
(6.62)
As with the SPBP, the QBP does not linearize the process or measurement models
as in the case of the classical nonlinear processors. It calculates the weighted quadra-
ture points in state-space over a ixed grid to estimate the unknown distribution
(see Ref. [36–39] for more details).
Another powerful approach to nonlinear estimation is the Gaussian sum (mixture)
processor [40], which we discuss in more detail next.
6.5
GAUSSIAN SUM (MIXTURE) BAYESIAN PROCESSORS
Another general approach to the Bayesian processing problem is the Gaussian sum
(G-S) approximation leading to a processor. It has been shown [4, 40, 41] that any
non-Gaussian distribution can be approximated by a sum of Gaussian distributions,
that is,
pX(x) ≈
Ng
∑
i=1
ipi(x) =
Ng
∑
i=1
i(x : �x(i), Σx(i))
for
Ng
∑
i=1
i = 1 and i ≥0∀i
(6.63)
a mixture of Gaussian distributions with {i} the set of mixing coeficients or
weights. Clearly, this approach can be implemented with a bank of parallel classical
processors ( LZ-BP, XBP, IX-BP) or with any of the modern SPBP family just
discussed, in order to estimate the mean and variance of the individual Ng-processors.

6.5
GAUSSIAN SUM (MIXTURE) BAYESIAN PROCESSORS
225
In addition, the particle iltering algorithms to be discussed in the next chapter can
also be incorporated into a Gaussian mixture (G-M) framework—that is what makes
this approach important [42]. Before we develop the processor, let us investigate some
of the underlying properties of the Gaussian sum or equivalently Gaussian mixture
that makes it intriguing.
The fundamental problem of approximating a probability distribution or density
evolves from the idea of delta families of functions, that is, families of functions that
converge to a delta or impulse function, as the parameter that uniquely characterizes
that family converges to a limiting value. Properties of such families are discussed in
Ref. [41]. The most important result regarding Gaussian sums is given in a theorem,
which states that a probability density function formed by
pX(x) = ∫
∞
−∞
p(�)�(x −�) d�
(6.64)
converges uniformly to pX(x) [41]. The Gaussian density forms a delta family with
parameter �represented by
��(x) = (x : 0, �2) =
1
√
2��2
exp
{
−x2
2�2
}
(6.65)
which satisies the requirement of a positive delta family as �→0, that is, as the
variance parameter approaches zero in the limit, the Gaussian density approaches a
delta function; therefore, we have
pX(x) = ∫
∞
−∞
p(�)�(x −�) d�
(6.66)
This is the key result that forms the underlying basis of Gaussian sum or mixture
approximations, similar to the idea of an empirical probability distribution
̂Pr(x) ≈
Nx
∑
i=1
i�(x −xi) ⇔
̂Pr(x) ≈
Ng
∑
i=1
i(xi : �x(i), Σx(i))
(6.67)
as the variance �x →0. The Gaussian converges to an impulse located at its mean
�x. The Gaussian mixture distributions have some interesting properties that we list
below (see Ref. [40, 41] for more details)
r Mean:
�g = ∑Ng
i=1 i�x(i)
r Covariance: Σg = ∑Ng
i=1 i(Σx(i) + �x(i))
r Skewness:
�g = ∑Ng
i=1 i(�x(i) −�g)(3Σx(i) + (�x(i) −�g)2 × Σ
−3
2
g )
r Kurtosis:
�g = ∑Ng
i=1 i(3Σ2
x(i) + 6(�x(i) −�g)2Σx(i) + �4
g)Σ−2
g −3

226
MODERN BAYESIAN STATE–SPACE PROCESSORS
Next, let us see how this property can be utilized to develop a Bayesian processor.
The processor we seek evolves from the sequential Bayesian paradigm of Section 2.5
given by
Pr(x(t)|Yt) = Pr(y(t)|x(t)) × Pr(x(t)|Yt−1)
Pr(y(t)|Yt−1)
(6.68)
with the corresponding prediction step
Pr(x(t)|Yt−1) = ∫Pr(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1) dx(t −1)
(6.69)
Assume at time t that we approximate the predictive distribution by the Gaussian
mixture
Pr(x(t)|Yt−1) ≈
Ng
∑
i=1
i(t −1)(x(t) : xi(t), Pi(t))
(6.70)
Then substituting this expression into the iltering posterior of Eq. 6.68, we obtain
Pr(x(t)|Yt) = Pr(y(t)|x(t))
Pr(y(t)|Yt−1) ×
Ng
∑
i=1
i(t −1)(x(t) : xi(t), Pi(t))
(6.71)
For clarity in this development we constrain both process and measurement models
to additive Gaussian noise sources2 resulting in the nonlinear state-space approximate
Gauss-Markov representation of Section 4.8, that is, the process model
x(t) = a[x(t −1)] + �(t −1)
�∼(0, R��(t))
(6.72)
and the measurement model
y(t) = c[x(t)] + �(t)
�∼(0, R��(t))
(6.73)
with Gaussian prior, x(0) ∼(x(0), P(0)). Applying the fundamental convergence
theorem of Eq. 6.64, the Gaussian mixture distribution of the posterior can be approx-
imated by
Pr(x(t)|Yt) ≈
Ng
∑
i=1
i(t)(x(t) : xi(t), Pi(t))
(6.74)
2 This is not necessary but enables the development and resulting processor relations to be much simpler.
In the general case both noise sources can be modeled by Gaussian mixtures as well (see Ref. [41] for
details).

6.5
GAUSSIAN SUM (MIXTURE) BAYESIAN PROCESSORS
227
and converges uniformly in x(t) and y(t) as Pi(t) →0 for i = 1, … , Ng. Therefore,
{xi(t), Pi(t)} can be estimated from any of the classical (nonlinear) processors devel-
oped in Chapter 5 or the modern sigma-point processor of this chapter. We choose to
use the SPBP technique3 of Table 6.1 to provide a “bank” of Ng-parallel processors
required to estimate each member of the Gaussian mixture such that
yi(t) = f(xi(t))
ei(t) = y(t) −yi(t)
Reiei(t) = g(Pi(t), R��(t))
xi(t) = xi(t) + i(t)ei(t)
Pi(t) = Pi(t) −i(t)Reiei(t)′
i(t)
where f(⋅), g(⋅) are functions that are derived from the SPBP of Table 6.1, and the
weights4 (mixing coeficients) of the individual mixture Gaussians are updated,
i(t) =
i(t −1) × (y(t) : yi(t), Reiei(t))
∑Ng
i=1 i(t −1) × (y(t) : yi(t), Reiei(t))
(6.75)
Once we have performed the parallel SPBP estimation using the Gaussian mix-
tures, we can estimate the statistic of interest from the posterior: the conditional mean
as
̂x(t|t) = E{x(t)|Yt} = ∫x(t) ̂Pr(x(t)|Yt) dx(t)
≈
Ng
∑
i=1
i(t) ∫x(t)(x(t):xi(t), Pi(t)) dx(t)
Now using the sifting property of the implied delta function, the Gaussian sum
converges uniformly (Pi →0, (⋅) →�(⋅)) to give
̂x(t|t) =
Ng
∑
i=1
i(t)xi(t)
(6.76)
Deining the estimation error as
̃x(t|t) := x(t) −̂x(t|t)
3 We symbolically use the SPBP algorithm and ignore the details (�-points, etc.) of the implementation in
this presentation to avoid the unnecessary complexity.
4 The detailed derivation of these expressions can be found in Alspach [40] and Anderson [4]. Both
references use the uniform convergence theorem to develop the posterior representation given above.

228
MODERN BAYESIAN STATE–SPACE PROCESSORS
and the corresponding error covariance as ̃P(t|t) := cov(̃x(t|t)) as before in Chapter 5,
the approximated state error covariance is given by
̃P(t|t) =
Ng
∑
i=1
i(t)[Pi(t) + cov(xi(t) −̂x(t|t))]
(6.77)
Thus, updating consists of a bank of Ng-parallel SPBP to estimate the means and
covariance {xi(t), Pi(t)} required for the conditional statistics of Eqs. 6.76 and 6.77.
This set of relations constitute the update step of the Gaussian sum processor. Next,
let us briely develop the prediction step.
With the availability of the posterior ̂Pr(x(t)|Yt) and the process model of Eq. 6.72,
the one-step prediction distribution can also be estimated as a Gaussian mixture.
Using the iltering posterior and SPBP relations of Table 6.1, we have
Pr(x(t + 1)|Yt) ≈
Ng
∑
i=1
i(t) ∫x(t)(x(t + 1) : xi(t + 1), Pi(t + 1))
(6.78)
and using the Ng-SPBP, we have
xi(t + 1) = a[xi(t)]
Pi(t + 1) = h(Pi(t)) + R��(t)
for h(⋅) a function of the SPBP parameters in Table 6.1. These relations lead to the
one-step prediction conditional mean and covariance (as before)
̂x(t + 1|t) =
Ng
∑
i=1
i(t)xi(t + 1)
̃P(t + 1|t) =
Ng
∑
i=1
i(t)[Pi(t + 1 + cov(xi(t + 1) −̂x(t + 1|t))]
(6.79)
to complete the algorithm.
Next, we consider the application of nonlinear processors to a tracking problem.
6.6
CASE STUDY: 2D-TRACKING PROBLEM
In this section, we investigate the design of nonlinear BP to solve a two-dimensional
(2D) tracking problem. The hypothetical scenario discussed will demonstrate the
applicability of these processors to solve such a problem and demonstrate the “basic”
thinking behind constructing such a problem and solution. In contrast to the “bearings-
only” problem discussed in Chapter 5, let us investigate the tracking of a large

6.6
CASE STUDY: 2D-TRACKING PROBLEM
229
10
15
20
25
30
35
Tracking profile 
X-Position (nm)
0
5
10
15
20
25
30
35
40
45
50
Y-Position (nm)
(20, 50) t = 0
(20, 38) t = 1.0
(32, 28) t = 3.5
(10, 18) t = 7.5
(20, 10) t = 8.1
(20, 0) t = 9.1
0
1
2
3
4
5
6
7
8
9
10
10
15
20
25
30
35
X-Position (meters)
Time (hr)
0
1
2
3
4
5
6
7
8
9
10
0
5
10
15
20
25
30
35
40
45
50
Y-Position (meters)
Time (hr)
0
1
2
3
4
5
6
7
8
9
10
20
40
60
80
100
Bearing angle (deg)
Time (hr)
0
1
2
3
4
5
6
7
8
9
10
20
30
40
50
60
Range (nm)
Time (hr)
Bearing-range track
20
40
60
30
210
60
240
90
270
120
300
150
330
0
180
(a)
(b)
(c)
(d)
(e)
(f)
FIGURE 6.5
Tanker ground track geometry for the harbor docking application: (a)
instantaneous X-position (nm);(b) instantaneous Y-position (nm);(c) iled XY-path (nm);
(d) instantaneous bearing (deg); (e) instantaneous range (nm); (f) polar bearing-
range track from sensor measurement.
tanker entering a busy harbor with a prescribed navigation path. In this case, the
pilot on the vessel must adhere strictly to the path that has been iled with the
harbor master (controller). Here we assume that the ship has a transponder frequently
signaling accurate information about its current position. The objective is to safely
dock the tanker without any incidents. We observe that the ship’s path should track the
prescribed trajectory (Cartesian coordinates) shown in Fig. 6.5, which corresponds
to the instantaneous XY-positions (versus time) shown.
Our ictitious measurement instrument (e.g., low ground clutter phased array radar
or a satellite communications receiver) is assumed to instantly report on the tanker
position in bearing and range with high accuracy. The measurements are given by
Θ(t) = arctan
(Y(t)
X(t)
)
and
R(t) =
√
X2(t) + Y2(t)
We use the usual state-space formulation for a constant velocity model (see Sec-
tion 5.5) with state vector deined in terms of the physical variables as x(t) :=[X(t)
Y(t) Vx(t) Vy(t)] along with the incremental velocity input as u′ :=[−ΔVxo −ΔVyo].

230
MODERN BAYESIAN STATE–SPACE PROCESSORS
Using this information (as before), the entire system can be represented as a
Gauss–Markov model with the noise sources representing uncertainties in the states
and measurements. Thus we have the equations of motion
x(t)
=
⎡
⎢
⎢
⎢⎣
1
0
ΔT
0
0
1
0
ΔT
0
0
1
0
0
0
0
1
⎤
⎥
⎥
⎥⎦
x(t −1)
+
⎡
⎢
⎢
⎢⎣
0
0
0
0
1
0
0
1
⎤
⎥
⎥
⎥⎦
[−ΔVxo(t −1)
−ΔVyo(t −1)
]
+ �(t −1)
(6.80)
with the corresponding measurement model given by
y(t) =
⎡
⎢
⎢⎣
arctan x2(t)
x1(t)
√
x2
1(t) + x2
2(t)
⎤
⎥
⎥⎦
+ �(t)
for �∼(0, R��) and �∼(0, R��).
The SSPACK_PC software [43] was used to simulate this Gauss–Markov sys-
tem for the tanker path and the results are shown in Fig. 6.6. In this scenario, we
assume the instrument is capable of making measurements every ΔT = 0.02 hr with
a bearing precision of ±0.02degree and range precision of ±0.005 nm (or equiva-
lently R��= diag[4 × 10−4,
1 × 10−4]. The model uncertainty was represented by
R��= diag(1 × 10−6). An impulse-incremental step change in velocity, for example,
Vy going from −12 k to −4 k is an incremental change of +8 k corresponding to
ΔVyo = [8 1.5 −10.83 3.33] knots and ΔVxo = [0 4.8 −10.3 22.17] knots. These
impulses (changes) occur at time iducials of t = [0 1 3.5 7.5 8.1 9.1]hr corre-
sponding to the iled harbor path depicted in the igure. Note that the velocity changes
are impulses of height (ΔVx, ΔVy) corresponding to a known deterministic input u(t).
These changes relate physically to instantaneous direction changes of the tanker and
create the path change in the constant velocity model.
The simulated bearing measurements are generated using the initial conditions
x′(0) := [20 nm 50 nm 0 k −12 k] and R��= diag[1 × 10−6, 1 × 10−6] with the cor-
responding initial covariance given by ̃P(0) = diag[1 × 10−6, 1 × 10−6]. The Jacobian
matrices derived from the Gauss–Markov model above are shown below
A[x] = A
and
C[x] =
⎡
⎢
⎢
⎢⎣
x2(t)
R2(t)
−x1(t)
R2(t)
0
0
x1(t)
R(t)
x2(t)
R(t)
0
0
⎤
⎥
⎥
⎥⎦

6.6
CASE STUDY: 2D-TRACKING PROBLEM
231
0
2
4
6
8
10
5
10
15
20
25
30
35
Time
Amplitude
0
2
4
6
8
10
−10
0
10
20
30
40
50
Time
Amplitude
0
2
4
6
8
10
−10
−5
0
5
10
15
20
Time
Amplitude
0
2
4
6
8
10
−14
−12
−10
−8
−6
−4
−2
Time
Amplitude
0
2
4
6
8
10
0
0.5
1
1.5
2
Time
Amplitude
0
2
4
6
8
10
10
20
30
40
50
60
Time
Amplitude
0
1
2
3
4
5
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Norm. Corr.
Lags(Pct/No = 2.63(6))
0
1
2
3
4
5
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Norm. Corr.
Lags(Pct/No = 4.82(11))
(a)
(b)
(c)
(d)
FIGURE 6.6
XBP (EKF) design for harbor docking problem (input known): (a) X-position
and velocity estimates with bounds (0% out); (b) Y-position and velocity estimates with
bounds (0% and 3% out);(c) bearing and range estimates with bounds (1% and 2% out);
(d) innovations zero-mean/whiteness tests for bearing (6 × 10−4 < 26 × 10−�and 3% out)
and range (2 × 10−�< 42 × 10−�and 5% out).
The XBP, IX-BP, LZ-BP, and SPBP were executed under the constraint that
all of the a priori information for the tanker harbor path is “known”. Each of the
processors performed almost identically. A representative realization output for the
XBP is shown in Fig. 6.6. In (a) and (b), we observe the estimated states X (∼0%
out), Y (∼0% out), Vx (∼0% out), and Vy (∼3% out)5. Note that the velocities
are piecewise constant functions with step changes corresponding to the impulsive
incremental velocities. The iltered measurements: bearing (∼1% out) and range (∼2%
out) are shown in Fig. 6.6c with the resulting innovations zero-mean/whiteness tests
depicted in (d). The processor is clearly tuned with bearing and range innovations
zero-mean and white (6 × 10−4 < 26 × 10−4/3% out) and (2 × 10−4 < 42 × 10−4/5%
out), respectively. This result is not unexpected, since all of the a priori information
5 Here “% out” means the percentage of samples exceeding the conidence bounds.

232
MODERN BAYESIAN STATE–SPACE PROCESSORS
is given including the precise incremental velocity input u(t). An ensemble of 101
realizations of the estimator were run by generating random initial condition estimates
from the Gaussian assumption. The 101 realization ensemble averaged estimates
closely follow the results shown in the igure with the zero-mean/whiteness tests
(2 × 10−4 < 25 × 10−4/4% out), (2 × 10−4 < 15 × 10−4/7% out) slightly worse.
Next, we investigate the realistic case where all of the information is known a priori
except the impulsive incremental velocity changes represented by the deterministic
input. Note that without the input, the processor cannot respond instantaneously to
the velocity changes and therefore will lag (in time) behind, in predicting the tanker
path. The solution to this problem requires a joint estimation of the states and now
the unknown input which is a solution to the deconvolution problem [44]. It is also a
problem that is ill-conditioned, especially, since u(t) is impulsive.
In any case we ran the nonlinear BP algorithms over the simulated data and the best
results were obtained using the LZ-BP and SPBP. This is expected, since we used the
exact state reference trajectories or iled paths, but not the input. Note that the other
nonlinear BP have no knowledge of this trajectory inhibiting their performance in
this problem. The results are shown in Fig. 6.7, where we observe the state estimates
as before. We note that the position estimates appear reasonable, primarily because of
the reference trajectories. The LZ-BP is able to compensate for the unknown impul-
sive input with a time lag as shown at each of the iducials. The velocity estimates
(4% out, 1% out) are actually low-pass versions of the true velocities caused by
the slower LZ-BP response even with the exact step changes available. These
lags are more vividly shown in the bearing estimate of Fig. 6.7 c which shows
that the processor has great dificulty with the instantaneous velocity changes in
bearing (0% out). The range (0% out) appears insensitive to this lack of knowledge
primarily because the XY-position estimates are good and do not have step changes
like the velocity for the LZ-BP to track. Both processors are not optimal and the
innovations sequences are zero-mean but not white (75 × 10−3 < 81 × 10−3/59%
out), (2 × 10−3 < 4 × 10−3/8% out).
We also designed the SPBP (UKF) to investigate its performance on this problem
and its results were quite good6 as shown in Fig. 6.8. The processor does not per-
form a model linearization but a statistical linearization instead, it is clear from the
igure shown that it performs better than any of the other processors for this problem.
In Figs. 6.8 a– 6.8 d, we see that the XY-position estimates “track” the data very
well while the XY-velocity estimates are somewhat nosier due to the abrupt changes
(steps) tuning values of the process noise covariance terms. In order to be able to
track the step changes, the process noise covariance could be increased even further
at the cost of nosier estimates. The SPBP tracks the estimated bearing and range
reasonably well as shown in igure with a slight loss of bearing track toward the end
of the time sequence. These results are demonstrated by the zero-mean/whiteness test
results of the corresponding innovations sequences. The bearing innovation statistics
are 3.3 × 10−3 < 1.2 × 10−1 and 4.7% out, and the corresponding range innovation
6 We used noisier simulation data for this run than that for the LZ-BP with R��= diag = [4 × 10−4 5 × 10−1]
providing a more realistic measurement uncertainty.

6.6
CASE STUDY: 2D-TRACKING PROBLEM
233
0
2
4
6
8
10
5
10
15
20
25
30
35
Time
Amplitude
0
2
4
6
8
10
−10
0
10
20
30
40
50
Time
Amplitude
0
2
4
6
8
10
−20
−10
0
10
20
30
Time
Amplitude
0
2
4
6
8
10
−30
−20
−10
0
10
20
Time
Amplitude
2
4
6
8
−1.5
−1
−0.5
0
0.5
1
1.5
2
Time
Amplitude
2
4
6
8
20
25
30
35
40
45
50
Time
Amplitude
0
1
2
3
4
5
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Norm. Corr.
Lags(Pct/No = 58.77(134))
0
1
2
3
4
5
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Norm. Corr.
Lags(Pct/No = 7.46(17))
(a)
(b)
(c)
(d)
FIGURE 6.7
LZ-BP design for harbor docking problem (input unknown). (a) X-position
and velocity estimates with bounds (68% and 4% out); (b) Y-position and velocity esti-
mates with bounds (49% and 1% out);(c) bearing and range estimates with bounds (0%
and 3% out);(d) innovations zero-mean/whiteness tests for bearing (75 × 10−�< 81 × 10−�
and 59% out) and range (2 × 10−�< 4 × 10−�and 8% out).
statistics given by 6.5 × 10−3 < 1.2 × 10−1 and 4.7% out. Both indicate a tuned pro-
cessor. These are the best results of all of the nonlinear processors applied. This
completes the case study.
It is clear from this study that nonlinear processors can be “tuned” to give reason-
able results, especially when they are provided with accurate a priori information.
If the a priori information is provided in terms of prescribed reference trajectories
as in this hypothetical case study, then the SPBP appears to provide superior perfor-
mance, but in the real-world tracking problem (as discussed in Section 5.5) when this
information on the target is not available, the XBP and IX-BP can be tuned to give
reasonable results.
There are many variants possible for these processors to improve their performance
whether it be in the form of improved coordinate systems [45, 46] or in the form

234
MODERN BAYESIAN STATE–SPACE PROCESSORS
X-Position
10
20
30
40
0
20
40
60
Y-Position
−10
0
10
20
X-Velocity
−15
−10
−5
0
5
Y-Velocity
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
Bearing
0
1
2
3
4
5
6
7
8
9
15
20
25
30
35
40
45
50
55
Time (h)
Range
(a)
(b)
(c)
(d)
(e)
(f)
FIGURE 6.8
SPBP (UKF) design for harbor docking problem (input unknown). (a) X-
position estimate;(b) Y-position estimate;(c) X-velocity estimate;(d) Y-velocity estimate;
(e) bearing estimate (zero- mean/whiteness: 3.3 × 10−�< 1.2 × 10−�and 4.7% out); (f)
range estimate (zero-mean/whiteness: 6.5 × 10−�< 1.2 × 10−�and 4.7% out).
of a set of models, each with its own independent processor [8]. One might also
consider using estimator/smoothers as in the seismic case [7] because of the unknown
impulsive input. In any case, this is a challenging problem that much work has been
accomplished, the interested reader should consult Ref. [8] and the references cited
within.
6.7
ENSEMBLE BAYESIAN PROCESSORS (ENSEMBLE KALMAN FILTER)
Another approach to Bayesian processing problem is the ensemble Bayesian pro-
cessor (EnBP) popularly called the ensemble Kalman ilter (EnKF) approximation
leading to an eficient processor targeted for large-scale computational problems. It
has been shown that the EnKF provides a simple implementation, numerical stability,
convergence and interpretation of results especially because of its properties when
incorporated for nonlinear models [23–32]. It provides a mechanism to compute the
posterior distribution of the embedded model conditioned on the measurement data
and is based on generating an ensemble of model state estimates along with their
associated error covariances representing the uncertainty.

6.7
ENSEMBLE BAYESIAN PROCESSORS (ENSEMBLE KALMAN FILTER)
235
The EnKF provides yet another alternative to the XBF or extended Kalman ilter
(EKF) similar to the Monte Carlo (MC) approach to follow in the next chapter. It is
capable of resolving two major problems: (1) it provides a major closure scheme in
the sense that it is more robust than the EKF and does not diverge due to linearization;
and (2) it is capable of reducing the large storage and error covariance propagations
characteristic of Kalman-type model-based processors.
This class of Bayesian processor falls into the category of sequential data
assimilation methods that have been heavily applied in meteorology, oceanography,
seismology, and microwaves (radar) where the data are assimilated into the
underlying model creating a model-based processing scheme for large dimensional
problems. Speciically, the EnKF is an assimilation method where the error statistics
are predicted using MC or equivalently ensemble propagation techniques. This
implies that the EnKF can be interpreted as a purely statistical MC technique since
the ensemble of model states evolve in the state space with its mean provided as the
best estimate and spread given by the corresponding ensemble state error covariance.
At observation time, each measurement is represented by another ensemble with the
mean given by the actual measurement and the ensemble measurement error covari-
ance representing the corresponding errors [25]. Propagating the model states forward
in time enables the estimation of statistical moments from the resulting ensemble.
New ensembles are created by updating each member individually enabling a parallel
implementation in many applications.
The EnKF can be considered a cross between the unscented Bayesian processor
or EKF and the particle ilters (PF) to follow in that it uses regression techniques to
estimate the error covariances based on generated ensembles as well as a MC approach
to estimate ensemble statistics again simplifying the computations. The usual Kalman
ilter applied to nonlinear systems is the EKF. In an EKF, the covariance matrices
are propagated through the nonlinear model with the Jacobian of the state transition
and measurement functions. Such a irst-order Taylor series approximation can result
in large estimation errors and sometimes causes the ilter to diverge (the gain tends
to zero). The EnKF represents the underlying distributions with large stochastic
ensembles of models as in the MC methods. Each member is propagated through the
state and measurement functions and the statistics of the estimates are propagated
without the use of any linearization step.
In this section, we start with a discussion of state/measurement ensembles and
then proceed with the development of the EnKF processor after a brief review of
the Kalman ilter to motivate the ensuing discussion. Before we investigate the lin-
ear EnKF, we discuss the generation of linear state-space ensemble data and its
accompanying statistics.
State-Space Ensembles:
When the process statistics are stationary, the state-
space methods of Chapter 4 satisfy the relations developed; however, when the pro-
cesses are nonstationary (time-varying statistics), ensemble methods can be employed
to synthesize data capturing the evolution of the underlying probability mass func-
tions.

236
MODERN BAYESIAN STATE–SPACE PROCESSORS
Mathematically, we have the state–space ensemble technique for n = 1, … , N�
given by
r States:
xn(t) = A(t −1)xn(t −1) + wn(t −1)
r State ensemble:
�(t) = [x1(t) ⋯xN�(t)]T
r State means:
mx(t) = E{�(t)} =
1
N�
∑N�
n=1 xn(t)
r State variance:
Rxx(t) =
1
N�
∑N�
n=1
(xn(t) −mx(t))(xn(t) −mx(t))T
r Measurements:
yn(t) = C(t)xn(t) + wn(t)
r Measurement ensemble: �(t) = [y1(t) ⋯yN�(t)]T
r Measurement means:
my(t) = E{�(t)} =
1
N�
∑N�
n=1 yn(t)
r Measurement variance: Ryy(t) =
1
N�
∑N�
n=1
(yn(t) −my(t))(yn(t) −my(t))T
One way to achieve this operation is to perform the following operations at each
time step “t”:
r Process noise: for each component state, generate an ensemble of random pro-
cess noise samples {�i,n(t)}; i = 1, … , Nx; n = 1, … , N�
r States: for each component state, generate an ensemble of state samples driven
by the process noise (above) {xi,n(t)}; i = 1, … , Nx; n = 1, … , N�
r State mean: for each ensemble, estimate the state mean (over n) mx(t)
r State variance: for each ensemble, estimate the state variance (over n) Rxx(t)
Perform similar steps for the measurement process
r Measurement noise: for each component measurement, generate an ensemble
of random measurement noise samples {�j,n(t)}; j = 1, … , Ny; n = 1, … , N�
r Measurements: for each component measurement, generate an ensemble of
measurement samples perturbed by the measurement noise (above), {yj,n(t)}; j =
1, … , Ny; n = 1, … , N�
r Measurement mean: for each ensemble, estimate the measurement mean
(over n) my(t)
r Measurement variance: for each ensemble, estimate the measurement variance
(over n) Ryy(t)
generating the (Ny × N�)-measurement ensemble array, �(t) = [y1(t) ⋯yN�(t)].
Example 6.4
Consider the generation of an ensemble for the series RLC circuit (second-order
system) excited by a pulse train of Section 5.8.

6.7
ENSEMBLE BAYESIAN PROCESSORS (ENSEMBLE KALMAN FILTER)
237
The sampled-data Gauss–Markov simulation uses the following noise covariance
matrices to generate the ensemble:
R��= 0.1(V)2
and
R��= 0.01(V)2
The results are shown in Fig. 6.9 . We illustrate the noisy measurement ensemble
generated from these statistics in a and the estimated (kernel density smoother) PMF
at each point in time creating the corresponding probability surface (measurement
sample (realization) × measurement no. × probability) in Fig. 6.9c.
△△△
This completes the ensemble generation methodology that will be used to generate
PMFs employed in the EnKF algorithm to follow, irst we review the linear Kalman
ilter to motivate the development of the EnKF.
Linear Kalman Filter:
Here we start our discussion using the linear models and
the Kalman ilter to develop the EnKF and then briely extend these results to the
nonlinear case. Recall that the linear Kalman ilter (LKF) algorithm is based on the
fact that the posterior distribution of the states based on all of the data up to that time
is multivariate Gaussian. With that in mind the LKF essentially provides a prediction-
update technique that sequentially estimates the conditional mean and covariance of
the posterior Gaussian distribution, that is,
̂x(t|t −1) = A(t −1)̂x(t −1|t −1)
[ prediction ]
̂x(t|t) = ̂x(t|t −1) + K(t)(y(t) −C(t)̂x(t|t −1))
[ update ]
(6.81)
Deining the state prediction and correction errors by
̃x(t|t −1) := x(t) −̂x(t|t −1)
and
̃x(t|t) := x(t) −̂x(t|t)
the associated predicted error covariance is
̃P(t|t −1) := cov (̃x(t|t −1)) = E {̃x(t|t −1)̃xT(t|t −1)}
with the updated error covariance given by
P(t|t) := cov (̃x(t|t)) = E {̃x(t|t)̃xT(t|t)}
The corresponding gain or weighting function is
K(t) = ̃P(t|t −1)CT(t)(C(t)̃P(t|t −1)C(t) + R��(t))−1
[ Gain ]

(a)
(b)
FIGURE 6.9
Ensemble generation: (a) realization of 100-member ensemble for the RLC-circuit problem; (b) estimated PMF surface
(measurement sample (realization) × measurement no. × probability) using kernel density smoother.

6.7
ENSEMBLE BAYESIAN PROCESSORS (ENSEMBLE KALMAN FILTER)
239
where the error covariance “propagation relations” are given by
̃P(t|t −1) = A(t −1)̃P(t −1|t −1)A(t −1) + R��(t −1)
[Cov. prediction]
̃P(t|t) = (I −K(t)C(t))̃P(t|t −1)
[Cov. update]
Linear Ensemble Kalman Filter:
The EnKF follows the same basic struc-
ture as the LKF with ensemble operations replacing the “propagation relations”
by ensemble estimates. The EnKF relations above follow directly by rewriting
the LKF state/measurement vectors and covariances as the nth ensemble member
(e.g., ̂x(t|t) →̂xn(t|t)) yielding the ensemble relations
n = 1, … , N�
[Ensemble]
̂xn(t|t −1) = A(t −1)̂xn(t −1|t −1)
[Ens. prediction]
̂xn(t|t) = ̂xn(t|t −1) + Kn(t)(yn(t) −C(t)̂xn(t|t −1))
[Ens. update]
(6.82)
with the gain given by
Kn(t) = ̃Pn(t|t −1)CT(t)(C(t)̃Pn(t|t −1)C(t) + R�n�n(t))−1 [Ens. gain]
(6.83)
and covariances given by
̃Pn(t|t −1) = A(t −1)̃Pn(t −1|t −1)AT(t −1) + R�n�n(t −1) [Ens. Cov. prediction]
̃Pn(t|t) = (I −Kn(t)C(t))̃Pn(t|t −1)
[Ens. Cov. update]
The initial ensemble is chosen to represent the error states of the initial conditions
((̃x(0), ̃P(0)) where the “rule of thumb” is to create an ensemble of model states by
adding a perturbation to an initial state estimate and then propagate the ensemble
over the corresponding time interval. In terms of a more practical implementation, it
is more common to represent the EnKF algorithm in terms of vector-matrix relations
as in Refs. [23] and [26].
State Perturbation
̂xn(t|t −1) = Âxn(t −1|t −1) + �n(t −1);
n = 1, … , N�
(6.84)
with �n ∼(0, R�n�n) considered the modeling error or uncertainty used to gener-
ate the state ensemble samples for propagation (prediction).

240
MODERN BAYESIAN STATE–SPACE PROCESSORS
State Error
̃xn(t|t −1) = ̂xn(t|t −1) −x(t −1);
n = 1, … , N�
(6.85)
for x the ensemble mean.
These state error vectors are instrumental in estimating the associated error covari-
ance incorporated into the gain calculation. With this in mind, an ensemble matrix of
state error vectors at time (t −1) can be created as
̃�(t −1) = [̃x1(t|t −1) ⋯̃xN�(t|t −1)] ∈Nx×N�
(6.86)
The associated error covariance is computed simply as a sample estimate given by
Predicted State Error Covariance
̃P�(t|t −1) = 1
N�
̃�(t −1) ̃T
�(t −1) ∈Nx×Nx
(6.87)
To complete the MC representation
Measurement Perturbation
yn(t) = y(t) + �n(t);
n = 1, … , N�
(6.88)
with �n ∼(0, R��) considered the measurement error or uncertainty used to
generate the measurement ensemble samples for propagation (prediction).
Measurement Prediction
̂yn(t|t −1) = C(t)̂xn(t|t −1);
n = 1, … , N�
(6.89)
Measurement Error
̃yn(t) = ̂yn(t|t −1) −y(t);
n = 1, … , N�
(6.90)
for y the ensemble mean of the measurement samples.
An ensemble matrix can be created for use in covariance estimates as
̃�(t) = [̃y1(t) ⋯̃yN�(t)] ∈Ny×N�
(6.91)
and therefore we obtain
Measurement Error Covariance
R ̃̃(t) = 1
N�
̃�(t) ̃T
�(t) ∈Ny×Ny
(6.92)

6.7
ENSEMBLE BAYESIAN PROCESSORS (ENSEMBLE KALMAN FILTER)
241
The Ny × N�measurement noise ensemble is created to provide the sample measure-
ment covariance as
Measurement Noise Covariance
�(t) = [�1(t) ⋯�N�(t)] ∈Ny×N�
R(t) = = 1
N�
�(t)T
�(t) ∈Ny×Ny
(6.93)
The ensemble Kalman gain for the linear case can be obtained using the ensemble
error covariance as in the LKF processor as
Gain
�(t) = ̃P�(t|t −1)CT(t)(C(t)̃P�(t|t −1)CT(t) + R(t))−1
(6.94)
Deining the updated states, their errors and ensemble mean at time t we have
Updated State/Error
̂xn(t|t) = ̂xn(t|t −1) + �(t)(yn(t) −̂yn(t|t −1))
̃xn(t|t) = ̂xn(t|t) −x(t);
n = 1, … , N�
(6.95)
and therefore estimate the sample error covariance as
Updated State Error Covariance
̃P�(t|t) =
1
N�−1
̃�(t) ̃T
�(t) ∈Nx×Nx
(6.96)
Next, we investigate the nonlinear EnKF and its implementation.
Nonlinear Ensemble Kalman Filter:
Here instead of the matrices of the linear
models, we have nonlinear functions (models) of both the states and measurements,
that is,
A(t −1)x(t −1) ⟶a[x(t −1)]
and
C(t)x(t) ⟶c[x(t)]
As mentioned previously, the EKF linearizes these nonlinear model through a irst-
order Taylor series approximation (see Section 5.5 for details) which is the primary
cause of ilter divergence (gain →0). The EnKF processor approaches this problem
in a different manner.

242
MODERN BAYESIAN STATE–SPACE PROCESSORS
When the measurement system is nonlinear, then the operation of the EnKF, which
is primarily based on a linear measurement model, must be modiied, somehow, to
deal with this problem. The obvious approach is to “linearize” the measurement
model much the same as the EKF; however, this diminishes the robustness property
of the EnKF gained in the state dynamics. One possibility is to augment the nonlinear
measurement functions (c[x(t)]) into the state vector incorporating them into the pre-
diction ensemble and propagate them along with the states [23]. Another possibility
is that of developing another ensemble to estimate the cross-error covariance between
the state and measurement errors thereby eliminating the need for linearization or aug-
mentation [29]. We develop the latter approach in the gain calculation subsequently.
For the nonlinear implementation, we simply replace the prediction steps with the
nonlinear models producing the perturbation relations:
Ensemble Predictions
̂xn(t|t −1) = a[̂xn(t −1|t −1)] + �n(t −1)
[Nonlinear state perturbation]
̂yn(t|t −1) = c[̂xn(t −1|t −1)]
[Nonlinear measurement prediction]
yn(t) = y(t) + �n(t);
n = 1, … , N�
[Measurement perturbation]
(6.97)
Returning to the basic minimum variance estimation construct (see Section 2.4), the
original Kalman gain can be calculated by the product of the error cross-covariance
and the inverse measurement error covariance [10]
K(t) = R̃x̃y(t) × R−1
̃ỹy (t)
(6.98)
Therefore, we have that the ensemble Kalman gain has the same structure by
employing both the state and measurement error ensembles yielding an alternate
form using the ensemble error cross-covariance similar to the EKF processor [10] as
Gain
R ̃̃(t) = 1
N�
̃�(t −1) ̃T
�(t)
�(t) = R ̃̃(t)(R ̃̃(t) + R(t))−1
(6.99)
This approach has been successfully demonstrated [29].
We summarize both linear/nonlinear ensemble Kalman techniques in the combined
table, that is, Table 6.2 along with the structure of the EnKF algorithm depicted in
Fig. 6.10 emphasizing the basic components of the EnKF. More details can be found
in Ref. [23].

6.7
ENSEMBLE BAYESIAN PROCESSORS (ENSEMBLE KALMAN FILTER)
243
TABLE 6.2
ENSEMBLE Bayesian (Kalman Filter) Processor Algorithm.
Ensemble
n = 1, … , N�
State Prediction
̂xn(t|t −1) =
⎧
⎪
⎨
⎪⎩
A(t −1)̂xn(t −1|t −1) + �n(t −1)
[Linear state perturbation]
or
a[̂xn(t −1|t −1)] + �n(t −1)
[Nonlinear state perturbation]
̃xn(t|t −1) = ̂xn(t|t −1) −x(t −1)
[State error]
̃P�(t|t −1) = 1
N�
̃�(t −1) ̃T
�(t −1)
[Ensemble error covariance prediction]
Measurement Prediction
̂yn(t|t −1) =
⎧
⎪
⎨
⎪⎩
C(t)̂xn(t|t −1) + �n(t)
[Linear measurement perturbation]
or
c [̂xn(t|t −1)] + �n(t)
[Nonlinear measurement perturbation]
̃yn(t) = ̂yn(t|t −1)) −y(t)
[Measurement error]
R ̃̃(t) = 1
N�
̃�(t) ̃T
�(t)
[Ensemble error covariance prediction]
Measurement noise/Covariance
Gain
R ̃̃(t) = 1
N�
̃�(t −1) ̃T
�(t)
[Ensemble error cross-covariance prediction]
�(t) = ̃R ̃̃(t)
(
R ̃n ̃n(t) + R�n�n(t)
)−1
[Gain]
State Update
̂xn(t|t) = ̂xn(t|t −1) + �(t)
(
̂yn(t|t −1)) −y(t)
)
[State update]
̃xn(t|t) = xn(t|t) −x(t)
[State error update]
̃P�(t|t) = 1
N�
̃�(t) ̃T
�(t)
[Ensemble error covariance update]
Ensemble Means/Errors
̂x(t −1) = 1
N�
N�
∑
n=1
̂xn(t|t −1)
̃�(t −1) =
[
̃x1(t|t −1) ⋯̃xN�(t|t −1)
]
y(t) = 1
N�
N�
∑
n=1
̂yn(t|t −1)
̃�(t) =
[
̃y1(t) ⋯̃yN�(t)
]
x(t) = 1
N�
N�
∑
n=1
̂xn(t|t)
̃�(t) =
[
̃x1(t) ⋯̃xN�(t|t)
]

244
MODERN BAYESIAN STATE–SPACE PROCESSORS
( )
y t
t ⇒ t + 1
FIGURE 6.10
Ensemble Kalman ilter algorithm structure: initialization, state prediction
(ensemble), measurement prediction, measurement (perturbation) noise/covariance
(ensemble), gain, state update.
Before we conclude this section, let us revisit the RLC circuit of Section 5.8 and
compare the performance of the linear and ensemble Kalman processors.
Example 6.5
Consider the design of both LKF and EnKF processors for the series RLC circuit
(second-order system) excited by a pulse train of Section 5.8.
After inserting the physical circuit parameters, the resulting continuous-time,
differential equation model evolved as
dx
dt =
[
0
1
−4
−2
]
x +
[
0
−4
]
u +
[
0
−4
]
�
and the discrete-time voltage measurements
y(t) = [1 0]x(t) + �(t)

6.8
SUMMARY
245
where
R��= (0.1)2
T
= 0.1(V)2
and
R��= 0.01(V)2
The process model was converted to a sampled-data (discrete) representation with
a sampling interval of 0.1 sec providing the following discrete-time Gauss–Markov
model as input to our processors:
x(t) =
[
0.98
0.09
−0.36
0.801
]
x(t −1) +
[
−0.019
−0.36
]
u(t −1) +
[
−0.019
−0.36
]
�(t −1)
y(t) = [1|0]x(t) + �(t)
where
R��= 0.1(V)2
and
R��= 0.01(V)2
The discrete Bayesian processors were designed. The results are shown in
Fig. 6.11; in (a) through (c), we see the processed states and measurements using
both the LKF and EnKF processors along with the uncertain simulation data and cor-
responding true (mean) signals. From the igure, it is clear that the EnKF estimates
using and ensemble size of 1000 members “track” the optimal LKF outputs quite well.
To validate the performance for this processor, zero-mean/whiteness tests were per-
formed as shown in Fig. 6.11d. As shown, the innovations are statistically zero-mean
(0.033 ≪0.174) and white (3.1% out, WSSR below threshold) indicating a well-tuned
EnKF processor.
This completes example and the comparison for the RLC problem.
△△△
Next, we summarize the chapter.
6.8
SUMMARY
In this chapter, we have developed the “modern” sigma-point Bayesian processor
(SPBP) or equivalently, the unscented Kalman ilter (UKF), from the basic princi-
ples of weighted linear stochastic linearization (WSLR) and �-point transformations
(SPT). We extended the results for multivariate Gaussian distributions and calculated
the corresponding �-points and weights. Once determined, we developed the SPBP
by extrapolating the WSLR and SPT approaches coupled to the usual Kalman ilter
recursions. Grid-based quadrature and Gaussian sum processors were also discussed
and developed using the SPBP formulation to demonstrate a distribution approxima-
tion approach leading to the particle ilter formulation of the next chapter. Finally,
we developed the ensemble Kalman ilter (EnKF) processor explicitly designed for
large-scale problems. The EnKF is a hybrid between the UKF and the particle ilters
to follow in that it employs ensemble (sampling) techniques and approximates the
required computationally intensive covariances using regression methods. Examples

0
2
4
6
8
10
12
14
16
18
20
Amplitude
−2
−1.5
−1
−0.5
0
0.5
1
EnKF
KF
DATA
TRUE
0
2
4
6
8
10
12
14
16
18
20
Amplitude
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
EnKF
KF
DATA
TRUE
Time (sec)
0
2
4
6
8
10
12
14
16
18
20
Amplitude
−2
−1.5
−1
−0.5
0
0.5
1
EnKF
KF
DATA
TRUE
(a)
(b)
Lags
0
2
4
6
8
10
12
14
Norm.Corr.
−0.2
0
0.2
0.4
0.6
0.8
1
Zero-mean/whiteness test
(d)
(c)
FIGURE 6.11
Ensemble Kalman and optimal ilter for RLC-circuit problem. (a) State no. 1: data, true (mean), KF, EnKF
estimates. (b) State no. 2: data, true (mean), KF, EnKF estimates. (c) Measurement: data, true (mean), KF, EnKF estimates.
(d) Innovation zero-mean/whiteness test (Z-M: 0.03 < 0.17; 3.1% out).

REFERENCES
247
were developed throughout to demonstrate the concepts ending in a hypothetical
investigation based on tracking a tanker entering a busy harbor. We summarized the
results by applying some of the processors to the case study implementing a 2D-
tracking ilter. Finally, we compared the EnKF performance to the optimal LKF for
the linear RLC-circuit problem of the previous chapter.
MATLAB NOTES
SSPACK_PC is a third-party toolbox in MATLAB that can be used to design
model-based signal processors [10, 43]. This package incorporates the major
nonlinear MBP algorithms discussed in this chapter—all implemented in the
UD-factorized form [47] for stable and eficient calculations. It performs the dis-
crete approximate Gauss–Markov simulations using (SSNSIM) and both extended
(XMBP) and iterated-extended (IX-MBP) processors using (SSNEST). The lin-
earized model-based processor (LZ-MBP) is also implemented (SSLZEST).
Ensemble operations are seamlessly embodied within the GUI-driven framework
where it is quite eficient to perform multiple design runs and compare results.
Of course, the heart of the package is the command or GUI-driven post-processor
(SSPOST) which is used to analyze and display the results of the simulations and
processing (see http://www.techni-soft.net for more details).
REBEL is a recursive Bayesian estimation package in MATLAB available
on the web, that performs similar operations including the new statistical-based
unscented algorithms including the UKF including the unscented transforma-
tions [33]. It also has included the new particle ilter designs as discussed in
Ref. [33, 34, 48].
EnKF-MATLAB is an ensemble Kalman iltering software package in MAT-
LAB for complex problems [49].
REFERENCES
1. A. Jazwinski, Stochastic Processes and Filtering Theory (New York: Academic Press,
1970).
2. A. Sage and J. Melsa, Estimation Theory with Applications to Communications and
Control (New York: McGraw-Hill, 1971).
3. A. Gelb (editor), Applied Optimal Estimation (Boston, MA: MIT Press, 1975).
4. B. Anderson and J. Moore, Optimal Filtering (Englewood Cliffs, NJ: Prentice-Hall, 1979).
5. P. Maybeck, Stochastic Models, Estimation, and Control (New York: Academic Press,
1979).
6. M. Grewal and A. Andrews, Kalman Filtering: Theory and Practice (Englewood Cliffs,
NJ: Prentice-Hall, 1993).
7. J. Mendel, Lessons in Estimation Theory for Signal Processing, Communications and
Control (Englewood Cliffs, NJ: Prentice-Hall, 1995).

248
MODERN BAYESIAN STATE–SPACE PROCESSORS
8. Y. Bar-Shalom and X. Li, Estimation and Tracking: Principles, Techniques, and Software
(Norwood, MA: Artech House, 1993).
9. B. Bell and F. Cathey, “The iterated kalman ilter update as a Gauss-Newton method,”
IEEE Trans. Autom. Control, AC-38, 2, 294–297, 1993.
10. J. Candy, Model-Based Signal Processsing (Hoboken, NJ: John Wiley & Sons, Inc./IEEE
Press, 2006).
11. D. Simon, Optimal State Estimation: Kalman, H∞and Nonlinear Approaches (Hoboken,
NJ: John Wiley & Sons, 2006).
12. S. Julier, J. Uhlmann, and H. F. Durrant-Whyte, “A new approach for iltering in nonlinear
systems,” Proc. Am. Control Conf., 3, 1628–1632, 1995.
13. S. Julier and J. Uhlmann, “A general method for approximating nonlinear transformations
of probability distributions,” University of Oxford Report, 1996.
14. S. Julier, J. Uhlmann, and H. F. Durrant-Whyte, “A new method for the nonlinear transfor-
mation of means and covariances in ilters and estimators,” IEEE Trans. Autom. Control,
45, 3, 477–482, 2000.
15. S. Julier and J. Uhlmann, “Unscented iltering and nonlinear estimation,” Proc. IEEE, 92,
3, 401–422, 2004.
16. S. Julier and J. Uhlmann, “A new extension of the Kalman ilter to nonlinear systems,”
Proc. SPIE Conf., Orlando, FL, 1997.
17. E. Wan and R. van der Merwe, “The unscented Kalman ilter for nonlinear estimation,”
Proc. IEEE Sumpos. Adaptive Sys. for Sig. Proc., Comm. and Control, Lake Louise,
Alberta, 2000.
18. R. van der Merwe, A. Doucet, N. de Freitas, and E. Wan, “The unscented particle ilter,”
Cambridge University Technical Report, CUED/F-INFENG-380, 2000.
19. T. Lefebvre, H. Bruyninckx, and J. DeSchutter, Comments on “A new method for the
nonlinear transformation of means and covariances in ilters and estimators,” IEEE Trans.
Autom. Control, 47, 8, 1406–1409, 2002.
20. S. Julier and J. Uhlmann, “A consistent, debiased method for converting between polar
and Cartesian coordinate systems,” Proc. SPIE Conf., 1997.
21. S. Haykin, Kalman Filtering and Neural Networks (New York: John Wiley & Sons, Inc.,
2001).
22. A. Smith and A. Gelfand, “Bayesian statistics without tears: A sampling-resampling
perspective,” Am. Statistic., 46, 2, 84–88, 1992.
23. G. Evensen, Data Assimilation: The Ensemble Kalman Filter (New York: Springer, 2007).
24. G. Evensen, “Sequential data assimilation with a non-linear quasi-geostrophic model using
Monte-Carlo methods to forecast error statistics,” J. Geophys. Res., 99 (C5), 10143–10162,
1994.
25. G. Burgers, P. van Leeuven, and G. Evensen “Analysis scheme in the ensemble Kalman
ilter,” Mon. Weather Rev., 126, 1719–1724, 1998.
26. G. Evensen, “The ensemble Kalman ilter: theoretical formulation and practical imple-
mentation,” Ocean Dynam., 53, 343–367, 2003.
27. G. Evensen, “Sampling strategies and square root analysis schemes for the EnKF,” Ocean
Dynam., 54, 539–560, 2004.
28. J. Jensen, Ensemble Kalman Filtering for State and Parameter Estimation on a Reservoir
Model MS Thesis, (Norway:Norwegian University of Science and Technology, 2007).

REFERENCES
249
29. X. Han and X. Li, “An evaluation of the nonlinear/non-Gaussian ilters for the sequential
data assimilation,” Remote Sens. Environ., 112, 1434–1449, 2008.
30. P. Sakov and P. Oke, “A deterministic formulation of the ensemble Kalman ilter: an
alternative to ensemble square root ilters,” Tellus, 60A, 1361–371, 2008.
31. P. Sakov, G. Evensen, and L. Bertino, “Asynchronous data assimilation with the EnKF,”
Tellus, 62A, 24–28, 2009.
32. G. Evensen, “The ensemble Kalman ilter for combined state and parameter estimation,”
IEEE Cntrl. Sys. Magz., 6, 583–104, 2009.
33. R. van der Merwe and E. Wan, REBEL: Recursive Bayesian Estimation Library University
of Oregon, 2002.
34. R. van der Merwe and E. Wan, “Sigma-Point Kalman ilters for probabilistic inference in
dynamic state-space models,” Ph.D. dissertation, OGI School of Science and Engineering,
Beaverton, 2004.
35. K. Ito and K. Xiong, “Gaussian ilters for nonlinear iltering problems,” IEEE Trans.
Autom. Control, 45, 5, 910–927, 2000.
36. I. Arasaratnam, S. Haykin, and R. Elliott, “Discrete-time nonlinear iltering algorithms
using Gauss-Hermite quadrature,” Proc. IEEE, 95, 5, 953–976, 2007.
37. R. Bucy and K. Senne, “Digital synthesis of nonlinear ilters,” Automatica, 7, 3, 287–298,
1971.
38. K. Ito and K. Xiong, “Gaussian ilters for nonlinear iltering problems,” IEEE Trans.
Autom. Control, 45, 5, 910–927, 2000.
39. N. Cui, L. Hong, and J. Layne, “A comparison of nonlinear iltering approaches with an
application to ground target tracking,” Signal Proc., 85, 1469–1492, 2005.
40. D. Alspach and H. Sorenson, “Nonlinear Bayesian estimation using Gaussian sum approx-
imations,” IEEE Trans. Autom. Control, 17, 4, 439–448, 1972.
41. H. Sorenson and D. Alspach, “Recursive Bayesian estimation using Gaussian sums,”
Automatica, 7, 465–479, 1971.
42. J. Kotecha and P. Djuric, “Gaussian sum particle iltering,” IEEE Trans. Signal Proc., 51,
10, 2602–2612, 2003.
43. J. Candy and P. Candy, “SSPACK_PC: A model-based signal processing package on
personal computers,” DSP Applications, 2, 3, 33–42, 1993 (see http://www. techni-soft.net
for more details).
44. J. Candy and J. Zicker, “Deconvolution of noisy transient signals: A Kalman iltering
application,” LLNL Report, UCID-87432, and Proc. of CDC Conf., Orlando, 1982.
45. V. Aidala and S. Hammel, “Utilization of modiied polar-coordinates for bearings-only
tracking,” IEEE Trans. Autom. Control, AC-28, 283–294, 1983.
46. V. Aidala, “Kalman ilter behavior in bearings-only velocity and position estimation,”
IEEE Trans. Aerosp. Electron. Syst., AES-15, 29–39, 1979.
47. G. Bierman, Factorization Methods of Discrete Sequential Estimation (New York: Aca-
demic Press, 1977).
48. S. Haykin and N. de Freitas (editors), “Sequential state estimation: from Kalman ilters to
particle ilters,” Proc. IEEE, 92, 3, 399–574, 2004.
49. P. Sakov, F. Counillon, L. Bertino, K. Lisaeter, P. Oke, and A. Korablev, “TOPAZ4: an
ocean-sea ice data assimilation system for the North Atlantic and Artic,” Ocean Sci., 8,
633–656, 2012.

250
MODERN BAYESIAN STATE–SPACE PROCESSORS
PROBLEMS
6.1
Let x1 and x2 be i.i.d. with distribution (0, 1). Suppose y = x2
1 + x2
2
(a) What is the distribution of y, pY(y)?
(b) Suppose E{y} = 2 and �2
y = 4, using the sigma-point transformation what
are the �-points for x = [x1
x2]′?
(c) What are the �-points for y?
6.2
Suppose x ∼(0, 1) and y = x2
(a) What is the distribution of y, pY(y)?
(b) What is the Gaussian approximation of the mean and variance of pY(y)?
(Hint: Use linearization)
(c) What is the sigma-point transformation and corresponding mean and vari-
ance estimates of PY(y)?
6.3
From the following set of nonlinear system models, develop the SPBP algorithm
for each:
(a) Synchronous (unsteady) motor: ̈x(t) + C ̇x(t) + p sin x(t) = L(t)
(b) Dufing equation: ̈x(t) + �x(t) + �x3(t) = F cos(�t)
(c) Van der Pol equation: ̈x(t) + �̇x(t)[1 −̇x2(t)] + x(t) = m(t)
(d) Hill equation: ̈x(t) −�x(t) + �p(t)x(t) = m(t)
6.4
Suppose we are given the following discrete system
x(t) = −�2x(t −1) + sin(x(t −1)) + �u(t −1) + �(t −1)
y(t) = x(t) + �(t)
with �and �zero-mean, white Gaussian with usual covariances, R��and
R��. Develop the SPBP for this process. Suppose the parameters �and �are
unknown, develop the SPBP such that the parameters are jointly estimated along
with the states. (Hint: augment the states and parameters to create a new state
vector.)
6.5
The Mackey–Glass time delay differential equation is given by
̇x(t) =
�x(t −�)
1 + x(t −�)N −�x(t) + �(t)
y(t) = x(t) + �(t)
where �, �are constants, N is a positive integer with �and �zero-mean, white
Gaussian with covariances, R��and R��. For the parameter set: �= 0.2, �= 0.1,
�= 7 and N = 10 with x(0) = 1.2 (see Refs. [21] and [29]).
Develop the SPBP for this process.

PROBLEMS
251
6.6
Assume that a target is able to maneuver, that is, we assume that the target
velocity satisies a irst-order AR model given by
��(t) = −���(t −1) + ��(t −1)
for �∼(0, R����)
(a) Develop the Cartesian tracking model for this process.
(b) Develop the corresponding SPBP assuming all parameters are known a
priori.
(c) Develop the corresponding SPBP assuming �is unknown.
6.7
Nonlinear processors can be used to develop neural networks used in many
applications. A generic neural network behavior is governed by the following
relations:
x(t) = x(t −1) + �(t −1)
y(t) = c[x(t), u(t), �(t)] + �(t)
where x(t) is the network weights (parameters), u(t) is the input or training
sequence, �(t) is the node activators with �and �zero-mean, white Gaussian
with covariances, R��and R��.
Develop the SPBP for this process.
6.8
Consider the problem of estimating a random signal from an AM modulator
characterized by
s(t) =
√
2Pa(t) sin �ct
r(t) = s(t) + �(t)
where a(t) is assumed to be a Gaussian random signal with power spectrum
Saa(�) = 2kaPa
�2 + k2
a
Also assume that the processes are contaminated with the usual additive noise
sources: �and �zero-mean, white Gaussian with covariances, R��and R��. The
discrete-time Gauss–Markov model for this system was developed (chapter 5
problems) from the continuous-time representation using irst differences, then:
(a) Develop the SPBP.
(b) Assume the carrier frequency �c is unknown. Develop the SPBP for this
process.
6.9
Develop the Gaussian sum processor algorithm using the XBP instead of the
SPBP. In the literature, this is the usual approach that is used. How does the
overall algorithm differ? What are the apparent pitfalls involved in this approach
compared to the SPBP approach?

252
MODERN BAYESIAN STATE–SPACE PROCESSORS
6.10 We are given a sequence of data and know it is Gaussian with an unknown mean
and variance. The distribution is characterized by y ∼(�, �2).
(a) Formulate the problem in terms of a state–space representation. (Hint:
Assume that the measurements are modeled in the usual manner (scale by
standard deviation and add mean to a (0, 1) “known” sequence, say �(t)).)
(b) Using this model, develop the SPBP technique to estimate the model param-
eters.
(c) Synthesize a set of data of 2000 samples at a sampling interval dt = 0.01
with process covariance, R��= diag[1 × 10−5, 1 × 10−6] and measurement
noise of R��= 1 × 10−6 with x(0) = [
√
20
3]′.
(d) Develop the SPBP algorithm and apply it to this data, show the performance
results (inal parameter estimates, etc.). That is, ind the best estimate of the
parameters deined by Θ := [�
�]′ using the SPBP approach. Show the
mathematical steps in developing the technique and construct simple SPBP
to solve.
6.11 Design an ensemble Kalman ilter (EnKF) for the RC-circuit problem of Exam-
ple 5.1:
(a) Develop a state and measurement ensemble simulation.
(b) Develop the linear EnKF processor for this data set.
(c) Develop the linear (optimal) Kalman ilter processor and apply it to the
ensemble data.
(d) Compare the performance of both processors after “tuning” (zero-mean/
white).

7
PARTICLE-BASED BAYESIAN
STATE–SPACE PROCESSORS
7.1
INTRODUCTION
In this chapter, we develop particle-based processors using the state–space repre-
sentation of signals and show how they evolve from the Bayesian perspective using
their inherent Markovian structure along with importance sampling techniques as
our basic construct. Particle ilters offer an alternative to the Kalman model-based
processors discussed in the previous chapters possessing the capability not just to
characterize unimodal distributions but also to characterize multimodal distributions.
We irst introduce the generic state–space particle ilter (SSPF) and investigate some
of its inherent distributions and implementation requirements. We develop a generic
sampling-importance-resampling (SIR) processor and then perhaps its most popular
form—the “bootstrap” particle ilter. Next, we investigate the resampling problem
and some of the more popular resampling techniques also incorporated into the boot-
strap ilter from necessity. The bootstrap and its variants are compared to the classical
and modern processors of the previous chapters. Finally, we apply these processors
to a variety of problems and evaluate their performance using statistical testing as
part of the design methodology.
7.2
BAYESIAN STATE–SPACE PARTICLE FILTERS
Particle iltering (PF) is a sequential Monte Carlo method employing the sequen-
tial estimation of relevant probability distributions using the “importance sampling”
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
253

254
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
techniques developed in Chapter 3 and the approximations of distributions with dis-
crete random measures [1–4]. The key idea is to represent the posterior distribution
by a set of Np random samples, the particles, with associated weights, {xi(t), i(t)};
i = 1, … , Np, and compute the required Monte Carlo estimates. Of course, as the
number of particles becomes very large the MC representation becomes an equiva-
lent characterization of the analytical description of the posterior distribution (e.g.,
see Example 3.12 which converges to the optimal Bayesian estimate).
Thus, particle iltering is a technique to implement sequential Bayesian estima-
tors by MC simulation. It offers an alternative to approximate Kalman iltering for
nonlinear problems [1, 5]. In PF, continuous distributions are approximated by “dis-
crete” random measures composed of these weighted particles or point masses where
the particles are actually samples of the unknown or hidden states from the state–
space representation and the weights are the “probability masses” estimated using
the Bayesian recursions as shown in Fig. 7.1. From the igure, we see that associated
with each particle xi(t) is a corresponding weight or (probability) mass i(t) (illed
8( )
X
t
8( )
W t
(
)
(
)
1
ˆPr
|
( )
( )
( )
P
N
i
i
t
t
i
X Y
W t
( )
i
W t
X t
X t
=
=
−
∑
( )
iX t
Particle no. 
22
21
20
19
18
17
16
1415
13
12
11
910
8
7
6
5
4
3
2
1
0
0.02
0.04
0.06
Probability
Particles
FIGURE 7.1
Particle ilter representation of posterior probability distribution in terms of
weights (probabilities) and particles (samples).

7.2
BAYESIAN STATE–SPACE PARTICLE FILTERS
255
circle). Knowledge of this random measure {xi(t), i(t)} characterizes an estimate
of the instantaneous (at time t) iltering posterior distribution (dashed line),
̂Pr(x(t)|Yt) ≈
Np
∑
i=1
i(t)�(x(t) −xi(t))
We observe from the igure that the particles need not be equally spaced or conform
to a uniform grid and that they tend to coalesce in high probability regions (HPR).
Importance sampling plays a crucial role in state–space particle algorithm devel-
opment. The PF does not involve linearizations around current estimates, but rather
approximations of the desired distributions by these discrete random measures in
contrast, to the Kalman ilter which sequentially estimates the conditional mean and
covariance used to characterize the (Gaussian) iltering posterior Pr(x(t)|Yt). Particle
ilters are a sequential MC methodology based on “point mass” representation of
probability distributions that only require a state–space representation of the under-
lying process. This representation provides a set of particles that evolve at each
time-step leading to an instantaneous approximation of the target posterior distribu-
tion of the state at time t, given all of the data up to that time. Figure 7.2 illustrates
the evolution of the posterior at each time-step. Here we see the estimated posterior
at times t1, t2 to t6 creating an instantaneous approximation of t vs. xi vs. ̂Pr(x(t)|Yt).
Statistics are calculated across the ensemble at each time-step to provide estimates of
the states. For example, the minimum mean-squared error (MMSE) or equivalently
the conditional mean (CM) estimate is easily determined by averaging over xi, since
̂xMMSE(t) = ̂xCM(t) = ∫x(t)Pr(x(t)|Yt)dx ≈∫x(t) ̂Pr(x(t)|Yt)dx
= ∫x(t)
⎛
⎜
⎜⎝
Np
∑
i=1
i(t)�(x(t) −xi(t))
⎞
⎟
⎟⎠
dx =
Np
∑
i=1
i(t)xi(t)
The maximum a posteriori (MAP) estimate is simply determined by inding the
sample corresponding to the maximum weight of xi(t) across the ensemble at each
time-step (as illustrated in Fig. 7.2), that is,
̂xMAP(t) = arg max
xi(t)
̂Pr(x(t)|Yt)
(7.1)
In Bayesian processing, the idea is to sequentially estimate the posterior Pr(x(t −
1)|Yt−1) →Pr(x(t)|Yt). Recall that optimal algorithms “exactly” track these distribu-
tions; however, they are impossible to implement because the updates require integra-
tion that cannot usually be performed analytically. Recall that the batch joint posterior
distribution follows directly from the chain rule under the Markovian assumptions
on x(t) and the conditional independence of y(t), that is,
Pr(Xt|Yt) =
t∏
i=0
Pr(x(i)|x(i −1)) × Pr(y(i)|x(i))
for Pr(x(0)) := Pr(x(0)|x(−1))
(7.2)

256
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
(
)
1
Pr
( )|
i
t
X t
Y
( )
i
X t
1
( )
t
(
)
2
Pr
( )|
i
t
X t
Y
(
)
3
Pr
( )|
i
t
X t
Y
(
)
4
Pr
( )|
i
t
X t
Y
(
)
5
Pr
( )|
i
t
X t
Y
(
)
6
Pr
( )|
i
t
X t
Y
t6
t5
t4
t3
t2
t1
[
]
[
]
 
( )
i
W t
MAP
ˆX
2
( )
t
MAP
ˆX
3
( )
t
MAP
ˆX
( )t
MAP
ˆX
4
( )
t
MAP
ˆX
5
( )
t
MAP
ˆX
6
( )
t
MAP
ˆX
( )t
MAP
ˆX
Time-step
Particle no.
Probability 
FIGURE 7.2
Particle ilter surface (Xi vs. t vs. ̂Pr(Xi(t)|Yt)) representation of posterior
probability distribution in terms of time (index),particles (samples),and weights or prob-
abilities (left plot illustrates extracted MAP estimates vs. t).
The corresponding sequential importance sampling solution to the Bayesian esti-
mation problem was given generically in Eq. 3.59 starting with the recursive form
for the importance distribution as
q(Xt|Yt) = q(Xt−1|Yt−1) × q(x(t)|Xt−1, Yt)
leading to the sequential expression for the importance weights as
W(t) ∝Pr(Xt|Yt)
q(Xt|Yt) =
Pr(Yt|Xt) × Pr(Xt)
q(Xt−1|Yt−1) × q(x(t)|Xt−1, Yt)
W(t) = W(t −1) ×
Likelihood
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(y(t)|x(t)) ×
Transition
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
Pr(x(t)|x(t −1))
q(x(t)|Xt−1, Yt)
(7.3)
Similarly, the SSPF evolving from this sequential importance sampling construct
follows directly. Recall that the generic state–space characterization representing the

7.2
BAYESIAN STATE–SPACE PARTICLE FILTERS
257
transition and likelihood probabilities is
Pr(x(t)|x(t −1)) ⇔(x(t)|x(t −1))
Pr(y(t)|x(t)) ⇔(y(t)|x(t))
which leads to an alternate representation of Eq. 7.2
Pr(Xt|Yt) =
t∏
i=0
(x(i)|x(i −1)) × (y(i)|x(i))
for (x(0)|x(−1)) := Pr(x(0))
(7.4)
Thus the generic state–space sequential importance sampling solution is given by
xi(t) ∼q(x(t)|Xt−1, Yt)
Wi(t) = Wi(t −1) × (y(t)|xi(t)) × (x(t)|xi(t −1))
q(xi(t)|Xt−1(i), Yt)
i(t) =
Wi(t)
∑Np
i=1 Wi(t)
(7.5)
where the sample at time t, xi(t) is referred to as the population or system of particles
and Xt(i) for the ith-particle as the history (trajectory or path) of that particular particle
[6]. It is important to note that a desired feature of sequential MC sampling is that
the Np-particles of Xt(i) are i.i.d.
In the practical application of the SSPF algorithm, we can obtain samples from
the posterior by augmenting each of the existing samples with the new state draw,
that is,
Xt(i) = {xi(t), Xt−1(i)}
where xi(t) ∼q(x(t)|Xt−1, Yt) and Xt−1(i) ∼q(Xt−1|Yt−1).
Now if we further assume that
q(x(t)|Xt−1, Yt) →q(x(t)|x(t −1), y(t))
(7.6)
then the importance distribution is only dependent on [x(t −1), y(t)] which is common
when performing iltering Pr(x(t)|Yt) at each instant of time.

258
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
Assuming this is true, then the SSPF with xi(t) →Xt(i) and y(t) →Yt recursion
becomes
xi(t) ∼q(x(t)|x(t −1), y(t))
Wi(t) = Wi(t −1) × (y(t)|xi(t)) × (x(t)|xi(t −1))
q(xi(t)|xi(t −1), y(t))
i(t) =
Wi(t)
∑Np
i=1 Wi(t)
(7.7)
and the iltering posterior is estimated by
̂Pr(x(t)|Yt) ≈
Np
∑
i=1
i(t) × �(x(t) −xi(t))
(7.8)
We summarize the generic SSPF in Table 7.1. Note that as Np becomes large, in
the limit, we have
lim
Np→∞
̂Pr(x(t)|Yt) →Pr(x(t)|Yt)
(7.9)
which implies that the Monte Carlo error decreases as the number of particles
increase.
7.3
IMPORTANCE PROPOSAL DISTRIBUTIONS
Selection of the importance distribution is a critical part of the design phase in
particle iltering. Besides assuring that the distribution “covers” the posterior, there
are a number of properties that can also be satisied to achieve a robust design.
7.3.1
Minimum Variance Importance Distribution
Unfortunately, the generic algorithm presented in the previous section has a serious
law, the variance of the importance weights increases over time [4, 6]. Therefore,
the algorithm degenerates to a single non-zero weight after a few iterations. One
way to limit this degeneracy is to choose an importance distribution that minimizes
the weight variance based on the available information [Xt−1, Yt]. That is, we would
like the solution to the problem of minimizing the variance Vq(x(t)|Xt−1,Yt)(Wi(t)) with
respect to q(⋅) such that
Vq(Wi(t)) = W2
i (t)
[
∫
(Pr(y(t)|x(t))Pr(x(t)|Xt−1(i)))2
q(x(t)|Xt−1(i), Yt)
dx(t) −Pr(y(t)|Xt−1(i))2
]

7.3
IMPORTANCE PROPOSAL DISTRIBUTIONS
259
TABLE 7.1
Generic State–Space Particle Filtering Algorithm
Initialize
xi(0) →Pr(x(0));
Wi(0) = 1
Np
;
i = 1, … , Np
[Sample]
Importance Sampling
xi(t) ∼(x(t)|xi(t −1))
[State transition]
State–Space Transition
(x(t)|xi(t −1)) ⇐A(x(t −1), u(t −1), �i(t −1));
�i ∼Pr(�i(t))
[Transition]
Measurement Likelihood
(y(t)|xi(t)) ⇐C(xi(t), u(t), �(t));
�∼Pr(�(t))
[Likelihood]
Weight Update
Wi(t) = Wi(t −1) × (y(t)|xi(t)) × (x(t)|xi(t −1))
q(xi(t)|xi(t −1), y(t))
[Weights]
Weight Normalization
i(t) =
Wi(t)
∑Np
i=1 Wi(t)
[Weight normalization]
Distribution
̂Pr(x(t)|Yt) ≈
Np∑
i=1
i(t)�(x(t) −xi(t))
[Posterior distribution]
State Estimation (Inference)
̂x(t|t) = E{x(t)|Yt} ≈
Np∑
i=1
i(t)xi(t)
[Conditional mean]
̂XMAP(t) = arg max
xi(t)
̂Pr(x(t)|Yt)
[Maximum a posteriori]
̂XMED(t) = median
{
̂Pr(x(t)|Yt)
}
[Median]
is minimized. It has been shown [4] that the minimum variance importance distribu-
tion that minimizes the variance of the set of weights {Wi(t)} is given by
qMV(x(t)|Xt−1, Yt) →Pr(x(t)|x(t −1), y(t))
(7.10)
Let us investigate this minimum variance proposal distribution in more detail
to determine its realizability. Using Bayes’ rule we can decompose1 this proposal
distribution in steps with A = x(t) and B = x(t −1), y(t):
Pr(x(t)|x(t −1), y(t)) = Pr(x(t −1), y(t)|x(t)) × Pr(x(t))
Pr(x(t −1), y(t))
(7.11)
1 We apply the following form of Bayes’ rule: Pr(A|B) = Pr(B|A) × Pr(A)∕Pr(B).

260
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
but the irst term in the numerator can be decomposed further to obtain
Pr(x(t −1), y(t)|x(t)) = Pr(y(t)|x(t −1), x(t)) × Pr(x(t −1)|x(t))
= Pr(y(t)|x(t −1), x(t)) ×
[Pr(x(t)|x(t −1))Pr(x(t −1))
Pr(x(t))
]
(7.12)
Substituting this relation into Eq. 7.11 and canceling the Pr(x(t)) terms, we obtain
Pr(x(t)|x(t −1), y(t)) = Pr(y(t)|x(t −1), x(t)) × Pr(x(t)|x(t −1)) × Pr(x(t −1))
Pr(x(t −1), y(t))
(7.13)
Expand the denominator in Eq. 7.13 using Bayes’ rule,
Pr(x(t −1), y(t)) = Pr(y(t)|x(t −1)) × Pr(x(t −1))
substitute, cancel the Pr(x(t −1)) terms and apply the conditional independence
assumption of the measurements on past states, that is,
Pr(y(t)|x(t −1), x(t)) →Pr(y(t)|x(t))
to obtain the inal expression for the minimum variance proposal distribution as
qMV(x(t)|Xt−1, Yt) = Pr(x(t)|x(t −1), y(t)) = Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
Pr(y(t)|x(t −1))
(7.14)
If we substitute this expression for the importance distribution in the weight recursion
of Eq. 3.63, then we have
W(t) = W(t −1) × Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
qMV(x(t)|Xt−1, Yt)
or
W(t) = W(t −1)Pr(y(t)|x(t))Pr(x(t)|x(t −1)) ×
[
Pr(y(t)|x(t −1))
Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
]
Canceling like terms and applying the Chapman–Kolmogorov relation, we obtain the
corresponding minimum variance weights
WMV(t) = WMV(t −1) × Pr(y(t)|x(t −1)) = WMV(t −1)
× ∫(y(t)|x(t)) × (x(t)|x(t −1)) dx(t)
(7.15)

7.3
IMPORTANCE PROPOSAL DISTRIBUTIONS
261
which indicates that the importance weights can be calculated before the particles
are propagated to time t. From this expression we can also see the problem with
the minimum variance importance function approach: (1) we must sample from
Pr(x(t)|x(t −1), y(t)); and (2) we must evaluate the integral which generally has no
analytic form.
7.3.2
Transition Prior Importance Distribution
Another choice for an importance distribution is the transition prior. This prior is
deined in terms of the state–space representation by (x(t)|x(t −1)) ⇐A(x(t −1),
u(t −1), �(t −1)) which is dependent on the known excitation and process noise
statistics and is given by
qprior(x(t)|x(t −1), Yt) →Pr(x(t)|x(t −1))
Substituting this choice into the expression for the weights of Eq. 7.3 gives
Wi(t) = Wi(t −1) × Pr(y(t)|xi(t)) × Pr(x(t)|xi(t −1))
qprior(x(t)|xi(t −1), Yt)
= Wi(t −1) × (y(t)|xi(t))
(7.16)
since the priors cancel.
Note two properties for this choice of importance distribution. First, the weight
does not use the most recent observation y(t) and second it does not use the past
particles xi(t −1)) but only the likelihood. This choice is easily implemented and
updated by simply evaluating the measurement likelihood, (y(t)|xi(t)); i = 1, … , Np
for the sampled particle set. In contrast to the minimum variance choice, these weights
require the particles to be propagated to time t before the weights can be calculated.
This choice of importance distribution can lead to problems, since the transition
prior is not conditioned on the measurement data, especially the most recent. Failing
to incorporate the latest available information from the most recent measurement to
propose new values for the states leads to only a few particles having signiicant
weights when their likelihood is calculated. The transition prior is a much broader
distribution than the likelihood, indicating that only a few particles will be assigned
a large weight. Thus, the algorithm will degenerate rapidly and lead to poor per-
formance especially when data outliers occur or measurement noise is small. These
conditions lead to a “mismatch” between the prior prediction and posterior distribu-
tions. Techniques such as the auxiliary particle ilter [2, 7, 8] as well as local linearized
particle ilters [4, 6, 9] have been developed that drive the particles to regions of high
likelihood by incorporating the current measurement. Thus, the SSPF algorithm takes
the same generic form as before with the minimum variance approach; however, we
note that the importance weights are much simpler to evaluate with this approach
which has been termed the bootstrap PF, the condensation PF, or the survival of the
ittest algorithm. We summarize the bootstrap PF algorithm in Table 7.2 to follow.

262
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
TABLE 7.2
Bootstrap SIR State–Space Particle Filtering Algorithm
Initialize
xi(0) ∼Pr(x(0))
Wi(0) = 1
Np
i = 1, … , Np
[Sample]
Importance Sampling
xi(t) ∼(x(t)|xi(t −1)) ⇐A(x(t −1), u(t −1), �i(t −1));
�i ∼Pr(�i(t))
[State transition]
Weight Update
Wi(t) = (y(t)|xi(t)) ⇐C(x(t), u(t), �(t));
�∼Pr(�(t))
[Weight/likelihood]
Weight Normalization
i(t) =
Wi(t)
∑Np
i=1 Wi(t)
Resampling Decision
̂Neff =
1
∑Np
i=1 W2
i (t)
[Effective samples]
̂Neff =
{ Resample
≤Nthresh
Accept
> Nthresh
Resampling
̂xi(t) ⇒xi(t)
Distribution
̂Pr(x(t)|Yt) ≈
Np∑
i=1
i(t)�(x(t) −̂xi(t))
[Posterior distribution]
7.4
RESAMPLING
The main objective in simulation-based sampling techniques is to generate i.i.d.
samples from the targeted posterior distribution in order to perform statistical infer-
ences extracting the desired information. Thus, the importance weights are quite
critical since they contain probabilistic information about each speciic particle. In
fact, they provide us with information about “how probable a sample drawn from the
target posterior has been” [10, 11]. Therefore, the weights can be considered accep-
tance probabilities enabling us to generate independent (approximately) samples from
the posterior Pr(x(t)|Yt). Recall that the empirical distribution ̂Pr(x(t)|Yt) is deined
over a set of inite (Np) random measures {xi(t), i(t)}; i = 1, … , Np approximating
the posterior, that is,
̂Pr(x(t)|Yt) ≈
Np
∑
i=1
i(t)�(x(t) −xi(t))
(7.17)
One of the major problems with importance sampling algorithms is the depletion
of the particles. The degeneracy of the particle weights creates a problem that must be
resolved before these algorithms can be of any pragmatic use. It occurs because the
variance of the importance weights increases in time [4] thereby making it impossible

7.4
RESAMPLING
263
Target PDF 
Importance sampling PDF 
Resampling
Weights 
FIGURE 7.3
Resampling consists of processing the predicted particles with their asso-
ciated weights (probabilities), duplicating those particles of high weight (probability)
and discarding those of low weight.
to avoid this weight degradation. Degeneracy implies that a large computational effort
is devoted to updating particles whose contribution to the posterior is negligible. This
approach is bound to fail in the long run, since the weight degeneration leads to a few
particles containing most of the probability mass. Thus, there is a need to somehow
resolve this problem to make the sequential simulation-based techniques viable. This
requirement leads to the idea of “resampling” the particles.
Resampling involves sampling Np-draws from the current population of particles
using the normalized weights as selection probabilities. The resampling process is
illustrated in Fig. 7.3. Particles of low probability (small weights) are removed and
those of high probability (large weights) are retained and replicated. Resampling
results in two major effects: (1) the algorithm is more complex and is not merely the
simple importance sampling method; and (2) the resampled trajectories Xt(i) are no
longer i.i.d. and the normalized weights are set to 1∕Np.
Resampling, therefore, can be thought of as a realization of enhanced particles
̂xk(t) extracted from the original samples xi(t) based on their “acceptance probability”
i(t) at time t. Statistically, we have
Pr(̂xk(t) = xi(t)) = i(t)
for i = 1, … , Np
(7.18)
or we write it symbolically as
̂xk(t) ⇒xi(t)

264
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
where “⇒” deines the resampling operator generating a set of new particles {̂xk(t)}
replacing the old set {xi(t)}.
To see how this is achieved, consider the following resampling example.
Example 7.1
Consider the following example of resampling emphasizing the generation of more
particles in the HPR and the elimination (by draws) of particles with small probabil-
ities (weights). Assume we have 100 balls (samples) with the following distribution
and corresponding probabilities:
r White (W) = 40 — Pr(W) = 0.40
r Blue
(B) = 25 — Pr(B) = 0.25
r Red
(R) = 10 — Pr(R) = 0.10
r Green (G) = 2 — Pr(W) = 0.02
The balls are placed into an urn individually as indicated in Fig. 7.4a with the corre-
sponding histogram shown in Fig. 7.4b. Next, the balls are sampled with replacement
100 times and their new counts recorded. The new or resampled histogram is shown
in Fig. 7.4c where we see that those balls of highest probabilities are drawn more fre-
quently and therefore retained, since it is more likely that they will be selected rather
than those of smaller probabilities. This leads to the shape of the new histogram
and the elimination of the low probability green balls. Hypothetically, resampling
generates the following probabilities:
r White (W) = 60 — Pr(W) = 0.60
r Blue
(B) = 20 — Pr(B) = 0.20
r Red
(R) = 8 —
Pr(R) = 0.08
r Green (G) = 0 — Pr(W) = 0.00
illustrating this process.
△△△
Thus, the fundamental concept in resampling theory is to preserve particles with
large weights (i.e., large probabilities) while discarding those with small weights.
Two steps must occur to resample effectively: (1) a decision, on a weight-by-weight
basis, must be made to select the appropriate weights and reject the inappropriate; and
(2) resampling must be performed to minimize the degeneracy. This overall strategy
when coupled with importance sampling is termed sequential sampling-importance-
resampling (SIR) [4].
A reasonable measure of degeneracy is the effective particle sample size based on
the coeficient of variation [12] deined by
Neff (t) :=
Np
Eq{W2(t)} =
Np
1 + Vq(W(t)) ≤Np
(7.19)

7.4
RESAMPLING
265
Original
Resampled
(a)
(b)
(c)
FIGURE 7.4
Hypothetical resampling: (a) Urn of white, blue, red, and green balls; (b)
Original distribution (histogram): Pr(W) = 0.40, Pr(B) = 0.25, Pr(R) = 0.10, and Pr(G) =
0.02; (c) Resampled distribution (histogram): Pr(W) = 0.60,Pr(B) = 0.20,Pr(R) = 0.08,and
Pr(G) = 0.0.
An estimate of the effective number of particles at time t is given by
̂Neff(t) =
1
∑Np
i=1 W2
i (t)
(7.20)
and a decision based on the rejection method [13] is made by comparing it to
a threshold Nthresh. That is, when ̂Neff(t) is less than the threshold, resampling is
performed.
̂Neff(t) =
{≤Nthresh
Resample
> Nthresh
Accept

266
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
x
( )
PX x
ix
1
0
( )
PX
ix
(
)
1
PX
ix +
1
ix +
u
0
1
ui
( )
i
W t
( )
(
)
( )
1
P
Pr
( )
i
k
i
X
k
x
x
x t
W t
=
=
≤
= ∑
FIGURE 7.5
Resampling (with replacement) by inverse transforming a uniform sampler
to generate samples from target distribution.
Once the decision is made to resample, a uniform sampling procedure [14] can
be applied removing samples with low importance weights and replicating samples
with high importance weights. Resampling (with replacement) generates a set of new
samples with uniform weights from an approximate discrete posterior distribution,
̂Pr(x(t)|Yt) ≈
Np
∑
i=1
̂i(t)�(x(t) −̂xi(t))
(7.21)
so that Pr[̂xi(t) = xj(t)] = ̂Wj(t). The resulting independent and identically distributed
sample from the probability mass of Eq. 7.21 is uniform such that the sampling
induces the mapping of {̂xi(t), ̂i(t)} →{xi(t), i(t)}, ̂i(t) = 1∕Np∀i. The selection
of ̂xi(t) = xj(t) is shown in Fig. 7.5. Here the procedure is termed systematic resam-
pling [4]. For each resampled particle, that is, Ni-times is related to the original
particle. The methodology relies on uniformly sampling the cumulative distribution
function resulting in the new replicated particles or uniform weighting. The resam-
pling algorithm is incorporated in Table 7.2.
Resampling decreases the degeneracy problem algorithmically, but introduces
its own set of problems. After one resampling step, the simulated trajectories are no
longer statistically independent. Therefore, the simple theoretical convergence results

7.4
RESAMPLING
267
under these assumptions lose their validity. Pragmatically, resampling can limit algo-
rithm parallelization because combining particles causes an increase in computational
complexity. Also there is a possible loss in diversity caused by replication of those
particles with highest importance weights [4]. Thus as with any methodology there
are tradeoffs that must be considered.
7.4.1
Multinomial Resampling
There are a variety of techniques available to implement the basic resampling method
[1, 6, 15–19]. The usual approach is to resample with replacement, since the prob-
ability of each particle xi(t) is given by the normalized weight Wi(t). Therefore,
the number of times Ni that each particular particle in the original set {xi(t)} is
selected follows a binomial distribution Bin(Np, Wi(t)). The corresponding vector
[N1, … , NNp] is distributed according to a multinomial distribution with parameter
Np and probability of success [W1(t), … , WNp(t)]. With this resampling scheme, par-
ticles in the original set with small variance weights are most likely discarded, while
those of high weights are replicated in proportion to these weights. The multinomial
resampling method is given by
r Given a random measure at time t, that is, a set of particles and weights,
{xi(t), Wi(t)}, i = 1, … , Np;
r Sample uniformly, uk →U(0, 1); k = 1, … , Np;
r Determine the index, ik: ik = k for Pr(xik(t) = xk(t)) = uk;
r Select a new sample ̂xik(t) ⇒xi(t) and weight ̂Wik(t) = 1
Np based on the new
sample index ik; and
r Generate
the
new
random
(resampled)
measure:
{̂xik, ̂Wik(t)};
for
k = 1, … , Np.
Here, the index notation ik designates the original ith particle or parent and the new
kth particle using the inverse CDF method of Section 3.3. This sampling scheme
is equivalent to drawing ik; k = 1, … , Np samples from a multinomial distribution
with parameters (Nik, Wik(t)) and corresponding statistics: mean E{Nik} = Np and
variance,Var(Nik) = NpWik(t)(1 −Wik(t)).
The basic idea is to irst construct the CDF from the original random measure
{xi(t), Wi(t)}, since it is given by
Pr(X(t) ≤xi(t)) ≈
Np
∑
i=1
Wi(t)�(x(t) −xi(t))
(7.22)
where �(⋅) is the unit step function.

268
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
Uniform samples uk are drawn from the interval [0, 1] and projected onto the
inverse CDF (see Section 3.3) corresponding to the associated probability and iden-
tifying the particular new particle sample index ik and corresponding replacement
particle ̂xik(t) leading to the resampling
̂xik(t) ⇒xi(t)
(7.23)
Clearly those particles or samples with highest probability (or weights) will be
selected more frequently, thereby, replacing particles with lower probability (weights)
and therefore, the new random measure is created, that is,
{̂xik(t), ̂Wik(t)} ⇒{xi(t), Wi(t)}
with ̂Wik(t) = 1
Np
(7.24)
This resampling technique represents a direct implementation of random sampling
by generating an i.i.d. sample from the empirical posterior distribution
Pr(x(t)|Yt) ≈
Np
∑
i=1
Wi(t)�(x(t) −xi(t))
→
Np
∑
i=1
̂Wik(t)�(x(t) −̂xik(t)) = 1
Np
Np
∑
i=1
�(x(t) −̂xik(t))
(7.25)
A second more eficient way of generating this measure is the “systematic” resam-
pling method.
7.4.2
Systematic Resampling
The systematic resampling method is based on an ordered technique in which a set of
Np-ordered uniform variates are generated [20, 21]. It minimizes the error variance
between the original selected sample and its mean. Thus, the systematic sampling
method is given by
r Given a random measure at time t, that is, a set of particles and weights,
{xi(t), Wi(t)}, i = 1, … , Np;
r Sample uniform Np-ordered variates:
̂uk = uk + k−1
Np for k = 1, … , Np
and
uk →U(0, 1);
r Determine the index, ik: ik = k for PX(xk−1(t)) ≤̂uk ≤PX(xk(t)); (see Fig. 7.4)
r Select a new sample, ̂xik(t) ⇒xi(t) and weight, ̂Wik(t) = 1
Np based on the new
sample index, ik; and
r Generate the new random (resampled) measure: {̂xik, ̂Wik(t)}; for k = 1, … ,
Np.

7.4
RESAMPLING
269
where recall the CDF is given by: PX(xk(t)) = ∑Np
k=1 Wk(t)�(x(t) −xk(t)) with �(⋅) is
a unit step function.
The inal sampling scheme we discuss has a low weight variance, the residual
method.
7.4.3
Residual Resampling
The residual resampling method is based on the idea of estimating the number of
times each particle should be replicated, that is, the ith particle is replicated, say
Np(i) := Int(E{Np(i)}) = Int(Np × Wi(t))
(7.26)
times where Int means the “smallest integer value of”.
The remaining particles are sampled using the multinomial sampling method
discussed above. Here we have
Np(t) := Np −
Np
∑
i=1
Np(i)
(7.27)
with corresponding weights
̂Wi(t) =
1
Np(t)
(NpWi(t) −Np(i))
(7.28)
The overall effect is to reduce the variance by E{(Np(i) −E{Np(i)})2}, since the
particles cannot be replicated less than E{Np(i)} times.
We summarize the residual resampling method by
r Given a random measure at time t, that is, a set of particles and weights,
{xi(t), Wi(t)}, i = 1, … , Np;
r Calculate Np(i): Np(i) = Int(Np × Wi(t));
r Multinomial sample: ̂xi(t) ⇒xi(t) for i = 1, … , Np(i); and
r Update the new random (resampled) measure: {̂xik, ̂Wik(t)}; for k = 1, … , Np.
So we see that there are a variety of resampling schemes that can be employed
to solve the particle degeneracy problem. We can now update our generic particle
iltering algorithm to incorporate a resampling procedure and alleviate the degeneracy
problem created by the variation of the weights.
To visualize the “resampling” approach mitigating the particle degeneracy prob-
lem, the SIR is illustrated in Fig. 7.6. Here we show the evolution of the particles

270
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
{
}
( ),
( )
i
i
x t W t
{
}
(
1),
(
1)
i
i
x t
W t
+
+
{
}
ˆ
ˆ (
1),
(
1)
i
i
x t
W t
+
+
1
Pr
(
1)
t
x t
Y −
−
Pr
( )
t
x t Y
1
Pr
(
1)
t
x t
Y +
+
1
t −
1
t +
t
{
}
ˆ
ˆ ( ),
( )
i
i
x t W t
(
)
(
1)| (
1)
C y t
x t
+
+
{
}
ˆ
ˆ (
1),
(
1)
i
i
x t
W t
−
−
(
)
( )| ( )
C y t
x t
(
)
(
2)| (
1)
A x t
x t
+
+
(
)
| ( )
A
x t
(
1)
x t+
(
)
|
A ( )
x t
(
1)
x t−
Update
Update
Resam- 
ple 
Resam- 
ple 
Resam- 
ple 
P
r
e
d
i
c
t
P
r
e
d
i
c
t
P
r
e
d
i
c
t
FIGURE 7.6
Evolution of particle ilter weights and particles using the sequential state–
space SIR algorithm: resampling, propagation-step (state–space transition model),
update-step (state–space measurement likelihood), resampling … .
and weights starting with the uniform weighting
(
̂Wi(t −1) = 1
Np
)
. Once the ini-
tial weights are updated, they are resampled uniformly. Next, they are propagated
using the state–space transition mechanism (model), then updated using the mea-
surement likelihood producing the measure {xi(t), Wi(t)}, i = 1, … , Np leading to an
approximation of the posterior distribution at time t. This measure is then resampled,
propagated, updated, and so on. A generic low diagram of the algorithm is shown in
Fig. 7.7 where we again illustrate the basic ingredients of the SIR technique.
7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
There are a number of pragmatic PF techniques that have been introduced in the
literature. Here we discuss some of the more robust and popular techniques that have
been applied to a wide variety of problems starting with the bootstrap processor
[1, 2, 6].
7.5.1
Bootstrap Particle Filter
The basic “bootstrap” algorithm developed by Gordon, Salmond, and Smith [16] is
one of the irst practical implementations of the processor to the tracking problem.

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
271
{
}
ˆ
ˆ (
1),
(
1)
i
i
x t
W t
−
−
1
Pr
(
1)
t
x t
Y −
−
{
}
ˆ
ˆ ( ),
( )
i
i
x t W t
1
Pr
( )
t
x t Y −
Pr
( )
t
x t Y
{
}
( ),
( )
i
i
x t W t
{
}
( ),
( )
i
i
x t W t
(
)
( ) | (
1)
A x t
x t −
(
)
( ) | ( )
C y t
x t
ˆ
ˆ
( )
( )
( )
( )
i
i
i
i
x t
x t
W t
W t
⇒
⇒
( )
y t
1
t
t
⇒+
Pr
( )
t
x t Y
Initialize
State−space SIR algorithm 
Predict
Update
Resample
New 
sample?
Yes 
Output
Data
No 
Resample?
FIGURE 7.7
State–space SIR particle iltering algorithm structure:initialization,propaga-
tion (state transition), updating (measurement likelihood), resampling.
It is the most heavily applied of all PF techniques due to its simplicity. Thus, the
SSPF algorithm takes the same generic form as before with the minimum variance
approach; however, we note that the importance weights are much simpler to evaluate
with this approach which has been termed the bootstrap PF, the condensation PF, or
the survival of the ittest algorithm [2, 16, 22].
As mentioned previously, it is based on sequential SIR ideas and uses the transition
prior as its underlying proposal distribution,
qprior(x(t)|x(t −1), Yt) = Pr(x(t)|x(t −1))
The corresponding weight becomes quite simple and only depends on the likelihood;
therefore, it is not even necessary to perform a sequential updating because
W(t) =
(Pr(y(t)|x(t)) × Pr(x(t)|x(t −1))
Pr(x(t)|x(t −1))
)
× W(t −1) = Pr(y(t)|x(t)) × W(t −1)

272
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
since the ilter requires resampling to mitigate variance (weight) increases at each
time-step [16]. After resampling, the new weights become
(t) →
1
Np
⇒W(t) = Pr(y(t)|x(t)) = (y(t)|x(t))
revealing that there is no need to save the likelihood (weight) from the previous
step! With this in mind we summarize the simple bootstrap particle ilter algorithm
in Table 7.2. One of the primary features as well as shortcomings of this technique
is that it does not use the latest available measurement in the importance proposal,
but only the previous particles xi(t −1), which differs from the minimum variance
approach. Also in order to achieve convergence, it is necessary to resample at every
time-step. In practice, however, many applications make the decision to resample
based on the effective sample-size metric discussed in the previous section.
In order to construct the bootstrap PF, we assume that: (1) xi(0) ∼Pr(x(0)) is
known; (2) (x(t)|x(t −1)), (y(t)|x(t)) are known; (3) samples can be generated
using the process noise input and the state-space model A(x(t −1), u(t −1), �(t −1));
(4) the likelihood is available for point-wise evaluation (y(t)|x(t)) based on the
measurement model C(x(t), �(t)); and (5) resampling is performed at every time-step.
To implement the algorithm we
r Generate the initial state xi(0)
r Generate the process noise �i(t)
r Generate the particles xi(t) = A(xi(t −1), u(t −1), �i(t −1))—the prediction-
step
r Generate
the
likelihood
(y(t)|xi(t))
using
the
current
particle
and
measurement—the update step
r Resample the set of particles retaining and replicating those of highest weight
(probability) ̂xi(t) ⇒xi(t)
r Generate the new set {̂xi(t), ̂i(t)} with ̂i(t) = 1
Np
Next, we revisit the model of Jazwinski [21] in Chapter 5 and apply the simple
bootstrap algorithm to demonstrate the PF solution using the state–space SIR particle
iltering algorithm.
Example 7.2
Recall the discrete state–space representation of the basic problem given by the
Markovian model:
x(t) = (1 −0.05△T)x(t −1) + 0.04△Tx2(t −1) + �(t −1)
y(t) = x2(t) + x3(t) + �(t)

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
273
where △t = 0.01, �∼(0, 10−6) and �∼(0, 0.09). The initial state is Gaussian
distributed with xi(0) ∼(x(0), P(0)) and x(0) = 2.0, P(0) = 10−2.
We selected the following simulation run parameters:
Number of Particles:
250
Number of Samples:
150
Number of States:
1
Sampling Interval:
0.01 s
Number of Measurements:
1
Process Noise Covariance:
1 × 10−6
Measurement Noise Covariance:
9 × 10−2
Initial State:
2
Initial State Covariance:
10−20
Thus, the bootstrap SIR algorithm of Table 7.2 for this problem becomes:
1. Draw samples (particles) from the state transition distribution: xi(t) →(x(t) :
a[x(t −1)], R��), that is, generate
�i(t) →Pr(�(t)) ∼(0, R��)
and calculate {xi(t)} using the process model and �i(t)
xi(t) = (1 −0.05△T)xi(t −1) + 0.04△Tx2
i (t −1) + �i(t −1)
2. Estimate
the
weight/likelihood,
Wi(t) = (y(t)|xi(t)) →(y(t) : c[xi(t)],
R��(t))
c[xi(t)] = x2
i (t) + x3
i (t)
ln (y(t)|xi(t)) = −1
2 ln 2�R��−
(y(t) −x2
i (t) −x3
i (t))2
2R��
3. Update the weight: Wi(t) = (y(t)|xi(t))
4. Normalize the weight: i(t) = Wi(t)∕∑Np
i=1 Wi(t)
5. Decide to resample if Neff ≤Nthresh
6. If resample: ̂xi(t) ⇒xi(t)
7. Estimate the instantaneous posterior:
̂Pr(x(t)|Yt) ≈
Np
∑
i=1
i(t)�(x(t) −̂xi(t))

274
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
8. Estimate (inference) the corresponding statistics:
̂XMAP(t) = arg max
xi(t)
̂Pr(x(t)|Yt)
̂XMMSE(t) = ̂XCM(t) = E{x(t)|Yt} =
Np
∑
i=1
̂xi(t) ̂Pr(x(t)|Yt)
̂XMEDIAN(t) = median( ̂Pr(x(t)|Yt))
Note that compared to the previous examples of Chapter 5 for the extended
Bayesian processors, we have added more process noise to demonstrate the effec-
tiveness of the bootstrap processor. The results of the bootstrap PF are shown in Fig.
7.8. The usual classical performance metrics are shown: zero-mean (0.03 < 0.17),
whiteness (0.78% out) and WSSR (below threshold), all indicating (approximately)
a tuned processor. The PF tracks the state and measurement after the initial transient
error has diminished.
In Fig. 7.9, we show the bootstrap state and measurement estimates (inferences),
that is, the MAP and MMSE (CM) compared to the modern sigma-point processor
SPBP (UKF). The plots demonstrate that the PF can outperform the sigma-point
design, that assumes a unimodal Gaussian distribution. The estimated state and pre-
dicted measurement posterior distributions are shown in Fig. 7.10 along with a
time-slice in Fig. 7.11 at time 1.04 s, demonstrating the capability of the bootstrap
PF to characterize the multimodal nature of this problem.
△△△
This completes the development of the most popular and simple PF technique.
Next, we consider some alternative approaches that attempt to approxi-
mate the minimum variance importance distribution more closely for improved
performance.
7.5.2
Auxiliary Particle Filter
The auxiliary particle ilter employing sampling-importance-resampling (ASIR) is
a variant of the standard SIR [8]. It is based on attempting to mitigate two basic
weaknesses in particle iltering: (1) poor outlier performance; and (2) poor posterior
tail performance. These problems evolve from the empirical approximation of the
iltering posterior which can be considered a mixture distribution.
The basic concept of ASIR is to mimic the operation of the minimum variance
(optimal) importance distribution qMV(x(t)|x(t −1), y(t)) by introducing an auxiliary
variable representing the weight of the mixture used in the empirical prediction
distribution estimate. The idea is to perform resampling at time (t −1) using the
available measurement at time t before the particles {xi(t)} are propagated to time t
through the transition and likelihood distributions. The key step is to favor particles
at time (t −1) that are likely to “survive” (largest weights) at the next time-step t. The
problem is that these schemes tend to introduce a bias into the estimated posterior that

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
275
20
40
60
80 100 120 140 160
0
5
10
15
20
25
30
35
40
WSSR test
ρ
Time/thrsh not exceed
1
1.2
1.4
1.6
1.8
2
2.2
0
0.2
0.4
0.6
0.8
1
1.2
Lags (Pct/no=0.78(1))
0.5
0
1
1.5
11
11.5
12
12.5
13
13.5
14
Time (s)
Simulated measurement  
0
0.5
1
1.5
2
2.1
Simulated state 
Time (s)
(a
(
)
b)
(c
(
)
d)
(e
(
)
f)
0
0
0.5
1
1.5
1.98
2
2.02
2.04
2.06
2.08
2.1
Estimated state 
Time (s)
0.5
1
1.5
11
11.5
12
12.5
13
13.5
14
Time (s)
Predicted measurement
2.08
2.06
2.04
2.02
Zero-Mean/whiteness test
x^
x
y
y^
R^
ee
FIGURE 7.8
Nonlinear trajectory simulation/estimation for low process noise case:
(a) simulated state and mean; (b) simulated measurement and mean; (c) bootstrap
state estimate; (d) bootstrap measurement estimate; (e) zero-mean/whiteness test
(0.03 < 0.17/0.78% out); (f) WSSR test (below threshold).
must then be corrected by modifying the weight of the remaining particles. Thus, the
ASIR is a two-stage process such that: (1) particles with large predictive likelihoods
at time-step (t −1) are propagated; and (2) the resulting particles are then re-weighted
and drawn from the resulting posterior.
Following the development in Cappe [6], we start with a proposal over the entire
path {Xt} up to time t under the assumption that the joint posterior at time (t −1) is

276
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
0
0.5
1
1.5
1.98
2
2.02
2.04
2.06
2.08
2.1
2.12
Time (sec)
0
0.5
1
1.5
Time (sec)
11
11.5
12
12.5
13
13.5
14
14.5
15
MAP
CM
KF
Mean
Data
MAP
CM
KF
Mean
Data
State 
estimates 
Predicted 
measurements 
(a)
(b)
x^
y^
FIGURE 7.9
Nonlinear trajectory Bayesian estimation comparison for low process noise
case problem: (a) state estimates: MAP, MMSE (CM), UKF, median; (b) predicted mea-
surement estimates: MAP, MMSE (CM), UKF, median.
well approximated by a particle representation {i(t −1), Xt −1(i)}. Thus, the joint
importance proposal for the “new” particles {Xt(i)} is
q(Xt) =
Past
⏞⏞⏞⏞⏞⏞⏞
q(Xt−1|Yt) ×
New
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
q(x(t)|x(t −1), y(t))
(7.29)

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
277
2.115
X-update sample no.
145
0
0.5
1
1.5
Y-predicted posterior distribution (Pr[y(t )|Yt-1]) 
13.9
13.8
13.7
13.6
13.5
13.4
13.3
Y-predict sample no.
0.04
0.035
0.03
0.025
0.02
0.015
0.01
0.005
0
0
0.5
1
1.5
Time (sec)
Time (sec)
0.04
0.035
0.03
0.025
0.02
Probability
Probability
0.015
0.01
0.005
0
2.11
2.12
2.105
2.1
2.095
2.09
2.085
X-updated posterior distribution (Pr[x(t )|Yt]) 
(a)
(b)
FIGURE 7.10
Nonlinear trajectory Bayesian estimation instantaneous posterior distribu-
tions: (a) updated state distribution; (b) predicted measurement distribution.

(a) Updated PDF state  
(b) Predicted PDF state  
Xupdate sample no. 147
Xpredict sample no. 147
Weight sample no. 147
(c) WEIGHT distribution  
FIGURE 7.11
Nonlinear trajectory Bayesian estimation instantaneous posterior distribution at time-slice 1.47 sec: (a) updated state
distribution; (b) predicted state distribution; (c) weight (likelihood for bootstrap) distribution.

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
279
Note that the “past” trajectories depend on the data up to time-step t to enable the
adaption to the new data y(t) while the “new” conditional importance distribution
(q →qMV) incorporates the new state x(t). We substitute an empirical distribution for
Pr(Xt−1|Yt) centered on the previous particle paths {Xt−1(i)}
q(Xt−1|Yt) ≈
Np
∑
i=1
i(t −1)�(Xt−1 −Xt−1(i))
(7.30)
where ∑Np
i=1 i(t −1) = 1 and i(t −1) > 0. The ith weight (probability mass) for
each particle in this proposal is based on the pre-selected particles that are a “good
it” to the new data point y(t). One choice [8] for these weights is to choose a point
estimate of the state such as its mean,
̂mi(t) = ∫x(t) × Pr(x(t)|xi(t −1)) dx(t)
(7.31)
and then compute the weighting function as the likelihood evaluated at this point
i(t −1) = (y(t)| ̂mi(t))
as in the bootstrap technique [16] or if the particles {xi(t −1)} are weighted [6], then
i(t −1) = i(t −1) × (y(t)| ̂mi(t))
which follows from the marginal Pr(Xt−1|Yt)—a smoothing distribution. That is,
using the particle approximation from time (t −1) and expanding, we obtain
Pr(Xt−1|Yt) ∝∫Pr(Xt−1|Yt−1) × (x(t)|x(t −1)) × (y(t)|x(t)) dx(t) (7.32)
and using the empirical distribution approximation for the irst term gives
Pr(Xt−1|Yt) ≈
Np
∑
i=1
i(t −1)�(Xt−1 −Xt−1(i)) ×∫(y(t)|x(t))(x(t)|xi(t −1)) dx(t)
(7.33)
One approximation [8] (x(t)|xi(t −1)) →�(x(t) −̂mi(t)) leads to the estimator
̂Pr(Xt−1|Yt) ≈
Np
∑
i=1
(y(t)| ̂mi(t)) × i(t −1)
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
Combined weight
× �(Xt−1 −Xt−1(i))
(7.34)

280
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
giving the desired result above
i(t −1) := i(t −1) × (y(t)| ̂mi(t))
(7.35)
Using this proposal, the generalized weight
aux(i, t) := Pr(Xt|Yt)
q(Xt)
is determined from the ratio of the posterior
Pr(Xt|Yt) ∝∫(y(t)|x(t)) × (x(t)|x(t −1)) × Pr(Xt−1|Yt−1) dx(t)
to the joint proposal giving
aux(i, t) = Pr(Xt|Yt)
q(Xt)
= i(t −1)
i(t −1) × (y(t)|xi(t)) × (xi(t)|xi(t −1))
q(xi(t)|xi(t −1), y(t))
(7.36)
which follows directly from substitution of the empirical distributions [6]. Here the
bias correction 1∕i is introduced into the sampler to correct the auxiliary weight
(irst stage).
We summarize the auxiliary particle ilter in Table 7.3. First, the bootstrap tech-
nique is executed to generate a set of particles and auxiliary weights at time-step
(t −1), that is, {i(t), xi(t)} which are used to estimate the set of means (or modes)
{ ̂mi(t)} as in Eq. 7.31 for the “smoothing” weight calculation of Eq. 7.35 generat-
ing the probability masses {i(t −1)}. These weights are then used in resampling
to generate the set of “most likely” particles and weights under the new sampling
indices {j(i)}, {j(i)(t −1), xj(i)(t −1)}, that is, ̂xi(t −1) ⇒xj(i)(t −1); i = 1, … , Np.
Next, samples are drawn from the optimal proposal and used to update the aux-
iliary weights using the resampled particles and irst stage weights deined by
�i(t −1) := i(t −1)∕i(t −1). The posterior distribution is estimated using the aux-
iliary weights to complete the process.
If the process is governed by severe nonlinearities or contaminated by high process
noise, then a single point estimate such as ̂mi(t) does not suficiently represent the
transition probability Pr(x(t)|xi(t −1)) very well. Therefore, we can expect the ASIR
performance to be poor even yielding weaker results than that of the bootstrap
processor. However, if the process noise is small, implying that a point estimate can
characterize the transition probability reasonably well, then the ASIR is less sensitive
to “outliers” and the weights will be more uniformly balanced resulting in excellent
performance compared to the bootstrap. These concepts can be used as an aid to help
decide when such a technique is applicable to a given problem.

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
281
TABLE 7.3
Auxiliary SIR State–Space Particle Filtering Algorithm
Initialize
xi(0) ∼Pr(x(0))
Wi(0) = 1∕Np
i = 1, … , Np
[Sample]
Auxiliary Weights
Bootstrap Processor: {i(t), xi(t)}
̂mi(t) ≈E{x(t)}
[Bootstrap mean]
Weight Calculation
Ki(t −1) = i(t −1) × (y(t)| ̂mi(t))
[Bootstrap likelihood]
Weight Normalization
i(t −1) = Ki(t −1)
/ Np
∑
i=1
Ki(t −1)
[Auxiliary weight]
Resampling
Select indices {j(i)} using {j(i)(t −1)}:̂xi(t) ⇒xj(i)(t)
[Resample]
�i(t −1) := j(i)(t −1)∕j(i)(t −1)
[First stage weights]
Importance Sampling Proposal (Optimal)
̃xi(t) ∼q(̂xi(t)|xi(t −1), y(t))
[Sample]
Weight Update
̃Wi(t) = �i(t −1) × (y(t)|̃xi(t)) × (̃xi(t)|xi(t −1))
q(̂xi(t)|xi(t −1), y(t))
[Weight-update]
Weight Normalization
aux(i, t) = ̃Wi(t)
/ Np
∑
i=1
̃Wi(t)
[Normalize]
Distribution
̂Pr(x(t)|Yt) ≈
Np
∑
i=1
aux(i, t)�(x(t) −̃xi(t))
[Posterior distribution]
7.5.3
Regularized Particle Filter
In order to reduce the degeneracy of the weights in the SIR processor, resampling was
introduced as a potential solution; however, it was mentioned that even though the
particles are “steered” to HPR, they tend to lose their diversity among other problems
introduced by such a procedure [1, 23–44]. This problem occurs because samples are
drawn from a discrete rather than continuous distribution (see Section 1.5). Without
any attempt to correct this problem, the particles can collapse to a single location
giving a poor characterization of the posterior distribution and therefore result in poor
processor performance.
One solution to the diversity problem is to develop a continuous rather than
discrete approximation to the empirical posterior distribution using the kernel den-
sity estimator of Section 3.2 and then perform resampling directly from it. This is
termed a regularization-step resulting in diversiication by a form of “jittering” the
particles; thus, the processor is called the regularized particle ilter (RPF). The key
idea of the RPF is the transformation of the discrete empirical posterior distribution

282
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
̂Pr(x(t)|Yt) →Pr(xt|Yt) in order to resample from an absolutely continuous distribution
producing a “new” set of Np-particles with different locations.
To be more precise let us deine the properties of a kernel that can be applied
to this problem [7]. A regularization kernel (x) is a symmetric probability den-
sity function such that: (1) (x) ≥0; (2) ∫(x) dx = 1; (3) ∫x(x) dx = 0; and (4)
∫∥x2∥(x) dx < ∞and for any positive bandwidth △x the corresponding rescaled
kernel is deined by
Δx(x) =
(
1
Δx
)Nx

(
x
Δx
)
for x ∈Nx×1
(7.37)
The most important property of the kernel density follows from its regularization
property, that is, for any distribution (x) ∈Nx×1, the regularization results in an
absolutely continuous probability distribution, Δx(x) ∗(x), with ∗the convolution
operator, such that
d
dx[Δx(x) ∗(x)] = ∫Δx(x −�)(�) d�
(7.38)
If is an empirical distribution, then
̂(x) ≈
Np
∑
i=1
i�(x −xi)
for xi →{x1, … , xNp} a sample from the posterior and therefore
d
dx[Δx(x) ∗̂(x)] =
(
1
Δx
)Nx Np
∑
i=1
i
(x −xi
Δx
)
=
Np
∑
i=1
iΔx(x −xi)
(7.39)
Both the bandwidth and the kernel are selected in practice to minimize the mean
integrated error between the posterior and regularized distribution. Classical ker-
nels result under specialized assumptions such as the Epanechnikov, Box, Triangle,
Gaussian, etc. (see Ref. [7], Chapter 12 for more details).
One of the underlying assumptions of this transformation is that the true posterior
Pr(xt|Yt) has a unity covariance which is not the case when implementing the RPF
technique. Therefore, at each time-step we must estimate the ensemble mean and
covariance by the usual sample approach given by
m(t) = 1
Np
Np
∑
i=1
xi(t)
Rxx(t) = 1
Np
Np
∑
i=1
(xi(t) −m(t))(xi(t) −m(t))′
(7.40)

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
283
With this calculation, we factor the covariance using the Cholesky decomposition to
yield the matrix square roots used in a whitening transformation (unity covariance),
that is,
Rxx(t) = L1∕2(t)LT∕2(t)
which leads to the new scaled kernel
Δx(x) =
1
|L1∕2|(Δx)Nx 
(
L−1∕2x
Δx
)
(7.41)
The old particles are then “jittered” by using the step
̃xi(t) = xi(t) + ΔxL
1
2 (t)�i(t)
(7.42)
where the {�i(t)} are drawn from the new scaled kernel above. A typical example
of kernel density estimation of a discrete probability mass function is shown in Fig.
7.1 where the circles represent the discrete point masses (impulses) at the particular
location and the continuous approximation to the probability density is shown by the
smooth curve provided by the kernel density estimate using a Gaussian window. This
completes the RPF technique which is summarized in Table 7.4. Next, we discuss
another popular approach to produce particle diversity.
7.5.4
MCMC Particle Filter
Another
approach
to
increase
the
diversity
in
the
particle
set
{xi(t), Wi(t)}; i = 1, … , Np is to take an MCMC step(s) with the underlying
invariant distribution targeted as the posterior Pr(Xt|Yt) on each particle [45].
The MCMC particle ilter is available in two varieties: (1) MCMC-step(s) with
the usual BSP; and (2) full MCMC iterative ilter. The sequential processors use the
MCMC-steps as part of the resampling process for especially insensitive (weight
divergence) problems, while the full MCMC iterative processor is available as a
separate algorithm typically executed using the Metropolis, Metropolis–Hastings
or Gibbs samplers of Chapter 3. We conine our discussion to the MCMC-step
approach, since we are primarily interested in sequential techniques and refer the
interested reader to [1, 23–24] for the iterative approach.
The main idea is that the particles are distributed as Pr(Xt(i)|Yt), then applying a
Markov chain transition kernel deined by
(Xt|Xt(i)) := Pr(Xt|Xt(i))
(7.43)

284
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
TABLE 7.4
Regularized Particle Filtering Algorithm
Initialize
Draw: xi(0) ∼Pr(x(0))
Wi(0) = 1
Np i = 1, … , Np
[Sample]
Importance Sampling
Draw: xi(t) ∼(x(t)|xi(t −1))
[State transition]
Weight Update
Wi(t) = (y(t)|xi(t)) ⇐C(x(t), u(t), �(t)); �∼Pr(�(t))
[Weight/likelihood]
Weight Normalization
i(t) = Wi(t)
/ Np∑
i=1
Wi(t)
Resampling Decision
̂Neff = 1
/ Np∑
i=1
W2
i (t)
[Effective samples]
̂Neff =
{Resample
≤Nthresh
Accept
> Nthresh
[Decision]
Regularization Sample Statistics
m(t) = 1∕Np
Np∑
i=1
xi(t)
[Sample mean]
Rxx(t) = 1∕Np
Np∑
i=1
(xi(t) −m(t))(xi(t) −m(t))′
[Sample covariance]
Factorization
Rxx(t) = L1∕2(t)LT∕2(t)
[Cholesky decomposition]
Resampling
̂xi(t) ⇒xi(t)
Diversiication
Draw: �i(t) ∼Δx(x(t) −̂xi(t))
[Sample]
Diversify
̃xi(t) = ̂xi(t) + ΔxL1∕2(t)�i(t)
[Generate sample]
Distribution
̂Pr(x(t)|Yt) ≈
Np∑
i=1
i(t)�(x(t) −̃xi(t))
[Posterior distribution]
with posterior invariant distribution such that
Pr(Xt|Yt) = ∫(Xt|Xt(i)) × Pr(Xt(i)|Yt) dXt(i)
(7.44)
continues to result in a particle set with the desired posterior as its invariant dis-
tribution. However, the new particle locations after the move result in HPR of the
state–space. It has been shown that by applying the MCMC transition kernel that the
total variance of the current distribution can only decrease [46]. Any of the MCMC
methods (M-H, G-S, S-S, etc.) can be incorporated into the SMC framework to
achieve the desired move occuring after the resampling operation.

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
285
Following Refs. [46] and [47], the objective is to move the set of particles using a
combination of importance sampling, resampling and MCMC sampling, that is, the
approach is to:
r Initialize the set of particles yielding: {xi(t)}; i = 1, … , Np
r Resample this set to obtain: {̂xi(t)}; i = 1, … , Np
r Move using an MCMC step(s) to generate the “new” set of particles
{̃xi(t)}; i = 1, … , Np with ̃xi(t) ∼Pr(Xt|Yt) and transition kernel, (̃xi(t)|Xt(i))
The move-step performs one or more iterations of an MCMC technique on each
selected particle after the resampling step with invariant distribution Pr(Xt|Yt). Note
that before the move, the resampled particles are distributed ̂xi(t) ∼Pr(Xt|Yt); there-
fore, the “moved” particles ̃xi(t) are approximately distributed by this posterior as
well. The move-step improves particle diversity by enriching the particle locations to
those highest probability regions.
For instance, let us “track” the ith particle with corresponding high valued weight.
Based on its associated weight (probability), ̂xi(t) ⇒xi(t) is selected according to
Pr(̂xi(t) = xi(t)) = i(t)
Resampling results in replication of the ith-particle, Ni-times, producing the
resampled set {̂xi1(t), ̂xi2(t), … , ̂xiNi(t)}. Next, the move-step moves each replicant
̂xij(t) →̃xij(t) to a distinct (unique) location in the region of strongest support dictated
by Pr(Xt|Yt). This provides the “move-step” for the SMC technique and mitigates the
divergence problem.
To be more speciic, let us illustrate the “move” by choosing the Metropolis–
Hastings technique of Table 3.1 to perform our MCMC-step using the random walk
M–H approach of Section 3.4.
We start with the basic bootstrap PF of Section 7.5 to obtain the set of resampled
particles {̂xi(t)}. Using the random walk model, we perform the “move” step to obtain
the new set of particles as
̃xi(t) = ̂xi(t) + �i(t)
for �i ∼pE(�)
(7.45)
One choice is �i ∼pE(�) = (0, R��), since it is symmetric, easy to generate, and
will simplify the calculations even further. The corresponding acceptance probability
for the M-H approach is speciied by
A(̃xi(t), ̂xi(t)) = min
{
Pr( ̃Xt(i)|Yt))
Pr( ̂Xt(i)|Yt))
× q(̂xi(t)|̃xi(t))
q(̃xi(t)|̂xi(t)), 1
}
(7.46)

286
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
where ̃Xi(t) := {̃xi(t), Xt−1(i)} and ̂Xi(t) := {̂xi(t), Xt−1(i)} are the augmented sets of
joint random particles. Drawing samples from the random walk with (symmet-
ric) Gaussian distribution enables us to simplify the acceptance probability, since
q(̂xi(t)|̃xi(t)) = q(̃xi(t)|̂xi(t)), canceling these terms in Eq. 7.46 to produce
A(̃xi(t), ̂xi(t)) = min
{
Pr( ̃Xt(i)|Yt))
Pr( ̂Xt(i)|Yt))
, 1
}
(7.47)
But from the sequential Bayesian recursion,
Pr(Xt|Yt) ∝Pr(y(t)|x(t))Pr(x(t)|x(t −1)) × Pr(Xt−1|Yt−1)
we obtain
A(̃xi(t), ̂xi(t)) = min
{Pr(y(t)|̃xi(t)) × Pr(̃xi(t)|xi(t −1))
Pr(y(t)|̂xi(t)) × Pr(̂xi(t)|xi(t −1)), 1
}
(7.48)
With this information in mind, the implementation of the bootstrap PF with (ran-
dom walk) MCMC-step is given in Table 7.5. Another approach to improve particle
diversity is using local linearization techniques which can be implemented with any
of the classical/modern algorithms of the previous two chapters.
7.5.5
Linearized Particle Filter
Attempts to approximate the minimum variance importance proposal distribution of
Section 7.2 continue to evolve [24]. The motivation for this is based on inadequacies
created by selecting the transition prior of Section 7.5.1 as the proposal leading to the
popular bootstrap algorithm [16] of Table 7.2. As mentioned previously, the bootstrap
approach requires resampling to mitigate the particle depletion problem and lack of
incorporating the most recent measurement in the weight update. These reasons have
led to the development of the PF that incorporates the latest measurement sample.
One way to do so is to generate an approximately Gaussian importance proposal
based on linearization methods [4, 7, 9] with the idea of selecting
Pr(x(t)|Xt−1, Yt) ≈q(x(t)|Yt)
(7.49)
as a Gaussian proposal. This approach is used to provide coverage of the actual
posterior due to its long-tailed distribution while incorporating the latest available
measurement. This Gaussian proposal is the result of marginalizing the prior state
x(t −1) of the minimum variance proposal. That is,
q(x(t)|Yt) →Pr(x(t)|Yt) = ∫Pr(x(t)|x(t −1), y(t)) × Pr(x(t −1)|Yt−1) dx(t −1)
(7.50)

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
287
TABLE 7.5
MCMC Particle Filtering Algorithm
Initialize
Draw: xi(0) ∼Pr(x(0)) Wi(0) = 1
Np i = 1, … , Np
[Sample]
Importance Sampling
Draw: xi(t) ∼(x(t)|xi(t −1))
[State transition]
Weight Update
Wi(t) = (y(t)|xi(t))
[Weight/likelihood]
Weight Normalization
i(t) = Wi(t)
/ Np
∑
i=1
Wi(t)
Resampling Decision
̂Neff = 1
/ Np
∑
i=1
W2
i (t)
[Effective samples]
̂Neff =
{Resample
≤Nthresh
Accept
> Nthresh
[Decision]
Resampling
̂xi(t) ⇒xi(t)
Diversiication Acceptance Probability
A(̃xi(t), ̂xi(t)) = min
{(y(t)|̃xi(t)) × (̃xi(t)|xi(t −1))
(y(t)|̂xi(t)) × (̂xi(t)|xi(t −1)), 1
}
Diversify
Draw: �i(t) ∼(0, R��)
[Sample]
̃xi(t) = ̂xi(t) + �i(t)
[Generate sample]
Draw: uk →U(0, 1)
[Uniform sample]
Decision
xi(t) =
{̃xi(t)
if uk < A(xi, ̂xi)
̂xi(t)
otherwise
Distribution
̂Pr(x(t)|Yt) ≈
Np∑
i=1
i(t)�(x(t) −xi(t))
[Posterior distribution]
In a sense, this implicit marginalization effectively averages the proposal with
respect to the previous posterior Pr(x(t −1)|Yt−1), which incorporates all of the
“information” about x(t −1). Thus, we see that by choosing the Gaussian importance
distribution as our proposal enables us to implicitly incorporate all of the knowledge
available about the previous state as well as incorporate the current measurement
y(t). These features make q(x(t)|Yt) a reasonable choice as long as it provides the
overlapping support or coverage of the desired posterior [9].
One of the linearization approaches to implementing the minimum variance impor-
tance function qMV(x(t)|x(t −1), y(t)) is to estimate it as a Gaussian prior, that is,
qMV(x(t)|x(t −1), y(t)) ∼(̂x(t|t), ̃P(t|t))
(7.51)

288
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
where the associated (iltered) CM
̂x(t|t) = E{x(t)|Yt} and error covariance
̃P(t|t) = E{̃x(t|t)̃x′(t|t)} for ̃x(t|t) = x(t) −̂x(t|t) are obtained from an additional esti-
mation scheme.
There are a variety of choices available, each evolving from either the classical
(linearized, extended, or iterated Kalman ilters) or the modern unscented (sigma-
point) Kalman ilter. Further alternatives are also proposed to these approaches [4],
but we will conine our discussion to these popular and readily available approaches
[9]. In each of these implementations a linearization, either of the nonlinear dynam-
ics and measurement models in the classical case or in the statistical linearization
(unscented transformation) as in the unscented or sigma-point case occurs. All of
these “linearized-based” processors provide the updated or iltered conditional mean
estimate
̂x(t|t) = ̂x(t|t −1) + K(x∗(t))e(t)
(7.52)
where
̂x(t|t −1)
is the predicted conditional mean E{x(t)|Yt−1};
K(x∗(t))
is the gain or weight based on the particular linearization technique; and
e(t)
is the innovation sequence.
Here the choices are
r x∗(t) →xo(t) is a reference trajectory in the linearized case; or
r x∗(t) →̂x(t|�) is a extended or iterated cases; and
r x∗(t) →�i(t|t) is a sigma-point in the unscented case.
The error covariance is much different in each case, that is,
̃P(t|t) = (I −K(x∗(t))C[x∗(t)])̃P(t|t −1)
(7.53)
in the linearized and extended cases with measurement Jacobian
C[x∗(t)] = �ci[x]
�xj
|||||x=x∗(t)
(7.54)
and, of course,
̃P(t|t −1) = A[x∗(t)]̃P(t −1|t −1)A′[x∗(t)] + R��(t −1)
(7.55)
for A[x∗(t)] = �ai[x]
�xj
||||x=x∗(t)
.
In the sigma-point (unscented) case, we have
̃P(t|t) = ̃P(t|t −1) −K(x∗(t))Ree(t)K′(x∗(t))
(7.56)

7.5
STATE–SPACE PARTICLE FILTERING TECHNIQUES
289
TABLE 7.6
Linearized Particle Filtering Algorithm
Initialize
Draw: xi(0) ∼Pr(x(0))
Wi(0) = 1
Np
i = 1, … , Np
[Sample]
Linearization
LZKF/EKF/IEKF/UKF Processor
{xi(t), ̃Pi(t)} = (̂x(t|t), ̃P(t|t))
Importance Sampling
xi(t) ∼(̂x(t|t), ̃P(t|t))
[State draw]
Weight Update
Wi(t) = (y(t)|xi(t)) × (x(t)|xi(t −1))
qMV(x(t)|xi(t −1), y(t))
[MV weight]
for
qMV(x(t)|xi(t −1), y(t)) = (xi(t), ̃Pi(t))
Weight Normalization
i(t) = Wi(t)
/ Np∑
i=1
Wi(t)
Resampling Decision
̂Neff = 1
/ Np
∑
i=1
W2
i (t)
[Effective samples]
̂Neff =
{≤Nthresh
Resample
> Nthresh
Accept
[Decision]
Resampling
̂xi(t) ⇒xi(t)
Distribution
̂Pr(x(t)|Yt) ≈
Np∑
i=1
i(t)�(x(t) −̂xi(t))
[Posterior distribution]
So we see that depending on the linearization method or the particular classical
or unscented processor we select, we will generate the Gaussian prior at each time-
step which is used to obtain the minimum variance importance distribution. Thus,
we see why they are called the class of “local” linearization-based particle ilters.
The linearized particle ilter algorithm is shown in Table 7.6 where we see that the
conditional mean and covariance are estimated in each time-step of the algorithm and
particles are drawn from
xi(t) →̂Pr(x(t)|Yt) ∼(̂x(t|t), ̃P(t|t))
(7.57)
the updated “Gaussian” estimates and the weights also follow the importance distri-
bution of Eq. 7.51 given by
Wi(t) = (y(t)|xi(t)) × (x(t)|xi(t −1))
qMV(x(t)|xi(t −1), y(t))
(7.58)

290
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
This completes the linearized particle ilters, next we consider some of the practical
considerations for design.
7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
Pragmatic Monte Carlo methods [48–57], even those that are model-based, are specif-
ically aimed at providing a reasonable estimate of the underlying posterior distribu-
tion; therefore, performance testing typically involves estimating just “how close” the
estimated posterior is to the “true” posterior. However, within a Bayesian framework,
this comparison of posteriors only provides a measure of relative performance but
does not indicate just how well the underlying model embedded in the processor “its”
the measured data. Nevertheless, these closeness methods are usually based on the
Kullback–Leibler (KL) divergence measure [58] providing such an answer. However,
in many cases we do not know the true posterior and therefore we must resort to other
means of assessing performance such as evaluating mean-squared error (MSE) or
more generally checking the validity of the model by evaluating samples generated
by the prediction or the likelihood cumulative distribution to determine whether or
not the resulting sequences have evolved from a uniform distribution and are i.i.d.
(see Section 3.3) – analogous to a whiteness test for Gaussian sequences.
Thus, PF are essentially sequential estimators of the posterior distribution employ-
ing a variety of embedded models to achieve meaningful estimates. In contrast to
the BP designs which are typically based on Gaussian assumptions, the PF have no
such constraints per se. In the linear case, a necessary and suficient condition for
optimality of the linear BP is that the corresponding innovations or residual sequence
must be zero-mean and white (see Section 5.7 for details). In lieu of this constraint,
a variety of statistical tests (whiteness, uncorrelated inputs, etc.) were developed in
Section 5.7 evolving from this known property. When the linear Bayesian proces-
sors were “extended” to the nonlinear case, the same tests were performed based on
approximate Gaussian assumptions. Clearly, when noise is additive Gaussian these
arguments can still be applied. These same statistical tests can also be performed
based on the innovations or residual sequences resulting from the estimates (MAP,
ML, MMSE (CM) ) inferred from the estimated posterior distribution. However,
some other more meaningful performance tests for the PF can also be applied for
improved design and performance evaluation.
7.6.1
Sanity Testing
In what might be termed “sanity testing,” the classical methods discussed above
employ the basic statistical philosophy that ”if all of the signal information has been
removed (explained) from the measurement data, then the residuals (i.e. innovations
or prediction error) should be uncorrelated,” that is, the model its the data and all
that remains is a white or uncorrelated residual (innovations) sequence. Therefore,
performing the zero-mean, whiteness testing, that is, the conidence interval about
the normalized correlations (innovations) and the (vector) weighted sum-squared

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
291
residual tests of Section 5.7 as well as checking the normalized MSE of the state
vector (and/or innovations) given by
NMSE = E
{(xTrue(t) −̂x(t|t)
xTrue(t)
)2}
≈
Nt
∑
t=1
(xTrue(t) −̂x(t|t)
xTrue(t)
)2
(7.59)
are the basic irst steps that can be undertaken to ensure that models have been
implemented properly and the processors have been “tuned”. Here the normalized
mean-squared error range is: 0 < NMSE < 1.
7.6.2
Ensemble Estimation
Perhaps one of the most important aspects of nonlinear processor design is to recall
that processing results only in a single realization of its possible output. For instance,
the conditional mean is just a statistic, but still a random process; therefore, if direct
measurements are not available, it is best to generate an ensemble of realizations and
extract the resulting ensemble statistics using a variety of methods, (e.g., bootstrap-
ping [15]). In any case, simple ensemble statistics can be employed to provide an
average solution enabling us to generate “what we would expect to observe” when the
processor is applied to the actual problem. This approach is viable even for the mod-
ern nonlinear processors of the previous chapter; however, here we concentrate on
the particle ilter and assume we have a “truth model” (or data ensemble) available
for our designs. As illustrated in Fig. 7.12, the performance analysis of the particle
ilter is best achieved by combining both simulated and actual measurement data
possibly obtained during a calibration phase of the implementation. In this approach,
the data are pre-processed and the truth model adjusted to relect a set of predictive
Truth
model
Particle filter
ensemble
runs
Pre-process
State-space
model
Particle filter
design
OK?
Performance
analysis
Raw data
Initial model parameter calculations
Parameters
Tune
No
Yes
Model
Processor evaluation
FIGURE 7.12
Ensemble estimation. Truth model parameter estimates, state-space
model initialization, tuning, ensemble generation and performance analysis.

292
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
parameters that are then extracted and used to “parameterize” the underlying state-
space (or other) representation of the process under investigation. Once the models
and parameters are selected, then ensemble runs can be performed; such terms as
initial states, covariances, and noise statistics (means, covariances, etc.) can then be
adjusted to “tune” the processor much like in the modern techniques of the previous
chapter. Here, classical statistics (e.g., zero-mean/whiteness and WSSR testing) can
help in the tuning phase. Once tuned, the processor is then applied to the raw mea-
surement data and ensemble statistics are estimated to provide a thorough analysis of
the processor performance.
Statistics can be calculated over the ensemble of processor runs. The updated
MAP state estimate is obtained directly from the ensemble, that is,
̂xMAP(t|t) ⟶{̂xk
MAP(t|t)}; k = 1, … , K
and therefore, the updated state ensemble estimate is
̂xMAP(t|t) = 1
K
K
∑
k=1
̂xk
MAP(t|t)
(7.60)
The corresponding predicted MAP state estimate can be obtained directly from
the ensemble as well, that is,
̂xMAP(t|t −1) ⟶{̂xk
MAP(t|t −1)}; k = 1, … , K
and therefore, the predicted state ensemble estimate is
̂xMAP(t|t −1) = 1
K
K
∑
k=1
̂xk
MAP(t|t −1)
(7.61)
The predicted MAP measurement estimate is also obtained directly from the
ensemble, that is,
̂yMAP(t|t −1) ⟶{̂yk
MAP(t|t −1)}; k = 1, … , K
where recall
̂yk
MAP(t|t −1) = c[̂xk
MAP(t|t −1)]
(7.62)
Thus, the predicted measurement ensemble estimate is
̂yMAP(t|t −1) = 1
K
K
∑
k=1
̂yk
MAP(t|t −1)
(7.63)

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
293
Finally, the corresponding predicted innovation ensemble estimate is given by
ek(t) = y(t) −̂yk
MAP(t|t −1); k = 1, … , K
(7.64)
e(t) ⟶{ek(t)}; k = 1, … , K
and therefore, the predicted innovation ensemble estimate is
e(t) = 1
K
K
∑
k=1
ek(t)
(7.65)
Of course the ensemble residual or innovations sequence can be “sanity tested”
for zero-mean, whiteness, and the NMSE over the ensemble can be calculated to
ensure the processor has been tuned properly. So we see that the ensemble statistics
can be estimated and provide a better glimpse of the potential performance of the
PF processor for the actual problem. To observe the effect of ensemble averaging,
consider the previous example and apply these calculations to both the state and
measurement estimates.
Example 7.3
Consider the trajectory estimation of the previous example and now perform a set of
100-member ensemble runs averaging each of the state and measurement estimates
as discussed above. The results of ensemble estimates are shown in Fig. 7.13; in (a)
and (b), we see the results of a single realization (run) of the bootstrap PF indicating
a reasonable trajectory estimate, but not really giving us an indication of the potential
processor performance over a set of data. Ensemble results are shown in Fig. 7.13c
for the state estimate and Fig. 7.13d for the predicted measurement. Clearly, the
estimates are much smoother and give a better representation of how we would
expect the processor to perform.
△△△
7.6.3
Posterior Probability Validation
Much effort has been devoted to the validation problem with the most signiicant
results evolving from the information theoretical point of view [59]. Following this
approach, we start with the basic ideas and quickly converge to a reasonable solution
to the distribution validation problem [59–65].
Kullback–Leibler Theory
Let us irst deine some concepts about proba-
bilistic information necessary for the development. These concepts are applied
extensively in communications problems and will prove useful in designing

294
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
0
0.5
1
1.5
Time (sec)
11.5
12
12.5
13
13.5
14
14.5
Data
MAP
CM
True
Estimated
measurement (Ensemble = 100)
0
0.5
1
1.5
Time (sec)
2
2.01
2.02
2.03
2.04
2.05
2.06
2.07
2.08
2.09
2.1
Estimated state
(Ensemble = 100)
Data
MAP
CM
True
0
0.5
1
1.5
1.98
2
2.02
2.04
2.06
2.08
2.1
Estimated state
Time (sec)
MAP
Data
True
0
0.5
1
1.5
11
11.5
12
12.5
13
13.5
14
Time (sec)
Estimated
measurement
Data
MAP
True
(a)
(b)
(c)
(d)
FIGURE 7.13
Ensemble estimation for trajectory estimation: (a) single realization: state
estimate; (b) single realization: measurement estimate; (c) 100-member ensemble esti-
mate: state; (c) 100-member ensemble estimate: measurement.
parametric signal processors. The information (self) contained in the occurrence
of the event �i such that X(�i) = xi, is
(xi) = −logbPr(X(�i) = xi) = −logbPr(xi)
(7.66)
where b is the base of the logarithm which results in different units for information
measures (e.g., base 2 →bits, while base e →implies nats). The entropy or average
information is deined by
(xi) := EX{(xi)} =
N
∑
i=1
(xi)Pr(xi) = −
N
∑
i=1
Pr(xi) logbPr(xi)
(7.67)
Mutual information is deined in terms of the information available in the occur-
rence of the event Y(�j) = yj about the event X(�i) = xi or
(xi; yj) = logb
Pr(xi|yj)
Pr(xi)
= logbPr(xi|yj) −logbPr(xi)
(7.68)

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
295
Now using these concepts, we take the information theoretic approach to distribu-
tion estimation following [59, 60]. Since many processors are expressed in terms of
their “estimated” probability distributions, quality or “goodness” can be evaluated by
its similarity to the true underlying probability distribution generating the measured
data.l
Suppose Pr(xi) is the true discrete posterior probability distribution and ̂Pr(̂xi) is
the estimated distribution. Then the KL Information quantity of the true distribution
relative to the estimated is deined by using
KL(Pr(xi); ̂Pr(̂xi)) := EX
{
ln Pr(xi)
̂Pr(̂xi)
}
=
N
∑
i=1
Pr(xi) ln Pr(xi)
̂Pr(̂xi)
=
N
∑
i=1
Pr(xi) ln Pr(xi) −
N
∑
i=1
Pr(xi) ln ̂Pr(̂xi)
(7.69)
where we chose logb = ln. The KL possesses some very interesting properties which
we state without proof (see Ref. [60] for details) such as
1. KL(Pr(xi); ̂Pr(̂xi)) ≥0
2. KL(Pr(xi); ̂Pr(̂xi)) = 0 ⇔Pr(xi) = ̂Pr(̂xi) ∀i
3. The negative of the KL is the entropy, KL(Pr(xi); ̂Pr(̂xi))
The second property implies that as the estimated posterior distribution approaches
the true distribution, then the value of the KL approaches zero (minimum). Thus,
investigating Eq. 7.69, we see that the irst term is a constant speciied by the true
distribution; therefore, we only need to estimate the average value of the estimated
posterior relative to the true distribution, that is,
(̂xi) := EX{ln ̂Pr(̂xi)} =
N
∑
i=1
Pr(xi) ln ̂Pr(̂xi)
(7.70)
where (̂xi) is deined as the average log-likelihood of the random variable of value
ln ̂Pr(̂xi). Clearly, the larger the average log-likelihood, the smaller the KL implying
a better model.
The third property, entropy, is approximately equal to 1
N times the probability that
the relative frequency distribution of N measurements obtained from the estimated
posterior equals the true distribution.
The KL is applied frequently to parameter estimation/system identiication prob-
lems to estimate the intrinsic order of the unknown system [5]. Two popular informa-
tion metrics have evolved from this theory: the Akaike Information Criterion (AIC)
and the minimum data length (MDL) description [59, 60, 62, 63]. Both are used to

296
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
perform order estimation and are closely related as shown below
AIC(�) = −ln R��+ 2 �
N
MDL(�) = −ln R��+ �
2 ln N
where �is the system order, �is the one-step prediction error with corresponding
covariance R��, and N is the number of samples (data) values.
However, our interest lies in comparing two probability distributions to determine
“how close” they are to one another. Even though KL does quantify the difference
between the true and estimated distributions, unfortunately it is not a distance measure
due to its lack of symmetry. However, the Kullback divergence (KD) deined by a
combination of KL
KD(Pr(xi); ̂Pr(̂xi)) = KL(Pr(xi); ̂Pr(̂xi)) + KL( ̂Pr(̂xi); Pr(xi))
(7.71)
is a distance measure between distributions indicating “how far” one is from the
other. Consider the following example of this calculation.
Example 7.4
We
would
like
to
calculate
the
KD
for
two
Gaussian
distributions,
pi(x) ∼(mi, Vi); i = 1, 2 to establish a closeness measure. First, we calculate the
KL information,
KL(p1(x); p2(x)) = Ep1
{
ln p1(x)
p2(x)
}
= Ep1
{
1
2 ln V2
V1
+ (x −m2)2
2V2
−(x −m1)2
2V1
}
Now performing the expectation term-by-term gives
KL(p1(x); p2(x)) = 1
2 ln V2
V1
+
1
2V2 ∫(x −m2)2p1(x) dx −
1
2V1 ∫(x −m1)2p1(x) dx
Since the last term (under the integral) is the variance, V1, it is simply −1
2 and
therefore all we need to do is expand and perform the integration of the second
integral term-by-term to give
KL(p1(x); p2(x))
= 1
2 ln V2
V1
+
1
2V2
[
∫x2p1(x) dx −2m2 ∫xp1(x) dx + m2
2 ∫p1(x) dx
]
−1
2
or identifying terms from the properties of moments, we obtain
KL(p1(x); p2(x)) = 1
2 ln V2
V1
+
1
2V2
[(V1 + m2
1
) −2m2m1 + m2
2
] −1
2

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
297
Finally, we obtain
KL(p1(x); p2(x)) = 1
2 ln V2
V1
+ V1 + (m1 −m2)2
2V2
−1
2
Performing the same calculation, we get
KL(p2(x);p1(x)) = 1
2 ln V1
V2
+ V2 + (m1 −m2)2
2V1
−1
2
and therefore the KD is
KD(p1(x); p2(x)) = KL(p1(x); p2(x)) + KL(p2(x); p1(x))
=
V2
1 + (m1 −m2)2(V1 + V2) + V2
2
2V1V2
−1
This completes the example.
△△△
The KL and therefore the KD can also be determined by probability distribu-
tion estimation using MC sampling techniques [64–65]. As another example of this
approach, consider how to apply the KL information to distinguish between a uni-
modal Gaussian and a Gaussian mixture.
Example 7.5
Suppose we would like to test whether a given data set is from a Gaussian distri-
bution speciied by (m, V) or from a Gaussian mixture distribution speciied by
p(m1, V1) + (1 −p)(m2, V2) where p is the mixing coeficient (probability). The
Kullback divergence can easily be calculated and compared to a bound �to determine
“how close” the data is to a mixture or a Gaussian, that is,
KD(Pr(xi); ̂Pr(̂xi)) = KD(p(m1, V1) + (1 −p)(m2, V2);(m, V)) < �
In order to perform the test we choose m and
√
V to minimize the KD above.
Solving, we obtain
m = pm1 + (1 −p)m2;
and
V = pV1 + (1 −p)V2 + p(1 −p)(m1 −m2)2
A typical bound of �= 0.1 appears to perform well in distinguishing a single Gaussian
from a mixture.
△△△
Particle Filter Performance
Before we close this section, let us see how KL
theory can be applied to PF design. Typically, we have a simulation model of the

298
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
dynamics of the system under investigation in some form or another, that is, the
model can range from a very detailed “truth model” as discussed in Ref. [5] to
a simple signal processing representation (e.g., sinusoids). In any case using this
truth model, we can generate a “true distribution” of the system, say Pr(x(t)|Yt
)
and incorporate it into the divergence criterion by: (1) driving the underlying model
with a random sequence; (2) generating an ensemble (see Section 6.7); and then (3)
applying a nonparametric PDF/PMF histogram estimator. A nonparametric estimate
of the posterior distribution ̂Pr(x(t)|Yt
) is already provided by the particle ilter and
can be used in the KD criterion to be compared to this “true” estimate.
Particle ilters are basically developed to provide estimates of the underlying pos-
terior distributions for the problem under investigation in order to extract meaningful
statistics. Compared to the usual model-based (Kalman) processors which utilize their
inherent “optimality” property (zero-mean, uncorrelated residuals) to assess perfor-
mance, the estimated posterior of the PF can be compared to the true distribution of
the underlying process it is to estimate by using the divergence statistic of the KL
information as a metric [59].
For our problem, suppose Pr(x(t)|Yt
) is the true posterior PMF and ̂Pr(xi(t)|Yt
)
is the estimated (particle) distribution, then the KL information quantity of the true
distribution relative to the estimated is deined by [62–63]
KL
(Pr(x(t)|Yt
); ̂Pr(xi(t)|Yt
)) := Ex
{
ln
Pr(x(t)|Yt
)
̂Pr(xi(t)|Yt
)
}
=
Np
∑
i=1
ln
Pr(x(t)|Yt
)
̂Pr(xi(t)|Yt
) × Pr(x(t)|Yt
)
(7.72)
The KL satisies its most important property from a distribution comparison
viewpoint—when the true distribution and its estimate are close (or identical), then
the information quantity is
KL
(Pr(x(t)|Yt
); ̂Pr(xi(t)|Yt
)) = 0 ⇔Pr(x(t)|Yt
) = ̂Pr(xi(t)|Yt
)
∀i
(7.73)
As previously mentioned, this property infers that as the estimated posterior distri-
bution approaches the true distribution, then the value of the KL approaches zero
(minimum). The Kullback–Leibler divergence (KD) for this case is deined by
KD
(Pr(x(t)|Yt
); ̂Pr(xi(t)|Yt
)) := KL
(Pr(x(t)|Yt
); ̂Pr(xi(t)|Yt
))
+ KL
( ̂Pr(xi(t)|Yt
); Pr(x(t)|Yt
))
(7.74)
provides the distance metric indicating “how close” the estimated posterior is to the
true distribution or from our perspective, “how well does it approximate” the true.
Thus, the KD is a very important metric that can be applied to assess the performance
of Bayesian processors, providing a measure between the true and estimated posterior
distributions.

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
299
–15
–14
–13
–12
–11
–10
–9
0
20
40
60
80
100
0
0.05
0.1
0.15
0.2
Xupdate Sample No.
Time (sec)
(
)
i
k
ik
X t
p
=
,
,
(–14.3,18,0.13)
–8
3D-Probability surface
(Particle no × index (time) × probability)
FIGURE 7.14
Particle ilter posterior probability surface illustrating some triplet points
(Xi, tj, pij) within the volume.
The next question that arises is how do we go about performing the calculation,
that is, how do we obtain the corresponding “truth model” distribution to perform
the comparison. First, let us revisit the posterior probability surface generated by the
particle ilter. As depicted simply in Fig. 7.14, we see that a more careful investigation
of this surface reveals that each point in the space is a triplet deined the ith particle
number (location parameter), the index set or in our case the jth time sample number
and the corresponding posterior probability, that is, (Xi, tj, pij
) such that
{pij
} := Pr(xi(tj)|Yt
)
(7.75)
From the igure, the grid of points compose the overall Np × Nt surface, where
each of the points (coordinates) satisfy the sets
{Xi
} for i = 1, … , Np; {tj} for j = 1, … , Nt
(7.76)
along with the corresponding set of posterior probabilities
{pij
} for i = 1, … , Np; j = 1, … , Nt
(7.77)
Therefore, given the posterior surface produced by the PF, it is clear that sta-
tistical inferences lead to various solutions or combination of these probabilities

300
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
1t
2t
3t
4t
5t
6t
Particle no.
Time-step
Probability 
[
]
  
( )  
i
X t
1t
2t
3t
4t
5t
6t
(
)
MAP
ˆ
Pr
( ) | t
X
t
Y
(
)
MAP
ˆ
Pr
( ) | t
X
t
Y
(
)
Pr
( ) |
i
t
X t
Y
FIGURE 7.15
Particle ilter posterior probability surface: Updated state conditional
posterior × particle no. × index (time) along with corresponding MAP probability,
̂Pr( ̂XMAP(t)|Yt).
coupled with their corresponding location parameters. For instance, MAP estima-
tion selects the location parameters that correspond to the maximum probabilities as
illustrated in Fig. 7.15, that is, the MAP value at the (i, j)th location on the surface
corresponds to
̂Xi
MAP(tj) = max
ij
Pr(xi(tj)|Yt
) = pmax
ij
(7.78)
and the complete estimation (over time) is the set of values
̂XMAP(t) = { ̂Xi
MAP(tj)}; j = 1, … , Nt for i ∈max
ij
Pr(xi(tj)|Yt
)
(7.79)
So, we see that understanding this posterior probability surface aides in compre-
hending the mechanism that can now be applied to the KD metric. The PMF of the
MAP estimates are simply the set of posterior probabilities {pmax
ij
} and therefore we
can extract one of the required distributions for the KD metric as
Pr(xi(tj)|Yt
) for i ∈max
ij
Pr(xi(tj)|Yt
)
(7.80)

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
301
If we have a “truth model”, then its corresponding probability surface is analo-
gous to the PF surface and can be generated through an ensemble simulation with
values of the probabilities selected that correspond to the true state values at t. An
even simpler technique for non-analytic distributions is to synthesize perturbed (low
noise covariances) states generated by the model at each point in index (time) and
estimate its histogram by kernel density smoothers directly to obtain an estimate of
Pr(XTrue(t)|Yt
).
Now the KD can be approximated for a given realization by
KD
(Pr(XTrue(t)|Yt
); ̂Pr( ̂XMAP(t)|Yt
)) := KL
(Pr(XTrue(t)|Yt
); ̂Pr( ̂XMAP(t)|Yt
))
+ KL
( ̂Pr( ̂XMAP(t)|Yt
); Pr(XTrue(t)|Yt
))
(7.81)
The implementation of the KD approach (state component-wise) is:
r Generate samples from the state “truth model:” {XTrue(t)};
r Estimate the corresponding state truth model distribution: ̂Pr(XTrue(t)|Yt) using
the kernel density smoother;
r From the particle ilter estimates { ̂XMAP(t)} extract or estimate the correspond-
ing posterior distribution: ̂Pr( ̂XMAP(t)|Yt
);
r Calculate the KD: KD
(Pr(XTrue(t)|Yt
); ̂Pr( ̂XMAP(t)|Yt
)); and
r Determine if KD ≈0 for PF performance.
Performing ensemble estimation also enables a corresponding set of KDs that can
also be used to generate ensemble statistics as well.
Before we close this section, we briely mention a similar metric for comparing
probability distributions—the Hellinger distance (HD), [64], [65]. The HD evolved
from measure theory and is a true distance metric satisfying all of the required
properties [64–65]. It is a metric that can also be used to compare the similarity of
two probability distributions deined by
H (Pr(xk); ̂Pr(̂xk)) :=
1
√
2
[ K
∑
k=1
(√
Pr(xk) −
√
̂Pr(̂xk)
)2] 1
2
(7.82)
The Hellinger distance HHD is a bounded metric on the probability space possess-
ing the following properties:
1. 0 ≤HHD
(Pr(xk); ̂Pr(̂xk)) ≤1
2. HHD
(Pr(xk); ̂Pr(̂xk)) = 0 ⇔Pr(xk) = ̂Pr(̂xk)
∀k
3. HHD
(Pr(xk); ̂Pr(̂xk)) = 1 ⇔Pr(xk) ≠̂Pr(̂xk)
∀k

302
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
The second property of the Hellinger distance provides a “scaled metric” similar to
the “unscaled” KD providing a reasonable calculation to compare or evaluate overall
performance.
For particle ilter design/analysis, the corresponding Hellinger distance is speciied
by
HHD
(Pr(x(t)|Yt
); ̂Pr(xi(t)|Yt
)) =
1
√
2
[ Np
∑
i=1
(√
Pr(x(t)|Yt
) −
√
̂Pr(xi(t)|Yt
))2] 1
2
(7.83)
Using the truth model and its corresponding probability surface generated through
ensemble simulation, the values of the probabilities selected correspond to the “true
state” probabilities at t synthesizing Pr(XTrue(t)|Yt
).
The HD can be approximated for a given realization by
HHD
(Pr(XTrue(t)|Yt
); ̂Pr( ̂Xi
MAP(t)|Yt
)) =
1
√
2
[ Np
∑
i=1
(√
Pr(XTrue(t)|Yt
) −
√
̂Pr( ̂Xi
MAP(t)|Yt
))2] 1
2
(7.84)
Consider the following example illustrating both KD and Hellinger distance met-
rics applied to the PF design for the trajectory estimation problem.
Example 7.6
Let us revisit the nonlinear trajectory estimation problem and calculate the Kullback–
Leibler divergence using Eq. 7.81.
Recall the discrete state-space representation:
x(t) = (1 −0.05△T)x(t −1) + 0.04△Tx2(t −1) + �(t −1)
y(t) = x2(t) + x3(t) + �(t)
where △t = 0.01, �∼(0, 10−6) and �∼(0, 0.09). The initial state is Gaussian
distributed with xi(0) ∼(x(0), P(0)) and x(0) = 2.3, P(0) = 10−2.
Here we see the results of estimating the KD over a 100-member ensemble with
the corresponding state and measurement PMFs in Figs. 7.16a and 7.16b. The result-
ing KD over each member realization is shown in Figs. 7.16c and 7.16d, respec-
tively for the state and measurement ensembles with the HD shown in Figs. 7.16e
and 7.16f. Here the median and mean KD estimates are indicated by the dashed
lines in the igure. The corresponding measurement median and average KDs of
0.00124 and 0.00130 and state KDs of 0.00144 and 0.00146 are shown in (c) and
(d). Similarly, the Hellinger distance metric coincides with the KD-metric giving
HDs median and average state of 0.0189 and 0.0189 with corresponding measure-
ment median and average of 0.0176 and 0.0178 as shown in Figs. 7.16e and 7.16f,
respectively.
△△△

Measurement ensemble
State ensemble
0
10
20
30
40
50
60
70
80
90
100
Ensemble no.
0.014
0.016
0.018
0.02
0.022
0.024
0.026
Median HD = 0.0189415
Mean    HD = 0.0189345 
State ensemble
Hellinger distance
0
20
40
60
80
100
Ensemble no.
0.01
0.015
0.02
0.025
Hellinger distance
Median HD = 0.017561 
Mean    HD = 0.017759 
Kullback–leibler divergence
Probability
Probability
Kullback–leibler divergence
Measurement ensemble
11
11.5
12
12.5
13
13.5
14
14.5
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
1.95
2
2.05
2.1
2.15
Particles
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
(a)
(b)
Particles
0
20
40
60
80
100
Ensemble no.
0
0.5
1
1.5
2
2.5
Measurement ensemble
Median KLDiv = 0.00123759
Mean
KLDiv = 0.00129513 
0
20
40
60
80
100
Ensemble no.
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4 ×10-3
×10-3
State ensemble
Median KLDiv = 0.00143735
Mean
KLDiv = 0.00145541 
(c)
(d)
(e)
(f)
FIGURE 7.16
PMF data: Kullback–Leibler divergence and Hellinger distance calculations for the nonlinear
trajectory estimation problem over 100-member ensemble. (a) measurement PMF ensemble; (b) state PMF
ensemble; (c) KL-divergence measurement median/mean (KD = 0.00124/0.00130); (d) KL-divergence state
median/mean (KD = 0.00144/0.00146); (e) HD-distance measurement median/mean (HD = 0.0176/0.0178);
(f) HD-distance state median/mean (HD = 0.0189/0.0189).

304
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
This completes the section, next we discuss an entirely different approach to this
distribution problem by investigating “goodness of it” testing.
7.6.4
Model Validation Testing
Of the major practical concerns with all model-based processors is whether or not the
model embedded in the processor “matches” the underlying phenomena and can be
used to extract meaningful information from the noisy measurements. As mentioned,
in the classical Gaussian-based techniques, the zero-mean/whiteness testing of the
innovations is a critical measure of this match. These properties are also used exten-
sively for linearized models evolving from nonlinear dynamic systems as well [5]. In
all of these cases the distributions are considered unimodal and typically Gaussian.
In the non-unimodal (non-Gaussian) case the diagnostics are more complicated.
The roots of MC model diagnostics lie in the basic Uniform Transformation Theorem
of Sectiontion 3.3 and the works of Rosenblatt [48] and Smith [49] under the general
area of “goodness-of-it” statistical tests [39, 40, 50, 51, 57, 58].
The fundamental idea is based on analyzing the predicted measurement cumu-
lative distribution PY(y(t)|Yt−1). A processor is considered consistent only if the
measurement y(t) is governed by the statistics of its predicted cumulative distribu-
tions. Therefore, validation consists of statistically testing that the measurements
“match” the predictions using the underlying model embedded in the processor. By
deining the residual sequence as
�(t) := PY(y(t)|Yt−1) = Pr(Y(t) ≤y(t)|Yt−1) = ∫Y≤y
Pr(y′(t)|Yt−1)dy′(t)
(7.85)
we must show that {�(t)} is a valid realization of an independent, identically dis-
tributed, process uniformly distributed on the interval [0, 1] given the measurements
Yt−1. Thus, the statistical test validates whether or not the sequence is �(t) ∼U(0, 1)
(component-wise for the vector case).
More formally, we use Rosenblatt’s theorem2 that states, if y(t) is a continuous
random vector and the underlying model is “valid”, then the corresponding sequence
{�(t)} is i.i.d. on [0, 1]. Under the assumption that the residual sequence is standard
uniform, then we can transform to obtain an equivalent Gaussian sequence [48] such
that
�(t) = Φ−1(�(t))
for �∼(0, 1) with �∼U(0, 1)
(7.86)
where Φ−1 is the inverse standard Gaussian cumulative distribution. Once the residual
sequence is transformed, then all of the classical Gaussian statistical tests can be
performed to ensure validity of the underlying model.
2 The theorem states that for a given random vector y ∈Ny×1 with corresponding distribution PY(y),
the transformed vector, �= Ty, is uniformly distributed on the Ny-hypercube for Pr(�) = ∏Ny
i=1 �i when
0 ≤�i ≤1. The transformation, T is given by �i = PY(yi|Yi−1); i = 1, … , Ny [48].

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
305
With this in mind we are still required to solve two basic problems: (1) the esti-
mation of the residual sequence �(t) or equivalently the estimation of the predictive
measurement cumulative distribution, PY(y(t)|Yt−1); and (2) the diagnostic statis-
tical testing of �(t) or equivalently �(t), that is, demonstrating that �∼U(0, 1) or
�∼(0, 1).
The key to estimating the residual sequence is based on representing the predictive
cumulative distribution as an ininite mixture [39, 40, 51]
�(t) = PY(y(t)|Yt−1) = ∫PY(y(t)|x(t)) × Pr(x(t)|Yt−1) dx(t)
(7.87)
An MC approach to this estimation problem is to “particulate” the required under-
lying distribution and estimate the empirical prediction cumulative distribution or
equivalently the residuals. Perhaps the simplest MC technique is to sample from
the predicted state distribution directly “when possible”, that is, if we could replace
the prediction distribution with its empirical representation, then we could obtain an
estimated residual [57], that is,
̂�(t) = ∫PY(y(t)|x(t)) ×
⎡
⎢
⎢⎣
1
Np
Np
∑
i=1
�(x(t) −xi(t))⎤
⎥
⎥⎦
dx(t)
(7.88)
or simply
̂�(t) = 1
Np
Np
∑
i=1
PY(y(t)|xi(t))
(7.89)
However, if direct sampling of the predicted state distribution is not possible, then the
predictive decomposition into the transition prior and posterior can be accomplished,
that is,
Pr(x(t)|Yt−1) = ∫Pr(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1)dx(t −1)
(7.90)
or using the state–space representation of the transition prior
Pr(x(t)|Yt−1) = ∫(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1)dx(t −1)
(7.91)
and performing a particle approximation, we obtain the empirical estimate of the
(t −1)-step posterior as
̂Pr(x(t −1)|Yt−1) =
Np
∑
k=1
k(t −1)�(x(t −1) −xk(t −1))
(7.92)

306
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
Substituting this expression into Eq. 7.91 gives the prediction distribution
̂Pr(x(t)|Yt−1) = ∫(x(t)|x(t −1))
×
⎡
⎢
⎢⎣
Np
∑
k=1
k(t −1)�(x(t −1) −xk(t −1))⎤
⎥
⎥⎦
dx(t −1)
=
Np
∑
k=1
k(t −1)(x(t)|xk(t −1))
(7.93)
and the residual of Eq. 7.87 becomes
̂�(t) = ∫PY(y(t)|x(t))
⎡
⎢
⎢⎣
Np
∑
k=1
k(t −1)(x(t)|xk(t −1))
⎤
⎥
⎥⎦
dx(t)
(7.94)
If we draw a sample xi(t) from the transition prior xi ∼(x(t)|xk(t −1)) and use
the perfect sample approximation,
(x(t)|xk(t −1)) ≈�(x(t) −xi(t))
(7.95)
then substituting into Eq. 7.94 for the transition distribution yields
̂�(t) =
Np
∑
k=1
k(t −1) ∫PY(y(t)|x(t)) × �(x(t) −xi(t)) dx(t)
(7.96)
giving the inal expression for the estimated residual as [39, 40, 51]
̂�(t) =
Np
∑
k=1
k(t −1)PY(y(t)|xi(t))
(7.97)
for
PY(y(t)|xi(t)) = ∫Y≤y(t)
(y(t)|xi(t)) dy(t)
which can be estimated through direct integration or using an empirical CDF [14], if
necessary.
Once we have obtained the estimate of the residual �(t) (or equivalently the
transformed residual �(t)), we can perform diagnostic tests to evaluate the “goodness-
of-it” and therefore evaluate the validity of the embedded dynamic model.
There are a variety of diagnostic tests that can be performed which include:
�2-testing (C-sq), Kolmogorov-Smirnov (K-S) tests, normality testing (graphically),

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
307
zero-mean/whiteness testing, etc. Here, we concentrate on the C-sq and K-S as well
as moment testing of the transformed residuals. Zero-mean/whiteness testing was
already discussed in Section 5.6.
Any of the Kalman techniques can also be used to generate an approximation to the
sequence of residuals or prediction cumulative distribution, using the empirical PDF,
EKF, UKF, Gauss-Hermite (G-H) grid-based integration as well as the Gaussian
mixture approach, that is, Gaussian sums (G-S) (see Refs. [51, 66–74] for more
details).
Chi-Square Model Validation Test
Chi-square (C-Sq) tests are hypothesis
tests with the null hypothesis, o, that an N-length sequence of data is a random
sample from a speciied distribution against the alternative that it is not [14, 15]. It
is usually applied to Gaussian distributions. C-Sq tests are based on the fact that the
exponent of a Gaussian distribution, that is, the square of the ratio of the random
variable minus its mean divided by its standard deviation is chi-square distributed
with N degrees of freedom, that is, (x −�∕�)2 ∼�2(N). However, this test can be
applied to any distribution.
For instance, if the random variable is binomially distributed with B(N, p) for p
the success probability, then it takes the same form as the exponent above—it is
distributed (in the limit) as �2(1). Extending this to a multinomial distribution with
parameters N and p(i) for i = 1, … , k −1; (N, {p(i)}), then in the limit as N →∞
the test statistic, say k−1, has an approximate �2(k −1) distribution.3
Hypothesis testing that o is true using the test statistic is speciied by the value
�(probability bound) of the �2(k −1) using Pr(k−1 ≥�) = �for �the signiicance
level of the test. Thus, if the test statistic is less than �the null hypothesis is accepted
and the selected distribution is correct.
For our problem, a goodness-of-it test of the residuals follows directly from
their uniformity property of an adequate model. The most common statistical tests
for uniformity follows from the �2-test based on segmenting the estimated residual
sequence on [0,1] into subintervals and testing. The chi-square statistical test can be
used to decide whether or not the residual sequence �(t) is U(0, 1) or equivalently the
transformed residual, �(t) is (0, 1).
The C-Sq test statistic for our problem is given by
N�−1 =
N�
∑
i=1
(n�(i) −�)2
�
(7.98)
where N is the total number of residual samples; N�is the number of bins (equally
spaced subintervals); n�(i) is the number of residual counts in the ith-bin (subinterval);
and �is the expected number of counts per bin given by �= N
N�.
3 To be more speciic, if the i.i.d. random variables, y1, … , yk−1 are multinomially distributed
with yk = N −∑k−1
i=1 yi and p(k) = 1 −∑k−1
i=1 p(i), then the statistic, k−1 = ∑k−1
i=1 (yi −Np(i))2∕Np(i) is
k−1 ∼�2(k −1) [15].

308
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
If the residual sequence is uniform, then N�−1 ∼�2(N�−1) and �is compatible
with a �2(N�−1) distribution at signiicance level �. Therefore, if N�−1 ≤�the null
hypothesis that the residual sequence is uniformly distributed is accepted and the
model is adequate (validated) otherwise it is rejected. Thus, the �2-model validation
test is
r Partition the N-sample residual sequence into N�bins (equally spaced subinter-
vals)
r Count the number of residual samples in each bin, n�(i); i = 1, … , N�
r Calculate the expected bin count, �= N∕N�
r Calculate the test statistic N�−1 of Eq. 7.98
r Test that N�−1 ≤�[Accept o]
Example 7.7
Suppose we have a residual sequence, �(t), scaled on [0, 1] of N = 1000 samples and
we would like to test that it is uniformly distributed using the �2-model validation
test. We partition the sequence into N�= 10 bins; therefore, the expected counts per
bin is �= 100. At the �= 5% signiicance level, the test statistic,
N�−1 = 3.22
is less than �(probability bound) accepting the null hypothesis that the sequence is
uniform and therefore the model is validated.
△△△
Next, we consider another more robust method for goodness-of-it testing.
Kolmogorov–Smirnov Model Validation Test
The chi-square goodness-of-
it test suffers from the limitations of arbitrary interval widths and the requirement
of large data sets. An alternative or complementary approach is the Kolmogorov–
Smirnov (K-S) goodness-of-it test that is based on deciding whether or not a hypoth-
esized (e.g., uniform) or estimated cumulative distribution characterizes a given data
sequence (e.g., residual). The hypothesis test is given by
o:
̂PE(�) = Po(�)
1:
̂PE(�) ≠Po(�)
(7.99)
where ̂PE is the underlying (estimated) population CDF and Po is the hypothesized
CDF. The test statistic used in making the decision is
= max
�
|PE(�) −Po(�)|
(7.100)

7.6
PRACTICAL ASPECTS OF PARTICLE FILTER DESIGN
309
where ̂PE is given by the empirical distribution function estimate
̂PN(�) = N�
N
→Pr(E ≤�) = PE(�)
as N →∞
(7.101)
For large N, ≈0 with o true while for 1 true, is close to the maximum
difference. Therefore, we reject o if > �with �a constant determined by the
level-of-signiicance of the hypothesis test, �. That is,
�= Pr(> �| o) ≈2e−2N�2
(7.102)
Thus the K-S-test is:
r Estimate the empirical CDF, ̂PE(�)
r Calculate K-S test statistic from Eq. 7.100
r Test that
<
√
−1
2N ln �
2
[Accepto]
Example 7.8
We have a residual sequence, �(t), scaled on [0, 1] of N = 25 samples and we would
like to perform the K-S test that the samples are uniformly distributed at the �= 5%
signiicance level. The test statistic,
= 0.17
is less than �= 0.26 accepting the null hypothesis that the sequence is uniform and
therefore the model is valid. The test is shown in Fig. 7.17 as the location of the
maximum deviation between the hypothesized and empirical distributions.
△△△
When the transformed residuals are used, then the standard zero-mean/whiteness
testing can be accomplished as well as estimating the moments of the Gaussian
distribution which we discuss in the next section.
Moment-Based Model Validation Test
When the residuals are transformed
from the hypothesized uniformly distributed sequence to a standard Gaussian,
�∼(0, 1), then a wealth of normality diagnostics can be applied to validate the
adequacy of the embedded model. Besides the zero-mean/whiteness and WSSR tests
of Section 5.6 for Gaussian processes, the usual suite of diagnostics can be applied to
estimate the underlying moments to check for consistency of the Gaussian assump-
tion and therefore model validation. The brute force approach is simply to calculate

310
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Random variable
Empirical CDF
Hypothesized true CDF
Kolmogorov-Smirnov test
CDF
FIGURE 7.17
Kolmogorov–Smirnov model validation test of residual sequence: hypoth-
esized and empirical CDF.
the mean-squared (estimation) error over an ensemble of runs of the processor and
any truth model available for comparison,
�=
√
E{(Θtrue −̂Θ)2}
(7.103)
where Θ can be any parameter, state, or measurement estimated by ̂Θ and the expec-
tation can be calculated by integrating or solving over an ensemble generated by
executing the processor a multitude of times and averaging. This can be very costly
and sometimes impossible because of the lack of the “truth”.
Another approach is to calculate a set of statistical indexes that can be used to
“qualitatively” assess performance and model validity using the transformed residual
sequence �(t) [51–53]. Here the irst four central moments of an N-sample sequence
of transformed residuals are estimated based on
m�(k) = 1
N
N
∑
t=1
(�(t) −m�(1))k
for k ≥2
(7.104)
with the irst moment the sample mean
m�(1) = 1
N
N
∑
t=1
�(t)
(7.105)

7.7
CASE STUDY: POPULATION GROWTH PROBLEM
311
These moments can then be used to construct the following diagnostic indices
which are asymptotically distributed (0, 1) (see Ref. [51] for details).
r Bias Index: N =
√
Nm�(1)
r Dispersion Index: N = Nm�(2) −N + 1
√
2(N −1)
r Skewness Index: N =
√
(N + 1)(N + 3)
6(N −2)
×
m�(3)
√
m3�(2)
r Tail Index: N = (N + 1)
√
(N + 3)(N + 5)
√
24N(N −2)(N −3) ×
( m�(3)
m�(4) −3(N −1)
(N + 1)
)
r Joint Index: N = 2
N + 2
N
From a pragmatic perspective these indices are used in a more qualitative manner
even though they are quantitative. They are used to expose “surprising values”,
that is, for N not too small, the indices can be bound by some constant, �and
compared with upper and lower quantile estimates of their exact distribution [51].
For instance, consider the quantile N,�of the exact dispersion index distribution
under the assumption of a valid model. Then it can be shown [51] that
N,�= (�2
N−1,�−(N −1)∕
√
2(N −1))
(7.106)
where �2
N−1,�is �2(N −1) distributed. Other measures such as the skewness and tail
indices, SN and N can be obtained from MC simulations [51].
If N is surprisingly high or low, the measurements tend to be larger or smaller then
predicted (̂y(t)), while a surprisingly high or low dispersion index, N indicates that
the measurements are under or over dispersed. The SN and N are useful in analyzing
the measurement distribution. A higher or lower SN indicates a skew to either right or
left while a higher or lower N indicates longer or shorter tails, respectively. The N
is an asymptotically equivalent to normality tests [50, 54]. A suite of other statistics
exist for testing correlations [55, 56] as well.
This completes the section on practical aspects of PF design and analysis. We will
couple these statistical tests to the classical whiteness testing techniques to evaluate
the performance of the processors. Next, let us consider the design of a “bootstrap”
processor on a canonical problem: a case study for population growth.
7.7
CASE STUDY: POPULATION GROWTH PROBLEM
In this section, we discuss the development of SSPFfor the population growth prob-
lem. We consider this well-known problem that has become a benchmark for many
of the PF algorithms. It is highly nonlinear and nonstationary. Thus, consider the
problem of [25] and [20, 26–29].

312
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
The state transition and corresponding measurement model are given by
x(t) = 1
2x(t −1) +
25x(t −1)
1 + x2(t −1) + 8 cos(1.2(t −1)) + �(t −1)
y(t) = x2(t)
20 + �(t)
where △t = 1.0, �∼(0, 10) and �∼(0, 1). The initial state is Gaussian dis-
tributed with x(0) ∼(0.1, 5).
In terms of the nonlinear state–space representation, we have
a[x(t −1)] = 1
2x(t −1) +
25x(t −1)
1 + x2(t −1)
b[u(t −1)] = 8 cos(1.2(t −1))
c[x(t)] = x2(t)
20
In the Bayesian framework, we would like to estimate the instantaneous posterior
iltering distribution,
̂Pr(x(t)|Yt) ≈
Np
∑
i=1
i�(x(t) −xi(t))
(7.107)
where the unnormalized importance weight is given by
Wi(t) = (y(t)|xi(t)) × (x(t)|xi(t −1))
q(xi(t)|Xt−1, Yt)
(7.108)
The weight recursion for the bootstrap case is Wi(t) = Wi(t −1) × (y(t)|x(t)). There-
fore, for the Bayesian processor, we have that the state transition probability is given
by
(x(t)|x(t −1)) ∼(x(t) : a[x(t −1)], R��)
(7.109)
Thus, the SIR algorithm becomes:
1. Draw samples (particles) from the state transition distribution: xi(t) →(x(t) :
a[x(t −1)], R��)
�i(t) →Pr(�(t)) ∼(0, R��)
xi(t) = 1
2xi(t −1) + 25xi(t −1)
1 + x2
i (t −1) + 8 cos(1.2(t −1)) + �i(t −1)

7.7
CASE STUDY: POPULATION GROWTH PROBLEM
313
2. Estimate the weight/likelihood,
Wi(t) = (y(t)|x(t)) →(y(t) : c[x(t)], R��(t))
c[xi(t)] =
x2
i (t)
20
3. Normalize the weight: i(t) = Wi(t)∕∑Np
i=1 Wi(t)
4. Resample: ̂xi ⇒xi
5. Estimate the instantaneous posterior:
̂Pr(x(t)|Yt) ≈
Np
∑
i=1
i�(x(t) −xi(t))
6. Estimate (inference) the corresponding statistics:
̂XMAP(t) = arg max
x(t)
̂Pr(x(t)|Yt)
̂XCM(t) = E{x(t)|Yt} =
Np
∑
i=1
xi(t) ̂Pr(x(t)|Yt)
̂XMEDIAN(t) = median( ̂Pr(x(t)|Yt))
We show the simulated data in Fig. 7.18; in (a) we see the hidden state and
(b) the noisy measurement. The state and measurement PF estimates for a single
realization are shown in Figs. 7.18c and 7.18d. Final performance of the processor
over a 100-member ensemble is illustrated in Figs. 7.18e and 7.18f demonstrating
the effectiveness of the PF bootstrap processor for this problem. Various ensemble
estimates are shown for the CM and MAP estimates, each performing reasonably
well. Next, the estimated instantaneous posterior distribution surface for the state is
shown in Fig. 7.19a, while slices at selected instants of time (t = 26, t = 60, t = 96)
are shown in (b) to (d) with the circles annotating particle locations normalized to a
constant weight. Here we see that the posterior is clearly not unimodal and in fact we
can see its evolution in time as suggested by Fig. 7.1 previously. Finally, we show
the “distribution closeness” metrics in Fig. 7.20 with the ensemble PMF estimates
compared to the “true” distribution in (a) and (b) followed by the KD in (c) and
(d) and the corresponding Hellinger distance (HD) in (e) and (f). Here we see the
results of estimating the KD over a 100-member ensemble with the corresponding
state and measurement PMFs in Figs. 7.20a and 7.20b. The resulting KD over each
member realization is shown in Figs. 7.20c and 7.20d, respectively for the state
and measurement ensembles with the HD shown in Figs. 7.20e and 720f. Here the
median and mean KD estimates are indicated by the dashed lines in the igure.
The corresponding measurement median and average KDs of 0.283 and 0.284 and
state KDs of 0.0701 and 0.0704 are shown in (c) and (d). Similarly, the Hellinger

0
10
20
30
40
50
60
70
80
90
100
–20
–15
–10
–5
0
5
10
15
20
Time (sec)
X-Amplitude 
Simulated state
(a)
15
0
10
20
30
40
50
60
70
80
90
100
–5
0
5
10
20
 Simulated measurements
Y–Amplitude
Time (sec)
(b)
0
10
20
30
40
50
60
70
80
90
100
Time (sec)
–5
0
5
10
15
20
25
Y–Amplitude
Time (sec)
0
10
20
30
40
50
60
70
80
90
100
–25
–20
–15
–10
–5
0
5
10
15
20
25
PF ensemble state estimate
PF ensemble measurement estimate  
Amplitude
(f)
(e)
CM
CM
MAP
MAP
Data
Data
Time (sec)
0
10
20
30
40
50
60
70
80
90
100
–5
0
5
10
15
20
Time (sec)
Y–Amplitude
-
PF measurement estimate
(d)
MAP
CM
Data
0
10
20
30
40
50
60
70
80
90
100
–25
–20
–15
–10
–5
0
5
10
15
20
25
PF state estimate
Amplitude
(c)
MAP
CM
Data
FIGURE 7.18
Nonlinear, nonstationary, non-Gaussian problem: (a) simulated state; (b) simulated
measurement; (c) single realization of state PF estimates: CM and MAP; (d) single realization of mea-
surement PF estimates: CM and MAP; (e) 100-member ensemble of state PF estimates: CM and MAP;
(f) 100-member ensemble of measurement PF estimates: CM and MAP.

(a)
(b)
X-updated posterior distribution (Pr[x(t)||Yt]) state no.1
Xupdate sample no.
Time (sec)
(c)
(d)
FIGURE 7.19
Nonlinear, nonstationary, non-Gaussian problem surface and time slices (cross-section) with parti-
cle locations annotated by circles. (a) Instantaneous posterior surface; (b) 26th time slice; (c) 60th time slice; (d)
96th time slice.

Ensemble no.
0
10
20
30
40
50
60
70
80
90
100
0.26
0.27
0.28
0.29
0.3
0.31
0.32
0.33
Median KLDiv = 0.28254
Mean    KLDiv = 0.28387 
Measurement ensemble
Kullback–Leibler divergence
Kullback–Leibler divergence
Ensemble no.
0
10
20
30
40
50
60
70
80
90
100
0.055
0.06
0.065
0.07
0.075
0.08
0.085
0.09
0.095
Median KLDiv = 0.0700913
Mean
KLDiv = 0.0704262 
State ensemble
Hellinger distance
0
20
40
60
80
100
Ensemble no.
0.255
0.26
0.265
0.27
0.275
0.28
0.285
0.29
Median HDiv = 0.272102
Mean    HDiv = 0.272100 
Measurement ensemble
Hellinger distance
0
20
40
60
80
100
Ensemble no.
0.115
0.12
0.125
0.13
0.135
0.14
0.145
0.15
Median HDiv = 0.126951
Mean    HDiv = 0.127761 
State ensemble
–10
–5
0
5
10
15
20
25
30
35
Particles
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
Measurement ensemble
Probability
–40
–30
–20
–10
0
10
20
30
40
Particles
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
State ensemble
Probability
PF
PF
True
True
FIGURE 7.20
PMF data: Kullback–Leibler divergence and Hellinger distance calculations for the nonlinear tra-
jectory estimation problem over 100-member ensemble. (a) Measurement PMF ensemble; (b) state PMF ensem-
ble; (c) KL-divergence measurement median/mean (KD = 0.283/0.284); (d) KL-divergence state median/mean
(KD = 0.0701/0.0704); (e) HD-distance measurement median/mean (HD = 0.272/0.272); (f) HD-distance state
median/mean (HD = 0.1270/0.1277).

7.8
SUMMARY
317
distance metric coincides with the KD-metric giving HDs median and average state
of 0.272 and 0.272 with corresponding measurement median and average of 0.1270
and 0.1277 as shown in Figs. 7.20e and 7.20f, respectively.
7.8
SUMMARY
In this chapter, we have discussed the development of SSPF. After introducing the idea
of Bayesian particle ilters, we showed how the state–space models could easily be
interpreted in terms of this framework. We developed a generic state–space particle
iltering algorithm based on the importance (sampling) proposals selected either
using the minimum variance or transition prior approach. However we emphasized
that in practice these techniques suffer from particle depletion and lack of diversity
because of ever-increasing weight variances causing divergence of the processors.
We introduced the concept of resampling as a solution to the divergence problem and
discussed a number of techniques to mitigate the divergence problem. With that in
hand, we discussed the popular bootstrap particle ilter and showed some examples
to demonstrate its performance. We then proceeded to discuss improvements to the
bootstrap approach attempting to approximate the minimum variance proposal. These
methods included the auxiliary, regularized, MCMC and linearized algorithms. Next,
we investigated some of the practical aspects of particle ilter design and developed
a number of statistical tests to determine performance including both information
theoretic approaches to validate the posterior distribution as well as diagnostic testing
for model validation. We concluded the chapter with a case study on population
growth—a nonlinear/non-Gaussian model presenting a very challenging problem
for any particle ilter design. Besides the references in the chapter there has been a
wealth of particle iltering papers appearing in both the statistics and signal processing
literature [30–43].
MATLAB NOTES
MATLAB is a command oriented vector-matrix package with a simple yet effec-
tive command language featuring a wide variety of embedded C language con-
structs making it ideal for signal processing applications and graphics. MATLAB
has a Statistics Toolbox that incorporates a large suite of PDFs and CDFs as well
as “inverse’ CDF functions ideal for simulation-based algorithms. The mhsam-
ple command incorporate the Metropolis, Metropolis–Hastings and Metropolis
independence samplers in a single command while the Gibbs sampling approach
is adequately represented by the more eficient slice sampler (slicesample). There
are even speciic “tools” for sampling as well as the inverse CDF method cap-
tured in the randsample command. PDF estimators include the usual histogram
(hist) as well as the sophisticated kernel density estimator (ksdensity) offering a
variety of kernel (window) functions (Gaussian, etc.) and ICDF methods includ-
ing the empirical cumulative distribution (ecdf) estimator. As yet no sequential

318
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
algorithms are available. In terms of statistical testing for particle iltering diagnos-
tics MATLAB offers the chi-square “goodness-of-it” test chi2gof as well as the
Kolmogorov–Smirnov distribution test kstest. Residuals can be tested for white-
ness using the Durbin-Watson test statistic dwtest while “normality” is easily
checked using the normplot command indicating the closeness of the test distri-
bution to a Gaussian. Other statistics are also evaluated using the mean, moment,
skewness, std, var and kurtosis commands. Type help stats in MATLAB to get
more details or go to the MathWorks website.
REFERENCES
1. B. Ristic, S. Arulampalam, and N. Gordon, Beyond the Kalman Filter: Particle Filters for
Tracking Applications (Boston, MA: Artech House, 2004).
2. M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp, “A tutorial on particle ilters
for online nonlinear/non-Gaussian Bayesian tracking,” IEEE Trans. Signal Proc., 50, 2,
174–188, 2002.
3. P. Djuric, J. Kotecha, J. Zhang, Y. Huang, T. Ghirmai, M. Bugallo, and J. Miguez, “Particle
iltering,” IEEE Signal Proc. Mag., 20, 5, 19–38, 2003.
4. A. Doucet and X. Wang, “Monte Carlo methods for signal processing,” IEEE Signal Proc.
Mag., 24, 5, 152–170, 2005.
5. J. Candy, Model-Based Signal Processing (Hoboken, NJ: Wiley-IEEE Press, 2006).
6. O. Cappe, S. Godsill, and E. Moulines, “An overview of existing methods and recent
advances in sequential Monte Carlo,” Proc. IEEE, 95, 5, 899–924, 2007.
7. A. Doucet, N. de Freitas, and N. Gordon, Sequential Monte Carlo Methods in Practice
(New York: Springer-Verlag, 2001).
8. M. Pitt and N. Shephard, “Filtering via simulation: auxiliary particle ilters,” J. Am. Stat.
Assoc., 94, 446, 590–599, 1999.
9. R. van der Merwe, A. Doucet, N. de Freitas, and E. Wan, “The unscented particle ilter,”
in Advances in Neural Information Processing Systems 16 (Cambridge, MA: MIT Press,
2000).
10. R. van der Merwe, “Sigma-point Kalman ilters for probabilistic inference in dynamic
state–space models,” Ph.D. Dissertation, OGI School of Science & Engineering, Oregon
Health & Science University, 2004.
11. T. Schoen, “Estimation of nonlinear dynamic systems: theory and applications,” Ph.D.
Dissertation, Linkopings University, Linkoping, Sweden, 2006.
12. J. Liu, Monte Carlo Strategies in Scientiic Computing (New York: Springer-Verlag,
2001).
13. J. Ruanaidh and W. Fitzgerald, Numerical Bayesian Methods Applied to Signal Processing
(New York: Springer-Verlag, 1997).
14. A. Papoulis and S. Pillai, Probability, Random Variables and Stochastic Processes, 4th
Ed. (New York: McGraw-Hill, 2002).
15. R. Hogg, J. McKlean, and A. Craig, Introduction to Mathematical Statistics, 6th Ed.
(Englewood Cliffs, NJ: Prentice-Hall, 2005).

REFERENCES
319
16. N. Gordon, D. Salmond, and A. Smith, “A novel approach to nonlinear non-Gaussian
Bayesian state estimation,” IEE Proc. F., 140, 107–113, 1993.
17. D. Simon, Optimal State Estimation: Kalman H∞and Nonlinear Approaches (Hoboken,
NJ: Wiley-IEEE Press, 2006).
18. P. Stavropoulos and D. Titterington, “Improved particle ilters and smoothing,” in Sequen-
tial Monte Carlo Methods in Practice, edited by A. Doucet, N. de Freitas, and N. Gordon
(New York: Springer, 2001), pp. 295–317.
19. J. Liu, R. Chen, and W. Wong, “Rejection control and sequential importance sampling,”
J. Am. Stat. Assoc., 96, 446, 1022–1061, 1998.
20. G. Kitagawa, “Non-gaussian modeling of nonstationary time series,” J. Am. Stat. Assoc.,
82, 400, 1032–1073, 1987.
21. A. Jazwinski, Stochastic Processes and Filtering Theory (New York: Academic Press,
1970).
22. M. Isard and A. Blake, “Condensation–conditional density propagation for visual track-
ing,” Int. J. Comput. Vis., 29, 1, 5–28, 1998.
23. M. West and J. Harrison, Bayesian Forecasting and Dynamic Models, 2nd Ed. (New York:
Springer-Verlag, 1997).
24. O. Cappe, E. Moulines, and T. Ryden, Inference in Hidden Markov Models (New York:
Springer-Verlag, 2005).
25. M. Andrade Netto, L. Gimeno, and J. Mendes, “On the optimal and suboptimal nonlinear
iltering problem for discrete-time systems,” IEEE Trans. Auto. Control, AC-23, 6, 1063–
1067, 1978.
26. G. Kitagawa, “A nonlinear smoothing method for time series analysis,” Statistica Sinica,
1, 2, 371–388, 1991.
27. G. Kitagawa and W. Gersch, Smoothness Priors Analysis of Time Series (New York:
Springer-Verlag, 1997).
28. G. Kitagawa, “Monte Carlo ilter and smoother for non-Gaussian nonlinear state–space
models,” J. Comput. Graphical Stat., 5, 1, 1–25, 1997.
29. G. Kitagawa, “Self-organizing state space model,” J. Am. Stat. Assoc., 97, 447, 1207–1215,
1998.
30. H. Tanizaki, Nonlinear Filters (New York: Springer-Verlag, 1993).
31. M. Tanner, Tools for Statistical Inference: Methods for the Exploration of Posterior Dis-
tributions and Likelihood Functions, 2nd Ed. (New York: Springer-Verlag, 1993).
32. A. Kong, J. Liu, and W. Wong, “Sequential imputations and Bayesian missing data
problems,” J. Am. Stat. Assoc., 89, 425, 278–288, 1994.
33. J. Liu and R. Chen, “Blind deconvolution via sequential imputations,” J. Am. Stat. Assoc.,
90, 460, 567–576, 1995.
34. J. Liu and R. Chen, “Sequential Monte Carlo methods for dynamic systems,” J. Am. Stat.
Assoc., 96, 446, 1062–1044, 1998.
35. A. Smith and A. Gelfand, “Bayesian statistics without tears: a sampling-resampling per-
spective,” Am. Statistician, 44, 4, 84–88, 1992.
36. S. Haykin, Kalman Filtering and Neural Networks (Hoboken, NJ: John Wiley & Sons,
2001).
37. S. Godsill and P. Djuric, “Monte Carlo methods for statistical signal processing,” IEEE
Trans. Signal Proc., 50, 173–499, 2002 (Special Issue).

320
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
38. S. Haykin and N. de Freitas, “Sequential state estimation: from Kalman ilters to particle
ilters,” Proc. IEEE, 92, 3, 399–574, 2004 (Special Issue).
39. C. Andrieu, A. Doucet, S. Singh, and V. Tadic, “Particle methods for change detection,
system identiication and control,” Proc. IEEE, 92, 6, 423–468, 2004.
40. J. Vermaak, C. Andrieu, A. Doucet, and S. Godsill, “Particle methods for Bayesian
modeling and enhancement of speech signals,” IEEE Trans. Speech Audio Proc., 10, 3,
173–185, 2002.
41. A. Doucet, S. Godsill, and C. Andrieu, “On sequential Monte Carlo sampling methods for
Bayesian iltering,” Statist. Comput., 10, 6, 197–208, 2000.
42. A. Harvey, S. Koopman, and N. Shephard, State Space and Unobserved Compo-
nent Models: Theory and Applications (Cambridge, UK: Cambridge University Press,
2004).
43. J. Candy, “Bootstrap Particle Filtering,” IEEE Signal Proc. Magaz., 24, 4, 73–85, 2007.
44. C. Musso, N. Oudjane, and F. LeGland, “Improving regularized particle ilters,” in Sequen-
tial Monte Carlo Methods in Practice, edited by A. Doucet, N. de Freitas, and N. Gordon
(New York: Springer, 2001), pp. 247–271.
45. N. de Freitas, C. Andrieu, P. Hojen-Sorensen, M. Niranjan, and A. Gee, “Sequential Monte
Carlo methods for neural networks,” in Sequential Monte Carlo Methods in Practice,
edited by A. Doucet, N. de Freitas, and N. Gordon (New York: Springer, 2001), pp.
359–379.
46. W. Gilks and C. Berzuini, “Following a moving target—Monte Carlo inference for
dynamic Bayesian models,” J. R. Stat. Soc. B, 63, 127–146, 2001.
47. C. Berzuini and W. Gilks, “Resample-move iltering with cross-model jumps,” in Sequen-
tial Monte Carlo Methods in Practice, edited by A. Doucet, N. de Freitas, and N. Gordon
(New York: Springer, 2001), pp. 117–138.
48. M. Rosenblatt, “Remarks on a multivariate transformation,” Ann. Math. Stat., 23, 470–472,
1952.
49. J. Smith, “Diagnostic checks of non-standard time series models,” J. Forecasting, 4,
283–291, 1985.
50. A. Harvey, Forecasting, Structural Time Series Models and the Kalman Filter (Cambridge,
UK: Cambridge University Press, 1989).
51. S. Fruhwirth-Schnatter, “Recursive residuals and model diagnostics for normal and non-
normal state–space models,” Environ. Ecological Stat., 3, 291–309, 1996.
52. S. Fruhwirth-Schnatter, “Bayesian model discrimination and Bayes factors for linear
Gaussian state space models,” J. R. Stat. Soc. B, 57, 237–246, 1995.
53. S. Fruhwirth-Schnatter, “Applied state space modelling of non-Gaussian time series using
integration-based Kalman iltering,” Stat. Comput., 4, 259–269, 1994.
54. K. Bowman and L. Shenton, “Omnibus test countours for departures from normality based
on
√
b1 and b2,” Biometrika, 62, 2, 243–250, 1975.
55. G. Ljung and G. Box, “On a measure of lack of it in time series models,” Biometrika, 65,
2, 297–303, 1978.
56. S. Shapiro and M. Wilk, “An analysis of variance test for normality,” Biometrika, 52, 4,
591–611, 1965.
57. R. Gerlach, C. Carter, and R. Kohn, “Diagnostics for time series analysis,” J. Time Series
Anal., 20, 3, 309–330, 1999.

PROBLEMS
321
58. F. Gustafsson, Adaptive Filtering and Change Detection (New York: John Wiley & Sons,
2000).
59. H. Akaike, “A new look at the statistical model identiication,” IEEE Trans. Autom.
Control, 19, 716–723, 1974.
60. Y. Sakamoto, M. Ishiguro, and G. Kitagawa, Akaike Information Criterion Statistics
(Boston, MA: D. Reidel/Kluwer Academic, 1986).
61. A. Bhattacharyya, “On a measure of divergence between two statistical populations deined
by their probability distributions,” Bull. Calcutta Math. Soc., 35, 99–109, 1943.
62. S. Kullback and R. Leibler, “On information and suficiency,” Ann. Math. Stat., 22, 79–86,
1951.
63. S. Kullback, Information Theory and Statistics (Gloucester, MA: Peter Smith, 1978).
64. M. Nikulin, “Hellinger distance,” in Encyclopedia of Mathematics, edited by Hazewinkel
(New York: Springer, 2001).
65. R. Beran, “Minimum Hellinger distance estimates for parametric models,” Ann. Stat., 5,
3, 445–463, 1977.
66. S. Kay, Modern Spectral Estimation (New Jersey: Prentice-Hall, 1988).
67. S. Haykin, Adaptive Filtering Theory (New Jersey: Prentice-Hall, 1996).
68. M. Hayes, Statistical Digital Signal Processing and Modeling (New York: John Wiley &
Sons, Inc., 1996).
69. G. Hendeby, R. Karlsson, and F. Gustafsson, “Performance issues in non-Gaussian iltering
problems,” in Proceedings of IEEE NSSPW, Cat. No. 06EX1506, Cambridge, UK, 2006.
70. N. Cui, L. Hong, and J. Layne, “A comparison of nonlinear iltering approaches with an
application to ground target tracking,” Signal Proc., 85, 1469–1492, 2005.
71. K. Ito and K. Xiong, “Gaussian ilters for nonlinear iltering problems,” IEEE Trans.
Autom. Control, 45, 5, 910–927, 2000.
72. H. Sorenson and D. Alspach, “Recursive Bayesian estimation using gaussian sums,”
Automatica, 7, 465–479, 1971.
73. D. Alspach and H. W. Sorenson, “Nonlinear Bayesian estimation using Gaussian sum
approximations,” IEEE Trans. Autom. Control, 17, 4, 439–448, 1972.
74. I. Arasaratnam, S. Haykin, and R. Elliott, “Discrete-time nonlinear iltering algorithms
using Gauss-Hermite quadrature,” Proc. IEEE, 95, 5, 953–976, 2007.
PROBLEMS
7.1
Given a sequence of Gaussian data (measurements) characterized by
y ∼(�, �2), ind the best estimate of the parameters deined by Θ := [�
�]′
using a “sequential’ MC approach. Show the mathematical steps in developing
the technique and construct a simple PF to solve the problem.
7.2
Consider the following simple model [7]
x(t) = ax(t −1) + �(t −1)
for �∼(0, R��(i)) with (t) = i
y(t) = x(t) + �(t)
for �∼(0, R��)

322
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
with Pr((t) = i|(t −1), x(t −1)) = Pr((t) = i) = pi
(a) Suppose i = {1, 2}, what is the distribution, Pr((t) = (i1, i2), x1|y1, x0)?
(b) How would the marginal be estimated using a Kalman ilter?
(c) Develop a computational approach to bootstrap PF algorithm for this
problem.
7.3
Suppose we have two multivariate Gaussian distributions for the parameter
vector, Θ ∼(�i, Σi); i = 1, 2
(a) Calculate the Kullback–Leibler (KL) distance metric, J.
(b) Calculate the Hellinger (HD) distance metric, HHD.
(c) Suppose Σ = Σ1 = Σ2, recalculate the KL and HD for this case.
7.4
An aircraft lying over a region can use the terrain and an archival digital map
to navigate. Measurements of the terrain elevation are collected in real time
while the aircraft altitude over mean sea level is measured by a pressure meter
with ground clearance measured by a radar altimeter [7]. The measurement
differences are used to estimate the terrain elevations and compared to a digital
elevation map to estimate aircraft position. The discrete navigation model is
given by
x(t) = x(t −1) + u(t −1) + �(t −1)
for �∼(0, R��)
y(t) = c[x(t)] + �(t)
for �∼(0, R��)
where x is the 2D-position, y is the terrain elevation measurement, the navi-
gation systems output u and �are the respective distance traveled and error
drift during one time interval. The nonlinear function c[⋅] denotes the terrain
database yielding terrain elevation outputs with �the associated database errors
and measurements. Both noises are assumed zero-mean, Gaussian with known
statistics, while the initial state is also Gaussian, x(0) ∼(x(0), P(0)).
(a) Based on this generic description construct the bootstrap PF algorithm for
this problem.
(b) Suppose: P(0) = diag[104 104]′, R��= diag[25 25]′, R��= 16, N = 150
samples, u(t) = [25 25]′. Simulate the aircraft measurements and apply the
bootstrap algorithm to estimate the aircraft position.
7.5
In inancial systems, a stochastic volatility model is used in the analysis of inan-
cial time series such as daily luctuations in the stock market prices, exchange
rates and option pricing. The volatility is usually expressed in terms of a time-
varying variance with the model given by:
y(t) = �(t) × �(t)
�∼(0, 1)
ln �2(t) = �+ �ln �2(t −1) + ln �2(t)

PROBLEMS
323
or equivalently
y(t) = e�(t)∕2 × �(t) × �(t)
�∼(0, 1)
ln �2(t) = �(t) ln �2(t −1) + �(t)
�∼(0, �2)
where �(t) corresponds to the time-varying volatility (amplitude) and the second
relation represents the change in volatility. The parameters �and �are regression
coeficients, and the remaining parameters are the ln �2(t) variance term.
(a) Suppose we would like to estimate the unknown parameters augmenting the
original state (ln �2(t)) with the unknowns, �, �, ln �2. Assume the param-
eters can be represented by a random walk driven by zero-mean, Gaussian
noise processes. What is the overall model for this inancial system?
(b) Construct a bootstrap PF for this problem.
(c) Simulate the data for N = 1000 samples and estimate the volatility and
parameters. The simulation parameters are: �= 1.8, �= 0.95, �2 = 0.1, and
�∼(0, 1).
7.6
Develop a suite of particle ilters for the RC-circuit problem of Example 5.1
where the output voltage was given by:
e(t) =
(
1 −△T
RC
)
e(t −1) + △T
C Iin(t −1)
where eo is the initial voltage and R is the resistance with C the capacitance.
The measurement equation for a voltmeter of gain Ke is simply
eout(t) = Kee(t)
Recall that for this circuit the parameters are: R = 3.3 kΩ and C = 1000 �F,
ΔT = 100 ms, eo = 2.5 V, Ke = 2.0, and the voltmeter is precise to within ±4 V.
Then transforming the physical circuit model into state–space form by deining
x = e, y = eout, and u = Iin, we obtain
x(t) = 0.97x(t −1) + 100u(t −1) + �(t −1)
y(t) = 2x(t) + �(t)
The process noise covariance is used to model the circuit parameter uncertainty
with R��= 0.0001, since we assume standard deviations, △R, △C of 1%. Also,
R��= 4, since two standard deviations are △V = 2
(
1
24 V
)
. We also assume
initially that the state is x(0) ∼(2.5, 10−12), and that the input current is a step
function of u(t) = 300 �A.
With this in mind, we know that the optimal processor to estimate the state
is the linear BP (Kalman ilter).

324
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
(a) After performing the simulation using the parameters above, construct a
bootstrap PF and compare its performance to the optimal. How does it
compare? Whiteness? Zero-mean? State estimation error?
(b) Let us assume that the circuit is malfunctioning and we do not pre-
cisely know the current values of RC. Construct a parameter estimator
for A = 1∕RC using the EKF or UKF and compare its performance to the
bootstrap and linearized PF.
(c) Try “roughening” the bootstrap PF, does its performance improve? Compare
results (see Chapter 8 for details).
7.7
Consider the storage of plutonium nitrate in a tank (see Ref. [5] for details),
we would like to dynamically estimate the amount (mass) of Pu present at any
given time. Losses occur due to radiolysis and evaporation. The underlying
state–space model for this system is given by:
Summarizing the process and measurement models in state–space form, we
have
d
dt
[
m(t)
�(t)
]
=
[
−KrP
0
0
0
] [
m(t)
�(t)
]
+
⎡
⎢
⎢⎣
1
0
⎤
⎥
⎥⎦
u(t) +
[
�1(t)
�2(t)
]
where u is a step function of amplitude −KH. The corresponding measurement
model based on pressure measurements is
[
ΔPA
ΔPB
]
=
[
g∕b
−(a∕b)g
0
gH
] [
m(t)
�(t)
]
+
⎡
⎢
⎢⎣
�1(t)
�2(t)
⎤
⎥
⎥⎦
discretizing the dynamics and incorporating the model parameters, we obtain
the Gauss–Markov model with sampling interval of 0.1 day as
x(t) =
[
0.999
0
0
1
]
x(t −1) +
⎡
⎢
⎢⎣
1
0
⎤
⎥
⎥⎦
u(t −1) + �(t −1)
y(t) =
[
29.8
−0.623
0
24.9
]
x(t) + �(t)
R��= diag[10 10], R��= diag[5.06 × 104 1.4 × 105] with initial conditions
̂x(0|0) = [988 1455]′ and ̃P(0|0) = diag[0.01 0.01].
(a) Develop the optimal BP for this problem and compare its performance to
the bootstrap PF.
(b) How well does the bootstrap PF perform? How about the linearized PF?
7.8
We are asked to investigate the possibility of creating a synthetic aperture using
a single hydrophone to be towed by an AUV in search of targets. We know that

PROBLEMS
325
a single hydrophone offers no improvement in SNR in the sense of array gain,
but also wonder about its capability to localize, especially more than one target.
(a) Using the synthetic aperture model developed in the case study of Section
8.5, develop the bootstrap PF and UKF processors for this problem. Assume
we would like to track two targets.
(b) Perform the same simulation outlined in the case study for two targets at
−45◦, −10◦.
(c) Apply the bootstrap algorithm with and without “roughening” along with
the UKF. Discuss processor performances and compare. Zero-mean? White-
ness?
(d) Implement the “optimal” PF processor using the EKF or UKF linearization.
How does its performance compare?
7.9
We are asked to investigate the possibility of inding the range of a target
using a hydrophone sensor array towed by an AUV assuming a near-ield target
characterized by it spherical wavefront instead of the far-ield target of the
previous problem using a plane wave model. The near-ield processor can be
captured by a wavefront curvature scheme (see Ref. [5] for more details) with
process and measurement models (assuming that the parameters as well as
the measurements are contaminated by additive white Gaussian noise). The
following set of dynamic relations can be written succinctly as the Gauss–
Markov wavefront curvature model as
Θ(tk) = Θ(tk−1) + �(tk)
for Θ(tk) = [�
fo
�o
ro]′
p�(tk) = �1(tk)ej2��2(tk)(tk−��(Θ;tk)) + ��(tk); �= 1, … , L
where �, fo, �o and ro are the respective amplitude, target frequency, bearing
and range. The time delay at the �th-sensor and time tk is given in terms of the
unknown parameters of
��(Θ; tk) := 1
c
(
�4(tk) −
√
�2
4(tk) + d2
�(t) −2d�(t)�4(tk) sin �3(tk)
)
for d�(t) the distance between the �th sensor and reference range ro given by
d�(t) = x�+ �× tk
for x�the position of sensor �
(a) Using this model develop the bootstrap PF and UKF processors for this
problem. Assume we would like to estimate the target bearing, frequency
and range (�= 1).
(b) Perform a simulation with initial parameters ro = 3 Km, fo = 51.1 Hz and
�o = 27◦and true parameters at r = 2 Km, f = 51 Hz and �= 25◦, L = 4.

326
PARTICLE-BASED BAYESIAN STATE–SPACE PROCESSORS
(c) Apply the bootstrap algorithm with and without “roughening” along with
the UKF. Discuss processor performances and compare. Zero-mean? White-
ness?
(d) Implement the “optimal” PF processor using the EKF or UKF linearization.
How does its performance compare?
7.10 Consider the bearings-only tracking problem of Example 5.4 given by the
state–space model. The entire system can be represented as an approximate
Gauss–Markov model with the noise sources representing uncertainties in the
states and measurements. The equations of motion given by
x(t) =
⎡
⎢
⎢
⎢
⎢⎣
1
0
ΔT
0
0
1
0
ΔT
0
0
1
0
0
0
0
1
⎤
⎥
⎥
⎥
⎥⎦
x(t −1) +
⎡
⎢
⎢
⎢
⎢⎣
0
0
0
0
1
0
0
1
⎤
⎥
⎥
⎥
⎥⎦
⎡
⎢
⎢
⎢
⎢
⎢⎣
−Δ�ox(t −1)
−Δ�oy(t −1)
⎤
⎥
⎥
⎥
⎥
⎥⎦
+ �(t −1)
with the nonlinear sensor model given by
y(t) = arctanx1(t)
x2(t) + �(t)
for �∼(0, R��) and �∼(0, R��).
(a) Using this model develop the bootstrap PF and UKF processors for this
problem. Assume we would like to estimate the target bearing, frequency
and range (�= 1).
(b) Perform a simulation with the following parameters: an impulse-
incremental step change (Δ�ox = 24 knots and Δ�oy = −10 knots) was ini-
tiated at 0.5 h, resulting in a change of observer position and velocity
depicted in the igure. The simulated bearing measurements are shown in
Fig. 5.8d, The initial conditions for the run were x′(0) := [0 15 nm 20 k −10
k] and R��= diag 10−6 with the measurement noise covariance given by
R��= 3.05 × 10−4 rad2 for ΔT = 0.33 h.
(c) Apply the bootstrap algorithm along with the UKF. Discuss processor per-
formances and compare. Zero-mean? Whiteness?
(d) Implement the “optimal” PF processor using the EKF or UKF linearization.
How does its performance compare?

8
JOINT BAYESIAN
STATE/PARAMETRIC
PROCESSORS
8.1
INTRODUCTION
In this chapter, we develop the Bayesian approach to the parameter estimation/system
identiication problem [1–4] which is based on the decomposition of the joint poste-
rior distributions that incorporates both dynamic state and parameter variables. From
this formulation, the following problems evolve: (1) joint state/parameter estimation;
(2) state estimation; and (3) parameter (ixed and/or dynamic) estimation. The state
estimation problem is thoroughly discussed in the previous chapters. However, the
most common problem found in the current literature is the parameter estimation
problem which can be solved “off-line” using batch approaches (maximum entropy,
maximum likelihood, minimum variance, least squares, etc.) or “on-line” using
the expectation-maximization (EM) technique (see Chapter 2), the stochastic Monte
Carlo approach and for that matter almost any (deterministic) optimization tech-
nique [5, 6]. These on-line approaches follow the classical (EKF), modern (UKF),
and the sequential Monte Carlo or particle ilter (PF). However, it still appears that
there is no universally accepted approach to solving this problem, especially for
ixed parameters [7–9]. From the pragmatic perspective, the most useful problem is
the joint state/parameter estimation problem, since it evolves quite naturally from
the fact that a model is developed to solve the basic state estimation problem and
it is found that its inherent parameters are either poorly speciied, just bounded or
even unknown, inhibiting the development of the processor. We call this problem
the “joint” state/parameter estimation, since both states and parameters are estimated
simultaneously on-line and the resulting processor is termed parametrically adaptive
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
327

328
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
[10]. This terminology evolves because the inherent model parameters are adjusted
sequentially as the measurement data becomes available.
In this chapter, we concentrate primarily on the joint Bayesian state/parameter
estimation problem and refer the interested reader to the wealth of literature available
on this subject [7–19]. First, we precisely deine the three basic problems from
the Bayesian perspective and then investigate the classical, modern and particle
approaches to its solution. We incorporate the nonlinear re-entry problem of Jazwinski
[20] used throughout as an example of parametrically adaptive design and then discuss
a case study to demonstrate the approach.
8.2
BAYESIAN APPROACH TO JOINT STATE/PARAMETER ESTIMATION
To be more precise, we start by deining the joint state/parametric estimation problem.
We begin by formulating the Bayesian recursions in terms of the posterior distribution
using Bayes’ rule for decomposition, that is,
Pr(x(t), �(t)|Yt) = Pr(x(t)|�(t), Yt) × Pr(�(t)|Yt) = Pr(�(t)|x(t), Yt) × Pr(x(t)|Yt)
(8.1)
From this relation, we begin to “see” just how the variety of state and parameter
estimation related problems evolve, that is,
r Optimize the joint state/parameter posterior:
Pr(x(t), �(t)|Yt)
[State/parameter estimation]
r Optimize the state posterior:
Pr(x(t)|Yt)
[State estimation]
r Optimize the parametric posterior:
Pr(�(t)|Yt)
[Parameter estimation]
Now if we proceed with the usual factorizations, we obtain the Bayesian decompo-
sition for the state estimation problem as
Pr(x(t)|Yt) = Pr(y(t)|x(t)) × Pr(x(t)|Yt−1)
Pr(y(t)|Yt−1)
Pr(x(t)|Yt−1) = ∫Pr(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1)dx(t −1)
(8.2)

8.2
BAYESIAN APPROACH TO JOINT STATE/PARAMETER ESTIMATION
329
Equivalently for the parameter estimation problem, we have
Pr(�(t)|Yt) = Pr(y(t)|�(t)) × Pr(�(t)|Yt−1)
Pr(y(t)|Yt−1)
Pr(�(t)|Yt−1) = ∫Pr(�(t)|�(t −1)) × Pr(�(t −1)|Yt−1)d�(t −1)
(8.3)
Now for the joint state/parameter estimation problem of Eq. 8.1, we can substitute
the above equations above to obtain the posterior decomposition of interest, that is,
Pr(x(t), �(t)|Yt) = Pr(x(t)|�(t), Yt) × [Pr(y(t)|�(t)) × Pr(�(t)|Yt−1)]
Pr(y(t)|Yt−1)
(8.4)
or
Pr(x(t), �(t)|Yt) = Pr(x(t)|�(t), Yt) × Pr(y(t)|�(t))
×
∫Pr(�(t)|�(t −1)) × Pr(�(t −1)|Yt−1)d�(t −1)
Pr(y(t)|Yt−1)
(8.5)
This is the most common decomposition found in the literature [7–19] and leads to
the maximization of the irst term with respect to x and the second with respect to �
[21,22].
Alternatively, using the state/parameter estimation form which is rarely applied,
we have
Pr(�(t), x(t)|Yt) = Pr(�(t)|x(t), Yt) × [Pr(y(t)|x(t) × Pr(x(t)|Yt−1)]
Pr(y(t)|Yt−1)
(8.6)
or
Pr(�(t), x(t)|Yt) = Pr(�(t)|x(t), Yt) × Pr(y(t)|x(t))
×
∫Pr(x(t)|x(t −1)) × Pr(x(t −1)|Yt−1)dx(t −1)
Pr(y(t)|Yt−1)
(8.7)
Here, the irst term is maximized with respect to �and the second with respect to x
compared to the previous decomposition.
So we see that Bayes’ rule can be applied in a number of ways to develop the
sequential Bayesian processors for the state, parameter, and joint state/parameter
estimation problems.

330
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
Parameter
estimator
State
estimator
Innovation
Measurement
Innovation
Parameter
State
Parameter
FIGURE 8.1
Nonlinear parametrically adaptive (ABSP): simpliied processor structure
illustrating the coupling between parameter and state estimators through the innovation
and measurement sequences.
8.3
CLASSICAL/MODERN JOINT BAYESIAN STATE/PARAMETRIC
PROCESSORS
In this section, we develop the “joint” state–space Bayesian sequential processor or
equivalently the parametrically adaptive Bayesian signal processor (ABSP) for non-
linear state–space systems. The ABSP is a joint state/parametric processor, since it
estimates both the states as well as the unknown model parameters. It is parametri-
cally adaptive, since it adjusts or “adapts” the model parameters at each time step. The
simpliied structure of the classical (EKF) parameter estimator is shown in Fig. 8.1.
We see the basic structure of the ABSP which consists of two distinct yet coupled pro-
cessors: a parameter estimator and a state estimator. The parameter estimator provides
estimates that are corrected by the corresponding innovations during each recursion.
These estimates are then provided to the state estimator in order to update the model
parameters used in the estimator. After both state and parameter estimates are calcu-
lated, a new measurement is processed and the procedure continues. In general, this
processor can be considered to be a form of identiier, since system identiication is
typically concerned with the estimation of a model and its associated parameters from
noisy measurement data. Usually the model structure is pre-deined (as in our case)
and then a parameter estimator is developed to “it” parameters according to some
error criterion. After completion or during this estimation, the quality of the estimates
must be evaluated to decide if the processor performance is satisfactory or equiva-
lently the model adequately represents the data. There are various types (criteria) of
identiiers employing many different model (usually linear) structures [2–4]. Here
we are primarily concerned with joint estimation in which the models and parameters
are usually nonlinear. Thus, we will concentrate on developing parameter estimators
capable of online operations with nonlinear dynamics.

8.3
CLASSICAL/MODERN JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
331
8.3.1
Classical Joint Bayesian Processor
From our previous discussion in Chapter 5, it is clear that the extended Bayesian
processor XBP (extended Kalman ilter) can satisfy these constraints nicely, so we
begin our analysis of the XBP as a state/parametric estimator closely following
the approach of Ljung [23] for the linear problem discussed in Section 8.2. The
general nonlinear parameter estimator structure can be derived directly from the XBP
algorithm in Table 5.3.
Recall the Bayesian solution to the classical problem was based on solving for
the posterior distribution (see Eq. 8.2) such that each of the required distributions
was represented in terms of the XBP estimates. In the joint state/parameter esti-
mation case, these distributions map simply by deining an augmented state vector
X(t) := [x(t)|�(t)]′ to give
Pr(y(t)|x(t)) ∼(c[x(t)], R��(t))
⇔
Pr(y(t)|x(t), �(t)) ∼(c[x(t), �(t)], R��(t))
Pr(x(t)|Yt−1) ∼(̂x(t|t −1), ̃P(t|t −1))
⇔
Pr(X(t)|Yt−1) ∼( ̂X(t|t −1), ̃(t|t −1))
Pr(y(t)|Yt−1) ∼(̂y(t|t −1), Ree(t))
⇔
Pr(y(t)|Yt−1) ∼(̂y�(t|t −1), ̃Re�e�(t))
(8.8)
where
̂X(t|t −1) := [̂x(t|t −1)| ̂�(t|t −1)]′
̂y�(t|t −1) := c[̂x(t|t −1), ̂�(t|t −1)]
̃(t|t −1) :=
⎡
⎢
⎢⎣
̃Pxx(t|t −1) | ̃Px�(t|t −1)
−
−
−
̃P�x(t|t −1) | ̃P��(t|t −1)
⎤
⎥
⎥⎦
e�e�(t) := C[ ̂X(t|t −1)] ̃(t|t −1)C[ ̂X(t|t −1)]′ + R��(t)
To develop the actual internal structure of the ABSP, we start with the XBP equations,
augment them with the unknown parameters, and then investigate the resulting algo-
rithm. We irst deine the composite state vector (as before) consisting of the original
states x(t) and the unknown “augmented” parameters represented by �(t), that is,
X(t) :=
⎡
⎢
⎢⎣
x(t)
−−−
�(t)
⎤
⎥
⎥⎦
(8.9)

332
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
where t is the time index, X ∈R(Nx+N�)×1 and x ∈RNx×1, �∈RN�×1. Substituting this
augmented state vector into the XBP relations of Table 5.3, the following matrix
partitions evolve as
̃(t|t −1) :=
⎡
⎢
⎢⎣
̃Pxx(t|t −1) | ̃Px�(t|t −1)
−
−
−
̃P�x(t|t −1) | ̃P��(t|t −1)
⎤
⎥
⎥⎦
,
̃P�x(t|t −1) = ̃P′
x�(t|t −1)
(8.10)
where ̃∈R(Nx+N�)×(Nx+N�), ̃Pxx ∈RNx×Nx, ̃P��∈RN�×N�, and ̃Px�∈RNx×N�.
This also leads to the partitioning of the corresponding gain
(t) :=
⎡
⎢
⎢⎣
Kx(t)
−−−
K�(t)
⎤
⎥
⎥⎦
(8.11)
for ∈R(Nx+N�)×Ny, Kx ∈RNx×Ny, and K�∈RN�×Ny.
We must also partition the state and measurement predictions as equations, that
is,1
̂X(t|t −1) =
⎡
⎢
⎢⎣
̂x(t|t −1)
−−−
̂�(t|t −1)
⎤
⎥
⎥⎦
=
⎡
⎢
⎢
⎢⎣
a[̂x(t −1|t −1), ̂�(t −1|t −1)]
+ b[̂x(t −1|t −1), ̂�(t −1|t −1), u(t −1)]
−−−
̂�(t −1|t −1)
⎤
⎥
⎥
⎥⎦
(8.12)
where the corresponding predicted measurement equation becomes
̂y(t|t −1) = c[̂x(t|t −1), ̂�(t|t −1)]
(8.13)
Next we consider the predicted error covariance
̃P(t|t −1) = A[̂x(t|t −1), ̂�(t|t −1)]̃P(t|t −1)A′[̂x(t|t −1), ̂�(t|t −1)] + R��(t −1)
(8.14)
1 Note that we have “implicitly” assumed that the parameters can be considered piecewise constant,
Θ(t) = Θ(t −1) or follow a random walk if we add process noise to this representation in the Gausssense.
However, if we do have process dynamics with linear or nonlinear models characterizing the param-
eters, then they will replace the random walk and the associated Jacobian, etc. will change from this
representation.

8.3
CLASSICAL/MODERN JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
333
which can be written in partitioned form using Eq. 8.10 and the following Jacobian
process matrix2
A[̂x, ̂�] =
⎡
⎢
⎢⎣
Ax[̂x(t|t −1), ̂�(t|t −1)] | A�[̂x(t|t −1), ̂�(t|t −1)]
−
−
−
O
|
IN�
⎤
⎥
⎥⎦
(8.15)
where
Ax[̂x, ̂�] := �a[̂x, ̂�]
�x
+ �b[̂x, ̂�]
�x
A�[̂x, ̂�] := �a[̂x, ̂�]
��
+ �b[̂x, ̂�]
��
(8.16)
with A ∈R(Nx+N�) × (Nx+N�), Ax ∈RNx×Nx, A�∈RNx×N�.
Using these partitions, we can develop the ABSP directly from the XBP processor
in this joint state and “parameter estimation” form. Substituting Eq. 8.15 into the
XBP Prediction Covariance relation of Table 5.3 and using the partition deined in
Eq. 8.10, we obtain (suppressing the ̂x, ̂�, time index t notation for simplicity)
̃(t|t −1)
=
⎡
⎢
⎢⎣
Ax | A�
−−−
0 | IN�
⎤
⎥
⎥⎦
̃(t −1|t −1)
⎡
⎢
⎢⎣
Ax | A�
−−−
0 | IN�
⎤
⎥
⎥⎦
′
+
⎡
⎢
⎢⎣
R�x�x |
0
−
−
−
0
| R����
⎤
⎥
⎥⎦
(8.17)
Expanding these equations, we obtain the following set of predicted covariance
relations
̃(t|t −1)
=
⎡
⎢
⎢⎣
Ax ̃PxxA′
x + A�̃P�xA′
x + Ax ̃Px�A′
�+ A�̃P��A′
�+ R�x�x | Ax ̃Px�+ A�̃P��
−−−
−
−−−
̃P�xA′
x + ̃P��A′
�
|
̃P��+ R����
⎤
⎥
⎥⎦
(8.18)
The innovations covariance follows from the XBP as
Ree(t) = C[̂x, ̂�] ̃(t|t −1)C′[̂x, ̂�] + R��(t)
(8.19)
Now we must use the partitions of ̃above along with the measurement Jacobian
C[̂x, ̂�] = [Cx[̂x(t|t −1), ̂�(t|t −1)]|C�[̂x(t|t −1), ̂�(t|t −1)]]
(8.20)
2 Here is where the underlying random walk model enters the structure. The lower-block rows of Ax could
be replaced by [A�x[̂x, ̂�]|A��[̂x, ̂�]] which enables a linear or nonlinear dynamic model to be embedded
directly.

334
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
where
Cx[̂x, ̂�] := �c[̂x, ̂�]
�x
C�[̂x, ̂�] := �c[̂x, ̂�]
��
(8.21)
with C ∈RNy×(Nx+N�), Cx ∈RNy×Nx, C�∈RNy×N�.
The corresponding innovations covariance follows from Eqs. 8.19 and 8.20 as
Ree(t) = [Cx|C�]
⎡
⎢
⎢⎣
̃Pxx | ̃Px�
−−−
̃P�x | ̃P��
⎤
⎥
⎥⎦
⎡
⎢
⎢⎣
C′
x
−−−
C′
�
⎤
⎥
⎥⎦
+ R��(t)
(8.22)
or expanding
Ree(t) = Cx ̃PxxC′
x + C�̃P�xC′
x + Cx ̃Px�C′
�+ C�̃P��C′
�+ R��
(8.23)
Ree ∈RNy×Ny. The gain of the XBP in Table 5.3 is calculated from these partitioned
expressions as
(t) =
⎡
⎢
⎢⎣
Kx(t)
−−−
K�(t)
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣
̃Pxx | ̃Px�
−−−
̃P�x | ̃P��
⎤
⎥
⎥⎦
⎡
⎢
⎢⎣
Cx
−−−
C�
⎤
⎥
⎥⎦
′
R−1
ee (t)
(8.24)
or
(t) =
⎡
⎢
⎢⎣
Kx(t)
−−−
K�(t)
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣
(̃PxxC′
x + ̃Px�C′
�)R−1
ee (t)
−−−
(̃P�xC′
x + ̃P��C′
�)R−1
ee (t)
⎤
⎥
⎥⎦
(8.25)
where K ∈(Nx+N�)×Ny, Kx ∈RNx×Ny, K�∈RN�×Ny. With the gain determined, the
corrected state/parameter estimates follow easily, since the innovations remain
unchanged, that is,
e(t) = y(t) −̂y(t|t −1) = y(t) −c[̂x(t|t −1), ̂�(t|t −1)]
(8.26)
and therefore partitioning the corrected state equations, we have
̂X(t|t) =
⎡
⎢
⎢⎣
̂x(t|t)
−−−
̂�(t|t)
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣
̂x(t|t −1)
−−−
̂�(t|t −1)
⎤
⎥
⎥⎦
+
⎡
⎢
⎢⎣
Kx(t)e(t)
−−−
K�(t)e(t)
⎤
⎥
⎥⎦
(8.27)

8.3
CLASSICAL/MODERN JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
335
Finally, the corrected covariance expression is easily derived from the following
partitions
̃(t|t) =
⎡
⎢
⎢⎣
̃Pxx | ̃Px�
−−−
̃P�x | ̃P��
⎤
⎥
⎥⎦
−
⎡
⎢
⎢⎣
Kx(t)
−−−
K�(t)
⎤
⎥
⎥⎦
[Cx|C�]
⎡
⎢
⎢⎣
̃Pxx | ̃Px�
−−−
̃P�x | ̃P��
⎤
⎥
⎥⎦
(8.28)
Performing the indicated multiplications leads to the inal expression
̃(t|t) =
⎡
⎢
⎢⎣
̃Pxx −KxCx ̃Pxx −KxC�̃P�x
|
̃Px�−KxCx ̃Px�−KxC�̃P��
−−−
−−−
−−−
̃P�x −K�Cx ̃Pxx −K�C�̃P�x
|
̃P��−K�Cx ̃Px�−K�C�̃P��
⎤
⎥
⎥⎦
(8.29)
We summarize the parametrically adaptive model-based processor in predictor-
corrector form in Table 8.1. We note that this algorithm is not implemented in
this fashion, it is implemented in the numerically stable, “upper triangular-diagonal”
or UD-factorized form as in SSPACK_PC [10]. Here we are just interested in the
overall internal structure of the algorithm and the decomposition that evolves. This
completes the development of the generic ABSP.
It is important to realize that, besides its numerical implementation, the ABSP
is simply the XBP with an augmented state vector thereby implicitly creating the
partitions developed above. The implementation of these decomposed equations
directly is not necessary—just augment the state with the unknown parameters and
the ABSP evolves naturally from the standard XBP algorithm of Table 5.3. The ABSP
of Table 8.1 indicates where to locate the partitions. That is, suppose we would like
to extract the submatrix ̃P��but the XBP only provides the overall (Nx + N�) error
covariance matrix ̃P. However, locating the lower N�× N�submatrix of ̃P enables us
to extract ̃P��directly.
Next, let us reconsider the nonlinear system example given in Chapter 5 and
investigate the performance of the parametrically adaptive Bayesian processor.
Example 8.1
Recall the discrete nonlinear trajectory estimation problem [20] of Chapter 5 given
by
x(t) = (1 −0.05△T)x(t −1) + 0.04x2(t −1) + �(t −1)
with corresponding measurement model
y(t) = x2(t) + x3(t) + �(t)
where �(t) ∼(0, 0.09), x(0) = 2.0, P(0) = 0.01, △T = 0.01 sec, and R��= 0.

336
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
TABLE 8.1
ABSP Algorithm
Predictor/Corrector Form
Prediction
̂x(t|t −1) = a[̂x(t|t −1), ̂�(t −1|t −1)] + b[u(t −1)]
(state)
̂�(t|t −1) = ̂�(t −1|t −1)
(parameter)
̃Pxx(t|t −1) = Ax[̂x, ̂�]̃Pxx(t −1|t −1)A′
x[̂x, ̂�] + A�[̂x, ̂�, u]̃P�x(t −1|t −1)A′
x[̂x, ̂�]
+ Ax[̂x, ̂�]̃Px�(t −1|t −1)A′
�[̂x, ̂�, u] + A�[̂x, ̂�]̃P��(t −1|t −1)A′
�[̂x, ̂�, u] + R�x�x(t −1)
(state cov.)
̃P��(t|t −1) = ̃P��(t −1|t −1) + R����(t −1)
(param. cov.)
̃Px�(t|t −1) = Ax[̂x, ̂�]̃Px�(t −1|t −1) + A�[̂x, ̂�, u]̃P��(t −1|t −1)
(cross cov.)
Innovation
e(t) = y(t) −̂y(t|t −1) = y(t) −c[̂x(t|t −1), ̂�(t|t −1)]
(innovation)
Ree(t) = Cx[̂x, ̂�]̃Pxx(t|t −1)C′
x[̂x, ̂�]+ C�[̂x, ̂�, u]̃P�x(t|t −1)C′
x[̂x, ̂�]
+ Cx[̂x, ̂�]̃Px�(t|t −1)C′
�[̂x, ̂�, u] + C�[̂x, ̂�, u]̃P��(t|t −1)C′
�[̂x, ̂�, u] + R��(t)
(innovation covariance)
Gain
Kx(t) = (̃Pxx(t|t −1)C′
x[̂x, ̂�] + ̃Px�(t|t −1)C′
�[̂x, ̂�, u])R−1
ee (t)
(state gain)
K�(t) = (̃P�x(t|t −1)C′
x[̂x, ̂�] + ̃P��(t|t −1)C′
�[̂x, ̂�, u])R−1
ee (t)
(parameter gain)
Correction
̂x(t|t) = ̂x(t|t −1) + Kx(t)e(t)
(state)
̂�(t|t) = ̂�(t|t −1) + K�(t)e(t)
(parameter)
̃Pxx(t|t) = ̃Pxx(t|t −1) −Kx(t)Cx[̂x, ̂�]̃Pxx(t|t −1) −Kx(t)C�[̂x, ̂�, u]̃P�x(t|t −1)
(state covariance)
̃P��(t|t) = ̃P��(t|t −1) −K�(t)C�[̂x, ̂�, u]̃Px�(t|t −1) −K�(t)C�[̂x, ̂�, u]̃P��(t|t −1)
(parameter covariance)
̃Px�(t|t) = ̃Px�(t|t −1) −Kx(t)Cx[̂x, ̂�]̃Px�(t|t −1) −Kx(t)C�[̂x, ̂�, u]̃P��(t|t −1)
(cross covariance)
Initial Conditions
̂x(0|0)
̃P(0|0)
A[̂x, �] :=
�
�xA[x, �]
|||| x = ̂x(t|t −1)
�= ̂�(t|t −1)
C[̂x, �] :=
�
�xC[x, �]
|||| x = ̂x(t|t −1)
�= ̂�(t|t −1)
Here we generalize the problem to the case where the coeficients of the process
are unknown leading to the ABSP solution. Therefore, the process equations for this
problem become
x(t) = (1 −�1△T)x(t −1) + �2x2(t −1) + �(t −1)
with the identical measurement and covariances as before. The true parameters are
Θtrue = [0.05 0.04]′. The ABSP can be applied to this problem by deining the param-
eter vector as
Θ(t) = Θ(t −1)
(constant)

8.3
CLASSICAL/MODERN JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
337
and augmenting it to form the new state vector X = [x′ �1 �2]′ with the new process
noise vector w = [���1 ��2]′. Therefore the process model becomes
X(t) =
⎡
⎢
⎢⎣
(1 −�1(t −1)△T)x(t −1) + �2(t −1)△Tx2(t −1)
�1(t −1)
�2(t −1)
⎤
⎥
⎥⎦
+ w(t −1)
y(t) = x2(t) + x3(t) + �(t)
To implement the ABSP the required Jacobians are
A[X(t −1)]
=
⎡
⎢
⎢
⎢⎣
[1 −�1(t −1)△T + 2△T�2(t −1)x(t −1)]
△T)x(t −1)
△Tx2(t −1)
0
1
0
0
0
1
⎤
⎥
⎥
⎥⎦
C[X(t −1)] = [2x(t −1) + 3x2(t −1)
0
0]
Using SSPACK_PC [10] the ABSP is applied to solve this problem for 1500 samples
with △T = 0.01 sec. Initially, we used the starting parameters
̃P(0|0) = diag[100 100 100]
and
̂x(0|0) = [2 0.055 0.044]′
The results of the ABSP run are shown in Fig. 8.2. We see the estimated state and
parameter estimates in Fig. 8.2b and Fig. 8.2c. After a short transient (25 samples),
the state estimate begins tracking the true state as evidenced by the innovations
sequence in Fig. 8.2c. The parameter estimates slowly converge to their true values
as evidenced by the plots. The inal estimates are
̂�1 = 0.0470
̂�2 = 0.0395
Part of the problem for the slow convergence results stems from the lack of sensitivity
of the measurement, or equivalently, innovations to parameter variations in this
problem. This is implied from the zero-mean/whiteness tests shown in Fig. 8.2c.
The innovations are statistically white (3.6% out), and zero-mean (0.008 < 0.061).
The iltered measurement is also shown in Fig. 8.2c as well. This completes the ABSP
example.
△△△
As pointed out by Ljung [1, 2, 23], it is important to realize that the XBP is
suboptimal as a parameter estimator as compared to the recursive prediction error
(RPE) method based on the Gauss–Newton (stochastic) descent algorithm. Compar-
ing the processors in this context, we see that if a gradient term [∇�K(Θ)] e(t) is
incorporated into the XBP (add this term to A�), its convergence will be improved

338
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
−0.02
−0.01
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
−1
−0.5
0
0.5
1
1.5
0
5
10
15
1.5
2
2.5
3
3.5
4
4.5
5
5.5
6
6.5
MeanX
DataX
EKF
MeanX
DataX
EKF
DataX
EKF
0
(a)
(b)
(c)
5
10
15
−0.02
0
0.02
0.04
θ
0.06
0.08
0.1
0.12
0.14
Time (sec)
Time (sec)
0
5
10
15
Time (sec)
0
5
10
15
Time (sec)
0
5
10
15
Time (sec)
0
50
100
150
200
250
300
0
1
2
3
4
5
6
7
8
9
10
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Lags
ˆx
1ˆ
θ2ˆ
e
ˆy
Zero mean/whiteness-test
(Mean = 0.0081 < 0.0612) 
Percent out = 3.61%
MeanX
DataX
EKF
ee
ˆR
FIGURE 8.2
XBP (EKF) simulation. (a) estimated state and parameter no. 1; (b)
estimated parameter no. 2 and innovation; (c) predicted measurement and zero-
mean/whiteness test (0.008 < 0.061 and 3.6% out).
approaching the performance of the RPE algorithm (see Ljung [23] for details). We
also note in passing that the nonlinear BSP in the form developed in Chapter 5 as well
as the parametrically adaptive ABSP are all heavily employed as neural networks.
For more details of this important application, see Haykin [18]. Next, we consider
the development of the “modern” approach to Bayesian processor design using the
unscented Bayesian processor of Chapter 6.
8.3.2
Modern Joint Bayesian Processor
The modern unscented processor offers a similar representation as the extended
processor detailed in the previous subsection. Here, we briely outline its structure
for solution to the joint problem and apply it to the trajectory estimation problem
for comparison. We again start with the augmented state vector deined initially by

8.3
CLASSICAL/MODERN JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
339
sigma-points, that is,
(t) :=
⎡
⎢
⎢⎣
x(t)
−−−
�(t)
⎤
⎥
⎥⎦
(8.30)
∈R(Nx+N�)×1 and x ∈RNx×1, �∈RN�×1. Substituting this augmented state vector
into the SPBP relations of Table 6.1 yields the desired processor. We again draw the
equivalences (as before):
Pr(y(t)|x(t), �(t)) ∼(c[x(t), �(t)], R��(t))
Pr((t)|Yt−1) ∼((t|t −1), ̃(t|t −1))
(8.31)
Pr(y(t)|Yt−1) ∼(̂y�(t|t −1), ̃Re�e�(t))
where
(t|t −1) := [̂x(t|t −1)| ̂�(t|t −1)]′
̂y�(t|t −1) := c[̂x(t|t −1), ̂�(t|t −1)]
̃(t|t −1) :=
⎡
⎢
⎢⎣
̃Pxx(t|t −1) | ̃Px�(t|t −1)
−
−
−
̃P�x(t|t −1) | ̃P��(t|t −1)
⎤
⎥
⎥⎦
e�e�(t) := C[ ̂X(t|t −1)] ̃(t|t −1)C[ ̂X(t|t −1)]′ + R��(t)
With this in mind, it is possible to derive the internal structure of the SPBP in a
manner similar to that of the XBP. But we will not pursue that derivation here. We
just note that the sigma points are also augmented to give
i :=
⎡
⎢
⎢⎣
̂x(t|t −1)
−−−
̂�(t|t −1)
⎤
⎥
⎥⎦
+
⎛
⎜
⎜⎝
(N+ �)
⎡
⎢
⎢⎣
̃Pxx(t|t −1) | ̃Px�(t|t −1)
−
−
−
̃P�x(t|t −1) | ̃P��(t|t −1)
⎤
⎥
⎥⎦
⎞
⎟
⎟⎠
1
2
(8.32)
with the corresponding process noise covariance partitioned as
��(t −1) :=
⎡
⎢
⎢⎣
R�x�x(t −1) |
0
−
−
−
0
| R����(t −1)
⎤
⎥
⎥⎦
(8.33)
It also follows that the prediction step becomes
i(t|t −1) =
⎡
⎢
⎢⎣
a[̂x(t|t −1), ̂�(t|t −1)] + b[ ̂�(t|t −1), u(t −1)]
−−−
a[ ̂�(t|t −1)]
⎤
⎥
⎥⎦
(8.34)

340
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
and in the multichannel (vector) measurement case, we have
i(t|t −1) =
⎡
⎢
⎢⎣
c[̂x(t|t −1), ̂�(t|t −1)]
−−−
c[ ̂�(t|t −1)]
⎤
⎥
⎥⎦
(8.35)
Using the augmented state vector, we apply the “joint” approach to the trajectory
estimation problem [20] and compare its performance to that of the XBP.
Example 8.2
Using the discrete nonlinear trajectory estimation problem of the previous example
with unknown coeficients as before, we deine the augmented sigma-point vector
(t) deined above and apply the SPBP algorithm of Table 6.1.
The process equations for this problem are
x(t) = (1 −�1△T)x(t −1) + �2x2(t −1) + �(t −1)
with the identical measurement and covariances as before. The true parameters are
Θtrue = [0.05 0.04]′. The SPBP can be applied to this problem by deining the param-
eter vector as a constant and augmenting it to form the new sigma-point vector
= [x′
�1
�2]′ with the new process noise vector w = [���1��2]′. Therefore
the process model becomes
⎡
⎢
⎢⎣
x(t)
−−
�(t)
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣
(1 −�1(t −1)△T)x(t −1) + �2(t −1)△Tx2(t −1)
�1(t −1)
�2(t −1)
⎤
⎥
⎥⎦
+ w(t −1)
y(t) = x2(t) + x3(t) + �(t)
To implement the SPBP the sigma points are selected as before for a Gaussian
distribution using the scaled transformation with �= 1, �= 0, and �= 2, using the
same initial conditions as the XBP.
Using MATLAB [10], the ABSP is applied to solve this problem for 1500 sam-
ples with △T = 0.01 sec. The results of the SPBP run are shown in Fig. 8.3. We
see the estimated state and parameter estimates in Fig. 8.3a and Fig. 8.3b. After a
short transient, the state estimate begins tracking the true state as evidenced by the
predicted measurement and innovations sequence in Fig. 8.3c. The parameter esti-
mates converge to their true values as evidenced by the plots. The inal estimates are:
̂�1 = 0.05; ̂�2 = 0.04. The processor appears to converge much faster than the XBP
demonstrating its improved capability. This is implied from the zero-mean/whiteness
tests shown in Fig. 8.3c. The innovations are statistically white (1.86% out) and
zero-mean (0.0113 < 0.0612). The iltered measurement is also shown in Fig. 8.3c as
well. This completes the ABSP example.
△△△

8.4
PARTICLE-BASED JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
341
0
5
10
15
0
1
2
3
4
5
6
7
−1.4
−1.2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
MeanX
DataX
UKF
DataX
UKF
MeanX
DataX
UKF
MeanX
DataX
UKF
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
(a)
(b)
(c)
0
50
100
150
200
250
300
0
1
2
3
4
5
6
7
8
9
10
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Zero mean/whiteness-test
(Mean = 0.0113 < 0.0612)
Percent out = 1.86% 
Lags
ˆx
ˆ
e
ˆy
ˆRee
Time (sec)
0
5
10
15
Time (sec)
0
5
10
15
Time (sec)
0
5
10
15
Time (sec)
0
5
10
15
Time (sec)
θ2
ˆθ1
FIGURE 8.3
SPBP (UKF) simulation: (a) estimated state and parameter no. 1; (b)
estimated parameter no. 2 and innovation; (c) predicted measurement and zero-
mean/whiteness test (0.0113 < 0.0612 and 1.86% out).
We also note in closing that a “dual” rather than “joint” approach has evolved in
the literature. Originally developed as a bootstrap approach, it is constructed by two
individual (decoupled) processors: one for the state estimator and the other for the
parameter estimator which pass updated estimates back and forth to one another as
they become available. This is a suboptimal methodology, but appears to perform
quite well (see Refs. [21] and [22] for more details). This completes our discussion
of the joint modern approach; next, we investigate the SMC approach to solving the
joint problem.
8.4
PARTICLE-BASED JOINT BAYESIAN STATE/PARAMETRIC
PROCESSORS
In this section, we briely develop the sequential Monte Carlo approach to solving the
joint state/parametric processing problem. There are a variety of ways to search the
feasible space in pursuing solutions to the parameter estimation problem, but when

342
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
states (or signals) must be extracted along with the parameters, then a solution to
the joint estimation problem must follow as discussed before [24–30]. One of the
major problems that evolves is how to “model” the parameter evolution in order to
provide an effective way to proceed with the search, especially if there does not exist
a physical model characterizing the parameters.
8.4.1
Parametric Models
Perhaps the most popular approach to this quandary is to use the so-called “random
walk” model that has evolved from the control/estimation area. This model essentially
assumes a constant parameter (vector) �with slight variations. In continuous-time a
constant can be modeled by the differential equation
d�t
dt = 0
for
�0 = constant
(8.36)
Here, the solution is just �0 ∀t. Note that this differential equation is essentially a state–
space formulation in �enabling us to incorporate it directly into the overall dynamic
model. Now if we artiicially assign a zero-mean Gaussian process noise term wt to
excite the model, then a random walk (pseudo dynamic) model evolves. Providing
a small variance to the noise source approximates small variations in the parameter
enabling it to “walk” in the underlying parameter space and converge (hopefully) to
the true value. Since we typically concentrate on a sampled-data systems, we can
discretize this representation using irst differences (with △t = 1) and incorporate its
corresponding mean/covariance propagation into our Gauss–Markov model, that is,
�(t) = �(t −1) + w�(t −1)
for
w�∼(0, R����)
m�(t) = m�(t −1)
P��(t) = P��(t −1) + R����(t −1)
(8.37)
The process noise covariance R����controls the excursions of the random walk or
equivalently the parameter space. Using artiicial dynamics is the identical approach
employed in both the classical (XBP) and modern (UBSP) techniques used in the
previous sections. The only problem results when the parameter is truly static such
as in inancial models and its variations can have very large repercussions in the
money and economic markets. Thus, a large variety of “off-line” MC methods have
evolved [17], but we will not discuss them here since we are primarily interested in
physical systems which typically have parametric uncertainties that are well-modeled
by the random walk or other variations. Of course, if the parametric relations are truly
dynamic, then the joint approach incorporates these dynamics into the augmented
state–space model and yields an optimal iltering solution to this joint problem.
A popular variation of the random walk is based on the “forgetting factor” that
has evolved from the system identiication literature [1] and is so-called because

8.4
PARTICLE-BASED JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
343
it controls the time constant of an exponential window over the data. To see this,
consider a squared-error performance function deined by
=
k
∑
t=1
�(t, k)�2(t)
for
�(t, k) = �k−t
0 < �< 1
(8.38)
where the weighting function �is the forgetting factor that creates an exponentially
decaying window of length, say T�, in which the most recent data is weighted more
than the past data. This follows from the following approximation [1, 2]:
�(t, k) = e(t−k) ln �≈e−(t−k)(1−�)
for
T�=
1
1 −�
(8.39)
where T�is called the memory time constant that remains constant (approximately)
over T�samples with typical choices between 0.98 < T�< 0.995 in practice.
The forgetting factor has been introduced into a variety of sequential algorithms
in different roles. For instance, a direct implementation into the random walk model
of Eq. 8.37 [31] is
�(t) = (1 −�(t))�(t −1) + �(t)w�(t −1)
(8.40)
here �affects the tracking speed of the updates providing a tradeoff between speed
and noise attenuation. Setting �= 1 implies T�→∞, an “ininite memory,” while
�= 0 provides instantaneous response forgetting the entire past.
Thus, the forgetting factor introduces a certain amount of lexibility into the joint
state/parameter estimation processors by enabling them to be more responsive to new
data and therefore yielding improved signal estimates. The same affect is afforded by
the process noise covariance matrix of Eq. 8.37 using an equivalent technique called
“annealing.” The covariance matrix, usually assumed diagonal, is annealed towards
zero using exponentially (decay) weighting (see Refs. [21] and [22] for more details).
Other variations of the parameter estimation models exist besides the statistical
random walk model. For instance, similar to the random walk is a process called
roughening which is very similar in concept and is another simple pragmatic method
of preventing the sample impoverishment problem. It is a method suggested by
Gordon [15, 17] and reined in Refs. [18] and [10], termed particle “roughening”
which is similar to adding process noise to constant parameters when constructing
a random-walk GM model. It is useful in estimating embedded state–space model
parameters and can also be applied to the joint state/parameter estimation problem.
Roughening consists of adding random noise to each particle after resampling is
accomplished, that is, the a posteriori particles are modiied as
̃xi(t) = ̂xi(t) + �i(t)
(8.41)

344
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
where �i ∼(0, diag[�nN−1∕Nx
p
]) and �is a constant “tuning” parameter (e.g.,
∼0.2), n is a vector of the maximum difference between particle components before
roughening, the nth element of given by
n = max
ij
|||x(n)
i (t) −x(n)
j (t)|||
for
n = 1, … , Nx
(8.42)
8.4.2
Joint Bayesian State/Parameter Estimation
Here we are concerned with the joint estimation problem consisting of setting a
prior for �and augmenting the state vector to solve the joint estimation problem as
deined in Section 8.2 thereby converting the parameter estimation problem to one
of optimal iltering. Thus, conining our discussion to state–space models and the
Bayesian equivalence, we develop the Bayesian approach using the relations
x ∼x (x(t)|x(t −1), �(t −1))
�∼�(�(t)|�(t −1), x(t −1))
(8.43)
y ∼(y(t)|x(t), �(t))
Here we separate the state transition function into the individual vectors for illustrative
purposes, but in reality (as we shall observe), they can be jointly coupled. The key
idea is to develop the PF technique to estimate the joint posterior Pr(x(t), �(t)|Yt)
relying on the parametric posterior Pr(�(t)|Yt) in the Bayesian decomposition. We
will follow the approach outlined in Refs. [17], [32] and [33] starting with the full
posterior distributions and proceeding to the iltering distributions.
Suppose it is possible to sample Np-particles, {Xt(i), Θt(i)} for i = 1, … , Np
from the joint posterior distribution where we deine Xt := {x(0), … , x(t)} and
Θt := {�(0), … , �(t)}. Then the corresponding empirical approximation of the joint
posterior is given by [34]
̂Pr(Xt, Θt|Yt) ≈1
Np
Np
∑
i=1
�(Xt −Xt(i), Θt −Θt(i))
(8.44)
and it follows directly that the iltering posterior (see Chapter 2) is given by
̂Pr(x(t), �(t)|Yt) ≈1
Np
Np
∑
i=1
�(x(t) −xi(t), �(t) −�i(t))
(8.45)
Unfortunately, it is not possible to sample directly from the full joint posterior
Pr(Xt, Θt|Yt) at any time t. However, one approach to mitigate this problem is by
using the importance sampling approach of Chapter 2.

8.4
PARTICLE-BASED JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
345
Suppose we deine a (full) importance distribution, q(Xt, Θt|Yt) such that
Pr(Xt, Θt|Yt) > 0 implies q(⋅) > 0, then we deine the corresponding importance weight
(as before) by
W(Xt, Θt) ∝Pr(Xt, Θt|Yt)
q(Xt, Θt|Yt)
(8.46)
From Bayes’ rule we have that the posterior can be expressed as
Pr(Xt, Θt|Yt) = Pr(Yt|Xt, Θt) × Pr(Xt, Θt)
Pr(Yt)
(8.47)
Thus, if Np-particles, {Xt(i), Θt(i)}; i = 1, … , Np, can be generated from the impor-
tance distribution
{Xt(i), Θt(i)} →q(Xt, Θt|Yt)
(8.48)
then the empirical distribution can be estimated and the resulting normalized weights
speciied by
t(i) =
W(Xt(i), Θt(i))
∑Np
k=1 W(Xt(k), Θt(k))
for i = 1, … , Np
(8.49)
to give the desired empirical distribution of Eq. 8.44 leading to the corresponding
iltering distribution of Eq. 8.45.
If we have a state transition model available, then for a ixed parameter estimate
the state estimation problem is easily solved as before in Chapter 7. Therefore, we
will conine our discussion to the parameter posterior distribution estimation problem,
that is, marginalizing the joint distribution with respect to the states (that have already
been estimated) gives
Pr(Θt|Yt) = ∫Pr(Xt, Θt|Yy)dXt
(8.50)
and it follows that
(Θt) ∝Pr(Θt|Yt)
q(Θt|Yt)
(8.51)
Assuming that a set of particles can be generated from the importance distribution as
Θt ∼q(Θt|Yt), we have the set of normalized weights
t(Θ(i)) =
W(Θt(i))
∑Np
k=1 W(Θt(k))
for i = 1, … , Np
(8.52)

346
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
which is the joint “batch” importance sampling solution when coupled with the
dynamic state vectors.
The sequential form of this joint formulation follows directly (as before in Chapter
2). We start with the factored form of the importance distribution and focus on the
full posterior Pr(Θt|Yt), that is,
q(Θt|Yt) =
t∏
k=0
q(�(k)|Θk−1, Yk)
(8.53)
with Pr(�(0)|Θ−1, Yt) →Pr(�(0)|Yt).
Assuming that this factorization can be expressed recursively in terms of the
previous step q(Θt−1|Yt−1) and extracting the tth term gives
q(Θt|Yt) = q(�(t)|Θt−1, Yt) ×
t−1
∏
k=0
q(�(k)|Θk−1, Yk)
(8.54)
or simply
q(Θt|Yt) = q(�(t)|Θt−1, Yt) × q(Θt−1|Yt−1)
(8.55)
With this in mind, the weight recursion becomes
W(Θt) = W(t) × W(Θt−1)
(8.56)
Applying Bayes’ rule to the posterior, we deine
W(t) := Pr(y(t)|Θt, Yt−1) × Pr(�(t)|Θ(t −1))
Pr(y(t)|Yt−1) × q(�(t)|Θt−1, Yt)
∝Pr(y(t)|Θt, Yt−1) × Pr(�(t)|�(t −1))
q(�(t)|Θt−1, Yt)
(8.57)
As before in the state estimation problem, we must choose an importance
distribution before we can construct the algorithm. We can choose from
the minimum variance (optimal) using local linearization techniques given by
q(�(t)|Θt−1, Yt) →Pr(�(t)|Θt−1, Yt) which leads to the transition posterior
Pr(�(t)|Θt−1, Yt) = Pr(y(t)|Θt−1, Yt−1) × Pr(�(t)|�(t −1))
Pr(y(t)|Θt−1, Yt−1)
(8.58)

8.4
PARTICLE-BASED JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
347
and therefore it follows using Eq. 8.57 that
WMV(t) ∝Pr(y(t)|Θt−1, Yt−1) = ∫Pr(y(t)|Θt, Yt−1) × Pr(�(t)|�(t −1)) d�(t)
(8.59)
with (local linearization implementation of Chapter 7)
Pr(y(t)|Θt, Yt−1) ∼(̂y�(t|t −1), R����)
which can be obtained from any of the classical or modern techniques (Chapters 5
and 6).
The usual bootstrap approach can also be selected as the importance distribu-
tion leading to a simpler alternative with q(�(t)|Θt−1, Yt) →Pr(�(t)|�(t −1)) and the
weight of Eq. 8.57 becomes
WBS(t) = Pr(y(t)|Θt, Yt−1)
(8.60)
From the pragmatic perspective, we must consider some practical approaches to
implementing the processor for the joint problem. The irst approach, when appli-
cable, (not inancial problems) is to incorporate the random walk model of Eq. 8.37
when reasonable [17]. We will use this approach for our case study to follow. Another
variant is to use the “roughening” method that moves the particles (after resampling)
by adding a Gaussian sequence of speciied variance.3
The kernel method (regularized PF of Chapter 7) can also be applied to the joint
problem. In the bootstrap implementation, we can estimate the posterior distribution
using the kernel density approach, that is, after resampling we have the empirical
distribution given by
̂Pr(�(t)|Yt) = 1
Np
Np
∑
i=1
�(�(t) −̂�i(t))
(8.61)
The kernel technique consists of substituting for this degenerate distribution, the
kernel density estimate
̂Pr(�(t)|Yt) = 1
Np
Np
∑
i=1
(�(t) −̂�i(t))
(8.62)
for (⋅) the kernel (e.g., Gaussian, triangle, etc.). Now a new set of parametric
particles can be obtained by generating samples from �i(t) ∼(�(t)). In the same
3 Recall that the sequence is distributed �∼(0, �ijN−1∕Nx
p
) for �a constant and ij is the maximum
distance between the ith and jth particles discussed previously of Section 7.5.

348
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
manner as the standard bootstrap, this approach introduces diversity into the set of
particles.
Yet another alternative is to introduce the MCMC-step (see Chapter 7) to “move”
the particles to the regions of high probability using a Markov chain with appropriate
invariant distribution. Again the new particles are sampled according to an MCMC
with joint distribution (when possible) Pr(Xt(i), Θt(i)|Yt) such that
(Xt(i), Θt(i)) ∼MCMC(Xt, Θt|Yt)
This completes the discussion of the joint state/parameter estimation problem using
the PF approach; we emphasize that the algorithm of Chapter 7 may be used by merely
augmenting the state vector with the parameter vector especially when a dynamic
equation characterizing the parameter dynamics is available. Next, we consider an
example to illustrate this approach.
Example 8.3
Again, we consider the trajectory estimation problem [20] using the particle il-
ter technique. At irst, we applied the usual bootstrap technique and found what
was expected, a collapse of the parameter particles giving an unsatisfactory result.
Next, we tried the “roughening” approach and the results were much more rea-
sonable. We used a roughening factor or �= 5 × 10−5 along with Np = 350. The
results are shown in Fig. 8.4. We see both the estimated states and measurement
along with the associated zero-mean/whiteness test. The result, although not as good
as the modern approach, is reasonable with the inal estimates converging to the
static parameter values of true parameters: �1 = 0.05(0.034) and �2 = 0.04(0.039).
The state and measurement estimates are quite good as evidenced by the zero-
mean (0.002 < 0.061) and whiteness (1.76% out). We show the estimated posterior
distributions for the states and parameters in Fig. 8.5 again demonstrating a rea-
sonable solution. Note how the distributions are initially multi-modal and become
unimodal as the parameter estimates converge to their true values as depicted in
Fig. 8.5.
Next, we generate an ensemble consisting of a set of a 100-member realizations,
execute the PF and obtain the ensemble estimates shown in Fig. 8.6. In Fig. 8.6a, we
see the ensemble state estimate and in (b) and (c) the corresponding joint parameter
estimates. Comparing these to those of Fig. 8.4, we see that after the initial transients
die out, they converge to reasonable estimates for both the state and parameters.
The ensemble processor gives reasonable zero-mean/whiteness (sanity) test results:
(Z-M: 0.023 < 0.123/W-Test: 1.2% out) along with relative root mean-squared errors
(RMSE: state = 0.0010; parameter no. 1 = 0.0013; and parameter no. 2 = 0.0010).
The corresponding median Kullback–Leibler divergence/Hellinger distance statistics
are KL/HD: state = 0.024∕0.077; parameter no. 1 = 1.794∕0.629; parameter no.
2 = 2.201∕0.642, and measurement = 0.025∕0.079. These metrics also indicate a

8.5
CASE STUDY
349
0
5
10
15
1.5
2
2.5
3
3.5
4
4.5
5
5.5
6
6.5
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
Time (sec)
0
5
10
15
Time (sec)
0
5
10
15
Time (sec)
0
5
10
15
Time (sec)
0
5
10
15
Time (sec)
0.02
0.03
0.04
0.05
0.06
0.07
0.08
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
0
50
100
150
200
250
300
0
1
2
3
4
5
6
7
8
9
10
−0.2
0
0.2
0.4
0.6
0.8
Lags
Zero mean/whiteness-test
(Mean = 0.0023 < 0.0612)
Percent out = 1.76%
(c)
(b)
(a)
ˆx
ˆ
e
ˆy
ˆRee
θ1
θ2ˆ
MeanX
DataX
PF
MeanX
DataX
PF
MeanX
DataX
PF
DataY
PF
FIGURE 8.4
PF simulation: (a) estimated state and parameter no. 1; (b) estimated
parameter no.2 and innovation;(c) predicted measurement and zero-mean/whiteness
test (0.002 < 0.061 and 1.76% out).
reasonable performance for both the state and measurement estimates and a mediocre
performance at best for the parameter estimates.
△△△
8.5
CASE STUDY: RANDOM TARGET TRACKING USING A SYNTHETIC
APERTURE TOWED ARRAY
Synthetic aperture processing is well-known in airborne radar, but not as familiar
in sonar [35–40]. The underlying idea in creating a synthetic aperture is to increase
the array length by motion, thereby increasing spatial resolution (bearing) and gain
in SNR. It has been shown that for stationary targets, the motion-induced bearing
estimates have smaller variance than that of a stationary array [38, 41]. Here we
investigate the case of both array and target motion. We deine the acoustic array
space–time processing problem as:

0.06
0.05
0.04
Probability
Probability
Probability
0.03
0.02
0.01
0
15
10
5
0
3.928
3.93
3.932
3.934
X-update sample no.
3.936
3.938
3.94
3.942
Time (s)
0.1
0.08
0.07
0.09
0.06
0.05
0.04
0.03
0.02
0.01
0
15
10
5
0
0.024
0.026
0.028
X-update sample no.
0.03
0.032
0.034
0.036
Time (s)
X-updated posterior distribution (Pr[x(t)|yt]) state no. 3
X-updated posterior distribution (Pr[x(t)|yt]) state no. 2
X-updated posterior distribution (Pr[x(t)|yt]) state no. 1
0.08
0.07
0.09
0.06
0.05
0.04
0.03
0.02
0.01
0
15
10
5
0
0.032
0.033
0.034
X-update sample no.
0.035
0.036
0.037
0.038
0.039
Time (s)
FIGURE 8.5
PF posterior distribution estimation: (a) estimated state posterior; (b) parameter no. 1 posterior; (c) parameter no. 2 posterior.

0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Time (sec)
1.5
2
2.5
State amplitude
Amplitude
State amplitude
State amplitude
Ens. Estimated state
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Time (sec)
0
0.05
0.1
0.15
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Time (sec)
−0.1
−0.05
0
0.05
Mean
MAP/CM
Data
True parameter
MAP
CM
True parameter
MAP/CM
Ens. Estimated parameter
Ens. Estimated parameter
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Time (sec)
11
12
13
14
15
16
17
18
19
20
Ensemble estimated measurement
MEAN
Data
MAP/CM
(a)
(b)
(c)
(d)
FIGURE 8.6
PF ensemble estimation for a 100-member realizations. (a) ensemble state estimate; (b) ensemble parameter no. 1
estimate; (c) ensemble parameter no. 2 estimate; (d) ensemble measurement estimate.

352
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
GIVEN a set of noisy pressure-ield measurements from a horizontally towed array
of L-sensors in motion, FIND the “best” (minimum error variance) estimate of the
target bearings.
We use the following nonlinear pressure-ield measurement model for M
monochromatic plane wave targets characterized by a corresponding set of temporal
frequencies, bearings, and amplitudes, [{�m}, {�m}, {am}]. That is,
p(x, tk) =
M
∑
m=1
amej�mtk−j�(x,tk) sin �m + n(tk)
(8.63)
where �(x, tk) := kox(to) + �tk, ko = 2�
�o is the wave number, x(tk) is the current spatial
position along the x-axis in meters, �is the tow speed in m/sec, and n(tk) is the
additive random noise. The inclusion of motion in the generalized wave number �is
critical to the improvement of the processing, since the synthetic aperture effect is
actually created through the motion itself and not simply the displacement.
If we further assume that the single sensor equation above is expanded to include
an array of L-sensors, x →x�, �= 1, … , L; then we obtain
p(x�, tk) =
M
∑
m=1
amej�mtk−j�(x�,tk) sin �m + n�(tk)
→
M
∑
m=1
am cos(�mtk −�(x�, tk) sin �m) + n�(tk)
(8.64)
Since our hydrophone sensors measure the real part of the complex pressure-ield, the
inal nonlinear measurement model of the system can be written in compact vector
form as
p(tk) = c[tk; �] + n(tk)
(8.65)
where p, c, n ∈CL×1, are the respective pressure-ield, measurement, and noise vec-
tors and �∈M×1 represents the target bearings. The corresponding vector mea-
surement model
c�(tk; �) =
M
∑
m=1
am cos(�mtk −�(x�, tk) sin �m)
for �= 1, … , L
Since we model the bearings as a random walk emulating random target motion, the
Markovian state–space model evolves from irst differences as
�(tk) = �(tk−1) + w�(tk−1)
(8.66)
Thus, the state–space model is linear with no explicit dynamics; therefore, the process
matrix A = I (identity) and the relations are greatly simpliied.

8.5
CASE STUDY
353
Now let us see how a particle ilter using the bootstrap approach can be constructed
according to the generic algorithm of Table 7.2. For this problem, we assume the
additive noise sources are Gaussian, so we can compare results to the performance
of the approximate processor. We deine the discrete notation, tk+1 →t + 1 for the
sampled-data representation.
Let us cast this problem into the sequential Bayesian framework, that is, we would
like to estimate the instantaneous posterior iltering distribution, ̂Pr(x(t)|Yt), using
the PF representation to be able to perform inferences and extract the target bearing
estimates. Therefore, we have that the transition probability is given by (Θ(t) →x(t))
Pr(�(t)|�(t −1)) ⟶(�(t)|�(t −1)) ∼(Θ(t) :a[Θ(t −1)], R��,��)
or in terms of our state transition (bearings) model, we have
�(t) = a[Θ(t −1)] + ��(t −1) = �(t −1) + w�(t −1) for Pr(w�(t)) ∼(0, R����)
The corresponding likelihood is speciied in terms of the measurement model
(y(t) →p(t)) as
Pr(y(t)|x(t)) ⟶(y(t)|x(t)) ∼(y(t) :c[Θ(t)], R��(t))
where we have used the notation: z ∼(z : mz, Rzz) to specify the Gaussian distribu-
tion in random vector z. In terms of our problem, we have
ln (y(t)|x(t)) = �−1
2(y(t) −
M
∑
m=1
am cos(�mt −�(t) sin �m))′R−1
��
× (y(t) −
M
∑
m=1
am cos(�mt −�(t) sin �m))
with �a constant, �∈L×1 and �(t) := [�(x1, t)| … |�(xL, t)]′, the dynamic wavenum-
ber expanded over the array. Thus, the SIR algorithm becomes
r Draw samples (particles) from the state transition distribution:
Θi(t) ∼(Θ(t):a[Θ(t −1)], R��,��)
��i(t) ∼Pr(�(t)) ∼(0, R��i��i ), Θi(t) = Θi(t −1) + ��i(t −1)
r Estimate the likelihood: (y(t)|Θ(t)) ∼(y(t):c[Θ(t)], R��(t)) with c�(t; Θi) =
∑M
m=1 am cos(�mtk −�(x�, t) sin Θm,i(t)) for �= 1, … , L and Θm,i is the ith par-
ticle at the mth bearing angle;

354
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
r Update and normalize the weight: i(t) = Wi(t)∕∑Np
i=1 Wi(t);
r Resample: ̂Neff (t) ≤Nthresh;
r Estimate the instantaneous posterior: ̂Pr(Θ(t)|Yt) ≈∑Np
i=1 i(t)�(Θ(t) −Θi(t));
r Perform the inference by estimating the corresponding statistics: ̂Θmap(t) =
arg max ̂Pr(Θ(t)|Yt); ̂Θmmse(t) = ̂Θcm(t) = E{Θ(t)|Yt} = ∑Np
i=1 Θi(t) ̂Pr(Θ(t)|Yt);
̂Θmedian(t) = median( ̂Pr(Θ(t)|Yt)).
Consider the following simulation of the synthetic aperture using a four-element,
linear-towed array with “moving” targets using the following parameters:
Target: unity amplitudes with temporal frequency is 50 Hz, wavelength = 30 m,
tow speed = 5 m/sec; array: four (4) element linear towed array with 15 m spacing;
particle ilter: N�= 4 states (bearings), Ny = 4 sensors, N = 250 samples, Np = 250
weights; SNR: −10 dB; noise: white Gaussian with R��= diag [2.5], R��= diag
[0.1414]; sampling interval: 0.005 sec; initial conditions: (bearings and uncertainty)
Θo = [45◦−10◦5◦−75◦]′, Po = diag (10−10).
The array simulation was executed and the targets moved according to a random
walk speciied by the process noise and sensor array measurements with −10 dB
SNR. The results are shown in Fig. 8.7 where we see the noisy synthesized bearings
(left) and four (4) noisy sensor measurements at the moving array. The bearing (state)
estimates are shown in Fig. 8.8 where we observe the targets making a variety of
course alterations. The PF (MAP) is able to track the target motions quite well while
we observe the unscented Kalman ilter (UKF) [10] unable to respond quickly enough
and inally losing track completely for target no. 4. It should be noted that targets no.
2 and no. 4 “crossover” between 0.8 and 1.0 sec. The PF loses these tracks during this
time period getting them confused but recovers by the 1-sec time step. Both the MAP
and MMSE (CM) estimates using the estimated posterior provide excellent tracking.
Note that these bearing inputs would provide the raw data for an XY-tracker [10]. The
PF estimated or iltered measurements are shown in Fig. 8.9 . As expected, the PF
tracks the measurement data quite well while the UKF is again in small error.
For performance analysis, we applied the usual “sanity tests”. From this perspec-
tive, the PF processor works well, since each measurement channel is zero-mean
and white with the WSSR lying below the threshold indicating white innovations
sequences demonstrating the tracking ability of the PF processor at least in a clas-
sical sense [10] (see Fig. 8.10 and Table 8.2). The corresponding normalized root
mean-squared errors RMSE, median Kullback–Leibler divergence/Hellinger distance
statistics for the bearing estimates are also shown in the table along with the measure-
ments at each sensor. Estimating the KD/HD metrics for the measurements indicate
a reasonable performance for both the bearings and measurements.
The instantaneous posterior distributions for the bearing estimates are shown in
Fig. 8.10. Here, we see the Gaussian nature of the bearing estimates generated by
the random walk. Clearly, the PF performs quite well for this problem. Note also the
capability of using the synthetic aperture, since we have only a four-element sensor

0
20
40
60
Target no. 1 
Bearing (deg) 
−40
−20
0
Target no. 2 
−40
−20
0
20
Target no. 3  
0
0.2
0.4
0.6
0.8
1
1.2
1.4
−100
−80
−60
Target no. 4  
Time (s)
1.4
1.2
1
0.8
0.6
0.4
0.2
0
Time (s)
1.4
1.2
1
0.8
0.6
0.4
0.2
0
Time (s)
1.4
1.2
1
0.8
0.6
0.4
0.2
0
Time (s)
0
0.2
0.4
0.6
0.8
1
1.2
−5
0
5
Sensor no. 4 
Time (s)
Pressure
0
0.2
0.4
0.6
1.2
1
0.8
−5
0
5
Sensor no. 3 
Time (s)
Pressure
0
0.2
0.4
0.6
1.2
1
0.8
−5
0
5
Sensor no. 2
Time (s)
Pressure
0
0.2
0.4
0.6
1.2
1
0.8
−2
0
2
Sensor no. 1
Time (s)
Pressure
Bearing (deg) 
Bearing (deg) 
Bearing (deg) 
FIGURE 8.7
Synthetic aperture sonar tracking problem: simulated target motion from initial bearings of 45◦, −10◦, 5◦, and −75◦,
and array measurements (−10 dB SNR).

356
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.4
1.2
1
0.8
0.6
0.4
0.2
0
1.4
1.2
1
0.8
0.6
0.4
0.2
0
1.4
1.2
1
0.8
0.6
0.4
0.2
0
0
20
40
60
MAP est. target no. 1 
−40
−30
−20
−10
0
MAP est. target no. 2 
−40
−20
0
20
MAP est. target no. 3 
−120
−100
−80
−60
−40
MAP est. target no. 4 
Data
CM
UKF
Bearing (deg)
Bearing (deg)
Bearing (deg)
Bearing (deg)
Time (sec)
CM 
CM 
PF 
PF 
UKF 
UKF 
CM 
CM 
PF 
PF 
UKF 
UKF 
PF
FIGURE 8.8
Particle ilter bearing estimates for four targets in random motion: PF bear-
ing (state) estimates and simulated target tracks (UKF, conditional mean, MAP).
TABLE 8.2
PF Performance Towed Array Problem
Particle Filter Performance Results
Parameter
RMSE
Median KLD
Median HD
Bearing No. 1
0.117
0.528
0.342
Bearing No. 2
0.292
0.180
0.208
Bearing No. 3
0.251
0.179
0.209
Bearing No. 4
0.684
0.406
0.309
Measurements
Median KLD
Median HD
Sensor No. 1
0.066
0.139
Sensor No. 2
0.109
0.166
Sensor No. 3
0.259
0.275
Sensor No. 4
0.312
0.327
Innovations
Zero-Mean < 0.173
Whiteness
WSSR < 455
Sensor No. 1
0.0102
5.47%
Below
Sensor No. 2
0.0136
1.56%
Below
Sensor No. 3
0.0057
5.47%
Below
Sensor No. 4
0.0132
2.34%
Below

8.5
CASE STUDY
357
−2
−1
0
1
2
−4
−2
0
2
4
−6
−4
−2
0
2
4
0
0.2
0.4
0.6
0.8
1
1.2
1.4
0
0.2
0.8
0.6
0.4
1.4
1.2
1
0
0.2
0.8
0.6
0.4
1.4
1.2
1
0
0.2
0.8
0.6
0.4
1.4
1.2
1
−4
−2
0
2
4
Time (sec)
Data
Mean
UKF
CM
PF
Pressure
Pressure
Pressure
Pressure
Predicted measurement no. 4  
PF 
Predicted measurement no. 3  
PF 
Predicted measurement no. 2  
PF 
Predicted measurement no. 1  
PF 
FIGURE
8.9
Particle
ilter
predicted
measurement
estimates
for
four-channel
hydrophone sensor array.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0
0.2
0.4
0.6
0.8
1
1.2
Whiteness (Pct/No = 2.34(3))
Whiteness (Pct = 5.47%)
0.1
0.2
0.3
0.4
0.5
0.6
0
0.2
0.4
0.6
0.8
1
1.2
0
1
Lags
Time (sec)
−0.2
−0.2
Zero mean/whiteness-test: 
(Mean=0.0057<0.173) 
Zero mean/whiteness-test: 
(Mean=0.0132<0.173) 
Zero mean/whiteness-test: 
(Mean=0.0136<0.173)  
whiteness (Pct = 1.56%)
Zero mean/whiteness-test: 
(Mean=0.0102<0.173) 
Whiteness (Pct = 5.47%)
0.3
0.4
WSSR test: 
(Length=100, Threshold=455)
0
0
R^
ee
R^
ee
R^
ee
R^
ee
FIGURE 8.10
Particle ilter classical performance metrics:zero-mean/whiteness tests for
45◦, −10◦, 5◦, and 75◦targets, as well as the corresponding WSSR test.

0.2
0.18
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
1.4
1.2
1 0.8
0.6 0.4
0.2
Time (s)
0
4
6
8
10
X-update sample no
12
0.03
0.04
0.05
0.06
0.07
0.08
ytilib
a
b
o
r
P
ytilib
a
b
o
r
P
ytilib
a
b
o
r
P
ytilib
a
b
o
r
P
0.02
0.01
0
1.4
1.2
1 0.8
0.6 0.4
0.2
Time (s)
0
−30
−25
−20
−15
−10
X-update sample no
14
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
1.4
1.2
1 0.8
0.6 0.4
0.2
Time (s)
0
−15
−20
−25
−30
X-update sample No
0.3
0.35
0.4
0.25
0.2
0.15
0.1
0.05
0
1.4
1.2
1 0.8
0.6 0.4
0.2
Time (s)
0
−60
−70
−65
−80
−75
−85
−90
X-update sample no
x-updated posterior distribution (Pr[x(t)|Yt]) state no. 3
x-updated posterior distribution (Pr[x(t)|Yt
[r
P
( 
n
oit
u
birtsid
 r
oir
e
ts
o
p
 
d
e
t
a
d
p
u
-
x
1
 .o
n
 
e
t
a
ts )]
x(t)|Yt]) state no. 2
x-updated posterior distribution (Pr[x(t)|Yt]) state no. 4
(a)
(b)
(c)
(d)
FIGURE 8.11
Particle ilter instantaneous posterior bearing estimates: (a) 45◦target no.1.posterior; (b) −10◦target no.
2 posterior; (c) 5◦target no. 3; and (d) −75◦target no. 4.

8.6
SUMMARY
359
array, yet we are able to track 4 targets. Linear array theory implies with a static array
that we should only be able to track L −1 = 3 targets!
In this case study, we have applied the bootstrap PF to an ocean acoustic synthetic
aperture towed array target tracking problem to test the performance of a the particle
iltering technique. The results are quite reasonable on this simulated data set.
8.6
SUMMARY
In this chapter, we have discussed the development of joint Bayesian state/parametric
processors. Starting with a brief introduction, we deined the variety of problems
based on the joint posterior distribution Pr(x(t), �(t)|Yt) and its decomposition. We
decided to focus on the joint problem of estimating both states and parameters simul-
taneously (online)—the most common problem of highest interest. We then briely
showed that all that is necessary for this problem is to deine an “augmented” state
consisting of the original state variables along with the unknown parameters typi-
cally modeled by a random walk when a dynamic parametric model is not available.
This casts the joint problem into an optimal iltering framework. We then showed
how this augmentation leads to a decomposition of the classical (EKF) processor
and developed the “decomposed” form for illustrative purposes. The algorithm is
implemented by executing the usual processor with the new augmented state vector.
We also extended this approach to both the modern “unscented” and “particle-based”
processors, again only requiring the state augmentation procedure to implement. It
was shown that all of the processors required a random walk parametric model to
function, while the particle ilters could be implemented using the “roughening”
(particle random walks) or any of the “move” techniques developed in Chapter 7
to track the parameters effectively. Besides applying these processors to the usual
nonlinear trajectory estimation problem, we developed a case study for a synthetic
aperture towed array and compared the modern to the particle-based processors.
MATLAB NOTES
SSPACK_PC is a third party toolbox in MATLAB that can be used to design
model-based signal processors. This package incorporates the major nonlinear
MBP algorithms discussed in this chapter—all implemented in the UD-factorized
form [10] for stable and eficient calculations. It performs the discrete approximate
Gauss–Markov simulations using (SSNSIM) and both extended (XMBP) and
iterated-extended (IX-MBP) processors using (SSNEST). The linearized model-
based processor (LZ-MBP) is also implemented (SSLZEST). Ensemble opera-
tions are seamlessly embodied within the GUI-driven framework where it is quite
eficient to perform multiple design runs and compare results. Of course, the
heart of the package is the command or GUI-driven post-processor (SSPOST)
which is used to analyze and display the results of the simulations and processing
(see http://www.techni-soft.net for more details). REBEL is a recursive Bayesian

360
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
estimation package in MATLAB available on the web, that performs similar oper-
ations including the new statistical-based unscented algorithms including the UKF
including the unscented transformations. It also has included the new particle ilter
designs.
REFERENCES
1. L. Ljung, System Identiication: Theory for the User (Englewood Cliffs, NJ: Prentice-Hall,
1987).
2. L. Ljung and T. Soderstrom, Theory and Practice of Recursive Identiication (Boston,
MA: MIT Press, 1983).
3. T. Soderstrom and P. Stoica, System Identiication (Englewood Cliffs, NJ: Prentice-Hall,
1989).
4. J. Norton, An Introduction to Identiication (New York: Academic Press, 1986).
5. J. Liu, Monte Carlo Strategies in Scientiic Computing, (New York: Springer-Verlag,
2001).
6. O. Cappe, E. Moulines, and T. Ryden, Inference in Hidden Markov Models, (New York:
Springer-Verlag, 2005).
7. J. Liu and M. West, “Combined parameter and state estimation in simulation-based ilter-
ing,” in Sequential Monte Carlo Methods in Practice, edited by A. Doucet, N. de Freitas,
and N. Gordon (New York: Springer-Verlag, 2001), pp. 197–223.
8. A. Doucet, N. de Freitas, and N. Gordon, Sequential Monte Carlo Methods in Practice
(New York: Springer-Verlag, 2001).
9. S. Godsill and P. Djuric, “Monte Carlo methods for statistical signal processing,” IEEE
Trans. Signal Proc., 50, 173–499, 2002 (Special Issue).
10. J. Candy, Model-Based Signal Processing. (Hoboken, NJ: John Wiley & Sons, Inc./IEEE
Press, 2006).
11. O. Cappe, S. Godsill, and E. Moulines, “An overview of existing methods and recent
advances in sequential Monte Carlo,” Proc. IEEE, 95, 5, 899–924, 2007.
12. G. Kitagawa and W. Gersch, Smoothness Priors Analysis of Time Series (New York:
Springer-Verlag, 1997).
13. G. Kitagawa, “Self-organizing state-space model,” J. Am. Statistical Assoc., 97, 447,
1207–1215, 1998.
14. R. van der Merwe, A. Doucet, N. de Freitas, and E. Wan, “The unscented particle ilter,”
in Advances in Neural Information Processing Systems 16 (Cambridge, MA: MIT Press,
2000).
15. N. Gordon, D. Salmond, and A. Smith, “A novel approach to nonlinear non-gaussian
Bayesian state estimation,” IEE Proc. F., 140, 107–113, 1993.
16. S. Haykin and N. de Freitas, “Special issue: sequential state estimation: from Kalman
ilters to particle ilters,” Proc. IEEE, 92, 3, 399–574, 2004.
17. C. Andrieu, A. Doucet, S. Singh, and V. Tadic, “Particle methods for change detection,
system identiication and control,” Proc. IEEE, 92, 6, 423–468, 2004.
18. S. Haykin, Kalman Filtering and Neural Networks. (New York: John Wiley & Sons, Inc.,
2001).

REFERENCES
361
19. D. Simon, Optimal State Estimation: Kalman H∞and Nonlinear Approaches (Hoboken,
NJ: John Wiley & Sons/IEEE Press, 2006).
20. A. Jazwinski, Stochastic Processes and Filtering Theory. (New York: Academic Press,
1970).
21. R. van der Merwe, “Sigma-point Kalman ilters for probabilistic inference in dynamic
state-space models,” Ph.D. Dissertation, OGI School of Science & Engineering, Oregon
Health & Science University, 2004.
22. A. Nelson, “Nonlinear estimation and modeling of noisy time-series by dual Kalman
iltering methods,” Ph.D. Dissertation, OGI School of Science & Engineering, Oregon
Health & Science University, 2000.
23. L. Ljung, “Asymptotic behavior of the extended Kalman ilter as a parameter estimator
for linear systems,” IEEE Trans. Auto. Control, AC-24, 36–50, 1979.
24. J. Rajan, P. Rayner, and S. Godsill, “Bayesian approach to parameter estimation and
interpolation of time-varying autoregressive processes using the Gibbs sampler,” IEE
Proc-Vis. Image Signal Process., 144, 4, 249–256, 1997.
25. N. Polson, J. Stroud, and P. Muller, “Practical iltering with sequential parameter learning,”
University of Chicago Technical Report, 1–18, 2002.
26. C. Andrieu, A. Doucet, S. Singh, and V. Tadic, “Particle methods for change detection,
system identiication and control,” Proc. IEEE, 92, 3, 423–438, 2004.
27. G. Storvik, “Particle ilters in state-space models with the presence of unknown static
parameters,” IEEE Tran. Signal Proc., 50, 2, 281–289, 2002.
28. P. Djuric, “Sequential estimation of signals under model uncertainty,” in Sequential Monte
Carlo Methods in Practice, edited by A. Doucet, N. de Freitas, and N. Gordon (New York:
Springer-Verlag, 2001), pp. 381–400.
29. D. Lee and N. Chia, “A particle algorithm for sequential Bayesian parameter estimation
and model selection,” IEEE Tran. Signal Proc., 50, 2, 326–336, 2002.
30. A. Doucet and V. Tadic, “Parameter estimation in general state-space models using particle
methods,” Ann. Inst. Stat. Math., 55, 2, 409–422, 2003.
31. J. Candy, “Bootstrap particle iltering,” IEEE Signal Proc. Magz., 24, 4, 73–85, 2007.
32. C. Andrieu, A. Doucet, and V. Tadic, “On-line parameter estimation in general state-space
models,” Proc. IEEE Conf. Decision and Control, pp. 332–337, 2005.
33. J. Vermaak, C. Andrieu, A. Doucet, and S. Godsill, “Particle methods for Bayesian
modeling and enhancement of speech signals,” IEEE Trans. Speech Audio Proc., 10, 3,
173–185, 2002.
34. T. Schoen and F. Gustafsson, “Particle ilters for system identiication of state-space models
linear in either parameters or states,” Linkoping University Report, LITH-ISY-R-2518,
2003.
35. R. Williams, “Creating an acoustic synthetic aperture in the ocean,” J. Acoust. Soc. Am.,
60, 60–73, 1976.
36. N. Yen and W. Carey, “Applications of synthetic aperture processing to towed array data,”
J. Acoust. Soc. Am., 60, 764–775, 1976.
37. S. Stergiopoulus and E. Sullivan, “Extended towed array processing by an overlap corre-
lator,” J. Acoust. Soc. Am., 86, 764–775, 1976.
38. E. Sullivan, W. Carey, and S. Stergiopoulus, “Editorial in special issue on acoustic synthetic
aperture processing,” IEEE J. Ocean. Eng., 17, 1–7, 1992.

362
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
39. D. Ward, E. Lehmann, and R. Williamson, “Particle iltering algorithm for tracking and
acoustic source in a reverberant environment,” IEEE Trans. Speech and Aud. Proc., 11, 6,
826–836, 2003.
40. M. Orton and W. Fitzgerald, “Bayesian approach to tracking multiple targets using sensor
arrays and particle ilters,” IEEE Trans. Signal Proc., 50, 2, 216–223, 2002.
41. E. Sullivan and J. Candy, “Space-time array processing: the model-based approach,” J.
Acoust. Soc. Am., 102, 5, 2809–2820, 1997.
PROBLEMS
8.1
Suppose we are given the following innovations model (in steady state)
̂x(t) = âx(t −1) + ke(t −1)
y(t) = ĉx(t) + e(t)
where e(t) is the zero-mean, white innovations sequence with covariance. Ree.
(a) Derive the Wiener solution using the spectral factorization method of Sec-
tion 4.5.
(b) Develop the linear steady-state BP for this model.
(c) Develop the parametrically adaptive processor to estimate k and Ree.
8.2
As stated in the chapter, the XBP convergence can be improved by incorporating
a gain gradient term in the system Jacobian matrices, that is,
A∗
�[x, �] := A�[x, �] + [∇�Kx(Θ)]e(t)
for:= [Kx|K�]
(a) By partitioning the original Nx × N�Jacobian matrix, A�[x, �], derive the
general “elemental” recursion, that is, show that
A∗
�[i, �] = ∇��ai[x, �] +
Ny
∑
j=1
∇��kx(i, j)ej(t); i = 1, … , Nx; �= 1, … , N�
(b) Suppose we would like to implement this modiication, does there exist a
numerical solution that could be used? If so, describe it.
8.3
Using the following scalar Gauss–Markov model
x(t) = Ax(t −1) + �(t −1)
y(t) = Ĉx(t) + �(t)
with the usual zero-mean, R��and R��covariances.
(a) Let {A, C, K, Ree} be scalars, develop the ABSP solution to estimate A from
noisy data.
(b) Can these algorithms be combined to “tune” the resulting hybrid processor?

PROBLEMS
363
8.4
Suppose we are given the following structural model
m̈x(t) + c ̇x + kx(t) = p(t) + �(t)
y(t) = �x(t) + �(t)
with the usual zero-mean, R��and R��covariances.
(a) Convert this model to discrete-time using irst differences. Using cen-
tral difference create the discrete Gauss–Markov model. (Hint: ̈x(t) ≈
x(t)−2x(t−1)+x(t−2)
Δ2
t
).
(b) Suppose we would like to estimate the spring constant k from noisy dis-
placement measurements, develop the ABSP to solve this problem.
(c) Transform the discrete Gauss–Markov model to the innovations represen-
tation. (Hint: Use the KSP equations of Ref. [10]).
(d) Solve the parameter estimation problem using the innovations model, that
is, develop the estimator of the spring constant.
8.5
Given the ARMAX model
y(t) = −ay(t −1) + bu(t −1) + e(t)
with innovations covariance Ree:
(a) Write the expressions for the ABSP in terms of the ARMAX model.
(b) Write the expressions for the ABSP in terms of the state–space model.
8.6
Consider tracking a body falling freely through the atmosphere [10]. We assume
it is falling down in a straight line towards a radar. The state vector is deined
by x := [z
̇z
�], where �∼(��, R��) = (2000, 2.5 × 105) is the ballistic
coeficient. The dynamics are deined by the state equations
̇x1(t) = x2(t)
̇x2(t) =
�x2
2(t)
2x3(t) −g
̇x3(t) = 0
�= �oe
−x1(t)
k�
where d is the drag deceleration, g is the acceleration due to gravity (32.2), �
is the atmospheric density (with �o (3.4 × 10−3) density at sea level) and k�a
decay constant (2.2 × 104). The corresponding measurement is given by
y(t) = x1(t) + �(t)

364
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
for
�∼(0, R��) = (0, 100).
Initial
values
are
x(0) = �∼(1065,
500), ̇x(0) ∼(−6000, 2 × 104), and P(0) = diag[po(1, 1), po(2, 2), po(3, 3)] =
[500, 2 × 104, 2.5 × 105).
(a) Is this an ABSP If so, write out the explicit algorithm in terms of the
parametrically adaptive algorithm of this chapter.
(b) Develop the XBP for this problem and perform the discrete simulation using
MATLAB.
(c) Develop the LZ-BP for this problem and perform the discrete simulation
using MATLAB.
(d) Develop the PF for this problem and perform the discrete simulation using
MATLAB.
8.7
Parameter estimation can be performed directly when we are given a nonlinear
measurement system such that
y = h(�) + v
where y, h ∈Ny×1 , �∼(m�, R��), and v ∼(0, R��).
(a) From the a posteriori density, Pr(�|y) derive the MAP estimator for �.
(b) Expand y = h(�) in a Taylor series about �o and incorporate the irst order
approximation into the MAP estimator (approximate).
(c) Expand y = h(�) in a Taylor series about �o and incorporate the second
order approximation into the MAP estimator (approximate).
(d) Develop and iterated version of both estimators in (b) and (c). How do they
compare?
(e) Use the parametrically adaptive formulation of this problem assuming the
measurement model is time-varying. Construct the ABSP assuming that �
is modeled by a random walk. How does this processor compare to the
iterated versions?
8.8
Suppose we are asked to solve a detection problem, that is we must “decide”
whether a signal is present or not according to the following binary hypothesis
test
o:y(t) = �(t)
for �∼(0, R��)
1:y(t) = s(t) + �(t)
The signal is modeled by a Gauss–Markov model
s(t) = a[s(t −1)] + �(t −1)
for �∼(0, R��)
(a) Calculate the likelihood-ratio deined by
(Y(N)) := Pr(Y(N)|1)
Pr(Y(N)|o)

PROBLEMS
365
where the measurement data set is deined by Y(N); = {y(0), y(1), … , y(N)}.
Calculate the corresponding threshold and construct the detector (binary
hypothesis test).
(b) Suppose there is an unknown but deterministic parameter in the signal
model, that is,
s(t) = a[s(t −1); �(t −1)] + �(t −1)
Construct the “composite” likelihood ratio for this case. Calculate the cor-
responding threshold and construct the detector (binary hypothesis test).
(Hint: Use the ABSP to jointly estimate the signal and parameter.)
(c) Calculate a sequential form of the likelihood ratio above by letting the
batch of measurements, N →t. Calculate the corresponding threshold and
construct the detector (binary hypothesis test). Note there are two thresholds
for this type of detector.
8.9
Angle modulated communications including both frequency modulation (FM)
and phase modulation (PM) are basically nonlinear systems from the model-
based perspective. They are characterized by high bandwidth requirements and
their performance is outstanding in noisy environments. Both can be captured
by the transmitted measurement model
s(t) =
√
2P sin[�ct + kpm(t)]
(PM)
or
s(t) =
√
2P sin[�ct + 2�kf ∫
t
−∞
m(�)d�]
(FM)
where P is a constant, �c is the carrier frequency, kp and kf are the deviation
constants for the respective modulation systems and of course, m(t), is the
message model. Demodulation to extract the message from the transmission is
accomplished by estimating the phase of s(t). For FM, the recovered phase is
differentiated and scaled to extract the message, while PM only requires the
scaling.
Suppose the message signal is given by the Gauss–Markov representation
m(t) = −�m(t −1) + �(t −1)
y(t) = s(t) + �(t)
with both �and �zero-mean, Gaussian with variances, R��and R��.
(a) Construct a receiver for the PM system using the XBP design.
(b) Construct an equivalent receiver for the FM system.
(c) Assume that the message amplitude parameter �is unknown, construct
the ABSP receiver for the PM system to jointly estimate the message and
parameter.

366
JOINT BAYESIAN STATE/PARAMETRIC PROCESSORS
(d) Under the same assumptions as (c), construct the ABSP receiver for the FM
system to jointly estimate the message and parameter.
(e) Compare the receivers for both systems. What are their similarities and
differences?
8.10 We are given the population model of the Chapter 7 case study and would like to
“parameterize” it for adaptive processing, since we know the parameters are not
very well known. The state transition and corresponding measurement model
are given by
x(t) = 1
2x(t −1) +
25x(t −1)
1 + x2(t −1) + 8 cos(1.2(t −1)) + �(t −1)
y(t) = x2(t)
20 + �(t)
where △t = 1.0, �∼(0, 10), and �∼(0, 1). The initial state is Gaussian
distributed with x(0) ∼(0.1, 5).
In terms of the nonlinear state–space representation, we have
a[x(t −1)] = 1
2x(t −1) +
( 25x(t −1)
1 + x2(t −1)
)
b[u(t −1)] = 8 cos(1.2(t −1))
c[x(t)] = x2(t)
20
(a) Choose the model constants: 25, 8, 0.5, and
1
20 as the unknown param-
eters, reformulate the state estimation problem as a parameter estimation
problem with unknown parameter vector, Θ and a random walk model with
corresponding process noise variance, R��= diag[1 × 10−6].
(b) Develop the joint SPBP algorithm to solve this problem. Run the SPBP
algorithm and discuss the performance results.
(c) Develop the joint PF algorithm to solve this problem. Run the PF algorithm
and discuss the performance results.
(d) Choose to “move” the particles using the roughening approach, how do
these results compare to the standard bootstrap algorithm?
(e) Develop the joint linearized (UKF) PF algorithm to solve this problem. Run
this PF algorithm and discuss the performance results.

9
DISCRETE HIDDEN MARKOV
MODEL BAYESIAN
PROCESSORS
9.1
INTRODUCTION
In this chapter we develop discrete (event) hidden Markov models. All of the Bayesian
processors we have discussed are, in fact, hidden Markov processors, since the internal
states are usually not measured directly and are therefore “hidden” by deinition, but
the distinguishing factor is the type of underlying process governing the sequence. In
fact, the (state) transition matrix is a “probability” matrix with speciic properties that
distinguish it uniquely from other dynamic systems. These discrete representations
of stochastic processes ind enormous application in speech, economics, biomedical,
communications and music areas where coding approaches are prevalent. We discuss
the development of the basic processor and investigate a case study in communications
to demonstrate the design and application.
9.2
HIDDEN MARKOV MODELS
A discrete-time hidden Markov model (HMM) is a stochastic representation (model)
of a process that can be used for simulation, modeling, and estimation much the
same as the state–space model is used for dynamic (physical) systems. These models
are prevalent in acoustics, biosciences, climatology, control, communications, econo-
metrics, text recognition, image processing, signal processing, and speech processing
[1]. Perhaps its distinguishing feature is that it is a “probabilistic model” in the sense
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
367

368
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
that it is driven by internal probability distributions for both states and observations
or equivalently measurements. Here the state-transition matrix prevalent in linear
systems theory is still valid and is also called a transition matrix, but it is a discrete
probability matrix with rows summing to unity and in some cases (doubly stochastic)
columns summing to unity as well. The underlying structure from which the HMM
evolves is the Markov chain of Chapter 3 along with the sequential Bayesian recur-
sions of Chapter 2. We start with the idea of a Markov chain and its decomposition
basics leading to HMM.
9.2.1
Discrete-Time Markov Chains
A discrete-time Markov chain is characterized by a state variable that changes at
certain time instances [2–4]. At each time-step t the state is deined by x(t) ∈
(state–space) and = {1, …, Nx}. The probability that at time t the chain occupies
state i is deined by Pr(xi(t)). The dynamics of the Markov chain are represented by
its transition probability amn(t −1, t) := Pr(xn(t)|xm(t −1)) where xi(t) := {x(t) = i}.
This expression means that the probability that the state at time t is n given that
it is currently in state m at time t −1 for (m, n) ∈. Here the key Markovian
assumption is that the transition probability amn applies whenever state m is “visited”
independent of the “past” and the path or previous states employed to reach m. This
is merely a statement of the Markovian property that
amn(t −1, t) = Pr(xn(t)|xm(t −1), … , x�(0)) = Pr(xn(t)|xm(t −1))
∀
t and (m, n) ∈
(9.1)
Further, if the chain is homogeneous in time, then amn(t −1, t) depends only on the
time difference (in general) and therefore the transition probability is stationary such
that amn(t −1, t) →amn with amn ≥0 and ∑Nx
n=1 amn = 1 [2].
Summarizing, a discrete-time Markov chain is characterized by:
r a inite set of known Nx-states: = {1, … , Nx};
r a nonnegative set of state-transition probabilities for (m, n) →{amn}; and
r a sequence of random variables: xm(0), xn(1), … ∈that satisfy the Markovian
property
amn(t −1, t) = Pr(xn(t)|xm(t −1)) ∀t and all states (m, n) ∈
The elements of the homogeneous chain are embedded in the Nx × Nx
state-transition probability matrix A = [amn]; m, n = 1, … , Nx. The chain can be
speciied pictorially by a directed graph with nodes representing states and
arcs or arrows corresponding to the transition probabilities as illustrated in
Fig. 9.1.

9.2
HIDDEN MARKOV MODELS
369
X2
a21
a11
a22
State−transition probabilities
a12
State
X1
State
FIGURE 9.1
Directed graph representation of two-state Markov chain.
Example 9.1
Suppose we are given a two-state (Nx = 2) Markov chain with transition probability
amn = Pr(xn(t)|xm(t −1));
m, n = 1, 2
and amn = {0.55, 0.45, 0.25, 0.75}. Construct the state-transition probability matrix A
and the corresponding directed graph. The transition probability is given by
A =
[
0.55
0.45
0.25
0.75
]
(9.2)
The resulting graph is shown in Fig. 9.1.
△△△
9.2.2
Hidden Markov Chains
An HMM is simply a Markov chain in which all of the states are not observed—
some are hidden. In this case we introduce the observation or measurement or output
process where only a subset of the states are observed directly. Thus, the essential
difference between a Markov chain and an HMM is that for an HMM there is one-
to-one correspondence between the states and observations (output measurements).
It is not possible to tell which state the model was in by merely observing the outputs
of the chain. We illustrate the structural model in Fig. 9.2a. Note that when the states
are directly observed in a, then the observations and states are identical.
Thus, we differentiate the hidden Markov chain or HMM from the Markov chain by
introducing an observation or measurement process [5–8]. Here the state sequence
is not known, that is, it is hidden in the measurement sequence. Thus, at every
time-step t, the system generates a measurement or observation y(t) according to a
probability distribution that depends on the state x(t). The number of observations
Ny corresponds to a known distinct set, that is, at time t the observation is y(t) ∈

370
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
(a)
yn(t +1)
yl(t −1)
ym(t)
xk(t +1)
xi(t −1)
xj(t)
ym(t) xj(t)
Pr
( )
(
1)
j
i
x t x t −
Pr
(
1)
( )
k
j
x t
x t
+
Pr
Pr
(
1)
(
1)
i
y t
x t
−
−
l 
(b)
HMM 
HMM 
Observations
(measurements)
Initial conditions
(prior)
Markov chain
(states) 
FIGURE 9.2
Hidden Markov model structure: (a) Markov chain (states) and observa-
tions (measurements); (b) Markov chain with state-transition probabilities and observa-
tions with measurement probabilities (likelihoods).
(observation space) with = {1, …, Ny}. We deine the corresponding “discrete”
observation probability (likelihood) by1
ck�(t, t) := Pr(y�(t)|xk(t))
(9.3)
Again for the homogeneous case, ck�(t, t) →ck�and ck�≥0 and ∑Ny
�=1 ck�= 1. As
in the chain, we have the associated Ny × Nx observation probability matrix given
by C = [ck�] for k = 1, … , Nx; �= 1, … , Ny with C ∈RNy×Nx. The inal ingredient
to characterize the HMM is the prior or initial probability distribution given by
Pr(x(0) = i(0)); i = 1, … , Nx which represents the initial probability of the chain.
Summarizing an HMM is speciied by the model Σ := {A, C, Pr(xi(0))} (homoge-
neous case) where
r The state-transition probability matrix is
A = [amn] = Pr(xn(t)|xm(t −1));
m, n = 1, … , Nx;
1 This probability expression has two subscripts to annotate the discrete state (xk(t)) and the discrete
measurement or observation (y�(t)). Most references assume a continuous observation and use the notation
ck(y(t)) [9–12].

9.2
HIDDEN MARKOV MODELS
371
r The observation probability matrix is
C = [ck�] = Pr(y�(t)|xk(t))
for k = 1, … , Nx;
�= 1, … , Ny; and
r The prior probability is
Pr(xi(0));
i = 1, … , Nx
where Nx, Ny are the number of states and observations (measurements), respectively
(see Fig. 9.2b).
We must realize a subtle point that in contrast to dynamic physical systems
where the states and measurements can be any real value or number, the HMM
states or observations can only assume predeined integer values, = {1, … , Nx}
and = {1, … , Ny}—this is very important to comprehend. It is the transition
and observation probabilities that drive the occurrence of an individual state and
observation event, since both are merely (integer) realizations of model outputs. For
example, the mapping or quantization of a “real” physical communications signal
to a binary coded representation takes the form of a sequence of a 0 or 1 inte-
ger value at each time step which are mapped to the observation sequence (see
Section 9.7).
It should also be noted that with the addition of the observation process it is simple
to deine an underlying HMM state–space model as
x(t) = Ax(t −1) + �(t −1)
y(t) = Cx(t) + �(t)
(9.4)
where �, �are uncorrelated (white) sequences (noise) with x, y the usual state and
measurement sequences and associated initial conditions x(0), all speciied by the
HMM above Fig. 9.2b.
Note that the additive sequences (noise) are not necessarily Gaussian and therefore
the linear Bayesian processor (Kalman ilter) is not optimum in this case. However,
it has been shown [13] that under some (suficient) conditions (stationarity, etc.)
an optimal minimum error variance estimator (Kalman ilter) can be constructed
based on a stochastic realization of an HMM. The results of this design are capable
of providing reasonable estimates of the HMM states and observations. It is also
important to understand that there exist state–space representations in which both
discrete HMM models are combined with dynamic (physical) state–space systems.
For instance, one prevalent form is termed switching models in which the discrete
HMM determines which underlying dynamic model applies at a given time step. This
is an approach frequently used in target tracking problems [14] to provide multiple
model choices.

372
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
9.3
PROPERTIES OF THE HIDDEN MARKOV MODEL
In this section we investigate some of the underlying probabilistic properties of the
discrete HMM. To no surprise it matches our Bayesian processor development in
the previous chapters. After all, once placed in the state–space representation all
Bayesian properties should hold. We start with the joint distribution.
The HMM is a probabilistic model of the joint collection of random variates
(Yt, Xt). Critical properties of the HMM rely on basic Bayesian methodologies and
developments. Perhaps the most useful notions inherited from the Markov chain
theory are the two major properties of conditional independence that are used over and
over again along with Bayes’ rule. That is, under an HMM there are two assumptions
enabling the development of the underlying techniques:
1. The
hidden
variables
are
irst-order
Markov2:
Pr(x(t)|Xt−1, Yt−1) =
Pr(x(t)|x(t −1)) (state transition); and
2. The observation is independent of other variates given the state (at time t):
Pr(y(t)|Yt−1, Xt) = Pr(y(t)|x(t)) (likelihood).
These properties imply that the underlying joint distribution can be expanded as
Pr(Yt, Xt) = Pr(y(t), Yt−1, x(t), Xt−1)
= Pr(y(t), x(t)|Yt−1, Xt−1) × Pr(Yt−1, Xt−1)
(9.5)
Continuing to apply Bayes’ rule to this expression gives
Pr(Yt, Xt) = [Pr(y(t)|x(t), Xt−1, Yt−1) × Pr(x(t)|Xt−1, Yt−1)]
× Pr(Yt−1, Xt−1)
(9.6)
or inally
Pr(Yt, Xt) = Pr(y(t)|x(t)) × Pr(x(t)|x(t −1)) × Pr(Yt−1, Xt−1)
(9.7)
where we have applied the conditional independence properties of the HMM. From
the chain rule and these independence properties, we can expand this expression even
further to obtain
Pr(Yt, Xt) =
t∏
k=0
Pr(y(k)|x(k)) ×
t∏
k=2
Pr(x(k)|x(k −1)) × Pr(x(0))
(9.8)
2 Any Nth-order Markov process can be transformed to a irst-order process [15].

9.4
HMM OBSERVATION PROBABILITY: EVALUATION PROBLEM
373
Thus, in order to characterize an HMM we require the following probabilities:
r Prior:
Pr(x(0));
r Transition:
Pr(x(t)|x(t −1)); and
r Likelihood:
Pr(y(t)|x(t)).
These quantities correspond to the classic3 deinition of an HMM [10]. The under-
lying Markov chain is usually assumed to be homogeneous in time with associated
stochastic state-transition matrix deined before by A = amn = Pr(xn(t)|xm(t −1))∀t
and the observation (measurement) probability is given by C = [ck�] = Pr(y�(t)|xk(t)).
The HMM parameters are usually speciied by Σ = (A, C, Pr(xi(0))). Here the mea-
surements Yt are observed and the states or internal variables are hidden. In order to
generate (simulate) samples from the HMM, the initial “state” distribution is gen-
erated followed by the likelihood (prior →transition →likelihood). It is important to
understand that each measurement sample simulated requires new state samples, that
is, two synthesized measurement samples originated from two different states in the
hidden Markov chain.
9.4
HMM OBSERVATION PROBABILITY: EVALUATION PROBLEM
With the HMM properties of the previous section available, we can now pose the irst
problem of interest. With the model known and a set of observations available, how
can we evaluate the performance of the HMM to faithfully synthesize observations?
One way to approach this problem is to estimate the corresponding observation prob-
ability Pr(YT) and use it to “validate” that the model and observations are compatible
(see Fig. 9.3a). This approach is especially useful when we are to compare or “match”
different models to the same observation sequence and search for that model which
provides the best match. Thus, calculating the total observation probability provides
a solution to the evaluation problem of HMM, that is,
GIVEN the observation sequence YT and HMM parameters Σ, FIND the total obser-
vation probability Pr(YT) for YT = {y(0), … , y(T)}.
The observation probability is obtained by marginalizing (summing over) the total
probability
Pr(Yt) =
∑
Xt
Pr(Yt, Xt) =
∑
Xt
( t∏
k=0
Pr(y(k)|x(k)) ×
t∏
k=2
Pr(x(k)|x(k −1)) × Pr(x(0))
)
(9.9)
3 Classical notation: �o →Pr(x(0)); aij →Pr(xj(t)|xi(t −1)); and bi(y(t)) →Pr(y(t)|xi(t)) (continuous obser-
vation) or bij →Pr(yj(t)|xi(t)) (discrete observation).

374
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
HMM 
(Sequence est.)
HMM 
(Parameter est.)
(a)
(b)
(c)
(
)
Pr
(0)
x
XT
T
X
T
X
ˆT
X
(
)
Pr
(0)
x
(
)
Pr
(0)
x
T
Y
T
Y
YT → Pr(YT)
(IC)
(IC)
(IC)
(Observations)
(Observations)
(Observations)
(States)
(States)
{
}
ˆ
ˆ
ˆ
ˆ
,
, Pr( (0))
mn
kl
a
c
x
Θ =
(Parameters)
(Unknown states)
(Known states)
HMM 
(Evaluation)
FIGURE 9.3
HMM basic problems: (a) evaluation problem; (b) sequence estimation
problem; (c) parameter estimation problem.
Blindly computing this summation is a very ineficient method to estimate the
desired probability. Instead, we factor the states using their irst-order Markov prop-
erty (conditional independence) such that
Pr(Yt) =
∑
x(t),x(t−1)
Pr(Yt, x(t), x(t −1))
(9.10)
but continuing the expansion over Yt we have
Pr(Yt, x(t), x(t −1)) = Pr(Yt−1, x(t −1), y(t), x(t))
= Pr(y(t), x(t)|Yt−1, x(t −1)) × Pr(x(t −1), Yt−1)
or
Pr(Yt, x(t), x(t −1)) = Pr(y(t)|x(t), Yt−1, x(t −1)) × Pr(x(t)|Yt−1, x(t −1))
× Pr(x(t −1), Yt−1)

9.4
HMM OBSERVATION PROBABILITY: EVALUATION PROBLEM
375
which yields the inal expression
Pr(Yt, x(t), x(t −1)) = Pr(y(t)|x(t)) × Pr(x(t)|x(t −1)) × Pr(Yt−1, x(t −1))
(9.11)
Marginalizing, we obtain
Pr(Yt, x(t)) =
∑
x(t−1)
Pr(Yt, x(t), x(t −1))
=
∑
x(t−1)
Pr(y(t)|x(t)) × Pr(x(t)|x(t −1)) × Pr(Yt−1, x(t −1))
(9.12)
Deine the forward operator as F(t) := Pr(Yt, x(t) = ), then rewriting Eq. 9.11
we have
Fk(t) = Pr(Yt, xk(t))
= Pr(y(t)|xk(t))
∑
�
Pr(xk(t)|x�(t −1)) × Pr(Yt−1, x�(t −1))
or substituting for the previous time step, we obtain the forward recursion for the
HMM
Fk(t) = Pr(y(t)|xk(t))
∑
�
Pr(xk(t)|x�(t −1)) × F�(t −1))
(9.13)
Now, if we assume a stationary chain, then A = [ak�], C = [ck�], and this result can
be expressed in terms of transition probabilities simply as
Fk(t) =
∑
�
ak�× ck�× F�(t −1)
for ck�= Pr(y�(T)|xk(T))
(9.14)
Clearly marginalizing over x(t) gives the total observation probability as
Pr(YT) =
∑
k
Fk(T) =
∑
xk(t)
Pr(YT, xk(t))
(9.15)
Thus, we have the forward recursion algorithm for HMM that can be used to
obtain the total observation probability as
r Initialize:
Fk(0) = Pr(xk(0)) × ck0;
r Recursion:
Fk(t) = ∑
�ak�× ck�× F�(t −1);
r Termination:
Pr(YT) = ∑
k Fk(T).
This algorithm will be used not only to estimate the observation probability as
the solution to the evaluation problem, but also to combine with another recursion to
estimate model states and parameters.

376
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
Before we close this section, consider the following example of simulating an
HMM.
Example 9.2
Suppose we have a discrete binary signal with the two states (Nx = 2) speciied by
{x1(t) = 1, x2(t) = 2}. The observation is also discrete with Ny = 3 and speciied by
{y1(t) = 1, y2(t) = 2, y3(t) = 3}. The transition and observation probabilities are given
by
amn = Pr(xn(t)|xm(t −1));
m, n = 1, 2
and
ckn = Pr(yk(t)|xn(t)); k = 1, 2, 3
with amn = {0.6, 0.4; 0.3, 0.7} and ckn = {0.50, 0.25, 0.25; 0.35, 0.25, 0.40}. Construct
the state-transition probability matrix A and the corresponding directed graph. The
transition probability is given by
A =
[
0.6
0.4
0.3
0.7
]
;
C =
[
0.50
0.25
0.25
0.35
0.25
0.40
]
(9.16)
The resulting directed graph is identical to that in Fig. 9.1. The transition proba-
bility implies that once a particular state is occupied, it is more than likely to remain
in that state since a11 = 0.6 and a22 = 0.7 rather than transition to the other states,
a12 = 0.4 and a21 = 0.3. So we expect the state transitions to essentially have longer
time steps with fewer transitions. The observation probability on the other hand seems
almost equally likely to transition with c11 = 0.5 implying that when occupying state
1 it is most probable that the observation output will be 1 with c23 = 0.4 next, that is,
if in state 2 then the output 3 is most likely.
Using MATLAB a simulation was performed for 100 samples with the results
shown in Fig. 9.4. The state transitions are shown in Fig. 9.4a and appear to conform
the intuition afforded by the transition probability, while the observations also follow
as well. The evaluation problem can be solved by estimating the corresponding total
observation probability which is ln Pr(YT) = −106 and then making additional runs
with various HMM for comparison.
△△△
9.5
STATE ESTIMATION IN HMM: THE VITERBI TECHNIQUE
In this section we develop solutions to the state estimation problem for two cases
of interest: (1) individual hidden state estimation, that is, the state estimate at a
given time step; and (2) entire sequence or “all” time-steps hidden state estimation
problem. Both these problems lead to reconstructing the entire sequence of hidden
states strictly from the observations and HMM. Think of receiving a signal and being
asked to retrieve or recognize the individual symbols from a coded sequence. Here the

9.5
STATE ESTIMATION IN HMM: THE VITERBI TECHNIQUE
377
0
10
20
30
40
50
60
70
80
90
100
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
State
Sample no. 
0
10
20
30
40
50
60
70
80
90
100
0
0.5
1
1.5
2
2.5
3
Value
Sample no. 
(a)
(b)
State sequence 
Observation sequence 
FIGURE 9.4
HMM realization of a discrete two-state Markov chain and observa-
tion: (a) hidden state simulation; (b) observation simulation. Note that both states/
observations can assume only integer values governed by the transition and observa-
tion probabilities.
hidden states are the embedded sequence and the observations are the noisy digitized
measurements.
9.5.1
Individual Hidden State Estimation
State estimation in HMM provides a methodology by which the hidden variables or
states embedded within the HMM can be extracted from knowledge of the model
parameters Σ and the noisy observations as illustrated in Fig. 9.3b. The basic problem
to be solved is:
GIVEN the observation sequence, YT and HMM parameters Σ, FIND the “best”
(MAP) estimate ̂xk(t) of the hidden state at time t based on the posterior distribution
Pr(xk(t)|YT), that is,
̂xk(t) = arg max
xk Pr(xk(t)|YT)
for xk(t) ⇔x(t) = k

378
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
The solution to this estimation problem is analogous to the forward recursion algo-
rithm and incorporates the so-called backward algorithm, since it proceeds sequen-
tially backwards in time (smoothing). The solution which follows is accomplished by
decomposing or partitioning the total observation sequence into two subsequences:
Yt = {y(0), … , y(t)} and Yt + 1:T := {y(t + 1), … , y(T)}. To see this let us investigate
the solution to the state estimation problem assuming uninformative priors
Pr(xk(t)|YT) = Pr(YT, xk(t))
Pr(YT)
∝Pr(YT, xk(t))
(9.17)
PartitioningYT as above we haveYT = {Yt, Yt+1:T} which can be used to decompose
the joint distribution as
Pr(YT, xk(t)) = Pr(Yt, Yt+1:T, xk(t)) = Pr(Yt, xk(t)) × Pr(Yt+1:T|Yt, xk(t))
Applying the Markov property along with the conditional independence properties
of the HMM, we have
Pr(YT, xk(t)) = Pr(Yt, xk(t)) × Pr(Yt+1:T|xk(t))
(9.18)
Deining the backward operator as k(t) := Pr(Yt+1:T|xk(t)) we can write the
marginalization
Pr(Yt+1:T|xk(t)) =
∑
x�(t+1)
Pr(x�(t + 1), y(t + 1), Yt+2:T|xk(t))
(9.19)
and applying Bayes’ rule
Pr(Yt+1:T|xk(t)) =
∑
x�(t+1)
Pr(Yt+2:T|x�(t + 1), y(t + 1), xk(t))
× Pr(y(t + 1), x�(t + 1)|xk(t))
Now using the Markovian independence properties of the HMM and expanding the
last term using Bayes’ rule, we obtain
Pr(Yt+1:T|xk(t)) =
∑
x�(t+1)
Pr(Yt+2:T|x�(t + 1))
× Pr(y(t + 1)|x�(t + 1)) × Pr(x�(t + 1)|xk(t))
Using the deinition of the backward operator, we obtain the inal backward recursion
as
k(t) =
∑
�
ak�Pr(y(t + 1)|x�(t + 1))�(t + 1)
for t = T −1, T −2 … , 1, 0
(9.20)

9.5
STATE ESTIMATION IN HMM: THE VITERBI TECHNIQUE
379
with k(0) = 1∀k. This relation, when coupled with the forward operator can also be
used to calculate the desired posterior probability for state estimation, since
Pr(YT, xk(t)) = Pr(Yt, xk(t)) × k(t) = Fk(t) × k(t)
(9.21)
Thus, we have by marginalization that the total observation probability can be esti-
mated by
Pr(YT) =
∑
k
Fk(T) × k(t)
(9.22)
and therefore the posterior distribution is given by
Pr(xk(t)|YT) =
Fk(t) × k(t)
∑
k Fk(T) × k(t)
(9.23)
leading to the desired state estimate ̂xMAP(t).
With this information available, we now have the solution to the individual hidden
state estimation problem using the backward recursion algorithm as
r Initialize:
k(0) = 1∀k;
r Recursion:
k(t) = ∑
�ak�Pr(y(t + 1)|x(t + 1)�(t + 1);
r Termination:
Pr(YT) = ∑
k Fk(T) × k(t);
r Posterior:
Pr(xk(t)|YT) = Fk(t)×k(t)
Pr(YT)
; and
r Estimation:
̂xk(t) = arg max
xk
Pr(xk(t)|YT).
Together the forward–backward recursions are the key ingredient to estimating the
HMM parameters from noisy observation data as well which will be discussed sub-
sequently, but irst we consider extending the MAP state estimation for the individual
state (̂xk(t)) to the problem of estimating the entire sequence of hidden states ( ̂XT)
from the observation data (YT).
An example follows to demonstrate the forward–backward recursion in estimating
the posterior distribution.
Example 9.3
Suppose we have the discrete binary signal (Nx = 2) speciied by {x1(t) = 1, x2(t) = 2}
and the discrete observation speciied by {y1(t) = 1, y2(t) = 2, y3(t) = 3}. Here we
attempt to “decode” the message from the observations, that is, consider the binary
state sequence generated by the HMM along with the corresponding the observations
and we wish to extract the coded state sequence at each time step using the forward–
backward approach discussed above.
We apply MATLAB (hmmdecode) to perform the estimation using the forward–
backward approach for the 100 observation samples. Using the synthesized output

380
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
0
10
20
30
40
50
60
70
80
90
100
0
0.5
1
1.5
2
Hidden state simulation 
State
Sample no.
0
10
20
30
40
50
60
70
80
90
100
0
0.2
0.4
0.6
0.8
1
Sample no.
0
10
20
30
40
50
60
70
80
90
100
0
0.2
0.4
0.6
0.8
1
Posterior state
Sample no.
(a)
(b)
(c)
Posterior probability (Pr(X (t)|Y )): state no. 1
Posterior probability (Pr(X (t)|Y )): state no. 2
Posterior state
FIGURE 9.5
HMM realization of a discrete two-state Markov chain and observation: (a)
hidden state sequence realization; (b) state 1 posterior probability estimate ̂Pr(x1(t)|Yt);
(c) state 2 posterior probability estimate ̂Pr(x2(t)|Yt).
data and corresponding transition and observation probability matrices, we can esti-
mate the corresponding posterior distribution for each individual state Pr(xk(t)|Yt)
with the results shown in Fig. 9.5. The combined state transitions are shown in
Fig. 9.5a and the posterior state probabilities in Figs. 9.5b and 9.5c, respectively. We
can see that the estimated probabilities “match” the states reasonably well with the
state transitioning according to the estimated posterior at each time step, that is, when
the HMM is in state 1, the posterior probability is high relative to that of state 2 and
visa versa. This completes the decoding example. Next we consider estimating the
entire state sequence.
△△△
9.5.2
Entire Hidden State Sequence Estimation
The maximum a posteriori estimation of the state at time t using the forward–
backward recursion algorithm above can be extended to reconstruct the entire

9.5
STATE ESTIMATION IN HMM: THE VITERBI TECHNIQUE
381
hidden state sequence which provides a more meaningful solution when attempt-
ing to extract a critical coded message from a hostile environment or accurately
extracting a DNA sequence for forensic analysis. Unfortunately, estimating the indi-
vidually “most likely” states as in the previous subsection does not imply that the
entire sequence is estimated with minimal probability of error. Therefore, the state
estimation problem must be based on jointly estimating “all” states in the sequence
to obtain the optimal solution. The individual state estimates at each time step of
the forward–backward algorithm minimize the error probabilities of individual states
maximizing the expected number of correctly estimated states [16]. However, we are
interested in estimating the entire state sequence, that is, we would like to solve the
following problem:
GIVEN the observation sequence YT and HMM parameters Σ, FIND the “best”
(MAP) estimate the sequence ̂XT where ̂XT = {̂xk(0), … , ̂xk(T)} of the entire hidden
state sequence from time-step 0 to time-step T based on the posterior distribution
Pr(XT|YT), that is,
̂XT = arg max
XT
Pr(XT|YT)
Since we are seeking a sequential solution to this problem, we must track the
estimate at time-step t. Following the development in [16], for each x(t) a partial
sequence of length t + 1 is deined for each possible state; therefore, there are Nx
partial sequences for each t. An alternative is to use the joint distribution, since the
observation sequence is ixed in length YT, that is, we require
̂Xt−1 = arg max
Xt−1
Pr(Xt−1, x(t), Yt)
for x(t) endpoint
(9.24)
At each time step, the maximal path (Xt−1) problem terminating in x(t) given Yt is
transformed into the maximization problem of inding the best path ending in x(t + 1)
given Yt+1. This follows directly by applying the chain rule to the joint probability
distribution
Pr(Xt+1, Yt+1) = Pr(x(t + 1), Xt, y(t + 1), Yt)
= Pr(x(t + 1), y(t + 1)|Xt, Yt) × Pr(Xt, Yt)
(9.25)
applying Bayes’ rule along with the conditional independence properties of the chain
gives
Pr(Xt+1, Yt+1) = Pr(y(t + 1)|x(t + 1)) × Pr(x(t + 1)|x(t)) × Pr(Xt, Yt)
(9.26)
Recursively maximizing the probability gives
max
Xt
Pr(Xt+1, Yt+1) = max
Xt
{Pr(y(t + 1)|x(t + 1)) × Pr(x(t + 1)|x(t)) × Pr(Xt, Yt)}
= Pr(y(t + 1)|x(t + 1)) × max
Xt
{Pr(x(t + 1)|x(t)) × Pr(Xt, Yt)}

382
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
= Pr(y(t + 1)|x(t + 1)) × max
x(t)
{
Pr(x(t + 1)|x(t))
× max
Xt−1
{Pr(Xt, Yt)}}
Now this gives us a recursion with (x(t)) := max
Xt−1
{Pr(Xt, Yt)}
(x(t + 1)) = Pr(y(t + 1)|x(t + 1)) × arg max
x(t) {Pr(x(t + 1)|x(t)) × (x(t))}
(9.27)
Deining the smoothing variable as
U(x(t)) := max
Xt−1
{Pr(x(t + 1)|x(t)) × (x(t))}
(9.28)
enables us to construct the entire state (sequence) estimation or equivalently the
Viterbi algorithm as [16]:
r Initialize:
(x(0)) = Pr(x(0)), Pr(y(0)|x(0))
U(x(0)) = 0
for x(0) = 1, … , Nx
r Recursion:
(x(t)) = Pr(y(t)|x(t)) × max
x(t−1){Pr(x(t)|x(t −1)) × (x(t −1))}
U(x(t)) = max
x(t−1){Pr(x(t)|x(t −1)) × (x(t −1))}
for x(t) = 1, … , Nx;
t = 2, … , T
r Termination:
P = max
x(T) {(x(T))}
̂x(T|T) = arg max
x(T) {(x(T))}
r Smoothing: ̂x(t|T) = U(̂x(t + 1)|T)
for t = T −1, T −2, … , 0
The Viterbi algorithm uses these recursions and smoothing relations to estimate
the “optimal path” and has the same order of operations as the forward algorithm
discussed in the previous section. It has proved to be an extremely popular and robust
algorithm to perform decoding. Consider the following example of a path estimate.

9.5
STATE ESTIMATION IN HMM: THE VITERBI TECHNIQUE
383
0
10
20
30
40
50
60
70
80
90
100
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Sample no.
State estimate
Most likely state sequence: Viterbi path 
True state
Est. state
FIGURE 9.6
HMM realization of a discrete two-state Markov chain sequence and
the results of the Viterbi path estimation with an 52% match (estimated-to-actual
states).
Example 9.4
Using the discrete binary signal and observation of the previous example we would
like to “decode” the entire message from the observations, that is, we wish to extract
the “entire” coded sequence at each time step using the Viterbi approach discussed
above.
We apply MATLAB (hmmviterbi) to perform the optimal entire state sequence
(path) estimation using the Viterbi algorithm for the 100 observation samples. Using
the synthesized output data and corresponding transition and observation probability
matrices, as before, we obtain the estimation results shown in Fig. 9.6. Here we
can observe the path (dark solid line) which corresponds to the sequence estimation.
Note that it is a simple path but contains most of the states and leads directly to the
desired result. The matching capability of this approach is captured by estimating the
percentage of the time that the actual sequence agrees with the estimated. For this
simulation, the estimated matches the actual sequence 52% of the time.
△△△
This completes the state sequence estimation example, next we consider estimating
the model parameters.

384
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
9.6
PARAMETER ESTIMATION IN HMM: THE EM/BAUM–WELCH
TECHNIQUE
The most challenging problem in HMM is the development of the model in the irst
place. Just as in dynamic (physical) systems theory [17, 18], the system identiica-
tion/parameter estimation problem is still a highly researched problem especially for
nonlinear systems. The basic estimation problem consists of two major issues: (1)
estimation of the underlying internal structure (interconnections, state assignments,
etc.); and (2) HMM parameter estimation consisting of the transition and observa-
tion probabilities and initial conditions assuming that the internal structure of (1) is
known a priori.
For dynamic physical systems, the identiication of the internal structural model
usually evolves from irst principles where relations governing the phenomenology
are assembled. For nonphysical systems, parametric models (with interconnections)
are assumed (e.g., ARMA) and then the solution to the parameter estimation problem
follows [19]. HMM are very similar from this perspective. Their structure is developed
from an internal probabilistic representation that is application driven. For instance,
the well-known problem in signal processing of recovering a transmitted random
telegraph signal from noisy observations is representative. Here the problem is to
“decode” the signal into a sequence of zeros or ones with the probability distribution of
the transitions (zero-to-one) assumed known (Poisson). An HMM can be structurally
developed to model this problem quite easily [2]. Another example is the decoding
of DNA strings for forensic analysis. Here the same modeling principle applies to
develop the internal structural model [5]. In any case developing the internal model is
usually the task of the phenomenologist, whether a physical or nonphysical system,
and the next step is to “it” the parameters of this structure to the model—the primary
focus of this section. Thus, we discuss the development of the parameter estimation
techniques applied to estimate the parameters of an HMM. Here we assume the
number of states and measurements are known along with the internal structure and
the problem becomes a matter of “itting” these well-deined parameters (transition
probabilities, observation probabilities, and initial conditions) to the known model
internal structure.
Parameter estimation for HMM has been a dificult and challenging problem,
especially in an on-line environment [1]. The original efforts of Baum–Welch [20]
have led to the general expectation-maximization (EM) algorithm (see Chapter 2)
which is a very powerful iterative approach using likelihood estimation techniques to
solve this problem [21, 22]. Here we briely outline the iterative approach and then
show how the algorithm is a special case of EM.
The basic HMM parameter estimation problem is (see Fig. 9.3c):
GIVEN a set or J-sets4 of observation sequences {Yt(j)}; j = 1, … , J along with
the underlying HMM internal structure Σ, FIND the “best” (MAP) estimate of the
4 These sets are called training sets, a term that evolves from the classiication/neural-net technical area.

9.6
PARAMETER ESTIMATION IN HMM: THE EM/BAUM–WELCH TECHNIQUE
385
underlying parameters ̂ΘMAP := {amn, ck�, P(0)} maximizing the posterior distribu-
tion Pr(Θ|Yt).
We will discuss this problem in two parts: (1) state sequence is known a priori;
and (2) state sequence is unknown [5].
9.6.1
Parameter Estimation with State Sequence Known
When the state sequence is “known” a priori, then the parameter estimation problem
is much simpler as in the case of physical systems for the design of optimal inputs
for system identiication [18].
We deine the following posterior probability
mn(t, t + 1) := Pr(xm(t), xn(t + 1)|YT, Θ)
This posterior is the probability of the joint event that a path (state sequence) passes
through state m at time-step t and through state n at t + 1 and the HMM generates a
sequence of observations YT given the model parameters Θ.
To analyze this probability further we apply Bayes’ rule and then partition the data
as before
mn(t, t + 1) = Pr(xm(t), xn(t + 1), YT|Θ)
Pr(YT|Θ)
= Pr(xm(t), xn(t + 1), Yt, Yt+1:T|Θ)
Pr(YT|Θ)
(9.29)
now applying Bayes’ rule to the numerator results in
Pr(xm(t), xn(t + 1), Yt, Yt+1:T|Θ) = Pr(xn(t + 1), Yt+1:T|Yt, xm(t), Θ)
× Pr(Yt, xm(t)|Θ)
(9.30)
The last term is just Fm(t), the forward operator (with the parameter set Θ given).
Now concentrating on the remaining term of this expression, we extract y(t + 1) from
the data term and apply Bayes’ rule again to obtain
Pr(xn(t + 1), y(t + 1), Yt+2:T|Yt, xm(t), Θ)
= Pr(Yt+2:T|xn(t + 1), y(t + 1), Yt, xm(t), Θ)
× Pr(xn(t + 1), y(t + 1)|Yt, xm(t), Θ)
(9.31)
where the last term above decomposes further to
Pr(xn(t + 1), y(t + 1)|Yt, xm(t), Θ) = Pr(y(t + 1)|xn(t + 1), Yt, xm(t), Θ)
× Pr(xn(t + 1)|xm(t), Yt, Θ)
(9.32)

386
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
enabling us to simplify each of these terms individually to yield
Pr(Yt+2:T|xn(t + 1), y(t + 1), Yt, xm(t), Θ) →Pr(Yt+2:T|xn(t + 1), Θ)
Pr(xn(t + 1), y(t + 1)|Yt, xm(t), Θ) →Pr(y(t + 1)|xn(t + 1), Θ)
× Pr(xn(t + 1)|xm(t), Θ)
(9.33)
and therefore we obtain the expression
mn(t, t + 1) = Pr(Yt, xm(t)) × Pr(xn(t + 1)|xm(t), Θ)
× Pr(y(t + 1)|xn(t + 1), Θ) × Pr(Yt+2:T|xn(t + 1), Θ)∕Pr(YT|Θ)
Finally, substituting for the known parameters, we have the desired result
mn(t, t + 1) = Fm(t) × amn × ckn × n(t + 1)
Pr(YT|Θ)
(9.34)
where Fk(t) encompasses the past history ending at time t and state m while n(t + 1)
accounts for the path’s future which at time t + 1 is at state n evolving until the end.
The product term (amn × ckn) takes into account the current activity at t with discrete
observation yk(t + 1) →y(t + 1).
With this term determined, we then deine the posterior distribution from Eq. 9.23
as
m(t) := Pr(xm(t)|YT)
(9.35)
which is a probability of the joint event that a path passes through state m at time-step t
and the HMM generates a sequence of observations YT given the model parameters Θ.
Note that both probabilities are related, since one can be obtained through
marginalization of the other
m(t) =
Nx
∑
n=1
mn(t, t + 1)
(9.36)
Summing both these quantities “across time” enables us to obtain the expected number
of times in state m and the expected number of transitions away from state m for Y
(see Ref. [15] for more details)
T−1
∑
t=1
m(t)
(9.37)

9.6
PARAMETER ESTIMATION IN HMM: THE EM/BAUM–WELCH TECHNIQUE
387
Similarly, the expected number of transitions from state m to state n for Y is given
by
T−1
∑
t=1
mn(t)
(9.38)
Thus, using these expectations and counting estimation of probabilities [5], we are
able to obtain the Baum–Welch estimates
̂Pm(0) = m(1)
̂amn =
∑T−1
t=1 mn(t)
∑T−1
t=1 m(t)
̂ckn =
∑T
t=1 mn(t)
∑T
t=1 m(t)
such that y(t) = k
(9.39)
where
Pm(0)
is the expected number of times in state xn(t) at t = 1;
amn
is the expected number of transitions from state xm(t) to state xn(t) over
the expected transitions in state xm(t); and
ckn
is the expected number of times in state xn(t) and observing yk(t) over
the expected number of times in state xn(t).
Thus, when all of the paths are known (this case), it is possible to count the number
of times each particular transition or output observation is applied in a set of training
data. It has been shown that counting functions, say Nmn(x(t)) for the state transitions
and Nkn(y(t)) for the output observations, provide maximum likelihood estimates for
the desired model parameters [5], such that
̂amn =
Nmn(x(t))
∑
n Nmn(x(t))
and
̂ckn =
Nkn(y(t))
∑
n Nkn(y(t))
(9.40)
Next we consider the unknown path case and combine the above results to establish
the algorithm.
9.6.2
Parameter Estimation with State Sequence Unknown
In this section we consider the case where the state sequence is “not known” [5]
and must be determined using the current parameter estimates available. When the
paths are unknown for training sequences, a closed-form equation is nonexistent
and therefore some type of iterative approach must be applied (e.g., EM [22–30]).
The EM/Baum–Welch approach precisely solves the HMM parameter estimation

388
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
problem in an iterative manner. It irst estimates the counting functions Nmn(x(t)) for
states and Nkn(y(t)) for observations by considering possible paths for the training
sequences using current model parameters Θ and then calculates the new estimates
using Eq. 9.40. The algorithm continues to iterate until the log-likelihood function
ln Pr(YT|Θ) no longer increases with each iteration. Baum [20] has shown that the
overall log-likelihood increases with each iteration indicating convergence to a local
maximum.
More precisely, this technique estimates the counting functions Nmn(x(t)) and
Nkn(y(t)) as the expected number of times each transition or output is utilized from
the given training sequences. It also uses the identical forward/backward operators
as before (see Section 9.5) using the posterior probability mn(t, t + 1) of Eq. 9.34.
From this relation, we can derive the expected number of times that amn is used by
summing over all possible positions and over all training sequences YT(j); j = 1, … , J.
We can also use the training sequences to derive the expected number of times the
observation occurs to obtain
Nmn(x(t)) =
∑
j
1
Pr(YT|Θ)
∑
t
Fm(t, j) × amn × ckn × n(t + 1, j)
Nk�(y(t)) =
∑
j
1
Pr(YT|Θ)
∑
t
Fk(t, j) × k(t, j)
(9.41)
Once these expectations are estimated, the model parameters are updated as above
and these new estimates are used in the counting functions. We summarize the
EM/Baum–Welch algorithm as:
r Initialization: ̂Θ0, Nmn(x(t)) and Nk�(y(t));
r Forward/backward recursions: Fk(t, j) and k(t, j) of Eqs. 9.12 and 9.20;
r Counting functions: Nmn(x(t)) and Nk�(y(t)) of Eq. 9.41;
r Parameter estimation: ̂Θ = {amn, ckn, P(x(0))} of Eq. 9.40;
r Likelihood: Pr(YT| ̂Θ); and
r Termination: Pr(YT| ̂Θ) < �for �a threshold.
This completes the algorithm. It should be noted that an alternative approach
to searching over all paths is to use the Viterbi paths providing the most probable
paths for all of the training sequences. However, this approach does not maximize
the true likelihood. It is known that Viterbi training does not perform as well as the
Baum–Welch, but it is still popular when applied to decoding problems.
There are also a number of techniques that practitioners use to enhance numerical
performance and convergence of this technique. These include: (1) logarithmic trans-
formation of the product probabilities to create sums [5]; (2) scaling both forward
and backward operators [10]; (3) initial conditions; and (4) training data issues [23].
In closing, we note that the Baum–Welch algorithm is just a special case of the EM

9.6
PARAMETER ESTIMATION IN HMM: THE EM/BAUM–WELCH TECHNIQUE
389
algorithm of Section 2.3. That is, the E-step of the EM algorithm is given by [15]
E-step:Q(Θ, ̂Θi−1) =
∑
x
ln Pr(x|YT, Θ) × Pr(x|YT, ̂Θi−1)
=
∑
x
ln ̂P(x(0))Pr(YT, x(t)| ̂Θ) +
∑
x
( T
∑
t=1
ln ̂amn(t −1, t)
)
× Pr(YT, x(t)| ̂Θ) +
∑
x
( T
∑
t=1
ln ̂ckn(t, t)
)
× Pr(YT, x(t)| ̂Θ)
(9.42)
where Pr(YT, x(t)| ̂Θ) = P(x(0)) ∏T
t=0 ̂ckn(t, t) × ∏T
t=1 ̂amn(t, t + 1). Optimizing these
terms leads precisely to the expressions in Eq. 9.39 (see Ref. [10] or [15] for details).
Thus, the E-step of the EM consists of estimating the required expectations using the
forward/backward recursions which completely determines Q(Θ, ̂Θ) and the maxi-
mum (M-step) consists of substituting these terms into the corresponding likelihood.
Example 9.5
Again using discrete binary signal and the discrete observation of the previous exam-
ples, we perform the parameter estimation of the transition and observation prob-
abilities, irst using the “known” (actual) state sequence and then generating an
ensemble of training sequences (N = 25) to perform the EM/Baum–Welch algorithm
(hmmtrain) with a maximum of 500 iterations and a error tolerance of 1 × 10−4. Here,
we also use the MATLAB maximum likelihood estimation with the “known” state
sequence (hmmestimate) as well to compare performance. The resulting parameter
estimates and percentage errors are:
EM/BAUM–WELCH PARAMETER ESTIMATES
ATRU =
[
0.6
0.4
0.3
0.7
]
;
CTRU =
[
0.50
0.25
0.25
0.35
0.25
0.40
]
̂ABW =
[
0.62
0.38
0.30
0.7
]
;
A%ERR =
[
3
4
0
0
]
̂CBW =
[
0.51
0.29
0.19
0.34
0.22
0.44
]
;
C%ERR =
[
3
18
23
3
13
11
]
Thus, the parameter estimates are quite reasonable under these conditions. Note
the initial probability matrices are automatically established by this implementation
in MATLAB; however, it is possible to alter them if desired.
MAXIMUM LIKELIHOOD PARAMETER ESTIMATES
ATRU =
[
0.6
0.4
0.3
0.7
]
;
CTRU =
[
0.50
0.25
0.25
0.35
0.25
0.40
]

390
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
̂AML =
[
0.67
0.33
0.36
0.64
]
;
A%ERR =
[
12
18
21
9
]
̂CML =
[
0.45
0.23
0.32
0.47
0.19
0.34
]
;
C%ERR =
[
9
9
28
34
23
15
]
Again the estimates appear quite reasonable. Longer sequences can be employed
to improve the estimates even further. We see that there is a distinct advantage when
the state sequence is known a priori, because the training sequences are not required.
The Viterbi initialization was also executed on this data, but it did not perform near
as well as the Baum–Welch technique.
△△△
This completes the section, next we consider a case study.
9.7
CASE STUDY: TIME-REVERSAL DECODING
In this section, we consider applying the Viterbi algorithm to decode a message trans-
mitted through a hostile environment with reverberations along with the processor
and decoding algorithm. Acoustic time-reversal (T/R) communications is an applica-
tion area motivated by the recent theoretical advances in T/R theory [30]. Although
perceived by many in signal processing as simply an application of matched-ilter
theory, a T/R receiver offers an interesting solution to the communications problem
for a highly reverberant channel. This case study briely describes an acoustic com-
munications experiment of data gathered in air and its associated signal processing.
The experiment is developed to evaluate the performance of a point-to-point T/R
receiver designed to extract a transmitted code information sequence propagating in
a hostile, highly reverberant environment. These results are merely used to “synthe-
size” an HMM based on the raw/quantized acoustic measurements and then used
to extract the transition and observation probabilities for simulation and evaluation.
Even though this case study is based on real data, it is only chosen to illustrate the
application of HMM techniques after data is simulated through the HMM process
(evaluation).
From a signal processing perspective, T/R processing appears to be an application
of matched iltering in which the output signal-to-noise ratio (SNR) is maximized.
This T/R replicant is then cross-correlated with the noisy received signal to pro-
duce the optimal iltered output [31]. However, it becomes more complicated in the
spatiotemporal case in which the optimal matched ilter must not only match the
transmitted temporal function, but also the corresponding spatiotemporal channel
medium impulse response or the so-called Green’s function. It has been shown that
T/R techniques are applicable to spatiotemporal phenomena that satisfy a wave-type
equation possessing the T/R invariance property [30]. Thus, T/R is the dynamic
broadband analog of the well-known phase conjugate mirror used to focus narrow-
band monochromatic waves. It represents the “optimal” spatiotemporal matched ilter
in the sense of maximizing the output SNR. It is essentially a technique which can be
used to “remove” the aberrations created by an inhomogeneous or random channel.

9.7
CASE STUDY: TIME-REVERSAL DECODING
391
In communications, the T/R receiver can overcome the inherent noise created by the
medium providing the enhancement required to extract the transmitted information
sequence. Here we ignore the array aspects of T/R by considering only point-to-point
communications. In this case study the realization of a T/R receiver is briely dis-
cussed and applied to a noisy microphone measurement in a hostile environment. It
is then used to estimate the required transition and observation matrices for eventual
synthesis/analysis.
For T/R, the matched ilter in additive white noise is identical to that posed above
with a “known” Green’s function of the medium replacing the known signal replicant
[31]. The Green’s function g(r, ro; t) is the result of a point-to-point communication
link between a station (source) at ro to a master station (receiver) at r. In this case, the
matched-ilter solution is again found by maximizing SNRout leading to the solution
that is satisied with equality at some time T. If the resulting ilter response is f(t)
then the solution is given by
f(t) = g(r, ro; T −t)
(9.43)
Thus, for T/R, the optimal matched-ilter solution is the time-reversed Green’s
function from the link station-to-master station (source-to-receiver) or visa versa.
Comparing these results with the standard matched-ilter solution found in the litera-
ture, the Green’s function of the channel is time reversed rather than the transmitted
replicant signal as in radar or sonar. Note that since T/R theory requires reciprocity
[30], the result of Eq. 9.43 is valid for both transmission and reception, that is,
g(r, ro; T −t) ↔g(ro, r; T −t). Note also that if an array is included to sample the
spatial ield or transmit a wave, then these results include the focus at link sta-
tion (source) position ro yielding the optimal spatiotemporal matched-ilter solution
g(r�, ro; T −t) at sensor position r�.
So we see that in transmitting a coded signal (state sequence) through a disruptive
medium the distorting effects can be mitigated by time reversing the estimated media
Green’s function and creating an effective receiver. The details of this mechanism are
discussed in Refs. [31–33] and is beyond the scope of this case study. Here we just
describe one of the variety of receiver types that can be used, once Green’s function
is estimated from pilot signals transmitted from transmitter (speaker) to receiver
(microphone) producing ̂g(r, ro; T −t).
With the estimated Green’s function or impulse response available, we choose to
apply T/R processing on reception [31] to the noisy received data, y(t) = g(r; t) ∗i(t)
with i(t) the coded information (state) sequence. On reception, the estimated Green’s
function is reversed and convolved with the receiver input to give
R(t) = z(t) ∗̂g(r; −t) = g(r; t) ∗i(t) ∗̂g(r; −t) = Cĝg(t) ∗i(t)
(9.44)
where Cĝg is the estimated autocorrelation function of the medium possessing all of
the relection and scattering information—but modiied for code signal enhancement.
We show a typical T/R receiver output that was used to “synthesize” a discrete
state and output sequence for transition and observation probability estimates. We
show the receiver structure in Fig. 9.7a where the time-reversed Green’s function
is convolved with the received data and then quantized to recover the code. Actual

392
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
R(t)
zi(t)
i(t)
g(r;−t)
Transmission
Reception
ˆ
g(r;t)
ˆ
0
10
20
30
40
50
60
70
80
90
100
−1.5
−1
−0.5
0
0.5
1
1.5
2
Raw quantized T/R states and observations
Sample no.
Amplitude
(a)
(b)
State 
Raw 
Absolute value (quantized ) 
measurement 
Information
Receive
Reverse
Green’s function
Information
Channel 
medium
FIGURE 9.7
T/R processor acoustic microphone data: (a) T/R receiver structure;
(b) raw measurement data, synthesized observation and state data input for HMM
parameter estimation.
T/R processed data is shown in Fig. 9.7b along with quantized state and observation
sequence extracted for illustrative purposes and eventual application of the HMM
techniques.
The results of processing these quantized sequences using the EM/Baum–Welch
algorithm are:
EM/BAUM–WELCH PARAMETER ESTIMATES
̂ABW =
[
0.42
0.58
0.28
0.72
]
;
̂CBW =
[
1
0
0.22
0.78
]
Next we used these extracted probability matrices to synthesize “realistic” T/R
data for HMM processing, the results are shown in Fig. 9.8. With this available we

9.7
CASE STUDY: TIME-REVERSAL DECODING
393
0
10
20
30
40
50
60
70
80
90
100
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
States
Sample no.
0
10
20
30
40
50
60
70
80
90
100
0
0.5
1
1.5
2
2.5
3
Observation sequence
Observation
Sample no.
State sequence
FIGURE 9.8
HMM realization of the T/R discrete Markov chain and observation:
(a) hidden state sequence realization; (b) observation realization.
proceed as before and estimate the individual states as depicted by the posterior
probabilities in Fig. 9.9. These results are quite reasonable as can be observed by
comparing samples with the aligned probability functions at each time step. Next the
entire state sequence was estimated using the “most likely” Viterbi approach and the
results are illustrated in Fig. 9.10, where both the actual (synthesized time-reversed)
state sequences are shown along with the Viterbi result superimposed. The agreement
is quite good with an 85% matching (in time) of the actual with the estimated
states.
With these synthesized probability matrices, we performed the parameter estima-
tion approach as before to give
EM/BAUM–WELCH PARAMETER ESTIMATES
ATRU =
[
0.42
0.58
0.28
0.72
]
;
CTRU =
[
1
0
0.22
0.78
]
̂ABW =
[
0.45
0.55
0.27
0.73
]
;
A%ERR =
[
6
5
4
2
]
̂CBW =
[
1
0
0.24
0.76
]
;
C%ERR =
[
0
0
8
2
]

394
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
0
10
20
30
40
50
60
70
80
90
100
0
0.5
1
1.5
2
Hidden state simulation 
State
Sample no.
0
10
20
30
40
50
60
70
80
90
100
Sample no.
0
10
20
30
40
50
60
70
80
90
100
Sample no.
0
0.2
0.4
0.6
0.8
1
Posterior probability (Pr(X (t)|Y )): state no. 1
Posterior state
Posterior state
0
0.2
0.4
0.6
0.8
1
Posterior probability (Pr(X (t)|Y )): state no. 2
FIGURE 9.9
HMM estimation of the T/R discrete two-state Markov chain and observa-
tion: (a) hidden state sequence realization; (b) state 1 posterior probability estimate
̂Pr(x1(t)|Yt); (c) state 2 posterior probability estimate ̂Pr(x2(t)|Yt).
Thus, the parameter estimates are quite reasonable under these conditions. Note
the initial probability matrices are automatically established by this implementation
in MATLAB; however, it is possible to alter them if desired.
MAXIMUM LIKELIHOOD PARAMETER ESTIMATES
ATRU =
[0.42
0.58
0.28
0.72
]
;
CTRU =
[1
0
0.22
0.78
]
̂AML =
[0.42
0.58
0.29
0.71
]
;
A%ERR =
[0
0
1
1
]
̂CML =
[1
0
0.24
0.76
]
;
C%ERR =
[0
0
11
3
]
The estimates are quite reasonable. We see that there is a distinct advantage when
the state sequence is known a priori, then the training sequences are not required.

9.8
SUMMARY
395
0
10
20
30
40
50
60
70
80
90
100
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Most likely state sequence: Viterbi path
Sample no.
State estimate
True states
Est. states
FIGURE 9.10
Entire state sequence estimation using the Viterbi algorithm illustrating
the most likely path with an 82% match between the actual state sequence and the
estimated.
Again the Viterbi initialization was also executed on this data but it did not perform
very well. This completes the case study.
9.8
SUMMARY
In this chapter we have introduced the concept of HMM and illustrated their internal
characteristics through a state–space representation. We irst developed the concepts
of Markov and hidden Markov chains and showed how they were related. Next, we
investigated properties of the HMM illustrating how the Bayesian concepts easily
transfer over to this discrete representation. We next investigated the three fundamen-
tal problems along with some variations: (1) the evaluation (simulation) problem; (2)
the state estimation problem; and (3) the parameter estimation problem. A careful
analysis of each led us to the popular Viterbi decoding technique and the specialized
EM algorithm popularly called the Baum–Welch technique. We concluded with a
case study to decode a transmitted coded sequence from data enhanced by a T/R
processor.

396
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
MATLAB NOTES
MATLAB has a Statistics Toolbox that incorporates the capability to develop and
process hidden Markov models (HMM) along with demonstrations and a tutorial.
hmmgenerate synthesizes a sequence for an HMM, while the command hmmde-
code calculates the posterior state probabilities of a given sequence (Section 9.3).
The most likely (entire) state path can be estimated using the Viterbi algorithm
of Section 9.5 (hmmviterbi). Training sequences can be used to solve the HMM
parameter estimation problem (Section 9.6) while the EM/Baum–Welch technique
is used to estimate the model parameters using the hmmestimate command. The
PDF estimators include the usual histogram (hist) as well as the sophisticated ker-
nel density estimator (ksdensity) offering a variety of kernel (window) functions
(Gaussian, etc.).
There also exists NETLAB which is a free MATLAB software package that
includes HMM algorithms (see Ref. [24] for details and website). The EM algo-
rithm is well documented [20–22, 25–29] and is an integral part of each of these
packages.
REFERENCES
1. O. Cappe, “Ten years of HMMs,” www.tsi.enst.fr/cappe/docs/hmmmbib, 2001.
2. A. Papoulis and S. Pillai, Probability, Random Variables and Stochastic Processes, 4th
Ed. (Englewood Cliffs, NJ: McGraw-Hill, 2002).
3. R. Hogg, J. McKlean, and A. Craig, Introduction to Mathematical Statistics, 6th Ed.
(Englewood Cliffs, NJ: Prentice-Hall, 2005).
4. D. Bertsekas and J. Tsitsiklis, Introduction to Probability (M.I.T. Lecture Notes, Course
6.041–6.043, 2000).
5. R. Durbin, S. Eddy, A. Krough and G. Mitchison, Biological Sequence Analysis (Cam-
bridge, UK: Cambridge University Press, 1990).
6. D. MacKay, Information Theory, Inference and Learning Algorithms (Cambridge, UK:
Cambridge University Press, 2006).
7. R. Elliott, L. Aggoun, and J. Moore, Hidden Markov Models (New York: Springer, 1994).
8. O. Cappe, E. Moulines, and T. Ryden, Inference in Hidden Markov Models (New York:
Springer-Verlag, 2005).
9. L. Rabiner and B. Juang, “An introduction to hidden Markov models,” IEEE ASSP Mag.,
3, 1, 4–16, 1986.
10. L. Rabiner, “A tutorial on hidden Markov models and selected applications in speech
recognition,” Proc. IEEE, 77, 2, 257–286, 1989.
11. A. Poritz, “Hidden Markov models: A guided tour.” Proc. IEEE Confr. Acoustics, Speech
and Sig. Proc., 7–13, 1988.
12. L. Rabiner and B. Juang, Fundamentals of Speech Recognition (Englewood Cliffs, NJ:
Prentice-Hall, 1993).

REFERENCES
397
13. L. White, “A comparison between optimal and Kalman iltering for hidden Markov pro-
cesses,” IEEE Sig. Proc. Letters, 5, 5, 124–126, 1998.
14. S. Fruhwirth-Schnatter, Finite Mixture and Markov Switching Models (New York:
Springer, 2006).
15. J. Bilmes, “What HMMs Can Do?” Univ. Wash. Elect. Engr., UWEETR-2002-0003, 2002.
16. F. van der Heijden, R. Duin, D. de Ridder, and D. Tax, Classiication, Parameter Estimation
and State Estimation (Hoboken, NJ: John Wiley & Sons, Inc., 2004).
17. G. Goodwin and R. Payne, Dynamic System Identiication (New York: Academic Press,
1976).
18. L. Ljung, System Identiication: Theory for the User (Englewood Cliffs, NJ: Prentice-Hall,
1987).
19. J. Candy, Model-Based Signal Processing (Hoboken, NJ: John Wiley & Sons, Inc./IEEE
Press, 2006).
20. L. Baum, T. Petrie, G. Soules, and N. Weiss, “A maximization technique occurring in the
statistical analysis of probabilistic functions of Markov Chains,” Ann. Math. Statist., 41,
1, 164–171, 1970.
21. G. McLachlan and T. Krishnan, The EM Algorithm and Extensions (Hoboken, NJ: John
Wiley & Sons, Inc., 1997).
22. T. Moon, “The expectation-maximization algorithm,” IEEE Sig. Proc. Mag., 13, 6, 47–60,
1996.
23. S. Theodoridis and K. Koutroumbas, Pattern Recognition (New York: Academic Press,
1999).
24. I. Nabney, NETLAB Algorithms for Pattern Recognition (New York: Springer, 2001).
25. J. Bilmes, “A gentle tutorial of the EM algorithm and its application to parameter estimation
for Gaussian mixture and hidden Markov models,” Internat. Comp. Sci. Instit., TR-97-021,
1998.
26. A. Dempster, N. Laird, and D. Rubin, “Maximum likelihood from incomplete data via the
EM algorithm,” J. R. Statist. Soc., B, 39, 1, 1–38, 1977.
27. R. Duda and P. Hart, Pattern Classiication (New York: John Wiley & Sons, Inc., 2000).
28. C. Wu, “On the convergence properties of the EM algorithm,” Ann. Statist., 11, 1, 95–103,
1983.
29. R. Redner and H. Walker, “Mixture densities, maximum likelihood and the EM algorithm,”
SIAM Rev., 26, 2, 195–239, 1984.
30. M. Fink, “Time reversal in acoustics,” Contemp. Phys., 37, (2), 95–109, 1996.
31. J. Candy, A. Meyer, A. Poggio, and B. Guidry, “Time reversal processing for an acoustic
communications experiment in a hostile reverberant environment,” J. Acoust. Society
Amer., 115, (4), 1621–1631, 2004.
32. J. Candy, A. Poggio, D. Chambers, C. Robbins, and B. Guidry, “Multichannel time reversal
communications a hostile reverberant environment,” J. Acoust. Society Amer., 118, (4),
2339–2354, 2005.
33. J. Candy, D. Chambers, C. Robbins, B. Guidry, A. Poggio, F. Dowla, and C. Hertzog,
“Wideband multichannel time-reversal acoustic communications highly reverberant envi-
ronments,” J. Acoust. Society Amer., 120 (2), 838–851, 2006.
34. G. Kitagawa and W. Gersch, Smoothness Priors Analysis of Time Series (New York:
Springer-Verlag, 1996).

398
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
35. A. Doucet, N. de Freitas, and N. Gordon, Sequential Monte Carlo Methods in Practice
(New York: Springer, 2001).
PROBLEMS
9.1
Suppose we have a noisy binary channel with input (symbol) x and output
(symbol) y such that x ∈= {0, 1} and y ∈= {0, 1}. The transition probabil-
ity matrix is
A =
[
Pr(y = 0|x = 0)
Pr(y = 0|x = 1)
Pr(y = 1|x = 0)
Pr(y = 1|x = 1)
]
=
[
0.85
0.15
0.15
0.85
]
Assume we observe the symbol y = 1 and x ∼Pr(x(0)) = [0.90.1]′, then
(a) What is posterior probability of x?
(b) Let x = 1, what is the posterior if this is true?
(c) Let x = 0, what is the posterior if this is true?
(d) Suppose y = 0, what are the corresponding posteriors of x?
9.2
A ly [4] moves along a straight line in unit increments. At each time period
it moves one unit to the left with probability 0.3, one unit to the right with
probability 0.3 and stays in place with probability 0.4. A spider is hiding at
positions 1 and m: if the ly lands there, it is captured by the spider and the
process ends.
(a) Construct a Markov chain model, assuming the ly starts at positions
2, … , m −1.
(b) Sketch the corresponding directed graph.
(c) What is the probability of the following state evolution sequence:
Pr(1 = 2, 3 = 3, 4 = 4|2)?
9.3
Consider placing a ball in one of the N compartments at each event. Each
compartment can hold multiple balls. Let xi; i = 0, … , N be the state where k
compartments are occupied. At the next event, the next ball can go into one of
the occupied compartments with probability k∕N or an empty compartment.
(a) Create a Markov chain for this problem.
(b) What is the state diagram?
(c) What is the transition matrix, A.
9.4
Suppose we have a discrete state–space and discrete-time measurement system
(sampled data). Deining the discrete (inite) states as xi(t) and the measurements
as y(t), then:
(a) What is the state prediction probability Pr(xi(t)|Yt−1)?
(b) What is the state posterior distribution Pr(xi(t)|Yt)?
(c) Sketch out the steps of the Bayesian iltering operation at times t −1 and t.

PROBLEMS
399
9.5
Autoregressive (AR(Na)) models (all-pole) occupy a large part of the signal
processing literature especially in speech applications [10].
(a) An AR model is an example of a Markov chain on a continuous space, show
that the AR(1) model forms a Markov chain, that is,
y(t) = a1y(t −1) + �(t),
�∼(0, �2)
(b) Show an AR(Na) model also forms a Markov chain. (Hint: Place the AR
model in state–space form).
(c) Does an ARMA(Na, Na) model form a Markov chain as well?
9.6
Autoregressive (AR(Na)) switching models also occupy a signiicant part of the
time series literature [14]. It is a model where the mean can switch between
two values, �0 and �1. It enables the time series with several regimes or local
nonstationarities to be represented as
Pr(y(t)|y(t −1), x(t), x(t −1)) ∼(�x(t) + a1(y(t −1) −�x(t−1))), �2)
Pr(x(t)|x(t −1)) ∼px(t−1)x(t−1)(x(t))
+ (1 −px(t−1))1−x(t−1)(x(t))
where the hidden state x(t) takes values in {0, 1} with initial values x(0) = �0
and y(0) = 0 and is an indicator function.
(a) What is the sampling distribution Pr(x(t)|x(t −1), x(t + 1), y(t), y(t −1),
y(t + 1))?
(b) Using the priors Pr(�1 −�0) ∼(0, �2), Pr(a, �2) with p0, p1 ∼U(0, 1) sim-
ulate the AR switching model for N = 500 samples. What are the inal
parameter estimates for {�0, �1, a, p1, p2}?
9.7
Consider a four-state Markov switching model [34, 35] with the set of discrete
states given by = {1, 2, 3, 4} representing a Markov chain with transition
matrix
A =
⎡
⎢
⎢
⎢⎣
1 −3�
�
�
�
�
1 −�−2�
�
�
�
�
1 −�−2�
�
�
�
�
1 −�−2
⎤
⎥
⎥
⎥⎦
The observation sequence is speciied by a set of AR(2) models
y(t) = a1iy(t −1) + a2iy(t −2) + �i(t)
for i; i = 1, … , 4
where �i ∼(0, �2)
(a) What is the (state) prediction probability for this model Pr(s(t)|Yt−1)?
(b) What is the (state) iltering posterior probability for this model Pr(s(t)|Yt)?

400
DISCRETE HIDDEN MARKOV MODEL BAYESIAN PROCESSORS
(c) What is the likelihood for the following set of parameters describing this
model Θ = {�, �, �, �2, a1i, a2i}; i = 1, … , 4?
(d) Simulate the system with the following parameters {�, �, �, �2} = 0.0033,
0.016, 0.002, 0.1 and {a1i, a2i} = {(1.785, −0.903), (1.344, −0.903), (1.386,
−0.640), (0.800, −0.640)} for N = 1000 samples.
9.8
Suppose we have an HMM model with discrete state–space deined by
= {xi(t) = i}i = 1, … , Nx with state-transition matrix A. We would like to
establish a parameter estimation problem given the observation sequence YT.
Assume that the complete likelihood is given by Pr(y, x|�) and the density is
given by Pr(y|xi, �) = (�x(t), Σ) with known diagonal covariance and unknown
mean. Develop the EM algorithm to estimate the parameter �, that is,
(a) What is the Q-step?
(b) What is the M-step?
9.9
State–space models are perhaps the most important class of linear dynamic
systems characterized by
x(t + 1) = Ax(t) + �(t)
y(t) = Cx(t) + �(t)
Develop the EM algorithm for this class of model based on the usual Gauss–
Markov assumptions.
(a) Suppose we are asked to estimate the A and C parameters. What is corre-
sponding the E-step? (Hint: Use gradient techniques.)
(b) What is the associated M-step?

10
SEQUENTIAL BAYESIAN
DETECTION
10.1
INTRODUCTION
Detection theory and more speciically sequential detection theory is closely coupled
to sequential estimation techniques and is often the primary reason for constructing
the estimator in the irst place. Sequential techniques ind application in many techni-
cal application areas such as radar, sonar (detection/tracking), biomedical (anomaly
detection/localization), speech (recognition/tracking), communications (real-time/
obstructed environments), the sciences (e.g., seismology (earthquakes), structures
(vibrations), materials (additive manufacturing/threat detection), radiation (threat
detection), etc.) and of course, a huge variety of military applications. In this chapter,
we develop sequential detection techniques primarily aimed at the binary decision
problem. Here, we enable the extension of these estimation methods to an entire
class of problems especially when a physical model is available that can be incorpo-
rated into the algorithm leading to model-based detection. We develop the Bayesian
approach to decision theory primarily aimed at a coupling of sequential Bayesian
estimation to sequential decision-making.
Decision theory is rooted in hypothesis testing with the Bayesian approach pro-
viding the underlying statistical basis for its evolution. We start with the binary
decision problem and develop the usual Bayesian solutions based on probability-
of-error minimization leading to the well-known Bayes’ risk criterion. Next, the
classical Neyman–Pearson detection approach (maximize detection probability for
ixed false-alarm probability) is developed and compared to the Bayesian schemes
illustrating their similarity and differences. Detectors for multiple measurements,
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
401

402
SEQUENTIAL BAYESIAN DETECTION
multiple hypotheses, and multivariate (vector) processes are developed to provide
a more pragmatic set of solutions. Next, we investigate a variety of performance
criteria based on the receiver operating characteristic (ROC) curve and its variants
that provide the foundations for classical analysis. Other metrics (e.g., area under
curve, etc.) associated with the ROC curve are introduced and applied as well. Once
these “batch schemes” are developed, we introduce the sequential approach to solv-
ing these problems in pseudo real-time evolving to sequential model-based detection.
The set of model-based processing schemes are coupled to the detector providing
the mechanism to solve a variety of problems in real time. Finally, we investigate an
important class of problems that motivate the application of model-based detection—
failure detection/classiication. Here we develop the approach using the model-based
detection schemes and conclude with a realistic case study.
10.2
BINARY DETECTION PROBLEM
The basic detection problem that we face is that we are given a set of noisy mea-
surement data that has been generated by some unknown source and we are asked
to “decide” whether it is present or not. This formulation is the simple radar, sonar,
tumor, law, or threat detection problems. Thus, the fundamental decision problem is
that we have a random source or target (Θ) that is known by either hypotheses (0
or 1) generating a unique signal (S(Θ)) that is observed or measured [1–3]. Both
source and signal reside in the source and signal spaces. The signal is “mapped”
from the signal space through some probabilistic transition mechanism (Pr(Y|S(Θ)))
creating points in the measurement space (Y). Finally, the measurement is mapped
into an equivalent decision space, (D) that is made up of disjoint regions of the
measurement space (Y ⟺D = ∪iDi) by a decision function or rule ((Y|�)).
Here the measurement is mapped into subregions of the measurement space that are
deined explicitly by the particular decision function (similar to clustering), that is,
the decision function partitions the measurement space into a number of disjoint
regions corresponding to each hypothesis. The basic decision problem is illustrated
(simply) in Fig. 10.1. The true source generates one of the hypotheses as an output
that initiates a signal. For instance, a code “A” might correspond to a unit positive
pulse while a “B” might correspond to a unit negative pulse. The signal probabilistic
transition mechanism, which knows the true hypotheses, separates these hypothesis
from the measurements and generates points in the measurement space according to
some probabilistic distribution. A decision rule (function) using the measurements is
developed to decide which of the hypotheses to accept as correct. The ultimate deci-
sion is based on knowledge of the a priori probability of each hypothesis (Bayesian)
and of any of the conditional probabilities inherent in the transition mechanism.
Formally, we can deine the simple binary detection problem of a noisy measure-
ment y(t) consisting of a signal s(t) in noise �(t) or just noise as
0 : y(t) = �(t)
[Noise]
1 : y(t) = s(t) + �(t)
[Signal+Noise]
(10.1)

10.2
BINARY DETECTION PROBLEM
403
Signal
space 
Measurement 
space
Source
Θ
(
)
Pr
⏐( )
Θ
Θ
Y S
( )
S
Y
Decision
rule 
Decision
regions
Probability
transition
mechanism
H1
or
Accept 
Accept 
H0
Decision
(
)
⏐H
D Y
{
}
0
1
or
H
H
1
D
1
D
1
D
1
D
1
D
0
D
0
D
ℓ
FIGURE 10.1
Fundamental decision problem: (a) source, Θ (Truth); (b) signal space,
S(Θ); (c) measurement space, Y with probability transition (Pr(Y|S(Θ)); (d) decision
space, D = {D0∪D1} with decision rule (Y|�).
where the subscript notation refers to the noise (“0”) or alternate signal hypothesis
(“1”) of the test corresponding to the two respective hypotheses (0, 1) and cor-
responding decision regions (D0, D1) that partition the observation or measurement
space.
Perhaps the simplest approach is to solve the “single” measurement problem in
order to illustrate the approach that is taken in classically solving this type of binary
decision problem. The rudiments of decision theory follow directly from this problem.
10.2.1
Classical Detection
In order to solve the classical binary detection problem, we require the following
ingredients: the underlying probabilistic transition mechanisms under each hypoth-
esis Pr(y(t)|�); �= 0, 1; the prior probabilities Pr(�); �= 0, 1; a decision rule
(y(t)|�)); �= 0, 1 and some manner to determine a threshold for the test. That is,
(y(t))
1
>
<
0
�
(10.2)
which implies that if the decision function is greater than the threshold �, accept
hypothesis 1 that the signal is present or if it is less than the threshold, accept the
null hypothesis 0 that the signal is not present.

404
SEQUENTIAL BAYESIAN DETECTION
Detectors are not perfect by any means, so to be realistic, we will require some
manner to capture the errors that can be made. Therefore, we deine four probabilities
associated with our decision problem:
PDET
a signal detection declared when the measurement is a signal (correct)
PFA
a false alarm when a signal detection is declared and the measurement is
noise (wrong)
PMiss
a noise detection declared when the measurement is a signal (miss)
PReject
a noise detection declared when the measurement is noise (correct)
Based on our probabilistic transition mechanism (assumed known), we are able to
calculate these probabilities. The probability of detection is deined by
PDET(�) = ∫
∞
�:D1
Pr((y(t))|1
)d
(10.3)
with D1 a partition of the measurement space. The probability of false alarm is
deined by
PFA(�) = ∫
∞
�:D1
Pr((y(t))|0
)d
(10.4)
Note that this integral is performed over the region D1 leading to false alarms as
illustrated in Fig. 10.2. Also related to these two probabilities is the probability of a
miss given by
PMiss(�) = ∫
�:D0
−∞
Pr((y(t))|1
)d= 1 −PDET(�)
(10.5)
There are errors associated with each “wrong” decision. Suppose the decision
space is partitioned into two regions (binary: signal/noise problem) with region D0
corresponding to the noise (0) and region D1 corresponding to the signal (1).
There are two possible mechanisms in which an error can occur: (1) either a decision
(y(t)) falls into region D1 and the measurement is noise or (2) the measurement is
a signal and falls into D0. Since these events are mutually exclusive, we can deine
the total probability-of-error as
PError := Pr(∈D1, D0
) + Pr(∈D0, D1
)
(10.6)
applying Bayes’ rule (Pr(A, B) = Pr(A|B) × Pr(B)) to the joint distribution gives
PError = Pr(|1
) × Pr(D0
) + Pr(|0
) × Pr(D1
)
(10.7)

10.2
BINARY DETECTION PROBLEM
405
(Threshold)
D0
D1
τ1
τ ≥ τi: D1  
∞
Pr D H1
PDET
dD
D
DET
P
FA
P
“Decision regions”
Pr D H1 ∈D1
Pr D H0 ∈D0
τ ≥ τi: D0  
∞
Pr D H0
PFA
dD
(a)
(b)
Signal
Noise
FIGURE 10.2
Decision function probability distributions with deined decision regions:
(a) noise probability distribution Pr((y(t))|0); (b) signal probability distribution
Pr((y(t))|1).
where Pr(D0
), Pr(D1
) are the prior probabilities (prevalence [4]) associated with
each hypothesis and of course �is the hypothesis associated with its corresponding
decision region �.
We now have all of the ingredients we need to develop the detector except the most
crucial—the decision function. There are a wide variety of decision functions that
have evolved and they are typically based on a particular decision criterion. We start
with possibly the most intuitive—the maximum likelihood decision criterion that is
based on the likelihood probabilities under each hypothesis Pr(y(t)|�); �= 0, 1. We
decide on the “most likely” hypothesis based on its likelihood, that is, the likelihood
decision function is [5]
(y(t)) =
{
(y(t)|0)),
if Pr(y(t)|0) > Pr(y(t)|1)
(y(t)|1)),
if Pr(y(t)|1) > Pr(y(t)|0)
(10.8)
Here we have deined the decision regions as
D0 = {y(t) : Pr(y(t)|0) > Pr(y(t)|1)}
D1 = {y(t) : Pr(y(t)|0) < Pr(y(t)|1)}
(10.9)
So we see that the decision rule is to select the hypothesis that is most likely.

406
SEQUENTIAL BAYESIAN DETECTION
An equivalent method for representing this decision rule is to deine the likelihood-
ratio by
(y(t)) ⟶(y(t)) := Pr(y(t)|1)
Pr(y(t)|0)
(10.10)
with decision regions
D0 = {y(t) : (y(t)) < 1}
D1 = {y(t) : (y(t)) > 1}
(10.11)
leading to the maximum likelihood detector (ML)
(y(t))
1
>
<
0
1
(10.12)
Consider the following example of detecting a constant signal in Gaussian noise.
Example 10.1
Suppose we have a constant signal s(t) = �∀t that is contaminated with additive
zero-mean, Gaussian measurement noise �(t) of variance R��and we would like to
construct a likelihood detector to decide whether or not the signal is present. With
the signal present, the measurement model is simply
y(t) = s(t) + �(t)
and the probability distributions under each hypothesis are Gaussian:
Pr(y(t)|0) =
1
√
2�R��
exp
{
−
1
2R��
y2(t)
}
Pr(y(t)|1) =
1
√
2�R��
exp
{
−
1
2R��
(y(t) −�)2}
The likelihood decision function is
(y(t)) = Pr(y(t)|1)
Pr(y(t)|0) =
1
√
2�R��exp
{
−
1
2R��(y(t) −�)2}
1
√
2�R��exp
{
−
1
2R��y2(t)
}

10.2
BINARY DETECTION PROBLEM
407
or
(y(t)) = exp
{
−
1
2R��
(−2y(t)�+ �2)
}
= exp
{ 1
R��
(
y(t)�−�2
2
)}
which for a given �and R��yield the decision rule
(y(t)) = exp
{ 1
R��
(
y(t)�−�2
2
)}1
>
<
0
1
△△△
10.2.2
Bayesian Detection
The Bayesian approach to the binary detection problem revolves around the prob-
ability of various hypotheses given the data, while the classical approach revolves
around the probability of the data given the speciic hypothesis. As before, similar
to the development of the maximum likelihood detector, we select the maximum a
posteriori (MAP) criterion for our Bayesian decision function speciied by
(y(t)) =
{
(y(t)|0)),
if Pr(0|y(t)) > Pr(1|y(t))
(y(t)|1)),
if Pr(1|y(t)) > Pr(0|y(t))
(10.13)
Here we have deined the decision regions as
D0 = {y(t) : Pr(0|y(t)) > Pr(1|y(t))}
D1 = {y(t) : Pr(0|y(t)) < Pr(1|y(t))}
(10.14)
As before, an equivalent method for representing this decision rule is to deine the
likelihood-ratio by the ratio of posterior distributions
(y(t)) ⟶(y(t)) := Pr(1|y(t))
Pr(0|y(t)) = Pr(y(t)|1) × Pr(1)
Pr(y(t)|0) × Pr(0)
(10.15)
where we have applied Bayes’ rule (likelihood × prior). Therefore, the decision
regions become
D0 =
{
y(t) : (y(t)) < Pr(0)
Pr(1)
}
D1 =
{
y(t) : (y(t)) > Pr(0)
Pr(1)
}
(10.16)

408
SEQUENTIAL BAYESIAN DETECTION
leading to the MAP detector
(y(t))
1
>
<
0
Pr(0)
Pr(1)
(10.17)
So we note that in the Bayesian case, the detector is based on the conditional and
prior probabilities as mentioned previously. Let us return to the Gaussian example to
illustrate the differences between the classical likelihood and MAP detection schemes.
Example 10.2
We have a constant signal s(t) = �∀t contaminated with additive zero-mean, Gaus-
sian measurement noise �(t) of variance R��and we would like to construct a MAP
detector to decide whether or not the signal is present. The measurement model is
y(t) = s(t) + �(t)
and the probability distributions under each hypothesis are Gaussian as before in the
maximum likelihood case, but now we also have a prior probability to incorporate
so that
Pr(1) = 
Pr(0) = 1 −
The MAP decision function (as in the previous example) is given by
(y(t)) = exp
{ 1
R��
(y(t)�−�2
2 )
}1
>
<
0
1 −

for a given �and R��.
△△△
Before we leave this discussion of the binary detection problem, let us consider
one extension that of unknown parameters in either or both signal and noise models
that leads us to the so-called composite hypothesis test.
10.2.3
Composite Binary Detection
In many applications the signal and noise uncertainties are unknown and possibly
random, but can be parameterized in some form such as an unknown signal ampli-
tude with a random phase or a distribution with unknown mean and variance. Binary
detection problems in which the hypotheses do not have any unknown or random

10.2
BINARY DETECTION PROBLEM
409
parameters are termed simple hypotheses, while if they do possess unknown/random
parameters they are termed composite. In this case the decision problem is formu-
lated with a parameter vector, say �, which in the classical case can be considered
deterministic but unknown or in the random case characterized by its distribution
Pr(�). Let us return to the binary problem as before and incorporate the unknown
vector of parameters.
Formally, we can deine the composite binary detection problem of a noisy mea-
surement y(t) consisting of a signal s(t; �s) in noise �(t; ��) or just noise as
0 : y(t) = �(t; ��)
[Noise+Uncertainties]
1 : y(t) = s(t; �s) + �(t; ��)
[Signal+Noise+Uncertainties]
(10.18)
where the unknown/random parameters for the signal and noise are represented by
�s and ��and can be captured functionally in the parameter vector �.
We start with the likelihood-ratio decision function from the Bayesian perspective
and assume that �is random with prior distribution Pr(�), then we have the joint
distribution
(y(t); �) := Pr(y(t), �|1)
Pr(y(t), �|0) = Pr(y(t)|�, 1) × Pr(�|1)
Pr(y(t)|�, 0) × Pr(�|0)
(10.19)
where we have applied Bayes’ rule (likelihood × prior) as before.
For the case where we assume that the parameters are continuous and random with
a prior, then the compositelikelihood-ratiois determinedinterms of thecorresponding
marginal conditional distributions as
(y(t); �) :=
∫∞
−∞Pr(y(t), �|1)d�
∫∞
−∞Pr(y(t), �|0)d�
=
∫∞
−∞Pr(y(t)|�, 1) × Pr(�|1)d�
∫∞
−∞Pr(y(t)|�, 0) × Pr(�|0)d�
(10.20)
That is, by integrating over �, the likelihood-ratio is determined and the composite
hypothesis test is now treated just as a simple test.
However, if the parameters are assumed non-random but unknown or random
without a known distribution, then the so-called generalized likelihood-ratio test
(GLRT) evolves. Here an estimate of the parameter ̂�under each hypothesis is
performed irst and then the simple hypothesis test is performed, that is, we have
(y(t); ̂�) :=
arg max
�
Pr(y(t), �|1)
arg max
�
Pr(y(t), �|0)
(10.21)
Let us consider the previous example and now incorporate an unknown parameter
�into the detection problem [5].

410
SEQUENTIAL BAYESIAN DETECTION
Example 10.3
We have a random signal s(t) = �contaminated with additive zero-mean, Gaussian
measurement noise �(t) of known variance R��and we would like to construct both
MAP and maximum likelihood detectors to decide whether or not the signal is present.
The measurement model is
y(t) = s(t; �) + �(t)
and the probability distributions under each hypothesis are Gaussian and have a prior
probability Pr(1) = as before and a prior parametric distribution given by
Pr(�|1) =
{
1
if 1 ≤�< 2
0
otherwise
The composite MAP of Eq. 10.20 is therefore
(y(t); �) =
1
√
2�R��∫2
1 exp
{
−
1
2R��(y(t) −�)2}
d�
1
√
2�R��exp
{
−
1
2R��y2(t)
}
or
(y(t); �) =
∫2
1 exp
{
−
1
2R��(y(t) −�)2}
d�
exp
{
−
1
2R��y2(t)
}
1
>
<
0
1 −

for a speciied R��.
Next, the maximum likelihood decision function is speciied by irst obtaining the
maximum likelihood parameter estimator over each hypothesis. For this problem, we
need only to maximize the conditional probability under 1 which is obtained by
differentiating this distribution, setting the result to zero and solving to obtain
̂ΘML = arg max
�
Pr(y(t), �|1) = y(t)
and substituting into the conditional distribution, we obtain
Pr(y(t), ̂�|1)|||Θ= ̂ΘML =
1
√
2�R��
exp
{
−
1
2R��
(y(t) −̂ΘML)2}
=
1
√
2�R��
(y(t); Θ) = exp
{
1
2R��
y2(t)
}1
>
<
0
1
△△△

10.3
DECISION CRITERIA
411
This completes the discussion of the classical and Bayesian approaches to decision
theory, next we extend these results leading to a variety of the popular detection
techniques.
10.3
DECISION CRITERIA
In detection theory, each decision function deines a particular and unique scheme
which can range from ad hoc techniques like “lipping a coin” to a sophisticated
and complex mapping of the measurement space into (hopefully) disjoint decision
regions. In this section, we concentrate on various decision criteria and show how
they lead to a variety of so-called “optimal” decision functions.
10.3.1
Probability-of-Error Criterion
We start with the total probability-of-error usually termed “Bayes’ error” and develop
the Bayesian solution to minimize this error. Recall that the total probability-of-error
with decision regions under each hypotheses deined by D0 and D1 is given by
[5]
PError = Pr(D1|0
) × Pr(0
) + Pr(D0|1
) × Pr(1
)
(10.22)
and since the priors are mutually exclusive, we have
Pr(0
) + Pr(1
) = 1
(10.23)
We can express the Pr(D0|1
) as
Pr(D0|1
) = ∫D0
Pr(y(t)|1)dy + ∫D1
Pr(y(t)|1)dy −∫D1
Pr(y(t)|1)dy (10.24)
or
Pr(D0|1
) = 1 −∫D1
Pr(y(t)|1)dy = 1 −Pr(D1|1)
(10.25)
since the sum of the irst two terms is unity. We can also express
Pr(D1|0
) = 1 −∫D1
Pr(y(t)|0)dy
(10.26)

412
SEQUENTIAL BAYESIAN DETECTION
as a function of D1. With these relations in mind, the probability-of-error of Eq. 10.22
can be expressed as
PError = Pr(0
)
∫D1
Pr(y(t)|0)dy + Pr(1
)[
1 −∫D1
Pr(y(t)|1)dy
]
= Pr(1) + ∫D1
[
Pr(0)Pr(y(t)|0) −Pr(1)Pr(y(t)|1)
]
dy
(10.27)
Minimizing this expression is accomplished by selecting the decision region D1
such that the second term in braces is negative, that is,
D1 =
{
y(t) :
[
Pr(0)Pr(y(t)|0) −Pr(1)Pr(y(t)|1)
]
< 0
}
(10.28)
leading to region D0 > 0. Therefore, in terms of the likelihood-ratio, we have the
equivalent decision region
D1 =
{
y(t) : (y(t)) > Pr(1)
Pr(0)
}
(10.29)
and therefore the decision rule for the minimum probability-of-error (P-E) detector
is
(y(t))
1
>
<
0
Pr(0)
Pr(1)
(10.30)
Comparing this result to the MAP detector, we see that they are identical, that is,
P−E
(y(t)) ⟺MAP
(y(t))
10.3.2
Bayes Risk Criterion
We generalize our previous results for the MAP detector to incorporate a set of “cost
functions” that enable the designer to penalize errors that might be quite serious for
a particular application. For instance, a high miss probability in a stock transaction
may cost proit, but a miss of a tumor in medicine may cost a life.
We deine the following costs in the binary detection problem associated with the
types of errors that can evolve
C00——cost of accepting 0 when 0 is true (right)
C01——cost of accepting 0 when 1 is true (wrong)

10.3
DECISION CRITERIA
413
C10——cost of accepting 1 when 0 is true (wrong)
C11—–cost of accepting 1 when 1 is true (right)
These costs are basically meaningless unless we know their a priori probabilities;
therefore, we deine the Bayes’ risk (B-R) as the “expected” cost for these cost as
ℜ= E{C} =
∑
i,j
Cij × Pr(i|j) × Pr(i or j)
(10.31)
or expanding
ℜ= C00Pr(0|0) × Pr(0) + C01Pr(0|1) × Pr(1)
+ C10Pr(1|0) × Pr(0) + C11Pr(1|1) × Pr(1)
Grouping this expression in terms of each decision region, we have
ℜ=
[
C00Pr(0|0)Pr(0) + C01Pr(0|1)Pr(1)
]
D0
+
[
C10Pr(1|0)Pr(0) + C11Pr(1|1)Pr(1)
]
D1
Since the decision function maps the measurements into disjoint regions (Y ⟺
D = ∪iDi), we have that each of these terms can be speciied directly within the
measurement space as
ℜ=
[
∫D0
C00Pr(y(t)|0)Pr(0) + C01Pr(y(t)|1)Pr(1)dy
]
+
[
∫D1
C10Pr(y(t)|0)Pr(0) + C11Pr(y(t)|1)Pr(1)dy
]
To minimize Bayes’ risk with respect to the decision regions D0 and D1, we select
hypothesis 1 for those values of y(t) that yield a greater value for the second integral,
that is,
C10Pr(y(t)|0)Pr(0) + C11Pr(y(t)|1)Pr(1)
> C00Pr(y(t)|0)Pr(0) + C01Pr(y(t)|1)Pr(1)
hypothesis 0 is selected when the inequality is reversed; therefore, combining like-
terms, we have
(C10 −C00
)Pr(0)Pr(y(t)|0)<
>
(C01 −C11
)Pr(1)Pr(y(t)|1)
(10.32)

414
SEQUENTIAL BAYESIAN DETECTION
creating the likelihood-ratio as before,
(y(t)) = Pr(y(t)|1)
Pr(y(t)|0)
we obtain the Bayes’ risk detector as
(y(t))
1
>
<
0
Pr(0)(C10 −C00
)
Pr(1)(C01 −C11
)
(10.33)
Compare this to Eq. 10.17 (and Example 10.2) and we see (as before) that both
schemes “minimize the probability-of-error” and are identical if we let C00 = C11 = 0
and C01 = C10 = 1. The advantage of the Bayes’ risk scheme is that we penalize our
errors heavily depending on the severity of the error relative to our application. Next,
we consider a different approach to the binary detection problem in which we focus
on the detection probability.
10.3.3
Neyman–Pearson Criterion
In decision problems lacking in any a priori information such as prior probabilities
or costs where it is challenging to construct any reasonable guesses, the Neyman–
Pearson detector has evolved as a predominant choice under these conditions. This
scheme evolves directly from an optimization perspective and has motivated a large
number of “optimization-based” approaches to solve the binary detection problem
[6]. The Neyman–Pearson (N-P) approach constrains the false-alarm probability
while maximizing the detection probability, since it is not possible to simultaneously
maximize detection and minimize false alarms. It is considered a frequentist rather
than a statistical or equivalently Bayesian approach [6–8]; however, it is applied quite
heavily in engineering applications.
Formally, the Neyman–Pearson decision criterion can be stated as “ix the prob-
ability of false-alarm PFA at probability p and then maximize the probability of
detection PDET”. That is,
arg max
D1
PDET subject to PFA = p
Following the usual Lagrange optimization approach with Lagrange multiplier �, we
have the augmented decision criterion in which we would like to select the decision
region D1 to maximize [5]
N−P = Pr(1|1) −�× [Pr(1|0) −p]
(10.34)

10.3
DECISION CRITERIA
415
Substituting the conditional distributions, we have
N-P = ∫D1
Pr(y(t)|1)dy −�× ∫D1
[
Pr(y(t)|0) −p
]
dy
(10.35)
We see that the maximization problem is now unconstrained but with the Lagrange
multiplier �parameterizing D1. It is selected to satisfy the constraint such that the
last term of Eq. 10.34 is zero and therefore the detection probability Pr(1|1) is
maximized.
Grouping terms in Eq. 10.35 we have
N−P = ∫D1
[
Pr(y(t)|1) −�Pr(y(t)|0)
]
dy + �p
(10.36)
To maximize this expression by the choice of D1, we see the last term is ixed
(assuming �is positive) and the irst term is positive for
D1 = {y(t) :
[
Pr(y(t)|1) −�Pr(y(t)|0)
]
> 0}
(10.37)
subject to the constraint that
Pr(1|0) = ∫D1
Pr(y(t)|0)dy = p
(10.38)
The fundamental approach is to calculate Pr(1|0) as a function of �and ind the
value of �such that Pr(1|0) = p.
Therefore, in terms of likelihood-ratio we have that
(y(t)) = Pr(y(t)|1)
Pr(y(t)|0)
we obtain the Neyman–Pearson detector as
(y(t))
1
>
<
0
�
(10.39)
We again note that similar to the techniques we have discussed, the decision
functions are identical in form testing a likelihood-ratio against a threshold. It is the
thresholds that differ in each approach: ML is a unit threshold, MAP is a ratio of
priors, B- R is a ratio of priors with cost constraints and N-P is �constrained by
a ixed false-alarm probability p. To illustrate the N-P scheme, consider our usual
Gaussian example as before.

416
SEQUENTIAL BAYESIAN DETECTION
Example 10.4
Again we have a constant signal s(t) = �∀t that is contaminated with additive
zero-mean, Gaussian measurement noise �(t) of variance R��and we would like to
construct an N-P detector to decide whether or not the signal is present under the
constraint that the false-alarm probability must be �.
Recall from Example 10.1 that the Neyman–Pearson (likelihood) decision function
is given by
(y(t)) = exp
{ 1
R��
(
y(t)�−�2
2
)}1
>
<
0
�
To determine �, we must solve the integral equation for
Pr(1|0) = ∫D1
Pr(y(t)|0)dy = ∫
∞
�
1
√
2�R��
exp
{
−
1
2R��
y2(t)
}
dy = �
which for the Gaussian case can easily be determined, once �is speciied.
△△△
This completes the section on the variety of decision criteria that we will consider
for our problems; however, we have only considered a single measurement at time t,
y(t)—how do we handle multiple or a “batch” of measurements?
It should also be noted that there are a wide variety of optimization-based decision
criteria (e.g., minimax, local optimal) that exist, but are beyond the scope of this text
(see Refs. [3,5–9] for more detailed texts).
10.3.4
Multiple (Batch) Measurements
In most pragmatic problems, multiple measurements are required to make a rea-
sonable decision with any conidence at all. There are some nuances that evolve
when considering a batch of data. To see this, deine the batch by the set of mea-
surements YN = {y(0), y(1), … , y(N)} and now the hypothesis test is identical to that
of Eq. 10.18 with the fact that the samples are indexed from t = 0, 1, 2, … , N. Sta-
tistically, the measurements are jointly distributed and if they are also considered
independent, then
Pr(YN|�
) = Pr(y(0), y(1), … , y(N)|�
)
= Pr(y(0)|�
) × Pr(y(1)|�
) ×, … , × Pr(y(N)|�
) (10.40)

10.3
DECISION CRITERIA
417
So we see from the detection perspective that the decision functions now incorpo-
rate joint rather than a single measurement distribution, that is, the likelihood-ratio
for multiple measurements is simply
(YN) =
Pr(YN|1
)
Pr(YN|0
) =
Pr(y(0), y(1), … , y(N)|1
)
Pr(y(0), y(1), … , y(N)|0
)
(10.41)
If each measurement is independent, then the likelihood-ratio becomes
(YN) =
Pr(YN|1
)
Pr(YN|0
) =
∏N
t=1 Pr(y(t)|1
)
∏N
t=1 Pr(y(t)|0
)
(10.42)
therefore, thresholds for each of the previous detection schemes remain the same
since the distributions just change to joint, that is,
ML(y(t)) ⟶ML(YN)
MAP(y(t)) ⟶MAP(YN)
B-R(y(t)) ⟶B-R(YN)
N-P(y(t)) ⟶N-P(YN)
To illustrate this point, let us return to our Gaussian example problem and recal-
culate the likelihood-ratio for the batch measurement problem.
Example 10.5
Suppose we have a constant signal s(t) = �∀t that is contaminated with additive
zero-mean, Gaussian measurement noise �(t) of variance R��and we would like to
construct the likelihood-ratio for a variety of detectors to decide whether or not the
signal is present. With the signal present, the measurement model is simply
y(t) = s(t) + �(t);
for t = 1, … , N
and the probability distributions for each individual measurement is Gaussian
Pr(y(t)|0) =
1
√
2�R��
exp
{
−
1
2R��
y2(t)
}
Pr(y(t)|1) =
1
√
2�R��
exp
{
−
1
2R��
(y(t) −�)2}

418
SEQUENTIAL BAYESIAN DETECTION
Assuming that the measurements are independent, then the joint distribution under
each hypothesis is given by
Pr(YN|�
) =
N
∏
t=1
Pr(y(t)|�
); for �= 0, 1
The likelihood decision function is
(YN
) = Pr(YN|1)
Pr(YN|0) =
1
√
2�R��
∏N
t=1 exp
{
−
1
2R��(y(t) −�)2}
1
√
2�R��
∏N
t=1 exp
{
−
1
2R��y2(t)
}
or
(YN) =
N
∏
t=1
exp
{
−
1
2R��
(−2y(t)�+ �2)
}
=
N
∏
t=1
exp
{ 1
R��
(
y(t)�−�2
2
)}
which for a given �and R��yield the decision rule
(YN) =
N
∏
t=1
exp
{ 1
R��
(
y(t)�−�2
2
)}1
>
<
0
�
where �is speciied by the particular detector selected.
△△△
10.3.5
Multichannel Measurements
In many cases, multiple channel or equivalently multivariable measurements are made
ranging from antenna arrays of radar systems, hydrophone arrays of sonar systems
to geophone arrays for seismic activity as well as microphones arrays for speech
application. In fact, in many cases a variety of measurements are made and combined
or “fused” together to get a complete view of the measurement space. In all of these
applications, a multichannel measurement system provides a set of data at a particular
instant of time captured by a measurement vector y. Assuming jointly distributed,
independent vector measurements, the statistics and likelihood decision function for
the multichannel measurement case are
Pr(YN|�
) = Pr(y(0), y(1), … , y(N)|�
)
= Pr(y(0)|�
) × Pr(y(1)|�
)×, … , ×Pr(y(N)|�
)
(10.43)
where y(t) ∈Ny×1 and the batch N-vector data set YN = {y(0), y(1), … , y(N)}.

10.3
DECISION CRITERIA
419
So we see from the detection perspective the decision functions now incorporate
joint vectors, that is, the likelihood-ratio for multiple measurements is
(YN) =
Pr(YN|1
)
Pr(YN|0
) =
Pr(y(0), y(1), … , y(N)|1
)
Pr(y(0), y(1), … , y(N)|0
)
(10.44)
With independent measurements, the likelihood-ratio becomes
(YN) =
Pr(YN|1
)
Pr(YN|0
) =
∏N
t=1 Pr(y(t)|1
)
∏N
t=1 Pr(y(t)|0
)
(10.45)
Therefore, as before in the multiple measurement case, thresholds for each of the
previous detection schemes remain the same since the distributions just change to
joint vector distributions, that is,
ML(YN) ⟶ML(YN)
MAP(YN) ⟶MAP(YN)
B-R(YN) ⟶B-R(YN)
N-P(YN) ⟶N-P(YN)
Let us return to our Gaussian example problem, construct it as multichannel and
recalculate the likelihood-ratio for the batch measurement problem.
Example 10.6
Suppose, we have a vector signal s(t) = �∈Ny×1 that is contaminated with additive
zero-mean, Gaussian measurement noise v(t) of variance R��and we would like to
construct the likelihood-ratio for a variety of detectors to decide whether or not the
signal is present. With the signal present, the measurement model is simply
y(t) = s(t) + v(t)
for y, v ∈Ny×1.
The distribution in vector-matrix form under each hypothesis is given by
Pr(Yt|0) = (2�)−N
2 × |R��|−N
2 × exp
{
−1
2yT(t)R−1
��y(t)
}
Pr(Yt|1) = (2�)−N
2 × |R��|−N
2 × exp
{
−1
2(y(t) −�)TR−1
��(y(t) −�)
}
where R��= diag(R��) ∈Ny×Ny and �∈Ny×1.

420
SEQUENTIAL BAYESIAN DETECTION
Assuming that the measurements are independent, then
Pr(YN|�
) =
N
∏
t=1
Pr(y(t)|�
); for �= 0, 1
The likelihood decision function is
(YN
) = Pr(YN|1)
Pr(YN|0) =
(2�)−N
2 × |R��|−N
2 ∏N
t=1 exp
{
−1
2(y(t) −�)TR−1
��(y(t) −�)
}
(2�)−N
2 × |R��|−N
2 ∏N
t=1 exp
{
−1
2yT(t)R−1
��y(t)
}
or simplifying
(YN) = 1
2
N
∏
t=1
exp
{
�TR−1
��y(t) + yT(t)R−1
���−�TR−1
���
}1
>
<
0
�
which for a given �and R��yield the decision rule and �is speciied by the particular
detector selected.
△△△
This completes the section on multivariate detection, next we consider multiple
hypothesis testing.
10.3.6
Multiple Hypotheses
Up to this point we have discussed the binary decision problem, that is, given two
hypotheses choose between them to make a decision. What happens when we have
more than two? This is the multiple hypotheses problem which occurs frequently in
many applications. For instance, in undersea operations, we may ask the question,
was that a submarine or a whale or a rock or a mine? Multiple hypothesis testing
or detection has evolved to be known as a “classiication” problem in which a large
number of texts have been written [2], [6], [10], [11].
In this section, we briely discuss the multiple hypotheses decision problem from
the Bayesian risk perspective developed for the binary problem in Section 10.3.2 (see
Eq. 10.31) and generalize it by incorporating the M-multiple hypotheses directly into
the risk criterion for minimization, that is, [3]
ℜ= E{C} =
M
∑
i=1
M
∑
j=1
Cij × Pr(j) × Pr(i|j)
(10.46)

10.3
DECISION CRITERIA
421
where the measurement is y ∈Yi or equivalently y ∈Di, then j is selected such
that
Pr(i|j) = ∫Di
Pr(y(t)|j)dy
(10.47)
and
Cij—————cost of accepting i when j is true
Pr(j)———probability of j with j true
Pr(y(t)|j)—–conditional probability of the measurement given that j is true
D—————measurement space divided into disjoint sets such that ∑M−1
i=0 Di
After substituting Eq. 10.47 into Eq. 10.46, the average risk becomes
ℜ=
M
∑
i=1 ∫Di
M
∑
j=1
Cij × Pr(j) × Pr(y(t)|j)dy
(10.48)
Recall that, as in the binary case, the Bayes’ criterion is to select the decision
regions Di; i = 1, … , M such that the average risk ℜis minimized. Therefore, this
can be achieved by selecting y ∈Yi or equivalently y ∈Di if (see Ref. [5] for
proof)
M
∑
k=1
Cjk × Pr(k) × Pr(y(t)|k) <
M
∑
k=1
Cmk × Pr(k) × Pr(y(t)|k) ∀j ≠m (10.49)
Now, if we let these costs be
Cij =
{
0,
if i = j
1,
if i ≠j
(10.50)
which essentially implies that the errors are of equal importance, then the risk is the
probability-of-error PError and Eq. 10.49 simpliies. That is, we accept k, if
Pr(k) × Pr(y(t)|k) > Pr(m) × Pr(y(t)|m) ∀m ≠k
(10.51)
Applying Bayes’ rule we have the posteriors and therefore the equivalent decision
rule consists of accepting k if
Pr(k)|y(t)) > Pr(m|y(t)) ∀m ≠k
(10.52)
which implies that for the M-ary hypotheses, we must calculate each of the a posteriori
probabilities and select the largest.

422
SEQUENTIAL BAYESIAN DETECTION
These results also can be extended to the composite hypotheses case as well. There
the required probabilities for each hypothesis are given by
∫
∞
−∞
Pr(i|y(t), Θ) × Pr(Θ|y(t))dΘ for i = 0, 1, … , M −1
(10.53)
and accept hypothesis Pr(i) for i the largest value of Eq. 10.53.
Consider the previous “batch” example of 10.14 and extend it to the multiple
hypotheses case.
Example 10.7
Suppose that we have a set of three constant signals si(t) = �i; i = 1, … , 3 that are
contaminated with additive zero-mean, Gaussian measurement noise �(t) of variance
R��and we would like to construct a decision function to decide which particular
signal is present. That is, we would like to decide which hypothesis is true
1 : y(t) = s1(t) + �(t)
[Signal no. 1]
2 : y(t) = s2(t) + �(t)
[Signal no. 2]
3 : y(t) = s3(t) + �(t)
[Signal no. 3]
The measurement model for this problem is simply
y(t) = si(t) + �(t);
for t = 1, … , N; i = 1, … , 3
and the probability distributions for each individual measurement is Gaussian
Pr(y(t)|i) =
1
√
2�R��
exp
{
−
1
2R��
(y(t) −�i)2}
; i = 1, … , 3
Assuming that the measurements are independent, then the joint distribution under
each hypothesis is given by
Pr(YN|i
) =
N
∏
t=1
Pr(y(t)|i
); for i = 1, 2, 3
and taking logarithms, we have
ln Pr(YN|i
) = N ln
(
1
√
2�R��
)
−
1
2R��
N
∑
t=1
(y(t) −�i)2; i = 1, … , 3

10.4
PERFORMANCE METRICS
423
Further assuming equal priors Pr(1) = Pr(2) = Pr(3), then the decision func-
tion of Eq. 10.51 requires that we select the largest probability, that is
ln Pr(y(t)|i) > ln Pr(y(t)|m) ∀m ≠i
or substituting
N ln
(
1
√
2�R��
)
−
1
2R��
N
∑
t=1
(y(t) −�i)2 > N ln
(
1
√
2�R��
)
−
1
2R��
N
∑
t=1
(y(t) −�m)2
Removing the constant terms, cancelling like-terms, and multiplying by the minus
sign changes the inequality leading to
N
∑
t=1
(y(t) −�i)2 <
N
∑
t=1
(y(t) −�m)2 ∀m ≠i
and a “minimum”, then the decision function becomes
i(YN) = min
i
( N
∑
t=1
(y(t) −�i)2
)
; i = 1, … , 3
which achieves its minimum for the largest value of �i.
△△△
This completes the section on multiple hypotheses, next we consider techniques
to evaluate detection performance.
10.4
PERFORMANCE METRICS
Detection theory is a fundamental tool in decision analysis [1], [10], [12]. However,
many decision functions both formal and informal evolve in a wide variety of appli-
cations. The fundamental detection problem of interest is simply given a set of data
and a decision function, decide whether or not a signal is present.
Detection (binary), signal or non-signal, and classiication (signal type) methods
form the basis of signal detection processors including modern machine-learning
algorithms. The major question that arises when investigating these methods [1–20]
is their underlying performance on problems of interest. There exists a variety of
metrics that can be applied to evaluate algorithm performance ranging from confusion
matrices to sophisticated statistical hypothesis tests [3], but perhaps the most basic
and most robust method is the calculation of the ROC curve. The ROC curve is simply
a graph of detection (PDET) versus false-alarm (PFA) probabilities parameterized by
threshold �. This particular metric has evolved from the analysis of radar systems
during World War II [2], [13] as a critical tool for diagnostic testing in medicine, to

424
SEQUENTIAL BAYESIAN DETECTION
pattern recognition in forensics, and a wide variety of other applications [1]. There
are many individual metrics that can be extracted from an ROC curve including
sensitivity, speciicity, cost/beneit analysis along with a set of speciic features like
area under the curve (AUC) and minimum probability-of-error (MinE) [1]. All of these
problems have one requirement in common—they must be analyzed in some uniform
manner so that their detection performance can be evaluated. This requirement leads
directly to the ROC curve, since it provides all of the fundamental information
from which most other metrics are derived (e.g., area under ROC curve, AUC)
[21–25].
10.4.1
Receiver Operating Characteristic (ROC) Curves
A typical ROC curve is shown in Fig. 10.3 where we observe that the “ROC
space” is deined by the 1 × 1 square region in the (PFA,PDET)-plane. The graph
is monotonically increasing from (0, 0) to (1, 1). Detection performance can range
from complete alternative (negative) hypothesis at (0, 0) to complete hypothesis
(positive) detection at (1, 1) with “perfect detection” at (PFA, PDET) = (0, 1) and
Probability of false alarm
Probability of detection
1
0
1
Perfect detection
1
T
T
T
T
T
2
3
4
5
All negatives detected
Random
detection
Thresholds
Good
Bad
ROC curve
ROC curve
All
Positives detected
FIGURE 10.3
Receiver operating characteristic (ROC) curve: detection (PDET) ver-
sus false-alarm probability (PFA) for selected thresholds (�) indicating various perfor-
mance metrics including: (a) all negative (PFA,PDET) = (0, 0)) detection; (b) all positive
(PFA,PDET) = (1, 1)) detection; (c) perfect (PFA,PDET) = (0, 1)) detection; (d) random (coin
toss) detection (PDET = PFA).

10.4
PERFORMANCE METRICS
425
“random detection” (e.g., coin toss) along the cross-diagonal or 450-line from (0, 0)
to (1, 1), that is, PDET = PFA. Curves lying above this line are considered a rep-
resentation of “good” detection performance (i.e., better than a coin toss), while
those lying below the line are considered “bad” detection performance (i.e., worse
than a coin toss). Each (operating) point along the ROC curve is parameterized by
a threshold value,�n; n = 1, … , N deining a particular expected operating point of
the detector under analysis, that is, (PFA(�n), PDET(�n)) at �n. ROC curves are a
function of detection and false-alarm probability density (or mass) functions deter-
mined by sweeping the threshold through the decision PDFs and calculating the
underlying area overlaps [1]. We shall discuss this in more detail shortly. ROC
curves are generated from “known” explicit decision functions based on the partic-
ular problem (under investigation) statistics. For example, Gaussian decision func-
tions lead to explicit error function calculations that can be calculated analytically
[1]. Unfortunately, most decision function probability distributions (not necessarily
data distributions) are unknown or too complex to evaluate directly; therefore, we
must resort to numerical techniques (e.g., series approximations) to calculate the
ROCs or resort to “brute” force techniques, if possible, by generating large ensemble
realizations and applying counting methods [11]. Even though it appears to be a
straightforward calculation, ROC curves still possess a bit of “mysticism” because
we rarely ind simple interrelations between PDET and PFA such as a random detector
PDET(�n) = PFA(�n) ∀n. For instance, the well-known Neyman–Pearson detection
[1] algorithm ixes PFA and then maximizes PDET for a speciied threshold (�n).
Typically, we know the decision function employed in the detector can perform
the required integration (analytically or numerically) to determine the detection and
false-alarm probabilities enabling us to generate various points along the curve at
each threshold, tracing out the curve. So we see that the ROC curve, though simple
in concept, can present a challenge to calculate depending on the underlying problem
scenario and availability of good measurements and known or unknown decision
distributions.
In this chapter, we discuss the basic theory required to comprehend (intuitively
and mathematically) the ROC and its inherent features that enable us to ascertain the
performance of detection algorithms. We irst develop the theory and from it develop
a variety of metrics that can be extracted from the ROC to increase our understanding
of the embedded information. We apply the analysis to examples and use the ROC to
compare performance of a variety of detection techniques.
ROC Curve Generation
Next, let us investigate just how an ROC curve is gen-
erated, irst, intuitively (pictorially) and then numerically. Consider the two (binary
problem) decision distribution functions shown in Fig. 10.4—the disturbance and the
signal. From the igure we observe that their means (distribution peaks) differ provid-
ing an offset and they overlap one another. It is this overlapping that dictates the shape
of the ROC and the performance of the detector. If we allow the decision variable
(threshold) to assume various values and sweep it from −∞to +∞, an ROC curve
is traced out. That is, for each threshold value �n, a vertical line drawn from = �n

Pr
Minimum error
D H1 ∈D1
Pr D H0 ∈D0
τ ≥ τi: D0  
∞
Pr D H0
PFA
dD
τ ≥ τi: D1  
∞
Pr D H1
PDET
PDET
PFA
dD
(a)
(b)
Signal
Disturbance
(Threshold)
D1
D1
D1
D0
D0
D0
τ1
D
“Decision regions”
τ1
τ1
τ2
τ2
τ3
τ3
False alarm probability
Detection probability
ROC curve
1
FIGURE 10.4
Decision function probability distributions for selected thresholds (�n) and deined decision regions: (a)
disturbance probability distribution Pr((y(t))|0);(b) signal probability distribution Pr((y(t))|1).Note that the star is
location of minimum error probability (maximum detection/minimum false-alarm and optimal decision point (ODP)).

10.4
PERFORMANCE METRICS
427
intersects either curve associated with the underlying hypothesis Pr(|�
); �= 0, 1
deining the lower integration limit for both PDET and PFA (see Eqs. 2, 3). Perform-
ing the integration at �n calculates the areas under both decision distributions (see
Fig. 10.4) providing a corresponding operating point (PFA(�n), PDET(�n)) on the ROC
curve for the selected threshold. Sweeping �n; n = 1, 2, … the lower integration
limits (thresholds) are varied and the corresponding areas deined by these boundary
limits trace out the entire ROC curve. From Fig. 10.4 we also see that selecting the
thresholds deines the new boundaries for the decision regions D0 and D1 as well as
the corresponding areas of integration for all of the operating points. There exists a
particular point of minimum error corresponding to the intersection of the conditional
distributions (star in Fig. 10.4), providing the maximum detection and minimum false-
alarm probabilities for an optimum (Bayes) detector design [1]. Note also that for a
given threshold both PMiss and PReject can be calculated by changing the integration
limits to −∞to �, if desired. So we see that knowledge of the decision function PDFs
can provide us with some insight about functions generating the ROC curve and its
construction.
Numerical calculation of the ROC curve can evolve from a variety of meth-
ods. Perhaps the simplest is through integration, either analytically (where pos-
sible) or numerically, with the particular availability of the detection and false-
alarm probabilities and their known forms (analytic function or numerical values).
Recall that it is necessary for both probabilities to evolve from “known” functions
or data.
One particular technique that can be applied to calculate the ROC directly from
known data sequences generated either through simulations or controlled experiments
is the so-called brute force method. Once the decision sequences are calculated, then
this method can be applied using simple counting methods. For this method, known
data are generated and input to the decision function which is varied according to
selected threshold values similar to sweeping the thresholds illustrated in Fig. 10.4,
that is, for the decision problem, we must decide
(y(t))
>
<
[Signal]
�n
[Non-signal/Disturbance]
Once this decision function is obtained, then for any threshold value, we can calculate
the probability of detection and the probability of false alarm. These are obtained
empirically by estimating the probability of detection as the ratio of the number of
correct signal decisions declared for that threshold with the signal present over the
total number of signal samples. The false-alarm probability is the ratio of the number
of signal decisions declared for that threshold without the signal present over the
total number of non-signal or disturbance samples. These estimated probabilities
provide a single point on the ROC curve at the selected threshold. Varying the

428
SEQUENTIAL BAYESIAN DETECTION
threshold and performing the same calculation for both detection and false-alarm
probabilities generates the entire ROC curve. That is, we calculate the detection
and false-alarm probabilities based on the decisions made for each realization such
that
PDET(n) = No. of detections (Signal present)
Total no. of signal realizations (K); PFA(n) = No. of detections (Signal NOT present)
Total no. of non-signal realizations (K)
with realizations {(y(t))} ; t = 1, … , K and @ �n for n = 1, … , N
enabling the generation of a single point (PFA(�n), PDET(�n)) on the ROC curve for
the speciied threshold value (�n).
Summarizing, we can now see that the selection of the decision threshold clearly
speciies an operating point of the detector by its location on the ROC curve. It
is the overlap of the decision function distributions (conditional) that determine
the corresponding detection and false-alarm probabilities. For instance, if there is
no overlap then perfect detection can be achieved ((0,1) on ROC). Therefore, by
sweeping through the thresholds, loci of operating points are deined tracing out the
entire ROC curve.
The steps required to generate the ROC curve from “known” data are
ROC generation: Brute force method
1. Generate two ensembles of system realizations (or signal/non-signal) through
simulations or controlled experiments;
2. For each realization, calculate the corresponding decision function and compare
its value to the threshold;
3. Estimate the detection and false-alarm probabilities at the speciied threshold
(above);
4. Continue to choose new thresholds and compare the decision function while
accumulating the counts of detection and false-alarm probabilities generating
the ROC curve.
So we see that the dynamic ROC curve can easily be used to evaluate individual
detector performance as well as compare techniques.
Average ROC (AROC)
One of the questions with an ROC curve is whether or
not it is actually the “true” curve. Perhaps a better way to pose the problem is to ask
what is the best estimate of an ROC curve from synthesized or actual measurement
data? One way to approach this problem is to ask for the estimate, but also include a
measure of precision (standard deviation) along with it.
One technique is to create an ensemble of ROC s which can be accomplished in a
variety of ways such as through (1) simulation; (2) controlled experimental data; or
(3) sectioning of actual data. When data are sparse and a simulation is not possible

10.4
PERFORMANCE METRICS
429
80
90
100 110 120 130 140 150 160
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
Feature
Decision probability density functions (PDF)
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Receiver operating characteristic curve:
K = 100 ensemble members
PD-Probability of detection
PFA-Probability of false alarm
Non-Signal
Signal
ROC curves
Avg ROC curve
Total bounds (threshold avg.)
Error box wrt/[avg & opt O.P.]
Optimal operating point
FIGURE 10.5
Threshold averaging of ROC curves: (a) example decision PDFs; (b) ROC
ensemble (100 members) results with average (solid) and ±2�bounds (dots). The ODP
(diamond) and 2�−by−1�uncertainty box is also shown (zoom box).
then “bootstrap” methods can be applied to generate the known (signal or non-signal)
data to generate the ROC curves [26].
A simple method that can easily be applied would be to generate an ensemble
of realizations (when possible) and create an ensemble average along with its cor-
responding conidence bounds to assess the quality of the ROC curve estimates as
long as the thresholds are the same for each member [20]. For a Gaussian problem,
we show an ensemble of 100 curves with the mean estimate R along with the ±2�
bounds in Fig. 10.5. It must be noted that simple averaging or so-called vertical
averaging [27] assumes that all of the threshold values for both detection and false-
alarm probabilities are identical (aligned) for each member. If the thresholds are not
available and we only have values of detection and false-alarm probabilities, then
the value of the PFA is ixed and the values of the PDET for each ensemble value are
interpolated and then averaged.
Another method of averaging is called threshold averaging where the detection,
false-alarm, and threshold values are available for “each” realization of the ROC
curve. Here the thresholds are chosen and the corresponding detection probabilities
selected (or interpolated) to provide a threshold and false-alarm probability with
the resulting L-ensemble of ROC curves averaged. One way that is employed is
to: (1) ind the global minimum/maximum thresholds for each ensemble member,
and (2) generate a set of thresholds based on these values using them to gener-
ate all ROC curves in the ensemble. This way the ROCs are forced to “thresh-
old align” and then averaging across the ensemble is accomplished. This is the
method of choice, when possible, that is, if we generate an ensemble of ROC curves,

430
SEQUENTIAL BAYESIAN DETECTION
�(PDET(�n), PFA(�n)); �= 1, … , L, ∀n, then the ensemble average ROC, is
given by
(PDET, PFA) = 1
L
L
∑
�=1
�(PDET(�n), PFA(�n)); ∀n
(10.54)
with the ensemble standard deviation given by
�(PDET, PFA) =
√
√
√
√1
L
L
∑
�=1
(�(PDET(�n), PFA(�n)) −(PDET, PFA))2
(10.55)
Example 10.8
As an example using a set of Gaussian distributions, we perform simple vertical
averaging on an ensemble of 100 members (gray lines). The average (solid line)
ROCs shown in Fig. 10.5 along with the corresponding conidence limits or bounds
(dots). So we see that we have an estimated ROC with its associated precision metric
indicating the uncertainty in the estimate. Of course if desired, the uncertainty can be
decreased by incorporating more and more realizations (ensemble members) of the
ROC ensuring tighter and tighter bounds and therefore a more precise estimate of the
ROC curve. Also shown in the igure (zoom box) is the “optimal decision (threshold)
point” (ODP) and its corresponding 2�−by−1�uncertainty box. This ODP value is
the best operating point for the detector. We shall discuss this in more detail in the
next section.
△△△
Next, let us consider a variety of metrics that can be derived and extracted from
the ROC curve.
ROC Properties
In this section, we discuss a variety of properties that can be
extracted from a ROC. Knowledge of the ROC speciies detection performance and
enables us to compare various detection techniques. The shape and location of points
along the curve can be used for performance analysis and speciications.
The basic properties of an ROC curve are well known [1], [2], [10], and can be
summarized succinctly by
1. the ROC curve is monotonically increasing
2. the slope of the ROC curve is identical to its threshold value at that point
�n = dPDET(�n)∕dPFA(�n)
3. decision functions have ROC s that typically lie above the random detection
curve (coin toss)
4. a suficient statistic (contains all of the statistical information required) is
desirable for decisions

10.4
PERFORMANCE METRICS
431
0
20
40
60
80
100 120 140 160 180
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Decision functions PDFs
Feature
Decision probability density function (PDF)
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Receiver operating characteristic
False alarm probability
Detection probability
Non-Signal
Signal
Perfect
detection
Perfect
detection
Good
Random  detection
Random  detection
(coin flip)
Bad
FIGURE 10.6
Family of ROC curves: as the decision function PDFs move closer to the
signal PDF, the ROCs move closer to the random detector performance. All parameters
of the ROC are listed below.
Besides these basic properties, there are certain metrics that can be determined
from the ROC curve that are used to give a “feel” toward a single quantitative number
that can be used to assess the detection performance such as.
Distance,d′
Consider a family of ROC curves generated from a set of individual
non-signal items, assumed Gaussian, with different location parameters (means and
variances) relative to a signal item as shown in Fig. 10.6. We know if the distance, say
d′, between the non-signal and signal distribution is large [2], then “perfect detection”
can be achieved as shown in the igure by the PDF and its corresponding ROC curve
[1], [12]. If the distribution is Gaussian, then the distance is simply the Euclidean
distance of the ratio of individual means (M0) to standard deviations (
√
V0) relative
to the signal distribution parameters (M1,
√
V1), that is,
d
′ =
||||||
M1
√
V1
−M0
√
V0
||||||
(10.56)
As the non-signal mean of each individual (non-signal) item increases (in the
igure), the corresponding non-signal distribution moves closer and closer to the
signal distribution increasing the overlap and decreasing desirable detector perfor-
mance. This is illustrated in the igure by the non-signal decision function PDFs
migrating closer to the signal decision function PDF and the corresponding ROC
curves approaching the random detector (coin toss) performance (cross-diagonal or
450-line) signifying complete overlap of the distributions. From the distance metric,
we gain insight into the separability of the signal and non-signal PDFs and we can

432
SEQUENTIAL BAYESIAN DETECTION
observe performance degradation as they overlap more and more or equivalently as
the distance gets smaller and smaller. A large distance metric means a large separation
(smaller overlap) and higher expected detection performance. From Fig. 10.6, we see
an example of this for the respective distances: d
′ = 4.6, 3.2, 2.4, 1.6, 0.8, 0.01, 0.0
with the ROC curve moving closer to the random detector (coin toss) performance
as d′ decreases.
1. ROC1 : d
′
1 = 4.6, AUC1 = 1.00, MinE1 = 2.1;
2. ROC2 : d
′
2 = 3.2, AUC2 = 0.99, MinE2 = 8.4;
3. ROC3 : d
′
3 = 2.4, AUC3 = 0.87, MinE3 = 14.4;
4. ROC4 : d
′
4 = 1.6, AUC4 = 0.74, MinE4 = 21.5;
5. ROC5 : d
′
5 = 0.8, AUC5 = 0.53, MinE5 = 27.4;
6. ROC6 : d
′
6 = 0.5, AUC6 = 0.05, MinE6 = 29.7.
Area Under the Curve (AUC)
Another method to compare the performance
of detection techniques is to calculate the area under the ROC curve [27–29]. In fact,
it has been shown that the AUC is statistically consistent [30]. The AUC is a portion
of the area of the ROC space (1 × 1 or unit square), its value is always between 0 and
1; however, since the 450-line from (0, 0) to (1, 1) represents the random guess, no
pragmaticdetector would have an AUC less than 0.5; therefore, AUC ≥0.5. The AUC
has an important statistical property, that is, the AUC of a detector is equivalent to the
probability that the classiier will rank a randomly selected signal (1) measurement
“higher” than a randomly selected non-signal (0) measurement [27] implying that
it is very sensitive to detecting signals. In practice, the AUC performs very well and
is frequently employed as a general metric of detection performance. It is calculated
numerically by simple trapezoidal integration as
AUC =
∑
n
PDET(�n)ΔPFA(�n) + 1
2ΔPDET(�n) × ΔPFA(�n)
(10.57)
where ΔPDET(�n) = −(PDET(�n) −PDET(�n−1))
ΔPFA(�n) = (PFA(�n) −PFA(�n−1))
Referring to Fig. 10.6, the area under each ROC curve is given by
AUC = 1.00, 0.99, 0.96, 0.87, 0.74, 0.53, 0.50

10.4
PERFORMANCE METRICS
433
clearly demonstrating the robustness of this metric and its ability to predict overall
performance. Thus, the larger the AUC or equivalently the closer its value is to unity
(perfect detection), the better the expected detection performance.
Minimum Probability-of-Error
The minimum (attainable) probability-of-error
or equivalently Bayesian error corresponds to the intersection point of the decision
probabilities as shown as the “star” in Fig. 10.4. It evolves directly from the Gaussian
distribution assumption and requires the solution of an optimization problem. We
would like to investigate the decision errors more closely, that is, the probability-
of-error in making the decision—right or wrong. Assuming that we have a binary
decision problem with the usual two hypotheses: 0 and 1, as before and the data
set, Y := {y1, … , yK}; therefore, the total probability-of-error is
Pr (Error|Y) = Pr(Y, 0|1) + Pr(Y, 1|0)
(10.58)
or applying Bayes’ rule, we have
Pr (Error|Y) = ∫1
Pr(Y|0) Pr(0)dY + ∫0
Pr(Y|1) Pr(1)dY
(10.59)
Thus, the probability-of-error is based on making the wrong decision, that is,
Pr (Error|Data) := Pr (Error|Y) =
⎧
⎪
⎨
⎪⎩
Pr (1|Y) if we decide on 0
[Miss]
or
Pr (0|Y) if we decide on 1
[False alarm]
(10.60)
Bayesian decisions are based on the principle of selecting the hypothesis corre-
sponding to the largest posterior probability such that
If
Pr (0|Y) > Pr (1|Y)
decide on 0
Otherwise
decide on 1
(10.61)
Under this decision function (Bayesian) the error probability becomes
Pr(Error|Y) = min[Pr(0|Y), Pr(1|Y)] ≤Pr(0|Y)�× Pr(1|Y)1−�; 0 ≤�≤1
(10.62)

434
SEQUENTIAL BAYESIAN DETECTION
A general error integral can be upper bounded [1] using this inequality to give
Pr (Error|U) ≤P�
Y(0|Y) × P1−�
Y
(1|Y)
× ∫p�
Y(Y|0) × p1−�
Y
(Y|1) dY; 0 ≤�≤1
(10.63)
where pY(⋅) is a probability density function and PY(⋅) the corresponding distribution.
If the conditional probabilities are Gaussian, then the integral in this expression can
be simpliied to
∫p�
Y(Y|0) × p1−�
Y
(Y|1) dY = e−�(�)
(10.64)
where �(�) is a function of the means and variances of the distributions (see Ref. [11]
for details) leading to
Pr (Error|Y) ≤P�
Y(0|Y) × P1−�
Y
(1|Y) × e−�(�); 0 ≤�≤1
(10.65)
and this is called the Chernoff upper bound on the error probability Pr(Error) [11].
The bound is calculated analytically or numerically by inding the value of �that
minimizes e−�(�) with the error calculated by substituting the �min from the optimizer
into the integrals of Eq. 10.64.
If the decision functions are Gaussian (N(M0, V0), N(M1, V1)), then the bound
expression becomes [11]
�(�) = �(1 −�)
2
(M1 −M0
)′ [�V0 −(1 −�)V1
]−1 (M1 −M0
)
+ 1∕2 ln
||�V0 −(1 −�)V1||
||V0||
�||V1||
1−�
(10.66)
For the Gaussian example of Fig. 10.6, we have the following sequence of bounds
in percentage of error
MinE (%) = 2.1%, 8.4%, 14.4%, 21.5%, 27.4%, 29.7%
which occurs because of the overlapping in the tails of the Gaussian distributions.
Confusion Matrix
Another set of metrics that can be applied to the decision
problem has been developed by diagnosticians (medicine, inance, etc.) and is based
on the so-called confusion matrix which is shown in Fig. 10.7 [31]. For a binary
(signal/non-signal) decision problem, it is a 2 × 2 matrix with critical ROC statistics
extracted at a particular operating point on the ROC curve. On the diagonals of the
matrix, we have the detection and rejection probabilities at a selected threshold �n

10.4
PERFORMANCE METRICS
435
(Threshold)
Prob [Non-signals]
Non-signal
Signal
D(k)
(True 
negative)
(True
positive)
(False
positive)
(False
negative)
(False
positive)
(False
negative)
Prob [signals]
Confusion matrix 
Confusion matrix 
Truth:
Hypothesized
choices:
Ptrue
Ntrue
P′est
N′est
(No. of signal detections
declared—signal
present)
(No. of signal detections
declared—signal
Not present)
P′total = TP+FP
(No. of non-signal
detections declared—
non-signal Not present)
(No. of non-signal
detections declared—
non-signal present)
N′total = TN+FN
Totals:
Ptotal = TP+FN
Ntotal = FP+TN
N = TP + FN +
FP+TN
(a)
(b)
TP
TP
FP
FP
FN
FN
TN
TN
τ
FIGURE 10.7
Confusion matrix for binary decision problem: (a) matrix entries: Diag-
onals are detection (TP) and rejection (TN) probabilities; off-diagonals are false-alarm
(FP) and miss (FN) probabilities, totals are columns and row sums, rows headers are
“truth” and columns are “estimates” (guesses or predictions); (b) decision probabilities
distinguishing regions mapped to matrix at a given threshold location.
with (slight notational change: �n →n) PDET(n), PReject(n) and on the off-diagonals,
we have the corresponding false-alarm and miss probabilities PFA(n), PMiss(n).
A common jargon in diagnostics maps these probabilities into
PDET(n) ⇒PTP
−−−True positive rate
PReject(n) ⇒PTN
−−−True negative rate
PFA(n) ⇒PFP
−−−False positive rate
PMiss(n) ⇒PFN
−−−False negative rate
From these distribution values extracted from the ROC curve, we can calculate other
meaningful statistics.

436
SEQUENTIAL BAYESIAN DETECTION
We deine a positive instance or event as a “signal” and a negative event as a
“non-signal.” The true positives (TP) are the number of correct detections declared
and the corresponding true positive rate (tpr) is deined by
PDET(n) = tpr = TP
P = No. of correct threat detections
Total no. of threat realizations
(10.67)
corresponding to the detection probability at �n.
Likewise, the false positives (FP) are the number of detections declared when the
signal is not present and the corresponding false positive rate (fpr) is
PFA(n) = fpr = FP
N = No. of incorrect threat detections
Total no. of non-threat realizations
(10.68)
corresponding to the false-alarm probability at �n.
The true negatives (TN) are the number of true non-signals declared and the true
negative rate (tnr) is given by
PReject(n) = tnr = TN
N
= No. of correct non-threat detections
Total no. of non-threat realizations
(10.69)
corresponding to the rejection probability at �n.
Finally, the false negatives (FN) are the number of non-detections declared, then
the non-signal is not present and the false negative rate (fnr) is deined to be
PMiss(n) = fnr = FN
P
= No. of incorrect non-threat detections
Total no. of threat realizations
(10.70)
corresponding to the miss probability at �n.
Examining the confusion matrix further, we have that the column summations
(PTotal, NTotal) are the frequencies of occurrence of the truth (actual) items (signal/non-
signal) and the row summations (P
′
Total, N
′
Total) are the frequencies of the choices
(estimates) of the item. The total sample size NAll is the overall sum of all the
occurrences.
From these values extracted at a given operating point on the ROC curve, we can
calculate a variety of useful metrics such as
1. Accuracy (ACC ) is deined as the total number of correct decisions (signals
and non-signals) divided by the total possible correct, that is,
ACC = Total no. of correct decisions
Total no. of possible correct = TP + TN
P + N
(10.71)
2. Precision is usually deined as the “positive (signal)” predictive value (PPV)
or the “negative (non-signal)” predictive value (NPV), since they offer an

10.4
PERFORMANCE METRICS
437
indication of how well the detector can predict signals or non-signals and is
given by
PPV = No. of threat decisions
Total threat decisions =
TP
TP + FP
NPV = No. ofnonthreat decisions
Total non-threat decisions =
TN
TN + FN
1. Speciicity: SPEC = PReject = tnr = 1 −PFA = 1 −fpr
2. Sensitivity: SENS = tpr = PDET
It should be noted that ACC can be a misleading metric that should be used with
caution [21]. This completes the section on metrics derived from ROC curves.
Optimum Decision (Threshold) Point (ODP)
After obtaining the ROC
curve from a particular detector or equivalently a detection algorithm, it is natural to
ask the question: What is the “best” threshold �to set and its corresponding operating
point (PFA, PDET)? That is, what is the best tradeoff between cost (PFA) and beneit
(PDET) for the particular detection scheme? In order to answer this question, we can
cast the problem into one of Bayes’ risk by irst deining the various costs of making a
decision, deining the criterion in terms of these costs and determining the threshold
value (operating point) that minimizes this risk. Thus, in this section we develop
the relations to calculate the optimum decision (threshold) point (ODP) required
to choose the best operating point from the estimated or average ROC curve. The
Bayes’ risk criterion for this detector has the following costs (weights) associated
with decision making
r C00——cost of accepting 0 when 0 is true [Rejection]
r C01——cost of accepting 0 when 1 is true [Miss]
r C10——cost of accepting 1 when 0 is true [False alarm]
r C11—–cost of accepting 1 when 1 is true [Detection]
Also required are the prior probabilities associated with the underlying hypotheses
Pr(1) (signal) and Pr(0) (non-signal). With this information, we deine the Bayes’
risk criterion [3], [30] as before true
ℜ= C00Pr(accept 0, 0 true) + C01Pr(accept 0, 1 true)
+ C10Pr(accept 1, 0 true) + C11Pr(accept 1, 1 true) (10.72)
Applying Bayes’ rule (Pr(A, B) = Pr(A|B) × Pr(B)) to this expression, we obtain
ℜ= C00Pr(0) × Pr(accept 0|0 true) + C01Pr(0) × Pr(accept 0|1 true)
+ C10Pr(1) × Pr(accept 1|0 true) + C11Pr(1) × Pr(accept 1|1 true)

438
SEQUENTIAL BAYESIAN DETECTION
Recognizing the last term in each summand as known probabilities, we have
ℜ= C00Pr(0) × PReject + C01Pr(0) × PMiss
+ C10Pr(1) × PFA + C11Pr(1) × PDET
Substituting for PReject and PMiss in terms of false-alarm and detection probabilities
and gathering like-terms, we obtain the risk as
ℜ= C00Pr(0) + C01Pr(1) + (C10 −C00)Pr(0)
× PFA + (C11 −C01)Pr(1) × PDET
(10.74)
This expression is minimized by differentiating the risk criterion with respect to the
false-alarm probability, setting the result to zero and solving for the threshold or
equivalently the differential or slope of the ROC curve to give
dℜ
dPFA
= (C10 −C00)Pr(0) + (C11 −C01)Pr(1) × dPDET(�)
dPFA(�) = 0
(10.75)
where solving for the slope of the ROC with �→�∗
�∗= dPDET(�)
dPFA(�)
|||�=�∗= (C10 −C00)Pr(0)
(C01 −C11)Pr(1)
(10.76)
gives the slope leading to the desired ODP. We illustrate this calculation in the
following example.
Example 10.9
In this example, we return to the example illustrated in Fig. 10.5 where we show two
Gaussian decision functions N(110, 5) and N(120, 5.5) where the notation (M, V)
is a normal distribution with mean M and variance V. An ensemble of 100-members
was generated for the non-signal or disturbance and signal distributions, respec-
tively. Using the “brute force” method described earlier, each member ROC curve
was estimated and threshold averaged. The results are shown in Fig. 10.8. First
we note the (average) AROC obtained using the threshold averaging method dis-
cussed earlier along with its corresponding ±2�conidence limits (bounds). We also
observe the optimal decision threshold point (diamond) and its associated uncertainty
(2�−by−1�) box indicating the maximum and minimum uncertainty for both PDET
(vertical sides) and PFA (horizontal sides). In Fig. 10.8, we see some of the other
metrics (e.g., AUC, ODP ) calculated as well as the inset of the ODP. These metrics
are summarized in Table 10.1.

0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
PFA-Probability of false alarm
PD-Probability of detection
ROC Curves for 100-Ensemble Runs:
AUC = 0.911, optimal ROC point = [0.156, 0.820]
Threshold at optimal ROC point = 0.0419
ROC curves
Avg ROC curve
Bounds (threshold Avg.)
Error box wrt/[Avg & Opt O.P.]
Optimal operating point
FIGURE 10.8
Final ROC curve for Gaussian decision function example including met-
rics along with legend with optimal decision function operating point, average (thresh-
old averaging) and bounds.
TABLE 10.1
Results for Gaussian Decision
Function Example
Ensemble Average Results
No. of ensemble members
100
Area under curve
0.91
Distance
4
Min. error probability
14.9
Optimum decision point
[0.16,0.82]
Confusion matrix
[0.82 0.16;0.18 0.84]
Detection probability
0.82
False alarm probability
0.16
Rejection probability
0.84
Miss probability
0.18
Accuracy
0.83
Positive pred. value
0.94
Negative pred. value
0.61
△△△

440
SEQUENTIAL BAYESIAN DETECTION
In this section, we have developed the concept of performance metrics for auto-
mated detection systems. We have shown both pictorially and mathematically (briely)
how the ROC curve evolves from the detection and false-alarm probabilities. We have
also shown how a variety of performance metrics can be extracted from the ROC
curve computation and how some enable a “single number” point (AUC, ODP, ACC,
etc.) that can be used for performance ranking the performance of detection sys-
tems. Next, we investigate methods that provide an alternative to “batch” detection
processing—the sequential approach.
10.5
SEQUENTIAL DETECTION
In many real-time applications, a decision must be made quite rapidly. Batch schemes
are exactly that—a batch of data is gathered and made available to the detector and
a decision is made. For off-line applications this is acceptable, but a ighter pilot in a
life/death situation must have an instantaneous indicator that a lethal weapon not a
bird is approaching the aircraft. A reasonable approach to this problem of making
a reliable decision with high conidence in a timely manner is to develop a sequen-
tial detection processor. At each measurement sample y(t), we sequentially update
the decision function and compare it to the thresholds to perform the detection—
“sample-by-sample”. Here as each sample is collected producing the measurement
sequence, the detector processes that measurement and attempts to “decide” whether
or not it has evolved from the signal. Therefore, for each measurement the decision
function is “sequentially” updated and compared to the detection thresholds obtained
from the ROC curve operating point enabling a rapid decision. Once the threshold
is crossed, the decision (signal or non-signal) is made and the measurement is pro-
cessed; however, if not enough data are available to make the decision, then another
measurement is collected. Realize, of course, that the decision function is random
(see Fig. 10.9), but once either of the thresholds is crossed the detection is achieved
(star in igure) and a decision is made.
We continue with the multiple channel/multiple measurement development, since
other scenarios can be considered special cases of this formulation. Thus, an alter-
native to the batch approach is the sequential method which can be developed
by expanding the likelihood-ratio for each instantaneous vector measurement to
obtain
(YN) =
Pr(YN|1
)
Pr(YN|0
) =
Pr(y(t0), y(t1), … , y(tN)|1
)
Pr(y(t0), y(t1), … , y(tN)|0
)
(10.77)
From the chain rule of probability
Pr(YN|�
) =
t∏
k=0
Pr(y(t −k)|Yt−k−1; �
); �= 0, 1
(10.78)

10.5
SEQUENTIAL DETECTION
441
Sample
Decision function
Threshold 1 
Threshold 0 
Signal
Non-signal
No decision 
(Take another sample)
Confidence: Detection/false alarm probabilities 
Performance: Receiver operating characteristic  
Sequential detector
FIGURE 10.9
Conceptual implementation of the sequential detection technique. As
each individual sample is extracted,the decision function is calculated and compared
to thresholds to “decide” if the signal is present or not (non-signal). Quantitative perfor-
mance and sequential thresholds are determined from estimated ROC curves.
and Bayes’ rule [20], we have that
Pr(YN|�
) = Pr(y(N), YN−1|�
) = Pr(y(N)|YN−1, �
) × Pr(YN−1|�
)
(10.79)
for �= 0, 1.
Substituting this expression into the likelihood-ratio above, replacing t →N group-
ing and reordering, we obtain
(Yt) =
Pr(Yt−1|1
)
Pr(Yt−1|0
) ×
Pr(y(t)|Yt−1, 1
)
Pr(y(t)|Yt−1, 0
)
(10.80)
and the recursion or equivalently sequential likelihood-ratio for the tth measurement
follows as
(Yt) = (Yt−1) ×
Pr(y(t)|Yt−1, 1
)
Pr(y(t)|Yt−1, 0
)
(10.81)
with t = 0, … , N and Pr(y(0)|Y−1, �
) = Pr(y(0)|�
), the prior under each
hypothesis.
Before we close this section, it should be noted that many problems can be
characterized by distributions that are members of the exponential family; therefore,
we can take the natural logarithm of Eq. 10.81 producing a monotonic function that
does not alter the decision theoretic results. Thus, the sequential log-likelihood-ratio
Λ(Yt) = ln (Yt) is deined by
Λ(Yt) = Λ(Yt−1) + ln Pr(y(t)|Yt−1, 1
) −ln Pr(y(t)|Yt−1, 0
)
(10.82)

442
SEQUENTIAL BAYESIAN DETECTION
10.5.1
Sequential Decision Theory
In this subsection, we discuss two approaches to sequential decision theory: the
Bayesian approach and the Neyman–Pearson approach [3]. For the batch approach,
we compared the likelihood decision function to a threshold that evolved from the
speciic decision criterion selected. In contrast, for the sequential decision function
(above) there must be two thresholds, an upper and a lower, that vary with the number
of measurements—sequentially. If the decision function exceeds the upper threshold
then 1 is decided, while if it is below the lower then 0 is decided. In between the
thresholds, no decision is made and another data sample must be processed.
Bayesian Approach
To determine the threshold of a test, the prior probabilities
of each hypothesis are required, that is, from Bayes’ rule for the posterior probability
at the tth step Pr(�|t), we have that [8]
Pr(1|t) =
Pr(t|1
) × Pr(1)
Pr(t|0
) × Pr(0) + Pr(t|1
) × Pr(1)
(10.83)
similarly for 0
Pr(0|t) =
Pr(t|0
) × Pr(0)
Pr(t|0
) × Pr(0) + Pr(t|1
) × Pr(1)
(10.84)
where the posterior for each hypothesis satisfy the relation
Pr(0|t) + Pr(1|t) = 1
Therefore, dividing Eq. 10.83 by Eq. 10.84 we have that
Pr(1|t)
Pr(0|t) =
Pr(t|1
)
Pr(t|0
) ×
Pr(1
)
Pr(0) = (t) ×
Pr(1
)
Pr(0)
(10.85)
In statistics [8], this expression relates the posterior odds ratio to the prior odds
ratio through the likelihood which is called the Bayes’ factor.
From the sequential perspective [3], we can consider the posterior at step t to be
related to the posterior at the previous stage t −1 by
Pr(1; t) = Pr(1|y(t −1))
=
Pr(y(t −1)|1
) × Pr(1; t −1)
Pr(y(t −1)|0
) × Pr(0; t −1) + Pr(y(t −1)|1
) × Pr(1; t −1)
(10.86)

10.5
SEQUENTIAL DETECTION
443
and for the null hypothesis we have a similar relation using Bayes’ rule for the
posterior
Pr(0; t) = Pr(0|y(t −1))
=
Pr(y(t −1)|0
) × Pr(0; t −1)
Pr(y(t −1)|0
) × Pr(0; t −1) + Pr(y(t −1)|1
) × Pr(1; t −1)
(10.87)
Dividing Eq. 10.86 by Eq. 10.87 we obtain
Pr(1; t)
Pr(0; t) = (y(t −1)) ×
Pr(1; t −1)
Pr(0; t −1)
(10.88)
If we impose the independent measurement constraint, then we can easily show by
induction that
Pr(1; t)
Pr(0; t) = (Yt−1
) ×
Pr(1
)
Pr(0
)
(10.89)
completing the general Bayes’ approach to sequential hypothesis testing.
Neyman–Pearson: Wald SPRT Approach
The sequential probability-ratio
test (SPRT) is a modiication of the Neyman–Pearson scheme for sequential detection
[32]. It follows directly from the likelihood decision function assuming that after N-
samples 1 is accepted so that
(YN) = Pr(YN|1)
Pr(YN|0) = 1(N)
(10.90)
cross-multiplying and integrating both sides over D1, we have that
∫D1
Pr(YN|1)dY = 1(N) × ∫D1
Pr(YN|0)dY
(10.91)
or in terms of detection, miss and false-alarm probabilities this relation becomes
PDET = 1 −PMiss = 1(N) × PFA
(10.92)
Alternatively, if 0 is accepted, then following the same approach we have
(YN) = Pr(YN|1)
Pr(YN|0) = 0(N)
(10.93)

444
SEQUENTIAL BAYESIAN DETECTION
and cross-multiplying and integrating both sides over D0, we obtain
PMiss = 0(N) × (1 −PFA
)
(10.94)
Solving these relations individually, the thresholds are speciied in terms of the
false-alarm (PFA) and miss (PM) probabilities with t ⟶N as
0(t) =
PMiss(t)
1 −PFA(t);
1(t) = 1 −PMiss(t)
PFA(t)
(10.95)
These thresholds are determined from an ROC curve (detection vs. false-alarm
probabilities) obtained by simulation or a controlled experiment to calculate the
decision function. That is, an operating point is selected from the ROC corresponding
to speciic detection (or equivalently miss) and false-alarm probabilities, specifying
the required thresholds which are calculated according to Eq. 10.95 for each parameter
update.
Therefore, the SPRT is now completely speciied by
(y(t))
> 1(t)
Accept 1
0(t)
≤(y(t))
≤1(t)
Continue
(y(t))
< 0(t)
Accept 0
(10.96)
It should be noted that the non-sequential Bayesian detection technique is optimum
in the sense that no other hypothesis test can achieve a smaller average risk (smallest
error probabilities [32]).
For the case of the sequential log-likelihood, the SPRT is given by
Λ(y(t))
> ln 1(t)
Accept 1
ln 0(t)
≤Λ(y(t))
≤ln 1(t)
Continue
Λ((y(t))
< ln 0(t)
Accept 0
(10.97)
This approach was developed under the assumption that the number of measure-
ments required to achieve this optimum is known (ixed) in advance. In relaxing
this constraint, sequential detection techniques are superior to ixed non-sequential
Bayesian detection in the sense that “on the average” a substantially smaller number
of measurements are required to achieve the same error probabilities. The disad-
vantage though is that this number of measurements required to make a decision
is a random number and therefore we must estimate its expected value or average
value.
With this in mind, we show that the average number of measurements
̂=
E{N|�} required to reach a decision can be estimated [3], [32]. Starting with the
log-likelihood ratio for a batch of N measurements YN, assuming each is independent

10.5
SEQUENTIAL DETECTION
445
and identically distributed (i.i.d.) then so is each Λ(y(t)) and therefore we have
that
Λ(YN
) =
N
∑
t=1
Λ(y(t))
(10.98)
The joint expectation conditioned on each hypothesis �; �= 0, 1 and N is
EΛ
{
Λ(YN
)|�
}
= EN
{
EΛ
{
Λ(YN
)|N, �
}}
(10.99)
but because of independence and performing the expectation over N, we have
EΛ
{
Λ(YN
)|�
}
= E{N|�} × E
{
Λ(y(t))|�
}
(10.100)
and therefore we have that the average number of measurements required can be
estimated from
̂= E{N|�} =
E
{
Λ(YN
)|�
}
E
{
Λ(y(t))|�
}
(10.101)
The following possible conditions on the sequential decision boundaries (ignoring
the “continue” option)
Λ(YN
) = ln 0 with 0 true which implies Pr(ln 0|0) = 1 −PFA
Λ(YN
) = ln 0 with 1 true which implies Pr(ln 0|1) = PMiss
Λ(YN
) = ln 1 with 0 true which implies Pr(ln 1|0) = PFA
Λ(YN
) = ln 1 with 1 true which implies Pr(ln 1|1) = 1 −PMiss
Combining these relations, we see that the expected log-likelihood under a given
hypothesis is
E{Λ(YN)|�} =
{
ln 0(1 −PFA) + ln 1PFA
0 true
ln 0PMiss + ln 1(1 −PMiss)
1 true
(10.102)
Finally substituting into Eq. 10.101, we obtain the relations for the average number
of measurements to make a decision using the log-likelihood decision function to
perform the SPRT as
̂=
⎧
⎪
⎨
⎪⎩
ln 0(1−PFA)+ln 1PFA
E{Λ(y(t))|�}
0 true
ln 0PMiss+ln 1(1−PMiss)
E{Λ(y(t))|�}
1 true
(10.103)

446
SEQUENTIAL BAYESIAN DETECTION
Returning to the likelihood relations, we obtain similar expressions for the
expected number of measurements to make a decision with the expected likelihood
under a given hypothesis given by
E{(YN)|�} =
{
0(1 −PFA) + 1PFA
0 true
0PMiss + 1(1 −PMiss)
1 true
(10.104)
and the average number of measurement samples
̂=
⎧
⎪
⎨
⎪⎩
0(1−PFA)+1PFA
E{(y(t))|�}
0 true
0PMiss+1(1−PMiss)
E{(y(t))|�}
1 true
(10.105)
Next, we return to our previous example and develop the “sequential” solution.
Example 10.10
Suppose we have the vector signal s(t) = �∈Ny×1 that is contaminated with addi-
tive, zero-mean Gaussian measurement noise v(t) of variance R��and we would like
to construct the sequential likelihood-ratio under the same assumptions of Example
10.6.
The likelihood decision function is
(Yt) = (Yt−1) × 1
2 exp
{
�TR−1
��y(t) + yT(t)R−1
���
}
1
>
=
<
0
1 + 1
2�TR−1
���
No decision
0 + 1
2�TR−1
���
where we have moved all known functions into the threshold. For the log-likelihood
we have
Λ(Yt) = Λ(Yt−1) + 1
2�TR−1
��y(t) + 1
2yT(t)R−1
���
1
>
=
<
0
ln 1 + 1
2�TR−1
���
No decision
ln 0 + 1
2�TR−1
���
Since the average sample log-likelihood under each hypothesis for this problem
is found by examining the thresholds,
Λ(y(t)|�
) = 1
2�TR−1
���

10.6
MODEL-BASED SEQUENTIAL DETECTION
447
we can estimate the average number of measurements required to make a decision
from Eq. 10.103
The average number of samples can be estimated from
̂=
⎧
⎪
⎨
⎪⎩
2×(
ln 0(1−PFA)+ln 1PFA
)
�TR−1
���
0 true
2×(
ln 0PMiss+ln 1(1−PMiss
)
�TR−1
���
1 true
△△△
This completes the example, next we consider the sequential model-based solu-
tions to solve the binary detection problem when a priori information about the signal
is known.
10.6
MODEL-BASED SEQUENTIAL DETECTION
In this section, we arrive at the heart of this chapter—the application of the sequential
detection theory to Bayesian model-based techniques. Here we show how to solve
the joint signal estimation/detection problem by combining some of the sequential
processors with the sequential likelihood detection approach. All of the results are
based on creating the likelihood decision function and specifying the threshold (ROC
curves) corresponding to the decision function selected. We start with the linear
Gauss–Markov model set, discuss the nonlinear case, and then generalize to the
non-Gaussian case.
10.6.1
Linear Gaussian Model-Based Processor
In this section, we develop the model-based approach to sequential detection employ-
ing the sequential likelihood-ratio as the mechanism to implement the model-
based designs starting with the linear time-varying (non-stationary) problem (see
Refs.[3]and [33] for more details). We begin with the development of the generic
Gauss–Markov signal model deined by its state (signal) vector s(t), where the linear
state-space process model is given by
s(t) = A(t −1)s(t −1) + B(t −1)u(t −1) + w(t −1)
(10.106)
with corresponding measurement model as
y(t) = C(t)s(t) + v(t)
(10.107)
where s, w are the Ns-dimensional signal and process noise vectors, with y, v the Ny-
dimensional measurement and noise vectors along with u the Nu-dimensional known
input vector. Both w and v are zero-mean, Gaussian with respective covariances
Rww(t −1) and Rvv(t). The corresponding system, input and measurement matrices
are appropriately dimensioned and given by A(t −1), B(t −1), and C(t), respectively.
The initial state vector is Gaussian with s(0) ∼(s(0), Pss(0)).

448
SEQUENTIAL BAYESIAN DETECTION
Because the underlying distributions are Gaussian, we know that the optimal
solution to the signal estimation problem is given by the model-based processor
(Kalman ilter of Section 5.3) providing the predicted conditional mean estimate
̂s(t|t −1) = E{s(t)|Yt−1)1 with corresponding predicted conditional (error) covari-
ance ̃P(t|t −1) [33,34].
With this signal model in hand, we can now deine the binary problem to decide
whether the measurement contains the signal and noise or just noise alone, that is,
we are testing the hypotheses that
0 :
y(t) = v(t)
[Noise]
1 :
y(t) = C(t)s(t) + v(t)
[Signal+Noise]
From the underlying Gauss–Markov assumption, the sequential likelihood-ratio
solution is speciied by the ratio of conditional Gaussian posterior distributions
Pr(y(t)|Yt−1; i); i = 0, 1. That is,
(y(t)) = Pr(y(t)|Yt−1; 1)
Pr(y(t)|Yt−1; 0)
(10.108)
with the conditional probabilities distributed as
Pr(y(t)|Yt−1; 0) ∼(y(t) : 0, Rvv(t)
)
Pr(y(t)|Yt−1; 1) ∼(y(t) : C(t)̂s(t|t −1), Ree(t))
where the innovations e(t) and its corresponding covariance Ree(t) are obtained as
outputs of the model-based processor (Kalman ilter) speciied by
e(t) = y(t) −̂y(t|t −1) = y(t) −C(t)̂s(t|t −1)
Ree(t) = C(t)̃P(t|t −1)C′(t) + Rvv(t)
(10.109)
Thus, under the null hypothesis we have that
Pr(y(t)|Yt−1; 0) =
1
(2�)Ny∕2|Rvv(t)|1∕2 exp
{
−1
2y′(t)R−1
vv (t)y(t)
}
(10.110)
while the conditional probability under alternate hypothesis is given by
Pr(y(t)|Yt−1; 1) =
1
(2�)Ny∕2|Ree(t)|1∕2 ×
exp
{
−1
2(y(t) −̂y(t|t −1))′R−1
ee (t)(y(t) −̂y(t|t −1))
}
(10.111)
1 Recall that this notation is deined in terms of predicted conditional means and covariances by ̂s(t|t −1)
and ̃P(t|t −1) = cov(̃s(t|t −1)) for the predicted state estimation error, ̃s(t|t −1) = s(t) −̂s(t|t −1).

10.6
MODEL-BASED SEQUENTIAL DETECTION
449
or simply
Pr(y(t)|Yt−1; 1) =
1
(2�)Ny∕2|Ree(t)|1∕2 exp
{
−1
2e′(t)R−1
ee (t)e(t)
}
(10.112)
Moving all known terms to the threshold, the required sequential log-likelihood
of Eq. 10.82 for the linear Gauss–Markov signal model becomes
Λ(Yt) = Λ(Yt−1) −1
2e′(t)R−1
ee (t)e(t) + 1
2y′(t)R−1
vv (t)y(t)
1
>
=
<
0
T1
No decision
T0
T�(t) = ln �(t) −ln
(
1
(2�)Ny∕2|Ree(t)|1∕2
)
+ ln
(
1
(2�)Ny∕2|Rvv(t)|1∕2
)
; �= 0, 1
(10.113)
All that remains is to specify the predicted and corrected means and covariances
to implement the sequential detector. These are available as part of the model-based
algorithm given by
̂s(t|t −1) = A(t −1)̂s(t −1|t −1) + B(t −1)u(t −1)
[Prediction]
̃P(t|t −1) = A(t −1)̃P(t −1|t −1)A′(t −1) + Rww(t −1)
[Prediction cov.]
̂s(t|t) = ̂s(t|t −1) + K(t)e(t)
[Correction]
̃P(t|t) = [I −K(t)C(t)] ̃P(t|t −1)
[Correction cov.]
for K(t) the corresponding gain (see Ref. [33] for more details), next we consider
the RC-circuit problem of Example 5.1 and construct a model-based sequential
detector.
Example 10.11
Let us return to the RC-circuit of Example 5.1 where we have the Gauss–Markov
model given by
s(t) = 0.97s(t −1) + 100u(t −1) + �(t −1)
y(t) = 2s(t) + �(t)
(10.114)
�∼(0, 10−5), �∼(0, 4) and s(0) ∼(2.5, 10−6).
We simulated this system as before shown in Fig. 5.3 and constructed the model-
based processor resulting in Fig. 5.4.

450
SEQUENTIAL BAYESIAN DETECTION
The log-likelihood decision function is
Λ(t) = Λ(t −1) −
e2(t)
2Ree(t) + y2(t)
8
1
>
=
<
0
T1
No decision
T0
T�(t) = ln �(t) −ln
(
1
√
2�|Ree(t)|
)
+ ln
(
1
2
√
2�
)
; �= 0, 1
where we have moved all known functions into the threshold.
Recall that in order to estimate the thresholds, we irst must estimate the ROC
curve. The simulation was executed irst for the known signal case as shown in Fig. 5.4
and then for the case of noise only. The results are shown in Fig. 10.10 where we
see the estimated ROC curve in 10.10d and the log-likelihood for both cases with the
corresponding thresholds in 10.10a,b along with the underlying PMFs in 10.10c. Here
Time (sec)
0
5
10
15
20
25
30
–100
0
100
200
300
400
500
600
700
Sequential model-based detection:
(Pdet, Pfa) = (0.817527, 0.10732)
Time (sec)
0
5
10
15
20
25
30
Log-likelihood decision function
Log-likelihood decision function
–120
–100
–80
–60
–40
–20
0
20
Sequential model-based detection:
(Pdet, Pfa) = ( 0.817527, 0.1073  )
LLike
LLike
Thresh1
Thresh0
LLike
LLike
Thresh1
Thresh0
(a)
(b)
Probability of false alarm
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Probability of detection
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
ROC curve: (Pfa, Pdet) = (0.10732, 0.817527)
The OPTIMUM thresholds for sequential
detection are: Tau0 = 0.20441 and Tau1 = 7.61769 
(d)
Samples
–200 –100 0
100 200 300 400 500 600 700
Probability
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
0.045
0.05
Log-likelihood PMFs
(c)
Yt
Yt
1
0
1
0
FIGURE 10.10
Sequential model-based detector design for RC-Circuit problem: (a)
signal case: log-likelihood detection; (b) noise case: log-likelihood detection; (c) log-
likelihood PMFs; (d) ROC curve.

10.6
MODEL-BASED SEQUENTIAL DETECTION
451
the detection and false-alarm probabilities were PDET = 0.81 and PFA = 0.11 at the
optimum threshold. Using Eq. 10.113, we calculate the corresponding thresholds as
ln 0 = −1.59 and ln 1 = 2.03 leading to the thresholds T1(t) = 1.75 + ln
1
√
2�|Ree(t)|
and T0(t) = −1.87 + ln
1
√
2�|Ree(t)|. In steady-state we have that T1 ≈2.03 and
T1 ≈−1.59.
△△△
This completes the example, next we consider the sequential model-based solu-
tions to solve the binary detection problem for nonlinear processes.
10.6.2
Nonlinear Gaussian Model-Based Processor
In this section, we use the development of the linear case as a road map and develop
the sequential model-based detector for the nonlinear case. We start with the nonlinear
(approximate) Gauss–Markov model given by
s(t) = a [s(t −1)] + b [u(t −1)] + w(t −1)
y(t) = c [s(t)] + v(t)
(10.115)
where (as before) s, w are the Ns-dimensional signal and process noise vectors with y,
v the Ny-dimensional measurement and noise vectors along with u the Nu-dimensional
known input vector. Both w and v are zero-mean Gaussian with respective covariances
Rww(t −1) and Rvv(t). The corresponding nonlinear system, input and measurement
vector functions are appropriately dimensioned and given by a[⋅], b[⋅] and c[⋅],
respectively. The initial state vector is Gaussian with s(0) ∼(s(0), Pss(0)).
Because the underlying distributions are assumed approximately Gaussian, we
know that one possible solution to the signal estimation problem is given by the
model-based processor (extended Kalman ilter2) providing the predicted conditional
mean estimate ̂s(t|t −1), with corresponding predicted conditional (error) covariance
̃P(t|t −1) [33].
With this nonlinear signal model in hand, we can now deine the binary problem
to decide whether the measurement contains the signal or just noise alone, that is, we
are testing the hypotheses that
0 :
y(t) = v(t)
[Noise]
1 :
y(t) = c [s(t)] + v(t)
[Signal+Noise]
(10.116)
Before we proceed with the sequential detection development for nonlinear,
non-Gaussian problems, we have chosen to employ the irst-order Taylor series rep-
resentation to approximate the nonlinear vector functions. The development evolves
2 It is well known that some of the modern estimation techniques available ([33], [35]) offer improved alter-
natives like the unscented Kalman ilter of Chapter 6, but we choose this formulation from a pedagogical
perspective, since its easily tracks the linear case developed in the previous subsection.

452
SEQUENTIAL BAYESIAN DETECTION
quite naturally from a linearized model-based processor (linearized Kalman ilter)
[33]. These approximations when expanded about a reference s = s∗take the general
form
c [s(t)] ≈c [s∗(t)] + C [s∗(t)] × (s(t) −s∗(t)) + H.O.T.
(10.117)
with Jacobian matrix C[s∗(t)] := �
�sc[s]||s=s∗(t). Each of the nonlinear system, input
and measurement functions are approximated in this manner using the Taylor series.
For the ad hoc nonlinear EKF processor, the most current estimate available, ̂s(t| ∗),
is used as a reference during the prediction and correction steps for the linearization,
that is, the state estimates are
̂s(t|t −1) = a [̂s(t −1|t −1)] + b [u(t −1)]
̂s(t|t) = ̂s(t|t −1) + K [̂s(t|t −1)] e(t)
(10.118)
where the Jacobians appear in the covariance equations.
With this in mind and from the underlying approximate Gauss–Markov assump-
tion, the sequential likelihood-ratio solution is again speciied by the ratio of con-
ditional Gaussian posterior distributions Pr(y(t)|Yt−1; i); i = 0, 1 as before. That
is,
Pr(y(t)|Yt−1; 0) ∼
(
y(t) : 0, Rvv(t)
)
Pr(y(t)|Yt−1; 1) ∼
(
y(t) : c
[
̂s(t|t −1)
]
, Ree(t)
)
where the innovations e(t) and its corresponding covariance Ree(t) are obtained as
outputs of the model-based processor (extended Kalman ilter) speciied by
e(t) = y(t) −̂y(t|t −1) = y(t) −c [̂s(t|t −1)]
Ree(t) = C [̂s(t|t −1)] ̃P(t|t −1)C′ [̂s(t|t −1)] + Rvv(t)
(10.119)
Thus, under the null hypothesis we have that
Pr(y(t)|Yt−1; 0) =
1
(2�)Ny∕2|Rvv(t)|1∕2 exp
{
−1
2y′(t)R−1
vv (t)y(t)
}
(10.120)
while the conditional probability under alternate hypothesis is given by
Pr(y(t)|Yt−1; 1) =
1
(2�)Ny∕2|Ree(t)|1∕2 exp
{
−1
2e′(t)R−1
ee (t)e(t)
}
(10.121)

10.6
MODEL-BASED SEQUENTIAL DETECTION
453
Again moving all known terms to the threshold, the required sequential log-
likelihood for the nonlinear Gauss–Markov signal model becomes
Λ(Yt) = Λ(Yt−1) −1
2e′(t)R−1
ee (t)e(t) + 1
2y′(t)R−1
vv (t)y(t)
1
>
=
<
0
T1
No decision
T0
T�(t) = ln �(t) −ln
(
1
(2�)Ny∕2|Ree(t)|1∕2
)
+ ln
(
1
(2�)Ny∕2|Rvv(t)|1∕2
)
; �= 0, 1
(10.122)
All that remains is to specify the predicted and corrected covariances to implement
the sequential detector, since the state estimates we given in Eq. 10.118. These are
available as part of the nonlinear model-based algorithm (EKF) given by
̃P(t|t −1) = A [̂s(t|t −1)] ̃P(t −1|t −1)A′ [̂s(t|t −1)] + Rww(t −1)
[Prediction cov.]
̃P(t|t) = [I −K [̂s(t|t −1)] C [̂s(t|t −1)]] ̃P(t|t −1)
[Correction cov.]
for A the system Jacobian and K [̂s(t|t −1)] the corresponding gain (see Ref. [33]
for more details). This completes the development.
Example 10.12
Let us return to the nonlinear problem of Example 5.2 where we have the nonlinear
Gauss–Markov model given by
s(t) = (1 −0.05△T)s(t −1) + 0.04△Ts2(t −1) + �(t −1)
y(t) = s2(t) + s3(t) + �(t)
�∼(0, 10−6), �∼(0, 0.09) and s(0) ∼(2.3, 10−2) and △T = 0.01 sec.
We simulated this system as before and constructed the model-based processor
resulting in Fig. 5.5.
The log-likelihood decision function is
Λ(t) = Λ(t −1) −
e2(t)
2Ree(t) + y2(t)
5.6
1
>
=
<
0
T1
No decision
T0
T�(t) = ln �(t) −ln
(
1
√
2�|Ree(t)|
)
+ ln
(
1
2
√
2�
)
; �= 0, 1
where we have moved all known functions into the threshold.

454
SEQUENTIAL BAYESIAN DETECTION
Time (s)
0
0.5
1
1.5
Log-likelihood decision function
Log-likelihood decision function
×105
×105
–0.5
0
0.5
1
1.5
2
2.5
3
Sequential model-based detection:
(Pdet, Pfa) = (0.902, 0.26)
Time (s)
0
0.5
1
1.5
–20000
–15000
–10000
–5000
0
5000
Sequential model-based detection:
(Pdet, Pfa) = (0.902, 0.26)
Probability of false alarm
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Probability of detection
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
ROC curve: (Pfa, Pdet) = (0.260206, 0.902396) 
(a)
(b)
(d)
The OPTIMUM thresholds for sequential
detection are: Tau0 = –0.21 and Tau1 = 1.20
Samples
–2
–1
0
1
2
3
4
Log-likelihood probability
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
Log-likelihood pmfs
H0
H1
(c)
LLike
LLike
Thresh1
Thresh0
LLike
LLike
Thresh1
Thresh0
Yt
Yt
1
0
1
0
FIGURE 10.11
Sequential model-based detector design for nonlinear problem: (a)
signal case: log-likelihood detection; (b) noise case: log-likelihood detection; (c) log-
likelihood PMFs; (d) ROC curve. (AUC = 0.86.)
Recall that in order to estimate the thresholds, we irst must estimate the ROC
curve. The simulation was executed irst for the known signal case as shown in
Fig. 5.4 and then for the case of noise only. The results are shown in Fig. 10.11 where
we see the estimated ROC curve in 10.11d and the log-likelihood for both cases with
the corresponding thresholds in 10.11a,b along with the underlying PMFs in 10.11c.
Here the detection and false-alarm probabilities were PDET = 0.90 and PFA = 0.26 at
the optimum threshold. Using Eq. 10.113 we calculate the corresponding thresholds as
ln 0 = −0.203 and ln 1 = 1.24 leading to the thresholds T1(t) = 1.10 + ln
1
√
2�|Ree(t)|
and T0(t) = −2.17 + ln
1
√
2�|Ree(t)|. In steady-state we have that T1 ≈1.20 and T0 ≈
−0.205. The AUC for this detector was AUC = 0.86.
△△△
This completes the example, next we consider the sequential model-based solu-
tions to solve the binary detection problem for non-Gaussian processes.
10.6.3
Non-Gaussian Model-Based Processor
Non-Gaussian processes are prevalent in many applications such as tracking, biomed-
ical processing and inancial problems [36–39]. The same basic nonlinear additive

10.6
MODEL-BASED SEQUENTIAL DETECTION
455
noise model of Eq. 1.101 governs the dynamics and measurements of the non-
Gaussian processor although it is not limited to additive noise which could be mul-
tiplicative. Perhaps it is best to start from the Bayesian perspective in this case and
point out that the “data” likelihood distribution (evidence of Section 2.53) is required
to implement a sequential detection scheme. We require an estimate of the data
likelihood
̂Pr(y(t)|Yt−1; �); �= 0, 1
(10.123)
under each hypothesis of Eq. 1.102.
In order to obtain this estimate, we can use the particle ilter processors of Chap-
ter 7. Recall that the generic PF (Table 7.1) provides an estimate of the iltering
distribution both before the required resampling as a non-uniformly weighted prob-
ability mass function
̂Pr(x(t)|Yt) =
Np
∑
i=1
i(t)�(x(t) −xi(t))
(10.124)
where is the normalized importance weight and after resampling (̂xi →xi) by the
uniformly weighted PMF
̂Pr(x(t)|Yt) = 1
Np
Np
∑
i=1
�(x(t) −̂xi(t))
(10.125)
These estimates, depending on the choice of importance distribution q(⋅) (see
Section 7.3), lead to particular sets of weights. Therefore from Bayes’ rule the data
likelihood of Eq. 2.81
Pr(y(t)|Yt−1) = ∫Pr(y(t)|x(t)) × Pr(x(t)|Yt−1)dx(t)
(10.126)
coupled with the assumption of a “perfect sampler” for the one-step prediction
distribution
̂Pr(x(t)|Yt−1) = 1
Np
Np
∑
i=1
�(x(t) −xi(t))
gives the estimated data likelihood as
̂Pr(y(t)|Yt−1) = ∫Pr(y(t)|x(t)) ×
( 1
Np
Np
∑
i=1
�(x(t) −xi(t)))
dx(t)
= 1
Np
Np
∑
i=1 ∫Pr(y(t)|x(t)) × �(x(t) −xi(t))dx(t)
(10.127)

456
SEQUENTIAL BAYESIAN DETECTION
or
̂Pr(y(t)|Yt−1) ≈1
Np
Np
∑
i=1
Pr(y(t)|xi(t))
(10.128)
If we further assume a irst-order Markov process (Yt−1 →y(t −1)) and choose the
importance distribution to be the state transition q(x(t)|x(t −1), Yt) →Pr(x(t)|x(t −
1)), then the bootstrap PF of Table 7.2 results with the state likelihood weight, that
is, i(t) →Pr(y(t)|xi(t)) or Eq. 10.128 can be approximated by
̂Pr(y(t)|y(t −1)) = 1
Np
Np
∑
i=1
Pr(y(t)|xi(t)) ≈1
Np
Np
∑
i=1
i(t)
(10.129)
or simply deining the ensemble mean of the weight at each instant as
(t) = 1
Np
Np
∑
i=1
i(t)
(10.130)
we have
̂Pr(y(t)|y(t −1)) ≈(t)
(10.131)
this is an a priori estimate that employs the predicted state (point) estimate ̂x(t|t −1).
Other approaches to estimating the data likelihood can be obtained as well
[40, 41]. They also evolve from Bayes’ rule and the Chapman–Kolomogorov
relations
̂Pr(y(t)|Yt−1) = ∫Pr(y(t)|x(t)) × Pr(x(t)|Yt−1) dx(t)
(10.132)
or equivalently
̂Pr(y(t)|Yt−1) = ∫Pr(y(t)|x(t −1)) × Pr(x(t −1)|Yt−1) dx(t −1) (10.133)
Using the predicted estimate (weight) at time t, we have that
̂Pr(x(t)|Yt−1) = 1
Np
Np
∑
i=1
i(t)�(x(t) −xi(t))
(10.134)

10.6
MODEL-BASED SEQUENTIAL DETECTION
457
then following the same steps as before and using the sifting property of the delta
function, we have
̂Pr(y(t)|Yt−1) ≈1
Np
Np
∑
i=1
i(t) × Pr(y(t)|xi(t))
(10.135)
while using the iltered estimate at time t −1, we obtain
̂Pr(x(t −1)|Yt−1) ≈1
Np
Np
∑
i=1
i(t −1)�(x(t −1) −xi(t −1))
(10.136)
leading to
̂Pr(y(t)|Yt−1) = 1
Np
Np
∑
i=1
i(t −1) × Pr(y(t)|xi(t −1))
(10.137)
More details of these processors can be found in Ref. [36], [40] and [41]; here we
will apply the bootstrap PF approximation of Eq. 10.131 to develop our sequential
detectors.
For the non-Gaussian detection problem, we again calculate the likelihood-ratio
decision function using the estimated data likelihood from the PF as
(y(t)) =
̂Pr(y(t)|Yt−1; 1)
̂Pr(y(t)|Yt−1; 0)
(10.138)
Taking logarithms and substituting the empirical distribution estimates the sequen-
tial log-likelihood formulation results
Λ(y(t)) = Λ(y(t −1)) + ln ̂Pr(y(t)|Yt−1; 1) −ln ̂Pr(y(t)|Yt−1; 0)
(10.139)
Consider the nonlinear example of the previous subsection.
Example 10.13
Let us return to the problem where we again have the nonlinear model given by
s(t) = (1 −0.05△T)s(t −1) + 0.04△Ts2(t −1) + �(t −1)
y(t) = s2(t) + s3(t) + �(t)
�∼(0, 10−6), �∼(0, 0.09), and s(0) ∼(2.3, 10−2) and △T = 0.01 sec.
The required distribution using the bootstrap PF can be approximated by
ln ̂Pr(y(t)|Yt−1; 1) ≈ln((t; 1))

458
SEQUENTIAL BAYESIAN DETECTION
with the distribution under the null hypothesis given by
ln ̂Pr(y(t)|Yt−1; 0) = ln
(
1
√
2�× 0.09
)
−y(t)R−1
��y(t)
The resulting non-Gaussian, log-likelihood decision function with threshold is
given by
Λ(t) = Λ(t −1) + ln
(
(t; 1)
)
−ln
(
1
√
2�× 0.09
)
+
y2(t)
2 × 0.09
1
>
=
<
0
T1
No decision
T0
T�(t) = ln �(t); �= 0, 1.
As before, to estimate the thresholds we irst estimate the ROC curve. The deci-
sion function simulation was executed irst for the known signal case and then
for the case of noise only. The results are shown in Fig. 10.12 where we see the
Time (sec)
0
0.5
1
1.5
Log-likelihood
–300
–250
–200
–150
–100
–50
0
Sequential log-likelihood (PF):  
Time (sec)
0
0.5
1
1.5
Log-likelihood
0
200
400
600
800
1000
1200
Sequential log-likelihood (PF):
PDET  = 0.80;  PFA = 0.25
PDET  = 0.80;  PFA = 0.25
PDET  = 0.80;  PFA = 0.25
Probability of false alarm
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Probability of detection
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
ROC curve (PF) 
(b)
(a)
(d)
Samples
–500
0
500
1000
1500
2000
Log-Likelihood Probability
0
0.005
0.01
0.015
0.02
0.025
Log-likelihood PMFs
H0
H1
(c)
t
t
T1  = 1.2
T1  = 1.2
T0  = –1.3
T0  = –1.3
FIGURE 10.12
Sequential model-based detector design for nonlinear, non-Gaussian
problem: (a) signal case: log-likelihood detection; (b) noise case: log-likelihood detec-
tion; (c) log-likelihood PMFs; (d) ROC curve. (AUC = 0.75.)

10.7
MODEL-BASED CHANGE (ANOMALY) DETECTION
459
estimated ROC curve in 10.12d and the log-likelihood for both cases with the cor-
responding thresholds in 10.12a,b along with the underlying PMFs in 10.12c. Here
the detection and false-alarm probabilities were PDET = 0.80 and PFA = 0.25 at the
optimum threshold. Using Eq. 10.113 we calculate the corresponding thresholds as
ln 0 = −1.33 and ln 1 = 1.17 shown in the igures. The AUC for this detector was
AUC = 0.75.
△△△
This completes the example, next we consider the change or anomaly detection
problem.
10.7
MODEL-BASED CHANGE (ANOMALY) DETECTION
When a system under investigation changes its character in some way or another,
this change can be relected in a number of different ways. For instance, the dynamic
response of a structure subjected to an extraneous source such as an earthquake can
be severely altered or a motor running lawlessly beginning to shutter altering its
performance perhaps due to wear, or an aircraft abruptly altering altitude due to
a subsystem malfunction. All of these occurrences are examples that indicate the
system operating normally suddenly or slowly can change its operation requiring
some form of monitoring to not only detect the resulting change or anomaly, but
also predict its potential occurrence and even classify its change mechanism. In
this section, we briely discuss how monitoring characteristics of a system can be
used to detect changes in its performance. This is an area that has been heavily
researched for quite a while, the interested reader can ind much more detail in Refs.
[42], [43], and [44–47]. Here we just introduce the idea of detecting a change by
monitoring the “normal” response of a system and detect when that response becomes
“abnormal”.
Changes, from a signal processing perspective, can be captured in a number of
ways: altered statistics of the process (change in mean), altered spectral response
(frequency change), altered parametric response (model parametric change), other
characteristics that uniquely represent the system performance. In all of these cases,
it is desirable to ind a feature that uniquely captures the system performance. From
the model-based perspective, it is well known [33] that a system model contaminated
by additive Gaussian noise when employed in a sequential model-based scheme
yields a one-step prediction error or equivalently an innovations sequence that can
be investigated statistically to provide an online change detection monitor.
A model-based approach to develop diagnostic techniques for change or anomaly
detection is based on a well-established theoretical formalism that ensures a careful
and systematic analysis of the system or classes of systems under investigation and
their associated change mechanisms. Models can be developed from a irst-principles
mathematical representation or by utilizing sensor measurements to “it” the model
parameters to the data. In cases where the change mechanism is not well understood,
the model-itting approach offers an effective solution. In fact, in contrast to many
approaches of solving this problem, the model-based approach does not require an

460
SEQUENTIAL BAYESIAN DETECTION
explicit representation of the change mechanism at all to design an online monitor
for initial change detection. It is based on obtaining a representation of the sys-
tem during normal certiication operations, or even more desirable, during quality
assurance or acceptance testing. Once these normal operational characteristics of
the system are known, the processor is developed based on the properties of the
innovations sequence, the difference between the measured and predicted measure-
ments obtained from the underlying normal system model. Once this condition or
“difference” monitor detects a change, it can then be classiied.
10.7.1
Model-Based Detection
In this section, we discuss the design of a detector to monitor the performance of the
model-based processor and indicate when the model is no longer adequate or equiv-
alently does not track the measured data. First, we briely discuss the required theory
with details to follow. Once this is accomplished, we then discuss the development
of a practical processor.
Developing the model-based processor for the change detection problem is based
on a stochastic representation of the underlying dynamical state-space system. We use
a linear, continuous-discrete Gauss–Markov representation, that is, excite the system
with white Gaussian noise and take into account the measurement uncertainty, we
have
̇x(t) = Ax(t) + Bu(t) + �(t)
for �∼(0, R��)
y(tk) = Cx(tk) + �(tk)
for �∼(0, R��)
(10.140)
where tk is the sample time at the output of the digitizer (analog-to-digital converter)
and the initial state is assumed Gaussian x(0) ∼(x(0), P(0)). Thus, this represents
a stochastic extension of the deterministic system. The system response as well
as the states are contaminated with noise and uncertainties (unknown parameters);
therefore, we formulate the enhancement problem as a state/response estimation
problem using an embedded model developed from irst principles or “it” to the data
using parameter estimation techniques. In any case, the system enhancement problem
can be formulated succinctly as:
Given a set of noisy response sampled-measurements {y(tk)} and known excita-
tions {u(tk)} along with the corresponding Gauss–Markov model of Section 4.5, ind
the best estimate of the response (and state), ̂y(tk) (̂x(tk|tk)).
Discretizing the continuous system, the optimal sampled-data solution to this
problem is well known [33] and is given (succinctly) by
̂x(tk|tk−1) = Âx(tk−1|tk−1) + Bu(tk−1)
̂y(tk) = Ĉx(tk|tk−1)
e(tk) = y(tk) −̂y(tk)
̂x(tk|tk) = ̂x(tk|tk−1) + K(tk)e(tk)
(10.141)

10.7
MODEL-BASED CHANGE (ANOMALY) DETECTION
461
where ̂x(tk|tk) is the state estimate at time tk based on all of the data up to time tk and
K is the gain (Kalman) matrix obtained from a set of error covariance calculations
(see Ref. [33] for details).
Thus, based on the assumed Gauss–Markov model, the optimum processor or
Kalman ilter has the known excitation (u(tk)) and noisy measurement data (y(tk)) as
input and produces an estimate of the states (̂x(tk|tk)), enhanced or iltered response
measurement (̂y(tk)), and the innovations sequence (e(tk)), as output. The statistical
properties of the innovations are used to assess the performance of the processor
since a necessary and suficient condition for the MBP to be optimal is that the
innovations sequence must be zero-mean and white [33]. The innovations sequence
is zero-mean and white only when the process and measurement models relect the
true system response (and states) for a properly tuned MBP. Statistical changes in
e(tk) relect changes from the normal or expected operation; therefore, we can utilize
these changes to monitor the performance of the model embedded in the processor.
Theoretically, it can be shown that when “model mismatch” occurs, the innovations
become non-zero mean and are no longer white; therefore, we must develop a monitor
to decide whether or not the innovations satisfy the required properties for optimality
[33]. Assuming a normal (no changes) system initially, the MBP is tuned to produce
a zero-mean, white innovations establishing the normality operating condition. When
something changes in the system, the underlying normal model will no longer “match”
the measured response data indicating a change from normal condition to what we
deine as abnormal or an anomaly alerting us to a potential change; therefore, we
declare that a change has occurred and attempt to classify its type. This is the
underlying principle of the monitor/detector or more properly “change detector.”
10.7.2
Optimal Innovations Detection
To formally pose the sequential change detection problem, we appeal to classical
detection theory as before. We are to test the binary hypothesis that the innovations
sequence is zero-mean and white
0 :
e(tk) ∼(0, Ree(tk))
[White]
1 :
e(tk) ∼
(
�e, Ree(tk)
)
[Non-white]
which is a statistical test for the zero-mean and whiteness of the innovations sequence.
Note that we assume that we know the model error and how to calculate �e(tk) and
Ree(tk), a priori.
The optimal solution to this binary detection problem is based on applying the
Neyman–Pearson theorem leading to the usual likelihood-ratio and is given by the
ratio of probabilities for the sequential innovations detector, that is,
[EtN] =
Pr(EtN|1)
Pr(EtN|0)
1
>
<
0
�

462
SEQUENTIAL BAYESIAN DETECTION
where EtN := {e(t0), e(t1), … , e(tN)} or expanding
[EtN] = Pr(e(t0), e(t1), … , e(tN)|1)
Pr(e(t0), e(t1), … , e(tN)|0)
but from the chain rule of probability [33], we have that
Pr(Etk|i) = Pr(e(tk)|Etk−1; i) × ⋯× Pr(e(t1)|e(t0); i) × Pr(e(t0)|i)
which can be expressed succinctly using Bayes’ rule as
Pr(Etk|i) = Pr(e(tk), Etk−1|i) = Pr(e(tk)|Etk−1; i) × Pr(Etk−1|i)
Substituting these expressions (replacing tN by t) into the likelihood-ratio (above)
and grouping, we obtain
[Etk] =
[Pr(Etk−1|1)
Pr(Etk−1|0)
]
×
Pr(e(tk)|Etk−1; 1)
Pr(e(tk)|Etk−1; 0)
and therefore, we have the recursion or equivalently sequential likelihood as
[Etk] = [Etk−1] ×
Pr(e(tk)|Etk−1; 1)
Pr(e(tk)|Etk−1; 0)
Taking logarithms, we obtain the relation for the sequential log-likelihood as before
�e(tk) = ln [Etk] = �e(tk−1) + ln Pr(e(tk)|Etk−1, 1) −ln Pr(e(tk)|Etk−10)
The corresponding Wald or sequential probability ratio test (SPRT) [32] is then
given by
�e(tk)
≥ln �1
Accept 1
ln �0
≤�e(tk)
≤ln �1
Continue
�e(tk)
≤ln �0
Accept 0
and the underlying conditional Gaussian distributions are given by
Pr(e(tk)|Etk−1, 0) = (2�)−N∕2|Ree(tk)|−1∕2 exp
(
−1
2e′(tk)R−1
ee (tk)e(tk)
)

10.7
MODEL-BASED CHANGE (ANOMALY) DETECTION
463
and
Pr(e(tk)|Etk−1, 1) = (2�)−N∕2| ̄Ree(tk)|−1∕2
exp
(
−1
2(e(tk) −̄�e(tk))′ ̄R−1
ee (tk)(e(tk) −̄�e(tk))
)
If we include the determinants in the thresholds, we have the modiied decision
function
Λe(tk) = Λe(tk−1) + 1
2e′(tk)R−1
ee (tk)e(tk) −1
2(e(tk) −̄�e(tk))′ ̄R−1
ee (tk)(e(tk) −̄�e(tk))
which yields the new test
Λe(tk)
≥Υ1
Accept 1
Υ0
≤Λe(tk)
≤Υ1
Continue
Λe(tk)
≤Υ0
Accept 0
where
Υ1 = ln �1 + 1
2 ln |Ree(tk)|−1∕2 −1
2| ̄Ree(tk)|−1∕2
Υ0 = ln �0 + 1
2 ln |Ree(tk)|−1∕2 −1
2| ̄Ree(tk)|−1∕2
(10.142)
The implementation of this “optimal” change detector/monitor presents a basic
problem, such as how to obtain estimates of the innovations (abnormal) mean and
covariance required, but it does illustrate a potential optimal solution to the model
monitoring problem. As mentioned, the sequential innovations detector requires a
priori knowledge of the actual model “mismatch” and structurally how it enters the
process model to obtain [ ̄�e(tk)), ̄Ree(tk)] for the monitor.
10.7.3
Practical Model-Based Change Detection
Because of the inability to characterize statistical estimates of the innovations under
abnormal conditions, we must develop more pragmatic statistical methods for change
detection that incorporate this underlying knowledge. Here we present the techniques
already developed in Section 5.7 for “tuning” the optimal MBP. We briely review
these developments.
Note that there exist other prediction error models (e.g., AR, ARMA, ARMAX)
that still require the optimality conditions (zero-mean, white) to validate their per-
formance. So the following statistical tests are not just limited to the Kalman-based
state-space processors, but can be applied to all one-step prediction error techniques.
Recall that a necessary and suficient condition for an MBP to be optimal is that the

464
SEQUENTIAL BAYESIAN DETECTION
innovation sequence is zero-mean and white. Note also that these optimality con-
ditions are not necessarily true for output error models. We review the zero-mean,
whiteness, and weighted sum-squared residual tests as detectors (hypothesis tests)
themselves in light of this chapter.
Zero-Mean Detection
In some cases, if the innovations are assumed ergodic,
then a composite hypothesis test can be constructed using sample statistical estimators
for the required statistics [33]. When the processor is “tuned”, it provides an optimal
or minimum (error) variance estimate of the state. The innovations sequence, which
was instrumental in deriving the processor, also provides the starting point to check
the MBP operation.
If we assume that the innovation sequence is ergodic and Gaussian, then we can
use the sample mean as the test statistic to estimate �e, the population mean [33].
The sample mean for the ith component of ei is given by
̂�e(i) = 1
N
N
∑
t=1
ei(tk) for i = 1, … , Ny
(10.143)
where ̂�e(i) ∼(�e, Ree(i)∕N) and N is the number of data samples. We perform a
statistical hypothesis test to “decide” if the innovation mean is null [33]. We test that
the mean of the ith component of the innovation vector ei(tk) is
0 :
�e(i) = 0
1 :
�e(i) ≠0
As our test statistic we use the sample mean. At the �-signiicance level, the proba-
bility of rejecting the null hypothesis 0 is given by
Pr
(||||||
̂�e(i) −�e(i)
√
Ree(i)∕N
> �i −�e(i)
√
Ree(i)∕N
||||||
)
= �
for i = 1, … , Ny
(10.144)
Therefore, the zero-mean test [33] on each component innovation ei is given by
̂�e(i)
> Reject 0
< Accept 0
�i for i = 1, … , Ny
(10.145)
Under the null hypothesis 0, each �e(i) is assumed zero. Therefore, at the 5 %
signiicance level (�= 0.05), we have that the threshold is
�i = 1.96
√
̂Ree(i)
N
(10.146)

10.7
MODEL-BASED CHANGE (ANOMALY) DETECTION
465
where ̂Ree(i) is the sample variance (assuming ergodicity) estimated by
̂Ree(i) = 1
N
N
∑
t=1
ei
2(tk)
(10.147)
Component Whiteness Detection
Under the same assumptions, we can per-
form a whiteness test [33], that is, check statistically that the innovations covariance
corresponds to that of an uncorrelated (white) sequence. Assuming ergodicity of the
innovations sequence, we use the sample covariance function as our test statistic with
the ith component covariance and lag k are given by
̂Ree(i, k) = 1
N
N
∑
n=k+1
(ei(tn) −̂�e(i)) (ei(tn+k) −̂�e(i))
(10.148)
We actually use the normalized covariance test statistic
̂�ee(i, k) =
̂Ree(i, k)
̂Ree(i)
(10.149)
Asymptotically, it can be shown that
̂�ee(i, k) ∼(0, 1∕N)
Therefore, the 95% conidence interval estimate is
I�ee = ̂�ee(i, k) ± 1.96
√
N
for N > 30
(10.150)
Hence, under the null hypothesis, 95% of the ̂�ee(i, k) values must lie within this
conidence interval to accept 0. That is, for each component innovation sequence
to be considered statistically white. The whiteness test of Eq. 10.150 is very useful
to detect modeling inaccuracies from individual component innovations. However,
for complex systems with a large number of measurement channels, it becomes com-
putationally burdensome to investigate each innovation component wise especially
under the limiting ergodicity assumptions.
Vector Whiteness Detection
A statistic containing all of the innovation infor-
mation is the weighted sum-squared residual (WSSR). It aggregates all of the inno-
vation vector information over some inite window of length M. It can be shown that

466
SEQUENTIAL BAYESIAN DETECTION
the WSSR is related to a maximum-likelihood estimate of the normalized innovations
variance. The WSSR test statistic is given by
�e(�) :=
�
∑
k=�−M+1
e(tk)′R−1
ee (tk)e(tk) for �≥M
e ∈Ne×1
(10.151)
The WSSR hypothesis test is based on
0 :
�e(�)
[White]
1 :
�e(�)
[Non-white]
and is given by
�e(�)
>
1
<0
�
(10.152)
Under the null hypothesis, the WSSR is chi-squared distributed, �e(�) ∼�2(NeM).
However, for NeM > 30, �(�) is approximately Gaussian (NeM, 2NeM) (see Ref.
[48] for more details). At the �-signiicance level, the probability of rejecting the null
hypothesis is given by
Pr
(||||||
�(�) −NeM
√
2NeM
> �−NeM
√
2NeM
||||||
)
= �
(10.153)
For a level of signiicance of �= 0.05, we have
�= NeM + 1.96
√
2NeM
(10.154)
Thus, we see that the WSSR can be considered a “whiteness test” of the inno-
vations vector over a inite window of length N. Note that since [{e(tk)}, {Ree(tk)}]
are obtained from the state-space MBP algorithm directly, they can be used for both
stationary as well as nonstationary processes. In fact, in practice for a large number
of measurement components, the WSSR is used to “tune” the ilter and then the com-
ponent innovations are individually extracted and checked for zero-mean/whiteness
to detect changes. Note also that the adjustable parameter of the WSSR statistic is the
window length M, which essentially controls the width of the window sliding through
the innovations sequence. Therefore, even if we cannot implement the optimal inno-
vations detector, we can still perform a set of pragmatic statistical hypothesis tests to
investigate the condition of the underlying system and classify its change.
Consider the following example to illustrate the pragmatic approach.

10.7
MODEL-BASED CHANGE (ANOMALY) DETECTION
467
Example 10.14
Let us return to the RC-circuit of Example 5.1 where we have the Gauss–Markov
model given by
s(t) = 0.97s(t −1) + 100u(t −1) + �(t −1)
y(t) = 2s(t) + �(t)
�∼(0, 10−5), �∼(0, 4), and s(0) ∼(2.5, 10−6).
We simulated this system as before shown in Fig. 5.3 and constructed the
model-based processor resulting in Fig. 5.4. For the abnormal case we modiied
the system dynamics model by decreasing it by 10%, that is, A →A −0.1 × A. The
resulting system model changed and the various pragmatic tests were used to monitor
the response and detect any anomalies. The results are shown in Fig. 10.13. In the
Lags(Pct/No = 97.66 (250))
0
5
10
15
20
25
30
–0.2
0
0.2
0.4
0.6
0.8
1
Zero mean/whiteness-test:
mean = 1.86e+00<1.23e-01)
Abnormal system
Lags (Pct/No = 1.17 (3))
0
5
10
15
20
25
30
Norm .corr.
Norm .corr.
–0.2
0
0.2
0.4
0.6
0.8
1
Zero mean/whiteness-test:
mean = 1.26e-01<1.23e-01
Normal system
Time(sample)/Thrsh Exceed > 2.10e + 01(22) 
0
50
100
150
200
250
300
Rho
5
10
15
20
25
30
WSSR Test:
Length = 17, Threshold = 2.84e+01
Abnormal system
Time/Thrsh Not exceed
0
50
100
150
200
250
300
Rho
5
10
15
20
25
30
WSSR Test:
Length = 17, Threshold = 2.84e+01
Normal system
(a)
(b)
(c)
(d)
FIGURE 10.13
Sequential model-based detector design for RC-circuit problem:(a) Nor-
mal case: zero-mean/whiteness (0.13 ≈0.13 and 1.2% out) detection; (b) Abnormal
case: zero-mean/whiteness (1.9 > 0.13 and 98% out) detection; (c) Normal case: WSSR
detection (not exceeded); (d) Abnormal case: WSSR detection (exceeded).

468
SEQUENTIAL BAYESIAN DETECTION
igure, the zero-mean and whiteness detectors clearly indicate an anomaly with the
mean signiicantly exceeding its bound 1.9 > 0.13 and the percent of samples for the
whiteness greatly exceeding 5% at 98% as illustrated in (a) and (b). The WSSR statis-
tic is also able to pick up the “change” in response with the threshold “exceeded” as
shown in (c) and (d). This completes the example. If there was a transient or “abrupt”
change the WSSR would be able to discern and locate it, while there is a possibility
that the zero-mean/whiteness test would be insensitive to it. We demonstrate this in
the case study to follow.
△△△
10.8
CASE STUDY: REENTRY VEHICLE CHANGE DETECTION
In this section, we apply the pragmatic detectors to tracking anomalies of a space vehi-
cle as it re-enters the atmosphere. Here, we employ an autoregressive moving average
(ARMA) model to capture the system dynamics as compared to the state-space mod-
els discussed previously. The tracking of space vehicles from launch to splash down
and extracting critical information about the vehicle dynamics is a problem of high
concern whether it be a Space Shuttle launched to deliver a new communications
satellite or a reentry vehicle launched to analyze its light performance. In any case,
the basic question of interest is how to extract the vehicle dynamics from noisy and
incomplete trajectory information gathered by various independent radar sensors and
detect anomalies.
We start with a signal processing model that captures some of the simple vehicle
dynamics in terms of its precession and nutation signature that give an indication of
the dynamics. Consider the following signal processing representation of the reentry
vehicle (RV) response received at the radar. Suppose we model the dynamics of the
RV signal as [49],
s(t) = Ap sin(2�fpt + �p)
[
1 +
N�
∑
k=1
A�(k) sin(2�f�(k)t + ��(k))
]
z(t) = s(t) + c(t) + �(t)
(10.155)
where z(t) is the measured radar return; s(t) is the RV signal model including pre-
cession and nutation �; c(t) is the trajectory (trend); �(t) is Gaussian random noise
(0, �2
�); Ap, A�are the precession and nutation amplitudes; fp, f�are the precession
and nutation frequencies; and �p, ��are the precession and nutation phase.
We develop a recursive-in-time approach to instantaneous spectral estimation
enabling us to produce the desired spectrogram (amplitude vs. time vs. frequency)
for event detection. Suppose we parametrically model the enhanced measurement
data by a time-frequency representation speciied by an ARMA model. This model
has the general difference equation form given by
A(q−1, t)y(t) = C(q−1, t)e(t)
(10.156)

10.8
CASE STUDY: REENTRY VEHICLE CHANGE DETECTION
469
for the enhanced measurement y(t), contaminated with zero-mean, white Gaussian
noise e ∼(0, �2
ee), with the corresponding instantaneous polynomials at the instant
t deined by
A(q−1, t) = 1 + a1(t)q−1 + ⋯+ aNa(t)q−Na
C(q−1, t) = co + c1(t)q−1 + ⋯+ cNc(t)q−Nc
(10.157)
Here, the backward shift or delay operator is deined by q−iy(t) := y(t −i) and there-
fore, we can write Eq. 10.156 simply as
y(t) = −
Na
∑
k=1
ak(t)y(t −k) +
Nc
∑
k=0
ck(t)e(t −k)
(10.158)
If we transform the difference equation using the discrete Fourier transform (DFT),
then we obtain the instantaneous transfer function (ignoring stochastic aspect)
H(ej2�f , t) = Y(ej2�f , t)
E(ej2�f , t) = C(ej2�f , t)
A(ej2�f , t)
(10.159)
or more appropriately the corresponding instantaneous power spectrum deined by
S(f, t) := |||H(ej2�f , t)|||
2 =
|||||
C(ej2�f , t)
A(ej2�f , t)
|||||
2
(10.160)
So we see that if we use a model-based parametric ARMA(Na,Nc) representation of
the enhanced measurement signal and transform it to the spectral domain, then we can
obtain the instantaneous spectral estimate. We are primarily interested in estimating
the spectrum at each time instant, we chose to apply a recursive-in-time or one-step
prediction error technique—the recursive prediction error method (RPEM) (see Ref.
[33] for details). Using this approach, we expect the spectrogram will enable us to
extract the dominant precession spectral peak as it temporally evolves as well as the
nutational side band frequencies. After some signiicant pre-processing, the enhanced
measurement is available for spectrogram estimation [49].
Recursive-in-time parameter estimation algorithms take on the following generic
form:
̂Θ(t + 1) = ̂Θ(t) + K(t)e(t)
[Parameter update]
e(t) = y(t) −̂y(t) = y(t) −�′(t) ̂Θ(t)
[Prediction error]
�(t) ≡[y(t −1)
⋯
y(t −Na −1) | ̂e(t)
⋯
̂e(t −Nc)] ,
̂Θ(t) ≡
[
−̂a1(t −1)
⋯
−̂aNa(t −Na −1) | ̂co(t)
⋯
̂cNc(t −Nc)
]′
(10.161)

470
SEQUENTIAL BAYESIAN DETECTION
with K(t) the gain or weighting vector and the “hat” symbol deining the best (min-
imum error variance) estimate at the speciied time. There are also many variations
and forms of this basic recursion [33], but here we limit our application to the recur-
sive prediction error method (RPEM) based on a local Gauss–Newton optimization
method. We show the instantaneous spectrogram estimation for an RV simulation (to
follow) in Fig. 10.15.
Event Detection
We developed a set of event detectors based on the instanta-
neous ARMA signal models and recursive algorithms discussed above. The underly-
ing idea motivating this type of detector is based on the statistical properties of the
prediction error or innovations sequence which is (simply) the difference between
the measurement and its prediction using the ARMA model parameters. When the
model and its parameters “track” the data (after initialization), then any “abrupt”
change in parameter estimates or data will be relected directly in the prediction
error sequence. The pragmatic detectors test the sequence for statistically signiicant
changes indicating an event or possible phase change. The main point to realize is
that since we are using a recursive-in-time estimator, the prediction error represents
“how well the ARMA model its the data at each time instant”. If it is an optimal
it, then the prediction error sequence should be zero-mean and statistically white
(uncorrelated) and the vector detectors of the previous section evolve naturally from
this property.
When using these statistical tests care must be taken. If the models are nonlinear
or nonstationary, then the usual whiteness/zero-mean tests, that is, testing that 95%
of the sample (normalized) prediction error correlations lie within the bounds and the
corresponding zero-mean test both rely on quasi-stationary assumptions and sample
statistics to estimate the required correlations. However, it can be argued heuristically
that when the ARMA estimator is tuned, the nonstationarities are being tracked by
the processor even in the nonlinear case and therefore, the prediction errors should
be covariance stationary.
When data are nonstationary, then a more reliable statistic to use is the WSSR
which is a measure of the overall global estimation performance of the processor
again determining the “whiteness” of the prediction error sequence. It essentially
aggregates all of the information available in the prediction error and tests whiteness
by requiring that the decision function �(�) lies below the speciied threshold to
be deemed statistically white. If the WSSR statistic does lie beneath the calculated
threshold, then theoretically, the estimator is tuned and said to converge or in our
problem there is no abrupt phase change. Here the N-sample window is designed to
slide through the prediction error data and estimate its whiteness. Even in the worst
case where these estimators may not prove to be completely consistent, the processor
(when tuned) predicts the nonstationary prediction error covariance �2
ee(k) enabling
a simple (varying with �) conidence interval to be constructed and used for testing.
Thus, overall performance of the processor and therefore the event detector can be
assessed by analyzing the statistical properties of the prediction errors.
The inal detector is ad hoc, but based on the premise above that abrupt changes
in the data will be relected by abrupt changes in the parameters of the ARMA

10.8
CASE STUDY: REENTRY VEHICLE CHANGE DETECTION
471
model. The parametric change detector is obtained by averaging over all of the
recursive parameter estimates and searching for signiicant peaks to detect events. It is
deined by
�a(tk) =
1
Na + Nc
Na+Nc
∑
i=1
�i(tk)
�a(tk)
⨘
>
<
o
�
(10.162)
This completes our discussion of the model-based signal processing approach
taken to analyze the radar measurements, extract the required RV dynamics and
detect abrupt events.
10.8.1
Simulation Results
For this application, we synthesize the response of a ballistic vehicle that has been
launched and measured with a radar tracking system as it re-enters the earth’s atmo-
sphere. The vehicle dynamic motion, assumed stable, is characterized by it’s preces-
sion frequency and the small angular frequencies called nutations that it undergoes
during reentry. We also synthesize some events that are simulated as simple phase
changes in the temporal response. For our simulation, we assumed a precession
frequency of 0.235 Hz and nutation frequencies ranging between 1.6 ± 0.24 Hz,
2.4 ± 0.24 Hz, 3.2 ± 0.24 Hz, and 4.0 ± 0.24 Hz. In the spectrum, these nutation
frequencies appear in the side bands, since the signal model is essentially an ampli-
tude modulated signal. So for this data we extract the precession frequency and the
eight sidebands. We also synthesized three (3) events at 550, 590, and 640 sec. We
simulated the data with additive zero-mean, Gaussian noise with a variance of SNR
= 20 dB for 1024 samples and processed the data using the ARMA model given by
ARMA(35,25). The synthesized RV radar data are shown in Fig. 10.14 along with a
motion compensation pre-processing step.
We ran the instantaneous spectrogram estimator using the RPEM over the
ionosphere-free enhanced measurements and the results are shown in Fig. 10.15
below. Here we see that the spectrogram image clearly displays the dominant preces-
sion spectral peak (0.235 Hz) as it temporally evolves as well as the nutational side
band frequencies. Note with this high SNR the synthesized ”phase changes” are also
clearly observable as indicated by the arrows. The measurement is time aligned and
shown below the spectrogram as well. This example demonstrates the effectiveness
of the adaptive ARMA-model spectrogram MBP on synthetic data.
We executed these detectors over synthesized data sets in the ionosphere-free case
with the results shown in Fig. 10.16. We observe that in this case all three of the
detectors perform well in detecting the changes in nutational phase. In a, the WSSR
or phase change detector shows three peaks above the threshold at the correct event

472
SEQUENTIAL BAYESIAN DETECTION
74
76
78
80
500
520
540
560
580
600
620
640
660
–1
0
1
Time (sec)
Trajectory signal model simulation 
Trajectory motion compensation 
0
1
2
3
4
5
10 –8
10 –6
10 –4
10 –2
Frequency (Hz)
1.370         1.84     2.17         2.64      2.97         3.44     3.77         4.24
Nutation Frequencies
1.6
2.4
3.2
4.0
Precession frequency
0.235
Power spectrum  
Phase changes
Lonosphere effect
FIGURE 10.14
Trajectory simulation and tracking: (a) simulation; (b) motion compen-
sation; (c) spectral estimate with ionospheric effects (dotted).
times (550, 580, 630 sec) as do the parametric change (shown in b, c) and whiteness
d detectors. This completes our discussion of the estimation and monitoring of the
RV dynamics to detect abrupt events.
10.9
SUMMARY
In this chapter, we developed the fundamental decision or detection problem. Start-
ing with the classical binary hypothesis problem, we introduced the notion of
a likelihood-ratio decision function that was carried throughout investigating the
Bayesian approach to detector design for a single measurement both when the under-
lying signals and noise are completely known and unknown leading to composite
hypothesis testing and the so-called generalized likelihood-ratio test. Next, a vari-
ety of detection approaches were developed based on the most popular decision
criteria: probability-of-error, Bayes’ risk, and the well-known Neyman–Pearson cri-
terion. Multiple or batch measurements were then considered and shown to lead to
similar results for each scheme just modifying the likelihood-ratio in each case. The

10.9
SUMMARY
473
–5
–4
–3
–2
–1
0
Sample no.
540
560
580
600
620
640
Frequency (Hz)
Events 
Precession frequency (0.235 Hz) 
Nutation frequency side bands  
FIGURE 10.15
Adaptive ARMA Spectrogram Estimation for Event Detection: RPEM algo-
rithm for ARMA(35,25). Events detected are shown by the arrows.
multichannel measurement case then followed again leading to similar results. Finally,
the multiple hypothesis case was developed from the Bayesian probability-of-error
perspective. Performance metrics, critical tools in detector analysis, were developed
in an effort to assess and compare detectors. Starting with the ROC curve other met-
rics evolved (e.g., AUC) enabling a “quick” performance analysis. Development of an
ROC curve was discussed along with various approaches leading to the average ROC
curve with accompanying statistics, when ensemble data are created or are available.
Other metrics followed: distance, MinE, optimum decision point, and the confusion
matrices. Besides being available for performance analysis and comparing various
detection schemes, the ROC curve is necessary to establish an acceptable threshold
to set the detector for desired performance once the operating point (PFA, PDET)
is selected.
With all of this information at hand, the heart of the chapter followed—sequential
detection. Not only was this approach developed from the batch likelihood-ratio but
the underlying theory leading to the average number of samples required for detection
followed. Next, model-based detection evolved with developments for linear, non-
linear, and non-Gaussian model sets. Here it was shown how each of the sequential

474
SEQUENTIAL BAYESIAN DETECTION
–4
0
4
Parameter estimates
–0.5
0.5
Parametric phase change detector
520
540
560
580
600
620
640
0
0.5
1
Time (sec)
Whiteness detector  
100
300
500
Phase change detector  
FIGURE 10.16
Event detection of enhanced measurement: (a) phase change detec-
tion (T = 25, Threshold = 38.8); (b) parameter estimates, ARMA(32,25); (c) parametric
change detector; (d) whiteness event detector (4.4% out).
Bayesian (signal) model-based processors coupled with the newly developed sequen-
tial (likelihood-ratio) detectors could provide a powerful solution to a wide variety
of decision problems. The idea of detecting a change or anomaly of a system from
normal operation was exploited using this approach leading to the so-called family of
innovations-based detectors. Finally, a case study followed showing the applicability
of the model-based designs to anomaly detection.
MATLAB NOTES
MATLAB is a command oriented vector-matrix package with a simple yet effec-
tive command language featuring a wide variety of embedded C language con-
structs making it ideal for signal processing applications and graphics. MATLAB
has a Statistics Toolbox that incorporates a large suite of PDFs and CDFs as well
as “inverse” CDF functions ideal for simulation-based algorithms. The mhsam-
ple command incorporates the Metropolis, Metropolis–Hastings, and Metropolis

REFERENCES
475
independence samplers in a single command while the Gibbs sampling approach
is adequately represented by the more eficient slice sampler (slicesample). There
are even speciic “tools” for sampling as well as the inverse CDF method cap-
tured in the randsample command. PDF estimators include the usual histogram
(hist) as well as the sophisticated kernel density estimator (ksdensity) offering a
variety of kernel (window) functions (Gaussian, etc.). Perhaps the most relevant
command for detection is the (perfcurve) command which enables the develop-
ment of receiver operating characteristic (ROC) curves along with the majority
of metrics, discussed such as the confusion matrix, optimum threshold, detection
and false-alarm probability, etc. MATLAB also offers a sophisticated classiica-
tion tool, the “Bayesian learner” for classiication or multiple hypothesis testing
problems.
In terms of statistical testing for particle iltering diagnostics MATLAB offers
the chi-square “goodness-of-it” test chi2gof as well as the Kolmogorov–Smirnov
distribution test kstest. Residuals can be tested for whiteness using the Durbin–
Watson test statistic dwtest while “normality” is easily checked using the norm-
plot command indicating the closeness of the test distribution to a Gaussian.
Other statistics are also evaluated using the mean, moment, skewness, std, var
and kurtosis commands. Type help stats in MATLAB to get more details or go to
the MathWorks website.
REFERENCES
1. S. Theodoridis and K. Koutroumbas, Pattern Recognition (New York: Academic Press,
1998).
2. H. Van Trees, Detection, Estimation and Modulation Theory, pt. 1, (New York: John Wiley
& Sons, Inc., 1968).
3. A. Sage and J. Melsa, Estimation Theory with Applications to Communications and
Control (New York: McGraw-Hill, 1971).
4. D. Middleton and R. Esposito, “New results in the theory of simultaneous optimum
detection and estimation of signals in noise,” Problemy Peredachi Informatsii, 6, 3, 3–20,
1970.
5. J. Melsa and D. Cohn, Detection and Estimation Theory (New York: McGraw-Hill, 1978).
6. K. Murphy, Machine Learning (Cambridge, MA: MIT Press, 2014).
7. A. Gelman, J. Carlin, H. Stern, and D. Rubin, Bayesian Data Analysis (New York:
Chapman & Hall, 2004).
8. S. Press, Subjective and Objective Bayesian Statistics (Hoboken, NJ: John Wiley & Sons,
Inc., 2003).
9. S. Kay, Fundamentals of Statistical Signal Processing: Detection Theory (Englewood
Cliffs, NJ: Prentice-Hall, 1998).
10. R. Duda, P. Hart, and D. Stork, Pattern Classiication, 2nd Ed. (Hoboken, NJ: John Wiley
& Sons, Inc., 2001).
11. C. M. Bishop, Pattern Recognition and Machine Learning (New York: Springer, 2006).

476
SEQUENTIAL BAYESIAN DETECTION
12. K. Fukunaga, Statistical Pattern Recognition (New York: Academic Press, 1990).
13. W. Peterson, T. Birdsall, and W. Fox, “The theory of signal detectability,” Transactions of
the IRE Professional Group on Information Theory, PGIT-4, 171–212, 1957.
14. C. Therrien, Decision, Estimation, and Classiication: An Introduction to Pattern Recog-
nition and Related Topics (New York: John Wiley & Sons, Inc., 1989).
15. J. Hancock and P. Wintz, Signal Detection Theory (New York: McGraw-Hill, 1966).
16. D. Middleton, Introduction to Statistical Communication Theory (New York: McGraw-
Hill, 1960).
17. D. Middleton and R. Esposito, “Simultaneous optimum detection and estimation of signals
in noise,” IEEE Transactions on Information Theory, IT-14, 3, 434–444, 1968.
18. E. Sullivan and D. Middleton, “Estimation and detection issues in matched-ield process-
ing,” IEEE Trans. Oceanic Engr., 18, 3, 156–167, 1993.
19. J. Candy and D. Middleton, Joint detection-estimation: a model-based solution, LLNL
Report, UCRL-JC-120219, 1995.
20. A. Papoulis, Probability, Random Variables and Stochastic Processes (New York:
McGraw-Hill, 1965).
21. C. E. Metz, “Basic principles of ROC analysis,” Semin Nucl. Med., VIII, 4, 1978.
22. T. Fawcett, “ROC graphs: notes and practical considerations for researchers,” Technical
Report, (Palo Alto, CA: HP Laboratories, 2004).
23. T. Fawcett, “An introduction to ROC analysis,” Pattern Recogn. Letters, 27, 861–874,
2006.
24. H. Chernoff, Sequential Analysis and Optimal Design (Philadelphia, PA: SIAM, 1972).
25. A. Wald, Sequential Analysis (New York: Dover Publications, 1947.
26. A. Zoubir and D. Iskander, Bootstrap Techniques for Signal Processing (Cambridge, UK:
Cambridge University Press, 2004).
27. A. Bradley, “AUC: a statistically consistent and more discriminating measure than accu-
racy,” Pattern Recogn., 30, 7, 1145–1159, 1997.
28. J. Swets,”Indices of discrimination or diagnostic accuracy: their ROCs and implied mod-
els,” Psycho. Bulletin, 99, 1, 100–117, 1986.
29. K. Horsch, M. L. Giger, and C. Metz, “Prevalence scaling: application to an intelligent
workstation for the diagnosis of breast cancer,” Acad. Radiol., 15, 1446–1457, 2008.
30. R. Irwin and T. Irwin, “A principled approach to setting optimal diagnostic thresholds:
where ROC and indifference curves meet,” Europ. J. Inter. Med., 230–234, 2011.
31. C. Ling, J. Huang, and H. Zhang, “The use of the area under the ROC curve in the
evaluation of machine learning algorithms,” in Proceedings of 16th Canadian Confr. Art.
Intell., Springer, 2003.
32. A. Wald, Sequential Analysis (New York: Dover Publications, 1973).
33. J. Candy, Model-Based Signal Processing (Hoboken, NJ: Wiley/IEEE Press, 2006).
34. A. Jazwinski, Stochastic Processes and Filtering Theory (New York: Academic Press,
1970).
35. J. Candy, Bayesian Signal Processing, Classical, Modern and Particle Filtering (Hoboken,
New Jersey: Wiley/IEEE Press, 2009).
36. P. Li and V. Kadirkamanathan, “Particle methods based likelihood-ratio approach to fault
diagnosis in nonlinear stochastic systems,” IEEE Trans. Syst., Man and Cyber. Pt. C, 31,
3, 337–342, 2001.

PROBLEMS
477
37. C. Nemeth, P. Fearnhead, and L. Mihaylova, “Sequential Monte Carlo methods for state
and parameter estimation in abruptly changing environments,” IEEE Trans. Signal Proc.,
62, 5, 1245–1255, 2014.
38. P. Djuric, J. Kotecha, J. Zhang, Y. Huang, T. Ghirmai, M. Bugallo, and J. Miguez, “Particle
iltering,” IEEE Signal Proc. Mag., 20, 5, 19–38, 2003.
39. S. Kassam, Signal Detection in Non-Gaussian Noise (New York: Springer-Verlag, 1988).
40. A. Doucet, S. Godsill, and C. Andrieu, “On sequential Monte Carlo sampling methods for
Bayesian iltering,” Statist. Comput., 10, 176–183, 2000.
41. C. Andrieu, A. Doucet, S. Singh, and V. Tadic, “Particle methods for change detection,
system identiication, and control,” Proceedings of the IEEE, 92, 3, 423–438, 2004.
42. R. Hogg and A. Craig, Introduction to Mathematical Statistics (New York: MacMillan,
1970).
43. L. Scharf, Statistical Signal Processing: Detection, Estimation, and Time Series Analysis
(Reading, MA: Addison-Wesley, 1990).
44. M. Basseville and I. Nikiforov, Detection of Abrupt Changes: Theory and Application
(Englewood Cliffs, NJ: Prentice-Hall, 1993).
45. F. Gustafasson, Adaptive Filtering and Change Detection (Hoboken, New Jersey: John
Wiley & Sons, 2000).
46. R. Mehra and J. Peschon, “An innovations approach to fault detection and diagnosis in
dynamic systems,” Automatica, 7, 637–640, 1971.
47. A. Willsky, “A survey of failure detection in dynamic systems,” Automatica, 12, 601–611,
1976.
48. B. Anderson and J. Moore, Optimum Filtering (New Jersey: Prentice-Hall, 1979).
49. J. Candy, “Processing of reentry vehicle signatures from radar tracking data,” LLNL
Report, UCRL-130433, 1998.
PROBLEMS
10.1
We are given a sequence of counting measurements {yk} and asked to design
a set of different detectors based on a random signal that is Poisson distributed
s ∼(�s) and contaminated with additive Poisson noise given by
yk = sk + �k for �∼(��)
Design the following set of detectors to detect the random signal from a
single measurement:
(a) Maximum likelihood detector.
(b) Maximum a posteriori detector with priors Pr(0) and Pr(1). How does
this detector compare to the one in (a)? Under what conditions are they
identical?
(c) Bayes’ risk detector with costs: Cii = �ii and Cij = �ij. How does this
detector compare to the one in (b)? Under what conditions are they iden-
tical?

478
SEQUENTIAL BAYESIAN DETECTION
(d) Neyman–Pearson detector with threshold �.
(e) Repeat this problem for multiple measurements.
10.2
We have measured a parameter vector �and would like to decide if
0 : �= �0
1 : �= �1
where each vector is multivariate Gaussian distributed such that (m0, R0
)
and (m1, R1
).
(a) Develop the maximum likelihood, maximum a posteriori (equal priors)
Bayes’ risk (Cii = 0, Cij = 1); and Neyman–Pearson detectors with thresh-
old �to decide which vector is selected from a measurement Θ.
(b) What if m1 = m2 = m. What are the new decision functions?
(c) What if R1 = R2 = R. What are the new decision functions now?
10.3
A person is attempting to estimate the DC voltage level in a battery with a
“cheap” voltmeter and the needle continues to luctuate wildly. He wants to
detect whether the battery is completely dead (0 V) or alive (greater than
0 V). Initially, the person takes a single “guess” (measurement) to decide.
Assuming a signal in additive zero-mean, Gaussian noise measurement model
with variance �, develop the corresponding decision problem.
(a) Set up the hypothesis test for d, the DC voltage.
(b) Develop the maximum likelihood, maximum a posteriori (equal priors),
Bayes’ risk (Cii = 0, Cij = 1), and Neyman–Pearson detectors with thresh-
old �to decide whether or not to replace the battery.
(c) Calculate the detection, miss and false-alarm probabilities under these
assumptions.
(d) Frustrated, the person now take a sequence of guesses (multiple measure-
ments) in order to make the decision. What are the new decision functions?
Calculate the corresponding miss and false-alarm probabilities. What is
the total probability-of-error?
(e) Still not satisied with the results, the person decides that the level is
actually random and can be considered Gaussian such that d ∼(d, �2
d),
calculate the detection, miss and false-alarm probabilities under these
assumptions for the Neyman–Pearson detector for a single measurement.
10.4
Consider multivariate Gaussian distributions under binary hypotheses:
(m�, R�
); �= 0, 1 with the following means and covariances:
m0 = [0
0]T and m1 = [0
2]T
with corresponding covariance matrices
R0 = diag(1.00
0.25) and R0 = diag(0.25
1.00)

PROBLEMS
479
(a) Design a Neyman–Pearson detector for threshold �.
(b) What type curves are the decision boundaries?
(c) Sketch the decision region with these boundaries.
10.5
Suppose we are given the hypothesis to test as
0 : y(t) = �(t) for �∼(0, 1)
1 : y(t) = �+ �(t)
(a) Develop the maximum likelihood, maximum a posterior (equal priors),
Bayes’ risk (Cii = 0, Cij = 1), and Neyman–Pearson detectors with thresh-
old �to decide on the presence or absence of the signal (�= 1) from a
single measurement.
(b) Calculate the detection and false-alarm probabilities.
(c) For a ixed false-alarm probability of Pr(|0) = 0.25, calculate the
threshold for each detector.
(d) Sketch (or calculate) the PDFs and ROC curve for this problem and anno-
tate the critical regions.
(e) Consider incorporating multiple measurements {y(t)}; t = 1, … , N, how
do these detectors change? What are the new decision functions for each?
(f) Sketch the PDFs and ROC curve for this case and annotate the critical
regions.
10.6
Calculate the total probability-of-error for the previous problem (c), if the
priors are: Pr(0) = 0.25 and Pr(1) = 0.75.
10.7
We have an exponentially distributed measurement and would like to decide
if it is from an (1) or (�), that is, a binary decision problem.
(a) Determine the Neyman–Pearson detector for a threshold of �.
(b) Determine the ROC curve for this problem.
(c) Calculate the slope of the ROC curve. What is its signiicance?
10.8
Similar to the above binary decision problem, suppose we have the hypotheses
distributed: Pr(y|0) = 0.5 exp{−|y|} and Pr(y|1) = exp{−2|y|} with cor-
responding costs given by Cii = 0, C01 = 1, C10 = 2, and priors Pr(0) = 0.25
and Pr(1) = 0.75.
(a) Calculate the detection and false-alarm probabilities.
(b) Calculate the Bayes’ risk.
10.9
Consider the following multiple hypothesis decision problem
0 : y(t) = �(t) for �∼(0, R��)
1 : y(t) = �+ �(t)
2 : y(t) = −�+ �(t)

480
SEQUENTIAL BAYESIAN DETECTION
(a) With �assumed known and positive and the hypotheses equally likely
with costs Cii = 0, Cij = 1, develop the MAP detector for this problem.
(b) Sketch the PDFs. What are the decision regions?
10.10 For the binary decision problem under the following hypotheses
0 : �(t) = �0(t) for �∼(m�0, R�0�0)
1 : �(t) = �1(t) for �∼(m�1, R�1�1)
use the following statistics to simulate Gaussian sequences under each hypoth-
esis with m�0 = 110, R�0�0 = 5.0 and m�1 = 120, R�1�1 = 5.5. Using the sim-
ulated data, calculate the corresponding Neyman–Pearson decision functions
under each hypothesis, then
(a) Generate the ROC curve (you can use the perfcurve of MATLAB).
(b) Calculate the performance metrics: AUC, PPV, NPV, MinE, ODP with
threshold.
(c) Calculate the confusion matrix.
(d) Calculate the ACC, PPV, NPV. Compare your results with those of Table 1
of Example 10.8.
10.11 Given the following decision problem
0 : y(t) = �(t) for �∼(0, R��)
1 : y(t) = �(t) + �(t)
(a) Assume �(t) is deterministic, but unknown. Develop the generalized
likelihood-ratio test (GLRT) for threshold �and a single measurement
y(t).
(b) Assume �(t) is random with �∼(0, R��), develop the Neyman–Pearson
(N-P) detector for this case.
(c) Suppose we now have a set of measurements {y(t)}; t = 1, … , N and
assume �(t) is represented by a random-walk with variance R����. What
is the MAP estimate of �→̂�MAP? How does this change the GLRT
(explain)?
(d) Again assume �(t) is deterministic, but unknown. Develop the sequential
N-P detector assuming independent measurements. Determine the average
number of samples required for the termination of the test assuming that
the operating point obtained from an ROC curve is: PDET = 0.95 and
PFA = 0.10.
10.12 Suppose we have a known pulse-like signal in zero-mean, Gaussian noise. Like
a radar or sonar system, we transmit the pulse p(t) into the environment and
would like to decide whether it is present or not, that is we test the hypotheses
0 : y(t) = �(t) for �∼(0, R��)
1 : y(t) = p(t) + �(t)

PROBLEMS
481
(a) Assuming we have a set of measurements {y(t)}; t = 1, … , N available,
develop the N-P detector with threshold �. What is the resulting decision
function?
(b) Suppose we interpret the pulse as a inite impulse response (all-zero) ilter
with weights
W(t) = p(N −t −1); t = 0, 1, … , N −1
Using the convolution relationship z(t) = W(t) ∗y(t), show that this is
equivalent to the decision function (matched-ilter) in (a).
(c) Determine the performance of the matched-ilter for this problem, that is,
estimate its ROC curve.
10.13 Suppose we are given the measurement vector y(t) := [y(0)y(1) ⋯y(N −1)]
and we would like to test the hypotheses
0 : y(t) = v(t) for v ∼(0, R��)
1 : y(t) = s(t) + v(t)
where y, s, v ∈N×1, s known.
(a) Develop the Neyman–Pearson detector with threshold �. What is the result-
ing decision function?
(b) Suppose the noise is uncorrelated, that is, R��= �2
�I is diagonal with equal
variances. For the N-P detector, how does this decision function differ from
that of the previous example.
(c) Suppose the noise is uncorrelated, but with unequal variances, R��=
�2
�(n)I for n = 0, … , N −1. What is the new decision function for the N-P
detector?
10.14 We would like to develop a simple scheme to estimate a change in the statistics
of a given signal s(t) in real-time, but we can only measure the signal that is
contaminated in noise
y(t) = s(t) + �(t) for �∼(0, �2
�)
If the signal is assumed deterministic, then
(a) Develop a sequential estimate of the signal along with a sequential estimate
of its statistics (Hint: calculate the sequential mean/variance estimators).
(b) With these statistics in hand construct a sequential test to detect a change
(Hint: dynamic conidence interval).
(c) Can this problem be placed in an equivalent hypothesis testing framework?
What is it?
(d) Assume the signal is a sinusoid that changes its phase at the midpoint of
its measured time interval for various SNRs (SNR: signal energy/noise

482
SEQUENTIAL BAYESIAN DETECTION
variance), then simulate this signal and construct the sequential
detector.
10.15 Design a sequential “reference” detector using the Neyman–Pearson criterion
that is capable of deciding between a Gauss–Markov (state-space) model
deined by Σ := {A, C, ̂x(0), ̂P(0), R��, R��} and a known reference model
Σ := {A, C, x(0), P(0), R��}.
The reference model is given by
x(t) = Ax(t −1)
y(t) = Cx(t) + �(t)
for �∼(0, R��)
and
x(t) = Ax(t −1) + �(t)
for �∼(0, R��)
y(t) = Cx(t) + �(t)
for �∼(0, R��)
(a) Determine the decision function and the thresholds �0 and �1.
(b) Could this general formulation be applied as a change detector? Explain.
10.16 For the RC-circuit problem of Example 5.1, assume that we only know the
component values within 10% precision.
(a) Simulate the true circuit. Construct a model-based solution and perform
the zero-mean/whiteness along with the WSSR tests to ensure a tuned
processor.
(b) Let the resistor value be R ± 0.1R and simulate its response. Apply the
“normal” model-based processor in (a) and perform the same statistical
tests. How do they compare?
(c) Develop a Neyman–Pearson sequential detector for this problem and
observe the decision function. Is it sensitive enough to detect this para-
metric change?
(d) Repeat these simulations for a better component R ± 0.05R. Is the change
detected?
10.17 Suppose our estimates of the trajectory from our nominal guesses of the
parameters in Example 5.2 are off by 10%, that is, for the nonlinear system
given by
x(t) = (1 −�1△T)x(t −1) + �2△T)x2(t −1) + �(t −1); for �
∼(0, 1 × 10−6)
y(t) = x2(t) + x3(t) + �(t) for �∼(0, 0.09)
Investigate the possibility of detecting changes using the zero-mean/whiteness
and WSSR tests for �1 ± 0.1�1 and then �2 ± 0.1�2.

PROBLEMS
483
(a) For this nonlinear problem, construct a model-based processor (EKF, UKF,
or PF) and “tune” it for the true parameters by performing the zero-
mean/whiteness along with the WSSR tests to ensure a tuned processor.
(b) Let �1 ± 0.1�1 and observe the MBP performance? Discuss the results.
(c) Let �2 ± 0.1�2 and observe the MBP performance? Discuss the results.
(d) Develop an N-P sequential detector for this problem and observe the
decision function. Does it detect the change? Compare this performance
to the zero-mean/whiteness and WSSR tests.

11
BAYESIAN PROCESSORS
FOR PHYSICS-BASED
APPLICATIONS
In this chapter, we develop a set of Bayesian signal processing applications based on the
underlying physical phenomenology generating the measured process. The complexity
of the process and the desire for enhanced signals drive the design primarily indicated
by the process model. We motivate each application, succinctly develop the process and
measurement models, develop the BSP, and analyze its performance. More details on
any of the designs can be obtained from the references for the interested reader. The
main objective is to demonstrate the applicability of the Bayesian approach to a variety
of interesting applications and analyze their performance.
11.1
OPTIMAL POSITION ESTIMATION FOR THE
AUTOMATIC ALIGNMENT
The alignment of high-energy laser beams for fusion experiments demands high
precision and accuracy of the underlying positioning algorithms whether it be for
actuator control or monitoring the beam line for potential anomalies. This section
discusses the development of online, optimal position estimators in the form of
Bayesian processors to achieve the desired results. Here, we discuss the modeling,
development, implementation, and processing of Bayesian model-based processors
applied to both simulated and measured beam line data.
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
484

11.1
OPTIMAL POSITION ESTIMATION FOR THE AUTOMATIC ALIGNMENT
485
11.1.1
Background
Alignment of a high-power beam is a complex and critical process requiring precise
and accurate measurements. Misalignment of such a beam could easily destroy costly
optics causing a deleterious disruption of an entire experiment. The alignment of large
operative, short pulse, laser systems is a signiicant and costly endeavor dating back to
the late sixties and early seventies [1]. Contemporary imaging systems employ high-
resolution video cameras to image and accurate position control systems to align the
beam. This approach estimates the current beam position from the image, adjusts
mirrors relative to an accurate reference measurement of physical beam center, and
minimizes their difference or deviation [2–9]. However, even with these sophisticated
measurements, the beam position estimate is still a function of the inherent beam noise
caused by the internal beam line gas turbulence as well as instrumentation noise [10].
Here, we introduce the idea of post-processing these uncertain measurements using
advanced signal processing techniques to “enhance” the raw data and “detect” any
beam line anomalies during laser system operations [11].
High-power, tightly focused laser beams are required to achieve successful igni-
tion and therefore fusion at the Lawrence Livermore National Laboratory (LLNL)
National Ignition Facility (NIF) [12]. These beams must simultaneously focus pre-
cisely on a nanoscale target capsule to succeed. Therefore, there are a large number
of alignment measurements that must be performed along the NIF beam line to
assure that the pointing and alignment control system centers the beam in order to
provide the maximum energy on the fusion target located in the associated chamber
[12–14]. An automatic alignment (AA) system was designed and implemented to
assure successful deployment of the high energy beam in each of the 192 beam lines.
However, since a variety of techniques are provided to perform the alignment, there
is a quantiiable uncertainty associated with each technique that may or may not meet
the desired accuracy and precision speciications associated at each control point.
Therefore, there is a need for a post-processing technique, which accepts as input an
uncertain position measurement and provides as output an improved position estimate
(see Fig. 11.1). As illustrated in the igure, the measured image position estimate is
compared to the reference image estimate providing an position error that is input
to the mirror control system that moves the associated mirrors correcting the beam
position.
Perhaps the most challenging of all beam line measurements are those made on the
KDP (potassium dihydrogen phosphate) crystals. These crystals are critical elements
used to double or triple the frequency of the laser beam as it passes providing a shorter
wavelength. The higher frequency determined from the target physics enables laser
plasma interactions for fusion. The NIF inal optics assembly matches lenses to
this particular frequency producing the beam that is tightly focused on the target
capsule required to achieve fusion ignition. In order for the KDP crystals to optimally
double or triple the laser operating frequency, they must be precisely positioned at
the appropriate angle. This is one of the critical tasks of the AA system. The KDP
measurement consists of using a charge coupled device (CCD) imaging camera,
which produces a noisy back relection image of a diagnostic alignment beam. The

486
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
(
)
( ), ( )
x k
y k
( , )
I x y
( , )
rI
x y
(
)
( ),
( )
r
r
x k
y
k
ˆ( )
k
Δp
( )
k
( )l
Anomaly 
detector 
(innovations) 
Post-processor 
(BP position est.)
Raw position
calculation
Reference 
image
Raw position 
calculation
Measured
image
Optimal position estimator/anomaly detector  
FIGURE 11.1
Optimal position estimation with anomaly detector: Bayesian post-
processing and innovations-based anomaly detection.
noise is caused by the camera itself as well as uncertainties that are due to small
pointing errors made during the measurement. A sophisticated two-dimensional (2D)
phase-only, matched-ilter [15] algorithm was developed to provide the initial raw
position estimates.
The image acquired from the CCD imaging camera produces both noisy measure-
ment and reference images. A precise reference image is used to provide the desired
iducial that is used by the alignment system. Corrections to align the measured image
with the reference is accomplished using the dedicated control loops that adjust point-
ing mirror stepping motors until the deviations between both reference and measured
positions are within acceptable limits [14]. Ultimately, the goal is to make this differ-
ence zero assuring proper beam alignment. Fig. 11.2 shows a sequence of measured
KDP images with position estimates (O) along with the corresponding reference
image measurement (+). Note how the control loop adjusts the KDP measurements
(O) until the centroid position converges to the reference position (+). The objective,
therefore, of the control loop is to adjust the beam mirrors such that both measured
and reference positions completely overlap (zero deviation) as shown in the bottom of
this igure. Thus, the smaller the XY-deviations, the closer the beam is to the center-
line reference assuring a tightly focused, high-energy beam on target—the goal of the
alignment system. Should, for some reason, an anomaly develops in any beam line,
it may not be possible to align for a particular shot. The timely detection of beam
line anomalies are necessary to avoid future problems, which, if left unmitigated,
could result in less than optimum performance of the laser. In this work, we show
how a Bayesian processor (BP) can be used to detect anomalies, online, during the
calibration phase of a laser shot.
Thus, we discuss the feasibility of applying a Bayesian processor as an online post-
processing technique to improve the inal position estimates provided by a variety
of estimators and detect anomalies in a high-energy laser beam line [11]. These
estimators are used to align high-powered laser beams for experiments at NIF. We

11.1
OPTIMAL POSITION ESTIMATION FOR THE AUTOMATIC ALIGNMENT
487
+
Position estimates
+
+
Reference 
Data
Raw KDP image
Reference
FIGURE 11.2
Raw KDP crystal back-relection image and reference position estimates.
irst motivate a stochastic model of the overall process and measurement system.
Next, we discuss the underlying theory for both position estimation and anomaly
detection. With the theory in hand, we develop the processor for the KDP application
through ensemble statistics, simulation, and application to real measurement and
reference data.
11.1.2
Stochastic Modeling of Position Measurements
The typical beam position estimator is accomplished by calculating the centroid of
the measured images [16]. The point is that these measured positions are derived
from the associated noisy CCD images. We deine the true centroid positions by the
position vector p(k) := [x(k)|y(k)]′. where p ∈RNp×1 and k is the sample time. Since
quite a number of images are acquired daily, a large database consisting of position
estimates are available, say, P(t) = {p(k); k = 1, … , K} and the position estimates
are to be updated continuously. Since we know that the images are contaminated with
noise and uncertainty, a more reasonable position measurement model is given by
z(k) = Cp(k) + v(k)
(11.1)
where z, v ∈RNz×1, C ∈RNz×Np, and v ∼N(0, R��), that is, the measurement noise
is assumed zero-mean, multivariate Gaussian with covariance matrix, R��∈RNz×Nz.
We also note that since the CCD camera uses the identical beam line to measure
both images, we model the position estimates as piecewise constants contaminated

488
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
with beam line noise besides that noise contributed by the measurement systems. This
process noise can be considered luctuations caused by the inherent system optical
transfer functions and turbulence caused by the argon gas-illed housing during the
laser beam propagation (boiling noise). Therefore, we assume that the contaminated
position measurement is represented as
̇p(t) = 0 + w(t)
with
p(0) = [x(0)|y(0)]′
(11.2)
in continuous time, but if we discretize over the k-sample images, then using irst
differences we obtain
̇p(t) = p(tk+1) −p(tk)
Δtk
= w(tk)
for
Δtk :=tk+1 −tk
(11.3)
Substituting into Eq. 11.2, we obtain the following Gauss–Markov position model
p(tk+1) = p(tk) + Δtkw(tk)
(11.4)
where p, w ∈RNp×1 and w ∼N(0, R��) along with the accompanying measurement
model of Eq. 11.1. This completes the basic description of the underlying Gauss–
Markov model. We note in passing that for a complete description of the general
model including means, mp(k), mz(k) with their associated covariances see Ref. [11]
for more details.
Since we have both inal measured and reference position estimates, we re-deine
a more convenient position vector by grouping the positions as
p(k) :=
⎡
⎢
⎢
⎢
⎢⎣
x(k)
y(k)
−−−
xr(k)
yr(k)
⎤
⎥
⎥
⎥
⎥⎦
and
w(k) :=
⎡
⎢
⎢
⎢
⎢
⎢⎣
�x(k)
�y(k)
−−−
�xr(k)
�yr(k)
⎤
⎥
⎥
⎥
⎥
⎥⎦
where p(0) ∼N (̄p(0), ̄Rpp(0)) are the respective measurement and reference posi-
tions coordinates (pixels) with the corresponding process noise covariance matrix
given by
R��=
⎡
⎢
⎢⎣
̄R��
|
0
−
−
−
0
|
̄R�r�r
⎤
⎥
⎥⎦
since each of the measured and reference images are uncorrelated.
This type of formulation enables us to estimate the process noise covariances
independently for each image as well as characterize their uncertainties individually.

11.1
OPTIMAL POSITION ESTIMATION FOR THE AUTOMATIC ALIGNMENT
489
Since the control loop jointly uses both the reference and measured images to produce
its inal centroid position estimates, we model the measurement matrix as the deviation
(difference) between these data contaminated with independent measurement noise;
that is, our measurement model of Eq. 11.1 becomes
z(k) =
[
1
0
−1
0
0
1
0
−1
]
p(k) + v(k)
with measurement covariance matrix
R��=
⎡
⎢
⎢⎣
�2
��
|
0
−
−
−
0
|
�2
�r�r
⎤
⎥
⎥⎦
and �2
��= �2
xx + �2
yy and �2
�r�r = �2
xrxr + �2
yryr. Note that the deviations are deined by
Δp(k) := Cp(k) =
[
Δx(k)
Δy(k)
]
=
[
x(k) −xr(k)
y(k) −yr(k)
]
This completes the section on position (uncertainty) modeling; next, we consider the
development of the optimal position estimator.
11.1.3
Bayesian Position Estimation and Detection
It is well known that the optimal solution to the position estimation problem under the
Gauss–Markov model assumption is provided by the Bayesian model-based (state–
space) processor or Kalman ilter of Chapter 5. This solution can be considered
a predictor-corrector design in which the processor uses the model (random walk)
to predict in absence of a measurement and then corrects the estimate when the
measurement becomes available. Under the assumption of a perfect model, that is,
the model embedded in the process exactly matches the process, the BP is capable
of achieving the optimal minimum (error) variance estimate under the Gaussian
assumptions.
For the position estimation problem, the BP takes on the following predictor-
update form where tk →k:
r Prediction: ̂p(k + 1|k) = ̂p(k|k)
r Innovation: �(k + 1) = z(k + 1) −̂z(k + 1|k) = z(k + 1) −Ĉp(k + 1|k)
r Update: ̂p(k + 1|k + 1) = ̂p(k + 1|k) + G(k + 1)�(k + 1)
r Gain: G(k + 1) = ̃P(k + 1|k)CTR−1
��(k + 1)
for ̂p(k + 1|k) := E {p(k)|p(k −1), … , p(1)} and ̂z(k + 1|k), the underlying condi-
tional means, and G(k + 1) ∈RNp×Nz is the corresponding gain matrix calculated
from the error covariance matrix ̃P(k + 1|k) = Cov (̃p(k + 1|k)) with position error

490
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
̃p(k + 1|k) := p(k + 1) −̂p(k + 1|k). The innovations covariance matrix is deined by
R��(k + 1).
Recall that for a Gauss–Markov representation a necessary and suficient con-
dition for the BP to be optimal is that the innovations sequence be zero-mean and
white (uncorrelated)—conditions that we test during processor design. It is possible
to exploit this property of the innovations to detect anomalies in the system reveal-
ing potential problems in the beam line in pseudo real-time—a large asset when
attempting to automate the alignment system. We apply two detection techniques to
monitor the position estimates from the daily measurements: zero-mean/whiteness
detector and the WSSRdetector (see Section 5.7 for details). Both of these techniques
rely on the assumption that the position deviations in the loop should change little
during the measurement cycles. The underlying idea in anomaly detection is that
the processors are “tuned” during calibration to operate in an optimal manner (inno-
vations zero-mean/white). However, when an anomaly occurs, the innovations no
longer maintain their optimal statistical properties leading to a “change from normal”
and an anomaly is declared. With this detection, a decision must be made to either
classify the anomaly or perform some other action. The main point to realize is that
since we are using a recursive-in-time BP, the innovations represent “how well the
position model and its underlying statistics represent the raw data.” If it is an optimal
it, then the innovations should be zero-mean and statistically white (uncorrelated)
and the detectors evolve naturally.
This completes the description of the BP and the associated anomaly detectors;
next, we consider a simulation of the data and processor to predict the expected
performance.
11.1.4
Application: Beam Line Data
In this section, we discuss the application of optimal position estimators based on daily
historical position estimates (database) provided by the KDP algorithm. The data are
a record of 48 days of inal positions output from both the accurate reference system
(reference data) and the estimated inal position output from the KDP back-relection
data coupled to a phase-only, matched ilter [15] imaging algorithm. The motivation
for applying the Bayesian approach to this data set is to obtain a more accurate
and precise estimate of error deviations from the reference characterizing the overall
control loop performance in that position of the beam line. Theoretically, the position
deviations between the reference and the KDP estimates should ideally be zero, but
because of the beam line noise and variations, CCD camera limitations and control
system tolerances, this is not the case. Instead, the overall error statistics are used to
bound the performance and assure that they remain within design speciication.
11.1.4.1
BP Design
In the design of the BP, the usual procedure is to (1)
develop the required models; (2) simulate a set of position data characterized by any
of the a-priori information available; (3) develop the minimum error variance design;
and (4) apply the processor to the available data set evaluating its performance. We
developed the basic model set assuming a Gauss–Markov structure as in the previous

11.1
OPTIMAL POSITION ESTIMATION FOR THE AUTOMATIC ALIGNMENT
491
subsection. These parameters of this model were estimated from the statistics of a
large ensemble (> 5000) of images and performance statistics of the KDP centroiding
algorithm. We used this information to construct the initial simulation of the BP to
“match” with the historical data available (48 days) and the corresponding ensemble
statistics.
Thus, our approach is to irst perform a simulation of the measurement process
using estimated statistics from the data and then apply it to the actual data. During
the simulation phase, we are able to analyze the performance of the BP and assure
ourselves that all of the models and statistics are correct. We expect to obtain the
minimum variance estimates; if not achieved, then it is usually an implementation
issue. Once the simulation and model adjustments have been made, we apply the
processor to the measured data.
11.1.4.2
Simulation
Now that we have developed the models and have some
estimates from the ensemble statistics of the database, we are now able to perform a
Gauss–Markov simulation to assess the feasibility of the BP. We simulated a set of
data based on the following parameters using the mean XY-position estimates, that
is, xi = �xi ± 1.96�i for both the measured and reference data:
x(0) = [344 ± 8, 270 ± 13.8, 344 ± 7.8, 270 ± 14.4]′
We used the mean values as the initial position estimates with low error variances
( 1 × 10−6). We chose an uncorrelated measurement (deviation) noise covariance
matrix as: R��= diag [0.0076
0.0078]. The process noise covariance selected is
R��=
[ ̄R��(1)
0
0
̄R��(2)
]
for
̄R��(1) =
[
50.0
−26.5
−26.5
50.0
]
;
̄R��(2) =
[
50.0
−37.7
−37.7
50.0
]
The synthesized positions have small variations due to the process noise, but
are essentially constants (mean values). The simulated noisy DX-, DY-deviation
measurements (dotted line) including the process and measurement noise are shown
in Fig. 11.3. Next, we executed the BP over this data set and the position deviations
(solid line) are also shown in the igure. Here we see that much of the raw measurement
and process noise have been removed by the processor and only the deviation errors
are shown. Recall that they should be close to zero for the alignment control system
to be operating eficiently.
To validate the results, we investigate the minimum variance design procedure.
We investigate the statistics of the innovations sequence and check that they are zero-
mean and white for optimality. Both innovations sequences are zero-mean: (0.30 <
3.5;0.95 < 3.3) and white: (4% out; 0% out); with the WSSR decision function
lying below the threshold for a window of size N: (threshold = 69.6, N = 25). These
statistics indicate that the minimum variance position deviation estimates have been

492
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
−10
0
10
20
30
40
DX-position
DY-position
Estimated
Raw 
0
5
10
15
20
25
30
35
40
45
50
−30
−20
−10
0
10
20
Time (days) 
Raw 
Estimated
(a)
(b)
FIGURE 11.3
Simulated XY-position deviations: raw (dotted) and estimated (solid). (a)
X-deviation. (b) Y-deviation.
achieved. This result is expected, since the models used in the BP are identical to
those in the Gauss–Markov simulator. However, the results can be interpreted as the
“best” (minimum variance) one could hope to do under these circumstances. Next,
we apply the BP to the actual deviation data.
11.1.5
Results: Beam Line (KDP Deviation) Data
In order to process the KDP deviation data, we must develop parameters for the under-
lying model embedded in the processor. We start with guesses of the noise (process
and measurement) statistics from the simulator and then adjust them accordingly.
For instance, if the innovation sequence lies outside its predicted bounds implying
that the measurement noise variance is too small, then it can be adjusted to satisfy

11.1
OPTIMAL POSITION ESTIMATION FOR THE AUTOMATIC ALIGNMENT
493
0
5
10
15
20
25
30
35
40
45
50
−5
0
5
Time (days)
−5
0
5
Estimated
Raw
Estimated
Raw
ΔY-position
ΔX-position
(a)
(b)
FIGURE 11.4
Actual KDP XY-deviations and estimated XY-positions: raw measured data
(dashed); estimated data (solid). (a) △X-position. (b) △Y-position.
this constraint and “match” the data. The process noise is actually quite dificult to
select, since it is directly proportional to the BP gain. In essence, once all of the other
model parameters are reasonably adjusted, they are then held ixed and the process
noise covariance is varied to achieve the “best” possible (minimum error variance)
innovations statistics (zero-mean/white, WSSR below threshold).
The results of the BP design for the deviation data are shown in Figs. 11.4 and 11.5.
We see the raw KDP position deviation estimates along with the optimal processor
results over the 48-day period in Fig. 11.4. It is clear that the processor is tracking
the trends in the data while reducing the noise or equivalently enhancing the SNR. To
conirm this, we observe the three-sigma error ellipsoid plots of Fig. 11.5 where we
observe that much of the uncertainty has been removed and the estimated deviations
are clearly clustered (centered) around the (0,0) position and have a much smaller
ellipsoid (better precision) than the raw data. Again, to conirm the optimality of
the processor, we check the zero-mean-whiteness/ WSSR statistics which give the
following results: zero-mean: 0.08 < 0.80; 0.05 < 0.71; approximately white: 4% out,
8% out; and WSSR decision function lies below the threshold for a window of size N:
threshold = 69.6, N = 25. These statistics again indicate that the minimum variance
design has been achieved and the processor, along with its associated statistics, is

494
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
−6
−4
−2
0
2
4
6
−5
−4
−3
−2
−1
0
1
2
3
4
5
DX-deviation (pixels)
DY-deviation (pixels)
Raw data
Enhanced
3 Sigma  
bounds
FIGURE 11.5
Three-sigma error ellipsoid for KDP XY-position deviations from simulated
data: raw deviations (O) and estimated (+) with less outliers.
valid and optimal. With this in mind, we can also observe the performance of the BP
in estimating (iltering) both measured KDP and reference positions. The results are
shown in Fig. 11.6. Here, we see the estimated (iltered) positions observing that they
are random (conditional mean) and vary slightly from the initial means indicating
that the process noise is not too severe in this case. This completes the BP design
for the position estimation problem. Next, we investigate the feasibility of using this
approach for anomaly detection.
11.1.6
Results: Anomaly Detection
We use the actual KDP measurement data as before to assess the feasibility of applying
the BP as an effective means to detect anomalies (off-normal) that could occur in the
beam line. Here, we assume that the BP has been “tuned” to normal operations for
the particular beam line and optics. Thus, the innovations are zero-mean, white, and
the WSSR lies below the threshold for optimal design. To “simulate” an off-normal
condition (in terms of position estimates), we increase the amplitude of both X and

11.1
OPTIMAL POSITION ESTIMATION FOR THE AUTOMATIC ALIGNMENT
495
Time  (days)
0
10
20
30
40
50
−20
−10
0
10
20
Time (days)
0
10
20
30
40
50
−50
0
50
Time (days)
0
5
10
15
20
25
−0.5
0
0.5
1
0
5
10
15
20
25
−0.5
0
0.5
1
Lag (days)
Lag (days)
20
25
30
40
(c)
(b)
(a)
45
50
10
30
50
70
WSSR statistic
Rho
Norm. Corr.
Norm. Corr.
Pixels
Pixels
DY-innovation
DX-innovation
Threshold
FIGURE 11.6
BP design for KDP XY-position deviation data: (a) innovations for X-
deviation and Y-deviation; (b) optimality tests: zero-mean (0.08 < 0.80; 0.05 < 0.71) and
whiteness (4% out; 8% out); (c) WSSR test (threshold = 69.6, N = 25).
Y deviations ivefold in the raw measurement data during the period of 29–35 days.
This can be thought of as corresponding to a pulse-like transient in either or both
of the measurement and/or reference position data. We applied the optimal (for no
anomaly) BP to these data to determine whether or not it could detect and track the
unknown transient anomaly.
The results of the effect on the deviation measurements are shown in Fig. 11.7.
We see the normal measurement and then the transient “jump” within the prescribed
time period. It is interesting to note that there is a corresponding disturbance in the
estimated (iltered) measurement indicating that there is enough of a disruption at
this SNR to cause the BP to track it. However, the BP is not able to track the transient
extremely well—the expected results. Next, we observe the deviation innovation
sequences output by the BP in Fig. 11.8. We again observe the transient anomaly
in both sequences, since the position estimates do not track it well enough. The

496
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
−25
−20
−15
−10
−5
0
5
0
5
10
15
20
25
30
35
40
45
50
−20
−10
0
10
20
30
Time (days)
DY-position
DX-position
Estimated
Raw
Estimated
Raw
Anomaly
Anomaly
FIGURE 11.7
Raw KDP data XY-deviations with simulated anomaly: raw (dotted) and
estimated (solid).
zero-mean/whiteness tests seem a bit too insensitive to the rapid change (six samples)
and do not dramatically detect it even the whiteness tests do not indicate a non-white
sequence (0% out; 4% out). On the other hand, the WSSR test clearly detects “change
from normal” caused by the simulated beam line anomalies almost instantaneously
indicating a feasible solution. This is again expected since the WSSR statistic ( �(�))
can be tuned to transient disruption by selecting the appropriate window length. For
this problem, we chose: N = 5; threshold = 18. To verify the performance of the
zero-mean/whiteness test, we observe the estimated positions (states) in Fig. 11.9.
Here, we see that the BP actually responds to such a high amplitude level change in
the anomaly transient. The processor could easily be “tuned” to ignore the change of
the states by decreasing the process noise variance. Finally, the scatter plots for this
case are shown in Fig. 11.10: one for the optimal solution (no anomaly) and one for
the solution with the anomaly. The size difference of the error ellipsoids in both cases
is obvious due to the added uncertainty of the modeled anomaly. The three-sigma
error ellipsoid for the case with an anomaly suspiciously indicates that something is
different, since the estimated deviation uncertainty (ellipsoid) is actually about the
same size or larger than that of the raw data. This completes the study of applying a
model-based anomaly detector.

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
497
0
10
20
30
40
50
−30
−20
−10
0
10
20
Time (days)
Pixels 
0
10
20
30
40
50
−30
−20
−10
0
10
20
Pixels
0
5
10
15
20
25
−0.5
0
0.5
1
Norm. Corr.
0
5
10
15
20
25
−0.5
0
0.5
1
Norm. Corr.
Time (days)
Lag (days)
Lag (days)
0
5
10
15
20
25
30
35
40
45
50
0
5
10
15
20
25
30
Time (days)
WSSR statistic
Rho
(a)
(b)
(c)
Anomaly
Anomaly
Anomaly
DX-innovation
DY-innovation
Threshold
FIGURE 11.8
BP detection with simulated anomaly: (a) DX and DY innovations with
anomaly; (b) optimality tests: zero-mean (0.07 < 1.7; 0.05 < 2.3); whiteness (0% out; 4%
out); (c) WSSR test (threshold = 18; N = 5).
11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC
SOURCES
Acoustic sources found in the ocean environment are spatially complex and broadband
due to temperature related sound-speed variations and dispersion that complicate the
analysis of received acoustic data considerably. A model-based approach is developed
to detect a broadband source in a shallow ocean environment characterized by a
normal-mode propagation model. Here, we develop the Bayesian solution to the

498
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
340
345
350
Pixels
Pixels
Pixels
Pixels
355
360
250
260
270
280
340
345
350
355
360
0
10
20
30
40
50
250
260
270
280
Time (days)
50
40
30
20
10
0
Time (days)
50
40
30
20
10
0
Time (days)
50
40
30
20
10
0
Time (days)
Est. image X-reference position 
Est. image Y-reference position 
Est. image Y-position 
Est. image X-position 
Anomaly
Anomaly
Anomaly
Anomaly
(a)
(b)
FIGURE 11.9
Estimated XY-positions with anomaly: (a) measured position estimates;
(b) reference position estimates.
source detection problem while simultaneously enhancing both the modal functions
and pressure-ield measurements.
11.2.1
Background
Sound propagation in the shallow ocean initiated by sources signiicantly compli-
cates the analysis of received acoustic data especially when they are broadband.
Temperature changes resulting in sound-speed variations can cause highly dispersive
propagation resulting in a statistically nonstationary signal. Highly correlated prop-
agation channels obscure the problem of extracting target signals from disturbances
and noise even further. Noise and inherent uncertainties weather ambient, distant ship-
ping, and wind blown surface generated disrupt this uncertain environment primarily
because propagation is through the same acoustic channel. When propagating in the
shallow ocean, these source characteristics complicate the analysis of received acous-
tic data considerably—especially in littoral regions providing an important challenge
for signal processing [17–23].
Employing a vertical hydrophone sensor array, the improved SNR of broadband
acoustic pressure-ield measurements using a multichannel Bayesian technique to
estimate or ilter the noisy measurement data is discussed. Here, the approach is
developed for the broadband source using a normal-mode propagation model. Prop-
agation theory predicts that a different modal structure evolves for each spectral line;
therefore, it is not surprising that the multichannel solution to this problem results
in a scheme that requires a bank of processors—each employing its own underlying
modal structure for the narrow frequency band that it operates.

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
499
−30
−20
−10
0
10
20
30
−25
−20
−15
−10
−5
0
5
10
15
20
25
DX-deviation (pixels)
Anomaly
3 Sigma 
bounds 
DX-deviation (pixels)
(a)
(b)
DY-deviation (pixels)
DY-deviation (pixels)
−30
−20
−10
0
10
20
30
−25
−20
−15
−10
−5
0
5
10
15
20
25
Raw data
Enhanced
3 Sigma 
bounds
Normal
Enhanced
Raw data
FIGURE 11.10
Three-sigma error ellipsoid and estimated XY-position deviations: (a)
measured data with no anomaly; (b) measured data with anomaly. O, measured data;
+, enhanced data.

500
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
The methodology employed is based on a state–space representation of the normal-
mode propagation model [24]. Following Refs. [25–27], the Bayesian solution of
using state–space forward propagators is discussed. It is shown that each state–space
processor is naturally decoupled in modal space and recombined in the measurement
space to provide improved signal level estimates. That is, the estimated or equivalently
“iltered” modal/pressure-ield data with improved SNR evolves providing a solution
to the signal/measurement enhancement problem and subsequent broadband source
detection problem.
In this study, we develop a sequential Bayesian solution to the signal enhance-
ment/detection problem. First, we estimate both modal functions and pressure-ield
measurements from noisy, uncertain, broadband acoustic signals in a shallow ocean
environment using a Markov chain Monte Carlo (MCMC) sampling approach (see
Chapter 7). We evaluate the processor performance by applying the Kullback–Leibler
information metric along with the classical “sanity” tests. These techniques lead to
a nonparametric representation of the posterior modal (state/measurement) distri-
butions and their associated statistics that are then used to develop a sequential
source detection technique. We perform ensemble (100-members) testing to bound
the Bayesian estimates and then develop a sequential solution to the broadband source
detection problem. To evaluate detection performance, we estimate the receiver oper-
ating characteristic (ROC) curve of Section 10.4.
11.2.2
Broadband State–Space Ocean Acoustic Propagators
In this section, we discuss the development of a broadband propagator eventually
employed in a Bayesian scheme to enhance noisy pressure-ield measurements from
a vertical array of hydrophone sensors. First, we briely discuss the propagator from
normal-mode theory following the Green’s function approach [28] and then extend
it using a state–space representation to develop a forward propagation scheme for
eventual use in Bayesian processor design.
It is well known [28–30] in ocean acoustics that the pressure-ield solution to the
Helmholtz equation under the appropriate assumptions can be expressed as the sum
of normal modes
p(rs, z, t) =
M
∑
m=1
ao
(�r(m)rs
) �m(zs)�m(z)ei�ot
(11.5)
where p is the acoustic pressure-ield; a is the source amplitude; o is the zeroth-
order Hankel function; �m is the mth modal function evaluated at z and source depth
zs; �r(m) is the horizontal wave number associated with the mth mode; �o is the
temporal source frequency, and rs is the horizontal range of the source. The wave
numbers satisfy the corresponding dispersion relation
�2 =
�2
c2(z) = �2
r (m) + �2
z (m),
m = 1, … , M
(11.6)

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
501
where the depth-dependent �z is the vertical wave number and c the corresponding
depth-dependent sound-speed proile. Taking the temporal Fourier transform of the
pressure-ield, we obtain
p(rs, z, �) =
M
∑
m=1
ao
(�r(m)rs
) �m(zs)�m(z)�(�−�o)
(11.7)
indicating a narrowband solution or equivalently a line at �o in the temporal frequency
domain.
This modal representation can be extended to include a broadband source s(t)
with corresponding spectrum Ss(�). In this case, the ocean medium is speciied by its
Green’s function (impulse response) which can be expressed in terms of the inherent
normal modes spanning the water column
(r, z, �) =
∑
m
o
(�r(m)r) �m(zs)�m(z)
(11.8)
and therefore the resulting pressure-ield in the temporal frequency domain is given
by
p(rs, z, �) = (rs, z, �)S(�)
(11.9)
which equivalently results from the temporal convolution of (r, z, t) and s(t).
Suppose we decompose the continuous source spectrum into a sampled or discrete
spectrum using a periodic impulse (frequency) sampler, then it follows that
Ss(�) = △�
∑
q
S(�)�(�−�q) = △�
∑
q
S(�q)�(�−�q)
(11.10)
from the sampling properties of Fourier transforms. Therefore, a broadband signal
spectrum can be decomposed into a set of narrowband components assuming an
impulse sampled spectrum.
Utilizing this property in Eq. 11.10 and extracting just the qth source frequency,
we have
p(rs, z, �q) = (rs, z, �)Ss(�q)
(11.11)
where Ss(�q) is interpreted as a single narrowband impulse at �q with amplitude,
aq = △�|S(�q)|. Suppose that the broadband source is assumed to be bandlimited
and sampled Ss(�), �1 ≤�≤�Q then
Ss(�) = △�
Q
∑
q=1
S(�q)�(�−�q)
(11.12)

502
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Thus, the normal-mode solution to the Helmholtz equation for the broadband
source problem can be decomposed into a series of narrowband solutions, that is,
p(r, z, �q) =
Mq
∑
m=1
aqo
(�r(m, q)r) �m(zs, �q)�m(z, �q)
(11.13)
where Mq is the number of modes spanning the water column at frequency �q with
the corresponding dispersion relation satisfying
�2
r (m, q) =
�2
q
c2(z) −�2
z (m, q),
m = 1, … , Mq; q = 1, … , Q
(11.14)
and the pressure-ield at depth z and time t can be expressed in terms of the bilateral
inverse (discrete) Fourier transform as
p(r, z, t) = ∫
∞
−∞
p(r, z, �)ej�td�≈1
Q
Q−1
∑
q=−(Q−1)
p(r, z, �q)ej�qt
(11.15)
Suppose we further assume an L-element vertical sensor array, then z →z�, �=
1, … , L and therefore, the pressure-ield at the array for the qth temporal frequency
of Eq. 11.13 becomes
p(rs, z�, �q) =
Mq
∑
m=1
�m(rs, zs, �q)�m(z�, �q)
(11.16)
where �m(rs, zs, �q) := aqo
(�r(m, q)rs
) �m(zs, �q) is the mth-modal coeficient at
the qth temporal frequency.
In terms of these models, it has been shown [26] that the broadband state-space
propagator can be expressed as
d
dz�(z, Ω) = A(z, Ω)�(z, Ω)
p(z�, Ω)
= C(rs, zs, Ω)�(z�, Ω)
(11.17)
where
�(z, Ω) ∈2M×1,
A(z, Ω) ∈2M×2M,
C(rs, zs, Ω) ∈1×2M
with
M =
∑Q
q=1 Mq and Ω := {�q}; q = 1, … , Q is the entire set of discrete temporal
frequencies.

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
503
Broadband pressure-field
( , , )
ω
p r z
Narrowband pressure-field
1
( , ,
)
ω
p r z
Narrowband pressure-field
( , ,
)
ωQ
p r z
Narrowband modes
1
1
( ,
)
ϕ
ϕ
ϕ
ϕ
ω
z
Narrowband modes
1
( ,
)
ω
M z
Narrowband modes
1( ,
)
ωQ
z
Narrowband modes
( ,
)
ω
M
Q
z
FIGURE 11.11
Decomposition of broadband signal into narrowband components
based on normal-mode propagation representation.
The internal structure of this overall processor admits the following decomposi-
tion:
d
dz�(z, Ω) =
⎡
⎢
⎢
⎢⎣
A(z, �0)
O
⋯
O
O
A(z, �1)
⋯
O
⋮
⋱
⋮
O
O
⋯
A(z, �Q−1)
⎤
⎥
⎥
⎥⎦
⎡
⎢
⎢
⎢⎣
�(z, �0)
�(z, �1)
⋮
�(z, �Q−1)
⎤
⎥
⎥
⎥⎦
(11.18)
and A(z, �q) = diag
[
A1(z, �q) ⋯AMq(z, �q)
]
∈R2Mq×2Mq and
Am(z, �q) =
[
0
1
−�2
z (m, q)
0
]
,
m = 1, … , Mq
(11.19)
with the pressure-ield sensor measurement model given by (see Fig. 11.11).
p(z�, Ω) =
[
1
QCT
1(rs, zs, �0)ej�0t ⋯1
QCT
Q(rs, zs, �Q−1)ej�Q−1t
] ⎡
⎢
⎢⎣
�(z�, �0)
⋮
�(z�, �Q−1)
⎤
⎥
⎥⎦
(11.20)
This deterministic model can be extended to a stochastic Gauss–Markov repre-
sentation [11] given by
d
dz�(z, Ω) = A(z, Ω)�(z, Ω) + w(z, Ω)
p(z�, Ω)
= C(rs, zs, Ω)�(z�, Ω) + �(z, Ω)
(11.21)

504
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
where w, �are additive, zero-mean Gaussian noise sources with respective spectral
covariance matrices R��(z, Ω), and R��(z, Ω).
11.2.3
Discrete Normal-Mode State–Space Representation
Since our array spatially samples the pressure-ield discretizing depth, we discretize
the differential state equations of Eq. 11.21 in depth. Using a central difference
approach for improved numerical stability, we have
d2�m(z, �q)
dz2
≈
�m(z�, �q) −2�m(z�−1, �q) + �m(z�−2, �q)
△z2
�
for △z�:= z�−z�−1. Substituting this approximation into the modal relations gives
�m(z�, �q) −2�m(z�−1, �q) + �m(z�−2, �q) + △z2
��2
z (m, q)�m(z�−1, �q) = 0
where m = 1, … , Mq and z�is the location of the �th sensor. Deining the discrete
broadband modal state vector as �m(z�, �q) := [�m(z�−2, �q)|�m(z�−1, �q)]T, we
obtain the following set of difference equations for the mth mode at the qth frequency
�m1(z�, �q) = �m2(z�−1, �q)
�m2(z�, �q) = −�m1(z�−1, �q) +
(
2 −△z2
��2
z (m, q)
)
�m2(z�−1, �q)
with each of the corresponding modal A-submatrices given by
Am(z, �q) =
⎡
⎢
⎢⎣
0
1
−1
2 −△z2
��2
z (m, q)
⎤
⎥
⎥⎦
;
m = 1, … , Mq
11.2.4
Broadband Bayesian Processor
For our pressure-ield/modal function estimation problem, we deine the underlying
broadband pressure-ield/modal function signal enhancement problem as:
GIVEN
a
set
of
noisy
broadband
pressure-ield
measurements,
P�:=
{p(z1, Ω), … , p(z�, Ω)} and the underlying stochastic model of Eq. 11.21, FIND an
estimate of the posterior distribution, ̂Pr [�(z�, Ω)|P�
] and infer the corresponding
enhanced estimates of the broadband modal functions, ̂�(z�, Ω) and pressure-ield,
̂p(z�, Ω) .
The solution to this problem can be obtained by estimating the joint a posteriori
distribution applying Bayes’ theorem, that is, the joint probability of the broadband

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
505
modal functions at the �th depth based on the set of pressure-ield measurements up
to z�is given by
Pr[��|P�
] =
Pr[P�|��
] × Pr[��
]
Pr[P�
]
(11.22)
where ��:= {�(z1, Ω), … , �(z�, Ω)} is the set of broadband modal functions
(states) and P�is the set of broadband measurements up to and including p(z�, Ω).
Following Ref. [26], the measurement likelihood distribution, that is, the joint set
of measurements up to and including the �th based on the set of broadband modal
functions at depth z�can be factored using Bayes’ rule as
Pr[P�|��
] = Pr[p(z�, Ω)|�(z�, Ω)] × Pr[P�−1|��−1
]
(11.23)
under the assumed independence of p(z�, Ω) with P�−1 and ��−1, and �(z�, Ω) with
P�−1.
Similarly, the joint prior modal distribution at depth z�can also be factored to
give the (modal) transition distribution
Pr[��
] = Pr[�(z�, Ω), ��−1
] = Pr[�(z�, Ω)|�(z�−1, Ω)] × Pr[��−1
]
under the irst-order Markov assumption, while that for the joint evidence is factored
as
Pr[P�
] = Pr[p(z�, Ω), P�−1
] = Pr[p(z�, Ω)|P(z�−1, Ω)] × Pr[P�−1
]
Substituting these relations into Eq. 11.22, cancelling like terms, assuming con-
ditional independence and recognizing the Bayes’ relation for the previous step
Pr[��−1|P�−1
], we obtain the sequential Bayes’ expression for the joint posterior
density of the set of broadband modal functions based on the pressure-ield measure-
ments as
Pr [��|P�
] =
(
Pr [p(z�, Ω)|�(z�, Ω)] × Pr [�(z�, Ω)|�(z�−1, Ω)]
Pr [p(z�, Ω)|P�−1
]
)
× Pr [��−1|P�−1
]
(11.24)
consisting of the measurement likelihood, modal transition prior and evidence (for
details see Section 2.5.3).
11.2.5
Broadband Particle Filters
One approach to estimate the required posterior distribution of Eq. 11.24 from noisy
broadband measurements is to develop the so-called particle ilter (PF) [31]. A par-
ticle ilter is a completely different approach to nonlinear iltering that is capable of

506
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
characterizing multi-modal distributions. In fact, it might be easier to think of the
PF as a histogram or kernel density-like estimator in the sense that it is an estimated
empirical probability mass function (PMF) that approximates the desired posterior
distribution such that inferences can be performed and statistics extracted directly.
Here, the idea is a change in thinking where we attempt to develop an empirical
estimation of the posterior distribution following a purely Bayesian approach using
Monte Carlo (MC) sampling theory as its enabling foundation. As one might expect,
the computational burden of the PF is much higher than that of other processors,
since it must provide an estimate of the underlying state posterior distribution state
by state at each z�-step along with the fact that the number of samples to char-
acterize the distribution is equal to the number of particles (Np). The estimated
empirical posterior distribution for the broadband signal enhancement problem is
given by
̂Pr[�(z�, Ω)|P�] =
Np
∑
i=1
i(z�, Ω) × �(�(z�, Ω) −�i(z�, Ω))
(11.25)
where the weights and posterior distribution estimated by the PF are given by
P�
is the set of batch pressure-ield measurements,
i(z�, Ω) is the ith broadband weight (normalized) at depth z�
�i(z�, Ω) is the ith particle of the broadband modal function at depth z�
Once the underlying posterior is available, estimates of important statistics can be
extracted directly. For instance, the maximum a posteriori (MAP) estimate is found
by locating a particular particle �i(z�, Ω) corresponding to the maximum of the PMF
at that depth, that is,
̂�MAP(z�, Ω) = max
i
̂Pr
[
�i(z�, Ω)|P�
]
(11.26)
while the conditional mean (CM) or equivalently the minimum mean-squared error
(MMSE) estimate is estimated by
̂�CM(z�, Ω) ≈1
Np
Np
∑
i=1
i(z�, Ω) × �i(z�, Ω)
(11.27)
The Bayesian solution for this problem is based on determining the associated
broadband weighting function that leads to the estimated empirical posterior distri-
bution. A sampling or equivalently importance distribution I(�(z�, Ω)|P�) is selected

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
507
irst, then the weight (unnormalized) is determined by the ratio of the desired posterior
to this choice (see Section 7.5.1)
W(z�, Ω) := Pr[�(z�, Ω)|P�]
I(�(z�, Ω)|P�)
which can be expanded using Bayes’ rule of Eq. 11.22 to provide the “sequential”
generic weight
W(z�, Ω) := W(z�−1, Ω) × Pr[p(z�, Ω)|�(z�, Ω)] × Pr[�(z�, Ω)|�(z�−1, Ω)]
I(�(z�, Ω)|P�)
(11.28)
where the numerator is the product of the likelihood and the state transition proba-
bility.
11.2.6
Broadband Bootstrap Particle Filter
There are a variety of PF algorithms available based on the choice of the importance
distribution [26]. Perhaps the simplest is the bootstrap technique. The PF design for
our problem using the bootstrap approach employs the state transition probability as
its importance distribution, that is,
I(Φ(z�, Ω)|P�) := Pr[Φ(z�, Ω)|Φ(z�−1, Ω)]
(11.29)
Substituting this expression into Eq. 11.28 leads to the weighting function
(z�, Ω) = (z�−1, Ω) × Pr[p(z�, Ω)|Φ(z�, Ω)]
(11.30)
which is simply the likelihood distribution.
For the bootstrap implementation, we draw samples from the state transition
distribution using the dynamic modal model of Eq. 11.21 driven by the process
uncertainty wi(z�−1, Ω) to generate the set of particles, {�i(z�, Ω)} for each i =
1, … , Np.
The likelihood, on the other hand, is determined from the pressure-ield measure-
ment model for each mode giving the likelihood (assuming Gaussian measurement
noise) as
Pr[p(z�, Ω)|�i(z�, Ω)] =
1
√
2�R��(Ω)
× exp
{
−
1
2R��(Ω)(p(z�, Ω) −C(rs, zs, Ω)�i(z�, Ω))2}
(11.31)

508
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Thus, we can estimate the posterior distribution using a sequential Monte Carlo
approach and construct a bootstrap particle ilter of Section 7.5 using the following
steps:
r Initialize: �i(z0, Ω), wi(z0, Ω) ∼(0, R��(z0, Ω)),
�(z0, Ω) ∼(0, R��(z0, Ω)), Wi(z0, Ω) = 1∕Np; i = 1, … , Np
r State transition: �i(z�, Ω) = A(z�−1, Ω)�i(z�−1, Ω) + wi(z�−1, Ω)
r Likelihood probability: Pr[p(z�, Ω)|�i(z�, Ω)] of Eq. 11.31
r Weights: Wi(z�, Ω) = Wi(z�−1, Ω) × Pr[p(z�, Ω)|�i(z�, Ω)]
r Normalize: i(z�, Ω) =
Wi(z�,Ω)
∑Np
i=1 Wi(z�,Ω)
r Resample:
{ ̂�i(z�, Ω) ⇒�i(z�, Ω)
Neff ≤N�[Resample]
Neff > N�[No resample]
r Posterior: ̂Pr[�i(z�, Ω)|P�] = ∑Np
i=1 i(z�, Ω)�(�(z�, Ω) −̂�i(z�, Ω))
r MAP estimate: ̂�MAP(z, Ω) = max
i
̂Pr[�i(z�, Ω)|P�]
r CM estimate: ̂�CM(z, Ω) =
1
Np
∑Np
i=1 i(z�, Ω) × �i(z�, Ω)
We see that after initialization, the broadband modal model is used to generate the
particles during the prediction step. These particles, �i(z�, Ω), are then incorporated
into the likelihood distribution providing the update step. Recall that resampling of the
particles (see Section 7.4) is usually required to prevent degeneracy of the associated
weights which increase in variance at each depth making it impossible to avoid the
degradation. Resampling consists of processing the particles with their associated
weights duplicating those of large weights (probabilities) and discarding those of
small weights. In this way, only those particles of highest probabilities (importance)
are retained enabling a coalescence at the peaks of the resulting posterior distribution
while mitigating the degradation. A measure based on the coeficient of variation, the
effective particle sample size given by
Neff =
1
∑Np
i=1 W2
i (z�, Ω)
(11.32)
is the underlying decision statistic such that when its value is less than a pre-
determined threshold resampling is performed.
We should also note from the structure of the PF algorithm that each mode (two
states) is driven by the modal process noise/uncertainty vector wi(z�). This process,
coupled with the underlying block diagonal structure of A(z�, Ω), enables a parallel
construct of the overall processor that is eventually combined by the measurement
model of the likelihood distribution. Here, in contrast to the approximate (unimodal)

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
509
model-based (Kalman) scheme of Section 5.3, no approximations are required to
obtain this overall block-diagonal structure and parallel implementation.
11.2.7
Bayesian Performance Metrics
Particle ilters are basically developed to provide estimates of the underlying poste-
rior distributions for the problem under investigation in order to extract meaningful
statistics. Compared to the usual model-based (Kalman) processors (see Section 5.7)
which utilize their inherent “optimality” property (zero-mean, uncorrelated residu-
als) to assess performance, the estimated posterior of the PF must be compared to
the true distribution of the underlying process it is to estimate. One way to achieve
this comparison as developed in Section 7.6, is to utilize the associated divergence
statistic of the Kullback–Leibler information as a metric.
Our interest lies in comparing two probability distributions to determine “how
close” they are to one another. Even though, the KL does quantify the difference
between the true and estimated distribution, it is not a distance metric to answer this
question due to its lack of symmetry. However, the Kullback divergence (KD) deined
by
KD
(Pr[�i(z�, Ω)|P�]; ̂Pr[�i(z�, Ω)|P�])
= KL
(Pr[�i(z�, Ω)|P�]; ̂Pr[�i(z�, Ω)|P�])
+ KL
( ̂Pr[�i(z�, Ω)|P�]; Pr[�i(z�, Ω)|P�])
(11.33)
is a distance metric between distributions indicating “how close” one distribution is
to the other or from our perspective, “how well does it approximate” the posterior.
Thus, the KD is a very important metric that can be applied to assess the performance
of Bayesian processors providing a metric between the true and estimated posterior
distributions that we apply to our broadband problem.
11.2.8
Sequential Detection
In this section, we develop a sequential detector that incorporates the particle ilter
to solve the basic problem of detecting a broadband source from noisy pressure-ield
measurements. For our decision problem, we deine the underlying broadband source
detection problem as:
GIVEN a set of noisy broadband pressure-ield measurements, {P�}; �= 1, … , L
with the underlying stochastic model of Eq. 11.21 and the “data likelihood” distri-
bution, Pr[p(z�, Ω)|P�−1], DECIDE whether or not the broadband source is present
where P�:= {p(z1, Ω), … , p(z�, Ω)}.
This is a binary decision problem; therefore, we are to test the hypothesis of
whether the noisy pressure-ield measurements have evolved from a broadband source

510
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
or not. The corresponding binary hypothesis test is
0 : p(z�, Ω) = �(z�, Ω)
[Noise]
1 : p(z�, Ω) = C(rs, zs, Ω)�i(z�, Ω) + �(z�, Ω)
[Source]
(11.34)
An optimal solution to this decision problem is based on applying the Neyman–
Pearson theorem leading to the likelihood ratio [32, 33] deined by
(PL) := Pr[PL|1]
Pr[PL|0]
1
>
<
0

(11.35)
where PL = {p(z1, Ω), … , p(zL, Ω)} with threshold .
Following Section 10.5, expanding the likelihood-ratio for each depth, we obtain
(PL) = Pr[p(z1, Ω), … , p(zL, Ω)|1]
Pr[p(z1, Ω), … , p(zL, Ω)|0]
(11.36)
As before, from the chain rule of probability and Bayes’ theorem [34], we have
Pr[PL|i] = Pr[p(zL, Ω), PL−1|i] = Pr[p(zL, Ω)|PL−1, i] × Pr[PL−1|i]
(11.37)
Substituting these expressions into the likelihood ratio above, replacing L →�,
and grouping, we obtain the sequential form of likelihood ratio as [33]
(p(z�, Ω)) = (p(z�−1, Ω)) × Pr[p(z�, Ω)|p(z�−1, Ω), 1]
Pr[p(z�, Ω)|p(z�−1, Ω), 0]
(11.38)
Taking logarithms simpliies the computations; therefore, we deine Λ(p(z�, Ω)) :=
ln (p(z�, Ω)) to obtain the sequential log-likelihood-ratio decision function for the
broadband source detection problem as
Λ(p(z�, Ω)) = Λ(p(z�−1, Ω)) + ln Pr[p(z�, Ω)|p(z�−1, Ω), 1]
−ln Pr[p(z�, Ω)|p(z�−1, Ω), 0]
(11.39)

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
511
To complete this development, we require thresholds that lead to the Wald sequen-
tial probability-ratio test [33] of Section 10.5
Λ(p(z�, Ω))
> ln 1(�)
Accept 1
ln 0(�)
≤Λ(p(z�, Ω))
≤ln 1(�)
Continue
Λ(p(z�, Ω))
< ln 0(�)
Accept 0
These thresholds can be obtained from an operating point (PFA,PDET) on the
associated ROC curve obtained through simulation or experimental data and are
speciied by
0(�) = 1 −PDET(�)
PFA(�)
1(�) = PDET(�)
PFA(�)
(11.40)
For this problem, the particle ilter is used to estimate the desired data likelihood
distribution based on the nonparametric estimate of the posterior distribution, that is,
we require an estimate of the
̂Pr[p(z�, Ω)|p(z�−1, Ω); �)]; �= 0, 1
(11.41)
under each hypothesis of Eq. 11.34.
Recall from Section 10.5 that assuming a irst-order Markov process (P�−1 →
p(z�−1, Ω)) and choosing the importance distribution to be the state transition
I(�(z�, Ω)|�(z�−1, Ω), P�−1) →Pr[�(z�, Ω)|�(z�−1, Ω)], then the bootstrap PF
results with weight i(z�, Ω) →Pr[p(z�, Ω)|�i(z�, Ω)]. Therefore, the data like-
lihood can be approximated by
̂Pr[p(z�, Ω)|p(z�−1, Ω)] = 1
Np
Np
∑
i=1
Pr[p(z�, Ω)|�i(z�, Ω)]
≈1
Np
Np
∑
i=1
i(z�, Ω) =: (z�, Ω)
(11.42)
where is the ensemble mean of the weight at each depth [35, 36].
Thus, the corresponding sequential log-likelihood decision function for the broad-
band source detection problem is
Λ(p(z�, Ω)) = Λ(p(z�−1, Ω)) + ln (z�, Ω; 1) −ln (z�, Ω; 0)
(11.43)
This completes the development of the sequential detector that is applied to our
simulated data.

512
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Receive
Sediment
Surface
Source  
Subbottom
Sound Speed
Ocean:
flat bottom, three layers, 100 m water column, 2.5 m sediment, 
100 element vertical array
Source:    50–100 Hz source at 10 km range and 50 m depth
FIGURE 11.12
Shallow ocean environment problem:channel (100 m) with broadband
(50 Hz) source located at range rs = 10 km and depth zs = 50 m.
11.2.9
Broadband BSP Design
In this section, we discuss the application of the Bayesian processor to data synthe-
sized by a broadband normal-mode model using the state–space forward propagator
and the particle ilter along with the sequential log-likelihood detector.
Let us consider a basic shallow water channel depicted in Fig. 11.12. We assume
a lat bottom, range-independent three-layer environment with a channel depth of
100 m, a sediment depth of 2.5 m, and a subbottom. A vertical line array of 100
sensors with spacing of △z = 1 m spans the entire water column and a broadband
source of unit amplitude and 50 Hz bandwidth ranging from 50 to 100 Hz in 10
Hz increments is located at a depth of 50 m and a range of 10 km from the array.
The sound-speed proile in the water column and the sediment are sketched in the
igure and speciied along with the other problem parameters. SNAP, a normal-mode
propagation simulator [37] is applied to solve this shallow water problem and executed
over the set of discrete temporal source frequencies. This boundary value problem
was solved using SNAP and the results at each narrowband frequency are obtained.
We note that as the temporal frequency increases, the number of modes increases
thereby increasing the corresponding order of the state–space. Details of the problem
parameters are given in Ref. [26].
The parameters obtained from SNAP are now used to construct the broadband
state–space and measurement models of the previous subsection. Here, we use the set
of horizontal wave numbers, {�(m, q)}, m = 1, … , Mq; q = 1, … , Q, and sound speed

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
513
Boundary Value
Modal Solver
(NMode)
Forward
Propagation
Model (NMode)
Measurement
Model
(Array)
Noise
Model
BAYESIAN PROCESSOR
Localization
Tracking
Detection
Measurement
(
)
ˆ
,
z
Θ
Ω
l
(
)
( )
{
}
p
,
,
z
c z
Ω
l
l
(
)
(
)
(
)
ˆ
,
ˆ
,
ˆp
,
z
z
z
⎧
⎫
Φ
Ω
⎪
⎪
⎪
⎪
Θ
Ω
⎨
⎬
⎪
⎪
Ω
⎪
⎪
⎩
⎭
l
l
l
FIGURE
11.13
Bayesian processor design: boundary value solver provides ini-
tial state–space parameters for modal forward propagation, measurement, and
noise/uncertainty models (state–space forward propagator) and data provide the
inputs of pressure-ield and sound speed. Bayesian processor outputs can be incor-
porated into potential ocean acoustic applications such as localization, tracking, and
detection.
{c(z�)} to implement the state models along with the corresponding modal function
values {�m1(zs, �q)}, as well as the Hankel functions {o(�(m, q)rs)} to construct
the measurement models. The inal set of parameters for our simulation are the modal
and measurement noise covariance matrices required by the Gauss–Markov model
(see Ref. [38] for more details).
It is important to realize that the state–space “forward” propagators do not offer
an alternative solution to the Helmholtz equation (not to be confused with a marching
method), but rather use the parameters from the boundary value solution to obtain a
set of initial conditions/parameters for the propagator construction. Even the adaptive
model-based processors still utilize the boundary value solutions to “initialize” the
processing [24] (see Fig. 11.13).
With this information available, a 100-member ensemble of stochastic simulations
was performed at SNRin = 10 dB (modes) and SNRout = 0 dB (pressure-ield) based
on the SNAP parameters of Ref. [26].
11.2.9.1
Classical Performance Metrics
Initially, we develop the proces-
sor for a single realization and perform some of the classical statistical tests to
ensure the validity of the embedded model. In statistical signal processing, a stan-
dard statistical test to determine whether or not a processor is operating properly is
whether the residual sequence (difference between the measurement and the proces-
sor “predicted” measurement) has a small mean-squared error (MSE). Speciically
for sequential algorithms, the one-step prediction error (or residual) has the property
that the prediction error, or equivalently the residual sequence, should be zero-mean
and uncorrelated (or white). Pragmatically, residuals that satisfy these properties

514
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
ensure that the embedded model-based processor has “removed” all correlation (of
the model) from the data. The remaining measurement (residual) is uncorrelated or
equivalently provides no further information about the signal (or model). Indeed this
is the case, since the zero-mean test conirms that the residual mean to be smaller
than the calculated bound (8.9 × 10−6 < 0.245) and uncorrelated with only 1.6% of
the correlation samples lying outside of the boundaries (5% or more are considered
correlated) for our 125-particle design.
Since our data are nonstationary, the weighted sum-squared residual (WSSR) is a
more reliable statistic to use to determine the “whiteness” of the residual (innovation)
sequence [38]. Recall (see Section 5.7) that the WSSR uses this sequence to test
whiteness by requiring that the constructed decision function lies below a threshold.
If the WSSR statistic does lie beneath the calculated threshold, then theoretically, the
estimator is considered tuned and the embedded model deemed appropriate. For this
application, the WSSR statistic also conirms the whiteness with its decision function
lying below the threshold of 81.5 with a 60-sample sliding window.
11.2.9.2
Ensemble Statistics
In order to evaluate the processor performance,
we construct an ensemble of 100-member realizations and calculate the ensemble
statistics. The following results are based on ensemble average estimates, that is,
all of the subsequent estimator results have been averaged over the 100-realizations
to provide a more meaningful representation of “what could be expected” from the
processor when implemented.
The results of the Bayesian design are shown in Fig. 11.14 where we see the
enhanced pressure-ield (MAP) and the true measurement (mean) as well as the
Pressure
×10–4
−10
−8
−6
−4
−2
0
2
4
6
8
Depth (m)
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Pressure-field enhancement
Data
True
MAP
Innovation
FIGURE 11.14
Broadband shallow water environment pressure-ield enhancement:raw
data (SNR = 0dB), particle ilter (125-particles) estimates (MAP, CM) and residual errors
(innovations).

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
515
Depth (m)
0.035
0.025
0.015
0.005
0
150
100
50
0
0.02
0.01
0.03
Pressure
× 10–4
−1
−0.5
0
0.5
1
Predicted pressure-ield posterior distribution
FIGURE 11.15
Predicted pressure-ield multi-modal posterior distribution (125-particles)
surface (depth vs. pressure vs. probability) indicating a multi-modal surface.
raw data and corresponding innovations sequence as a function of depth. Note from
Eq. 11.21 that the modal estimates ̂�(z�, �q), along with the measurement model
CT(rs, zs, �q), are used to construct the enhanced pressure-ield ̂p(z�, �q) at each
temporal frequency. To complete the performance analysis, we observe the posterior
pressure-ield distribution predicted by the PF at each depth in Fig. 11.15. Clearly this
distribution is not unimodal, but both MAP/CM inferences “track” the mean (true)
pressure-ield quite well. We have also estimated the KD statistic which is shown in
Fig. 11.19 a which will be discussed subsequently.
The estimated modal functions (ensemble averaged) extracted from the noisy
pressure-ield measurements are shown in Figs. 11.16 and 11.17—bounding the
estimates we could hope to achieve for this type of data. We use the annotation:
(Frequency/Mode No.), that is, M50 −1 is the irst modal function at 50 Hz frequency.
Here we observe that the MAP and CM estimates inferred from the predicted posterior
modal distributions essentially overlay one another and “track” the true (noise-free)
functions very well in spite of the uncertainties in the synthesized modal data. In Fig.
11.16, we observe the enhanced modal function estimates (ensemble averaged) and
uncertain data (DATA) corresponding to the two modes at 50 Hz, three at 60 Hz and

516
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
0 1 2 3
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
M50-1
−1  0 1
Data
Data
Data
Data
Data
Data
Data
Data
Data
Data
Data
Data
Map
Map
Map
Map
Map
Map
Map
Map
Map
Map
Map
Map
Tru
Tru
Tru
Tru
Tru
M50-2
0 2
M60-1
−1 0 1
M60-2
−0.5 0 0.5
M60-3
0
5
M70-1
−2  0 2
M70-2
−0.5 0 0.5
50 Hz 
60 Hz 
70 Hz 
80 Hz 
M70-3
0
5
M80-1
−2 0 2
M80-2
−0.5 0 0.5
Depth (m)
M80-3
−0.5 0 0.5
M80-4
FIGURE 11.16
Broadband shallow water environment mode tracking: particle ilter
(125-particles) modal function estimation (MAP, CM) with true (True) and uncertain
modes (Data) at 50–80 Hz frequencies.
70 Hz, and four at 80 Hz. In Fig. 11.17, we see the ensemble estimates for both 90
Hz (four modes) and 100 Hz (ive modes). The RMS MSE estimates for each of the
modal functions are shown in Table 11.1 where we observe small modal function
tracking errors.
−2 0
2
  M90-1 
−0.5 0 0.5
M90-2 
0
5
M90-3 
−2 0
2
M90-4 
−0.5 0 0.5
 M100-1 
−0.5 0 0.5
 M100-2 
0
5
 M100-3 
−2 0
2
 M100-4 
−0.5 0 0.5
M100-5
  100 Hz  
  90 Hz  
Data 
Data 
Data 
Data 
Data 
Data 
Data 
Data 
Data 
MAP
MAP
MAP
MAP
MAP
MAP
MAP
MAP
MAP
MAP
Tru 
Tru 
Tru 
Tru 
Tru 
Tru 
Tru 
Tru 
Tru 
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
FIGURE 11.17
Broadband shallow water environment mode tracking: particle ilter
(125-particles) modal function (21) estimation (MAP, CM) with true (True) and uncer-
tain modes (Data) at 90–100 Hz frequencies.

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
517
TABLE 11.1
Modal Parameters and Tracking Estimation
Particle Filter Performance
Frequency (Hz)
Mode No.
Modal Coeff.
Wave No.
MSE
KLD
50
1
0.122
0.207386
0.03244469
0.02333190
2
−0.070
0.202489
0.06390081
0.00042730
60
1
0.125
0.249339
0.02057981
0.01498970
2
−0.063
0.245106
0.02262004
0.00480695
3
−0.097
0.237639
0.00725442
0.00045842
70
1
0.127
0.291255
0.1173259
0.01173030
2
−0.057
0.287522
0.07374703
0.00414254
3
−0.108
0.280907
0.01009431
0.00070735
80
1
0.129
0.333144
0.1376377
0.01020890
2
−0.052
0.329802
0.03716592
0.00605280
3
−0.113
0.323913
0.01584901
0.00058421
4
0.087
0.315526
0.01425319
0.00067141
90
1
0.130
0.375015
0.1104416
0.00699367
2
−0.047
0.371985
0.02928122
0.00476581
3
−0.117
0.366685
0.01980555
0.00059496
4
0.084
0.358997
0.00782307
0.00031112
100
1
0.131
0.416871
0.3176212
0.00648074
2
−0.043
0.414098
0.06316895
0.00449904
3
−0.119
0.409278
0.01011795
0.00079068
4
0.079
0.402279
0.01544138
0.00031464
5
0.081
0.393399
0.00450539
0.00019501
Thus, we see that modal function tracking of the broadband data presents another
aspect of the PF estimates. We show the posterior PMF surfaces (depth vs. modal
amplitude vs. probability) for a single realization of mode: M50 −1 in Fig. 11.18.
The surface indicates a multi-modal posterior PMF at various depth slices for this
nonstationary process. This completes the modal analysis over the ensemble; next,
we investigate the information theoretical results.
11.2.9.3
Performance Metrics
In this section, we investigate the perfor-
mance of the broadband PF over the 100-member ensemble of synthetic pressure-
ield measurements using the information metrics discussed in Section 7.6. The KD
divergence of Eq. 11.33 provides us with a metric to determine “how close” the esti-
mated posterior is to the true distribution. Since we have simulations available, we
can generate deterministic or noise-free modal/pressure-ield data that can be used to
estimate the true distributions. The ensemble empirical PMF distributions provided
by the PF can then be compared with the truth using the KD divergence criterion
with approximate equality speciied by values close-to-zero. As an illustration, we
choose time slices of the pressure-ield and modal function and estimate these PMFs
for each as shown in Fig. 11.19 along with their corresponding KL metrics. We used
a kernel density estimator (smoothed histogram) from each of the random sequence

518
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Depth (m)
0.04
0.03
0.02
0.01
0
0
0
2
4
6
150
100
50
Modal Amplitude
−2
Modal Track  M50-1: Posterior Distribution
FIGURE 11.18
Estimated multi-modal (arrows) posterior modal distribution (125-
particles) surface (depth vs. amplitude vs. probability) for mode: M50 −1.
realizations for the raw synthesized pressure-ield data, the true, and MAP and CM
estimates.
For the pressure-ield shown in Fig. 11.19a, it is clear that the broadband enhanced
estimates are quite good compared to the noisy data as evidenced by estimated PMFs
and respective the KL divergences of 0.25 (Data), 0.002 (MAP) and 0.0003 (CM).
The M50 −1 mode also conirms a converged posterior with KL divergences of 0.070
(Data), 0.021 (MAP), and 0.097 (CM).
Since the modal process is nonstationary in space (depth z), the multi-modal
posterior varies at each discrete depth; therefore, we perform the above analysis
on all 21 (42-state) modal functions and the pressure-ield at each depth. We can
employ the KL divergence metric, calculate it at each depth (PMF) providing a set
of “KD trajectories” for the measurement and each mode summarizing the Bayesian
processor overall performance. Note that the perfect PMF would yield a “zero”
(trajectory) at every depth slice. Thus these trajectories estimate the KD for each PMF
depth slice compressing the information into a single number with summary statistics
(mean/median) to follow. The results of the KD divergence metric are shown in Fig.
11.20 comparing each of the multi-modal PMFs to the truth. We include the median

11.2
SEQUENTIAL DETECTION OF BROADBAND OCEAN ACOUSTIC SOURCES
519
Modal amplitude.
−2
−1
0
1
2
3
4
5
Probability
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
Kldata = 0.0703742;
KLcm = 0.0202995
Klmap = 0.0971681
Data
True
Cm
Mode M50-1 PMFs
Map
Sample no.
−8
−6 −4
−2
0
2
4
6
8
Probability
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
KLdata = 0.249539
KLcm= 0.000303
Klmap = 0.002362
Data
Map
True
Cm
Pressure-ield PMFs
(a)
(b)
Ensemble no.
0
10
20
30
40
50
60
70
80
90 100
Kullbach-leibler divergence
0
0.005
0.01
0.015
0.02
0.025
0.03
Mean
Median
PMFs: Meas. = 1; Ens = 100;
MED KLDiv = 0.00435911;
MN KLDiv = 0.00583772   
Pressure-ﬁeld 
(c)
Ensemble no.
0
10
20
30
40
50
60
70
80
90 100
Kullbach-leibler divergence
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Mean
Median
PMFs: State  = 1; Ens = 100;
MED KLDiv = 0.0233319; 
MN KLDiv= 0.0297981  
Mode M50-1 
(d)
× 10−4
FIGURE 11.19
Multi-modal PMF data, true, MAP, CM estimates: (a) pressure-ield (KD
= 0.0003); (b) mode: M50 −1 (KD = 0.02); (c) KL-divergence: pressure-ield; (d) KL-
divergence: mode: M50 −1 (125-particles).
estimates as a single metric performance indicator as well as the corresponding MSE
estimates in Table 11.1 for each mode.
Next, we apply the enhanced modal/pressure-ield estimator as a pre-processor
to solve the broadband source detection problem using the sequential detection
approach. First, we generated data sets under each hypothesis and then estimate
the log-likelihood decision functions for each. From these functions, we estimated
the corresponding PMFs using a kernel density estimator of Section 3.2 as shown
in Fig. 11.20a. From these distributions, we estimated the corresponding ROC curve
of Fig. 11.20b and obtained the optimal operating point [32] which was estimated
as (PFA, PDET) = (0.034, 0.998), that is, 99.8% detection with a 3.4% false alarm rate
for these SNRs. We calculated the required thresholds of Eq. 11.40 for the sequential
source detector and applied it to the noisy (0 dB) pressure-ield data shown in Fig.
11.14. The results for both the source present and absent scenarios are depicted in
Fig. 11.20c and 11.20d indicating a detection in (c) and a non-detection (noise) in (d).
These results indicate the applicability of this solution to broadband source detection
problem and characterize the processor performance for these SNRs.

520
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Sample No.
−350−300−250−200−150−100 −50
0
50 100 150
0
0.005
0.01
0.015
Decision
probability mass functions
Probability of false alarm
10−4
10−3
10−2
10−1
100
0
0.2
0.4
0.6
0.8
1
Probability of detection
ROC curve 
Optimum operating point:
(Pfa, Pdet) = (0.034, 0.998)
Ho
H1
(a)
(b)
(c)
(d)
Probability
Depth sample no.
0
20
40
60
80
100
120
−250
−200
−150
−100
−50
0
50
Depth Sample No.
0
20
40
60
80
100
120
−10
0
10
20
30
40
50
60
70
80
Log-likelihood decision function: H1
Thresholds:
(in Tau0,in Tau1) = (–6.12, 3.38)
Log-likelihood decision function: Ho
Thresholds:
(in Tau0,in Tau1) = (−6.12, 3.38)
Log-likelihood
Log-likelihood
FIGURE 11.20
Sequential detection application: (a) log-likelihood PMF distributions;
(b) ROC curve; (c) log-likelihood decision function under hypothesis 1: source detec-
tion; (d) log-likelihood decision function under hypothesis 0: noise.
11.2.10
Summary
In this study, we developed a sequential Bayesian solution to the broadband modal
function tracking and pressure-ield enhancement problem using a particle ilter then
coupled it to a sequential source detection scheme. We demonstrated the application
of the Kullback–Leibler divergence statistic as a reliable metric to evaluate the particle
ilter performance for this nonstationary problem. Next, we developed a sequential
detector that was capable of detecting the broadband source in noisy pressure-ield
measurements and evaluated its performance from the associated ROC curve. We
showed the results of the design demonstrating the capability of such an approach.
11.3
BAYESIAN PROCESSING FOR BIOTHREATS
The design of a “smart” physics-based processor for microcantilever sensor arrays to
detect various target species in solution based on the delections of a functionalized
array is discussed. A proof-of-concept design is demonstrated and shown to perform
quite well on experimental data.

11.3
BAYESIAN PROCESSING FOR BIOTHREATS
521
11.3.1
Background
Smart sensors with embedded processors offer unique advantages for applications
that must gather large amounts of data and continuously monitor evolving conditions
for potential changes (e.g., machine condition monitoring) or potential threats (e.g.,
biological, chemical, nuclear). Unfortunately, the usual processing techniques such
as nonparametric methods like wavelets or parametric methods like autoregressive-
moving average (ARMA) models do not capture the true essence of the problem
physics required to extract the desired information, detect the change, or monitor
the environment for threats. The underlying physical phenomenology governing the
propagation physics is usually quite complex governed by nonlinearities typically
characterized by nonlinear differential/difference equations. Coupling the resulting
nonlinear processor to the sensor performing the measurement has not been consid-
ered a realistic possibility until now with the evolution of high-speed microcomputer
chips that can easily be incorporated into the sensor design. We consider the design
of an algorithm coupled to a microelectromechanical sensor (MEMS) to estimate the
presence of critical materials or chemicals in solution.
Microcantilevers are powerful transducers for sensing inorganic, organic, and
biological molecules, since they readily bend or delect in the presence of a very
small number of target molecules (nanomolar to femtomolar concentrations) [39]
as shown in Fig. 11.21. The number of potential target chemicals is large, ranging
from DNA [40] to explosives [41], implying that these sensors may be useful in
defense, medicine, drug discovery, and environmental monitoring. Microcantilevers
are capable of recognizing antibodies [42] and nerve agent products (hydroluoric
acid) in solution [43]. However, a major limitation of these sensors is that their
500 μm
+σ
−σ
Γ
ΔZ
l
(a)
(b)
FIGURE 11.21
Micromachined cantilever array: (a) eight (8)-element lever array; (b)
lever delection.

522
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
signal-to-noise ratio (SNR) is low in many operational environments of interest.
Therefore, we discuss the design of a “smart sensor” design combining the array
with a physics-based processor to minimize its inherent limitations and maximize the
output SNR for enhancement.
We investigate the physics-based Bayesian approach [38] to develop a multi-
channel processor evolving into a smart sensor for this application. This approach
is essentially incorporating mathematical models of both physical phenomenology
(chemistry/low dynamics) and the measurement process (cantilever array including
noise) into the processor to extract the desired information. In this way, the resulting
Bayesian processor (BSP) enables the interpretation of results directly in terms of the
problem physics.
We discuss the design of physics-based signal processing to micromachined can-
tilever measurement arrays to estimate the critical materials in solution. We briely
present the underlying physical phenomenology and reduce it to a simple model for
processor development. Unknown parameters in this model are “it” from indepen-
dent experimental data. Once these parameters are estimated, we use minimum error
variance techniques for the BSP design [38]. We then apply the resulting processor
to experimental data, demonstrating the overall enhancement that would lead to an
eventual “smart sensor” design. The resulting processor is based on nonlinear evolu-
tion equations leading to an extended Bayesian processor or classically, the extended
Kalman ilter, (EKF) that can be implemented in an on-line manner yielding the
enhanced data as its output.
11.3.1.1
Microcantilever Sensors
The dynamics of the luids lowing over
the cantilever array of Fig. 11.21 is inluenced by two major factors: temperature and
low. The temperature is dependent on many variables and the dynamics are relatively
slow, creating a disturbance to the cantilever sensor system. Flow in the medium
associated with the array induces a stress along with the chemical forces created
by the molecules bonding with the functionalized levers leading to the measured
delection.
Micromachined cantilevers can function as detection devices when one side is
fabricated to be chemically distinct from the other, as shown in Fig. 11.21b. Func-
tionalization can be accomplished, for example, by evaporating a thin (10’s of nm)
ilm of metal such as gold on the top of the chip, then immersing the cantilever chip in
a “probe” chemical that will bind preferentially to the thin gold ilm. The lever acts as
a sensor when it is exposed to a second “target” chemical that reacts with the probe,
since the reaction causes a free energy change that induces stress at the cantilever
surface. Differential surface stress, △�, in turn, induces a delection of the cantilever
that can be measured optically or electronically. In this section, we describe results
of experiments with gold-coated cantilevers exposed to 2-mercaptoethanol, a small
sulfur-terminated molecule with high afinity for gold.
When the microcantilever is immersed in a luid and it has been functionalized
to attract the target molecules, the changes in surface stress can be predicted as a
function of surface loading. The evolution dynamics of this chemical interaction is
captured by the well-known Langmuir kinetics in terms of a set of ordinary nonlinear

11.3
BAYESIAN PROCESSING FOR BIOTHREATS
523
differential equations. Rather than propagate these equations directly, we choose
to use their solution in our processor that accounts for the adsorption–desorption
kinetics. We developed an approximation to the Langmuir evolution equations based
on a stirred tank reactor to estimate the target concentration as a function of time
under continuous low conditions. Experimentally, the applied chemical input signal
is a constant concentration initiated by a step (function) increase at time tON and
terminated at time tOFF [44, 45].
Based on this representation of the process evolution physics, the dynamic (nor-
malized) surface concentration of the interacting molecules on the surface of the
cantilever, Γ(t) =
̃Γ(t)
ΓMAX , is given by the relations
Γ(t) =
⎧
⎪
⎨
⎪⎩
0
t < tON
(
c(t)
c(t)+ka∕kd
)
{1 −exp[−(kac(t) + kd)(t −tON)]}
tON ≤t ≤tOFF
√
1
2kd(t−tOFF)
t > tOFF
(11.44)
where ka, kd and c(t) are the respective adsorption rate constant [M]−1s−1, desorp-
tion rate constant (cm−2M−1s−1), and bulk concentration of the target molecules in
solution (moles/liter) with ̃ΓMAX, the maximum surface concentration of the species
of interest (cm−2M−1).
The total free energy change of the cantilever surface, △G, is related to the surface
stress difference △�, between top and bottom side of the cantilever by:
△�(t) = △G(t)Γ(t)∕MA
(11.45)
where △G has the unit J/mole and is the change in the sum of all of the contributions
to the free energy of the surface of the cantilever with MA as Avogadro’s number
(constant). The differential surface stress in the cantilever induces a chemically
induced delection ΔzC (t), using a variant of Stoney’s equation [44] which implies
that the delection of the cantilever is directly proportional to the difference in surface
stress (signal) on the cantilever surface relating this stress difference to the surface
coverage and free energy of absorption, that is,
ΔzC (t) = �Δ�(t)
for
�= 3�2 (1 −�)
E�2
(11.46)
where E is the Young’s modulus, �is the Poisson’s ratio, and �and �are the cantilever
length and thickness, respectively. This model can be used to predict changes in
surface stress as a function of surface loading.
The measurement model is more complicated, since it is the superposition of both
the chemical and temperature delection phenomena
y�(t) = ΔzC
�(t) + ΔzT(t)
for
�= 1, … , L
(11.47)

524
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
where ΔzC
�is the chemical delection, different for different cantilevers, and ΔzT(t)
is the thermal delection, assumed to be the same for all cantilevers. Since we have
approximated the physics developing the well-founded formulation of Eq. 11.44,
we know that there is uncertainty in both the measurements (noise) and the model
parameters. Therefore, we cast the problem into a Gauss–Markov (GM) state–space
framework [38] representing these uncertainties as additive Gaussian processes,
that is,
ΔG(t) = ΔG(t −1) + �(t −1)
[State]
y�(t) = ��Γ(t; Θ)ΔG(t) + ΔzT(t) + ��(t)
[Measurements]
(11.48)
where �= 1, … , L; Γ(t; Θ) is given by Eq. 11.44 with unknown model parameters
deined by the vector, Θ = [kakd ̃ΓMAX] and free energy (state) modeled as a ran-
dom walk (△̇G(t) = 0). This representation, therefore, creates the foundation for our
physics-based processor design. The process uncertainty is modeled by �and the
corresponding measurement uncertainty as �, both zero-mean Gaussian with respec-
tive covariances R��and R��. With this representation in mind, the cantilever signal
enhancement problem is deined as:
GIVEN a set of noisy delection measurements {y�(t)} with known bulk con-
centration inputs {c(t)} and unknown parameters Θ, FIND the best (minimum error
variance) estimate of the delection ̂y(t|t −1), that is, the conditional mean at t based
on the data up to time t −1.
The design of the processor for this problem is illustrated in Fig. 11.22. After the
cantilever physics model is developed, it is used (1) to extract the required parameters
using a physics-based parameter estimator; (2) to synthesize “data” for the initial
processor designs; and (3) to enhance the noisy measurements being incorporated
into the inal BSP structure. In the igure, we see that the complex mathematical
model of Eq. 11.44 (dashed box) is used to perform the physics-based parameter
estimation using independent experimental data to extract the required parameters
(adsorption/desorption rate constants and maximum concentration) as well as initially
simulate data for BP design studies, once these parameters are extracted. The actual
experimental data replace the synthesized and are used to validate the processor
performance.
11.3.2
Parameter Estimation
The basic approach is to irst estimate the model parameters Θ (off-line) from an
independent set of delection measurements, and then, incorporate them into the BSP
to enhance the experimental (proof-of-concept) data. That is, we extract the critical
absorption, desorption rate constants and maximum concentration parameters for
each channel as: Θ�= [ka(�)kd(�)̃ΓMAX(�)]. The parameter estimator employed was

11.3
BAYESIAN PROCESSING FOR BIOTHREATS
525
Bayesian 
parameter 
estimator
Data
Model
Model
Parameters
Bayesian 
processor
Cantilever 
physics model
Data (SNR)
Data
Parameters
Enhanced deflection signal
Parameter fit
Raw data 
Enhancement
ka, kd, ΓMAX
∼
FIGURE 11.22
Physics-based approach to microcantilever “smart sensor” design:
physics evolution model, parameter estimation (off-line), Bayesian processor and data
enhancement.
a nonlinear least-squares solution using the Nelder–Meade polytope search algorithm
[46]. This algorithm is based on minimizing
min
Θ�
J(Θ) =
Nt
∑
t=1
�2
�(t; Θ)
for
�(t; Θ) := y�(t) −̂y�(t; Θ)
(11.49)
where the estimated cantilever measurement at the �th-lever is given by
̂y�(t; ̂Θ) = Δ̂zC
�(t; ̂Θ) + Δ̂zT(t) = ��Γ(t; ̂Θ)ΔG(t) + Δ̂zT(t)
(11.50)
We executed this estimator on raw experimental delection data and estimated the
parameters for each lever. The extracted parameters reasonably predicted the iltered
cantilever response and the resulting error was uncorrelated as discussed below.
11.3.3
Bayesian Processor Design
Next, using these estimated parameters, we developed BSP for the multichannel
delection data. The GM model was used to synthesize the multichannel data and
provide known truth data to “tune” or adjust the processor noise covariance matri-
ces that provide the “knobs” for BSP design (see Fig. 11.11 and Ref. [38] for
details). Since the simulation model and that used in the processor are identical,
optimal (minimum error variance) performance is achieved (zero-mean, uncorrelated
errors) providing the starting point for application to the experimental data. The inal
(simpliied) BSPalgorithm (assumingtheparameters ̂Θ have been estimated) is shown

526
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
TABLE 11.2
Bayesian Microcantilever Array Processor (BSP)
Δ ̂G(t|t −1) = Δ ̂G(t −1|t −1)
[Free energy prediction]
̂y�(t|t −1) = ��Γ(t; ̂Θ)Δ ̂G(t|t −1) + Δ̂zT(t)
[Delection prediction]
��(t) = y�(t) −̂y�(t|t −1)
[Innovation or residual]
Δ ̂G(t|t) = Δ ̂G(t|t −1) + k′(t)�(t)
[Free energy correction]
where k is the corresponding weight or gain and ̂Θ is the output estimate from
the parameter estimator.
in Table 11.2. Here, we see that the algorithm has a classical predictor-corrector form
where the prediction estimates (conditional mean) the free energy, ilters the measure-
ment, estimates the innovation, and corrects the inal (iltered) free energy estimate.
11.3.4
Results
First, we took the iltered measurement signals, averaged them to a single measure-
ment, itted the parameters using an off-line optimization technique [46], and used
the parameters in the Bayesian processor. The results are shown in Fig. 11.23 where
400
800
1200
−200
0
0
400
800
1200
Deflection (nm)
Deflection (nm)
Deflection (nm)
Ka      =   0.38300
Kd      =   0.00039 
Gmax =  1.07100e+015
−500
0
500
1000
1500
0
2000
4000
6000
8000
10000
−1
0
1
2
3
Time (sec)
8000
6000
4000
2000
0
Parameter estimation
Bayesian enhancement
Raw temperature data
Raw deflection data
10000
Time (sec)
(a)
(c)
(b)
(d)
10000
8000
6000
4000
2000
0
Time (sec)
0
2000
8000
6000
4000
10000
Time (sec)
Temperature (o)
Bayesian
estimate 
Parameter estimates:
Innovation
Raw
cantilever
data 
Raw
cantilever
data 
Bayesian
estimate 
FIGURE 11.23
Bayesian processing for the “average” microcantilever sensor array sig-
nal: (a) raw delection data; (b) raw temperature data; (c) parameter estimation; (d)
Bayesian estimation (enhancement).

11.3
BAYESIAN PROCESSING FOR BIOTHREATS
527
0
500
1000
Deflection (nm)
Deflection (nm)
Deflection (nm)
0
2000
4000
6000
8000
10000
6000
4000
2000
0
8000
10000
6000
4000
2000
0
8000
10000
6000
4000
2000
0
8000
10000
6000
4000
2000
0
8000
10000
6000
4000
2000
0
8000
10000
0
500
1000
Time (sec)
0
500
1000
0
500
1000
Deflection (nm)
Deflection (nm)
Deflection (nm)
0
500
1000
0
500
1000
Time (sec)
Time (sec)
Time (sec)
Time (sec)
Time (sec)
Data
Data
Data
Data
Data
Data
Innovation
Innovation
Innovation
Innovation
Innovation
Innovation
BP
BP
BP
BP
BP
BP
Cantilever no. 6 
Cantilever no. 4
Cantilever no. 3
Cantilever no. 2
Cantilever no. 1
Cantilever no. 5 
FIGURE
11.24
Bayesian
processing
of
microcantilever
experimental
(proof-of-
concept) data: raw data, enhanced (BP) delection measurement and residual results
for each lever.
we see the raw delection and temperature measurements in 11.23a and 11.23b. The
parameter estimator results are shown in Fig. 11.23c along with the state (signal)
estimator in 11.23d. The parametric it is quite reasonable as is the signal enhance-
ment. However, it is clear from the innovations that the optimal processor is clearly
not Gaussian, since it is not zero-mean or white. Next, we used the BP with the free
energy as our piecewise constant parameter (state) and the nonlinear cantilever array
model with 6 elements along with a iltered estimate of the temperature proile in the
processor △̂zT(t). By tuning the measurement noise covariance parameters (R��), we
demonstrate that the BP is capable of tracking the noisy cantilever delection data
reasonably well; however, the performance is again suboptimal, since the innovations
(shown in each igure), although quite small, are not uncorrelated. The results are
shown in Fig. 11.24 where we see the raw measured cantilever data, Bayesian pro-
cessor estimates and the corresponding residual errors or innovations. The results are
quite reasonable except for the systematic bias error in the processor output at each
lever. The bias is created by out lack of knowledge of the initial concentration input
and can easily be compensated (gain) at each lever as well. The dynamics appear to
be captured by the model especially in cantilever 5. From the igure, we note that the
dynamics of the individual levers (on-set and off-sets) are quite close to the expected.
This design demonstrates that even complex physical systems can be incorporated
into physics-based processors enabling the development of a “smart” sensor.

528
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
11.4
BAYESIAN PROCESSING FOR THE DETECTION OF
RADIOACTIVE SOURCES
With the increase in terrorist activities throughout the world, the need to develop
techniques capable of detecting radioactive sources in a timely manner is a critical
requirement. The development of Bayesian processors for the detection of contraband
stems from the fact that the posterior distribution is clearly multi-modal eliminating
the usual Gaussian-based processors. Here, we represent a radionuclide as a unique
superposition (union) of monoenergetic sources that are transported through the
path for measurement and counting as illustrated in Fig. 11.25. The measured data
consists of a low-count, impulsive-like, time series measurement (energy vs. time) in
the form of an event mode sequence (EMS) obtained from the electronics. We use this
representation to formulate and solve the radionuclide contraband detection problem
[47–51]. That is, detection is used to decide whether or not a target (threat) is present.
Radionuclide source detection is a critical technology to detect the transportation
of illicit radiological materials by potential terrorists. Detection of these materials
is particularly dificult due to the inherent low-count emissions produced. These
emissions result when sources are shielded to disguise their existence or, when being
transported, are in relative motion with respect to the sensors. Some work has been
accomplished on this problem [52–55]. Here, we model the source radionuclides by
decomposing them uniquely as a superposition (union) of monoenergetic sources.
Each �-ray emitted is then smeared and distorted as it is transported on a path to
the output of the detector for measurement and counting. We start with the “physics-
based” approach to solving this suite of problems and then discuss the measurement
system employed to detect �-rays and show how the mononenergetic approach leads
to a compound Poisson-driven Markov process [47] which is ampliied, shaped
and digitized for further processing. The processor is developed using state–space
representations of the transition probability and associated likelihood and we apply
it to synthesized data to evaluate its performance.
11.4.1
Physics-Based Processing Model
Gamma-ray interactions are subject to the usual physical interaction constraints
of scattering and attenuation as well as uncertainties intrinsic to the detection
Noisy
EMS 
Source
Scattering
medium
(shield)
Detector
material 
Detector
Detector
response 
Quantizer
(ADC)
FIGURE 11.25
Gamma-ray evolution and measurement: radionuclide source (EMS),
medium transport (physics), detector material interaction, detector temporal response
(preampliication/pulse shaping) and A/D conversion with quantization noise.

11.4
BAYESIAN PROCESSING FOR THE DETECTION OF RADIOACTIVE SOURCES
529
process. Energy detectors are designed to estimate the �-ray energy from the mea-
sured electron current. A typical detector is plagued with a variety of extraneous
measurement uncertainty that creates inaccuracy and spreading of the measured cur-
rent impulse (and therefore �-ray energy). The evolution of a �-ray as it is transported
through the medium and interacts with materials, shield, and the detector is shown in
Fig. 11.25.
The unique characterization of a radionuclide based on its electromagnetic emis-
sions has been an intense area of research and development for a long period of time
[48–51]. It is well known that a particular radionuclide can be uniquely character-
ized by the energies and relative intensities of the emitted �-rays. Mathematically, we
deine the pair [{�m}, {�m}] as the respective energy (MeV) and photon detection rate
of the mth �-ray line of the radionuclide. In the absence of shielding, the detection rate
�m is the product of the absolute decay rate per unit mass �, the mass , the absolute
intensity per decay �m, a geometric factor S (typically the solid angle subtended by
the detector), and a detector eficiency �m at energy �m, that is, �m = �m��mS.
The basic construct of a �-ray detector starts with the material selected. We con-
centrate on semiconductor materials, primarily HPGe, since it provides outstanding
performance enabling us to establish an upper bound for our experimental results.
The detector typically outputs a list of events, each consisting of an event time and an
amplitude (pulse height or energy). After a set time, a histogram of number of events
versus pulse height (pulse height spectrum or PHS) is calculated. In the absence of
shielding, a particular radionuclide is revealed by the presence of peaks in the PHS
at the expected energies (�-ray lines) for that nuclide. The areas of the peaks are
proportional to the intensities (detection rates). The widths of the peaks are deined
by the detector resolution and eficiency.
For sequential detection, we process each event in the event mode sequence
individually using a model with parameters that are analogous to the features in a
PHS. Since a radionuclide emits �-rays at speciic energies and rates, the sequence
of emitted photons can be characterized by sets of measured energies and arrival
times at the detector: [{�m
} , {�m
}] , m = 1, … , M�. The index m represents the
mth �-ray line (energy) for a radionuclide with M�lines. It is convenient to think
of each line as a separate source. Then the emission from a given radionuclide is
represented as a superposition of individual �-ray sources. We will refer to this as the
monoenergetic decomposition of the EMS for the radionuclide. Fig. 11.26 shows a
graphical depiction of the monoenergetic decomposition of an EMS with three �-ray
lines.
To be more precise, deine �(n; �m(n), �m(n)), a component of an EMS, as the nth
measured photon arrival from the mth monoenergetic source of energy �m, at arrival
time �m(n) with associated detection rate �m. Though the source energy may be �m,
the inite resolution of the detector introduces a random component to the measured
energy. Thus, the energy of the nth arrival is more accurately represented as a random
variable �m(n). The resulting impulse representation for a single photon arrival is
�(n; �m, �m) = �m(n)�(t −�m(n)). By photon arrival, we refer only to the arrival of
photons that are measured by the detector and contribute to the EMS. Thus terms like
arrival time, interarrival time, and arrival rate refer to photons that contribute to the
EMS output of the detector.

530
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Source 1
Source 2
Source 3
Time
Energy
Event mode sequence
FIGURE 11.26
Monoenergetic source decomposition: individual source constituent
EMS from ideal composite (superposition).
In order to deine the entire emission sequence over a speciied time inter-
val, [to, T), we introduce the set notation ̃�m := {�m(1) ⋯�m(N�(m))} and ̃�m :=
{�m(1) ⋯�m(N�(m))} with N�(m) the total number of counts for the mth source
in the interval. Therefore, �(n; ̃�m, ̃�m) represents an impulse train of random energies
and arrivals up to the nth arrival (see Fig. 11.26).
The interarrival time is deined by △�m(n) = �m(n) −�m(n −1) for △�m(0) = to
with the corresponding set deinition (above) of △̃�m(n). Using this deinition (and
with a slight abuse of notation), we can write the photon arrival as �(n; �m, �m) ⇒
�(n; �m, △�m) = �m(n)�(t −�m(n)), where it is understood that �m(n) = �m(n −1) +
△�m(n). We can then rewrite the EMS in terms of interarrivals just as easily as arrival
times, that is, the monoenergetic source representation of a radionuclide characterized
by its unique set of energy/interarrival pairs {�m, △�m
} is given by
�(N�(m); ̃�m, △̃�m)
N�(m)
∑
n=1
�m(n)�(t −�m(n)) at detection rate �m(n)
(11.51)
for to known.
Suppose we have a radionuclide source whose EMS is decomposed into its M�
monoenergetic source components �(n; ̃�m, △̃�m). The full EMS is given by the union
of the components: ∪M�
m=1�(n; ̃�m, △̃�m) ⇔∑M�
m=1 �(n; ̃�m, △̃�m) where the last equiv-
alence results from the pragmatic assumption that it is highly improbable that any
two arrivals will overlap. Thus, it follows that a radionuclide (RN) can be represented
in terms of its monoenergetic decomposition, that is, the EMS monoenergetic source
representation is:
(N; �, △�) =
M�
∑
m=1
N�(m)
∑
n=1
�m(n)�(t −�m(n))
(11.52)

11.4
BAYESIAN PROCESSING FOR THE DETECTION OF RADIOACTIVE SOURCES
531
for �:= {̃�1, … , ̃�M�}, the complete set of energies composing along with △�:=
{△̃�1, … , △̃�M�}, the corresponding set of interarrival times. The arrival index N is
the least upper bound of the set of N�(m).
The emission of photons follows a well-deined probability structure, that is, since
only one photon is emitted for each event there is a ixed probability (absolute intensity
�m) that the photon is emitted with energy �m out of M�possibilities. The probabilities
for a given radionuclide are speciied in its energy decay scheme [49]. Therefore, we
model this decay structure by incorporating an indicator function deined by Refs.
[34] and [56]: j(m) = 1m = j where j(m) is a random variable such that Pr(j(m) =
1|(n; �, △�)) = Pr(j(m) = 1|Ξn) = �j for �j the corresponding absolute intensity
(emission probability) of the jth monoenergetic radionuclide component and Ξn :=
{�(1), … , �(n)}, the set of n-EMS arrival measurements. Using the indicator function,
we can write the jth monoenergetic component of the EMS as
j(N; �, △�) =
M�
∑
m=1
N�(m)
∑
n=1
j(m)�m(n)�(t −�m(n))
(11.53)
where we model the energy variations as Gaussian, �m ∼(�m, �2
�m) the interar-
rivals as exponential, △�m ∼(�m�△�m△�m(n)) [49] with the emission probability
as �m.
Thus, this unique physics-based representation provides the basic signal model
for subsequent processing.
11.4.2
Radionuclide Detection
Since all of the measurement data and required parameters evolve from the EMS,
we are in search of a technique that enables us to “decide” when a particular tar-
get radionuclide is present or not. After the single photon is pre-processed by the
acquisition system, the energy and arrival time measurements are passed onto the
energy/rate discriminators to “decide” on the photon’s status (accept or reject). If
acceptable, the parameter estimates are sequentially updated and provided as input to
the decision function for detection (identiication). Thus, the decomposition implies
that each unique energy/interarrival component of the target radionuclide be pro-
cessed individually in a separate channel.
In order to develop a sequential processor [33,57], we must test the binary hypoth-
esis that the measured EMS has evolved from the targeted RN of Eq. 11.53. Therefore,
we specify the hypothesis test,
0 : �(n; �, △�) = (n; �, △�) + �(n)
[Nontarget]
1 : �(n; �, △�) = (n; �t, △�t) + �(n)
[Target]
(11.54)
where (n; �, △�) is the EMS model, �(n; �, △�) is the random composite EMS
contaminated with zero-mean, Gaussian measurement (instrumentation) noise,

532
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
�∼(0, �2
�) and the superscript notation “t” represents the true or target value
obtained from the Tables.
The optimal solution to this binary decision problem is based on applying the
Neyman–Pearson theorem leading to the likelihood ratio [33,57] (see Section 10.3).
Since the distributions under investigation are members of the exponential family
[34], taking logarithms simpliies the computations. The sequential log-likelihood
ratio is
Λ[Ξn] = Λ[Ξn−1] + ln Pr(�(n; �, △�)|Ξn−1, 1)
−ln Pr(�(n; �, △�)|Ξn−1, 0)
(11.55)
and therefore, the Wald sequential probability-ratio test becomes [33]
Λ[Ξn]
> ln 1(n)
Accept
1
ln 0(n)
≤Λ[Ξn]
≤ln 1(n)
Continue
Λ[Ξn]
< ln 0(n)
Accept
0
(11.56)
where the thresholds are speciied in terms of the false alarm (PFA) and miss (PMiss)
probabilities as
0(n) = PMiss(n)
PFA(n)
1(n) = 1 −PMiss(n)
PFA(n)
The thresholds are determined from a receiver operating characteristic (ROC)
curve (detection versus false alarm probabilities) for each radionuclide decision func-
tion. An operating point is selected from the ROC corresponding to speciic detection
and false-alarm probabilities and therefore specifying the required thresholds which
are calculated according to Eq. 11.56 for each radionuclide. So we see that at each
photon arrival (at n), we sequentially update the likelihood and thresholds to perform
the detection—“photon-by-photon”.
To implement the sequential detection approach, the required distributions of Eq.
11.55 must be speciied in order to calculate the decision function; therefore, we
have
Pr(�(n; �, △�)|Ξn−1, �) =
Pr((n; �, △�)|Ξn−1, �) + Pr(�(n)|Ξn−1, �)
(11.57)
for the hypotheses speciied by �; �= 0, 1 (see Eq. 11.54).
We start by estimating the RN posterior distribution (or its equivalent) from the
model parameters and uncertain data, that is,
Pr ((n; �, △�)|Ξn−1, �
) ⇔Pr (�, △�, j(m)|Ξn−1, �
)

11.4
BAYESIAN PROCESSING FOR THE DETECTION OF RADIOACTIVE SOURCES
533
Using the monoenergetic radionuclide model, we have
Pr(�(n; �, △�)|Ξn−1, �) =
Pr(�(n), △�(n), j(m)|Ξn−1, �) + Pr(�(n)|Ξn−1, �)
(11.59)
where the argument n in the sets �(n) and △�(n) specify all energies and interarrival
times up to the nth event. Applying Bayes’ rule, we obtain the decomposition
Pr(�(n; �, △�)|Ξn−1, �) =
Pr(△�(n)|�(n), j(m), Ξn−1, �) × Pr(�(n)|j(m), Ξn−1, �)
× Pr(j(m)|Ξn−1, �) + Pr(�(n)|Ξn−1, �)
(11.60)
Decomposing the parameter vectors using the fact that each arrival has “no memory”
and applying the chain rule of probability, we obtain the desired posterior distribution
for detection
Pr(�(n; �, △�)|Ξn−1, �) =
M�
∏
m=1
Pr(△̃�m(n)|̃�m(n), j(m), Ξn−1, �) ×
Pr(̃�m(n)|j(m), Ξn−1, �) × Pr(j(m)|Ξn−1, �) + Pr(�(n)|Ξn−1, �); �= 0, 1
(11.61)
Let us deine the notation
Θm(n; �) := Pr(△̃�m(n)|̃�m(n), m(k), Ξn−1, �) ×
Pr(̃�m(n)|m(k), Ξn−1, �) × Pr(m(k)|Ξn−1, �)
(11.62)
for �representing the vector of unknown parameters (energy, interarrival time, emis-
sion probability). Now substituting this expression into Eq. 11.55 and ignoring the
instrumentation noise, the sequential log-likelihood ratio decision function is given
by
Λ[Ξn] = Λ[Ξn−1] +
M�
∑
m=1
ln Θm(n; �t) −
M�
∑
m=1
ln Θm(n; �)
(11.63)
giving us the general form for the sequential solution. Note that this decision function
incorporates not only the energy and interarrival times for each constituent monoen-
ergetic source composing the target radionuclide but also the probability of emission
which acts as a weighting function in the overall superposition enabling all of the
energies to be combined in making the decision.
Next, we develop the statistical models to implement the decision function. Each
individual target RN is uniquely speciied by its parameter set, {�t, △�t, �t} known
from the Tables. Using the energy distribution and its decomposition of Eq. 11.60,

534
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
the jth-monoenergetic source component selected by the indicator function j(m) is
therefore
Pr(̃�j(n), j(m)|Ξn−1, �) = �jPr(̃�j(n)|Ξn−1, �)
(11.64)
where we have applied Pr(j(m) = 1|Ξn−1) = �j.
Each energy component is assumed Gaussian with corresponding distribution
Pr(�m(n)|j(m), Ξn−1, �) ∼(�j(n), �2
�j) =
1
√
2���j
exp
{
−
(�j(n) −�j(n))2
2�2
�j
}
(11.65)
This models the effect of inite detector resolution and other experimental uncertain-
ties in measuring the energy. The interarrival times △�are exponentially distributed
such that
Pr(△�(n) | �(n), j(m), Ξn−1, �) =
M�
∏
m=1
Pr(△�m(n)|�m(n), j(m), Ξn−1, �) =
M�
∏
m=1
�m�△�m exp{−�m�△�m△�m(n)}
(11.66)
with �m the emission probability and detection rate �△�m = 1∕△�m, that is, the
reciprocal of the mean interarrival time.
For the jth monoenergetic source component, we have
Pr(△�(n) | �(n), j(m), Ξn−1, �) ∼(�j�△�j△�j(n)) =
�j�△�j exp{−�j�△�j△�j(n)}
(11.67)
Both the energy �j(n) and interarrival time △�j(n) data are obtained from the detector
arrival measurement.
Thus, for the radiation detection problem, we have under hypothesis 0
Θm(n; �) =
�2
m�△�m
√
2���m
× exp
{
−�m�△�m△�m(n) −(�m(n) −�m(n))2
2�2
�m(n)
}
(11.68)
and under hypothesis 1
Θm(n; �t) =
(�t
m)2�t
△�m
√
2���tm
× exp
⎧
⎪
⎨
⎪⎩
−�t
m�t
△�m
△�m(n) −
(�m(n) −�t
m)2
2�2
�tm
⎫
⎪
⎬
⎪⎭
(11.69)

11.4
BAYESIAN PROCESSING FOR THE DETECTION OF RADIOACTIVE SOURCES
535
Substituting these expressions into Eq. 11.63 leads to the sequential log-likelihood
ratio decision function
Λ[Ξn] = Λ[Ξn−1] +
M�
∑
m=1
[
ln
((�t
m)2�t
△�m
√
2���tm
)
−ln
(�2
m�△�m
√
2���m
)
+
(
�m�△�m −�t
m�t
△�m
)
△�m(n) + 1
2
(�m(n) −�m(n)
��m
)2
−1
2
(�m(n) −�t
m(n)
��tm
)2]
(11.70)
This completes the structure of the sequential Bayesian radiation detector; we discuss
the actual photon-by-photon implementation of this processor next.
11.4.3
Implementation
In the previous section, we developed the radionuclide detection approach leading
to the sequential decision function. However, in order to implement the scheme, we
must estimate the required parameters to reach the optimal decision. In this section,
we discuss a more pragmatic approach to estimate the parameters and check their
validity. The implementation of the algorithm is based on one major physics-based
consideration: sequential or photon-by-photon processing leading to an individual
processor (channel) for each monoenergetic source �-ray.
There are three phases to the implementation after acquiring the individual photon
energy and arrival time measurement: (1) discrimination; (2) estimation; and (3)
detection as shown in Fig. 11.27a. The discrimination phase consists of determining
the appropriate monoenergetic channel based on irst testing (conidence interval)
for the correct energy and second testing for a consistent interarrival time. Once
this is accomplished, the estimation phase follows. Here, the parameters required to
calculate the decision function must be estimated. Finally, in the detection phase with
the decision function updated, sequential threshold testing proceeds where all of the
individual arrival information is combined and the log-likelihood decision function
updated at each arrival to detect (and identify) the targeted radionuclide.
The pragmatic implementation is accomplished in various stages: (1) photon
discrimination; (2) monoenergetic parameter estimation; (3) decision function cal-
culation and (4) threshold comparison as illustrated in Fig. 11.27b. Discrimination
is performed with the “true” parameters obtained from the tables of radionuclides
(energy, emission probability, and interarrival(rate)). From this information, we con-
struct the conidence intervals to decide if the photon arrival is valid for one of the
targeted radionuclide components. If so, we then move to the next step and perform
the parameter estimation using a linear Kalman ilter for energy (Gaussian model)
and particle ilter for interarrival (exponential). The emission probability is calculated
by sequentially updating valid counts in the channel. With the parameter estimates
available we then calculate the decision function. Finally, in order to calculate the
required thresholds for the detector, we must generate an ROC curve from simulation

536
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
(b)
Photon
Energy/rate
discrimination
Parameter
estimation
Decision
function
OK?
RN?
Alarm
Detection
Initialize
n → n + 1
ˆ
ˆ
ˆ
[
]
ˆ
ˆ
ˆ
( | ), 
( | ), (n)
n n
n n
ε
τ
α
Δ
ˆ
n
Λ Ξ
⎡
⎤
⎣
⎦
ˆ
  
  ( )
n
n
>
Λ Ξ
= Τ
⎡
⎤
⎣
⎦
<
No
No
Yes
Yes
Reject
Photon
Discrimination
Estimation
Detection
Ok?
RN?
Alarm
(a)
Yes
[ε(n | n), Δτ(n | n), α(n)]
FIGURE 11.27
Implementation of radionuclide detection showing discrimination, esti-
mation, and detection phases: (a) simpliied low of basic algorithm; (b) detailed low
diagram.
or high-idelity data and pick an operating point speciied by the desired detection
and false alarm probabilities.
11.4.3.1
Discrimination
Based on the parallel/distributed architecture of the
detector/identiier, we irst apply an energy discriminator to “decide” which channel
the photon should be processed followed by a detection rate discriminator using
the interarrival for veriication. The discriminators use implied hypothesis testing by
constructing conidence intervals about the means of the respective parameters [34].
The energy discriminator performs the following conidence interval test to accept or
reject the photon in a channel:
[�t −����≤�m(n) ≤�t + ����]
(11.71)
where �t is the true (channel) energy associated with the targeted radionuclide, ��is
the respective conidence coeficient with associated conidence level �, and ��is the
standard deviation associated with the precision of the measurement.

11.4
BAYESIAN PROCESSING FOR THE DETECTION OF RADIOACTIVE SOURCES
537
The interarrival measurement is tested similarly by the following conidence inter-
val discriminator. For large n, the estimate of the mean interarrival time is approxi-
mately Gaussian, △̂�∼(△�t, △�t∕
√
n).
[△�t −�̃��△�≤△̂�m(n) ≤△�t + �̃��△�]
(11.72)
where △�t is the true (channel) interarrival time associated with the targeted radionu-
clide, �̃�is the respective conidence coeficient with associated conidence level ̃�,
and �△�is the standard deviation of the variance of the estimated mean interarrival
time △̂�m. Events with interarrival times that cause the estimated mean to deviate
outside the conidence bounds are rejected.
Since the mean interarrival time is not necessarily the actual source interarrival,
but may include scattered or background photon interarrivals, we use an estimated
PHS obtained during the calibration phase to approximate the percentage (�o) of
downscattered photons to estimate △�t [49]. �o is based on the ratio of a ixed
number of higher energy bin counts to the target energy bin count. Because of its
Poisson nature, we average the interarrivals associated with the mth bin taking its
reciprocal to obtain the composite (total) rate ��m. Finally, we estimate the true
detection rate as
�t
m = (1 −�o)��m,
△�t = 1
�t
m
(11.73)
11.4.3.2
Estimation
In order to implement this radionuclide detection scheme,
we must estimate the underlying parameters (energy, interarrival time, emission
probability) distributions to enable the calculation of the decision function. We deine
an overall parameter vector by
�:= [�
|
�
|
�] =
[�1 ⋯�M�
|
△�1 ⋯△�M�
|
�1 ⋯�M�]
for �∈3M�×1 requiring 3M�parameters to specify an unknown radionuclide.
Since the measurement instrument measures both energy and arrival (interarrival)
time from the EMS, it can be considered a vector measurement with components
deined by
�(n) := [��(n)
|
�△�(n)]′
(11.74)
After discrimination, when accepted, the raw measurement is then processed using
Bayesian techniques for enhancement: the linear Kalman ilter (LKF) and a PF(see
Section 7.2). Both of these techniques are developed in the appendices.

538
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
11.4.3.3
Energy Estimation
The energy estimator is based on the Markovian
representation as
�m(n) = �m(n −1) + ��m(n −1)
��(n) = �m(n) + ��(n)
(11.75)
with �m(0) ∼(�t
m, R�tm�tm) and ��m ∼(0, R��m��m ); ��∼(0, R����).
This model is a linear Gauss–Markov model; therefore, the optimal Bayesian
processor is the linear Kalman ilter with posterior distribution speciied by
Pr(�m(n)|Ξn) ∼( ̂�m(n|n), ̃�2
�m(n|n)) and therefore, the Kalman ilter is
̂�m(n|n) = ̂�m(n|n −1) + K�m(n)(��(n) −̂�m(n|n −1))
K�m(n) = ̃�2
�m(n|n)∕�2
im(n)
(11.76)
where ̂�m(n|n) is the conditional mean estimate of the mth-energy at arrival time n
based on all of the data up to n; ̃�2
�m is the estimated error covariance cov(�m(n) −
̂�m(n|n)); im(n) is the innovations sequence with covariance, �2
im(n) = cov(im(n)) and
K�m is the weight or gain matrix (see Section 5.3).
11.4.3.4
Interarrival Estimation
From the statistics of the EMS process, we
know that the interarrival times for the mth monoenergetic source are exponen-
tially distributed with parameter �m�△�m such that △�m(n) ∼(�m�△�m△�m(n)) =
�m�△�m exp(−�m�△�m × △�m(n)) [47]. Our process model for the interarrival time
is just an exponential random variable, while the underlying measurement model
is this variable contaminated with exponential measurement (instrumentation) noise
given by
△�m(n) = �△�m(n)
�△�(n) = △�m(n) + �△�m(n)
(11.77)
for �△�m ∼(�m�△�m△�m(n)) and �△�m ∼(���△�m(n)).
We estimate the posterior distribution using a sequential Monte Carlo approach
and construct a bootstrap particle ilter (see Section 7.5) to obtain
̂Pr(△�m(n)|Ξn) =
Np
∑
i=1
i(n)�(�△�(n) −�△�mi(n))
(11.78)
with the weight given by Wi(n) = Wi(n −1) × ̂Pr(�△�(n)|△�mi(n)) for Np-particles.
The MAPestimate is then obtained as:
△̂�m(n|n) = arg max ̂Pr(△�m(n)|Ξn)
̂�△�m(n|n) =
1
△̂�m(n|n)
(11.79)

11.4
BAYESIAN PROCESSING FOR THE DETECTION OF RADIOACTIVE SOURCES
539
11.4.3.5
Emission Probability Estimation
We use a sequential counting
technique to estimate the emission probability parameter. At each accepted arrival
(after discrimination), the counting estimator for the mth-monoenergetic component
of the radionuclide is given by
̂�m(n) =
N�m(n)
M�(n)
(11.80)
where N�m(n) is the total counts for the mth source at arrival time n or simply the mth-
channel count and M�(n) is the total count of all of the RN channels or monoenergetic
sources at n.
11.4.4
Detection
Sequential radionuclide detection is implemented in a channel-by-channel frame-
work. Basically, the individual distributions are calculated in parallel at each channel
and then combined in the detector where the required parameters are replaced by
their estimates. At each arrival after discrimination, the accepted channel jth pho-
ton is processed by the energy and interarrival parameter estimators ( ̂�) providing
the input to the sequential decision function (log-likelihood ratio) along with the
true parameters (�t →[{�t
m}, {△�t
m}, {�t
m}]; m = 1, … , M�) from the Tables. Using
the relations developed for the joint parametric distributions, the following general
functional form is implemented using the results of the sequential estimators to
give
Λ[Ξn] = Λ[Ξn−1] +
M�
∑
m=1
ln Θm(n; �t) −
M�
∑
m=1
ln Θm(n; ̂�)
(11.81)
Combining similar terms, we obtain the inal sequential log-likelihood ratio radionu-
clide decision function speciied by:
Λ[Ξn] = Λ[Ξn−1] +
M�
∑
m=1
ln
⎛
⎜
⎜⎝
(�t
m)2�t
△�m
√
2���tm
⎞
⎟
⎟⎠
−ln
⎛
⎜
⎜⎝
̂�2
m ̂�△�m(n|n)
√
2�̂��m(n|n)
⎞
⎟
⎟⎠
+
(
̂�m ̂�△�m(n|n) −�t
m�t
△�m
)
�△�(n) + 1
2
(
��(n) −̂�m(n|n)
̂��m(n|n)
)2
−1
2
(
��(n) −�t
m(n)
��tm
)2
(11.82)
We observe that after successful discrimination the parameters are estimated and
employed to calculate the log-likelihood function of Eq. 11.82. These parameters
are estimated channel-by-channel (mth channel) and the overall decision function

540
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
updated sequentially (in arrival time). Once the parameters are estimated, they are
implemented in each channel log-likelihood partial calculation (Θm(n; �)) and all of
the partial sums are combined along with the previous (in arrival time) log likelihood
to sequentially update the new log likelihood at time n. The function is then compared
to the threshold to see if a detection is possible. If not, the next photon is processed
and the log-likelihood updated to see if a decision can be made. This sequential
radionuclide process continues until there is enough data for a statistical decision to
be made.
11.4.5
Data
A proof-of-concept experiment was developed to assess the feasibility of the sequen-
tial Bayesian processor. Three source radionuclides were targeted in a laboratory envi-
ronment contaminated with background and extraneous sources. Each target source
and background was individually counted with the results combined to generate the
controlled “feasibility” data set. Here the signal-to-noise ratio (SNR), background,
etc. were ixed by this environment.
This set of composite radionuclide EMS “feasibility” data consisted of the three
radionuclides cobalt (60Co), cesium (137Cs), barium (133Ba) represented by 2, 1, and
5 monoenergetic sources, respectively, along with background and the extraneous
source (potassium).
11.4.6
Radionuclide Detection
The sequential detection paradigm of Table 11.3 was applied to the “feasibility” data
set. Based on the experimental SNR, the selected operating point (detection and false-
alarm probabilities) was (98%, 2%) specifying the thresholds which were calculated
according to Eq. 11.56 for each radionuclide. Here, an ROC curve was synthesized
using simulated EMS and noise sequences to obtain these probabilities or operating
point. After an initial calibration phase of the algorithm which consisted of “tuning”
the processors on simulated and controlled data, setting initial parameters, etc., the
overall results of the processing are shown in Fig. 11.28. We note four columns
of data, the irst column is the composite pulse-height spectrum, with the second
the composite EMS with the circles representing the discriminator output photons.
Notice that they are chosen by the discriminator conidence intervals for both energy
and the corresponding interarrival and align with the PHS energy “lines”. The third
column represents the estimated or enhanced energy of the processed (channel)
photon, while the inal column is the decision function (log likelihood) for each of
the targeted radionuclides.
As each photon is processed, the decision function is sequentially updated until one
of the thresholds (target/nontarget) is crossed (lighter crosses in igure) declaring a
threat or nonthreat. Note that barium is detected (threshold exceeded) irst (0.513 sec)
followed by the cesium (0.678 sec) and then cobalt (3.02 sec).

11.5
SEQUENTIAL THREAT DETECTION: AN X-RAY PHYSICS-BASED APPROACH
541
TABLE 11.3
Sequential Radiation Detection
Discrimination
[�t −����≤�m(n) ≤�t + ����]
[Energy]
[△�t −�̃��△�≤△̂�m(n) ≤△�t + �̃��△�]
[Interarrival]
Estimation
̂�m(n|n) = ̂�m(n|n −1) + K�mim(n)
[Energy]
△̂�m(n|n) = arg max ̂Pr(△�m(n)|Ξn)
[Interarrival]
̂�△�m(n|n) =
1
△̂�m(n|n)
[Detection rate]
̂�m(n) =
N�m(n)
M�(n))
[Emission probability]
Λ[Ξn] = Λ[Ξn−1] + ln Θm(n; �t) −ln Θm(n; ̂�)
[Decn]
Detection
Λ[Ξn]
1
≥
=
≤
0
1
Continue
0
[Log-likelihood]
11.4.7
Summary
We have demonstrated that a sequential Bayesian detector can be developed to provide
a feasible solution to the radiation detection problem by deining a target radionu-
clide(s) and its monoenergetic decomposition model evolving from the underlying
transport physics of the photon and measurement process. Starting with the decom-
position, we developed a probabilistic framework to theoretically deine the problem.
Under certain assumed distributions, a particular realization of the process was suc-
cessfully developed and applied to experimental data demonstrating its overall feasi-
bility. The key idea was to process the data, photon by photon, rejecting any extraneous
nontargeted radionuclide measurements and process only those photons that corre-
spond to the targeted (threat) radionuclide(s). Thus, the Bayesian approach provides
a unique processor capturing all available physics information photon by photon.
11.5
SEQUENTIAL THREAT DETECTION: AN X-RAY PHYSICS-BASED
APPROACH
The timely and accurate detection of threat contraband especially for ports-of-entry
is an extremely critical problem of national security for many countries. The charac-
terization of signal processing models based on X-ray transport physics is a crucial
element in advanced sequential Bayesian processor designs. Incorporating the under-
lying statistics of X-ray interactions with materials offering a potentially unique sig-
nature of an object under investigation leads to a (stochastic) physics-based approach.

Cobalt
Cesium
Barium
Cobalt
detection
Cesium detection
Barium detection
(a)
Pulse height spectrum
Event mode sequence
accepted
rejected
Accepted KF EMS → RN channels
10
11
12
13
14
10
11
12
13
14
10
11
12
13
14
10
11
12
13
14
15
11
12
13
14
15
11
12
13
14
15
11
12
13
14
15
11
12
13
14
15
0
5
10
11
12
13
Time (sec)
Time (sec)
Time (sec)
0
5
10
15
Time (sec)
0
5
10
Time (sec)
14
15
RN channels → Decision functions
1400
1300
1200
1100
1000
900
800
700
600
500
400
300
200
100
0
1400
1338
1336
1334
1178
1176
667
666
665
390
385
364
362
360
358
356
310
305
285
280
88
−25
−20
−15
−10
−5
−50
−40
−30
−20
−10
−10
0
10
20
0
10
0
86
84
82
Co60
Co60
Cs137
Cs137
Ba133
Ba133
Ba133
Ba133
Ba133
Ba133
Co60
1300
1200
1100
1000
900
800
700
Volts (keV)
600
500
400
300
200
100
0
150
100
50
0
Counts
(b)
(c)
(d)
FIGURE 11.28
Sequential Bayesian detection and identiication: (a) pulse-height spectrum (after calibration);
(b) EMS with discrimination (circles); (c) enhanced energy estimates; (d) log-likelihood decision functions for
60Co (detection time: 3.02 sec), 137Cs (detection time: 0.67 sec),and 133Ba (detection time: 0.51 sec) radionuclide
detection/identiication.

11.5
SEQUENTIAL THREAT DETECTION: AN X-RAY PHYSICS-BASED APPROACH
543
A sequential Bayesian processor is developed to provide a reliable and accurate solu-
tion with high conidence in a timely manner for this problem based on a set of
synthesized object intensity data.
The basic approach is model-based incorporating the X-ray propagation physics
into the state–space framework. That is, the initial polyenergetic source intensity
is measured at the output of a detector array (multi-output). These data along with
a-priori knowledge of the targeted threat are incorporated into a threat model with the
appropriate attenuation coeficient parameters. Next, measured object intensities are
estimated from the raw detector data using a linear model-based processor (MBP)
or Kalman ilter to compute the log-likelihood decision function. Then at each step
(spatial), the intensity is predicted by the MBP and a decision (threat/nonthreat/no
decision) is made.
11.5.1
Physics-Based Models
The characterization of a wealth of items that could be enclosed in a shipping container
covers a wide range of features. From an X-ray interrogation perspective for threat
detection, we are concerned primarily with the interaction of X-ray photons (energy)
with the variety of materials enclosed within.
11.5.1.1
Background: X-ray Physics
When X-rays interact with matter
(materials), they undergo attenuation effects, that is, an X-ray or equivalently beam
of photons passing through matter is depleted or attenuated as photons are removed
through absorption and scattering [51, 58]. Here photon energy (�) is transformed to
heat (absorption) or scattered with its energy dissipated and redirected. Assume we
have a perfectly parallel monoenergetic (single energy) beam of X-rays with intensity
(�, x) irradiating a uniformly thick, single-material absorber as shown in Fig. 11.29,
then the transmitted (output) intensity is governed by
d
dx(�, x) = −�(�, , �)(�, x)
(11.83)
X-ray
source
Object
Detector
array 
FIGURE 11.29
X-ray transmission physics: polyenergetic source, object, detector array
measurements, and sequential Bayesian processing for threat detection.

544
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
where �(�, , �) is the attenuation coeficient (cm−1) at energy �(keV) for a “single”
material of mass density �(gcm−3) with atomic number along the X-direction
of path length △x = x −xo (cm) with (�o, xo) is the initial intensity. Solving this
equation leads to the Lambert–Beer Law [51, 58] given by
(�, x) = (�o, xo) × exp{−�(�, , �)(x −xo)}
(11.84)
This relation can be extended further to incorporate composite materials ( (, �) ⟶
(m, �m); m = 1, … , M) and multiple source energies (S(�n); n = 1, … , N) giving the
general expression
(S(�n), x) = (S(�o), xo)
× exp
{
−∫
( M
∑
m=1
�m(S(�n), m�m)△x
)
d�
}
(11.85)
for n = 1, … , N.
From these results, we see that the attenuation coeficients contain all of the critical
physical information required to uniquely characterize the material under irradiation
by the source X-rays.
11.5.1.2
Physics-Based State–Space Models
For our problem, we return
to the original irst-order differential transmission relation of Eq. 11.83 and realize
that it is already in the well-known state–space form [38]. We consider this model
a “lumped model” where the object is characterized by a set of average attenuation
coeficients. Assuming that a polyenergetic source consisting of a set of discrete
monoenergetic energies, �n; n = 1, … , N, irradiates the material (object), Beer’s law
is now a set of irst-order differential transport equations, that is,
d
dx(�n, x) = −�(�n, , �)(�n, x); n = 1, … , N
(11.86)
with incident intensities given by (�no, xno) identifying each monoenergetic source
component. Expanding over n, we obtain the equivalent state–space transmission
model given by
d
dx
⎡
⎢
⎢⎣
(�1, x)
⋮
(�N, x)
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣
−�(�1, , �)
O
⋱
O
−�(�N, , �)
⎤
⎥
⎥⎦
⎡
⎢
⎢⎣
(�1, x)
⋮
(�N, x)
⎤
⎥
⎥⎦

11.5
SEQUENTIAL THREAT DETECTION: AN X-RAY PHYSICS-BASED APPROACH
545
which can be expressed simply in vector-matrix form as
d
dx(�, x) = A(�, , �)(�, x)
(11.87)
where we have the state intensity vector ∈N×1, the system (physics) matrix,
A ∈N×N with initial (incident) intensity vector deined by
(�o, xo) :=
[
(�1o, x1o), … , (�No, xNo)
]T
and T the matrix transpose operator. It is well known that the solution to the linear
shift invariant (A not a function of ) state equations is given by the state transition
matrix as [38]
(�, x) = eA(�,,�)(x−xo)
(11.88)
with ∈N×N yielding Beer’s law for a polyenergetic source constructed as a
composition of monoenergetic sources, that is,
(�, x) = (�, x)(�o, x) = eA(�,,�)(x−xo)(�o, xo)
(11.89)
This representation can be considered a “lumped model” where the object is charac-
terized by a set of average attenuation coeficients {�(�n, , �)}n = 1, … , N, one at
each energy. Thus, energetic photons interacting with the object (material) are attenu-
ated according to each associated attenuation coeficient. An alternate representation
incorporates the discretization of the object into voxels through CT-reconstruction
followed by expressing transport as a set of coupled differential/difference equations
[38]. State–space methods can be applied in either of these representations. Here, we
concentrate on the lumped model, since it is the simplest to comprehend.
Next, let us consider an X-ray beam or equivalently ray path consisting of polyen-
ergetic photons irradiating the material and measured by a detector element, the �th.
We choose to use a scintillation measurement system composed of a crystal convert-
ing the X-ray radiation to visible light photons coupled to a photo diode converting
the photon energy to electrical charge/current. With this measurement system, the
detector is related to the photon intensity through a set of energy-dependent con-
version constants, that is, for the �th detector element and a set of N-energies, we
have
d�(�, x) = cT
�(�, △�)�(�, x) =
N
∑
n=1
c�(�n)�(�n, x)
(11.90)
where c�, �∈N×1, and c�is an energy-dependent vector of scintillation scale
factors converting photon energy to charge (current).

546
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
For acquisition speed, an array of L-elements is normally applied, that is, expand-
ing over �, we obtain the detector measurement model as
⎡
⎢
⎢
⎢
⎢⎣
d1(�, x)
−−−
⋮
−−−
dL(�, x)
⎤
⎥
⎥
⎥
⎥⎦
=
⎡
⎢
⎢
⎢
⎢
⎢⎣
cT
1(�, △�)
−−−
⋮
−−−
cT
L(�, △�)
⎤
⎥
⎥
⎥
⎥
⎥⎦
(�, x)
(11.91)
which can also be expressed simply as
d(�, x) = C(�, △�)(�, x)
(11.92)
where we have the detector measurement vector d ∈L×1, the measurement system
matrix C ∈L×N, and the corresponding state intensity vector ∈N×1.
Thus, the overall physics-based state–space description (deterministic) of the X-
ray transmission and detector system is summarized by combining the relations of
Eqs. 11.87 and 11.93 for each ray and detector element as
d
dx(�, x) = A(�; �)(�, x)
d(�, x) = C(�, △�)(�, x)
(11.93)
where the N-state intensity vector by , the N × N system matrix is deined by
A(�; �) := diag[ −�(�1; �), … , −�(�N; �)] and the material parameter set by �:=
{, �}.
We summarize the development of the state–space representation in Fig. 11.30.
Here, we see the evolution of the photon intensity proportional to the detector output
current. Initially, the polyenergetic source is represented by the composition of a
1
( ,x)
...
(
,x)
N
I
I
ε
ε
( ,x)
I ε
( ,x)
ε
I
Polyenergetic
X-ray beam
Object
transmission
Detector
array 
( )
ε
d
(
)1
N ×
(
)1
LN ×
(
)1
L ×
Monoenergetic
sources
Transmission physics
Transmission 
physics
Measurement 
physics
(
)
A
;
ε Θ
( )
C ε
( )
ε
d
( ,x)
ε
I
State-space 
FIGURE 11.30
X-ray transmission: transmission physics with “lumped” state–space
model (dashed).

11.5
SEQUENTIAL THREAT DETECTION: AN X-RAY PHYSICS-BASED APPROACH
547
set of monoenergetic sources ((�, x)) irradiating the object. The transmitted output
((�, x)) is collected by the detector array, integrated, producing a set of output
currents proportional to the transmitted photon energies (d(�, x)) used as an input to
image the object attenuation.
11.5.2
X-ray State–Space Simulation
In this section, we briely discuss the development of a state–space simulator capa-
ble of synthesizing X-ray detector outputs for generating noisy detector data. The
approach involves discretizing the solution using the state transition matrix which is
a matrix exponential [38] and generating data for an object.
The basic deterministic state–space model of Eq. 11.93 can easily be extended to
a stochastic representation assuming additive, zero-mean, Gaussian noise resulting
in the Gauss–Markov state–space model either given by the differential equation of
Eq. 11.93 or equivalently in terms of the state transition matrix of Eq. 11.89. The
system of equations may be discretized to obtain a sampled data representation [38]
resulting in the following discrete Gauss–Markov model given by
(�, xk) = (�, △xk)(�, xk−1) + △xk(�, △xk)w(xk−1)
(11.94)
with corresponding measurement (detector array) model
d(�, xk) = C(e, △�)(�, xk−1) + �(xk)
(11.95)
for N-intensity (state) and white, Gaussian process uncertainty/noise vectors, , w
with �∼(0, R��). Here d is the Nd-measurement (detector array) with corre-
sponding white, Gaussian uncertainty/noise (electronic) vector �for �∼(0, R��)
along with the corresponding Nd × Nmeasurement matrix C. The incremental path
length is speciied by △xk := xk −xk−1 with (N× N) state transition matrix ,
(�, △xk) = exp{A(�; �)△xk}
(11.96)
for A(�; �) = diag
[
−�(�1; �), … , −�(�Nd; �)
]
the material attenuation coeficients
and set of intrinsic material properties {�}. In addition to the intensity and mea-
surement models, the Gauss–Markov representation also propagates the associated
statistics (state/measurements) means and variances which are used to construct
uncertainty bounds around the synthesized data, that is, the mean state intensity is
given by the relation
(�, xk) = (�, △xk)(�, xk−1)
(11.97)
along with the mean detector measurement
d(�, xk) = C(�, △�)(�, xk−1)
(11.98)

548
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
The corresponding state and measurement covariances are given by
(xk) = (�, △xk)(xk−1)T(�, △xk) + R��(xk−1)
(11.99)
dd(xk) = C(�, △�)(xk−1)CT(�, △�) + R��(xk)
(11.100)
To summarize this “lumped model” representation, the discrete Gauss–Markov
model characterizes the photon transport through a homogeneous object irradiated by
a polyenergetic source with uncertainties approximated by additive zero mean, white
Gaussian sequences both in intensity (process) and detector intensity measurements
(measurement). Next, we develop the simulator.
In this problem, we assume that an object or item has been isolated and extracted
from a CT-image resulting in an attenuation coeficient sequence (ACS). From this
sequence, a set of average attenuation coeficients is obtained at each known source
energy and represented by {�(�n, �}n = 1, … , N. We developed a simple transport
simulator based on the lumped model and the state–space framework to synthesize
a threat object composed of ammonium nitrate (NH4NO3) material characterized
uniquely by its set of energy-dependent attenuation coeficients obtained from the
Tables [51] based on a polyenergetic source and detector bands at 30–160 keV incre-
mented every 10 keV. The transport is calculated every △x = 100 mm. We assume
that an X-ray beam (ray) at 0o passes through the object (no clutter) and is measured
by an eight-element scintillation detector array. We also assume that uncertainties
propagate and are captured by the model discussed above with intensity (process)
uncertainty of covariance R��= 25 and detector measurement noise of covariance
R��= 107. The scanner volume can be considered a 1 cubic meter spherical volume.
The problem parameters are summarized in Table 11.4. We have N= 14 states (and
TABLE 11.4
Transport Physics
for Ammonium Nitrate
Energy (keV)
Atten. Coeficients
30
0.95388
40
0.68456
50
0.58017
60
0.52641
70
0.49307
80
0.47019
90
0.45164
100
0.43706
110
0.42389
120
0.41288
130
0.40292
140
0.39344
150
0.38511
160
0.37761

11.5
SEQUENTIAL THREAT DETECTION: AN X-RAY PHYSICS-BASED APPROACH
549
average attenuation coeficients) with Nd = 8 elements in the detector array. The
simulation was performed for a single beam (ray) propagating through the object at
a path length of 100 cm (scan volume) with the object of cross-section 6 cm located
30 cm from the source.
The photons are at the initial intensity (�o, xo) and then drop off exponentially
based on their respective attenuation coeficients and detector measurements as they
interact with the material (ammonium nitrate) with the path length incremented in
△x = 0.1 cm steps. Note that in reality the detector array provides only a single
snapshot of integrated intensity at a given x-location providing a measured projection
[58]. These lumped model simulations will be used as input to the sequential detector
algorithm.
11.5.3
Sequential Threat Detection
Detection of threats residing in a variety of containers is essentially a binary detec-
tion problem. Here, we investigate a solution to this decision problem to detect the
presence of threat materials using X-ray radiation as the primary modality (e.g., pot
scanners) to irradiate each object and assess its status—threat or nonthreat. Therefore,
we deine the problem in terms of a binary hypothesis test. From the scanner, we use
detector outputs directly available from each of the array elements; that is, the binary
threat detection problem is based on testing the hypotheses
0 : d(�, xk) = C(�, △�)(�, xk; �) + v(xk)
[Nonthreat]
1 : d(�, xk) = C(�, △�)(�, xk; �t) + v(xk)
[Threat]
(11.101)
where
d is the Nd −element detector array
C is the (Nd × N) −energy measurement matrix
is the N−energy dependent intensities (states)
v is the Nd −white Gaussian uncertainty/noise vector
�is the set of material properties (object and target)
xk is the length along the ray
(11.102)
The optimal solution to this decision problem evolves directly from the Neyman–
Pearson theorem [33,57] maximizing the detection probability for a ixed false-alarm
probability resulting in the likelihood-ratio decision function deined by
[K] := Pr[K|1]
Pr[K|0]
(11.103)

550
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
where K := {d(�, x1), … , d(�, xK)} with the hypothesis test deined by
[K]
1
>
<
0
T
(11.104)
for threshold T. This expression implies a “batch” decision; that is, we gather the
K-detector array measurements, calculate the likelihood of Eq. 11.103 over the entire
batch of data and compare it to the threshold to make the decision.
Expanding the likelihood ratio for each detector output, we obtain
[K] =
Pr[d(�, x1), … , d(�, xK)|1]
Pr[d(�, x1), … , d(�, xK)|0]
(11.105)
From the Bayes’ rule [34], we have
Pr[K|�] = Pr[d(�, x1), … , d(�, xK)|�] = Pr[d(�, xK), K−1|�] (11.106)
and
Pr[d(�, xK), K−1|�] = Pr[d(�, xk)|K−1, �] × Pr[K−1|�]; �= 0, 1
(11.107)
Substituting these expressions into the likelihood ratio above, replacing K →k and
grouping, we obtain the recursion or equivalently sequential likelihood-ratio for the
kth detector output as follows [33]
[k] = [k−1] ×
Pr[d(�, xk)|k−1, 1]
Pr[d(�, xk)|k−1, 0];
k = 0, 1, … , K
(11.108)
with Pr[d(�, x0)|−1, �] = Pr[d(�, x1)|�], the prior under each hypothesis.
Anticipating the exponential family of distributions [34], we take logarithms to
obtain the sequential log likelihood ratio (decision function) Λ[k] as
Λ[k] = Λ[k−1] + ln Pr[d(�, xk)|k−1, H1] −ln Pr[d(�, xk)|k−1, H0] (11.109)
Therefore, the Wald sequential probability-ratio test is [33]
Λ[k]
> ln T1(k)
Accept
H1
ln T0(k)
≤
Λ[k]
≤ln T1(k)
Continue
Λ[k]
< ln T0(k)
Accept
H0
(11.110)

11.5
SEQUENTIAL THREAT DETECTION: AN X-RAY PHYSICS-BASED APPROACH
551
where the thresholds are speciied in terms of the false alarm (PFA) and miss (PMiss)
probabilities (from ROC curve) as
T0(k) = PMiss(k)
PFA(k) ;
T1(k) = 1 −PMiss(k)
PFA(k)
(11.111)
The sequential detector updates the decision function at each step along with the
upper and lower decision thresholds based on the desired operating point (from an
ROC curve).
For our X-ray material detection problem, we must specify the required proba-
bilities for each hypothesis which implies that we must incorporate the underlying
transport physics (Beer’s law) developed previously. Incorporating uncertainty and
noise into the representation, we choose the Gauss–Markov representation of Section
4.5 as
(�, xk) = (�, △xk)(�, xk−1) + △xk(�, △xk)w(xk−1)
(11.112)
with corresponding measurement (detector array) model
d(�, xk) = C(e, △�)(�, xk−1) + �(xk)
(11.113)
with N-intensity (state) and white, Gaussian process uncertainty/noise vectors, , w
with �∼(0, R��). Here, d the Nd-measurement (detector array) with correspond-
ing white, Gaussian uncertainty/noise (electronic) vector v for �∼(0, R��) along
with the corresponding Nd × Nmeasurement matrix C. The path length is speciied
by △xk := xk −xk−1 with (N× N) state transition matrix ,
(�, △xk) = eA(�;�)△xk
(11.114)
for A(�; �) = diag [−�(�1; �), … , −�(�N; �)] the material attenuation coeficients and
set of intrinsic material properties {�}.
With this representation of X-ray transport, we specify the binary decision problem
as
0 : d(�, xk) = C(�, △�) ̂(�, xk; �) + v(xk)
[Nonthreat]
1 : d(�, xk) = C(�, △�)(�, xk; �t) + v(xk)
[Threat]
(11.115)
by the Gaussian distributions
Pr[d(�, xk)|k−1; H0] = (̂d(xk|xk−1), Ree
)
Pr[d(�, xk)|k−1; H1] = (d(�, xk; �t), Rdd
)
(11.116)

552
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Taking logarithms of these distributions and inserting them into the log-likelihood
expression of Eq. 11.109, we obtain
Λ[k] = Λ[k−1] −ln ((2�)−Nd∕2|Rdd|−1∕2)
−1
2
(d(�, xk) −d(�, xk; �t))T R−1
dd
(d(�, xk) −d(�, xk; �t)) + ln ((2�)−Nd∕2|Ree|−1∕2)
+1
2
(d(�, xk) −̂d(xk|xk−1))T R−1
ee
(d(�, xk) −̂d(xk|xk−1))
(11.117)
Since the underlying physics-based models are assumed Gauss–Markov, we know
that the optimal solution to the linear estimation of the detector array measurement is
the conditional mean with sequential solution provided by the well-known Kalman
ilter of Section 5.4. Therefore, we have ̂d(xk|xk−1) = E{d(�, xk)|k−1} the condi-
tional mean at path length xk based on past path lengths up to xk−1 along with
conditional covariance Ree(xk) = cov(e(xk))—the innovations covariance provided
by the sequential algorithm, that is,
̂�(xk|xk−1) = (�, △xk; �) ̂�(xk−1|xk−1)
[Pred. state]
̂d(xk|xk−1) = C(�, △�) ̂�(xk|xk−1)
[Pred. measurement]
̃P(xk|xk−1) = (�, △xk; �)̃P(xk−1|xk−1)T(�, △xk; �) + R��(xk−1) [Pred. cov.]
e(xk) = d(�, xk) −̂d(xk|xk−1))
[Innovations]
Ree(xk) = C(�, △�)̃P(xk|xk−1)CT(�, △�) + R��(xk)
[Innovations cov.]
K(xk) = ̃P(xk|xk−1)CT(�, △�)R1
ee(xk)
[Gain]
̂�(xk|xk) = (�, △xk; �) ̂�(xk|xk−1) + K(xk)e(xk)
[Updated state]
(11.118)
Here, we ignore the update terms in the algorithm (for details see Ref. [38]).
An expression for the “target” or “true” distribution can be speciied using the true
(target) parameters from the available tables [51] for
(�, xk) = (�, △xk)(�, xk)
(11.119)
along with the mean detector measurement
d(�, xk) = C(�, △�)(�, xk−1)
(11.120)
The corresponding state and measurement mean and covariances are given by Eqs.
11.97–11.100, that is,
d(�, xk; �t) ↔d(�, xk)
Rdd(xk) ↔C(�, △�)(xk−1)CT(�, △�) + R��(xk)
(11.121)

11.5
SEQUENTIAL THREAT DETECTION: AN X-RAY PHYSICS-BASED APPROACH
553
Substituting these expressions into the log-likelihood decision function, we
obtain
Λ[k] = Λ[k−1] + �−1
2
(d(�, xk) −d(�, xk))T R−1
dd (xk)
(d(�, xk) −d(�, xk)) + 1
2
(eT(xk)R−1
ee (xk)e(xk))
(11.122)
where �:= 1
2(ln |Ree(xk)| −ln |Rdd(xk)|).
Following the simulation, we developed the physics-based processor to enhance
the intensity states and detector measurements. In Fig. 11.31, we observe the intensity
(state) estimates clearly demonstrating the capability of the processor along with the
enhanced measurements shown in Fig. 11.32.
Finally to demonstrate the sequential Bayesian detection algorithm using the
enhanced data provided by the Kalman ilter (above), we applied it to the synthesized
data with a lower signal-to-noise ratio (SNR) with the resulting output shown in
Fig. 11.33. We note the log-likelihood decision function and the associated bounds
assuming a detection probability of 95% and a false alarm probability of 5% which
are used to calculate the upper and lower thresholds. The results for this case are
expected with the log-likelihood function increasing until the detection threshold is
crossed.
0
200
400
600
800
1000
1200 0
2
4
6
8
10
12
14
0
20
40
60
80
100
120
140
160
180
State no.
State-space simulation (intensity vs energy vs path length)
Path length (cm)
Intensity (KeV)
−20
FIGURE 11.31
Physics-based processor results: intensity (state conditional mean)
estimation.

554
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
0
200
400
600
800
1000
1200
0
2
4
6
8
10
12
14
0
20
40
60
80
100
120
140
160
State no.
State-space intensity estimation (intensity vs energy vs path length)
Path length (cm)
Intensity (KeV)
−20
FIGURE 11.32
Physics-based processor results: detector measurement estimation.
11.5.4
Summary
We have demonstrated that a physics-based sequential Bayesian processor can be
developed to provide a feasible solution to the X-ray threat contraband detection prob-
lem by deining a target X-ray object. Sequential techniques based on the state–space
formulation [38] were developed demonstrating their ability to capture the X-ray
transport physics for a lumped transport model representation. The lumped approach
was further investigated and an X-ray transport synthesizer was developed including
uncertainties resulting in a Gauss–Markov state–space formulation. Synthesized data
for an ammonium nitrate explosive threat was then employed to investigate the per-
formance of a sequential Bayesian detector incorporating a physics-based processor
(Kalman ilter) for intensity measurement enhancement. The resulting log-likelihood
detection technique was capable of performing a detection under the assumed detec-
tion and false alarm probabilities (see Ref. [59] for more details).
11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
The shallow ocean is an ever-changing environment primarily due to temperature
variations in its upper layers directly affecting sound propagation throughout. The
need to develop processors capable of tracking these changes implies a stochastic
as well as an environmentally adaptive design. Bayesian techniques have evolved

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
555
0
10
20
30
40
50
60
70
80
90
100
0
5
10
15
20
25
Path-length (cm)
Log-likelihood
Log-likelihood decision function
LLike
Non-threat
Threat
Threat
Non-threat
FIGURE 11.33
Physics-based processor threat detection for Gaussian case: log-
likelihood-ratio decision function and thresholds for an assumed detection and false
alarm probabilities of 95% and 5%, respectively.
to enable a class of processors capable of performing in such an uncertain, non-
stationary, non-Gaussian, variable shallow ocean environment. Here, we develop a
sequential Bayesian processor capable of providing a joint solution to the modal func-
tion tracking and environmental adaptivity problem. The focus is on the development
of both a particle ilter and an unscented Kalman ilter capable of providing reasonable
performance for this problem. These processors are applied to hydrophone measure-
ments obtained from a vertical array. The adaptivity problem is attacked by allowing
the modal coeficients and/or wavenumbers to be jointly estimated from the noisy
measurement data along with tracking of the modal functions while simultaneously
enhancing the noisy pressure-ield measurements.
11.6.1
State–Space Propagator
For the ocean acoustic modal function enhancement problem, we assume a horizon-
tally stratiied ocean of depth h with a known horizontal source range rs and depth zs
and that the acoustic energy from a point source can be modeled as a trapped wave
governed by the Helmholtz equation [28, 60]. The standard separation of variables
technique and removing the time dependence leads to a set of ordinary differential

556
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
equations; that is, we obtain a “depth-only” representation of the wave equation which
is an eigenvalue equation in z with
d2
dz2 �m(z) + �2
z (m)�m(z) = 0,
m = 1, … , M
(11.123)
whose eigensolutions {�m(z)} are the so-called modal functions and �z is the ver-
tical wavenumber in the z-direction. These solutions depend on the sound- speed
proile c(z) and the boundary conditions at the surface and bottom as well as the
corresponding dispersion relation given by
�2 =
�2
c2(z) = �2
r (m) + �2
z (m),
m = 1, … , M
(11.124)
where �r(m) is the horizontal wavenumber (constant) associated with the mth mode
in the r direction and �is the harmonic source frequency.
By assuming a known horizontal source range a priori, we obtain a range solution
given by the Hankel function H0(�rrs) enabling the pressure-ield to be represented
by
p(rs, z) =
M
∑
m=1
�m(rs, zs)�m(z)
(11.125)
where p is the acoustic pressure; �m is the mth modal function with the modal
coeficient deined by
�m(rs, zs) := qH0(�rrs)�m(zs)
(11.126)
for (rs, zs) the source position and q its amplitude.
11.6.1.1
State–Space Model
The depth-only eigen equation can be trans-
formed to state–space form by deining the state vector of the mth mode as
�m(z) :=
[ �m(z)
d
dz�m(z)
]
=
[
�m1(z)
�m2(z)
]
(11.127)
leading to the state (vector) equation:
d
dz�m(z) = Am(z)�m(z)
(11.128)
for
Am(z) =
[
0
1
−�2
z (m)
0
]
(11.129)

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
557
Assuming that the ocean acoustic noise can be characterized by additive uncer-
tainties, we can extend this deterministic state equation for the M-modes; that is,
Φ(z) := [�1(z)| ⋯|�M(z)]T leading to the following 2M-dimensional Gauss–Markov
representation of the model:
d
dz�(z) = A(z)�(z) + w(z)
(11.130)
where w(z) = [�1�2 … �2M]T is additive, zero-mean random noise. The system
matrix A(z) is
A(z) =
⎡
⎢
⎢⎣
A1(z)
⋯
0
⋮
⋱
⋮
0
⋯
AM(z)
⎤
⎥
⎥⎦
(11.131)
with the overall state vector given by
�(z) = [�11�12|�21�22| … |�M1�M2]T
(11.132)
This representation leads to the measurement equations, which we can write as
p(rs, z) = CT(rs, zs)�(z) + �(z)
(11.133)
where
CT(rs, zs) = [�1(rs, zs)0| ⋯|�M(rs, zs)0
(11.134)
The random noise terms w(z) and �(z) can be assumed Gaussian and zero-mean with
respective covariance matrices R��and R��. The measurement noise (�) can be used
to represent the “lumped” effects of near-ield acoustic noise ield, low noise on the
hydrophone, and electronic noise. The modal noise (w) can be used to represent
the “lumped” uncertainty of sound-speed errors, distant shipping noise, errors in
the boundary conditions, sea state effects and ocean inhomogeneities that propagate
through the ocean acoustic system dynamics (normal-mode model).
Since the array spatially samples the pressure-ield discretizing depth, we choose
to discretize the differential state equations using a central difference approach for
improved numerical stability; that is, assuming uniformly-spaced hydrophones, from
Eq. 11.123 we have
d2
dz2 �m ≈�m(z�) −2�m(z�−1) + �m(z�−2)
△z2
�
(11.135)
for △z�:= z�−z�−1.

558
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Applying this approximation to Eq. 11.123 gives
�m(z�) −2�m(z�−1) + �m(z�−2) + △z2
��2
z (m)�m(z�−1) = 0
where z�is the location of the �th sensor. Deining the discrete modal state vector as
�m(z�) := [�m(z�−2)|�m(z�−1)]T, we obtain the following set of difference equations
for the mth mode
�m1(z�) = �m2(z�−1)
�m2(z�) = −�m1(z�−1) + (2 −△z2
��2
z (m))�m2(z�−1)
(11.136)
with each of the corresponding A-submatrices now given by
Am(z�) =
⎡
⎢
⎢⎣
0
1
−1
2 −△z2
��2
z (m)
⎤
⎥
⎥⎦
;
m = 1, … , M
(11.137)
and
�2
z (m) =
(
�2
c2(z)
)
−�2
r (m)
(11.138)
Substituting this model and combining all of the modes as in Eq. 11.131, the following
overall Gauss–Markov representation of our normal-mode process and measurement
is
�(z�) = A(z�)�(z�−1) + w(z�)
p(rs, z�) = CT(rs, zs)�(z�) + �(z�)
(11.139)
and �, w ∈2M×1, p, �∈1×1 for w ∼(0, R��), �∼(0, R��) with �(z�) ∼
(�(z0), P(z0)), A ∈2M×2M, CT ∈1×2M and with ∼meaning “distributed as”.
This completes the normal-mode representation of the shallow ocean in state–
space form; next, we consider augmenting this model with unknown parameters to
create a parametrically adaptive processor.
11.6.1.2
Augmented State–Space Models
The “parametrically adap-
tive” processor evolves from the normal-mode representation by deining parameter
sets of interest. Variations in the ocean can be relected, parametrically, in a number
of ways. For instance, sound-speed variations are related to temperature changes
especially in a shallow ocean environment directly impacting the corresponding dis-
persion relation of Eq. 11.124 that can be parametrically captured by the horizontal
wavenumber. Besides the wavenumbers, modal variations can be relected through

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
559
the measured pressure-ield relations of Eq. 11.125 that can be parametrically cap-
tured by the modal coeficients of Eq. 11.126. Therefore, we choose to use the modal
coeficients as well as the horizontal wavenumbers (individually) as the parameters
of interest in adapting to the changing shallow ocean environment.
Case(i): Modal Coeficients
The modal coeficients of Eq. 11.126 can be used to capture modal function
variations. In this case, we deine the unknown parameter vector as
�m(rs, zs) := �m(rs, zs);
m = 1, … , M
and a new “augmented” state vector for the mth mode as
Φm(z�; �m) := Φm(z�) = [�m1(z�)�m2(z�)|�m(z�)]T
With this choice of parameters (modal coeficients), the augmented state equations
for the mth mode becomes
�m1(z�) = �m2(z�−1) + �m1(z�−1)
�m2(z�) = −�m1(z�−1) + (2 −△z2
��2
z (m))�m2(z�−1) + �m2(z�−1)
�m(z�) = �m(z�−1) + △z���m(z�−1)
(11.140)
where we have selected a discrete random walk model ( ̇�m(z) = ��m(z)) based on
irst differences to capture the variations of the modal coeficients with additive,
zero-mean, Gaussian noise of covariance R��m��m .
Note that when we augment the unknown parameters into the state vector to
construct the parametrically adaptive processor, we assume that they are random
(walks) with our pre-computed initial values speciied (initial conditions or means)
and their corresponding covariances used to bound their uncertainty (2�conidence
bounds).
More succinctly, for the mth mode, we can write
Φm(z�) = Am(z�−1; �)Φm(z�−1) + wm(z�−1)
(11.141)
or expanding
⎡
⎢
⎢⎣
�m(z�)
−−−
�m(z�)
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣
Am(z�−1)
|
0
−
−
−
0
|
1
⎤
⎥
⎥⎦
⎡
⎢
⎢⎣
�m(z�−1)
−−−
�m(z�−1)
⎤
⎥
⎥⎦
+
⎡
⎢
⎢⎣
W�m(z�−1)
−−−
W�m(z�−1)
⎤
⎥
⎥⎦
(11.142)

560
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
where W�m ∼(0, RW�mW�m), W�m ∼(0, RW�mW�m ), �m(0) ∼(�m(0), R�m�m),
�m(0) ∼(�m(0), R�m�m).
The corresponding nonlinear measurement model is given by
p(rs, z�) =
M
∑
m=1
�m(z�)�m(z�) + �(z�);
�= 1, … , L
(11.143)
with dispersion (sound-speed)
c(z�) =
�
√
�2
z (m) + �2
r (m)
;
m = 1, … , M; �= 1, … , L
(11.144)
To complete this representation, we combine all of the modes and unknown param-
eters and therefore the state transition is characterized by the underlying augmented
state–space model as
�(z�) = A(z�−1; Θ)�(z�−1) + w(z�−1)
and the measurement, on the other hand, is determined from the nonlinear pressure-
ield measurement model
p(rs, z�) = c
[
�(z�); Θ
]
+ �(z�)
(11.145)
Note that for this case, the pressure-ield is nonlinear in the states (modal functions)
and parameters (modal coeficients), since they are multiplicands and therefore lead
to non-Gaussian measurements.
Case(ii): Horizontal Wavenumbers
The horizontal wavenumbers of Eq. 11.124 can be used to capture sound-speed
(temperature) variations. For this case, we deine the unknown parameter vector as
�m(z) := �r(m);
m = 1, … , M
and a new “augmented” state vector as
Φm(z�; �m) := Φm(z�) = [�m1(z�)�m2(z�)|�m(z�)]T
With this choice of parameters (horizontal wavenumber), the augmented state
equations for the mth mode become
�m1(z�) = �m2(z�−1) + �m1(z�−1)
�m2(z�) = −�m1(z�−1) +
(
2 −△z2
�
( �2
c2(z�) −�2
m(z�−1)))
�m2(z�−1) + �m2(z�−1)
�m(z�) = �m(z�−1) + △z���m(z�−1)
(11.146)

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
561
where we have again selected a discrete random walk model ( ̇�m(z) = ��m(z)) to cap-
ture the variations of the horizontal wavenumber with additive, zero-mean, Gaussian
noise of covariance R��m��m . Note that even though we know that theoretically the
horizontal wavenumbers are constant for each mode, we incorporate this stochastic
representation due to the uncertainty inherent in the measurements and the parametric
model itself.
More succinctly, for the mth mode, we can write
Φm(z�) = Am(z�−1; �)Φm(z�−1) + �m(z�−1)
(11.147)
for
Am(z�−1; �) =
⎡
⎢
⎢
⎢
⎢⎣
0
1
|
0
−1
2 −△z2
�
(
�2
c2(z�) −�2
m(z�−1))
|
0
−
−
−
0
0
|
1
⎤
⎥
⎥
⎥
⎥⎦
The corresponding measurement model is given by
p(rs, z�) =
M
∑
m=1
�m
(rs, zs; �m(z�))�m(z�) + �(z�);
�= 1, … , L (11.148)
with
�m(rs, zs; �m) := qH0(�m(z�)rs)�m(zs)
(11.149)
and dispersion (sound-speed)
c(z�; �m) =
�
√
�2
z (m) + �2
m(z�)
;
m = 1, … , M; �= 1, … , L
(11.150)
Here the “combined” augmented model for this case leads to both a nonlinear state
and measurement space, that is,
�(z�; Θ) = a
[
�(z�−1; Θ)
]
+ w(z�−1)
p(rs, z�) = c
[
�(z�; Θ)
]
+ �(z�)
(11.151)
In this case, both the propagator and the pressure-ield measurements are nonlinear
functions of the states (modes) and unknown parameters (wavenumbers). Note that
the modal coeficients are also direct functions of the estimated wavenumbers and
are adapted simultaneously. Therefore, this processor is clearly non-Gaussian similar
to the previous case.
It should be noted that the initial model parameters are obtained from the
prior solution of the boundary value problem typically developed as part of the

562
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
experimental design process and/or after the experiment has been executed. Here,
the initial “guesses” at modal coeficients and modal functions themselves are calcu-
lated based on the experimental conditions such as frequencies, current-temperature-
density (CTD), archival sound-speed proiles (SSP), boundary conditions, horizontal
wavenumber estimators (e.g., see Refs. [61] and [62] for more details) to provide
the input to the normal-mode boundary-value problem (BVP) solutions (SNAP [37],
KRAKEN [63], SAFARI [64]) yielding the required parameters. These parameters
are then input to the state–space, measurement, and noise/uncertainty models.
11.6.2
Processors
In this section, we briely discuss the processors for our shallow oceanic problem
with details available in Sections 6.4 and 7.5. The basic adaptive problem can be
deined in terms of the mathematical models as:
GIVEN, [{p(rs, z�)}, {c(z�)}], a set of noisy pressure-ield and sound-speed mea-
surements varying in depth along with the underlying state–space model of Eqs.
11.147, 11.148, and 11.150 with unknown parameters {�(z�)}, FIND the “best”
(minimum error variance) estimates (joint) of the modal functions and parameters,
that is, { ̂�m(z�)}, {̂�m(z�)}; m = 1, … , M and measurements {̂p(rs, z�)}.
The solution to this problem lies in the joint state/parameter estimation problem,
that is, deining the augmented state vector,
�(z�; �) :=
⎡
⎢
⎢⎣
�(z�)
−−−
�
⎤
⎥
⎥⎦
and starting with the joint distribution applying Bayes’ theorem, we obtain
Pr[�(z�; �)|P�] =
⎛
⎜
⎜
⎜⎝
Pr
[
p(rs, z�)|�(z�; �)
]
× Pr
[
�(z�; �)|�(z�−1; �)
]
Pr
[
p(rs, z�)|P�−1
]
⎞
⎟
⎟
⎟⎠
× Pr[�(z�−1; �)|P�−1]
(11.152)
where we have assumed conditional independence and deined the set of measure-
ments as P�:= {p(rs, z1), … , p(rs, z�)}.
Deine the joint weighting function in terms of the likelihood, transition, and
evidence as (see Section 2.5 for details)
W(z�; �) :=
⎛
⎜
⎜
⎜⎝
Pr
[
p(rs, z�)|�(z�; �)
]
× Pr
[
�(z�; �)|�(z�−1; �)
]
Pr
[
p(rs, z�)|P�−1
]
⎞
⎟
⎟
⎟⎠
(11.153)

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
563
yielding the sequential Bayesian posterior distribution as
Pr[�(z�; �)|P�] = W(z�; �) × Pr[�(z�−1; �)|P�−1]
(11.154)
In this study, we are interested in investigating the applicability of the PFof
Section 7.5 and the unscented Kalman ilter (UKF) of Section 6.3 with the goal
of analyzing their performance on pressure-ield data obtained from the well-known
Hudson Canyon experiments performed on the New Jersey shelf [61, 62]. Recall that
the PF is a sequential MCMC Bayesian processor capable of providing reasonable
performance for a multi-modal (multiple peaked) distribution problem estimating
a nonparametric representation of the posterior distribution. On the other hand, the
UKF is a processor capable of representing any unimodal (single-peaked) distribution
using a statistical linearization technique based on sigma points that deterministically
characterize the posterior.
Here, we are concerned with the joint estimation problem consisting of setting a
prior for �and augmenting the state vector to solve the problem as deined above
thereby converting the parameter estimation problem to one of optimal iltering. Thus,
the particle ilter estimates the weights required to specify the posterior distribution,
empirically, that is,
̂Pr[�(z�; �)|P�] ≈1
Np
Np
∑
i=1
̂Wi(z�; �) × �(�(z�; �) −�i(z�; �)) (11.155)
The approach we chose for our problem is to estimate these weights based on the
concept of importance sampling (see Section 3.6). Recall that importance sampling
is a technique to compute statistics with respect to one distribution using random
samples drawn from another. It is a method of simulating samples from a proposal or
sampling (importance) distribution to be used to approximate a targeted distribution
(joint posterior) by appropriate weighting. For this choice, the weighting function is
deined by
(z�; �) := Pr[�(z�; �)|P�]
q[�(z�; �)|P�]
(11.156)
where q[⋅] is the proposed sampling or importance distribution.
For the “sequential” case we have that the weighting function becomes
(z�; �) ∝
⎛
⎜
⎜
⎜⎝
Pr
[
p(rs, z�)|�(z�; �)
]
× Pr
[
�(z�; �)|�(z�−1; �)
]
q[�(z�; �)|�(z�−1; �), P�]
⎞
⎟
⎟
⎟⎠
× (z�−1; �)
(11.157)
where ∝means proportional to up to a normalizing constant (evidence).

564
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
There are a variety of PF algorithms available, each evolving by a particular choice
of the sampling or importance distribution, but the simplest is the bootstrap technique
which we apply to our problem. Here, the importance distribution is selected as the
transition prior, that is,
q
[
�(z�; �)|�(z�−1; �), P�)
]
⟶Pr
[
�(z�; �)|�(z�−1; �)
]
(11.158)
and substituting into Eq. 11.157, we obtain
(z�; �) = Pr
[
p(rs, z�)|�(z�; �)
]
× (z�−1; �)
(11.159)
Thus, we see that once the underlying posterior is available, the estimates of
important statistics can be inferred directly. For instance, the MAPestimate is simply
found by locating a particular particle ̂�i(z�) corresponding to the maximum of the
PMF, that is, ̂�i(z�; �)MAP, while the conditional mean estimate is calculated by
integrating the posterior to give ̂�i(z�; �)CM.
For the bootstrap implementation, we need only draw noise samples from the state
and parameter distributions and use the dynamic models above (normal-mode/random
walk) in Eq. 11.147 to generate the set of particles {�i(z�; �)} ⟶{�i(z�), �i(z�)}
for i = 1, … , Np. That is, both sets of particles are generated from the augmented
models (linear/nonlinear) for each individual case (adaptive modal coeficients or
adaptive wavenumbers) from
�i(z�; Θ) =
{ A(z�−1)�i(z�−1) + wi(z�−1)
(Case i: modal coeficients)
a
[
�i(z�−1; Θ)
]
+ wi(z�−1)
(Case ii: wavenumbers)
(11.160)
while the likelihood is determined from the nonlinear pressure-ield measurement
model
p(rs, z�) = c
[
�i(z�; Θ)
]
+ �(z�)
(11.161)
Assuming additive Gaussian noise the likelihood probability is given by
Pr[p(rs, z�)|�i(z�)] =
1
√
2�R��
× exp
{
−
1
2R��
(p(rs, z�) −c [�i(z�; Θ)])2
}
(11.162)
Thus, we estimate the posterior distribution using a sequential Monte Carlo
approach and construct a bootstrap particle ilter using the following steps:
r Initialize: �i(0), wi ∼(0, R��), Wi(0) = 1∕Np; i = 1, … , Np;

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
565
r State transition: �i(z�; Θ) =
{ A(z�−1)�i(z�−1) + wi(z�−1)
(Case i)
a
[
�i(z�−1; Θ)
]
+ wi(z�−1)
(Case ii);
r Likelihood probability: Pr[p(rs, z�)|�i(z�)] of Eq. 11.162;
r Weights: Wi(z�; �) = Wi(z�−1; �) × Pr[p(rs, z�)|�i(z�)];
r Normalize: i(z�; �) =
Wi(z�;�)
∑Np
i=1 Wi(z�;�);
r Resample: ̃�i(z�; �) ⇒�i(z�; �);
r Posterior:
̂Pr[�(z�; �)|P�] = ∑Np
i=1 i(z�: �) × �(�(z�; �) −�i(z�; �));
and
r MAP estimate: ̂�i(z�; �)MAP = max
i
̂Pr[�i(z�; �)|P�];
r MMSE (CM) estimate: ̂�i(z�; �)MMSE =
1
Np
∑Np
i=1 i(z�; �) × �i(z�; �).
The particle ilter (bootstrap) algorithm of Section 7.5 is illustrated with the pre-
diction and update steps along with a resampling algorithm to provide convergence.
11.6.3
Model-Based Ocean Acoustic Processing
In this section, we discuss the development of the propagators for the Hudson Canyon
experiment performed in 1988 in the Atlantic with the primary goal of investigating
acoustic propagation (transmission and attenuation) using continuous wave data [61,
62]. The Hudson Canyon is located off the coast of New Jersey in the area of the
Atlantic Margin Coring project borehole 6010. The seismic and coring data are
combined with sediment properties measured at that site. Excellent agreement was
determined between the model and data indicating a well-known, well-documented
shallow water experiment with bottom interaction and yielding ideal data sets for
investigating the applicability of an MBP to measured ocean acoustic data. The
experiment was performed at low frequencies (50–600 Hz) in shallow water of 73 m
depth during a period of calm sea state. A calibrated acoustic source was towed at
roughly 36 m depth along the 73-m isobath radially to distances of 4–26 km. The
ship speed was between 2 and 4 knots. The ixed vertical hydrophone array consisted
of 24 phones spaced 2.5 m apart extending from the sealoor up to a depth of about
14 m below the surface. The CTD and SSP measurements were made at regular
intervals and the data were collected under carefully controlled conditions in the
ocean environment. The normalized horizontal wavenumber spectrum for a 50 Hz
temporal frequency is dominated by ive modes occurring at wavenumbers between
0.14 and 0.21 m−1 with relative amplitudes increasing with increased wavenumber. A
SNAP [37] simulation was performed and the results agree quite closely, indicating
a well-understood ocean environment.
In order to construct the state–space propagator, we require the set of param-
eters which were obtained from the experimental measurements and processing

566
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
(wavenumber spectra). The horizontal wavenumber spectra were estimated using
synthetic aperture processing [61]. Eight temporal frequencies were employed: four
on the inbounds (75 Hz, 275 Hz, 575 Hz, 600 Hz) and four on the outbound (50 Hz,
175 Hz, 375 Hz, 425 Hz). In this application, we will conine our investigation to
the 50 Hz case, which is well documented, and to horizontal ranges from 0.5 to 4
km. The raw measured data was processed (sampled, corrected, iltered, etc.) and
supplied for this investigation. For this investigation, we used a single snapshot of
the pressure-ield across the vertical array.
11.6.3.1
Adaptive PF Design: Modal Coeficients
The design and
development of the environmentally adaptive PF proceeds through the following
steps: (1) preprocessing the raw experimental data; (2) solving the BVP [37] to
obtain initial parameter sets for each temporal frequency (e.g., modal coeficients,
wavenumbers, initial conditions.); (3) state–space forward propagator simulation of
synthetic data for PF analysis/design; (4) application to measured data; and (5) PF
performance analysis.
Preprocessing of the measured pressure-ield data follows the usual pattern of
iltering, outlier removal and Fourier-transforming to obtain the complex pressure-
ield as a function of depth along the array. These data along with experimental
conditions (frequencies, current-temperature-density (CTD), sound-speed proiles
(SSP), boundary conditions, horizontal wavenumber estimators (see Ref. [61] for
details) provide the input to the normal mode BVP solutions (SNAP [37]) yielding
the output parameters. These parameters are then used as input to the state–space
forward propagator developed previously.
The state–space propagator is then used to develop a set of synthetic pressure-ield
data with higher resolution than the original raw data (e.g., 46-element array rather
than 23-element at half-wave inter-element spacing). This set represents the “truth”
data that can be investigated when “tuning” the PF (e.g., number of particles, covari-
ances). Once tuned, the processors are applied directly to the measured pressure-ield
data (23-elements) after re-adjusting some of the processor parameters (covariances).
Here, the performance metrics are estimated and processor performance analyzed.
Since each run of the PF is a random realization, that is, the process noise inputs
are random, an ensemble of results are estimated with its statistics presented. In this
way, we can achieve a detailed analysis of the processor performance prior to ielding
and operational version. We constrain our discussion results to processing the noisy
experimental pressure-ield measurements.
We performed a series of “tuning” runs for both the UKF and PF. We primarily
adjusted the process noise covariance matrix (R��) for each of the modal functions
and then executed a 100-member ensemble of realizations using these parameters.
The particle ilter was designed with the same parameters and 1500-particles were
used to characterize the posterior PMF at each depth. Resampling (see Section 7.4)
was applied at every iteration of the PF to avoid any potential degradation.
First, we investigate the enhancement capabilities of the PF in estimating the
pressure-ield over a 100-member ensemble shown in Fig. 11.34. The resulting igures
show the averaged PF estimates. We observe the raw data (Data) as well as both MAP

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
567
−0.01 −0.005
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
−60
−50
−40
−30
−20
−10
0
Pressure
Depth (m)
Pressure-field estimation: ensemble = 100
CM
Data
Error
Map
FIGURE 11.34
Raw/enhanced pressure-ield (Data) data from the Hudson Canyon
experiment using particle ilter estimators with adaptive modal coeficients: maximum
a-posteriori (MAP), conditional mean (CM) and the corresponding innovations (Error)
sequence.
and CM estimates. Both estimators are capable of tracking the ield quite well and
even ilter the erratic measurements near the bottom of the channel. The innovations
or residuals (Error) are also shown in the igure. Both estimators are capable of
tracking and enhancing the pressure-ield. Using classical performance (sanity tests)
metrics on the innovations sequence (Error), the zero-mean/whiteness tests, both
processors satisfy the criteria of unbiasedness (Z-M: 6.2 × 10−4 < 4.9 × 10−1) and
uncorrelated innovations, that is, less than 5% exceeding the bound (6.3%). The
WSSRtest of Section 5.7 is also applied with satisfactory results, that is, no samples
exceed the threshold indicating a functionally “tuned” processor. The UKF processor
also produced reasonable results for the enhanced pressure-ield (not shown).
Ensemble mode tracking results are shown in Fig. 11.35 for each of the modal
function estimators, the PF (MAP/CM) and the UKF. In Fig. 11.35, we observe the
performance of the PF which appears to track the modes quite well compared to the
UKF. It is interesting to note that the modal coeficient estimates are constantly being
adapted (adjusted) by the processor throughout the runs attesting to the nonstationary
nature of the ocean statistics as illustrated in Fig. 11.36.

568
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
−0.05
0
0.05
−60
−50
−40
−30
−20
−10
0
Mode est. No. 1 
Modal amplitude
−0.02
0
0.02
Modal amplitude
−0.02
0
0.02
Modal amplitude
−0.01
0
0.01
Modal amplitude
−0.01
0
0.01
Modal amplitude
Depth (m)
−60
−50
−40
−30
−20
−10
0
Depth (m)
−60
−50
−40
−30
−20
−10
0
Depth (m)
−60
−50
−40
−30
−20
−10
0
Depth (m)
−60
−50
−40
−30
−20
−10
0
Depth (m)
Mode est. No. 2 
Mode est. No. 3 
Mode est. No. 4 
Mode est. No. 5 
Data
UKF
MAP/CM
MAP/CM
UKF
UKF
Data
Data
Data
Data
MAP/CM
MAP/CM
MAP/CM
UKF
UKF
FIGURE 11.35
Modal function tracking with adaptive modal coeficient estimation:raw
experimental data (Data),unscented Kalman ilter (UKF),maximum a-poster (MAP) (cir-
cles) and conditional mean (CM) (squares) particle ilters.
0
1
2
3
−10
0
−20
−30
−40
−50
−60
Parameter est. No. 1 
Parameter
amplitude
Parameter
amplitude
Parameter
amplitude
Depth (m)
−10
0
−20
−30
−40
−50
−60
Depth (m)
−10
−20
−30
−40
−50
−60
Depth (m)
−10
−20
−30
−40
−50
−60
Depth (m)
−10
−20
−30
−40
−50
−60
Depth (m)
0
0.5
1
Parameter
amplitude
0
0.2
0.4
Parameter
amplitude
0
0.2
0.4
Parameter est. No. 2 
−0.5
−1
0
0.5
Parameter est. No. 3 
Parameter est. No. 4 
Parameter est. No. 5 
MODEL
MODEL
MODEL
MODEL
MODEL
Parameter
est.
Parameter
est.
Parameter
est.
Parameter
est.
Parameter
est.
FIGURE 11.36
Adaptive modal coeficient parameter estimation data (Model) from
the Hudson Canyon experiment using the MAP particle ilter (Parameter est.).

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
569
0
−10
−20
Pressure-field estimation:
ensemble = 100
−30
−40
Error
Data
CM
MAP
−50
−60
−0.01
0
0.01
0.02
0.03
Pressure
0.04
0.05
0.06
0.07
Depth (m)
FIGURE 11.37
Raw pressure-ield data/enhanced data (Data) from the Hudson
Canyon experiment for a 23-element hydrophone vertical array using particle ilter esti-
mators with adaptive wavenumber processing: maximum a-posteriori (MAP), condi-
tional mean (CM), and the corresponding innovations (Error) sequence.
This completes the analysis of the Hudson Canyon experimental data for the
adaptive (modal coeficient) PF processing performance.
11.6.3.2
Adaptive PF Design: Wavenumbers
As before in the modal
coeficient case, we investigate the enhancement capabilities of the PF in estimating
the pressure-ield over a 100-member ensemble shown in Fig. 11.37. Using 1500-
particles, we see the raw hydrophone data (dashed line) from the experiment as well
as both MAP estimates (circles) and CM estimates (dotted line with circles). Both
estimators appear to track the ield quite well (true (mean) solution in dashes). The
corresponding innovations (residual) sequence is also shown (diamonds). Classically,
both estimators produced satisfactory zero-mean/statistical whiteness tests as well as
the WSSR tests indicating a “tuned” processor [38].
The ensemble mode tracking results are shown in Fig. 11.38 for each of the modal
function estimators, the PF (MAP/CM) and the UKF. In Fig. 11.38, we observe

570
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
Mode est. No. 1
0
−10
Map
Map
Map
Map
Map
CM
CM
CM
CM
CM
UKF
Model
Model
Model
Model
Model
UKF
UKF
UKF
UKF
−20
−30
Depth (m)
−40
−50
−60
0
−10
−20
−30
Depth (m)
−40
−50
−60
0
−10
−20
−30
Depth (m)
−40
−50
−60
0
−10
−20
−30
Depth (m)
−40
−50
−60
0
−10
−20
−30
Depth (m)
−40
−50
−60
−0.05
0
0.05
−0.02
0
0.02
−0.02
−0.01
0
0.01
−0.01
0
0.01
0
0.02
Modal amplitude
Modal amplitude
Modal amplitude
Modal amplitude
Modal amplitude
Mode est. No. 2
Mode est. No. 3
Mode est. No. 4 Mode est. No. 5
FIGURE 11.38
Modal function tracking for adaptive wavenumber estimation: Hudson
Canyon data (Model) of a 23-element array, unscented Kalman ilter (UKF), maximum
a-posteriori (MAP) and conditional mean (CM) (squares) particle ilters.
that the performance of the PF appears to track the modes quite well and better
than the UKF. The root-mean-squared (modal tracking) error for each mode is quite
reasonable on the order of 10−5 again conirming their performance. It is interesting
to note that the wavenumber estimates are constantly being adapted (adjusted) by
the processor throughout the runs attesting to the nonstationary nature of the ocean
statistics. The ensemble average wavenumber estimates are very reasonable: (0.206,
0.197, 0.181, 0.173, 0.142; (True) 0.208, 0.199, 0.183, 0.175, 0.142. The PF and CM
ensemble estimates are very close to the true values adapting to the changing ocean
environment yet still preserving wavenumber values on the average.
We also illustrate the multi-modal aspect of the oceanic data by observing the
modal function posterior probability PDF estimates for mode 5 illustrated in Fig.
11.39. It is clear from the plots that for each depth multiple peaks appear in the
posterior estimates. The wavenumber PDF estimate corresponding to mode 5 is
shown in Fig. 11.40. Again, we note the multiple, well-deined peaks in the posterior
distribution leading to the MAP parameter estimate.
This completes the analysis of the synthesized Hudson Canyon experiment and
the PF processing performance.

11.6
ADAPTIVE PROCESSING FOR SHALLOW OCEAN APPLICATIONS
571
Mode no. 5: posterior distribution
Depth (m)
0.05
0.04
0.03
0.02
0.01
0
60
50
40
30
20
10
0 −0.01 −0.05
0
0.005
0.01 0.015
0.02
Modal amplitude
FIGURE 11.39
Probability mass function (PMF) posterior estimation (mode 5) surface
for Hudson Canyon 23-element array data (particle vs. time vs. probability).
Mode no. 5: wavenumber posterior distribution
Depth (m)
0.045
0.04
0.035
0.03
0.025
0.02
0.015
0.01
0.005
0
60
50
40
30
10
20
0 0.1423
0.1423
0.1423
0.1423
0.1423
Wavenumber
FIGURE 11.40
Probability mass function (PMF) posterior estimation (wavenumber 5)
surface for Hudson Canyon 23-element array data (particle vs. time vs. probability).

572
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
11.6.4
Summary
In this study, we have discussed the development of environmentally adaptive proces-
sors capable of tracking modes and enhancing the raw pressure-ield measurements
obtained from a vertical hydrophone array in shallow water. The parametric adaption
was based on simultaneously estimating either the modal coeficients or the hori-
zontal wavenumbers along with the modes and pressure-ield as the environmental
parameters of interest. These wavenumber parameters were more challenging from a
processor design perspective because of their increased sensitivity to environmental
change compared to the modal coeficients. We chose a Bayesian sequential design
because of the varying nature of the shallow ocean and applied a normal-mode model
in state–space form to create a forward propagator. The algorithms applied were the
unscented Kalman ilter and the particle ilter, both modern approaches applied to this
problem (see Chapters 6 and 7). We compared their performance and found slightly
better results of the PF over a 100-member ensemble. These results with more detail
can be found in a recent paper [65].
REFERENCES
1. D. Speck, E. Bliss, J. Glaze, J. Herris, F. Holloway, J. Hun, B. Johnson, D. Kuizenga,
R. Ozarski, H. Patton, P. Ruppert, G. Suski, C. Swift, and C. Thompson, “The Shiva
laser-fusion facility,” IEEE J. Quantum Electr., 17, 9, 1599–1619, 1981.
2. J. Liu, H. Furuhashi, A. Torii, R. Sharma, V. Chitnis, B. Singh, J. Yamada, and Y. Uchida,
“Automatic mask alignment in the theta direction using moir sensors,” Nanotechnology,
6, 135–138, 1995.
3. W. Blum, H. Kroha, and P. Widmann, “A novel laser-alignment system for tracking
detectors using transparent silicon strip sensors,” IEEE Trans. Nuclear Sci., 43, 3, 1194–
1199, 1996.
4. G. Seward, J. Leszcynski, and E. Mulhern, “Rapid alignment of laser beams within optical
systems,” Opt. Eng., 36, 5, 1414–1420, 1997.
5. A. Adolph, A. Boscheron, A. Dulac, and E. Journot, “Final optics design for the megajoule
laser,” SPIE Proc., 3492, 1-2, 44–50, 1999.
6. W. He, Q. Chen, R. Xu, Z. Peng, H. Yang, C. Zhu, and J. Zhao, “Image transfer based
automatic alignment technique for laser-fusion facility,” Acta Opt. Sin., 19, 9, 1279–1283,
1999.
7. S. Roth, S. Schael, and G. Schmidt, “A test of the laser alignment system ALMY at the
TTF-FEL,” Nucl. Instr. Methods Phys. Res. A, 475, 537–544, 2001.
8. N. Fleurot, A. Adolf, M. Andre, J. Bruneau, C. Cavailler, M. Novaro, P. Philippe, F.
Kovacs, B. Le Garrec, J. Di Nicola, and J. Leidinger, “The ligne dintegration laser (LIL):
construction status and irst 1-w early results,” Proc. SPIE, 4948, 418–424, 2003.
9. D. Liu, J. Zhu, R. Zhu, and D. Fan, “Laser beam automatic alignment in multipass
ampliier,” Opt. Eng., 43, 9, 2066–2070, 2004.
10. R. Zacharias, N. Beer, E. S. Bliss, S. Burkhart, S. Cohen, S. Button, R. Van Atta,
S. Winters, J. Salmon, M. Latta, C. Stoiz, D. Pigg, and T. Arnold, “Alignment and

REFERENCES
573
wavefront control systems of the National Ignition Facility,” Opt. Eng., 43, 12, 2873–2884,
2004.
11. J. Candy, W. Mcclay, A. Awwal, and S. Ferguson, “Optimal position estimation for the
automatic alignment of a high energy laser beam,” J. Opt. Soc. Amer., 22, 7, 1348–1356,
2005.
12. E. Moses, “The national ignition facility comes to life,” Science & Technology Review,
LLNL Report, pp. 4–14, September 2003.
13. F. Holderner, E. Ables, E. Bliss, S. Boege, R. Boyd, C. Chocol, D. Davis, R. Demaret, R.
English, C. Laumann, J. Miller, and S. Thomas, “Beam control and diagnostic functions
in the NIF transport spatial ilter,” Proc. SPIE, 3047, 692–699, 1997.
14. E. Bliss, F. Holderner, J. Salmon, and J. Severyn, “Beam control and laser diagnostic
systems,” LLNL Report, UCRL-LR-105821-99-1, pp. 79–97, 1999.
15. A. Awwal, W. Mcclay, W. Ferguson, J. Candy, T. Salmon, and P. Wegner, “Composite
amplitude modulated phase-only ilter based detection and tracking of the back-relection
of KDP images,” in Photonic Devices and Algorithms for Computing VI, Proceedings of
SPIE 5556, 2004.
16. K. Castleman, Digital Image Processing (Prentice-Hall, 1979).
17. A. Parvulescu, “Signal detection in a multipath medium by MESS processing,” J. Acoust.
Soc. Am., 29, 223–228, 1965.
18. E. Westwood, “Broadband matched-ield source localization,” J. Acoust. Soc. Am., 91, 5,
2777–2789, 1992.
19. C. Clay, “Optimum time domain signal transmission and source localization in a waveg-
uide,” J. Acoust. Soc. Am., 81, 660–664, 1987.
20. S. Li and C. Clay, “Optimum time domain signal transmission and source localization
in a waveguide: experiments in an ideal wedge waveguide,” J. Acoust. Soc. Am., 82,
1409–1417, 1987.
21. R. Brienzo and W. Hodgkiss, “Broadband matched-ield processing,” J. Acoust. Soc. Am.,
94, 1409–1417, 1994.
22. A. Baggeroer, W. Kuperman, and H. Schmidt, “Matched-ield processing: source local-
ization in correlated noise as an optimum parameter estimation problem,” J. Acoust. Soc.
Am., 83, 2, 571–587, 1988.
23. T. Yang, “Broadband source localization and signature estimation,” J. Acoust. Soc. Am,
93, (4), 1797–1806, 1993.
24. J. Candy and E. Sullivan, “Ocean acoustic signal processing: a model-based approach,” J.
Acoust. Soc. Am., 92, 12, 3185–3201, 1992.
25. E. Sullivan, Model-Based Processing for Underwater Acoustic Arrays (New York:
Springer, 2015).
26. J. Candy and E. Sullivan, “Broadband model-based processing for shallow ocean envi-
ronments,” J. Acoust. Soc. Am., 104, 1, 275–287, 1998.
27. J. Candy, “Broadband processing in a noisy shallow ocean environment: a particle iltering
approach,” IEEE J. Oceanic Engr., 41, 1, 1-16, 2016.
28. C. Clay and H. Medwin, Acoustical Oceanography (New York: John Wiley & Sons, Inc.,
1977).
29. F. Jensen, W. Kuperman, M. Porter, and H. Schmidt, Computational Ocean Acoustics
(New York: AIP Press, 1994).

574
BAYESIAN PROCESSORS FOR PHYSICS-BASED APPLICATIONS
30. A. Robinson and D. Lee, Oceanography and Acoustics (New York: AIP Press, 1994).
31. M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp, “A tutorial on particle ilters
for online nonlinear/non-gaussian Bayesian tracking,” IEEE Trans. Sig. Process., 50, 2,
174–188, 2002.
32. H. Van Trees, Detection, Estimation and Modulation Theory, Part 1 (New York: John
Wiley & Sons, Inc., 1968).
33. A. Wald, Sequential Analysis (New York: John Wiley & Sons, 1947) (Reprint by Dover
Publications, 1973).
34. A. Papoulis and S. Pillai, Probability, Random Variables and Stochastic Processes, 4th
Ed. (New York: McGraw-Hill, 2002).
35. C. Andrieu, A. Doucet, S. Singh, and V. Tadic, “Particle methods for change detection,
system identiication and control,” Proc. IEEE, 92, 3, 423–438, 2004.
36. P. Li and V. Kadirkamanathan, “Particle methods based likelihood-ratio approach to fault
diagnosis in nonlinear stochastic systems,” IEEE Trans. Syst. Man Cyber. C, 31, 3, 337–
342, 2001.
37. F. Jensen and M. Ferla, “SNAP: the SACLANTCEN normal-mode acoustic propagation
model,” SACLANTCEN Report, SM-121, SACLANT Undersea Research Centre, La
Spezia, Italy, 1982.
38. J. Candy, Model-Based Signal Processing (Hoboken, NJ: Wiley/IEEE Press, 2006).
39. Y. Tang, J. Fang, X. Xu, H. Ji, G. Brown, and T. Thundat, “Detection of femtomolar
concentrations of HF using SiO2 microcantilever,” Anal. Chem., 76, 2478–2481, 2004.
40. M. Su, S. Li, and V. Dravid, “Microcantilever resonance-based DNA detection with
nanoparticle probes,” Appl. Phys. Lett., 82, 3562–3564, 2003.
41. G. Muralidharan, A. Wig, L. Pinnaduwage, D. Hedden, T. Thundat, and R. Lareau,
“Absorption-desorption characteristics of explosive vapors investigated with microcan-
tilevers,” Ultramicroscopy, 97, 433–439, 2003.
42. R. Raiteri, M. Grattarola, H. J. Butt, and P. Skladal, “Micromechanical cantilever-based
biosensors,” Sens. Actuators B Chem., 79, 115–126, 2001.
43. N. Lavrik, C. Tipple, M. Sepaniak, and P. Datskos, “Gold nano-structures for transduction
of biomolecular interactions into micrometer scale movements,” Biomed. Microdevices,
3, 35–44, 2001.
44. J. Tringe, D. Clague, J. Candy, A. Simensky, C. Lee, R. Rudd, and A. Burnham, “A
model-based processor design for smart microsensor arrays,” IEEE J. MEMS Syst., 15, 5,
1379–1391, 2006.
45. J. Candy, D. Clague, and J. Tringe, “Model-based processing of microcantilever sensor
arrays,” IEEE Signal Process. Magaz., 24, 1, 125–126, 2007.
46. P. Gill, W. Murray, and M. Wright, Practical Optimization (New York: Academic Press,
1981).
47. D. Snyder and M. Miller, Random Point Process in Time and Space (New York: Springer-
Verlag, 1991).
48. R. Evans, The Atomic Nucleus (New York: McGraw-Hill, 1985).
49. G. F. Knoll, Radiation Detection and Measurement, 3rd Ed. (Hoboken, NJ: John Wiley &
Sons, Inc., 2000).
50. G. Gilmore and J. Hemingway, Practical Gamma-Ray Spectrometry (Hoboken, NJ: John
Wiley & Sons, Inc., 2003).

REFERENCES
575
51. N. Carron, An Introduction to the Passage of Energetic Particles through Matter (New
York: Taylor & Francis Group, 2007).
52. S. Gulam Razul, W. Fitzgerald, and C. Andrieu, “Bayesian model selection and parameter
estimation of nuclear emission spectra using RJMCMC,” Nucl. Instrum. Methods Phys.
Res. A, 497, 492–510, 2003.
53. E. Barat and J. Heikkinen, “An algorithm for nonparametric Bayesian estimation of a
Poisson intensity,” Comput. Statist., 12, 3, 385–402, 1997.
54. J. Candy, E. Breitfeller, B. Guidry, D. Manatt, K. Sale, D. Chambers, M. Axelrod, and
A. Meyer, “Physics-based detection of radioactive contraband: a sequential Bayesian
approach,” IEEE Trans. Nucl. Sci., 56, 6, 3694–3711, 2009.
55. J. Candy, D. Chambers, E. Breitfeller, B. Guidry, K. Sale, M. Axelrod, and A. Meyer,
“Threat detection of radioactive contraband incorporating Compton scattering physics: a
model-based processing approach,” IEEE Trans. Nucl. Sci., 58, 1, 214–230, 2011.
56. J. Liu, Monte Carlo Strategies in Scientiic Computing (New York: Springer-Verlag, 2001).
57. D. Middleton, An Introduction to Statistical Communication Theory (New York: McGraw-
Hill, 1960).
58. A. Kak and M. Slaney, Principles of Computerized Tomographic Imaging (New York:
IEEE Press, 1988).
59. J. Candy, “Physics-based X-ray processing: a feasibility study,” LLNL Report, UCID-TR-
12345, 2012.
60. C. Yardim, Z-H. Michalopoulou, and P. Gerstoft, “An overview of sequential Bayesian
iltering in ocean acoustics,” IEEE J. Oceanic Eng., 36, 1, 73–91, 2011.
61. W. Carey, J. Doutt, R. Evans, and L. Dillman, “Shallow watertransmission measurements
taken on the New Jersey continental shelf,” IEEE J. Oceanic Eng., 20, (4), 321–336, 1995.
62. A. Rogers, Y. Yamamoto, and W. Carey, “Experimental investigation of sediment effect on
acoustic wave propagation in shallow water,” J. Acoust. Soc. Am., 93, 1747–1761, 1993.
63. M. Porter, “The KRAKEN normal mode program,” Report SM-245, SACLANTCEN,
Italy, pp. 183, 1991.
64. H. Schmidt, “SAFARI: Seismo-acoustic fast ield algorithm for range independent envi-
ronments,” Report SM-245, SACLANTCEN, Italy, pp. 142, 1987.
65. J. Candy, “Environmentally adaptive processing for shallow ocean applications: a sequen-
tial Bayesian approach,” J. Acoust. Soc. Am., 138, 3, 1268–1281, 2015.

Appendix
PROBABILITY AND
STATISTICS OVERVIEW
A.1
PROBABILITY THEORY
Deining a sample space (outcomes) Ω, a ield (events) B, and a probability function
(on a class of events) Pr, we can construct an experiment as the triple {Ω, B, Pr}.
Example A.1
Consider the experiment {Ω, B, Pr} of tossing a fair coin, then we see that
Sample space:
Ω
= {H, T}
Events:
B
= {0, {H}, {T}}
Probability:
Pr(H) = p
Pr(T) = 1 −p
△△△
With the idea of a sample space, probability function, and experiment in mind,
we can now start to deine the concept of a discrete random signal more precisely.
We deine a discrete random variable as a real function whose value is determined
by the outcome of an experiment. It assigns a real number to each point of a sample
space Ω, which consists of all the possible outcomes of the experiment. A random
variable X and its realization x are written as
X(�) = x
for ��Ω
(A.1)
Consider the following example of a simple experiment.
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
576

A.1
PROBABILITY THEORY
577
Example A.2
We are asked to analyze the experiment of lipping a fair coin, then the sample space
consists of a head or tail as possible outcomes, that is,
Ω = {0 H T} ⟹X(�) = x
�= {H, T}
If we assign a 1 for a head and 0 for a tail, then the random variable X performs the
mapping of
X(�= H)= x(H) = 1
X(�= T) = x(T) = 0
where x(.) is called the sample value or realization of the random variable X. △△△
A probability mass function is deined in terms of the random variable, that is,
PX(xi) = Pr(X(�i) = xi)
(A.2)
and the probability distribution function is deined by
FX(xi) = Pr(X(�i) ≤xi)
(A.3)
These are related by
PX(xi) =
∑
i
FX(xi)�(x −xi)
(A.4)
FX(xi) =
∑
i
PX(xi)�(x −xi)
(A.5)
where �and �are the unit impulse and step functions, respectively.
It is easy to show that the distribution function is a monotonically increasing
function (see Papoulis [1] for details) satisfying the following properties:
lim
xi→−∞FX(xi) = 0
and
lim
xi→∞FX(xi) = 1
These properties can be used to show that the mass function satisies
∑
i
PX(xi) = 1

578
PROBABILITY AND STATISTICS OVERVIEW
Either the distribution or the probability mass function completely describes the
properties of a random variable. Given either of these functions, we can calculate
probabilities that the random variable takes on values in any set of events on the
real line.
To complete our coin tossing example, if we deine the probability of a head
occurring as p, then we can calculate the distribution and mass functions as shown in
the following example.
Example A.3
Consider the coin tossing experiment and calculate the corresponding mass and
distribution functions. From the previous example, we have
Sample space:
Ω
= {H, T}
Events:
B
= {0, {H}, {T}}
Probability:
PX(x1 = H) = p
PX(x0 = T) = 1 −p
Random variable:
X(�1 = H) = x1 = 1
X(�2 = T) = x2 = 0
Distribution:
FX(xi)
=
⎧
⎪
⎨
⎪⎩
1
xi ≥1
1 −p
0 ≤xi ≤1
0
xi < 0
The mass and distribution functions for this example are shown in Fig. A.1. Note that
the sum of the mass function value must be 1, and that the maximum value of the
distribution function is 1 satisfying the properties mentioned previously.
△△△
If we extend the idea that a random variable is now a function of time as well,
then we can deine a stochastic process as discussed in Chapter 2. More formerly, a
random or stochastic process is a two-dimensional function of t and �:
X(t, �)
��Ω,
t�T
(A.6)
p
p
Px(x)
Px(x)
0
0
1
1
1
x
x
•
•
•
•
Fx(x)
(1 − p)
(1 − p)
=
1 − p
p
O
x = 0
x = 1
Otherwise
FIGURE A.1
Probability mass and distribution functions for the coin-tossing experiment.

A.1
PROBABILITY THEORY
579
where T is a set of index parameters (continuous or discrete) and Ω is the sample
space.
We list some of the major theorems in probability theory and refer the reader to
more detailed texts [1, 2].
Univariate:
Pr(X)
= PX(x)
Bivariate:
Pr(X, Y)
= PXY(x, y)
Marginal:
Pr(X)
= ∑
y PXY(x, y)
Independent:
Pr(X, Y)
= PX(x) × PY(y)
Conditional:
Pr(X|Y)
= PXY(x, y)∕PY(y)
Chain Rule:
Pr(X, Y, Z) = Pr(X|Y, Z) × Pr(Y|Z) × Pr(Z)
For a random variable, we can deine basic statistics in terms of the probability
mass function. The expected value or mean of a random variable X, is given by
mx = E{X}
and is considered the typical or representative value of a given set of data. For
this reason, the mean is called a measure of central tendency. The degree to which
numerical data tend to spread about the expected value is usually measured by the
variance or equivalently, auto-covariance given by
Rxx = E{(X −mx)2}
The basic statistical measures are called ensemble statistics because they are measured
across the ensemble (i = 1, 2, …) of data values, that is, the expectation is always
assumed over an ensemble of realizations. We summarize these statistics in terms of
their mass function as
Expected value: mx =
E{X}
= ∑
i XiPX(xi)
Nth-moment:
E{Xn}
= ∑
i Xn
i PX(xi)
Nth-moment about mean:
E{(X −mx)n} = ∑
i(Xi −mx)nPX(xi)
Mean-squared (N = 2):
E{X2}
= ∑
i X2
i PX(xi)
Variance: Rxx =
E{(Xi −mx)2} = ∑
i(Xi −mx)2PX(xi)
Covariance:
Rxy
= E{(Xi −mx)(Yj −my)}
Standard deviation:
�xx
=
√
Rxx
Conditional mean:
E{X|Y}
= ∑
i XiP(Xi|Y)
Joint conditional mean:
E{X|Y, Z}
= ∑
i XiP(Xi|Y, Z)
Conditional variance:
Rx|y
= E{(X −E{X|Y})2|Y}
These basic statistics possess various properties that enable them to be useful for
analyzing operations on random variables, some of the more important1 are
1 Recall that independence states that the joint mass function can be factored, Pr(x, y) = Pr(x) × Pr(y), which
leads to these properties.

580
PROBABILITY AND STATISTICS OVERVIEW
Linearity:
E{ax + b}
= aE{x} + b = amx + b
Independence:
E{xy}
= E{x}E{y}
Variance:
Rxx(ax + b) = a2Rxx
Covariance
Uncorrelated:
E{xy}
= E{x}E{y}
{Rxy = 0}
Orthogonal:
E{xy}
= 0
Note that the expected value operation implies that for stochastic processes, these
basic statistics are calculated across the ensemble. For example, if we want to calculate
the mean of a process, that is,
mx(t) = E{X(t, �i) = xi(t)}
We simply take the values of t = 0, 1, ... and calculate the mean for each value of
time across (i = 1, 2, …) the ensemble. Dealing with stochastic processes is similar
to dealing with random variables, except that we must account for the time indices
(see Chapter 2 for more details).
Next let us deine some concepts about the probabilistic information contained in
a random variable. We deine the (self) information contained in the occurrence of
the random variable X(�i) = xi as
I(xi) = −logb PX(xi)
(A.7)
where b is the base of the logarithm which results in different units for information
measures (base = 2 →bits), and the entropy or average information of X(�i) as
H(xi) = −E{I(xi)} =
∑
i
PX(xi) logb PX(xi)
(A.8)
Consider the case where there is more than one random variable. Then, we deine the
joint mass and distribution functions of an N-dimensional random variable as
PX(x1, … , xN),
FX(x1, … , xN)
All of the basic statistical deinitions remain as before, except that we replace the
scalar with the joint functions. Clearly, if we think of a stochastic process as a
sequence of ordered random variables, then we are dealing with joint probability
functions, that is, a collection of time-indexed random variables. Suppose we have
two random variables x1 and x2, and we know that the latter has already assumed a
particular value, the we can deine the conditional probability mass function of x1
given that X(�2) = x2 has occurred by
Pr(x1 ∣x2) := PX(X(�1) ∣X(�2) = x2)
(A.9)

A.1
PROBABILITY THEORY
581
and it can be shown from basic probabilistic axioms (see Papoulis [1]) that
Pr(x1 ∣x2) = Pr(x1, x2)
Pr(x2)
(A.10)
Note also that this expression can also be written as
Pr(x1, x2) = Pr(x2 ∣x1)Pr(x1)
(A.11)
Substituting this equation into Eq. A.10 gives Bayes’ rule, that is,
Pr(x1 ∣x2) = Pr(x2 ∣x1)Pr(x1)
Pr(x2)
(A.12)
If we use the deinition of joint mass function and substitute into the previous deini-
tions, then we can obtain the probabilistic chain rule [1–3],
Pr(x1, … , xN) = Pr(x1 ∣x2, … , xN)Pr(x2 ∣x3, … xN) … Pr(xN−1 ∣xN)Pr(xN)
(A.13)
Along with these deinitions follows the idea of conditional expectation, that is,
E{xi ∣xj} =
∑
i
XiPr(xi ∣xj)
(A.14)
With the conditional expectation deined, we list some of their basic properties:
1. Ex{X|Y} = E{X},
if X and Y are independent
2. E{X} = Ey{E{X|Y}}
3. Ex{g(y)X|Y} = g(y)E{X|Y}
4. Ex,y{g(Y)X} = Ey{g(Y)E{X|Y}}
5. Ex{c|Y} = c
6. Ex{g(Y)|Y} = g(Y)
7. Ex,y{cX + dY|Z} = cE{X|Z} + dE{Y|Z}
The concepts of information and entropy can also be extended to the case of more
than one random variable. We deine the mutual information between two random
variables xi and xj as
I(xi; xj) = logb
PX(xi ∣xj)
PX(xi)
(A.15)

582
PROBABILITY AND STATISTICS OVERVIEW
and the average mutual information between X(�i) and X(�j) as
I(Xi; Xj) = Exixj{I(xi, xj)} =
∑
i
∑
j
PX(xi, xj)I(xi, xj)
(A.16)
which leads to the deinition of joint entropy as
H(Xi; Xj) = −
∑
i
∑
j
PX(xi, xj) logb PX(xi, xj)
(A.17)
This completes the section on probability theory; next, let us consider an important
multivariable distribution and its properties.
A.2
GAUSSIAN RANDOM VECTORS
In this section, we consider the multivariable Gaussian distribution used heavily
in this text to characterize Gaussian random vectors, that is, z ∼(mz, Rzz) where
z ∈Nz×1 and deined by
Pr(z) = (2�)−Nz∕2|Rzz|−1∕2 exp
(
−1
2(z −mz)′R−1
zz (z −mz)
)
(A.18)
where the vector mean and covariance are deined by
mz := E{z}
and
Rzz = Cov(z) := E{(z −mz)(z −mz)′}
Certain properties of the Gaussian vectors are useful such as
r Linear transformation: Linear transformations of Gaussian variables are Gaus-
sian; that is, if z ∼(mz, Rzz) and y = Az + b, then
Y ∼(Amz + b, ARzzA′)
(A.19)
r Uncorrelated Gaussian vectors: Uncorrelated Gaussian vectors are independent.
r Sums of Gaussian variables: Sums of independent gaussian vectors yield Gaus-
sian distributed vectors with mean and variance equal to the sums of the respec-
tive means and variances.
r Conditional Gaussian vectors: Conditional Gaussian vectors are Gaussian dis-
tributed; that is, if x and y are jointly Gaussian, with
mz = E
{
x
y
}
=
[ mx
my
]
;
and
Rzz = Cov(z) =
[Rxx
Rxy
Ryx
Ryy
]

A.3
UNCORRELATED TRANSFORMATION: GAUSSIAN RANDOM VECTORS
583
then the conditional distribution for x and y is also Gaussian with conditional
mean and covariance given by
mx|y = mx + RxyR−1
yy (y −my)
Rx|y = Rxx −RxyR−1
yy Ryx
and the vectors x −E{x|y} and y are independent.
r Gaussian conditional means: Let x, y, and z be jointly distributed Gaussian
random vectors and let y and z be independent, then
E{x|y, z} = E{x|y} + E{y|z} −mx
A.3
UNCORRELATED TRANSFORMATION: GAUSSIAN
RANDOM VECTORS
Suppose we have a Gaussian random vector, x ∼(mx, Rxx) and we would like to
transform it to a normalized Gaussian random vector with the mean mx removed so
that z ∼(0, I). Assume that the mean has been removed (z →z −mx), then there
exists a nonsingular transformation T such that z = Tx, and therefore
Rzz = Cov(z) = Cov((Tx)(Tx)′) = TRxxT′ = I
(A.20)
Thus we must ind a transformation that satisies the relation
Rzz = I = TRxxT′
(A.21)
Since Rxx is a positive semi-deinite, symmetric matrix it can always be factored
into matrix square roots (R = UU′ = R1∕2
xx RT∕2
xx ) using a Cholesky decomposition [4];
therefore, Eq. A.21 implies
Rzz = I = (TU)U′T′
(A.22)
or simply that
T = U−1 = R−1∕2
xx
(inverse matrix square root)
(A.23)
and therefore
Rzz = (R−1∕2
xx
U)U′R−T∕2
xx
= R−1∕2
xx
RxxR−T∕2
xx
= I
(A.24)
the desired result.

584
PROBABILITY AND STATISTICS OVERVIEW
This discussion completes the introductory concepts of probability and random
variables which is extended to include stochastic processes in Chapter 2 and through-
out the text.
REFERENCES
1. A. Papoulis and S. Pillai, Probability, Random Variables and Stochastic Processes (New
York: McGraw-Hill, 2002).
2. R. Hogg, J. McKlean, and A. Craig, Introduction to Mathematical Statistics (Englewood
Cliffs, NJ: Prentice-Hall, 2005).
3. A. Jazwinski, Stochastic Processes and Filtering Theory (New York: Academic Press,
1970).
4. G. Bierman, Factorization Methods for Discrete Sequential Estimation (New York: Aca-
demic Press, 1977).

INDEX
�-points, 206, 211, 212, 227, 250
2D-tracking ilter, 150, 247
a posteriori density, 20, 21, 364
a posteriori distribution, 2
a posteriori particle, 343
a posteriori probabilities, 421
a posteriori probability, 165, 171, 181, 182
a priori density, 9, 21
a priori distribution, 2, 25
a priori information, 27
a priori probability, 402
abnormal condition, 461, 463
acceptance probability, 74, 76, 79, 263, 286
acceptance/rejection sampling, 66
accuracy, 436
acoustic communications, 390
adaptive, 12, 471
adaptive processor, 362
Akaike Information Criterion, 295
alignment, 485
all paths, 388
all-pole, 135, 147, 399
all-zero, 147, 148
AM modulator, 199, 251
AM receiver, 50
analytic distributions, 59
analytic form, 58, 66
annealing, 343
anomaly, 461, 474, 490, 495
anomaly detection, 459, 474
approximate Gauss–Markov process model,
149
approximate Gaussian, 290
approximate Kalman iltering, 254
approximation step, 215
AR model, 135
area under ROC curve, 424, 432
ARMA, 384
ARMAX model, 124, 132, 133
array, 557
array measurements, 354
array theory, 359
artiicial dynamics, 342
assimilation method, 235
asymmetric proposals, 74
asymptotically converges, 87
asymptotically distributed, 311
asymptotically eficient, 24
asymptotically Gaussian, 25
asymptotically optimal estimate, 87
attenuation coeficient, 544, 545, 549
augmented state vector, 335, 359, 559, 560,
562
augmenting, 257
automatic alignment, 485
autoregressive, 126
autoregressive (all-pole) model, 82
autoregressive model, 96
autoregressive moving average, 126, 468
autoregressive-moving average model with
exogenous inputs, 125, 126
auxiliary, 317
auxiliary particle ilter, 261, 274, 280
average information, 294, 580
average log-likelihood, 295
average mutual information, 582
average risk, 421, 444
Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods, Second Edition. James V. Candy.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
585

586
INDEX
backward algorithm, 378, 379
backward operator, 378
backward shift, 125, 469
ballistic vehicle, 471
bandwidth, 57, 58, 282
batch Bayesian, 34
batch Bayesian importance sampling, 87
batch least-squares estimate, 19
batch measurement problem, 419
Baum–Welch, 384, 387, 388, 390, 392, 395
Bayes’ approach, 158
Bayes’ criterion, 421
Bayes’ error, 411
Bayes’ factor, 442
Bayes’ risk, 401, 413, 414, 420, 437, 472
Bayes’ rule, 2, 17, 39–41, 43, 52, 53, 79, 85, 87,
259, 328, 329, 345, 346, 372, 378, 385, 404,
407, 421, 433, 437, 442, 443, 456, 462, 505,
507, 533
Bayes’ theorem, 37–39, 45, 504, 510, 562
Bayesian, 179
Bayesian algorithms, 38
Bayesian approach, 2, 3, 52, 67, 153, 165, 171,
327, 344, 401, 522
Bayesian constructs, 12
Bayesian decision function, 407
Bayesian decomposition, 27, 328, 344
Bayesian detection, 444
Bayesian estimation, 2, 20, 24, 38, 52, 66, 67, 87,
98, 151, 256
Bayesian estimation problem, 152
Bayesian factor, 88
Bayesian factorization, 87
Bayesian iltering, 398
Bayesian framework, 151, 290, 312
Bayesian importance sampling, 85
Bayesian methods, 2, 21
Bayesian model-based processor, 83, 484
Bayesian particle ilters, 317
Bayesian processing, 4, 45, 224, 255
Bayesian processor, 9, 40, 45, 52, 98, 142, 153,
185, 191, 193, 226, 245, 274, 298, 312, 367,
372, 484, 486, 522, 526, 528
Bayesian recursions, 254, 328
Bayesian representation, 151
Bayesian sequential techniques, 20, 45
Bayesian signal processing, 1–4, 54, 484
Bayesian solution, 89
Bayesian system, 152
Bayesian theory, 3, 38
beam line measurements, 485
bearing estimate, 232, 354
bearing measurements, 230
bearings-only, 175, 228, 326
Beer’s law, 544
best operating point, 437
best path, 381
best rank approximation, 113, 114
bias, 87, 274
bias index, 311
bias–variance tradeoff, 57
bimodal distribution, 57
bin-size, 57, 58
binary channel, 398
binary coded, 371
binary communication, 17
binary decision problem, 420, 433, 509, 532
binary detection, 447, 451, 454, 549
binary hypothesis test, 364, 365, 510, 549
binary signal, 376, 379, 383, 389
binomial distribution, 55, 267, 307
binomial random number, 58
bivariate distribution, 94
bivariate Gaussian, 81, 96
black-box models, 10, 124
bootstrap SIR algorithm, 273
bootstrap algorithm, 286, 322, 325
bootstrap approach, 347, 507
bootstrap ilter, 253
bootstrap implementation, 347
bootstrap particle ilter, 262, 272, 274, 285, 286,
317, 323, 359, 456, 457 508, 538, 564
bootstrap processor, 270, 274, 280, 313
box kernel, 54
broadband acoustic signals, 500
broadband modal functions, 504
broadband modal model, 508
broadband normal-mode model, 512
broadband pressure-ield/modal function, 504
broadband signal spectrum, 501
broadband source, 498, 501
broadband source detection problem, 500, 502,
510, 511, 519
broadband state-space propagator, 500, 502
brute force method, 427, 428
burn-in period, 83
calibration phase, 537
canonical forms, 120, 124, 132
cantilever array, 522
cantilever physics model, 524
cartesian coordinates, 175, 229
cartesian tracking model, 199, 251
CCD camera, 487
central difference, 222, 363, 504, 557
central limit theorem, 67, 69, 87

INDEX
587
central moments, 310
chain rule, 22, 35, 40, 45, 88, 156, 167, 172, 181,
255
chain rule decomposition, 87
chain rule of probability, 40, 440, 462, 510, 533
change detection, 460, 461, 463, 474
Chapman–Kolmogorov equation, 40, 43, 45, 153,
260, 456
characteristic polynomial, 112
chemical delection, 524
Chernoff upper bound, 434
chi-square statistical test, 307
chi-squared distributed, 189, 466
Cholesky decomposition, 283
Cholesky factor, 223
classical approach, 4, 141, 288, 347
classical nonlinear processors, 224
classical statistics, 292
classiication, 384, 420, 423
classiication theory, 9
cloud, 8
coded signal, 391
coeficient of variation, 264
coin tossing, 578
coloring ilter, 148
communications satellite, 18
complete likelihood, 28, 33, 400
completely controllable, 111, 112
completely observable, 109, 112
complex sinusoids, 49
composite hypotheses, 409, 422
composite hypothesis test, 472
composite likelihood-ratio, 409
condensation, 261
conditional density, 25, 80
conditional distribution, 79, 223, 410, 415, 583
conditional expectation, 28, 32, 47, 154, 165,
172, 581
conditional Gaussian distributions, 165, 172
conditional independence, 88, 255, 260, 372,
374, 378, 381, 562
conditional likelihood distribution, 152
conditional mean, 3, 33, 35, 39, 53, 170, 171,
223, 227, 237, 255, 289, 291, 448, 506,
564
conditional mean estimate, 288
conditional probability, 2, 33, 151, 448, 452
conditional transitions, 79
conditionally independent, 40, 151
conditionally unbiased, 35, 36
conidence bound, 429
conidence interval, 188, 290, 465, 535, 536, 540
conidence limits, 169
confusion matrix, 434, 436, 473
consistent, 24
constant velocity model, 229
continuous analog domain, 103
continuous approximation, 283
continuous distribution, 254, 282
continuous dynamics, 105
continuous observation, 370
continuous random variable, 95
continuous state-transition matrix, 115
continuous–discrete, 148
continuous-time, 99, 103, 105–107, 115, 142
continuous-time Gauss–Markov model, 115
continuous-time stochastic process, 117
continuous-time system, 98, 103, 106
contraband, 528
contraband detection, 554
control loop, 489
controllability, 111
convergence, 56, 57, 266
converges in-distribution, 67
converges uniformly, 225, 227
convolution, 127
coordinate systems, 233
corrected covariance, 335
corrected state estimate, 183
corrected state/parameter estimates, 334
correction equation, 43
correlated Gauss–Markov, 123
counting estimator, 539
counting functions, 387, 388
counting methods, 427
counts, 29
covariance, 127, 128, 213
covariance estimates, 189
covariance function, 145
covariance matrix, 133
coverage, 287
covering, 65
Cramer–Rao bound, 22, 23, 47, 51
cross error covariance, 219
cross-covariance, 188
cumulative distribution function, 14, 54, 58, 95,
266, 304, 308
current model parameters, 388
data ensemble, 291
data likelihood, 45, 455, 456, 511
decision, 446, 543, 550
decision analysis, 423
decision criteria, 414, 416, 472
decision distribution, 427
decision errors, 433

588
INDEX
decision function, 402, 403, 405, 411, 413, 415,
416, 419, 422, 423, 425, 427, 428, 430, 431,
433, 434, 440–442, 444, 447, 457, 458, 463,
470, 472, 531–533, 535, 537, 540
decision problem, 402, 409, 414, 434, 510, 549
decision region, 405, 407, 411–414, 421, 427
decision rule, 402, 403, 405, 406, 412, 421
decision space, 404
decision statistic, 508
decision theory, 411
decision threshold, 428
decoding, 382, 384
decoding example, 380
decomposition, 80, 114, 335
deconvolution problem, 232
degeneracy, 262–264, 266, 281
delay operator, 469
delta family, 225
delta function, 69, 225, 227, 457
demodulation, 365
density, 14, 54
density function, 207
depletion, 262
descent algorithm, 337
detailed balance, 73, 80
detection, 401–404, 407–409, 411, 412, 414, 415,
417, 419, 420, 423–425, 427–430, 434, 435,
437, 438, 440, 444, 451, 454, 457, 459, 461,
467, 472–475, 500, 528, 531–533, 535, 540
detection performance, 431–433, 500
detection probability, 414, 436, 549, 553
detection problem, 364, 472
detection rate, 534
detection theory, 423
detector, 408
detector analysis, 473
detector measurement model, 546
detector resolution, 534
determinant, 102
deterministic, 110
deviation data, 493
diagnostic tests, 306, 317
difference equation, 125, 132, 146, 469, 558
differential equation, 99, 103, 104
Dirac delta function, 86
direct method, 58
directed graph, 17, 369, 376
discrete cumulative distribution, 60
discrete domain, 103
discrete Fourier transform, 469
discrete nonlinear example, 174
discrete nonlinear process, 141, 149, 168
discrete observation, 386
discrete posterior distribution, 266
discrete power spectrum, 121
discrete probability mass function, 283
discrete probability matrix, 368
discrete random variable, 94
discrete spectrum, 501
discrete state-transition matrix, 109
discrete sums, 68
discrete system, 107, 108, 110
discrete systems theory, 109, 142
discrete transfer function, 111
discrete variate, 15
discrete Wiener equation, 37
discrete-time, 107, 115, 142
discrete-time hidden Markov model, 367
discrete-time Markov chain, 368
discrete-time representation, 98
discrete-time variable, 14
discriminator, 536, 537, 540
dispersion, 560
dispersion index, 311
dispersion index distribution, 311
distance, 431, 473
distance measure, 296
distance metric, 298, 301, 322, 431, 509
distribution, 2, 59, 67, 68, 73
distribution estimation, 9, 55
distribution function, 577
distribution validation, 293
diverge, 186
divergence, 317
divergence criterion, 298
divergence measure, 290
divergence metric, 518
divergence problem, 317
divergence statistic, 298, 509
diversity, 267, 281, 283, 348
DNA strings, 384
draw samples, 85
dynamic model, 342
dynamic physical systems, 107, 371, 384
dynamic random variables, 38
dynamic state variable, 151, 327
dynamic system, 99, 109, 112
dynamic variable, 40, 43, 45, 85, 88
dynamic wavenumber, 353
E-step, 29, 400
effective number of particles, 265, 508
eficient, 22
eigendecomposition, 105
eigenvalues, 114
eigenvector matrix, 114

INDEX
589
eigenvectors, 105
elliptical orbit, 51
EM principle, 28
EM/Baum–Welch, 388, 389
embedded dynamic model, 306
emission densities, 32
emission probability, 531, 533–535, 537, 539
empirical approximation, 344
empirical distribution, 7, 63, 67, 68, 262, 279,
280, 282, 307, 345, 347
empirical posterior distribution, 8, 268, 281,
506
empirical prediction cumulative distribution, 305
empirical probability mass function, 506
energy, 533, 534, 537
energy estimator, 538
enhanced modal function, 515
enhanced pressure-ield, 514
enhanced signal, 12
enhancement, 566
ensemble, 170, 171, 202, 232, 239, 242, 292,
298, 302, 348, 428, 429, 438, 500, 514, 517,
566, 569, 579
ensemble average, 293, 429, 514, 570
ensemble error, 242
ensemble estimates, 185, 301, 313, 348
ensemble generation, 237
ensemble Kalman ilter, 202, 234, 235, 239, 244,
245
ensemble Kalman gain, 241, 242
ensemble matrix, 240
ensemble mean, 241, 456
ensemble member, 239, 429
ensemble methods, 235
ensemble residual, 293
ensemble simulation, 302
ensemble statistics, 291–293, 301
entire hidden state sequence, 380
entire state sequence estimation, 383
entropy, 294, 580, 581
environmentally adaptive, 555, 566
environmentally adaptive processor, 572
Epanechnikov, 55, 282
ergodic, 73, 144, 186, 187, 464, 465
error covariance, 165, 228, 235, 239, 240, 335
error covariances, 38
error cross-covariance, 242
error probability, 433, 434
error statistics, 235
error variance, 26, 35, 268
estimated distributions, 296
estimated instantaneous posterior distribution,
313
estimated posterior distribution, 290
estimated residual, 306
estimated state, 337, 340
estimation, 2, 3, 9
estimation error, 22, 35, 36, 165, 227
estimation problem, 23
estimation scheme, 288
estimator, 14, 38
estimator quality, 22
evaluation, 390
evaluation problem, 373, 375, 376
event detection, 468, 470
event mode sequence, 528
evidence, 2, 3, 21, 39, 53, 66, 85, 89
expectation, 7, 66
expectation step, 27, 30, 32
expectation-maximization algorithm, 27, 327,
384, 395, 400
expected likelihood, 445, 446
expected value, 580
exponential class, 30
exponential distribution, 60, 61, 64, 97
exponential family, 30–33, 441, 532
exponential random variable, 538
exponential window, 343
extended Kalman ilter, 150, 170, 194, 241, 331,
451, 452, 522
external, 112
factored power spectrum, 145
factorization techniques, 171
false alarm, 532
false alarm probability, 553
false negative rate, 436
false positive rate, 436
false-alarm, 414, 426, 429, 435
false-alarm probability, 401, 414–416, 427–429,
436, 438, 440, 443, 444, 451, 454, 459,
549
iltered conditional, 154
iltered measurement, 171, 185, 337, 340
iltering distribution, 38, 44, 45, 153, 345
iltering posterior, 226, 228, 255, 274, 344, 399
inancial systems, 322
inite impulse response, 126
irst differences, 107, 197, 342, 352, 363
irst-order Markov, 40, 41, 372, 374
forensic analysis, 384
forgetting factor, 342, 343
forward algorithm, 382
forward operator, 375, 385
forward propagator, 572
forward recursion algorithm, 375, 378

590
INDEX
forward–backward algorithm, 379, 380, 381, 388,
389
fourth-order moments, 211
frequency modulation, 365
frequency ratio, 55
frequentist, 414
fundamental theorem of calculus, 59
fusion experiments, 484
gain, 158, 165, 171, 179, 183, 186, 237, 334
Gauss–Hermite numerical integration, 223
Gauss–Markov, 52, 503, 554
Gauss–Markov model, 115, 117–120, 123, 124,
145, 148, 155, 160, 165, 172, 176, 177, 196,
200, 230, 245, 324, 342, 362–364, 447, 449,
451, 453, 461, 467, 489, 513, 538, 548
Gauss–Markov perturbation model, 140, 164
Gauss–Markov representation, 98, 117, 142, 148,
365, 490, 547, 558
Gauss–Markov wavefront curvature model, 325
Gauss–Newton optimization, 337, 470
Gauss-Hermite grid-based integration, 307
Gaussian, 2, 7, 12, 30, 55, 69, 70, 75, 123, 144,
153, 255, 282, 297
Gaussian approximation, 250
Gaussian decision functions, 425, 438, 439
Gaussian density, 225
Gaussian distribution, 14, 52, 77, 82, 118, 307
Gaussian importance proposal, 286, 287
Gaussian kernel estimator, 57
Gaussian mixture, 76, 225, 226, 228, 297, 307
Gaussian noise, 96, 98, 217
Gaussian posterior, 52
Gaussian prior, 26, 226, 287, 289
Gaussian processes, 118, 309
Gaussian proposal, 286
Gaussian random variable, 25, 144
Gaussian random vectors, 582
Gaussian sequences, 290
Gaussian sum, 224, 225, 227, 245, 251, 307
Gaussian window, 57, 83
Gaussian-based technique, 304
generalized likelihood-ratio test, 409, 472
Gibbs sampler, 52, 73, 79–81, 90, 96, 283
Gibbs simulation-based sampler, 79
global estimation performance, 470
golden rule of sampling, 64
goodness-of-it, 304, 307, 308
gradient operator, 156, 167, 172, 182, 183
gradient vector, 13, 21, 181, 202
gray box, 124
Green’s function, 390, 391, 500, 501
grid-based, 4, 223, 245
Hankel function, 500, 513, 556
Hankel matrix, 112, 114
Hellinger distance, 301, 302, 313, 322, 348
Helmholtz equation, 500, 502, 513, 555
Hessian, 181–183
hidden dynamic, 151
hidden Markov chain, 369, 373, 395
hidden Markov model, 367, 369, 373, 377
hidden state estimation, 376, 379
hidden states, 254, 379, 399
hidden variables, 27, 29, 30, 372, 377
high probability regions, 255, 263, 281, 285
higher order moments, 213
histogram, 9, 53–58, 77, 264, 298, 506, 529
history, 386
HMM parameter estimation, 384, 387
homogeneous, 73
homogeneous in time, 368, 373
horizontal wavenumber, 512, 556, 560, 566, 572
Hudson Canyon experiment, 565, 570
hypothesis, 402, 403, 405, 409, 442, 534
hypothesis test, 188, 307–309, 409, 536
implicit marginalization, 287
importance distribution, 84, 85, 87, 256–258,
260, 261, 274, 346, 347, 455, 456, 506,
563
importance sampling, 52, 67, 83–85, 253, 255,
264, 285, 346, 563
importance sampling algorithm, 262
importance sampling approach, 90
importance weights, 256, 261, 262, 267, 271, 312
impulse function, 7, 14
impulse response, 391
impulse response matrix, 100, 112
impulse sampler, 14
incomplete data, 29, 32, 34
independent identically distributed, 53
independent samples, 53, 66
indicator function, 96, 531
individual state estimate, 381
inferences, 53
ininite impulse response, 125
ininite power series, 111
information, 580
information matrix, 22
information quantity, 298
information theoretic approaches, 293, 317
innovation, 12, 155, 164, 165, 179, 185, 514
innovation mean, 464
innovation vector, 124, 173, 187, 464
innovations, 169, 185, 188, 189, 232, 290, 304,
459, 466, 527, 567, 569

INDEX
591
innovations covariance, 157, 158, 187, 333, 334,
363
innovations model, 123, 124, 147, 362
innovations representation, 133, 363
innovations sequence, 158, 171, 177, 185–187,
337, 340, 362, 461, 470, 490, 515
innovations-based detector, 474
input excitation, 103
input transmission matrix, 104, 116
input–output structure, 124
instantaneous approximation, 255
instantaneous polynomials, 469
instantaneous posterior distribution, 354
instantaneous posterior iltering distribution,
312
instantaneous spectral estimate, 468, 469
instantaneous spectrogram, 470, 471
instantaneous transfer function, 469
integral, 66, 68
intensity parameter, 29
interarrival time, 530, 533–535, 537, 538
internal probabilistic representation, 384
internal structural model, 384
internal variables, 100, 109
invariant, 25
invariant distribution, 4, 71, 73–75, 79, 80,
283–285
inverse cumulative distribution method, 62
inverse Laplace transform, 100
inverse transform approach, 95
inverse transformation theorem, 61
inversion, 58, 60
inversion problem, 64
invertible transformation, 59
irregularly spaced, 105
iterated Kalman ilter, 288
iterated-extended Bayesian processor, 150, 179,
194
iterative approach, 384, 387
iterative methods, 67, 90
iterative sampling techniques, 83
iterative simulations, 81
iterative technique, 30
Jacobian, 59, 179, 213, 235, 332, 362, 453
Jacobian matrices, 139, 140, 164, 165, 171, 173,
333, 452
Jacobians, 164, 170, 201, 220, 337
jittering, 281, 283
joint a posteriori distribution, 504
joint Bayesian state/parameter estimation, 328,
359
joint bivariate Gaussian, 81
joint distribution, 39, 40, 348, 372, 381, 422
joint dynamic distribution, 3
joint entropy, 582
joint estimation, 232, 330, 344, 563
joint event, 386
joint index, 311
joint mass function, 579, 581
joint parametric distribution, 539
joint PF, 366
joint posterior distribution, 24, 38, 43, 79, 80,
327, 344, 359
joint posterior estimation problem, 41
joint random particles, 286
joint SPBP, 366
joint state/parameter estimation, 327, 329, 343,
348, 562
joint state/parameter estimation problems, 329
joint state/parameter posterior, 328
joint state/parametric estimation, 328
joint state/parametric processing, 341
joint state/parametric processor, 330
joint vector distribution, 419
jointly distributed, 48
jointly estimate, 365
Joseph form, 197
Kalman ilter, 12, 141, 165, 186, 222, 235, 237,
245, 255, 288, 322, 323, 371, 448, 461, 489,
537, 538, 543, 553, 554
Kalman iltering theory, 38
Kalman gain, 124, 242
Kalman techniques, 307
kernel, 54, 282
kernel density, 55, 57, 58, 77, 282, 283, 347, 506,
517
kernel smoothing, 9, 55, 301
kernel technique, 347
Kirchoff’s current equations, 160
Kolmogorov–Smirnov, 306, 308, 309
Kullback divergence, 296, 297, 300, 509
Kullback–Leibler, 290, 322
Kullback–Leibler divergence, 297, 298, 302, 348,
520
Kullback–Leibler information, 500, 509
kurtosis, 209
lack of diversity, 317
Lagrange optimization, 414, 415
Lambert–Beer law, 544
Langmuir kinetics, 522
Laplace transform, 100, 101, 125
large-scale, 234
law of large numbers, 4, 66, 70, 71

592
INDEX
least-squares, 19, 20, 37, 45
level-of-signiicance, 189, 309
likelihood, 2, 3, 21, 41, 45, 53, 96, 154, 261, 271,
272, 353, 372, 373, 389, 400, 442, 507, 528,
562, 564
likelihood cumulative distribution, 290
likelihood decision function, 405, 406, 418, 420,
442, 443, 446, 447
likelihood detector, 406
likelihood distribution, 4, 39, 151, 152, 257, 274,
505, 507
likelihood estimation techniques, 384
likelihood function, 24, 201
likelihood method, 23
likelihood-ratio, 364, 365, 406, 407, 409, 412,
414, 415, 417, 419, 440, 441, 457, 461,
472–474, 510, 532, 550
likelihood-ratio decision function, 409, 549
linear algebra, 101
linear Bayesian processor, 158, 290, 371
linear discrete Gauss–Markov model, 153
linear dynamic systems, 400
linear Gaussian, 38
linear Kalman ilter, 153, 237, 245
linear regression, 204
linear systems theory, 368
linear time-invariant, 100, 102
linear time-varying, 99, 115
linear time-varying state–space representation,
108
linear transformation, 118
linearization, 52, 138, 150, 162, 288
linearization approach, 141, 287
linearization error, 204
linearization method, 286, 289
linearization process, 170
linearization techniques, 98, 140, 141, 164
linearization-based particle ilter, 289
linearized, 198, 217, 288
linearized algorithm, 317
linearized Gauss–Markov models, 98
linearized Kalman ilter, 452
linearized measurement perturbation, 140
linearized model, 218
linearized model-based processor, 452
linearized particle ilter, 289, 290
linearized process model, 139
linearized state–space model, 162
local iteration, 179, 194
local linearization, 286, 346, 347
local linearized particle ilters, 261
local maximum, 388
location parameter, 299, 300, 431
log-likelihood, 24, 27–29, 31, 295, 388, 446, 450,
454, 540
log-likelihood decision function, 445, 450, 453,
458, 535, 543, 553
log-likelihood detection, 554
log-likelihood equation, 25
log-likelihood function, 388, 539, 553
log-likelihood ratio, 444, 539
logarithmic a posteriori probability, 165, 172
logarithmic transformation, 388
long-tailed distribution, 286
low dispersion index, 311
low probability, 263
Lyapunov equation, 115, 118
M-step, 34, 400
machine-learning, 423
Manhattan project, 4
MAP, 21, 25
MAP decision function, 408, 412
MAP estimate, 26, 156, 300
MAP state estimation, 379
marginal distribution, 40, 81, 87, 97
marginal posterior distribution, 28, 45
marginal probability distributions, 7
marginalization, 66, 379
marginalizing, 286, 373
marked Poisson process, 33
Markov, 40, 43, 118
Markov chain, 4, 52, 66, 67, 71, 73–75, 79, 80,
348, 368, 369, 373, 399
Markov chain model, 398
Markov chain Monte Carlo, 1, 71, 500
Markov chain simulation, 74
Markov chain theory, 90, 372
Markov chain transition kernel, 283
Markov chain transition probability, 75
Markov parameters, 112
Markov process, 456, 511
Markov property, 88, 378
Markov sequence, 112
Markov switching model, 399
Markovian assumptions, 255
Markovian independence, 378
Markovian model, 272
Markovian property, 151, 368
Markovian representations, 2
Markovian state vector, 151
Markovian state–space model, 352
Markovian structure, 253
mass, 14, 254
mass function, 54
matched ilter, 390, 391, 490

INDEX
593
matrix decomposition methods, 105
matrix differential equation, 102
matrix exponential, 101, 104, 105
matrix inversion lemma, 156, 173, 182
matrix square root, 123, 212, 223, 283
matrix-difference equation, 109
matrix-square-root, 213
maximal path, 381
maximization step, 27, 29, 30, 32
maximum a posteriori, 20, 37, 45, 49, 407, 506
maximum a posteriori estimate, 50, 380
maximum deviation, 309
maximum likelihood, 20, 37, 49
maximum likelihood decision function, 410
maximum likelihood detector, 406
maximum likelihood estimate, 23, 24, 25, 27, 32,
45, 50, 188, 387, 389, 466
maximum likelihood parameter estimation, 27,
28, 30
maximum weight, 255
MC approach, 7
MC methods, 4
MC model diagnostics, 304
MC sampling techniques, 297
MC simulation, 254
MCMC iterative processor, 283
MCMC technique, 285
MCMC-step, 283, 285, 286, 348
mean, 213, 579
mean propagation recursion, 127
mean-squared error, 513
mean-squared error criterion, 36
measure of degeneracy, 264
measurement covariance, 120
measurement distribution, 311
measurement error, 240
measurement estimate, 292
measurement instrument, 18
measurement Jacobian, 179, 288, 333
measurement likelihood, 261, 270
measurement linearization, 165
measurement mean vector, 117, 118
measurement model, 18, 288, 324
measurement noise, 155
measurement noise ensemble, 241
measurement nonlinearity, 179, 183, 185
measurement perturbation, 139
measurement power spectrum, 120
measurement prediction, 218
measurement space, 402, 413, 418, 500
measurement system, 50, 109
measurement system models, 9
measurement variance, 117, 119
measurement vector, 418
memory time constant, 343
method of composition, 54
metric, 298, 301, 302, 348, 432, 509
Metropolis, 77, 283
Metropolis algorithm, 74, 96
Metropolis methods, 81
Metropolis technique, 67
Metropolis–Hastings, 73, 74, 77, 79, 283, 285
Metropolis–Hastings approach, 52
Metropolis–Hastings sampler, 80, 90, 96
Metropolis–Hastings sampling method, 74
microcantilever sensor, 10, 520, 521
microelectromechanical sensor, 521
MinE, 473
minimal polynomial, 112
minimal realizations, 112
minimum data length description, 295
minimum error variance, 162, 185, 186, 470
minimum error variance estimator, 371
minimum mean-squared error, 20, 255, 506
minimum variance, 20, 37, 317, 346
minimum variance importance distribution, 274
minimum variance approach, 271, 272
minimum variance design, 158, 185
minimum variance estimation, 19, 242
minimum variance estimator, 35, 36, 45, 48
minimum variance importance function, 261, 287
minimum variance importance proposal, 286, 317
minimum variance proposal distribution, 259, 289
minimum variance weights, 260
miss probability, 436
missing data, 27, 28, 30, 33
missing/hidden vectors, 27
mitigate variance, 272
mixing coeficients, 76, 224, 227, 297
mixture, 224, 297
modal analysis, 517
modal coeficient, 555, 556, 559, 567
modal functions, 498, 500, 515, 517, 518, 556,
567, 569
modal representation, 501
modal space, 500
modal structure, 498
modal/pressure-ield estimator, 519
model error, 461
model mismatch, 189, 461
model monitoring problem, 463
model parameters, 387, 388
model uncertainties, 9
model validation, 317
model-based, 53, 290, 447, 449, 509
model-based anomaly detector, 496

594
INDEX
model-based approach, 2, 4, 9, 447, 459
model-based detection, 473
model-based likelihood, 153
model-based processor, 9, 18, 124, 304, 448, 449,
451–453, 460, 474, 543
model-based sequential detector, 449
model-based signal processing, 1, 9, 10, 12, 98
model-based solutions, 153
modeling error, 239
modeling inaccuracies, 465
modern technique, 347
moments, 14, 67, 68, 207, 210, 296
monoenergetic decomposition, 529
monoenergetic radionuclide model, 533
monoenergetic source, 528, 530, 535, 539
Monte Carlo, 1, 52, 68, 171, 564
Monte Carlo approach, 4, 66, 67, 70, 235, 327
Monte Carlo error, 258
Monte Carlo estimate, 7, 69, 254
Monte Carlo integration, 7
Monte Carlo methods, 4, 290
Monte Carlo techniques, 53, 67, 68, 71, 73
most probable paths, 388
move-step, 285, 366
moving average, 126
multi-modal, 1, 54, 348, 563, 570
multichannel, 98, 120
multichannel Bayesian technique, 498
multichannel data, 525
multichannel measurement, 418
multichannel processor, 522
multichannel solution, 498
multimodal distribution, 253
multinomial distribution, 267, 307
multinomial sampling method, 267, 269
multipath, 197
multiple channels, 418, 440
multiple hypotheses, 420, 422, 423
multiple measurement, 416, 417, 419, 440
multiple model choices, 371
multivariable measurements, 418
multivariable representation, 100
multivariable structures, 124
multivariable transfer function, 100
multivariate detection, 420
multivariate Gaussian distribution, 12, 154, 155,
215, 245, 322, 478
mutual information, 294, 581
National Ignition Facility, 485
navigation, 229
nearest-neighbor, 57
negative predictive value, 436
Nelder–Meade polytope, 525
neural network, 199, 251, 384
Newton–Rhapson, 181, 194
Neyman–Pearson, 416, 443
Neyman–Pearson approach, 442
Neyman–Pearson decision criterion, 414, 472
Neyman–Pearson detector, 414, 415
Neyman–Pearson theorem, 461, 510, 532, 549
non-Gaussian, 12, 53, 561
non-Gaussian distribution, 224
non-Gaussian model, 473
non-Gaussian processor, 455
nonlinear, 98
nonlinear Bayesian processors, 201
nonlinear Bayesian signal processing, 194
nonlinear cost function, 180
nonlinear discrete-time state–space
representation, 107
nonlinear dynamic model, 333
nonlinear dynamic system, 99, 304
nonlinear dynamics, 288, 330
nonlinear EnKF, 241
nonlinear estimation, 9, 141, 224
nonlinear iltering, 170, 185, 213
nonlinear measurement, 166
nonlinear measurement model, 139
nonlinear measurement system, 150
nonlinear models, 213, 220, 332
nonlinear parameter estimator, 331
nonlinear problems, 254
nonlinear process, 213, 214, 215
nonlinear processing, 62
nonlinear processor, 220, 228, 233, 251, 521
nonlinear re-entry problem, 328
nonlinear sensor model, 177, 326
nonlinear signal model, 451
nonlinear signal processing, 38, 90
nonlinear state estimation, 194, 202
nonlinear state–space representation, 312, 330,
366
nonlinear stochastic vector difference equations,
138, 162
nonlinear system, 104, 138, 142, 149, 162, 198,
250, 335, 384
nonlinear trajectory estimation, 220, 359
nonlinear transformation, 202, 204–206, 210,
214
nonlinear vector functions, 138, 164
nonlinear/non-Gaussian model, 317
nonlinear/non-Gaussian signal processing, 53
nonparametric methods, 9
nonphysical systems, 384
nonrandom constant, 25

INDEX
595
nonstationary, 53, 98, 120, 466, 514, 518, 520,
555, 567
normal form, 136, 137
normal modes, 500, 558
normal operation, 474
normal-mode propagation, 497, 512
normal-mode solution, 502
normal-mode theory, 500
normality diagnostics, 309
normality testing, 306, 311
normality, 461
normalization, 53, 66
normalization condition, 211
normalization constant, 65
normalization constraint, 205
normalized covariance, 188, 465
normalized Gaussian random vector, 583
normalized mean-squared error, 291
normalized weight, 263, 267
normalizing constant, 66, 73, 74, 85–87
normalizing distribution, 89
normalizing factor, 3
nuclear physics, 66
null hypothesis, 187, 465
numerical implementation, 335
numerical integration, 4, 5, 7, 39, 53, 68, 104, 106
numerical quadrature, 4
numerical stability, 335, 504
Nyquist sampling theorem, 103
observability matrix, 111
observable, 109
observation probability, 370, 371, 373, 375, 380,
384
observation sequence, 371
observer canonical form, 132, 133
ocean acoustics, 359, 500
ocean environment, 497
on-line, 330, 384
one-step prediction distribution, 228
operating point, 427, 428, 434, 436, 437, 511, 532
optimal, 38, 186
optimal bandwidth, 57
optimal Bayesian algorithms, 38
optimal Bayesian estimate, 254
optimal decision function, 439
optimal decision threshold point, 437, 438
optimal operating point, 519
optimal path, 382
optimal processor, 153, 323, 563
optimality conditions, 464
optimization, 4, 9, 66, 180, 327
optimization-based decision criteria, 416
optimum decision (threshold) point, 437
optimum threshold, 451
ordered moments, 211
ordered uniform variates, 268
ordinary differential equation, 10, 104, 105
orthogonal, 35, 36, 105, 144
orthogonality condition, 36, 37
outlier performance, 274
Pade’ approximation, 104
parameter estimates, 2, 21, 28, 337, 340, 348, 384
389, 531
parameter estimation, 34, 295, 327, 328, 344,
363, 384, 389, 469, 563
parameter estimation problem, 384, 385, 395, 400
parameter estimator, 330, 337
parameter posterior distribution, 345
parameter space, 75, 342
parameter variables, 327
parameter vector, 348
parametric change detector, 471
parametric models, 384
parametric posterior, 328
parametric signal processors, 294
parametrically adaptive, 328, 330, 338, 364, 558,
559
parametrically adaptive Bayesian signal
processor, 330, 335
partial differential equation, 10
partial fraction expansion, 136
particle, 8, 254
particle approximation, 305
particle degeneracy problem, 269
particle depletion, 286, 317
particle diversity, 285, 286
particle ilter, 8, 283, 291, 298, 299, 301, 302,
323, 327, 455, 505, 511, 512, 520, 555, 563,
565, 572
particle iltering, 253, 254, 255, 258, 269, 317,
359
particle number, 299
particle paths, 279
particle set, 284
particle weights, 262
particles, 254, 255, 269, 283, 345, 347
partitions, 333
Parzen-window, 55, 57
passive localization, 175
path, 382, 385, 386, 387
penalty function, 207
perfect detection, 424, 431, 433
perfect sampling, 7, 70, 455
performance, 310, 459

596
INDEX
performance analysis, 291, 473, 515
performance metric, 440
performance statistics, 38
performance tests, 290
perturbation model, 198
perturbation trajectory, 139
phase change detector, 471
phase modulation, 365
phased array radar, 229
photon counter, 33
photon emission computed tomography, 32
photon energy, 535
physical phenomenology, 9, 124, 521
physical system, 103, 107, 342, 385
physics-based, 531, 535, 541
physics-based parameter estimation, 524
physics-based processor, 520, 522, 527, 553, 554
physics-based state–space, 546
piecewise constant, 332
plane wave model, 325
point estimate, 3, 280
point mass, 254, 255
Poisson, 30, 32
Poisson distribution, 29
Poisson-driven Markov process, 528
polar coordinates, 175
pole-zero, 102, 147
polyenergetic source, 543, 544, 546
population growth, 311, 317, 366
position measurement model, 487
positive predictive value, 436
positive delta family, 225
possible paths, 388
posterior, 2, 3, 20, 21, 38, 42, 75, 89, 214, 255,
305, 346
posterior distribution, 2–4, 8, 38, 39, 42, 45,
52–54, 83, 85, 87, 96, 219, 234, 261, 270,
274, 281, 290, 298, 301, 328, 344, 347, 348,
379, 385, 386, 407, 504, 505, 511, 532, 533,
538, 563, 564
posterior equation, 153
posterior iltering distribution, 353
posterior invariant distribution, 284
posterior mean, 213
posterior odds ratio, 442
posterior probability, 28, 155, 295, 299, 379, 380,
385, 388, 393 398, 442, 570
posterior probability surface, 299, 300
posterior tail performance, 274
posterior target distribution, 85
power spectrum, 144, 200, 251
practical application, 257
practical aspects, 317
practical implementation, 239
precision, 436
predicted cumulative distribution, 304
predicted error covariance, 237, 332
predicted estimate, 171, 185
predicted innovation ensemble estimate, 293
predicted MAP, 292
predicted measurement, 218, 332
predicted measurement cumulative distribution,
304, 305
predicted measurement ensemble estimate, 292
predicted perturbation, 170
predicted state distribution, 305
predicted state ensemble estimate, 292
predicted state error covariance, 217
predicted state estimation error, 216
prediction distribution, 3, 39, 44, 45, 154, 226,
274, 306, 307
prediction error, 185, 459, 470, 513
prediction error sequence, 470
prediction estimates, 526
prediction probability, 399
prediction recursion, 43, 153
prediction step, 217, 226, 228
prediction update, 237
predictive decomposition, 305
predictor-corrector form, 335
pressure-ield, 500–503, 507, 517, 518, 555–557,
559, 560, 564, 566, 567, 572
pressure-ield measurement, 498, 500
prior, 2, 3, 4, 21, 39, 41, 53, 84
prior odds ratio, 442
prior prediction, 261
prior probability, 408, 410
probabilistic axioms, 581
probabilistic chain rule, 581
probabilistic framework, 37
probabilistic information, 262
probabilistic model, 367, 372
probabilistic transition distribution, 151
probabilistic transition mechanism, 402–404
probability bound, 308
probability density, 24, 54, 57, 58, 225, 282, 283
probability distribution, 1, 4, 9, 27, 37, 52, 54, 66,
68, 73, 202, 225, 253, 255, 295, 301, 368,
384, 406, 408, 410, 422
probability distribution function, 297, 576, 577
probability mass, 60, 254, 263, 266, 279
probability mass function, 7, 9, 94, 455, 577, 580
probability matrices, 392
probability of miss, 404
probability of detection, 404, 427
probability of error, 381

INDEX
597
probability of false alarm, 404, 427
probability of success, 267
probability space, 301
probability surface, 302
probability theory, 579
probability-of-error, 411, 412, 414, 421, 433, 472
process dynamics, 10
process model, 9, 154
process noise, 261, 272, 354
process noise covariance, 160, 323, 342, 343, 566
processor performance, 292, 514, 519
processor statistics, 189
proposal distribution, 65, 67, 74, 79, 83, 85, 259,
271
pulse transfer function, 125, 147
pulse-height spectrum, 540
quadrature Bayesian processor, 223
quadrature points, 223
quantile estimate, 311
radar, 363
radar tracking system, 471
radiation detection, 534, 541
radionuclide, 33, 529, 531, 535–537, 539–541
radionuclide contraband detection, 528
radionuclide detection, 532, 535, 537
radionuclide source, 528, 530
radionuclide source detection, 528
random amplitude, 50
random detection, 425, 430
random draw, 55
random inputs, 117
random measure, 254, 262, 267
random parameter, 2, 20
random sample, 5, 7, 8, 58, 59
random sampling, 4, 53, 59, 268
random signal, 2, 6, 37, 67, 117, 127, 251
random signal processing, 3
random target motion, 352
random telegraph signal, 384
random variable, 54, 59, 144, 576
random vector, 28, 48, 202, 205
random walk, 75, 76, 285, 332, 342, 343, 347,
352
random walk Metropolis–Hastings, 77
random walk parametric model, 359
range, 232
rank, 111, 113
rate parameter, 29, 32
Rayleigh-distributed, 50
RC-circuit, 449, 467
realization problem, 112
realizations, 62, 576
receiver operating characteristic, 402, 532
receiver operating characteristic (ROC) curve,
402, 500, 532
recursive algorithms, 470
recursive Bayesian estimation, 38
recursive form, 12, 13
recursive parameter estimate, 471
recursive prediction error method, 469, 470
recursive processor, 202, 213
recursive-in-time, 468, 470
reentry vehicle, 468
reference measurement, 139, 165
reference position estimate, 488
reference state, 170
reference trajectory, 138, 139, 162, 164, 168, 170,
179
region of strongest support, 285
regions of high probability, 348
regression coeficients, 323
regression form, 217
regression techniques, 235
regression weights, 204
regularization kernel, 282
regularization property, 282
regularized, 317, 347
rejection method, 64, 67, 74, 95, 265
rejection probability, 436
rejection sampling, 64, 73, 81, 90
rejection sampling method, 65, 95
relative frequency, 55
relative performance, 290
replication, 266, 285
resampled particles, 285
resampled uniformly, 270
resampling, 263, 264, 266, 267, 268, 272, 274,
281, 285, 286, 354, 508
resampling problem, 253
resampling process, 283
resampling scheme, 267, 269
resampling step, 266, 285
residual prediction, 219
residual resampling, 269
residual samples, 307
residual sequence, 290, 304, 305, 307–309, 513
residuals, 218, 305, 307, 309, 567
resolvent matrix, 101, 102
response time, 102
resulting processor, 44
reverberant channel, 390
RLC circuit, 190, 194, 236, 244, 245
ROC, 424, 425, 427–432, 434–438, 440, 444,
447, 450, 454, 458, 459, 473, 511, 520, 535

598
INDEX
roots, 102
Rosenblatt’s theorem, 304
roughening, 324, 343, 344, 347, 348
Runge–Kutta, 104
RV dynamics, 471, 472
S-plane, 102
sample impoverishment problem, 343
sample mean, 13, 70, 186, 310, 464
sample space, 576
sample variance, 162, 187, 189, 465
sample-based simulation, 53, 61
sampled-data, 98, 102, 142, 245, 460
sampled-data model, 103
sampled-data process noise, 116
sampled-data system, 103, 104, 107, 117, 116,
342
sampling, 64, 80, 254
sampling algorithms, 64, 79
sampling approach, 5, 8
sampling distribution, 86
sampling interval, 105
sampling scheme, 267, 269
sampling technique, 5, 52, 68, 79
sampling theory, 83, 90
sampling–resampling, 201
sampling-importance-resampling, 67, 253, 274
sanity, 348, 500
sanity testing, 290, 293 ,567
satellite communications, 229
scaled kernel, 283
scaled metric, 302
scaling and squaring, 104
scintillation measurement, 545
sensor array, 498
sequence estimation, 383
sequential approaches, 12, 67, 83
sequential Bayesian detector, 541, 553, 554
sequential Bayesian estimation, 38, 41, 254
sequential Bayesian framework, 353
sequential Bayesian posterior estimator, 42
sequential Bayesian processor, 42, 45, 540, 541,
555
sequential Bayesian radiation detector, 535
sequential Bayesian recursion, 286, 368
sequential Bayesian solution, 500
sequential counting technique, 539
sequential data assimilation, 235
sequential decision function, 442, 445, 535, 539
sequential detection, 440, 441, 443, 444, 447,
451, 455, 473, 529, 532, 540
sequential detector, 449, 453, 457, 511, 520
sequential estimation, 87, 253, 290, 539
sequential estimation framework, 38
sequential hypothesis testing, 443
sequential importance sampling, 89, 90, 256, 257
sequential innovations detector, 461, 463
sequential likelihood, 462
sequential likelihood detection, 447
sequential likelihood-ratio, 441, 446–448, 452
sequential log-likelihood, 441, 444, 449, 453,
457, 462, 532, 533, 535
sequential log-likelihood decision function, 511
sequential log-likelihood detector, 512
sequential methods, 38
sequential model-based detector, 451
sequential Monte Carlo, 253, 327, 341 508, 538
sequential probability-ratio test, 443, 462, 511,
532
sequential processing, 2, 12, 171, 531
sequential simulation-based techniques, 263
sequential source detection, 500, 519
sequential updating, 271
sequentially estimate, 255
series approach, 104
shallow ocean environment, 498, 500, 555, 558
shallow water channel, 512
sifting property, 7, 86, 227, 457
sigma points, 205, 222, 288, 563
sigma-point Bayesian processor, 201, 245
sigma-point processor, 274
sigma-point transformation, 53, 205, 206
signal enhancement, 37, 43, 153, 500, 504
signal estimation, 2, 448, 451
signal model, 531
signal processing, 6, 7, 9, 53, 67, 82, 99, 185,
384, 390
signal-to-noise ratio, 9, 540, 553
signiicance level, 187, 189, 307, 464, 466
similarity transformations, 105
simulated trajectories, 266
simulation-based approach, 4, 7, 67
simulation-based Bayesian processors, 52
simulation-based methods, 54, 58
simulation-based sampling, 90, 262
simulation-based solution, 70
single input/single output, 124
single realization, 291
singular vector, 113, 114
skewness Index, 311
slice sampler, 81, 90, 96, 97
smart sensor, 522
smoothed histogram, 517
smoothing, 378
smoothing parameter, 57
smoothing relation, 382

INDEX
599
sonar, 175
sound-speed proile, 497, 501, 512, 560
source detection problem, 498, 509
space–time processing problem, 349
spatiotemporal channel, 390
spatiotemporal matched ilter, 390
speciicity, 437
spectral factorization, 124
spectrogram, 468, 469, 471
square-root matrices, 114
squared-error, 343
stability, 102, 197
stable realization, 114
standard Gauss–Markov model, 123
standard Gaussian, 309
standard uniform, 304
state, 98, 99
state covariance, 119
state delay, 197
state ensemble, 239
state ensemble estimate, 292
state equations, 100, 101, 103
state error, 240
state error covariance, 154
state error covariance update, 219
state error prediction, 217
state estimate, 170, 292, 379, 382
state estimation, 327, 328, 346, 377, 379
state estimation error, 154, 155, 189
state estimation problem, 153, 345, 366, 376,
378, 381, 395
state mean vector, 118
state perturbation, 165
state posterior distribution, 328, 398
state prediction, 215, 237
state prediction probability, 398
state sequence, 385, 387, 391, 394
state sequence estimation, 383
state transition, 104, 344, 376, 387, 456
state transition distribution, 353
state transition matrix, 102–104, 109, 196, 368,
373, 400
state transition mechanism, 48
state transition model, 345
state transition probability, 152, 312, 370
state variable, 99, 213
state variance, 117, 118
state vector, 99, 101
state–input transfer matrix, 101
state–space, 2, 99, 160, 194, 224, 229, 323, 556
state–space ensemble, 235, 236
state–space form, 138, 147, 148, 162, 324
state–space formulation, 342
state–space forward propagator, 500, 512, 565,
566
state–space model, 98, 99, 107, 124, 142, 150,
151, 185, 352
state–space particle algorithm, 255
state–space representation, 98, 99, 108, 115, 124,
152, 253–255, 500
state–space representations, 124, 371
state–space structures, 124
state–space transition, 270
state–space transmission model, 544
state-transition probability matrix, 368, 376
state/parameter estimation, 27, 329, 331
state information, 215
static parameter, 348
stationary, 73, 119
stationary chain, 375
stationary distribution, 67
stationary processes, 121
statistical approximation, 202
statistical changes, 461
statistical estimation, 70
statistical hypothesis test, 187, 423, 466
statistical indexes, 310
statistical inference, 2, 3, 39, 53, 262
statistical linearization, 288
statistical measure, 67
statistical mechanics, 66
statistical model, 533
statistical sampling techniques, 59
statistical signal processing, 5, 37, 45, 150, 513
statistical simulation-based techniques, 53
statistical testing, 253, 305
statistical tests, 185, 253, 290, 304, 305, 311,
317, 470
statistically white sequence, 162
statistics, 255
steady state, 119, 189, 362
stochastic linearization, 245
stochastic process, 171, 367, 578, 580
stochastic realization, 371
stochastic sampling, 68
stochastic system, 4
stopping rule, 180
strong Law of Large Numbers, 67
structural model, 363
Student T distribution, 77
suboptimal, 337
suficient statistic, 25, 33, 430
sum-squared error criterion, 37
superposition integral, 103
survival of the ittest, 271
switching model, 399

600
INDEX
symmetric distribution, 74
synthetic aperture, 324, 349, 352, 354, 359
system identiication, 295, 342, 384
system model, 107
systematic resampling, 266, 268
systems theory, 99, 101, 109, 115, 384
T/R, 390, 391
T/R processor, 391, 395
tail index, 311
tank, 324
target, 199, 250
target distribution, 65, 73, 77, 80, 81, 84, 85, 96
target posterior distribution, 53, 54, 74, 255, 262
target tracking, 359
Taylor series, 53, 98 104, 106, 107, 117, 139, 140
173, 180, 191, 196, 201, 213, 364, 452
test statistic, 187, 188, 307, 308, 464–466
thermal delection, 524
threat detection, 543
threshold, 403, 415, 428, 437, 449, 450, 453, 463,
511, 532, 540, 550
threshold align, 429
threshold averaging method, 429, 438
threshold value, 427
time delay, 199, 250, 325
time domain representation, 125
time reversed, 391
time reversible, 73
time-frequency, 468
time-invariant systems, 109
time-reversed Green’s function, 391
time-varying, 104, 153, 170, 364
time-varying volatility, 323
total observation probability, 373, 375, 376, 379
total observation sequence, 378
total probability-of-error, 404, 411, 433
towed array, 359
tracking problem, 175, 228, 233, 245, 271, 371
tracking speed, 343
tracking telescope, 19
training sequence, 199, 251, 387, 388, 390
training sets, 384
trajectory estimation, 293, 302, 348
transfer function, 100, 108, 109, 112, 125, 136
transfer function matrix, 101
transformed residual, 306, 307, 310
transformed statistics, 213
transition distribution, 79, 80
transition kernel, 73, 74, 284
transition matrix, 101, 367, 399
transition mechanism, 402
transition posterior, 346
transition prior, 261, 271, 286, 305, 306, 317
transition probability, 4, 73, 80, 151, 152, 280,
353, 368, 375, 376, 384, 507, 528
transition probability matrix, 398
transport physics, 541, 544
true distribution, 298
true negative rate, 436
true positive rate, 436
true posterior, 282, 290, 298
truncated Gaussian, 66
truncation error, 106
truth model, 291, 298, 299, 301, 302
tuned processor, 186, 189, 274, 344
UD-factorized form, 335
unbiased, 67, 69
unbiased estimator, 47, 84
uncertainty bound, 547
unconditionally unbiased, 36
uncorrelated noise, 123
unequally sampled data, 104
uniform convergence, 227
uniform distribution, 58, 60, 290
uniform intervals, 82
uniform proposal, 96
uniform random samples, 5, 267
uniform random variable, 58
uniform sampling, 64, 69, 70, 90, 266
uniform transformation theorem, 60, 61, 304
uniform variate, 58, 63
uniform weighting, 266, 270
uniformity property, 307
uniformly distributed, 58, 59, 81, 308, 309
uniformly sampling, 266
unimodal, 253, 274, 304, 563
unit step function, 62
unnormalized weight, 87
unobservable, 110
unscented, 288
unscented Kalman ilter, 202, 235, 245, 354, 451,
555, 563, 572
unscented transformation, 205, 288
update equation, 43, 165, 185
update step, 224, 388
updated error covariance, 157
updated estimate, 27, 170, 171, 179, 241
validation problem, 293
validity, 290, 304
variance, 128, 579
variance equations, 121
vector calculus, 22
vertical wave number, 501

INDEX
601
vertical averaging, 429
Viterbi algorithm, 382, 383, 388, 390, 393,
395
volatility, 322, 323
Wald, 462, 511, 532
wavefront curvature, 325
wavenumber, 555, 558
weight variance, 258, 317
weighted particles, 254
weighted quadrature points, 224
weighted sum-squared residual, 292, 465, 514
weighting function, 42, 54, 85–87, 563
weighting matrix, 186
weights, 254, 261
white, 117, 123, 148, 162, 177, 185, 232, 290,
527
white noise, 98, 145
whiteness, 185, 293, 472
whiteness test, 162, 187–189, 290, 307, 311, 465,
466, 567, 569
whitening transformation, 283
Wiener solution, 37
Wiener–Kalman iltering, 124
Wold decomposition, 125
X-ray propagation, 541, 543, 546
X-ray transport physics, 541, 554
Z-transform, 108, 111, 120, 121
zero state, 101
zero-mean, 144, 148, 162, 199, 232, 251, 290,
293, 513, 527, 567, 569
zero-mean and white, 461
zero-mean test, 185, 187, 470
zero-mean/whiteness, 292, 348, 493
zero-mean/whiteness detector, 490
zero-mean/whiteness test, 304, 307, 337, 340, 468

Wiley Series on
Adaptive and Cognitive Dynamic Systems
Editor: Simon Haykin
Adali and Haykin r Adaptive Signal Processing: Next Generation Solutions
Beckerman r Adaptive Cooperative Systems
Candy r Model-Based Signal Processing
Candy r Bayesian Signal Processing: Classical, Modern, and Particle Filtering Methods,
Second Edition
Chen, Haykin, Eggermont, and Becker r Correlative Learning: A Basis for Brain and
Adaptive Systems
Chen and Gu r Control-Oriented System Identiication: An H∞Approach
Cherkassky and Mulier r Learning from Data: Concepts, Theory, and Methods
Cirrincione and Cirrincione r Neural-Based Orthogonal Data Fitting: The EXIN Neural
Networks
Costa and Haykin r Multiple-Input Multiple-Output Channel Models: Theory and Practice
Diamantaras and Kung r Principal Component Neural Networks: Theory and Applications
Haykin r Unsupervised Adaptive Filtering: Blind Source Separation
Haykin r Unsupervised Adaptive Filtering: Blind Deconvolution
Haykin and Liu r Handbook on Array Processing and Sensor Networks
Haykin and Puthussarypady r Chaotic Dynamics of Sea Clutter
Haykin and Widrow r Least Mean-Square Adaptive Filters
Hossain, Le, and Niyato r Radio Resource Management in Multi-Tier Cellular Wireless
Networks
Hrycej r Neurocontrol: Towards an Industrial Control Methodology
Hyv¨urinen, Karhunen, and Oja r Independent Component Analysis
Kristi´c, Kanellakopoulos, and Kokotovi´c r Nonlinear and Adaptive Control Design
Mann r Intelligent Image Processing
Nikias and Shao r Signal Processing with Alpha-Stable Distributions and Applications
Passino and Burgess r Stability Analysis of Discrete Event Systems
S´anchez-Pẽna and Sznaier r Robust Systems: Theory and Applications
Sandberg, Lo, Fancourt, Principe, Katagairi, and Haykin r Nonlinear Dynamical Systems:
Feedforward Neural Network Perspectives
Sellathurai and Haykin r Space-Time Layered Information Processing for Wireless
Communications
Spooner, Maggiore, Ord´õnez, and Passino r Stable Adaptive Control and Estimation for
Nonlinear Systems: Neural and Fuzzy Approximator Techniques
Tao r Adaptive Control Design and Analysis
Tao and Kokotovi´c r Adaptive Control of Systems with Actuator and Sensor Nonlinearities
Tsoukalas and Uhrig r Fuzzy and Neural Approaches in Engineering
Van Hulle r Faithful Representations and Topographic Maps: From Distortion- to
Information-Based Self-Organization
Vapnik r Statistical Learning Theory
Werbos r The Roots of Backpropagation: From Ordered Derivatives to Neural Networks and
Political Forecasting
Yee and Haykin r Regularized Radial Bias Function Networks: Theory and Applications

