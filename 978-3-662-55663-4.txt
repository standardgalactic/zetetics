Emergence, Complexity and Computation ECC
Ivan Zelinka
Guanrong Chen    Editors 
Evolutionary 
Algorithms, Swarm 
Dynamics and 
Complex Networks
Methodology, Perspectives and 
Implementation

Emergence, Complexity and Computation
Volume 26
Series editors
Ivan Zelinka, Technical University of Ostrava, Ostrava, Czech Republic
e-mail: ivan.zelinka@vsb.cz
Andrew Adamatzky, University of the West of England, Bristol, UK
e-mail: adamatzky@gmail.com
Guanrong Chen, City University of Hong Kong, Hong Kong, China
e-mail: eegchen@cityu.edu.hk
Editorial Board
Ajith Abraham, MirLabs, USA
Ana Lucia C. Bazzan, Universidade Federal do Rio Grande do Sul, Porto Alegre,
RS, Brazil
Juan C. Burguillo, University of Vigo, Spain
Sergej Čelikovský, Academy of Sciences of the Czech Republic, Czech Republic
Mohammed Chadli, University of Jules Verne, France
Emilio Corchado, University of Salamanca, Spain
Donald Davendra, Technical University of Ostrava, Czech Republic
Andrew Ilachinski, Center for Naval Analyses, USA
Jouni Lampinen, University of Vaasa, Finland
Martin Middendorf, University of Leipzig, Germany
Edward Ott, University of Maryland, USA
Linqiang Pan, Huazhong University of Science and Technology, Wuhan, China
Gheorghe Păun, Romanian Academy, Bucharest, Romania
Hendrik Richter, HTWK Leipzig University of Applied Sciences, Germany
Juan A. Rodriguez-Aguilar, IIIA-CSIC, Spain
Otto Rössler, Institute of Physical and Theoretical Chemistry, Tübingen, Germany
Vaclav Snasel, Technical University of Ostrava, Czech Republic
Ivo Vondrák, Technical University of Ostrava, Czech Republic
Hector Zenil, Karolinska Institute, Sweden

About this Series
The Emergence, Complexity and Computation (ECC) series publishes new
developments, advancements and selected topics in the ﬁelds of complexity,
computation and emergence. The series focuses on all aspects of reality-based
computation approaches from an interdisciplinary point of view, especially from
applied sciences, biology, physics, or chemistry. It presents new ideas and
interdisciplinary insight on the mutual intersection of subareas of computation,
complexity and emergence and its impact and limits to any computing based on
physical limits (thermodynamic and quantum limits, Bremermann’s limit, Seth
Lloyd limits…) as well as algorithmic limits (Gödel’s proof and its impact on
calculation, algorithmic complexity, Chaitin’s Omega number and Kolmogorov
complexity, non-traditional calculations like Turing machine process and its
consequences,…) and limitations arising in the artiﬁcial intelligence ﬁeld. The
topics are (but not limited to) membrane computing, DNA computing, immune
computing, quantum computing, swarm computing, analogic computing, chaos
computing and computing on the edge of chaos, computational aspects of dynamics
of complex systems (systems with self-organization, multiagent systems, cellular
automata, artiﬁcial life,…), emergence of complex systems and its computational
aspects, as well as agent based computation. The aim of this series is to discuss the
above-mentioned topics from an interdisciplinary point of view and present new
ideas coming from the mutual intersection of classical as well as modern methods
of computation. Within the scope of the series are monographs, lecture notes,
selected contributions from specialized conferences and workshops, special
contribution from international experts.
More information about this series at http://www.springer.com/series/10624

Ivan Zelinka
• Guanrong Chen
Editors
Evolutionary Algorithms,
Swarm Dynamics
and Complex Networks
Methodology, Perspectives
and Implementation
123

Editors
Ivan Zelinka
Department of Computer Science
Faculty of Electrical Engineering
and Computer Science VŠB-TUO
Ostrava, Poruba
Czech Republic
Guanrong Chen
Department of Electronic Engineering
City University of Hong Kong
Kowloon, Hong Kong
China
ISSN 2194-7287
ISSN 2194-7295
(electronic)
Emergence, Complexity and Computation
ISBN 978-3-662-55661-0
ISBN 978-3-662-55663-4
(eBook)
https://doi.org/10.1007/978-3-662-55663-4
Library of Congress Control Number: 2017948219
© Springer-Verlag GmbH Germany 2018
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made. The publisher remains neutral with regard to
jurisdictional claims in published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer-Verlag GmbH Germany
The registered company address is: Heidelberger Platz 3, 14197 Berlin, Germany

Ivan Zelinka dedicates this book to his family
and parents.
Guanrong Chen dedicates this book to the
memory of his mentor Professor Mingjun
Chen (1934–2008).

Foreword
Several natural processes including Darwinian evolution, the collective behavior of
social creatures and their foraging strategies are centered around the classical task of
optimization. For more than half a century now, researchers have been drawing
inspirations from the life-supporting activities and adaptation mechanisms of nat-
ural creatures to design algorithms that can solve complex and mathematically
intractable search and optimization problems which are ubiquitous in disciplines of
science and technology. Currently, the ﬁeld of such nature-inspired algorithms is
growing at a spectacular rate, and new algorithmic variants are continually
emerging to meet the fast-growing challenges of the real-world optimization
problems, for which no mathematically guaranteed methods are available. The two
main families of algorithms that primarily constitute this ﬁeld today are the evo-
lutionary computing methods and the swarm intelligence algorithms.
The book edited by Profs. Ivan Zelinka and Guanrong Chen takes a very dif-
ferent and elegant view of the fundamental algorithms belonging to evolutionary
computing and swarm intelligence: how to obtain an insight into the dynamics of
such algorithms by modeling them through the dynamics of an equivalent social
network? This view enables researchers to gain valuable information about the
search dynamics of these algorithms, thereby predicting the useful ranges of the
associated control parameters and applicability to various real-life problems, by
analyzing the equivalent social network. The book presents a well-organized col-
lection of 14 comprehensive chapters divided into three parts. The reader is care-
fully navigated through the efﬁcacies of complex networks, swarm and evolutionary
dynamics, and their randomization aspects. The exposure of the material is lucid.
Quite complicated concepts are presented in a clear and convincing way which
attributed to the expertise of the chapter authors and the Editors. The ﬁnal chapters
of the book (like Chaps. 11 and 12) provide very interesting extensions of the ideas
presented previously towards more practical scenarios, for example, Chap. 11 deals
with the dynamics and communications of swarm virus seen through the lens of
complex networks. In the exposure of the material, the authors have achieved a
sound balance between the theory and practice.
vii

This book is the ﬁrst of its kind, presenting a very interesting intersection of
three fast-growing research ﬁelds of the swarm and evolutionary computing,
complex networks, and CML systems. The idea of their mutual intersection is not
very typical in the existing literature, and this is probably one of the main reasons
why this edition should be especially valuable for the scientiﬁc and engineering
research community.
Finally, I must conclude that this is not only an urgently needed and very timely
volume, but also an authoritative and exceptionally well-compiled treatise of the
fascinating topic of uniﬁcation of the meta-heuristic dynamics and complex
networks.
Swagatam Das
Indian Statistical Institute, Kolkata, India
viii
Foreword

Preface
Evolutionary algorithms constitute a class of well-known numerical methods,
which are based on the Darwinian theory of evolution and Mendelian theory of
heritage. They are partly based on random and partly based on deterministic
principles. Due to this nature, it is challenging to predict its performance in solving
complex nonlinear problems. Many techniques and hybridization methods have
been developed to improve the algorithmic performances. These methods are
typically based on statistical approaches and usually lead to a recommended setting
for a given algorithm or a class of algorithms. Also, very diverse hybridizations are
suggested by utilizing deterministic chaos instead of using other pseudorandom
number generators, showing promising features and unique advantages. Recently,
the study of evolutionary dynamics is focused not only on the traditional investi-
gations, but also on the understanding and analyzing new principles, with the
intention of controlling and utilizing their properties and performances toward more
effective real-world applications.
This book, based on many years of intensive research of the authors, is
proposing novel ideas about advancing evolutionary dynamics toward new phe-
nomena including many new topics, even the dynamics of equivalent social net-
works. In fact, it includes more advanced complex networks and incorporates them
with the CMLs (coupled map lattices), which are usually used for spatiotemporal
complex systems simulation and analysis, based on the observation that chaos in
CML can be controlled, so does evolution dynamics. It will be shown that evo-
lutionary algorithms can be understood just like dynamical systems with feedback.
Thus, at least in theory, all engineering control methods can be applied. All such
ideas will be illustrated and discussed in the following chapters. All the chapter
authors are, to the best of our knowledge, originators of the ideas mentioned above
and researchers on evolutionary algorithms and chaotic dynamics as well as
complex networks, who will provide beneﬁts to the readers regarding modern
scientiﬁc research on related subjects.
ix

The organization of the chapters in the book is as follows. The book consists of
three parts. The ﬁrst part (Theory) discusses and explains basic ideas about swarm
dynamics and evolutionary algorithms related to complex networks and CML
systems. Chapter 1 presents most important notions with comprehensive references.
Chapter 2 discusses how to create networks from evolutionary dynamics, based on
a few selected evolutionary algorithms, like ant colony optimization, with original
experiments and visualizations. The second part (Applications) shows how the idea
above can be applied to developing various effective algorithms and what levels of
success it can reach to. Chapter 3 reports the use of the differential evolution
algorithms and its conversion into networks with performance improvements.
Chapters 4–6 explain, in more details, the conversion, analysis, and improvement
of the SOMA algorithm using the complex network framework. In Chap. 7, the use
of complex networks in particle swarm algorithms is discussed, followed by an
investigation of artiﬁcial bee colony algorithms in Chap. 8. Chapter 9 then presents
different views on how randomization and complex networks can be constructed for
meta-heuristic algorithms. The last part (Miscellanies) contains a few interesting
chapters as possible extensions of the above-discussed ideas to other directions.
Chapter 11 discusses possibilities for dynamics and communications of swarm
computer viruses to be visualized as a network. This can be necessary for its
analysis and prevention in the future. Today, the most advanced virus-attacking
technology is perhaps Botnet or viruses developed based on the CnC (command
and control) technology, e.g., Stuxnet or Gauss. Such new viral technologies can be
used not only for swarm intelligence, but also for the evolution of virus codes. This
chapter predicts the future merging of technologies such as swarm intelligence,
evolution dynamics, and complex networks. Chapter 12 further explains how
networks are related to the way they are extended to cellular automata. Chapter 13
studies the topic of this book but from an opposite point of view as for how
evolutionary dynamics can be used to design power grid networks. Chapter 14
discusses the dynamic analysis of genetic regulatory networks which can be an
inspiration to be applied to topics mentioned above.
Regarding the readership of the book, it presents instructional materials for
senior undergraduate and graduate students in computer science, physics, applied
mathematics and engineering, among others, who are working in the ﬁelds of
complex networks and evolutionary algorithms, and even chaotic dynamics.
Researchers who want to learn more on how evolutionary algorithms can be con-
structed, analyzed, or controlled, as well as the relationships among swarm
dynamics, complex networks, and CML systems, will ﬁnd this book very useful.
The book will be a resource handbook and material collection for practitioners who
want to apply these methods to solve real-life problems in challenging applications.
This book is by no means comprehensive on the three ﬁelds of research due to its
page limitation. Only selected basic ideas and main results are reported. For further
x
Preface

info, it is recommended to read referenced literature, which contains all relevant
research results and the latest research progress. The editors and the chapter authors
hope that the readers will ﬁnd the book informative and valuable for their studies,
experiments, and simulations.
Ostrava, Czech Republic
Ivan Zelinka
Kowloon, Hong Kong
Guanrong Chen
June 2017
Preface
xi

Acknowledgements
The following grants are acknowledged for the ﬁnancial support provided to this
research: Grant Agency of the Czech Republic—GACR P103/15/06700S, Grant of
SGS No. SGS 2017/134, VSB-Technical University of Ostrava, the Ministry of
Education, Youth and Sports from the National Programme of Sustainability
(NPU II) project “IT4Innovations excellence in science - LQ1602”.
xiii

Contents
Part I Theory
1
Swarm and Evolutionary Dynamics as a Network . . . . . . . . . . . . . .
3
Ivan Zelinka
2
Evolutionary Dynamics and Its Network Visualization - Selected
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
Orkhan Yarakhmedov, Victor Polyakh, Ivan Chernogorov
and Ivan Zelinka
Part II Applications
3
Differential Evolution Dynamics Modeled by Social Networks . . . .
. . . .
67
Lenka Skanderová and Ivan Zelinka
4
Conversion of SOMA Algorithm into Complex Networks . . . . . . . .
101
Lukáš Tomaszek and Ivan Zelinka
5
Analysis of SOMA Algorithm Using Complex Network . . . . . . . . . .
115
Lukáš Tomaszek and Ivan Zelinka
6
Improvement of SOMA Algorithm Using Complex Networks . . . . .
131
Lukáš Tomaszek and Ivan Zelinka
7
Complex Networks in Particle Swarm . . . . . . . . . . . . . . . . . . . . . . . .
145
Michal Pluhacek, Roman Šenkeřík, Adam Viktorin
and Tomas Kadavy
8
Comparison of Vertex Centrality Measures in Complex Network
Analysis Based on Adaptive Artiﬁcial Bee Colony Algorithm . . . . .
161
Magdalena Metlicka and Donald Davendra
xv

9
Randomization and Complex Networks for Meta-Heuristic
Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
177
Roman Šenkeřík, Ivan Zelinka, Michal Pluhacek, Adam Viktorin,
Jakub Janostik and Zuzana Kominkova Oplatkova
10
Gallery of Evolutionary Networks . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
Ivan Zelinka, Roman Šenkeřík and Michal Pluháček
Part III Miscellanies
11
Swarm Virus, Evolution, Behavior and Networking. . . . . . . . . . . . .
213
Lubomir Sikora and Ivan Zelinka
12
Simple Networks on Complex Cellular Automata: From de
Bruijn Diagrams to Jump-Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . .
241
Genaro J. Martínez, Andrew Adamatzky, Bo Chen, Fangyue Chen
and Juan C. Seck-Tuoh-Mora
13
A Hybrid Multi-objective Evolutionary Approach for Power Grid
Topology Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
265
Xiaowen Bi and Wallace K.S. Tang
14
Dynamic Analysis of Genetic Regulatory Networks with Delays
. . .
. . .
285
Zhi-Hong Guan and Guang Ling
15
Frontiers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
311
Ivan Zelinka
xvi
Contents

Contributors
Andrew
Adamatzky International
Centre
of
Unconventional
Computing,
University of the West of England, Bristol, UK
Xiaowen Bi Department of Electronic Engineering, City University of Hong
Kong, Kowloon, Hong Kong
Bo Chen School of Science, Hangzhou Dianzi University, Hangzhou, China
Fangyue Chen School of Science, Hangzhou Dianzi University, Hangzhou, China
Ivan Chernogorov Software of Computer Engineering and Automated Systems
Department, Information Technology and Computer Science Faculty, Don State
Technical University, Rostov, Russia
Donald
Davendra Department
of
Computer
Science,
Central
Washington
University, 400 E. University Way, Ellensburg, Washington, USA; Faculty of
Electrical Engineering and Computer Science, Department of Computer Science
VŠB – Technical University of Ostrava, Ostrava-Poruba, Czech Republic
Zhi-Hong Guan College of Automation, Huazhong University of Science and
Technology, Wuhan, P. R. China
Jakub Janostik Faculty of Applied Informatics, Department of Informatics and
Artiﬁcial Intelligence, Tomas Bata University in Zlín, Zlín, Czech Republic
Tomas Kadavy Regional Research Centre CEBIA-Tech, Tomas Bata University
in Zlín, Zlín, Czech Republic
Zuzana Kominkova Oplatkova Faculty of Applied Informatics, Department of
Informatics and Artiﬁcial Intelligence, Tomas Bata University in Zlín, Zlín, Czech
Republic
Guang Ling School of Science, Wuhan University of Technology, Wuhan,
P. R. China
xvii

Genaro
J.
Martínez International
Centre
of
Unconventional
Computing,
University of the West of England, Bristol, UK; Escuela Superior de Cómputo,
Instituto Politécnico Nacional, México City, México
Magdalena Metlicka College of Information and Computer Sciences, University
of Massachusetts Amherst. 140 Governors Dr., Amherst, Massachusetts, USA
Michal Pluhacek Regional Research Centre CEBIA-Tech, Tomas Bata University
in Zlín, Zlín, Czech Republic; Department of Informatics and Artiﬁcial Intelligence,
Faculty of Applied Informatics, Tomas Bata University in Zlín, Zlín, Czech
Republic
Victor Polyakh Software of Computer Engineering and Automated Systems
Department, Information Technology and Computer Science Faculty, Don State
Technical University, Rostov, Russia
Juan C. Seck-Tuoh-Mora Área Académica de Ingeniería, Universidad Autónoma
del Estado de Hidalgo, Pachuca, Hidalgo, México
Roman Šenkeřík Regional Research Centre CEBIA-Tech, Tomas Bata University in
Zlín, Zlín, Czech Republic; Faculty of Applied Informatics, Department of Informatics
and Artiﬁcial Intelligence, Tomas Bata University in Zlín, Zlín, Czech Republic
Lubomir Sikora Faculty of Electrical Engineering and Computer Science,
Department of Computer Science, VŠB – Technical University of Ostrava,
Ostrava-Poruba, Czech Republic
Lenka Skanderová Department of Computer Science, Faculty of Electrical
Engineering and Computer Science, VŠB – Technical University of Ostrava,
Ostrava-Poruba, Czech Republic
Wallace K.S. Tang Department of Electronic Engineering, City University of
Hong Kong, Kowloon, Hong Kong
Lukáš Tomaszek Faculty of Electrical Engineering and Computer Science,
Department of Computer Science, VŠB – Technical University of Ostrava,
Ostrava-Poruba, Czech Republic
Adam Viktorin Regional Research Centre CEBIA-Tech, Tomas Bata University
in Zlín, Zlín, Czech Republic; Faculty of Applied Informatics, Department of
Informatics and Artiﬁcial Intelligence, Tomas Bata University in Zlín, Zlín, Czech
Republic
Orkhan Yarakhmedov Software of Computer Engineering and Automated
Systems Department, Information Technology and Computer Science Faculty, Don
State Technical University, Rostov, Russia
Ivan Zelinka Department of Computer Science, Faculty of Electrical Engineering
and Computer Science, VŠB – Technical University of Ostrava, Ostrava-Poruba,
Czech Republic
xviii
Contributors

Acronyms
ABC
Artiﬁcial bee colony, heuristic algorithm
ACO
Ant colony optimization, heuristic algorithm based on
biological ant behavior
Best
The best individual, DE
Betweenness centrality
Graph attributes
CA
Cellular automata
CF
Cost function, used to evaluate individual quality
Chaotic map
Simple iterative description of chaotic systems
Closeness centrality
Graph attributes
CML
Coupled map lattices, simple model used to simulate
spatiotemporal deterministic chaos
CnC
Command and control, technology used to control
computer viruses in a centralized manner
CNCML
CML system that is created on scheme EA!CN!CML
CN
Complex network, graph (network) with nontrivial
topological features—features that do not occur in
simple networks such as lattices or random graphs,
usually occur in graphs modeling of real systems.
CNS
Complex network structure
CPRNG
Chaotic pseudorandom number generator, deterministic
chaos is used here instead of classical formulas for
PRNG
CR
Crossover threshold, DE
DE
Differential evolution
Degree centrality
Graph attributes
EA
Evolutionary algorithms
ECT
Evolutionary computational techniques
EP
Evolutionary programming
ES
Evolutionary strategies
xix

Fitness
Similar to CF, used to evaluate individual quality in
interval [0, 1], CF from min to max is converted into this
interval
F
Mutation factor, DE
GA
Genetic algorithms
G
Generations or graph (network)
Leader
The best individual in SOMA
Lj
Lower bound of interval for jth parameter of the
individual
Migrations
Migrations: Number of migrations/iterations of the
SOMA, equivalent to generations
MIMO
Multiple input—multiple output system
NP
Population (DE, SOMA)
Pheromone
Signal, weight on ant path used by ants (individuals) in
ACO
PL
PathLength: The distance the solution has to transverse
PopSize
Size of population, SOMA
PRNG
Pseudorandom number generator
PRT
PRTVector: Binary vector
PSO
Particle swarm algorithm
Rand
Random number, vector
SEA
Swarm and evolutionary algorithms
SOMA
Self-organizing migrating algorithm
SS
StepSize: The sampling period of the algorithm
Swarm virus
Computer virus based on swarm intelligence/algorithms
t
Time/iteration
Uj
Upper bound of interval for jth parameter of the
individual
Virus
Computer virus, self-replicate program
xG
r1
Randomly selected ﬁrst of three (or more) individuals in
DE
vG
i
Noisy vector in DE created by three randomly selected
individuals
w
Weight, PSO
X
Individual: Individual in the population
xi
Element: ith element in the individual
xG
i
Individual in the population, differential evolution
xx
Acronyms

List of Tables
Table 2.1
Detailed information about resulted graphs . . . . . . . . . . . . . . . .
60
Table 3.1
The analysis of cohesion of the 51 short-interval networks
created on the basis of the DE/rand/1/bin algorithm used to
search for the global optimum of the unimodal test functions
f1,f5, multimodal test function f6, and composition
function f21 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
Table 3.2
Triad models and their permitted triads. This table
is based on [11]. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
Table 3.3
The analysis of ranking of the 51 short-interval networks
created on the basis of the DE/rand/1/bin algorithm used to
search for the global optimum of the unimodal test functions
f1,f5, multimodal test functionf6, and composition
function f21 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
Table 3.4
The analysis of ranking of the 51 short-interval networks
created on the basis of the DE/rand/1/bin algorithm used to
ﬁnd the global optimum of the unimodal test functions f1,f5,
multimodal test function f6, and composition function f21.
The triad ratio of all triads except the triads number
003 and 012 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
Table 3.5
The cohesion analysis of the aggregated networks created on
the basis of the DE/rand/1/bin algorithm used to ﬁnd the
global optimum of the unimodal test functions f1,f5,
multimodal test function f6, and composition function f21 . . . . .
92
Table 3.6
The statistic analysis for the node-strength distribution for the
aggregated networks generated on the basis of the
DE/rand/1/bin algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
Table 4.1
SOMA parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
104
Table 6.1
CEC 2015 benchmark functions . . . . . . . . . . . . . . . . . . . . . . . .
132
Table 6.2
Results for D = 10 for SOMA Remove and SOMA AllToOne
for all CEC functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
136
xxi

Table 6.3
Results for D = 30 for SOMA Remove and SOMA AllToOne
for all CEC functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
138
Table 6.4
Results for D = 50 for SOMA Remove and SOMA AllToOne
for all CEC functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
140
Table 7.1
Network statistics - sphere function . . . . . . . . . . . . . . . . . . . . . .
150
Table 7.2
Network statistics - Schwefel function. . . . . . . . . . . . . . . . . . . .
153
Table 7.3
Network statistics - Rastrigin function . . . . . . . . . . . . . . . . . . . .
156
Table 7.4
Network statistics - multi-swarm PSO - Schwefel
function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
156
Table 8.1
Experiments. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
172
Table 8.2
Parameters settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
172
Table 8.3
Experiments results:n ¼ 10 . . . . . . . . . . . . . . . . . . . . . . . . . . . .
173
Table 8.4
Experiments results:n ¼ 20 . . . . . . . . . . . . . . . . . . . . . . . . . . . .
173
Table 8.5
Experiments results:n ¼ 30 . . . . . . . . . . . . . . . . . . . . . . . . . . . .
174
Table 9.1
Time Development of complex networks created by canonical
DE strategy De/Rand/ 1/Bin, Schwefel's function . . . . . . . . . . .
189
Table 9.2
Time Development of complex networks created by canonical
DE strategy De/Best/ 1/Bin, Schwefel's function . . . . . . . . . . . .
189
Table 9.3
Simple statistics of complex networks created by Chaos
DE/canonical DE strategy De/Rand/1/Bin,
Schwefel's function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
Table 9.4
Simple statistics of complex networks created by Chaos
DE/canonical DE strategy De/Best/1/Bin,
Schwefel's function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
Table 9.5
Simple statistics of complex networks created by Chaos
DE/canonical DE strategy De/Rand/1/Bin,
Ackley's function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
191
Table 9.6
Simple statistics of complex networks created by Chaos
DE/canonical DE strategy De/Best/1/Bin,
Ackley's function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
191
Table 13.1 Power injection Pi of generating nodes in Fig. 13.2 . . . . . . . . .
270
Table 13.2 Parameter settings of NSGA-II used in simulations . . . . . . . . . .
278
xxii
List of Tables

Part I
Theory

Chapter 1
Swarm and Evolutionary Dynamics
as a Network
Ivan Zelinka
Abstract This chapter is an introduction to a novel method for visualizing the
dynamics of evolutionary algorithms in the form of networks. The whole idea is based
on the obvious similarity between interactions between individuals in a swarm and
evolutionary algorithms and for example, users of social networks, linking between
web pages, etc. The analogy between individuals in populations in an arbitrary evolu-
tionary algorithm and vertices of a network is discussed, as well as between edges in
a network and communication between individuals in a population. The possibility of
visualizing the dynamics of network using the coupled map lattices method and con-
trol using chaos control techniques are also discussed. The chapter is introductory,
for more details it is recommended to read referenced sources.
1.1
Introduction
In this chapter, we merged two completely different areas of research: (complex)
networks and evolutionary computation. As already mentioned, interactions in a
swarm and evolutionary algorithms (SEA) can be considered like user interactions in
socialnetworksorjustpeopleinsociety.Thisinduceshypothesiswhetherinteractions
inside of SEA can be taken like interactions in society or swarm colonies. The
core of this idea is thus networks in general, speciﬁcally complex networks. In this
book, we are using networks and complex networks in the same meaning. It has
been observed that networks generated by evolutionary dynamics show properties
of complex networks in certain time frames and conditions. That is why it is used
here interchangeably. As suggested above, research that is still open is based on an
intersection of two ﬁelds - complex networks and SEA. Let’s discuss both ﬁelds
brieﬂy.
I. Zelinka (B)
Faculty of Electrical Engineering and Computer Science, Department of Computer Science,
VŠB – Technical University of Ostrava, 17. listopadu 15, 708 33
Ostrava-Poruba, Czech Republic
e-mail: ivan.zelinka@vsb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_1
3

4
I. Zelinka
Large-scale networks, exhibiting complex patterns of interaction amongst ver-
tices exist in both natures and human-made systems (i.e., communication networks,
genetic pathways, ecological or economic networks, social networks, networks of
various scientiﬁc collaboration, the Internet, World Wide Web, power grid, etc.). The
structure of complex networks thus can be observed in many systems. The word com-
plex networks [1, 2] comes from the fact that they exhibit substantial and non-trivial
topological features, with patterns of connection between vertices that are neither
purely regular nor purely random. Such features include a heavy tail in the degree
distribution, a high clustering coefﬁcient, hierarchical structure, amongst other fea-
tures. In the case of directed networks, these features also include reciprocity, triad
signiﬁcance proﬁle and other features. Amongst many studies, two well-known and
much-studied classes of complex networks are the scale-free networks and small-
world networks (see examples in Figs.1.1 and 1.2), whose discovery and deﬁnition
are vitally important in the scope of this research. Speciﬁc structural features can
be observed in both classes i.e. so-called power-law degree distributions for the
scale-free networks and short path lengths with high clustering for the small-world
networks. Research in the ﬁeld of complex networks has joined researchers from
many areas, which were outside of this interdisciplinary studies in the past like
mathematics, physics, biology, chemistry computer science, epidemiology, etc.
Evolutionary computation is a sub-discipline of computer science belonging to
the bio-inspired computing area. Since the end of the second world war, the main
3
4
5
7
8
9
10
11
12
13
14
16
18
19
21
22
23
24
27
28
31
32
33
34
35
36
38
39
40
41
42
43
44
45
47
48
1
2
6
15
17
20
25
26
29
30
37
46
49
50
Fig. 1.1 Example of a small network

1
Swarm and Evolutionary Dynamics as a Network
5
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
Fig. 1.2 A different network with multiple edges and selﬂoops
ideas of evolutionary computation have been published [3] and widely introduced
to the scientiﬁc community [4]. Hence, the golden era of evolutionary techniques
began, when Genetic Algorithms (GA) by Holland [4], Evolutionary Strategies (ES),
by Schwefel [5] and Rechenberg [6] and Evolutionary Programming (EP) by Fogel
[7] were introduced. All these designs were favored by the forthcoming of more
powerful and more easily programmable computers so that for the ﬁrst time interest-
ing problems could be tackled and evolutionary computation started to compete with
and became a serious alternative to other optimization methods. As mentioned in the
introduction, evolutionary algorithms are capable of hard problem-solving. Some
examples of evolutionary algorithms can be easily found. Evolutionary algorithms
(EA) use with chaotic systems is done for example in [8] where EAs have been used
on local optimization of chaos, [9] for chaos control with use of the multi-objective
cost function or in [10, 11], where evolutionary algorithms have been studied on
chaotic landscapes. Slightly different approach with evolutionary algorithms is pre-
sented in [12] where selected algorithms were used to synthesize artiﬁcial chaotic

6
I. Zelinka
systems. In [13, 14] EAs have been successfully used for real-time chaos control
and in [15] EAs were used for optimization of Chaos Control. Other examples of
evolutionary algorithms application can be found in [16], which developed statis-
tically robust evolutionary algorithms, alongside with research conducted by [17].
Parameters of permanent magnet synchronous motors have been optimized by PSO
and experimentally validated on the servomotor. Another research was focused on
swarm intelligence, which has been used for IIR ﬁlter synthesis, co-evolutionary
particle swarm optimization (CoPSO) approach for the design of constrained engi-
neering problems, particularly for pressure vessel, compression spring, welded beam,
etc. On the other side, complex networks, widely studied across many branches of
science are promising and represent a modern interdisciplinary research. Evolution-
ary algorithms, based on their canonical central dogma (following Darwinian ideas)
demonstrate intensive interaction amongst individuals in the population, which is
in general one of the important attributes of networks (as interaction amongst the
vertices). In fact, SEA is based on a set of possible solutions called population
whose members are in mutual interactions. To know more about evolutions, it is
recommended to read [18]. In this book, you can ﬁnd an overview of evolutionary
algorithms, but also their relations with deterministic chaos.
The main idea of our research is to show in this book that the dynamics of evo-
lutionary algorithms, in general, show properties of (complex) networks and evo-
lutionary dynamics can be analyzed and visualized like networks. The reason for
this is that various techniques for analysis and control of complex networks exist
nowadays and if complex network structure would be hidden behind EA dynamics,
then we believe that for example above mentioned control techniques could be used
to improve dynamics of EAs.
This chapter is focused on observation and description of networks phenomenon
in evolutionary dynamics and their possible control via CML system and feedback
loop principles. Possibilities of its use are discussed at the end. Ideas and results
presented in this chapter are in full detail available in [19] in [20] and the ﬁrst
paper on this topic in [21]. It is recommended to read those references for more
detailed information about experiments. Another paper using this idea that is suitable
for further reading are [21–54]. Related works on this topic are also discussed in
[55–59].
1.1.1
Selected Test Functions, Algorithms and Its Settings
To conﬁrm proposed ideas, it is necessary to do some experiments with selected
SEA on well-known test functions. For the experiments in [19, 21], various SEA,
such as differential evolution (DE) [60] and Self-Organizing Migrating Algorithm
(SOMA) [61, 62], can be used. Application of alternative algorithms like Artiﬁcial
bee colony and Simulated Annealing (SA), PSO and swarm algorithms are reported
in another chapter. To record SEA dynamics long enough, it is recommended to
use test functions in higher dimensions. The search of global extreme then takes

1
Swarm and Evolutionary Dynamics as a Network
7
5
0
5
5
0
5
0
20
40
Fig. 1.3 Selected test functions: 1st DeJong (a) and …
longer time, the population does not converge so quickly, and interactions between
individuals can be recorded for a longer time.
The test functions applied in experimentation [19] as well as in the following
chapters were selected from the test bed of 17 test functions. In total 16 test func-
tion were chosen as a representative subset of functions which shows geometrical
simplicity and low complexity as well as functions from the opposite side of spec-
tra. Selected functions (see Figs.1.3, 1.4, 1.5 and 1.6) were: 1st DeJong, Schwefels
function, Rastrigins function, Ackleys function amongst the others (see [19]). Each
of them has been used for identiﬁcation of complex networks dynamics and structure
in 50 dimensions (individual length was 50). Functions have been selected due to
their various complexity and mainly for the fact that these functions are widely used
by researchers working with SEA. Another reason was that the speed of convergence
and thus evolutionary dynamics itself is different and quickly converging, for simple
functions.
1.1.1.1
Recorded Behavior and Its Network Visualization
The most critical point of this research and related simulations was which data
and relations should be selected and consequently visualized. Based on investigated
algorithms, we believe that there is no universal approach, but rather a personal one,
based on the knowledge of algorithm principle. Of course, some conclusions (see
section Conclusion and [19]) can be generalized for a class or family of algorithms.

8
I. Zelinka
Fig. 1.4 …Schwefels function (b)
Fig. 1.5 Selected test functions: Rastrigins function (c) and …

1
Swarm and Evolutionary Dynamics as a Network
9
Fig. 1.6 …Ackleys function (d)
As mentioned in the previous sections, algorithms like DE and SOMA were used.
Each class of algorithm is based on a different principle. The main idea was that
each individual is represented by vertex, and edges between vertices should reﬂect
dynamics in population, i.e. interactions between individuals (which individual has
been used for offspring creation,). The SOMA algorithm, as described in [61, 62],
consists of a Leader attracting the entire population in each migration loop (the
equivalent of generation). In that class of swarm like algorithm, it is clear that the
position in a population of activated Leaders shall be recorded like vertex (getting
new inputs from remaining vertices - individuals) and used (with remaining part of
the population) for visualization and statistical data processing. The other case is
DE, e.g. DER and1Bin in which each individual is selected in each generation to be
a parent. Thus in DE, we have recorded only those individuals-parents, which have
been replaced by better offspring (like vertex with added connections). In the DE
class of algorithms, we have omitted the philosophy that a bad parent is replaced by
a better offspring, but we accepted the philosophical interpretation that an individual
(worse parent) is moving to the better position (better offspring). Thus no vertex
(individual) has to be either destroyed or replaced in the philosophical point of

10
I. Zelinka
view. If for example, DER and1Bin has a parent replaced by offspring, then it was
considered as an activation (new additional links, edges) of a vertex-worse parent
from three another vertices (randomly selected individuals, see [60]).
1.1.1.2
Visualization
Experimental data can be visualized in few different ways as explained in [19]. As
mentioned in the previous section, vertices in the complex network are individuals
that are activated by the other individuals, incrementally from generation to genera-
tion. It is shown in Figs.1.7 and 1.8 which show, that interactions between individuals
create (at ﬁrst glance) structures, which look like complex networks. The meaning
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Fig. 1.7 Network (oriented graph, arrowheads are omitted for better visibility) example of SOMA
dynamics in a natural format. Vertex (individual) 10 is the most proﬁtable vertex. This individual
is the best from the population and has been improved many times. Visualization of the multiple
edges is disabled on all pictures in this chapter for better visualization

1
Swarm and Evolutionary Dynamics as a Network
11
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
Fig. 1.8 Complex network (oriented graph, arrowheads are omitted for better visibility) of the
DELocalToBest with two of the most intensively connected vertices (individuals). The yellow is
the best one, the green ones are individuals with more incoming than outcoming connections, white
are balanced and pink are the least successful individuals from ﬁtness improvement point of view
[19]
of vertices in the ﬁgures mentioned above is given by the ratio of incoming and out-
going edges and implies that some individuals/vertices have more incoming edges
(their ﬁtness was more times successfully improved, green; yellow is the best) than
individuals with more outgoing edges (pink). In EA jargon, green/yellow vertex is
an individual, which has been successfully more times improved by offspring cre-
ation rather than less successful individuals (vertices) pink/white that reﬂects the
opposite. To ensure that an algorithm and its dynamics investigated for complex net-
work phenomenon can be understood and modeled like a complex network, typical
characteristics can be calculated.

12
I. Zelinka
1.1.2
Results
As reported in [19], algorithms in 10 versions have been tested on various test
functions (to reveal their complex networks dynamics) with a constant level of test
function dimensionality (i.e. individual length) and different number of generations
(migrations) in all used algorithms. All data has been processed graphically [19,
21] alongside calculations of basic statistical properties. The emergence of complex
network structure behind evolutionary dynamics depends on many factors. However,
some special versions of used algorithms did not show complex network structure
despite the fact that the number of generations was quite large. Nevertheless, net-
works are still formed by SEA dynamics, and their attributes can be successfully
used in feedback to SEA to improve its performance, as demonstrated in following
chapters and papers [23–52] and Chaps.2–9. An example of networks formed by
other algorithms in different experiments is visible in Figs.1.9, 1.10, 1.11, 1.12, 1.13
and 1.14.
Fig. 1.9 Network formed by ant colony optimization, see Chap.2

1
Swarm and Evolutionary Dynamics as a Network
13
Fig. 1.10 Network formed by artiﬁcial bee colony, see Chap.6
1.1.3
Complex Networks and CML Systems
In the previous section, we have shown that dynamics of evolutionary algorithms
can be under certain conditions visualized like a complex network. Following two
sections will demonstrate, how a complex the network can be converted to the CML
systems (Coupled Map Lattices, see [63]), for control and analysis (deterministic,
chaotic behavior,…) of network (i.e. evolutionary algorithm) dynamics.
CML belongs to the class of strongly nonlinear systems, which can, in general,
generate a very wide spectrum of behavior. All kinds of such behavior can be seen
in daily engineering activities and can have a negative impact on various devices
and everyday life. The term chaos covers a rather broad class of phenomena whose
behavior may seem erratic and unpredictable at ﬁrst glance. Often, this term is used
to denote phenomena, which are of a purely stochastic nature, such as the motion
of molecules in a vessel with gas, etc. This publication focuses on the determinis-

14
I. Zelinka
Fig. 1.11 Network formed by swarm virus based on ant colony optimization, see Chap.11
tic chaos, a phenomenon that - as its name suggests - is not based on the presence
of a random, stochastic effects. On the contrary, it is based on the absence of such
effects which may seem surprising at ﬁrst glance. Broadly used, the term chaos
can denote anything that cannot be predicted deterministically (e.g. motion of an
individual molecule, numbers in a lottery, …). If, however, the word chaotic is com-
bined with an attribute such as stochastic or deterministic, then a speciﬁc type of
chaotic phenomena is involved, having their speciﬁc laws, mathematical apparatus
and a physical origin. Stochastic system (not stochastic chaos) is the appropriate
term for a system such as plasma, gas, liquid, which should be studied by using a
suitable apparatus of plasma physics, statistical mechanics or hydrodynamics. On
the contrary, if a double pendulum, billiard or the similar objects are the subjects
of examination; a mathematical apparatus, which is based on classical mathematics
and does not exhibit stigmata of statistics, is employed. The mathematical apparatus

1
Swarm and Evolutionary Dynamics as a Network
15
Fig. 1.12 Network formed by DE, see Chap.9
for the description and study of the systems was not chosen at random; in fact, it
is related to the physical nature of the system being studied. Considering the class
of systems of deterministic chaos as mentioned above, signs of chaotic behavior
are usually conditional on the presence of nonlinearities, either in the system itself
(i.e. the system is a nonlinear system) or in links between linear systems [64]. Usu-
ally, such nonlinearities are only visible after creating a mathematical model of the
system or after analysis of observed data. Simple systems exhibiting deterministic
chaos include for instance double pendulum, magnetic pendulum, electronic circuit
or so called billiard problem through which balls are poured from the same starting
position.
Deterministic chaos, discovered by Lorenz [65] is a fairly active area of research in
the last few decades. The Lorenz system produces one of the well-known canonical
chaotic attractors in a simple three-dimensional autonomous system of ordinary
differential equations [65, 66]. For discrete chaos, there is another famous chaotic
system, called logistic equation [67]. Logistic equation is based on a predator-prey
model showing chaotic behavior. This simple model is widely used in the study of
chaos, where other similar models exist (canonical logistic equation [68] and 1D
or 2D coupled map lattices [63]). Since then, a large set of nonlinear systems that

16
I. Zelinka
Fig. 1.13 Network formed by SOMA, see Chap.3
Fig. 1.14 Network formed by PSO, see Chap.6

1
Swarm and Evolutionary Dynamics as a Network
17
can produce chaotic behavior has been observed and analyzed. Chaotic systems thus
have become a vitally important part of science and engineering in theoretical as
well as in practical levels of research. The most interesting and applicable notions
are, for example, that chaos control and chaos synchronization are related to secure
communication, amongst others. Recently, the study of chaos is focused not only on
the traditional trends but also on understanding and analyzing principles, with the
new intention of controlling and utilizing chaos as demonstrated in [69, 70]. The term
chaos control was ﬁrst coined by Ott, Grebogi, and Yorke in 1990. It represents a
process in which a control law is derived and used so that the original chaotic behavior
can be stabilized on a constant level of output value or a n-periodic cycle. Since the
ﬁrst experiment of chaos control, many control methods have been developed, and
some are based on the ﬁrst approach [71], including pole placement [72, 73] and delay
feedback [74, 75]. Another research has been done on CML control by [76], special
feedback methods for controlling spatiotemporal on-off intermittency have been used
there and [76]. This paper introduces a controller (based on discrete-time sliding
mode and Lyapunov function) for controlling of spatiotemporal chaos system. Many
methods were adapted for the so-called spatiotemporal chaos represented by coupled
map lattices (CML). Control laws derived for CML are usually based on existing
system structures [77], or by using an external observer [78]. Evolutionary approach
for control was also successfully developed, for example in, [79–81]. Many published
methods of deterministic chaos control (DCC) were (originally developed for classic
DCC) adapted for so-called spatiotemporal chaos represented by CML, given by
Eq.1.1.Modelsofthiskindarebasedonasetofspatiotemporal(for1D,Fig.1.15,axis
x is time). Typical example is CML based on so-called logistic equation, [67], [78,
82] which is used to simulate behavior of system which consists of n mutually joined
cells (logistic equations) via nonlinear coupling, usually noted like ε. Nonlinear
coupling is done exclusively between nearest cells. Cells that are not direct neighbor
of a cell X are not directly inﬂuenced by this cell. Mathematical description of CML
system is given by Eq.1.1, [82]. The function, which is represented by f (xn(i)) is an
arbitrary discrete system - in this case study logistic equations have been selected to
substitute f (xn(i)), variable is usually set to value that represent nonlinear coupling
between systems f (xn(i)). CML description based on (1.1) in Mathematica software
is given in Fig.1.15.
xn+1(i) = (1 −ε) f (xn(i)) + ε
2( f (xn(i −1)) + f (xn(i + 1)))
(1.1)
The most important, for our purposes and this participation, is Fig.1.15. This
ﬁgure depicts spatiotemporal chaos of CML systems. Note that in CML there are
observable deterministic - periodical windows. On the x-axis, there are iterations of
CML, while on y-axis there are sites, mutually joined, see Eq.1.1. Chaos is visible
here like grainy part while deterministic behavior like periodic parts. Ideas of CML
is in this participation used to show, that complex networks behavior can also be
visualized, analyzed and controlled in this way. The possibility to handle with a
complex network like with CML then allows using a wide class of CML control
methods to control complex networks.

18
I. Zelinka
Fig. 1.15 Typical CML behavior with chaotic and deterministic windows
1.1.4
Complex Networks as CML
Structure and dynamics of complex networks are usually visualized in a classical
way that is depicted on Figs.1.1 and 1.2. A complex network is depicted as a set
of vertices, mutually joined by single and multiple edges. Each edge can be added
or canceled during the evolution of the network, or importance of an edge can be
modiﬁed by weights associated with each edge. Adding or canceling the vertices and
modiﬁcation of the edge weights represents, in fact, dynamics of the network. The
network then changes its shape, structure, and size and as a consequence isolated
sub-networks (or their fractions) can be observed. In [83] there are reported various
techniques how to control and analyze such networks. Our approach is based on
well-known CML systems and their analysis and control using traditional as well as
heuristic methods. The proposed method of our visualization is based on the fact that
simplest version of CML (i.e. 1D version as used in many books, e.g. [32]) is usually
depicted in a row of mutually joined sites, where each site is nonlinearly joined with
its nearest sites. A row of pendulums, joined mutually with the nearest one, for better
imagination is used here, see Fig.1.16.
Our idea of equivalence between CML and complex network is quite simple. Each
vertex is equivalent to the site (row) in the CML. Comparing to the standard CML,
sites in complex network CML (CNCML) are not joined to the nearest site, but to
the sites equal to the complex network vertices. Thus sites in CNCML are not joined
symmetrically (i.e. from site x1 to x2 and vice versa) and between different sites,
there is a random pattern of connections, which can change at the time, see Fig.1.17.
Experiments of CNCML visualization were based on the above-described idea.
In all cases, CNCML has been calculated and visualized in such a way. Different
levels of vertices (sites) excitation are depicted by different colors, see Fig.1.18.
Colors represent different values of different CN attributes here. It can be page rank,
the degree of the vertex (an importance of the individual), etc. When compared with
our previous results, [21, 54] it is visible, that our proposed kind of visualization is
usable. It is observable that CNCML visualization shows the complex and obviously
nonlinear behavior of tested CNs. Some preliminary results, see Figs.1.19 and 1.20,
on its analysis and control are mentioned in Chap.4.

1
Swarm and Evolutionary Dynamics as a Network
19
0
10
20
30
40
50
0
10
20
30
40
50
1
2
3
4
5
6
Standard CML can be understand 
like row of pendulums with 
Fig. 1.16 Typical CML and its mechanical (pendulum-based) interpretation. Pendulums (e.g. sites)
are mutually inﬂuenced via (via ε) strength
1
2
3
4
5
0
10
20
30
40
50
0
10
20
30
40
50
5
6
7
1
2
3
4
5
6
1
2
3
4
5
6
Then complex network like 
CML is more complicated 
connections.
Fig. 1.17 Complex network like CML, vertices (pining sites in CML) are not connected equilateral
(via ε) but according to complex network topology

20
I. Zelinka
Fig. 1.18 Zoom of the network with 20 vertices in 500 iterations
Fig. 1.19 CML based on complex network from SEA, see Chap.4

1
Swarm and Evolutionary Dynamics as a Network
21
Fig. 1.20 CML based on complex network from SEA, see Chap.4
1.2
Swarm and Evolutionary Dynamics as a Feedback
Loop Control
There are very tight similarities between SEA dynamics and feedback loop that
allow us to think about evolutionary algorithm dynamics as if that would be complex
feedback loop system. The complexity here is present in evolutionary dynamics in
which individuals interact amongst themselves. If SEA is considered like a dynamical
MIMO system (multiple input - multiple outputs), then interaction amongst inputs
(parents) is driven by pseudo-random number generators and output (offsprings) are
then result of this interaction. Cost function itself can be very often complex (even
without noise).
In classical control theory, there is one of the ways how to control dynamical
system represented by a so-called feedback loop, which is depicted in Fig.1.21,
where w is so called desired value (the aim toward to which we would like to control
system), y is an output value of the controlled system, that is further taken back in a
feedback loop, subtracted from w and difference e goes to the controller. In controller
e is used to calculate the most suitable controller output u so that y will be more
close to the expected aim of control and future e = w −y will be minimized as much
as possible. Whole control process can be inﬂuenced by noise v, whose existence is
not, in control theory, welcome and each control technique tries to avoid or eliminate
it (paradoxically in SEA uses randomness as a “vital” force that is nothing more
than simulation of the “white noise”; as demonstrated in [84] SEA can work without

22
I. Zelinka
Controller
-
+
w
y
y
e
u
Controlled system
v
Fig. 1.21 Classical feedback loop control
randomness quite well, [27, 84, 85]). If this is taken into consideration, then it is clear
that evolutionary algorithms are nothing more than the discrete dynamical system,
that shall be controllable by modern as well as classical methods, too.
This control theory interpretation of SEA dynamics shows that randomness is
not vital for SEA dynamics and is usually disruptive with a negative impact on
controlling process, which is in full coincidence with our previous experimental
observations on evolution without PRNGs, [27, 84, 85].
As an alternative way of SEA dynamics control, reported in [53] is depicted in
Fig.1.22. Some methods on CML (coupled map lattices) systems control, especially
using evolutionary algorithms exist today. The spirit of this idea is to create a closed
loop following this scheme: evolutionary dynamics complex network CML system
control CML control evolutionary dynamics (and control of CN). The reason for
this is that proposed techniques can be used for analysis and control of complex
networks and if complex network structure is hidden behind EA dynamics, then it
is almost sure, that for example above mentioned control techniques could be used
to improve dynamics of EAs. A complex network is depicted as a set of vertices,
mutually joined by single and multiple edges. Each edge can be added or canceled
during the evolution of the network, or importance of an edge can be modiﬁed by
weights associated with each edge. Adding or canceling the edges (or their weights)
represents, in fact, dynamics of the algorithm, i.e. network.
Lets take a closer and more detailed look at Fig.1.22. In this ﬁgure the whole idea
is depicted in few steps as follows:
1. Evolutionary dynamics is observable-recordable via population behavior.
2. Interactions between individuals are recorded as a change of edge weights of the
complex network in which vertices are individuals (particles) of the swarm (pop-
ulation), and edges are interactions amongst them. Edges between vertices (and
their strength) then reﬂect dynamics of the evolutionary process. When another
one xm improves an individual xn, then oriented edge xn →xm is established
or/and increased by some weight increment. If no improvement is observed,
then, in the same way, the strength of the edge can be decremented. Thus we get
network that behaves in a similar way such as the well known complex networks
like social networks, citation networks, etc.

1
Swarm and Evolutionary Dynamics as a Network
23
Fig. 1.22 The schematic principle of proposed feedback control EAs and CNS: evolutionary
dynamics →complex network →CML system →control CML →control evolutionary (complex
network) dynamics
3. Complex network is then converted into a CML, where each row of CML is
understood as a time development of related vertex from the complex network.
The values (amplitudes, excitation,…) on that row are given by strengths and
number of incoming and outcoming edges - for example by In-degree and Out-
degree of given vertex.
4. CML can be then studied and analyzed for different kinds of behavior (determin-
istic and chaotic regimes, intermittence, …), [82].
5. Beside analysis, CML can also be controlled as very well described in [63]. The
control is in fact focused on a search of suitable control inputs and so-called
pinning values (i.e. controller output - u in the scheme) in CML system and is
based on mathematical analysis of CML if the structure is known. If not, then
SEA techniques can be used.
6. The most typical scheme of CML control is standard feedback control philosophy,
as depicted in Fig.1.22. The controller can be, in general, derived using classical
mathematics, based on a priori knowledge of CML system. However, this is more
complicated for CML with non-symmetrical structure (i.e. sites are not inﬂuenced
by nearest one but by a different one, and its change during the time). In such
a case it is better to use evolutionary control instead of classical one, as studied
and demonstrated in [14, 15, 18]. With such approach we can control an arbitrary
CML even without knowledge of its internal structure.
7. By controlling CML, that shall be understood as a reﬂection of algorithm dynam-
ics, we, in fact, control dynamics of complex network derived from SEA dynamics
(remember that this approach has side effect - if step 1 is omitted, then it can be
used to control complex networks.) and …
8. … also to control dynamics of SEA.

24
I. Zelinka
Steps 1–4 are reported in bigger details in [19, 21, 54], while (independently
on just described methodology) CML control by means of SEA in [14, 15, 18]. It
is clear from previous experiments and results, that proposed scheme of algorithm
dynamics conversion and its CML control is applicable and can be used to study and
visualize their control and performance. It is also possible to use it to make some
analysis using complex networks as well as CML systems tools.
1.3
Conclusion
The main motivation of this research is whether it is possible to visualize and simulate
underlying dynamics of an evolutionary process as a complex network and if it is
possible to control it, based on CML systems. Based on preliminary results [23–52]
it can be stated that:
1. No. of generations: occurrence of the complex network structure (CNS) sensi-
tively depends on the number of generations. If the number of generations is
small, then no CNS is established. This effect can easily understand so that a
low number of generations means that SEA has no sufﬁcient time to establish
CNS. This is quite a logical observation in complex network dynamic when CNS
is not observable at the beginning of linking process. During our experiments it
has been observed that the moment of CNS establishing depends on cost func-
tion dimension, population size, used algorithm and cost function. Very generally,
EAs searching for global extreme is in the beginning quite random-like, and when
domain of global extreme is discovered, then CNS is quite quickly established.
2. Dimensionality: the impact on CNS forming has been observed when the
dimension of the cost function was big and the number of generations was too
low. The selected EA was not able to ﬁnish successfully the extreme global search
not all connections had been properly established. Thus if high dimensional cost
functions are used, then the number of generations has to be selected so that at
least the domain of the global extreme is found. On the other side, if number of
generations (or Migrations in the case of the SOMA algorithm) is very big, then
it is possible to observe the effect that rich become richer, i.e. one vertex (individ-
ual) becomes winner repeatedly, see [19, 21]. This moment usually means that
global extreme has been found and further searching is not necessary. This the
conclusion is not generally true of course.
3. Test functions: dependence of CNS forming on the test function was not strictly
observed, the consensus is that for more complex test functions, like Schwefel,
etc., the algorithm needs more generations to establish CNS, i.e. more the complex
function requires more generations and bigger population size. In the case of
simpler functions like 1st DeJong moreover, low dimensions the global extreme
is quickly found moreover, the phase of CNS creation is very short and then active
the last phase rich becomes richer [19, 21] For more about test function impact
on CNS forming.

1
Swarm and Evolutionary Dynamics as a Network
25
4. Population size: CNS forming was usually observed from bigger population size
(depending on the algorithm) with dimensions >50. Again, it is a parameter which
does not inﬂuence CNS forming alone, but in combination with other parameters
as mentioned in the previous items.
5. Used algorithm: CNS forming has also been observed with algorithms that are
more or less based on swarm philosophy or partly associated with it. For example,
DER and1Bin did not show any CNS formatting in ﬁrst experiments (in principle
each individual is selected to be a parent), while in the case of the DELocalToBest
in which the best solution in the population plays an important role, CNS has
been observed, as well as in the SOMA strategies [19]. The conclusion is that
CNS formatting is more likely observable with swarm like algorithms rather than
randomly driven algorithms. We think that this is quite logical and close to the idea
of preferred linking in the complex networks modeling social behavior (citation
networks, etc).
Possible use and beneﬁt of this approach according to us are to evaluate and control
evolutionary dynamics. Based on numerically demonstrated fact (no mathematical
proof has been made) that EAs dynamics can be visualized like complex networks,
we believe that there is a new research area for the study of EAs dynamics and their
possible control via techniques of complex network and CML systems control [63,
65–81, 83].
Acknowledgements The following grants are acknowledged for the ﬁnancial support provided
to this research: Grant Agency of the Czech Republic - GACR P103/15/06700S, Grant of SGS
No. SGS 2017/134, VSB-Technical University of Ostrava. The Ministry of Education, Youth and
Sports from the National Programme of Sustainability (NPU II) project “IT4Innovations excellence
in science - LQ1602”.
References
1. Dorogovtsev, S.N., Mendes, J.F.F.: Evolution of networks. Adv. Phys. 51, 1079 (2002)
2. Boccaletti, S., et al.: Complex networks: structure and dynamics. Phys. Rep. 424, 175–308
(2006)
3. Turing, A.: Intelligent machinery, unpublished report for National Physical Laboratory. In:
Michie, D. (ed.) Machine Intelligence, vol. 7 (1969); Turing, A.M. (ed.): The Collected Works,
vol. 3, Ince D. North-Holland, Amsterdam (1992)
4. Holland, J.: Adaptation in Natural and Artiﬁcial Systems. University of Michigan Press, Ann
Arbor (1975)
5. Schwefel, H.: Numerische Optimierung von Computer-Modellen, Ph.D. thesis (1974);
Reprinted by Birkhauser (1977)
6. Rechenberg, I.: (1971) Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien
der biologischen Evolution (Ph.D. thesis), Printed in Fromman-Holzboog (1973)
7. Fogel, D.B.: Unearthinga Fossil from the history of evolutionary computation. Fundam. Inform.
35(1–4), 116 (1998)
8. Richter, H., Reinschke, K.J.: Optimization of local control of chaos by an evolutionary algo-
rithm. Phys. D 144, 309–334 (2000)

26
I. Zelinka
9. Richter, H.: An evolutionary algorithm for controlling chaos: the use of multi-objective ﬁtness
functions. In: Guervos, M., Panagiotis, J.J., Beyer, A., Villacanas, F.H.G., Schwefel, H.P. (eds.)
Parallel Problem Solving from Nature-PPSN VII. Lecture Notes in Computer Science, pp. 308–
317. Springer, Berlin (2002)
10. Richter, H.: Evolutionary Optimization in Spatio- temporal Fitness Landscapes. Lecture Notes
In Computer Science, vol. 4193, pp. 1–10. Springer, Berlin (2006). ISSN 0302-9743
11. Richter, H.: A study of dynamic severity in chaotic ﬁtness landscapes. In: Evolutionary Com-
putation, 2005. The IEEE Congress, vol. 3, Issue 2–5 Sept. 2005, pp. 2824–2831 (2005)
12. Zelinka, I., Chen, G., Celikovsky, S.: Chaos synthesis by means of evolutionary algorithms.
Int. J. Bifurc. Chaos Univ. California, Berkeley USA 18(4), 911–942 (2008)
13. Zelinka, I.: Real-time deterministic chaos control by means of selected evolutionary algorithms.
Eng. Appl. Artif. Intell. (2008). https://doi.org/10.1016/j.engappai.2008.07.008
14. Zelinka, I.: Investigation on realtime deterministic chaos control by means of evolutionary
algorithms. In: 1st IFAC Conference on Analysis and Control of Chaotic Systems, Reims,
France (2006)
15. Senkerik,R.,Zelinka,I.,Navratil,E.:Optimizationoffeedbackcontrolofchaosbyevolutionary
algorithms. In: 1st IFAC Conference on Analysis and Control of Chaotic Systems, Reims,
France (2006)
16. Dashora, Y., et al.: Improved and generalized learning strategies for dynamically fast and
statistically robust evolutionary algorithms. Eng. Appl. Artif. Intell. (2007). https://doi.org/10.
1016/j.engappai.2007.06.005
17. Li, L., Wenxin, L., David, A.C.: Particle swarm optimization-based parameter identiﬁcation
applied to permanent magnet synchronous motors. Eng. Appl. Artif. Intell. (2007). https://doi.
org/10.1016/j.engappai.2007.10.002
18. Zelinka, I., Chen, G., Celikovsky, S.: Evolutionary Algorithms and Chaotic Systems. Springer,
Germany (2010)
19. Ivan, Z., Davendra, D.D., Chadli, M., Senkerik, R., Dao, T.T., Skanderov, L.: Evolutionary
dynamics as the structure of complex networks. In: Handbook of Optimization, pp. 215–243.
Springer, Berlin (2013)
20. Ivan, Z., Snasel, V., Abraham, A. (eds.): Handbook of optimization: from classical to modern
approach, vol. 38. Springer Science and Business Media, Berlin (2012)
21. Ivan, Z., Davendra, D., Snel, V., Jaek, R., Enkek, R., Oplatkov, Z.: Preliminary investigation on
relations between complex networks and evolutionary algorithms dynamics. In: 2010 Interna-
tional Conference on Computer Information Systems and Industrial Management Applications
(CISIM), pp. 148–153. IEEE (2010)
22. Sheng, L., Guang, X., Chen, F., Wang, H., Gao, K.: A review on complex network dynamics
in evolutionary algorithm. In: Trustcom/BigDataSE/I SPA, 2016 IEEE, pp. 2221–2226. IEEE,
New York (2016)
23. Zelinka, I.: A survey on evolutionary algorithms dynamics and its complexity Mutual relations,
past, present and future. Swarm Evolutionary Comput. 25, 2–14 (2015)
24. Davendra, D., Zelinka, I., Metlicka, M., Senkerik, R., Pluhacek, M.: Complex network analy-
sis of differential evolution algorithm applied to ﬂowshop with no-wait problem. In: IEEE
Symposium on Differential Evolution, Orlando, FL, USA, 9–12 December, 65–72 (2014)
25. Davendra D., Metlicka M.: Ensemble centralities based adaptive artiﬁcial bee algorithm. In:
IEEE Congress on Evolutionary Computation (2015)
26. Zelinka I.: Evolutionary Algorithms as a Complex Dynamical Systems, tutorial at IEEE
Congress on Evolutionary Computation 2015, Sendai (2015)
27. Zelinka, I., Senkerik, R.: Does Evolutionary Dynamics Need Randomness, Complexity or
Determinism? ISCS 2014: Interdisciplinary Symposium on Complex Systems Emergence,
Complexity and Computation 14, 195–203 (2015)
28. Tan, S., Lu, J., Chen, G., Hill, D.: When structure meets function in evolutionary dynamics on
complex networks. IEEE Circ. Syst. Mag. 14, 3650 (2014)
29. Michal, P., Jakub, J., Roman, S., Ivan, Z., Donald, D.: PSO as complex networkcapturing
the inner dynamicsinitial study. In: Proceedings of the Second International Afro-European

1
Swarm and Evolutionary Dynamics as a Network
27
Conference for Industrial Advancement AECIA 2015, pp. 551–559. Springer International
Publishing (2016)
30. Michal, P., Roman, S., Jakub, J., Adam, V., Ivan, Z.: Study on swarm dynamics converted
into complex network. In: Proceedings of the 30th European Conference on Modelling and
Simulation, ECMS 2016, European Council for Modelling and Simulation (ECMS) (2016)
31. Michal, P., Roman, S., Adam, V., Jakub, J., Donald, D.: Complex network analysis in PSO as
an ﬁtness landscape classiﬁer. In: 2016 IEEE Congress on Evolutionary Computation (CEC),
pp. 3332–3337. IEEE (2016)
32. Michal, P., Roman, S., Adam, V., Ivan, Z.: Creating complex networks using Multi-swarm
PSO. In: 2016 International Conference on Intelligent Networking and Collaborative Systems
(INCoS), pp. 180–185. IEEE (2016)
33. Lenka, S., Tomas, F.: Differential evolution dynamics analysis by complex networks. In: Soft
Computing, 2015, pp. 1–15. Springer (2015)
34. Lenka, S., Tomas, F., Ivan, Z.: Differential evolution enhanced by the closeness centrality:
initial study. In: 2015 International Conference on Intelligent Networking and Collaborative
Systems (INCOS), 2015, pp. 346–353. IEEE (2015)
35. Lenka, S., Ivan, Z., Theodore, S., Charalambos, T.: Differential evolution based on the node
degree of its complex network: initial study. In: AIP Conference Proceedings, 2016, pp. 1–4.
AIP Publishing (2016)
36. Lenka, S., Tomas, F., Ivan, Z.: Small-world hidden in differential evolution. In: 2016 IEEE
Congress on Evolutionary Computation (CEC), 2016, pp. 3354–3361. IEEE (2016)
37. Lenka, S., Tomas, F., Ivan, Z.: Differential evolution dynamics modeled by longitudinal social
network. J. Intell. Syst. (2017). https://doi.org/10.1515/jisys-2015-0140
38. Lenka, S., Ivan, Z.: Differential evolution dynamic analysis in the form of complex networks.
In: 2016 IGI Global Advanced Methods for Complex Network Analysis, pp. 285–315 (2016)
39. Janostik, J., Pluhacek, M., Senkerik, R., Zelinka, I.: Particle swarm optimizer with diversity
measure based on swarm representation in complex network. In: Nostradamus 2015: AISC,
pp. 561–569. Springer, Berlin (2016)
40. Janostik, J., Pluhacek, M., Senkerik, R., Zelinka, I.: Capturing inner dynamics of ﬁreﬂy algo-
rithm in complex network initial study. In: Nostradamus 2015: AISC, pp. 571–579. Springer,
Berlin (2016)
41. Viktorin, A., Pluhacek, M., Senkerik, R.: Network based linear population size reduction in
SHADE. In: 2016 International Conference on Intelligent Networking and Collaborative Sys-
tems (INCoS), pp. 86–93. IEEE (2016). ISBN 978-1-5090-4124-4
42. Senkerik, R., Viktorin, A., Pluhacek, M., Janostik, J., Davendra, D.: On the inﬂuence of different
randomizationandcomplexnetworkanalysisfordifferentialevolution.In:2016IEEECongress
on Evolutionary Computation (CEC), pp. 3346–3353. IEEE (2016). ISBN 978-1-5090-0622-9
43. Senkerik, R., Pluhacek, M., Viktorin, A., Janostik, J.: On the application of complex net-
work analysis for metaheuristics. In: Bioinspired Optimization Methods and their Applications
(BIOMA), pp. 201–214 (2016)
44. Senkerik, R., Viktorin, A., Pluhacek, M., Janostik, J., Oplatkova, Z.K.: Study on the time
development of complex network for metaheuristic. In: Artiﬁcial Intelligence Perspectives in
Intelligent Systems, pp. 525–533. Springer International Publishing (2016). ISBN 978-3-319-
33625-1
45. Senkerik, R., Viktorin, A., Pluhacek, M.: On the transforming of the indices selection mecha-
nism inside differential evolution into complex network. Int. Conf. Intell. Netw. Collab. Syst.
(INCoS) 2016, 186–192 (2016)
46. Zelinka, I., Tomaszek, L., Kojecky, L.: On evolutionary dynamics modeled by ant algorithm. In:
2016 International Conference on Intelligent Networking and Collaborative Systems (INCoS),
Ostrava, pp. 193–198 (2016)
47. Tomaszek, L., Zelinka, I.: On performance improvement of the SOMA swarm based algorithm
and its complex network duality. In: 2016 IEEE Congress on Evolutionary Computation (CEC),
Vancouver, BC, pp. 4494–4500 (2016)

28
I. Zelinka
48. Zelinka, I., Tomaszek, L.: Competition on learning-based real-parameter single objective opti-
mization by SOMA swarm based algorithm with SOMA remove strategy. In: 2016 IEEE
Congress on Evolutionary Computation (CEC), Vancouver, BC, pp. 4981–4987 (2016)
49. Davendra, D., Zelinka, I., Metlicka, M., Senkerik, R., Pluhacek, M.: Complex network analysis
of differential evolution algorithm applied to ﬂowshop with no-wait problem. In: Proceedings
of the 2014 IEEE Symposium Series on Computational Intelligence (SSCI), Orlando, Florida,
USA, pp. 65–72, 9–12 December 2014
50. Davendra, D., Zelinka, I., Senkerik, R., Pluhacek, M.: Complex network analysis of discrete
self-organising migrating algorithm. In: Zelinka, I., Suganthan, P., Chen, G., Snasel, V., Abra-
ham, A., Rossler, O. (eds.) Nostradamus 2014: Prediction, Modeling and Analysis of Complex
Systems.AdvancesinIntelligentSystemsandComputing,pp.161–174.Springer,Berlin(2014)
51. Davendra, D., Zelinka, I., Senkerik, R., Pluhacek, M.: Complex network analysis of evolu-
tionary algorithms applied to combinatorial optimisation problem. In: Komer, P., Abraham,
A., Snasel, V. (eds.) Proceedings of the Fifth International Conference on Innovations in Bio-
Inspired Computing and Applications IBICA 2014, Advances in Intelligent Systems and Com-
puting, pp. 141–150. Springer, Berlin (2014)
52. Magdalena, M., Davendra, D.: Ensemble centralities based adaptive artiﬁcial bee algorithm.
In: 2015 IEEE Congress on Evolutionary Computation (CEC), pp. 3370–3376. IEEE (2015)
53. Zelinka, I., Saloun, P., Senkerik, R., Pavlech, M.: Controlling complexity. In: Zelinka I.,
Sanayei, A., Zenil, H., Rossler, O.E. (eds.) How Nature Works. Springer, Berlin (2014)
54. Zelinka I., Davendra D., enkek R., Jaek R., Do evolutionary algorithm dynamics create complex
network structures? Complex Syst. 2, 0891–2513, 20, 127–140
55. Lieberman, E., Hauert, C., Nowak, M.A.: Evolutionary dynamics on graphs. Nature 433,
312316 (2005)
56. Olfati-Saber, R.: Evolutionary dynamics of behavior in social networks. In: Proceedings of the
46th IEEE Conference on Decision and Control, New Orleans, LA, p. 61456150 (2007)
57. Olfati-Saber, R., Fax, J.A., Murray, R.M.: Consensus and cooperation in networked multi-agent
systems. Proc. IEEE 95, 215233 (2007)
58. Szabo, G., Fath, G.: Evolutionary games on graphs. Phys. Rep. 446, 97216 (2007)
59. Lu, J., Chen, G.: A time-varying complex dynamical network model and its controlled syn-
chronization criteria. IEEE Trans. Autom. Contr. 50, 841846 (2005)
60. Price, K.: An Introduction to Differential Evolution, New Ideas in Optimization, Corne, D.,
Dorigo, M., Glover, F. (eds.), p. 79108. McGraw-Hill, London, (1999)
61. Zelinka I.: SOMA self organizing migrating algorithm, Chap. 7, p. 33. In: Babu, B.V.,
Onwubolu, G. (eds), New Optimization Techniques in Engineering. Springer, Berlin (2004).
ISBN 3-540-20167X
62. Donald, D., Zelinka, I.: Self-Organizing Migrating Algorithm. New Optimization Techniques
in Engineering (2016)
63. Schuster, H.: Handbook of Chaos Control. Wiley, New York (1999). Wiley-Interscience, New
York (2002)
64. He, Q., Wang, L.: An effective co-evolutionary particle swarm optimization for constrained
engineering design problems. Eng. Appl. Artif. Intell. 20(1), 8999 (2007)
65. Lorenz, E.: Deterministic nonperiodic ﬂow. J. Atmos. Sci. 20(2), 130141 (1963)
66. Stewart, I.: The Lorenz attractor exists. Nature 406, 948949 (2000)
67. May, R.: Simple mathematical model with very complicated dynamics. Nature 261, 4567
(1976)
68. Gilmore, R., Lefranc, M.: The Topology of Chaos: Alice in Stretch and Squeezeland
69. Chen, G., Dong, X.: From Chaos to Order: Methodologies, Perspectives and Applications.
World Scientiﬁc, Singapore (1998)
70. Wang, X., Chen, G.: Chaotiﬁcation via arbitrarily small feedback controls: theory, method, and
applications. Int. J. of Bifur. Chaos 10, 549570 (2000)
71. Ott, E., Grebogi, C., Yorke, J.: Controlling chaos. Phys. Rev. Lett. 64, 11961199 (1990)
72. Grebogi, C., Lai, Y.C.: Controlling chaos. In: Schuster, H. (ed.) Handbook of Chaos Control.
Wiley-VCH, New York (1999)

1
Swarm and Evolutionary Dynamics as a Network
29
73. Zou, Y., Luo, X., Chen, G.: Pole placement method of controlling chaos in DC-DC buck
converters. Chin. Phys. 15, 17191724 (2006)
74. Just, W.: Principles of time delayed feedback control. In: Schuster, H. (ed.) Handbook of Chaos
Control.Wiley-VCH,NewYork(1999)19.JustW.:Principlesoftimedelayedfeedbackcontrol.
In: Schuster, H. (ed.) Handbook of Chaos Control. Wiley-VCH, New York (1999)
75. Just, W., Benner, H., Reibold, E.: Theoretical and experimental aspects of chaos control by
time-delayed feedback. Chaos 13, 259266 (2003)
76. Deilami, M., Rahmani, C., Motlagh, M.: Control of spatio-temporal on-off intermittency in
random driving diffusively coupled map lattices, Chaos, Solitons and Fractals, 21 December
2007
77. Schuster, H.: Handbook of Chaos Control. Wiley-VCH, New York (1999)
78. Chen, G.: Controlling Chaos and Bifurcations in Engineering Systems. CRC Press, Boca Raton
(2000)
79. Richter, H., Reinschke, K.: Optimization of local control of chaos by an evolutionary algorithm.
Phys. D 144, 309334 (2000)
80. Richter, H.: An evolutionary algorithm for controlling chaos: the use of multi-objective ﬁt-
ness functions. In: Guervos, J.J.M., Adamidis, P.A., Beyer, H.G., Fernandez-Villacanas, J.-L.,
Schwefel, H.P. (eds.) PPSN 2002. LNCS, vol. 2439, pp. 308–317. Springer, Heidelberg (2002)
81. Zelinka, I.: Investigation on real-time deterministic chaos control by means of evolutionary
algorithms. In: Proceedings of the First IFAC Conference on Analysis and Control of Chaotic
Systems, Reims, France, pp. 211–217 (2006)
82. Hilborn, R.: Chaos and Nonlinear Dynamics. Oxford University Press, Oxford (1994)
83. Meyn, S.: Control Techniques for Complex Networks. Cambridge University Press, Cambridge
(2007)
84. Ivan, Z., Lampinen J., Senkerik, R., Pluhacek, M.: Evolutionary algorithms powered by non-
random processes, Soft Computing. https://doi.org/10.1007/s00500-015-1689-2
85. Ivan, Z., Chadli, M., Davendra, D., Senkerik, R., Pluhacek, M., Lampinen, J.: Do evolutionary
algorithmsindeedrequirerandomnumbers?Extendedstudy.In:Nostradamus2013:Prediction,
Modeling and Analysis of Complex Systems, pp. 61–75. Springer International Publishing,
Berlin (2013)

Chapter 2
Evolutionary Dynamics and Its Network
Visualization - Selected Examples
Orkhan Yarakhmedov, Victor Polyakh, Ivan Chernogorov
and Ivan Zelinka
Abstract In this chapter is demonstrated, on selected algorithms, how can be con-
verted dynamics of the evolutionary process into a network. Selected algorithms are a
self-organizing migrating algorithm, differential evolution, particle swarm, artiﬁcial
bee colony and ant colony optimization. The main ideas and steps are discussed here,
for more detailed study and understanding references to original research papers are
throughout the text. The aim of this chapter is to show principles of conversion with
attention on the fact that there is no universal guide on how to do conversion - it is a
matter of creative approach and algorithm knowledge.
2.1
Introduction
In the basic visualization (see the previous chapter) is proposed that vertices of
the network be individuals and number of edges (or its strength) between them
only increase by an integer number. It is also possible to set decrement of edges
according to various criteria. For example when parents - individuals do not create
betteroffsprings,thenthenumberofedgesbetweenthemdecrease.Eachevolutionary
algorithm is running under different nature, so there is no universal guide how to
O. Yarakhmedov (B) · V. Polyakh · I. Chernogorov
Software of Computer Engineering and Automated Systems Department,
Information Technology and Computer Science Faculty,
Don State Technical University, Rostov, Russia
e-mail: orhashka@gmail.com
V. Polyakh
e-mail: silvervpolyah@gmail.com
I. Chernogorov
e-mail: hintaivr@gmail.com
I. Zelinka
Faculty of Electrical Engineering and Computer Science,
Department of Computer Science, VŠB – Technical University of Ostrava,
17. listopadu 15, 708 33 Ostrava-Poruba, Czech Republic
e-mail: ivan.zelinka@vsb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_2
31

32
O. Yarakhmedov et al.
convert dynamics of studied EA to complex network and has to be developed for each
speciﬁc algorithm. For example, SOMA, see [1]), is in each migration loop winner
only one individual, so-called Leader, and other individuals establish a connection
with this individual. On the other side, DE creates for selected parent individual, using
randomly selected another three individuals (DERand1Bin) new offspring which are
understood here as the movement of selected parent individual to the new position. If
ﬁtness is better, then this selected parent individual get new connections from those
randomly selected another three individuals. Decreasing of existing edges is done
in a similar inverse way. Complex networks, generated from EAs dynamics, can be
done, for example, in following scenarios:
• Scenario 1 (increasing mode): number of established edges increase only for
individuals whose ﬁtness was improved.
• Scenario 2 (real mode): number of edges between vertices is decreasing according
to various scenarios:
– Scenario 2a: if edge between individual A and B exist, then is decreased by 1,
if not exist, then decrease is not done, i.e. minimal value that can be reached is
0
– Scenario 2b: if edge between individual A and B exist, then is decreased by 1
even if not exist, i.e. minimal value that can be negative.
• Scenario 3: number of edges between vertices is increasing and decreasing accord-
ing to various scenarios that can involve ﬁtness and another attribute of EA dynam-
ics
For more details about results and visualizations, please see [2].
In this chapter are reported examples of the self-organizing migrating algorithm,
differential evolution, particle swarm, an artiﬁcial bee colony and ant colony opti-
mization and conversion of its dynamics into the network. Algorithms have been
tested on various test function (to reveal its complex networks dynamics) with a
constant level of test function dimensionality (i.e. individual length) and a differ-
ent number of generations (migrations) in all used algorithms. All data has been
processed graphically (see [2], etc.) alongside calculations of basic network prop-
erties. The emergence of network structure behind evolutionary dynamics depends
on many factors. However, some special versions of used algorithms did not show
complex network structure despite the fact that the number of generations was quite
large. Pictures in this chapter have been generated to visualize all important data
and relations, see also [1–21]. Another part of our experiments and results also show
the use of parallel evolutionary algorithms and its conversion and visualization as
complex networks.
Based on mentioned principles and algorithms, we believe that there is no uni-
versal approach, but rather a personal one, based on the knowledge of algorithm
principle. Lets take as an example DE, e.g. DERand1Bin in which each individual is
selected in each generation to be a parent. Thus in DE, we have recorded only those

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
33
individuals-parents, which have been replaced by better offspring (like vertex with
added connections). In the DE class of algorithms, we have omitted the philosophy
that a bad parent is replaced by a better offspring, but accepted philosophical inter-
pretation, which individual (worse parent) is moving to the better position (better
offspring in original DE philosophy). Thus no vertex (individual) has to be either
destroyedorreplacedinthephilosophicalpointofview.If,forexample,DERand1Bin
has a parent replaced by offspring, then it was considered as an activation (new addi-
tional links, edges) of vertex-worse parent from three another vertices (randomly
selected individuals, see [4, 15–17]). In fact, such general approach can also be used
in another algorithm. If interaction amongst N individuals leads to the improvement
of another arbitrary one, say Mth, then it is equivalent to the situation that N vertices
give incoming edges to the Mth vertex. Moreover, vice versa. Edges can be weighted
by integer numbers (+1 = successive support of the Mth vertex, −1 = nonsuccessive
support) or simply by differences in ﬁtness before interaction and after the interac-
tion. Again, this very general idea has to be adopted for each used algorithm. As
reported in [6–9], we have tried this conversion for SOMA, DE, PSO, ABC (Arti-
ﬁcial Bee Colony) and GA. Complex networks can be then visualized as in ﬁgures
below. From ﬁgures, it is visible that different algorithm dynamics produce different
complex networks structure. Another visualizations can be found in [6–9].
2.2
Interpretation
Visualized and analyzed networks have multiple edges that can be understood like
the weight of the single edge. Attributes of proposed analysis are represented by
subnetwork colors and vertices size in the network. Networks can be analyzed from
the different point of views. The most important is an interpretation of what network,
its structure, and dynamics represent. Our proposed interpretation, based on terms
and command from Wolfram Mathematica is following:
1. Adjacency graph, see Fig.2.1.
Meaning: Graph with vertices and oriented edges.
Interpretation: Visualization of evolutionary dynamics in the form of so called
graph. Each vertex represent one individual in the population and each edge (ori-
ented of course) represent successful offspring creation (i.e. ﬁtness improvement
of active parent in this philosophy) between parents connected by that edge.
2. Graph partition, see Fig.2.2.
Meaning: Graph partition ﬁnds a partition of vertices such that the number of
edges having endpoints in different parts is minimized. For a weighted graph,
graph partition ﬁnds a partition such that the sum of edge weights for edges hav-
ing endpoints in different parts is minimized.

34
O. Yarakhmedov et al.
Interpretation: Individuals in a population are separated into “groups” according
to their interactions with another individual, based on their success in active
individual ﬁtness improvements. “Endpoints” can be understood like successful
participation of selected individuals in active individual ﬁtness. On Fig.2.2 is
partition visualized by colors. This analysis gives a view of population structure
and shows the set of individuals that got or donate oriented edges (support from/to)
the same group of individuals. Based on some connections or weights of edge,
it can be analyzed what part of the population was the most important in the
evolutionary dynamics for given case.
3. Degree centrality, see Fig.2.3.
Meaning: Degree centrality of g gives a list of vertex degrees for the vertices
in the underlying simple graph of g. Degree centrality will give high centralities
to vertices that have high vertex degrees. The vertex degree for a vertex v is the
number of edges incident to v. For a directed graph, the in-degree is the number
of incoming edges, and the out-degree is the number of outgoing edges. For an
undirected graph, in-degree and out-degree coincide.
Interpretation: Degree centrality shows how many incoming (support from indi-
viduals), or out-coming (support to individuals) edges vertex - individual under
study has. This quantity can be related to the progress of the evolutionary search
and used to make the conclusion of what set of individuals has maximally con-
tributed to that. On Fig.2.3 are individuals sized according to that degree.
4. Community, see Fig.2.4.
Meaning: Community graph plot attempts to draw the vertices grouped into com-
munities.
Interpretation: Community graph plot showing the individuals grouped into
communities. Communities (with border are individuals that communicate
amongst themselves (higher density of edges in the community, multi-edges are
not visualized here, rather than between communities) and community are then
joined by connections that are “one-way” and shows the ﬂow of information
between communities). This kind of visualization can be interesting also in the
case of parallel EAs, where islands of subpopulations are formed.
Beside standard analysis of networks, it can study how information has been
spread throughout population during generations (i.e. network) as a ﬂow of inﬂuence.
In Fig.2.5 is captured how was inﬂuenced individual 50 (vertex 50) by individual
No. 1 (vertex 1). A set of possible paths is depicted by thick blue color there. It is
also clear that a part of the population has been inﬂuenced too. This is one example
of many. The whole tool of network analysis can be applied on networks generated
by evolutionary dynamics. For a more comprehensive overview and interpretations
of complex network properties and EAs parameters and structure it is recommended
to read for example [22], but also [1–21].

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
35
Fig. 2.1 Adjacency graph
Fig. 2.2 Graph partition

36
O. Yarakhmedov et al.
Fig. 2.3 Degree centrality
Fig. 2.4 Community graph

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
37
3
36
49
1
2
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
37
38
39
40
41
42
43
44
45
46
47
48
50
(a)
3
4
5
6
7
8
9
10
12
14
15
17
18
21
23
24
26
27
28
29
30
32
33
34
35
36
37
39
40
41
42
43
44
45
46
47
48
49
1
2
11
13
16
19
20
22
25
31
38
50
(b)
1
2
3 4 5 6 7 8 9 10
11
12
13
1415
16
1718
19
20
21
22
2324
25
2627282930
31
323334353637
38
3940414243444546474849
50
(c)
Fig. 2.5 Example of a ﬂow-inﬂuence from individual 1 to 50 in SOMA algorithm in a 200 gener-
ations, b 20 generations, c extracted from (b)

38
O. Yarakhmedov et al.
2.3
Algorithm Networks
2.3.1
Self-organizing Migrating Algorithm
SOMA is a stochastic optimization algorithm, modeled based on the social behavior
of competitive-cooperating individuals [1]. It was chosen because it has been proved
that this algorithm has the ability to converge towards the global optimum [1]. SOMA
works on a population of candidate solutions in loops, called migration loops. The
population is initialized by being randomly and uniformly distributed over the search
space at the beginning of the search. In each loop, the population is evaluated, and the
solution with the lowest cost value becomes the leader. Apart from the leader, in one
migration loop, all individuals will traverse the searched space in the direction of the
leader. Mutation, the random perturbation of individuals, is an important operation
for evolutionary strategies. It ensures the diversity among all the individuals and
it also provides a means to restore lost information in a population. Mutation is
different in SOMA as compared with other evolutionary strategies. SOMA uses a
parameter called PRT to achieve perturbations. This parameter has the same effect
for SOMA as mutation for GA. The novelty of this approach lies in that the PRT
vector is created before an individual starts its journey over the search space. The PRT
vector deﬁnes the ﬁnal movement of an active individual in the search space. The
randomly generated binary perturbation vector controls the permissible dimensions
for an individual. If an element of the perturbation vector is set to zero, then the
individual is not allowed to change its position in the corresponding dimension.
An individual will travel over a certain distance (called the PathLength) towards
the leader in a ﬁnite number of steps in the deﬁned length. If the PathLength is
chosen to be greater than one, then the individual will overshoot the leader. This
path is perturbed randomly. More about SOMA, see in [1, 5]. Networks generated
by SOMA and Scenario 1 is depicted in Fig.2.6. When applied to parallel hardware,
then network separated to subnetworks, weakly connected, can be expected, Fig.2.7.
2.3.2
Differential Evolution
Differential evolution [4] is a population-based optimization method that works on
real-number-coded individuals. For each individual xi,G in the current generation G,
DE generates a new trial individual x′
i,G by adding the weighted difference between
two randomly selected individuals xr1,G and xr2,G to a randomly selected third indi-
vidual xr3,G. The resulting individual x′
i,G is crossed-over with the original individual
xi,G. The ﬁtness of the resulting individual, referred to as a perturbed vector ui,G+1, is
then compared with the ﬁtness of xi,G. If the ﬁtness of ui,G+1 is greater than the ﬁtness
of xi,G, then xi,G is replaced with ui,G+1; otherwise, xi,G remains in the population
as xi,G+1. DE is quite robust, fast, and effective, with a global optimization ability. It
does not require the objective function be differentiable, and it works well even with

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
39
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
(a)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
(b)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
(c)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
(d)
Fig. 2.6 Example of a network growth of SOMA algorithm since beginning, a 1st generation,
b 2nd generation, c 3rd generation, d Nth generation. The yellow vertex represent the best individual
from the population
noisy, epistatic and time-dependent objective functions. For more about DE see in
[4].
In this case of [7, 10, 11] is discussed use of the weighted clustering coefﬁcient
[13, 14] in order to improve DE performance. One of the main goals of weighted
clustering coefﬁcient use on DE is to ﬁnd the way how to select the parents in the
mutation step to improve DE convergence rate. In the variant DE/best/1/bin, the best
individual is with the smallest (in minimizing problems) or greatest (in maximizing
problems) ﬁtness value. As it was described in former research, DE/best/1/bin does
not reach the best results in the non-separable and multimodal functions. This fact
led us to search for another criterion of the best individual selection. From the rules
that we have presented, we know that the edges between nodes representing the

40
O. Yarakhmedov et al.
Fig. 2.7 SOMA network on parallel platform. Five subnetworks has been created during the evo-
lutionary process
individuals are created only if the individuals represented by these nodes contributed
to the population improvement. The nodes representing the individuals becoming
the parents will have the greater out-degree (the number of out-going edges will be
greater) more often, and the weights of the edges leading from these nodes will be
higher. Such parents have the genomes of high quality, and it is important to spread
these genomes. The weighted clustering coefﬁcient is one of the most appropriate
candidates to be chosen as the criterion of parents selection in the mutation step from
two reasons:
1. It enables to capture spreading of the genomes from the node to another node
(individual).
2. Unlike the local clustering coefﬁcient, the weights of the edges are taken into
consideration.

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
41
1
2
3
5
4
100
100
6
100
(a)
1
2
3
5
4
100
50
100
6
100
100
100
(b)
1
2
3
5
4
100
50
100
6
50
100
50
(c)
Fig. 2.8 DE network principal growth, a 1st generation, b 2nd generation, c 3rd generation
When the adjacency matrix AG for the generation G is created, the weighted clus-
tering coefﬁcient of each node is computed. Then, for each individual the probability
of selection is computed according to the following equation:
pi =
Ci,Z
NP
j=1 Cj,Z
,
(2.1)
where pi denotes the probability of the i-th individual selection and Ci,Z is the
weighted clustering coefﬁcient of the node representing the i-th individual. Indi-
vidual represented by the node with the higher weighted clustering coefﬁcient has,
the higher probability to be selected as the parent in the mutation step. The net-
work can be constructed as suggested in Fig.2.8. The result can be then networked
as in Fig.2.9 or 2.10. As reported in [10, 11], this approach has improved DE’s
performance signiﬁcantly. Similar research is reported in [7].

42
O. Yarakhmedov et al.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
Fig. 2.9 Complex network of the DELocalToBest with two the most intensively connected vertices
(individuals) …
2.3.3
Particle Swarm
Papers [18] presents an initial proposal of methodology for converting the inner
dynamics of PSO algorithm into a complex network. The motivation is in the recent
trend of adaptive methods for improving the performance of evolutionary compu-
tational techniques. It seems very likely that the complex network and its statisti-
cal characteristics can be used within those adaptive approaches. The methodology
described in this paper manages to put a signiﬁcant amount of information about the
inner dynamics of PSO algorithm into a complex network as depicted in Figs.2.11
and 2.12, see [18–21].

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
43
(a)
(b)
(c)
(d)
(e)
(f)
Fig. 2.10 DE network examples; a and b HSDE, c and d JADE, e and f DERand1Bin
2.3.4
Artiﬁcial Bee Colony
Proposed approach has also been tested on Artiﬁcial Bee Colony algorithm (ABC)
andpresentedin[6, 8]. Themainideawas totest ABConschedulingproblems as well
as on continuous test problems. The complex network analysis was used for adaptive
control of the population. The structure of the algorithm was as follows: ﬁrstly, the
weighted adjacency matrix was created throughout the algorithm iterations, for some
ﬁxed number of iterations, a fraction of the total expected some iterations before
algorithm termination. The complex network recorded this way is then analyzed,

44
O. Yarakhmedov et al.
Fig. 2.11 Example of a network based on PSO. Network structure capture time development of
PSO in certain time window
and this information was subsequently used to identify the nodes (solutions) that
dont play a signiﬁcant role in the population dynamics. In this algorithm, such nodes
are replaced by the new randomly generated ones, although different schema of the
replacements generation could also be used.
The measures used to identify the nodes that do not contribute signiﬁcantly to
the population improvement were chosen to be the three types of vertex centrality,
the weighted degree centrality (strength), closeness and betweenness centrality, as
describedin[6, 8]. Thevertices representingsolutions wererankedaccordingtothese
measures, and the ﬁxed ratio of the solutions corresponding to the lowest ranking

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
45
Fig. 2.12 Example of a network based on PSO. Network structure capture time development of
PSO in certain time window - detail
nodes was removed and regenerated. The adjacency matrix was then reset. The entire
procedure of network recording and the nodes ranking and replacement are repeated
until the algorithm terminates. This concept is illustrated in Figs.2.13, 2.14 and 2.15.
ABC was used in other 2 (so in total in 3) variants. The 2nd variant (called in [8]
Adaptive ABC 2) is based on the use of three fully separated sub-populations, each
with their own network (or better sub-network, if whole EAs dynamics is taken like
network itself). Each of them was evaluated using different centrality measure type.
After the less inﬂuential nodes are pruned, and the networks reset, the tournament
selection of size two is performed to select every next-generation solution of every
sub-population, choosing the better of two solutions randomly selected from all
three sub-populations. In this way, the information sharing between sub-populations
is ensured.
The third version, named Adaptive ABC 3 was created to explore the inﬂuence
of distinct centralities on the speed of convergence. It takes the centrality measure to
be used for network analysis and nodes evaluation as a parameter. The algorithm is
fully described in [8].
Based on results reported in above-referenced papers, it can be stated that concept
proposed here was successful and has improved ABC performance signiﬁcantly [8].

46
O. Yarakhmedov et al.
6
7
3
9
11
8
10
15
14
12
4
13
2
1
5
Fig. 2.13 The network with labeled nodes (individuals) ranked by centrality. The larger centrality
nodes are marked in bigger size and different colors. The smallest blue nodes have the lowest
centrality, the largest red node has the highest centrality value
6
7
3
9
11
8
10
15
14
12
4
13
2
1
5
Cutoff x NS
NS
Fig. 2.14 The nodes (individuals) sorted according to their centrality score in ascending order. The
ﬁrst Cutoff NS nodes will be removed
2.3.5
Ant Colony Optimization
The Ant Colony Optimization (ACO) is another group of methods used in solving
different optimization tasks. The ACO’s distinctive feature is that the key behavioral
characteristics of real ants are simulated [23]. Commonly, ACO is mostly applied
to minimize the path in graph tasks [24], but the given algorithms also show good
results in other domains [25, 26]. In this chapter, we will describe the complex net-
work construction’s features of social interaction within an ants colony. The authors
study the multi-parameter benchmark tasks such as Rastrigin, Rosenbrock, Him-
melblau, Schwefel26, Giunta and Ursem01 functions. Some of these functions are

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
47
Fig. 2.15 The network after
the low centrality nodes
(individuals) removal. The
most important nodes are
preserved
6
7
3
9
11
15
12
4
1
characterized by multimodality, so, it undoubtedly will affect the ﬁnal structure of
the network. The described method, based on the classic ACO realization, is applied
for solving graph problems [26], however with some additions. Similar to the clas-
sic ACO, in this modiﬁcation, we can distinguish such steps as initialization and
arrangement, moving of ants, updating of pheromone and breakpoint checking. All
researching space is divided into n × n fragments, and each of them associated with
function value in the center and some pheromone level. The speciﬁed amount of ants
is placed on each fragment. As all the fragments are equal, the size of the fragment
can be calculated by the following formula:
m = (Xmax −Xmin)/n
(2.2)
Thus, the set of fragments is deﬁned by the matrix B = (Ii,j)n,n
i=q,j=l. When an ant
is moving from fragment I(i,j), it is calculating the moving probabilities towards the
adjacent fragments (see Fig.2.16), by using the following formula:
Pk
i,j =
⎧
⎪⎨
⎪⎩
τ α
i,j×ηβ
i,j
8
i,j=1
τ α
i,j×ηβ
i,j
, if i, j available
0, if i, j not available
(2.3)

48
O. Yarakhmedov et al.
Fig. 2.16 Available
fragments to move
where: i, j - fragments; k - ant number; - pheromone level; - visibility- difference
between two fragments function values; , - variable coefﬁcients; ∗- available if
fragment both adjacent and not an obstacle.
In each iteration pheromone both increases and evaporates. Thus the amount of
pheromone increment for the simulation step in the I(i,j) fragment is calculated by
the following formula:
τij(t + 1) = (1 −ρ) ∗τij(t) + Δ τij(t)
(2.4)
where: ρ ∈(0; 1) - evaporate coefﬁcient; τij(t) - pheromone level in I(i, j) fragment;
Δ τij(t) - increment at each iteration, is calculated by the next formula:
Δ τij(t) =
q

p=1
(K ∗(f (xi,j, yi,j)(kp) > f (xi+1,j+1, yi+1,j+1)(kp)))
(2.5)
where K pheromone increment coefﬁcient. Evaporation occurs because all the space
of possible solutions should be re-searched.
2.3.5.1
Experiment Design
By the described algorithm and the model (see Eqs.2.2–2.5) a software tool (ST) that
implements the search of local and global extremes was developed alongside with
a mechanism of analysis of ants interaction with each other. During every iteration,
ants move from fragment to fragment using pheromone traces of another ant. It is
the mechanism of experience exchange within the colony. You can see it step by step
on Fig.2.17.
As you can see in Fig.2.17 all ants tend to migrate to one fragment (gray one)
where the extreme is situated. In the process of building the ants are attracted to the
extreme, and also use the pheromones of other ants. The ﬁrst ant which is marked by

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
49
Fig. 2.17 Mechanism of experience exchange within the colony: a 1st step, b 2nd step, c 3rd step,
d 4th step
Fig. 2.18 Graph of relations
between ants
red color builds its route using only attraction. The third ant (the blue one) builds a
route using pheromone trace of the ﬁrst ant, and the second ant (green one) reaches
extreme fragment using both the ﬁrst and the second ant’s pheromone traces. Using
this data author can create a graph of relations between ants. You can see in in
Fig.2.18.
Using this approach, the authors have analyzed the behavior of ants in the process
of optimization of different test functions.
2.3.5.2
Results
All graphs described below were visualized using free software tool Gephi. For
the layout, the graphs authors used force-direct Yifan Hu algorithm [27]. The ﬁrst
test function is Rastrigin function. The function proposed in 1974 by Leonard Ras-
trigin [28] demonstrates the unlimited multimodal function. The equation of the
n-dimensional Rastrigin test function is:

50
O. Yarakhmedov et al.
Fig. 2.19 Rastrigin function chart
Fig. 2.20 Rastrigin function optimization process: a initialization step, b middle step, c ﬁnal result
fRastrigin(x) = 10n
n

i=1
	
x2
i −10 cos (2πxi)

(2.6)
Its 2-dimensional view is represented in the Fig.2.19.
Figure2.20showstheprocessofoptimizationofaRastriginfunction.Thefunction
was studied in the range [−1.5; 1.5].
Figure2.21 shows result graph. In Fig.2.21 you can see all ants and connections
between them. Obviously, complex graph consists of some clusters of vertexes - 9.
The same number of extremes in the considered area. Also, it should be noted, that
there are links between the clusters. They arise because of the probabilistic basis for
the selection of ants in the process of route construction. The next studied function
is Rosenbrock function [29]. The equation of the n-dimensional Rosenbrock test

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
51
Fig. 2.21 Resulting graph
function is:
fRosenbrock(x) =
n−1

i=1

100

x2
i −xi+1
2 + (xi −1)2
(2.7)
Its 2-dimensional view is represented in the Fig.2.22.
Figure2.23 shows the process of optimization of Rosenbrock function. The func-
tion was studied in the range [−2.5; 2.5].
As it is known, Rosenbrock function has one global minimum, whose coordinates
are (x, y) = (1, 1), where f (x, y) = 0. The Fig.2.23 shows that as a result of opti-
mization a lot of resulting fragments has been received. This is due to the speciﬁc
behavior of the function in these fragments and of course with the size the test space
partition. Figure2.24 shows the resulting graph.
The resulting graph consisting of clusters is obvious, but clusters are linked suc-
cessively rather than all together like in Rastrigin function resulted in graph. Him-
melblau function [30]. The equation of the n-dimensional Himmelblau test function
is:
fHimmelblau(x) =

x2
1 + x2 −11
2 +

x1 + x2
2 −7
2
(2.8)
Its 2-dimensional view is represented in the Fig.2.25.
Figure2.26 shows the process of optimization of Himmelblau function. The func-
tion was studied in the range [−5; 5].
This function has 4 equal global optimums in points:
• f (3.0, 2.0) = 0.0

52
O. Yarakhmedov et al.
Fig. 2.22 Rosenbrock function chart
Fig. 2.23 Rosenbrock function optimization process: a middle step, b ﬁnal result
• f (−2.805118, 3.131312) = 0.0
• f (−3.779310, −3.283186) = 0.0
• f (3.584428, −1.848126) = 0.0
All 4 extremes were localized. You can see them on Fig.2.26b. Figure2.27 shows
the resulting graph.
Figure2.27 shows all 4 localized extremes (4 clusters). Ursem01 function. The
equation of the n-dimensional Ursem01 test function is:

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
53
Fig. 2.24 Resulting graph
Fig. 2.25 Himmelblau function chart

54
O. Yarakhmedov et al.
Fig. 2.26 Himmelblau function optimization process: a middle step, b ﬁnal result
Fig. 2.27 Resulting graph

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
55
Fig. 2.28 Ursem01 function chart
Fig. 2.29 Ursem01 function optimization process: a middle step, b ﬁnal result
fUrsem01(x) = −sin (2x1 −0.5π) −3 cos (x2) −0.5x1
(2.9)
Its 2-dimensional view is represented in the Fig.2.28.
Figure2.29showstheprocessofoptimizationofaUserm01function.Thefunction
was studied in the range [−3; 3].
This function has one local and one global optimum in point with coordinates [3,
2] where f (3, 2) = 0.0; Fig.2.30 shows result graph.

56
O. Yarakhmedov et al.
Fig. 2.30 Resulting graph
Figure2.30 shows 2 clusters (2 extremes). One of them consists of more vertexes.
It is characterized by the global extreme. Giunta function. The equation of the n-
dimensional Giunta test function is:
fGiunta(x) = 0.6 +
n

i=1

sin2

1 −16
15xi

−1
50 sin

4 −64
15xi

−sin

1 −16
15xi

(2.10)
Its 2-dimensional view is represented in the Fig.2.31.
Figure2.32 shows the process of optimization of Giunta function. The function
was studied in the range [−1; 1].
Giunta function has one global optimum f(x) = 0,06447 for x = [0, 4673;
0, 4673]. It is situated in top right part in Fig.2.32b. There is a lot of localized
fragments on the left and bottom borders of Fig.2.32a and b. It happens because ants
can move only to fragments with lower function value, so they cannot pass through
the surface convexity to the global minimum and tend to move to borders. Figure2.33
shows resulting graph.
Figure2.33 shows one big cluster because Giunta function has only one extreme.
Also, there are many vertexes situated far from the main cluster. It occurred because
many ants accumulated on left and bottom borders. Schwefel26 function. The equa-
tion of the n-dimensional Schwefel26 test function is:
fSchwefel26(x) = 418.9829n −
n

i=1
xi sin

|xi|

(2.11)
Its 2-dimensional view is represented in the Fig.2.34.

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
57
Fig. 2.31 Giunta function chart
Fig. 2.32 Giunta function optimization process: a middle step, b ﬁnal result
Figure2.35 shows the process of optimization of a Schwefel26 function. The
function was studied in the range [−500; 500].
Schwefel26 function [31] has many extremes. Figure2.35 proves it. All of them
were localized. Figure2.36 shows result graph.
As a result, authors got a graph with many clusters. Also, authors noted, that there
are graphs which dont connect with the main graph. It means that in the process of
localizing the exact extremes ants did not connect with other ants. It depends on the

58
O. Yarakhmedov et al.
Fig. 2.33 Resulting graph
Fig. 2.34 Schwefel26 function chart

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
59
Fig. 2.35 Schwefel26 function optimization process: a middle step, b ﬁnal result
Fig. 2.36 Resulting graph

60
O. Yarakhmedov et al.
Table 2.1 Detailed information about resulted graphs
Function
Avg. degree
Avg. weighted
degree
Network
diameter
Graph density
Modularity
Connected
components
Avg. clustering
coefﬁcient
Avg. path
length
Rastrigin
245.612
569.648
11
0.047
0.894
1
0.818
4.755
Rosenbrock
690.186
56343.303
10
0.135
0.624
1
0.874
3.461
Himmelblau
707.384
7523.683
7
0.136
0.820
1
0.885
3.125
Ursem01
800.477
154.119
5
0.270
0.878
1
0.878
2.211
Giunta
1044.556
0.618
9
0.207
0.933
1
0.780
2.511
Schwefel26
68.425
572.385
32
0.014
0.939
8
0.821
12.365

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
61
Fig. 2.37 Network formatting during the process of Schwefel function optimization: a 3rd iteration,
b 5th iteration
size of the partition. More information [32] about the resulting graphs is shown in
Table2.1.
It is also possible to observe the dynamic change in the graph structure through
function optimization. Figure2.37 shows graph structure changes in the optimization
process.
As you can see in the course of time clusters are formed. Figure2.37a shows graph
on 3rd iteration. Ants have just started to move, and haven’t earned much experience
from the colony. But after 5th iteration (see Fig.2.37b) nodes form groups (clusters).
All ants in the cluster are participating in the optimization of a certain extreme, and
thus provide each other the greatest inﬂuence within the group.
2.4
Conclusion
The authors carried out series of experiments to analyze the behavior of ants. Special
software tool for optimization of the test functions was developed using C# program-
ming language and Microsoft Visual Studio. All experiments carried out on a PC
with processor AMD Phenom II P960 with 6GB of RAM. To analyze and to visual-
ize data authors used free software tool Gephi. Following the results of experiments,
we can conclude that there is a deﬁnite pattern in the behavior of ants and as a result
the structure of the graph. There is the formation of clusters. It is also worth noting
that there is a strong link between the ants within the group and a weak dependence
on the ants of other clusters. The experiments allowed to illustrate the interaction of
agents in the colony during the search for optimal solutions of test functions, such as
Rastrigin, Rosenbrock, Himmelblau, Schwefel26, Giunta and Ursem01 functions.

62
O. Yarakhmedov et al.
Acknowledgements The following grants are acknowledged for the ﬁnancial support provided
to this research: Grant Agency of the Czech Republic - GACR P103/15/06700S, Grant of SGS
No. SGS 2017/134, VSB-Technical University of Ostrava. The Ministry of Education, Youth and
Sports from the National Programme of Sustainability (NPU II) project “IT4Innovations excellence
in science - LQ1602”.
References
1. Zelinka, I.: SOMA self organizing migrating algorithm, Chap. 7. In: B.V. Babu, G. Onwubolu
(eds.) New Optimization Techniques in Engineering, p. 33. Springer, Berlin (2004). ISBN
3-540-20167X
2. Zelinka, I., Davendra, D., Chadli, M., Senkerik, R., Dao, T.T., Skanderova, L.: Evolutionary
dynamics and complex networks. In: Zelinka, I., Snasel, V., Ajith A. (eds.) Handbook of
Optimization, p. 1100s. Springer, Germany (2012)
3. Zelinka, I., Davendra, D., Chadli, M., Senkerik, R., Dao, T.T., Skanderova, L.: Evolutionary
dynamics and complex networks. In: Zelinka, I., Snasel, V., Ajith, A. (eds.) Handbook of
Optimization, p. 1100s. Springer, Germany (2012)
4. Price, K.: An introduction to differential evolution. In: Corne, D., Dorigo, M., Glover, F. (eds.)
New Ideas in Optimization, p. 79108. McGraw-Hill, London (1999)
5. Donald, D., Zelinka, I.: Self-organizing migrating algorithm. New Optimization Techniques in
Engineering (2016)
6. Metlicka, M., Davendra, D.: Chaos-driven discrete artiﬁcial bee colony. IEEE Congress on
Evolutionary Computation, pp. 2947–2954 (2014)
7. Davendra, D., Zelinka, I., Metlicka, M., Senkerik, R., Pluhacek, M.: Complex network analy-
sis of differential evolution algorithm applied to ﬂowshop with no-wait problem. In: IEEE
Symposium on Differential Evolution, 2014, Orlando, FL, USA, pp. 65–72, 9–12 December
2014
8. Davendra, D., Metlicka, M.: Ensemble centralities based adaptive artiﬁcial bee algorithm. In:
IEEE Congress on Evolutionary Computation (2015)
9. Zelinka, I.: Evolutionary algorithms as a complex dynamical systems. In: Tutorial at IEEE
Congress on Evolutionary Computation 2015, Sendai (2015)
10. Zelinka, I.: On mutual relations amongst evolutionary algorithm dynamics, its hidden com-
plex network structures. In: Meghanathan, N. (ed.) Advanced Methods for Complex Network
Analysis, IGI, An Overview and Recent Advances (2015)
11. Skanderova L., Zelinka I.: Differential evolution dynamic analysis by the complex networks.
In: Meghanathan, N. (ed.) Advanced Methods for Complex Network Analysis, IGI (2015)
12. Meyn, S.: Control Techniques for Complex Networks. Cambridge University Press, Cambridge
(2007)
13. van Steen, M.: Graph Theory and Complex Networks: An Introduction. Maarten van Steen,
Amsterdam (2010)
14. Chen, G., Wang, X.: Xiang Li Fundamentals of Complex Networks: Models. Wiley, Structures
and Dynamics (2015)
15. Zelinka, I., Davendra, D., Senkerik, R., Jasek, R.: Do evolutionary algorithm dynamics create
complex network structures? Complex Syst. 2, 0891–2513, 20, 127–140 (2011)
16. Zelinka, I., Davendra, D., Snasel, V., Jasek, R., Senkerik, R., Oplatkova, Z.: Preliminary Inves-
tigation on Relations Between Complex Networks and Evolutionary Algorithms Dynamics,
CISIM, Poland (2010)
17. Zelinka, I., Davendra, D., Chadli, M., Senkerik, R., Dao, T.T. Skanderova, L.: Evolutionary
dynamics and complex networks. In: Handbook of Optimization. Springer Series on Intelligent
Systems (2012)

2
Evolutionary Dynamics and Its Network Visualization - Selected Examples
63
18. Michal, P., Jakub, J., Roman, S., Ivan, Z., Donald, D.: PSO as complex network capturing
the inner dynamics initial study. In: Proceedings of the Second International Afro-European
Conference for Industrial Advancement AECIA 2015, pp. 551–559. Springer International
Publishing, Berlin (2016)
19. Michal, P., Roman, S., Jakub, J., Adam, V., Ivan, Z.: Study on swarm dynamics converted
into complex network. In: Proceedings of the 30th European Conference on Modelling and
Simulation, ECMS 2016, European Council for Modelling and Simulation (ECMS) (2016)
20. Michal, P., Roman, S., Adam, V., Jakub, J., Donald, D.: Complex network analysis in PSO as
an ﬁtness landscape classiﬁer. In: 2016 IEEE Congress on Evolutionary Computation (CEC),
pp. 3332–3337. IEEE (2016)
21. Michal, P., Roman, S., Adam, V., Ivan, Z.: Creating complex networks using multi-swarm
PSO. In: 2016 International Conference on Intelligent Networking and Collaborative Systems
(INCoS), pp. 180–185. IEEE (2016)
22. Zelinka, I.: Controlling complexity. In: Sanayei, A., Zelinka, I., Rossler, O.E. (eds.) ISCS 2013:
Interdisciplinary Symposium on Complex Systems, Emergence, Complexity and Computation,
vol. 8. Springer, Berlin (2014)
23. Dorigo, M., Gambardella, L.M.: Ant colony system: a cooperative learning approach to the
traveling salesman problem. IEEE Trans. Evol. Comput. 1(1), 53–66 (1997)
24. Liu, X., Fu, H.: An effective clustering algorithm with ant colony. J. Comput. 5(4), 598–605
(2010)
25. Toksari, M.D.: Ant colony optimization for ﬁnding the global minimum. Appl. Math. Comput.
176, 308316 (2006)
26. Neydorf, R.A., Yarakhmedov, O.T.: Development, optimization and analysis of parameters of
classic ant colony algorithm in solving travelling salesman problem on graph. Sci. Technol.
Prod. 3(2), 18–22 (2015)
27. Hu, Y.: Efﬁcient High-Quality Force-Directed Graph Drawing. Math. J. 10(1), 37–71 (2006).
Wolfram, Media
28. Rastrigin, L.A.: Systems of Extremal Control. Nauka, Moscow (1974). (in Russian)
29. Rosenbrock, H.H.: An automatic method for ﬁnding the greatest or least value of a function.
Comput. J. 3, 175184 (1960)
30. Himmelblau, D.: Applied Nonlinear Programming. McGraw-Hill, New York (1972)
31. Laguna, M., Marti, R.: Experimental Testing of Advanced Scatter Search Designs for Global
Optimization of Multimodal Functions (2002)
32. Newman, M.: Networks: An Introduction. Oxford University Press, Oxford (2010)

Part II
Applications

Chapter 3
Differential Evolution Dynamics Modeled
by Social Networks
Lenka Skanderová and Ivan Zelinka
Abstract During the last years, social networks have become a normal part of our
lives. Some people can not imagine the world without the social networks yet. They
are considered to be an appropriate tool for communication, advertisement, or even
business. Beside the indisputable importance of the social networks for the users,
they bring very valuable information for researchers from whole of the world. The
social network analysis is used to better understand some principles of difﬁcult sys-
tems. In this chapter, they are used to model and better understand the relationships
between individuals in the differential evolution algorithm. The short-interval net-
works, aggregated networks, and longitudinal social networks will be taken into
consideration and the results of the different analysis will be discussed.
3.1
Introduction
In the history, the social networks (SNs) have been investigated by scientists from
different areas of research as sociology, psychology, anthropology, and mathematics.
In 1930s, Moreno [37] developed a sociogram – a tool for interpersonal relationships
representation. In sociogram, social units are represented by points and relationships
between them by lines connecting the corresponding points in the two-dimensional
space [54]. The sociogram has been used by many researchers from whole of the
world, for example Laumann and Pappi [31] and Laumann and Knoke [30] used
the sociogram to represent a structure of inﬂuence among community elites. In [3],
the sociogram has been used to represent role structures in groups and in [42] to
investigate the interaction patterns in small groups [54].
L. Skanderová (B) · I. Zelinka
Department of Computer Science, Faculty of Electrical Engineering and Computer Science,
VŠB – Technical University of Ostrava, 17. listopadu 15,
708 33 Ostrava-Poruba, Czech Republic
e-mail: lenka.skanderova@vsb.cz
I. Zelinka
e-mail: ivan.zelinka@vsb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_3
67

68
L. Skanderová and I. Zelinka
In 1960s, the matrix representation of the social networks has been introduced.
The ﬁrst researchers using matrices to represent social network data were for example
Forsyth and Katz [16], Luce and Perry [35], or Harary and Norman [22].
Since1930s,manyresearchesdealingwiththemethodsoftheanalysisofthesocial
networks have been published, for example [6, 12, 21, 32, 43]. Social networks have
been also successfully used to better understand some real world phenomenons, for
example Brissette et al. [4] studied the role of optimism, coping and psychological
adjustment of the college students during the ﬁrst two semesters. Morrison [38]
analyzed the patterns of social relationships and their inﬂuence on socialization.
Perry-Smith et al. [39] proposed the study dealing with the connection of the context
of social relationships and individual creativity. Daly and Haahr [9] analyzed social
network for routing in sparse Mobile Ad hoc Networks (MANETs). Centola [7]
investigated how the network structure inﬂuence the diffusion such that he studied
the spread of health behavior in an online social network. Janson [27] in his thesis
used the social network analysis as a tool for mental models creation and comparison.
The evolutionary algorithms are considered to be very efﬁcient tool for optimiza-
tion. They are used to search an optimal solution of the difﬁcult problems, where the
standard mathematical methods are not capable to provide a satisfying solution in
real time. The evolutionary algorithms usually work with a population of individu-
als (solution vectors) and they are inspired by the biological evolution, where three
basic principles are applied – crossover, mutation and natural selection – to produce
the offspring with better properties than their parents. Thanks to this mechanism of
breeding, in each generation, in ideal case, better and better offspring is produced.
At the end of the algorithm, the best solution is selected as the solution of the given
problem.
The idea to model the evolutionary algorithms (EAs) dynamics via complex net-
works (CNs) has been introduced by Zelinka et al. in [56]. This work has been
followed by the other researchers as Davendra et al. [10], Skanderova and Fabian
[47], Janostik et al. [25, 26], or Pluhacek et al. [40]. The motivation to model the
dynamics of the EAs using CNs was to better understand the relationships between
individuals in a population and use this knowledge to improve the performance of
the selected EAs.
In this chapter, the idea to represent the dynamics of the selected evolutionary
algorithm – differential evolution (DE) – by the social networks will be discussed. As
well as many other EAs, DE works with a population of individuals and the principles
as crossover, mutation and natural selection are used to produce better offspring. It
can be said that the individuals communicate with each other to create an offspring.
If we consider the individuals to be the social units and the offspring creation as
a kind of the relation, the EA dynamics can be represented by the social network
and the standard methods of the social network analysis can be used to analyze the
relationships between the individuals in the population. The results of this analysis
could bring a new information, which can be used to improve the performance of
this algorithm.

3
Differential Evolution Dynamics Modeled by Social Networks
69
The rest of the chapter is organized as follows: In Sect.3.2, the DE algorithm is
described brieﬂy. Section3.3 deals with the fundamental concepts of social networks
and graph theoretic notation. In Sect.3.4, the methods of the social network analysis
are discussed. In Sect.3.5, the representation of the differential evolution dynamics
by the social networks is presented. And in Sect.3.6, the results of the experiments
are discussed and some conclusions are presented.
3.2
Differential Evolution
DifferentialevolutionworkswithapopulationofNP individualsxG
i ,i = {1, . . . , NP}.
G denotes a generation. One individual xG
i consists of D parameters. Each parameter
is constrained by its search range [xlower,j, xupper,j], where lower and upper denote
lower and upper bound for each parameter and j = {1, . . . , D} is an index of a para-
meter. The ﬁrst population is generated randomly in the space of possible solutions.
Then for each target vector xG
i , three mutually different solution vectors (parents) xG
r1,
xG
r2, and xG
r3 are selected randomly to create a mutation vector vG
i , see Eq. (3.1). In the
crossover operation, parameters of a mutation vector are combined with parameters
of a target vector on the basis of the crossover rate CR to create a trial vector uG
i ,
see Eq. (3.2). If an objective function value of a trial vector f (uG
i ) is not worse than
an objective function value of a target vector f (xG
i ), a trial vector (offspring) will
survive to the next generation, otherwise a target vector will survive, see Eq.3.3.
The mutation operation is mathematically deﬁned by the following equation:
vG
i = xG
r1 + F · (xG
r2 −xG
r3) ,
(3.1)
where F is the scale parameter with typical value between 0.4 and 0.95 [36].
The crossover operation is then described by the following equation:
uG
i,j =

vG
i,j
if r(j) ≤CR or j = rn(i)
xG
i,j
if r(j) > CR and j ̸= rn(i) ,
(3.2)
where CR ∈[0, 1], rn(i) ∈{1, . . . , D} is an integer selected randomly with the uni-
form distribution ensuring that a trial vector uG
i will contain at least one parameter
from a mutation vector vG
i , and rj ∈[0, 1] represents a random number from the unit
interval generated for each j-th parameter [51].
A selection of an individual, which will be accepted to the next generation is
dependent on the objective function value of target and trial vectors. If the objective
function value of a trial vector is not worse than the objective function value of a
target vector, a trial vector will replace a target vector in the next generation. In the
case that an objective function value of a trial vector is worse, a trial vector will be
erased and a target vector will survive to the next generation. This scheme could be
outlined by the following equation:

70
L. Skanderová and I. Zelinka
Fig. 3.1 Activation of a
target vector xG
i by three
solution vectors xG
r1, xG
r2, xG
r3
represented by a directed
graph
xG+1
i
=

uG
i
if f (uG
i ) ≤f (xG
i ) (for minimization problem)
xG
i
otherwise .
(3.3)
Zelinka et al. in [56, 57] mentioned a new philosophy for the DE algorithm,
where a new solution vector generation is considered to be just an activation of a
target vector to move to a better position. More precisely, if a trial vector uG
i replaces
a target vector xG
i in the next generation such that xG+1
i
= uG
i , it will be considered
to be an activation of a target vector xG
i by three solution vectors xG
r1, xG
r2 and xG
r3
(selected randomly in the mutation operation to create a donor vector vG
i ) to move
to a better position.
This activation can be modeled by a directed graph such that a target vector xG
i
and all three solution vectors xG
r1, xG
r2 and xG
r3 are represented by nodes and there
is a directed line (arc) leading from each node representing a solution vector xG
rj,
j = 1, 2, 3 to the node representing a target vector, see Fig.3.1. For each generation,
one directed graph is created.
3.3
Fundamental Concepts of Social Networks and Graph
Theoretic Notation
In Sect.3.1, a sociogram has been mentioned as a tool for representation of the rela-
tions among so called social units. A social unit can be anything, for example student
in the class, medical doctor in the hospital, animal in the pack, school in the state, or
even state in the world. From the view point of social network analysis, these social
units are denoted as actors. These actors can be characterized by their properties.
For example, students in the class are characterized by their results, medical doctors
by the number of patients, schools by the number of students etc. The properties of
the actors play a signiﬁcant role in the context of the social network analysis.
Actors are tied to the other ones by social ties. A social tie between two social
units can be for example individual evaluations (liking, friendship), transactions or
transfer (buying, selling), movement (migration), kinship (marriage, descent). The

3
Differential Evolution Dynamics Modeled by Social Networks
71
methods investigating ties between two actors are called dyadic. The methods dealing
with the relationships among three actors are called triadic [54].
Formally, a social network can be represented by a directed or undirected graph
G = (N , L ), where N denotes the set of nodes and L the set of lines between
pairs of nodes. The set of nodes represents the set of actors N = (n1, n2, . . . , ng). A
relation between two actors in a social network is usually drawn by a line connecting
two nodes in a graph. This line can be directed, in such case we talk about an arc,
or undirected, then we talk about an edge [11]. In the case of the directed graph, the
maximum number of arcs is g(g −1), where g denotes the number of nodes. In the
undirected graph, the set L contains at most g(g −1)/2 lines [54].
In social networks, it is possible to distinguish more than one type of relations.
Such social networks are called multirelational networks. The number of relations
is denoted as R. Each relation can be represented by one directed or undirected
graph. The set of nodes is the same for all relations, however, each relation has a
corresponding set of arcs (edges) Lr, where r = 1, 2, . . . , R, containing Lr ordered
pairs of actors [54].
3.4
Social Network Analysis
Social network analysis (SNA) is focused on the social ties among actors in the social
network [11]. The key attribute of the social network in the SNA is the relationship.
Two actors can be connected by directed or undirected line. For example in the case
of the SN representing the e-mail communication in the school, the lines would
be probably directed. On the other hand, the SN modeling marriage and business
among families in 15th century in Florence would contain undirected edges [54].
Beside the direction, a relationship can be characterized by its strength indicating
the intensity of the relationship. In the graph representing the SN, the strength of
the relationship between two actors is usually represented by a weighted line, where
the weight can be integer or real number. In [14], strong ties have been considered
to be contributing in the process of information exchange meaning that individuals
closely tied to others have more intimate ties and for this reason they are motivated
to provide information to the others [23]. In [20], the importance of weak ties in
the process of information transmission was conﬁrmed. Works of Granovetter [19]
and Lin and Bian [34] then indicated the importance of both strong and weak ties in
information exchange process [23].
In the SNA, a SN can be investigated from the two points of view: ego-centric
network and whole network. In the case of the ego-centric network, the SNA is
focused on the view point of the network from the perspective of an actor in the
network, while the whole network approach provides the view point of the whole
structure of the network [23].

72
L. Skanderová and I. Zelinka
The ego-centric networks are usually used in the case that “a population of actors
is too large or it is hard to deﬁne the boundaries of the population” [23]. They are
used to provide a picture of a typical actor in the network. In this case, the number of
ties of the individual actors to the others, the types of ties they maintain and kind of
information they provide to and receive from others in this network are investigated
[23]. For example, in [15], the ego-centric network has been used to understand how
people manage their personal and group communications. The work of Hite and Hes-
terly [24] is focused on the ﬁrm’s ego-centric network directly inﬂuencing the ﬂow
of resources across the ﬁrm’s boundaries. Abbasi et al. in [1] describes social net-
works based theoretical model for exploring scholar’s collaboration (co-authorship)
network properties, which are associated with their citation-based research perfor-
mance.
On the other hand, the whole network approach investigates the ties of all members
of the network maintaining with all others. The whole network approach can be used
to identify the key players in the process of information exchange. Moreover, the
analysis of the whole network is used to identify the groups of similar individuals
[23].
The most often investigated principles of the SNA are cohesion, structural equiv-
alence, prominence, range, and brokerage [23]. In the following text, each of the
principles will be described brieﬂy.
Cohesion analysis is used to describe the attributes of whole network. The mea-
sures of cohesion are density and centralization which indicate the extent to which
the actors in the network interact with all other ones. In the case of higher degree
of connectedness, network structures as clusters and cliques can be analyzed [23].
The subgroups of highly interconnected actors are called clusters. In the case that all
members of cluster is connected with each other, the cluster is called clique. Within
the clique, each member can reach each other in one step. However, it is possible to
deﬁne a clique, where each member can reach each other in two, three (generally n)
steps [23]. Another attribute investigated in the SNA in connection with cohesion is
a density, which is calculated as the ratio of the number of actual links in the network
to the number of all possible links in the network.
The second principle often used in the SNA is the structural equivalence identi-
fying actors with similar roles. Two actors are considered to be structurally equivalent
“if they have identical ties to and from all other actors in the network” [54].
To indicate an inﬂuence of a node in the network, a measures of prominence are
used. “Prominence can be measured by assessing the centrality of an individual in
a network” [23]. A centrality of a node can be measured by different ways. In the
following subsections, some centrality measurements will be described.
Range relates with the accessible resources for an actor. An actor represented by
a node with higher number of ties has better access to social resources [23].
The last discussed principle is brokerage. An actor denoted as a broker serves as
an intermediary between two groups carrying information from one group to another.
Thanks to this position, a broker can control the information ﬂow.

3
Differential Evolution Dynamics Modeled by Social Networks
73
3.5
Evolutionary Algorithms Represented by Social
Networks
As mentioned above, some works dealing with the representation of the evolutionary
or swarm algorithms dynamics by complex networks have been published during the
years 2009–2016. The main question, which has to be solved at the beginning of such
works, is how to model the dynamics of the DE algorithms by complex networks
and is there any framework for the analysis of such generated complex networks?
What would we like to gain by the analysis of such complex network and which
characteristics will be analyzed for this purpose? The answer for the ﬁrst question
– how to model the dynamics of the DE algorithm – has been partially provided by
Zelinka et al. in [56], where each individual is modeled by a node and a relationship
“activation” is represented by a directed arc, see Fig.3.1. Each generation of the
DE algorithm is modeled by one network. The evolution of the population is then
represented by the set of directed networks.
The main idea of this chapter is that the individual in a population can be consid-
ered to be a social unit. As mentioned above, a social unit can be anything – pupil
in a class, a class at a school, or a school in a city. As well as the other social units,
the individuals in a population have their own properties – parameters and ﬁtness.
These properties are in the context of the social network analysis very important. For
example we can investigate if there is a connection between the individual with the
best ﬁtness value and a node with the highest out-degree.
In this work, three possibilities how to represent the evolution process by a social
network have been taken into account. Considering the fact that the DE algorithms
work in generations, it is possible to create one directed network for each generation.
These networks will be denoted as the short-interval networks. Thanks to this mech-
anism, the inﬂuence of the solution vectors (selected to create a mutation vectors) on
the evolution of target vectors can be investigated. However, this principle does not
enable to analyze the inﬂuence of the individual on the evolution of the whole popu-
lation during the whole evolutionary algorithm. This problem can be solved by using
so called “aggregated” network, which is the accumulation of the short-interval net-
works, see Fig.3.2. Short-interval networks as well as aggregated network are often
used in connection with the longitudinal social networks, see [8, 17, 44–46, 52]. The
aggregated network is also used in relation with temporal networks. The possibility
to model the dynamics of the DE algorithm by the longitudinal social networks will
be discussed at the end of this chapter.
3.5.1
Short-Interval Networks and Cohesion Analysis
The term short-interval network is often used in connection with the longitudinal
social network (LSN). Longitudinal social network is composed by the number of
short-interval networks reﬂecting the state of the LSN at different points of time. In

74
L. Skanderová and I. Zelinka
Fig. 3.2 Illustration of the short-intervals network and aggregated network [52]
this subsection, we will not consider the longitudinal social network yet. However,
because the EAs usually work in generations, the social network has to be created
by short-interval networks (SIN) such that each SIN reﬂects the state of the social
network after one generation.
From the view point of the DE algorithm, each SIN captures the relation “acti-
vation” between the activators and activated individuals in one generation. In other
words, each SIN representing one generation captures the relationship “activation”
between all individuals, which have been successfully used to improve the popula-
tion in this generation. This means that only individuals participating in the process
of the population improvement are modeled by nodes. The arc leads always from
a node representing a solution vector (activator) xG
rj to a node representing a target
vector xG
i (activated individual). Target vectors, which are not replaced by a new
offspring in the next generation (they are not activated to move to a better position)
or solution vectors, which have been not selected in a mutation operation (they have
not become the activators for any target vector), will not be taken into account. The
important consequence of this rule is that the number of nodes of each short-interval
network will be different.
3.5.1.1
Experiment
The motivation of this experiment is to analyze the short-interval networks created by
the DE algorithm dynamics. We have selected the basic variant of the DE algorithm
– DE/rand/1/bin, which is thoroughly described in Sect.3.2. Its performance and
properties have been very well described in many publications. However, the social
networks have never been used to analyze the relationships between individuals in
the population. We do not know, whether the DE algorithm tends to create clusters,
the average path length between two individuals in one generation, or the network
motifs typical for the dynamics of the DE algorithm. This experiment is focused on
the basic characteristics of the networks created by the DE algorithm.

3
Differential Evolution Dynamics Modeled by Social Networks
75
3.5.1.2
Benchmark Set and Parameter Settings
Benchmark set CEC 2013 consists of 28 benchmark functions from CEC 2013 Spe-
cial session on real-parameter optimization. A detailed description of the 28 bench-
mark functions can be found in [33]. These benchmark functions can be divided into
three classes:
• Uni-modal functions: f1 – f5
• Multi-modal functions: f6 – f20
• Composition functions: f21 – f28
ThedetailedparametersettingsfortheDEalgorithmisgivenasfollows:Thepopu-
lation size is set to NP = 100, the dimension to D = 30 and the number of generation
to G = 3000. We have not worked with the maximum number of the objective func-
tion evaluation as suggested in [33] because for each generation, one short-interval
network is created. The scale factor has been set to F = 0.5 and crossover rate to
CR = 0.9.
3.5.1.3
Short-Interval Network Creation
The principle of the short-interval networks creation has been described above. Only
solution vectors selected in the mutation operation to create a mutation vector and
target vectors, which have been successful and created a better offspring are taken
into consideration. They are modeled by nodes and the arcs always lead from the
node representing a solution vector xG
rj to the node representing a target vector xG
i .
For each generation, one short-interval network is created regardless the previous
one.
In Fig.3.3, the example of two short-interval networks created on the basis of
the DE/rand/1/bin algorithm is depicted. In the ﬁrst generation (on the left), for the
target vector x1
1, the solution vectors x1
2, x1
4, and x1
6 have been selected to create a
mutation vector. These individuals have created a successful offspring. Or in other
words, the solution vectors x1
2, x1
4, and x1
6 have activated a target vector x1
1 to move
Fig. 3.3 Example of the two generations of the DE/rand/1/bin algorithm represented by two SINs

76
L. Skanderová and I. Zelinka
to a better position. The next activated target vector is x1
3, which has been activated
by solution vectors x1
2, x1
4, and x1
5. In the second generation (on the right), two target
vectors have been activated – x2
3 and x2
5. In the ﬁrst generation, six individuals have
contributed to the evolution of the population. However, in the second generation,
seven individuals have participated in the process of the population improvement.
The algorithms have been implemented in C#, Microsoft .NET Framework 4.5.1
and run on a computer with CPU Intel Xeon 2.83 GHz. To analyze the network
created on the basis of the DE algorithms dynamics, the software UCINET 6.0 [2]
has been used.
3.5.1.4
Investigated Characteristics
As mentioned at the beginning of this chapter, the social network analysis deals with
several basic characteristics. In this part of the work, we have been focused especially
on the cohesion characteristics. Beside the number of nodes, we have analyzed the
average degree, degree centralization, density, number of weakly connected compo-
nents, fragmentation of the network, average distance, diameter, compactness and
characteristics relating with arcs and dyads.
The number of nodes indicates how many individuals have been participating on
the population evolution. A degree ki of a node i is deﬁned as the number of nodes
connected with this node. For the undirected graphs, this measure is mathematically
deﬁned as follows:
ki = CD(i) =
g

j
aij ,
(3.4)
where aij is the element of the adjacency matrix deﬁned as 1 if the node i is connected
to the node j, and 0 otherwise [18].
In the case of the directed graphs, the node degree is deﬁned as the sum of two
parts, in-degree kin
i and out-degree kout
i
given by the following equation:
kin
i =

j
aji
kout
i
=

j
aij.
(3.5)
For weighted networks, the node strength si is deﬁned as
si =
g

j
wij ,
(3.6)
where wij is an element of a weighted adjacency matrix and wij > 0 if a node i
is connected to a node j. The value of wij represents the weight of the edge. For

3
Differential Evolution Dynamics Modeled by Social Networks
77
weighted oriented networks in-strength sin
i and out-strength sout
i
are deﬁned similarly
to in-degree and out-degree in oriented networks.
In social networks, the in-degree of a node is often denoted as the popularity, while
the out-degree is denoted as the activity of an actor in the population. The degree and
the density are the typical measurements of the cohesion in the network. The degree
centralization is then the normalized node-degree. To compare the node-degree of
the nodes from two networks with the different number of nodes it is necessary to
normalize the degree according to the following equation (for the directed networks):
kin
i =

j aji
g −1
kout
i
=

j aij
g −1 .
(3.7)
The density of the graph is a ratio of the number of edges in the network and the
number of all possible edges in the network.
The next investigated characteristic of the networks is the number of weakly
connected components. The directed graph is considered to be strongly connected if
there is a directed path between all pairs of nodes. The strongly connected component
in a directed graph is then a subgraph, where for each node i there is a directed path
to each node j. A directed path in the directed graph is the sequence of nodes and
directed arcs such that all directed arcs have the same direction and all nodes and
arcs are used only once. On the other hand, the weakly connected component of the
directed graph is a subgraph composed by the sequence of nodes and arcs such that
there is some path between each pair of nodes regardless the direction of the arcs [5].
Component ratio is then the number of weakly connected components minus one
and the number of nodes minus one. The fragmentation of the network is in UCINET
6.0 deﬁned as the proportion of pairs of node, which are unreachable.
The average distance is very often investigated in connection with the real-world
networks. The distance dij between two nodes i and j is the shortest path connecting
these two nodes. In other words, it is the number of edges along the shortest path
connecting these two nodes. The average path length L is then deﬁned as the mean
distance between two nodes, which is averaged over all pairs of nodes, see the
following equation:
L =
1
g(g −1)

i,j∈N ,i̸=j
dij .
(3.8)
The average path length is considered to be a measure of the typical separation
between two nodes in the graph. It has been shown that the most of the real world
networks have a relatively small average path length, even the networks containing
fewer edges than a typical globally coupled network containing an equal number
of nodes. This phenomenon is known as the “small-world effect” [53]. In UCINET
6.0, SD distance is mentioned in the cohesion analysis. SD distance is a standard
deviation of the geodesic distance amongst reachable pairs of nodes [2].

78
L. Skanderová and I. Zelinka
In the case of disconnected components in the graph, the average graph efﬁciency
is deﬁned as
E =
1
g(g −1)

i,j∈N ,i̸=j
1
dij
(3.9)
and it is a measure of the efﬁciency of the information exchange in the graph. This
efﬁciency is often denoted as the global efﬁciency Eglob. Beside the global efﬁciency
the local efﬁciency is deﬁned as the average efﬁciency of the local subgraphs, see
the following equation:
Eloc = 1
g

i∈V
E(Gi) ,
(3.10)
where Gi is the subgraph of the neighbors of the node i. The local efﬁciency of a node
i quantiﬁes how well the nodes are capable to exchange the information without the
node i [29]. Beside the average path length or efﬁciency, sometimes it is useful to
know the longest shortest path between two nodes in the graph – diameter.
In UCINET 6.0, the compactness is deﬁned as the mean of all reciprocated dis-
tances. The reciprocity will be also investigated in relation with the arcs and dyads.
We have mentioned above that in social networks, the dyads and triads are often ana-
lyzed. A dyad in a social network is composed by two actors and possible ties between
these actors while a triad consists of three actors and the possible ties between each
pair of actors in a triad. In the dyad analysis, we will investigate the dyads with
mutual ties, asymmetric ties, where there is a tie from an actor i to an actor j but not
from an actor j to an actor i. And ﬁnally, the number of null dyads will be analyzed.
The reciprocity in UCINET 6.0 can be arcs based and dyad based. The arc based
reciprocity is the number of reciprocated arcs divided by the total number of arcs,
while the dyad based reciprocity is the number of reciprocated dyads divided by the
number of adjacent dyads [2].
The last characteristic, which is analyzed in this experiment in connection with
cohesion, is clustering i.e. the tendency of the network to create tightly connected
neighborhoods, which can be measured by the clustering coefﬁcient ﬁrstly described
by Watts and Strogatz in [55]. The local clustering coefﬁcient of the node i of the
undirected graph G is deﬁned as follows:
ci =
2ei
ki(ki −1) =

j,m(aijajmami)
ki(ki −1)
,
(3.11)
where ei is the actual number of edges in Gi (the sub-graph of neighbors of the node
vi) and ki(ki −1) is a maximum possible number of the edges in Gi. The clustering
coefﬁcient of the graph G is then given by the following formula
C = 1
g
N

i=1
ci .
(3.12)

3
Differential Evolution Dynamics Modeled by Social Networks
79
Fig. 3.4 Four patterns of the triangle in directed graphs, [13]
In [13], Fagiolo deﬁnes for each pattern of the triangle in directed graph the
corresponding equation for the clustering coefﬁcient. Patterns are divided into four
categories: Cycle, Middleman, In, and Out, see Fig.3.4. The clustering coefﬁcient
of the node i in the pattern Cycle is deﬁned as follows:
Ccyc
i
=
(A)3
ii
din
i dout
i
−d↔
i
,
(3.13)
where A is the adjacency matrix, dtot
i
is the total degree of the node i and d↔
i
=

i̸=j aijaji = A2
ii. The second pattern of the triangle is the Middleman and the clus-
tering coefﬁcient is calculated according to the following equation:
Cmid
i
=
(AATA)ii
din
i dout
i
−d↔
i
.
(3.14)
The clustering coefﬁcients for patterns In and Out are deﬁned by Eqs. (3.15) and
(3.16), respectively.
Cin
i =
(ATA2)ii
din
i (din
i −1)
(3.15)
Cout
i
=
(A2AT)ii
dout
i
(dout
i
−1)
(3.16)
3.5.1.5
Experimental Results
The number of generations has been set to G = 3000, which means that for each
test function 3000 short-interval networks have been created. At the beginning of

80
L. Skanderová and I. Zelinka
the analysis, the graphs capturing the number of the new created offspring in each
generation of the DE algorithm have been created. In the case that the number of
individuals accepted to the next generation is small (below 10 per generation), the
short-interval network will be very small and such network is not valuable for this
experiment because the algorithm does not converges. This approach has eliminated
the number of the investigated networks. The DE/rand/1/bin is not very successful
to ﬁnd the global optimum of the difﬁcult test functions from the benchmark set
CEC 2013. For the purpose of the analysis of the short-interval networks created by
the dynamics of the DE algorithms, the results of the four test functions have been
used. We have analyzed the networks created by the DE algorithm, which has been
used to search for the global optimum of the unimodal test functions f1 and f5, the
multimodal test function f6, and the composition function f21.
We have selected 51 consecutive short-interval networks representing 51 consec-
utive generations for each test function. The networks have been selected on the
basis of the convergence of the algorithm. The networks created at the beginning of
the algorithm are not important for this analysis because at the beginning, the DE
algorithm usually produces more new individuals than in later generations. On the
other hand, at the end of the algorithm, if the most of individuals achieve the global
optimum, the most of trial vectors will be accepted to the next generation. These
two extreme cases will not be taken into consideration. In the case of the unimodal
test functions f1, f5 and multimodal test function f6, the SINs representing the gen-
erations 1501–1551 have been analyzed, see Fig.3.5a, b and c. For the composition
500
1000
1500
2000
2500
3000
5
10
15
20
25
30
500
1000
1500
2000
2500
3000
5
10
15
20
25
30
500
1000
1500
2000
2500
3000
5
10
15
20
25
500
1000
1500
2000
2500
3000
5
10
15
20
25
30
(a)
(b)
(c)
(d)
Fig. 3.5 Number of trial vectors accepted to the next generation. The x-axis represent the number
of generations, y-axis then the number of accepted trial vectors

3
Differential Evolution Dynamics Modeled by Social Networks
81
test function f21, the networks representing the generations 1001–1051 have been
selected, see Fig.3.5d.
3.5.1.6
Discussion and Conclusion
In Table3.1, the results of the selected characteristics relating with the cohesion in
networks are mentioned for the DE/rand/1/bin algorithm. As we can see, the networks
generated on the basis of the dynamics of the DE/rand/1/bin algorithm are very small.
In the case of the ﬁrst unimodal test function, the mean number of nodes is 44.588,
in the case of the multimodal test functions, the mean number of nodes is 46.157 and
34.275, respectively. And in the case of the composition function f28, it is 47.490.
This means that only about 48 individuals have been participating in the population
evolution. There are many unsuccessful combination of the parents. In other words,
the algorithm produces many bad solution vectors, which are not accepted to the
next generation. The networks are very sparse, see the mean density. The number
of components, components ratio and fragmentation of the network also indicate
that there is a small number of interconnections between the nodes representing
the individuals. The average degree is very small for all short-interval networks,
which means that the individuals are not very often used to activate more than one
target vector in one generation. In the case of the average distance, SD distance and
diameter, it is necessary to emphasize, that in the case that there is not any path from
a node i to a node j, the distance is set to be 0.
The characteristics Mutual, Asymmetric, and Null are focused on the dyad analy-
sis. We have mentioned that a dyad is composed by two nodes and the (possible) arcs
between these nodes. In the case that there is an arc from a node i to a node j and
from a node j to a node i the dyad is mutual. If there is an arc from a node i to a node
j, but there is not arc from a node j to a node i, the dyad is denoted as asymmetric.
And ﬁnally, in the case that there is no arc from a node i to a node j and from a
node j to a node i, the dyad is null dyad. The dyad as well as arc reciprocity in the
networks generated on the basis of the DE/rand/1/bin dynamics is very small. This
is not surprising because if the individual i is used to be an activator of the individual
j, the individual j will be hardly used to activate the individual i. It is possible only
in the case that the next two parents have signiﬁcantly better positions and they are
capable to produce the valuable mutation vector. The last analyzed characteristic is
the clustering coefﬁcient, which is also very small. We can say that the individuals
in the population of the DE algorithm do not tend to create tightly interconnected
groups.
3.5.2
Short-Interval Networks and Ranking Analysis
During the years, ranking has become a normal part of our life. It is nothing unusual
to divide people into some discrete groups – ranks. People can be divided into the

82
L. Skanderová and I. Zelinka
Table 3.1 The analysis of cohesion of the 51 short-interval networks created on the basis of the DE/rand/1/bin algorithm used to search for the global optimum
of the unimodal test functions f1, f5, multimodal test function f6, and composition function f21
f1
f5
Characteristic
Min
Max
Mean
Median
Stdev
Min
Max
Mean
Median
Stdev
Nodes
27
64
44.588
43
8.134
25
67
46.157
46
7.543
Avg. deg.
0.818
1.085
0.941
0.938
0.062
0.8
1.138
0.956
0.957
0.070
Deg. centr.
0.017
0.091
0.043
0.043
0.016
0.021
0.098
0.044
0.044
0.015
Out-centr.
0.017
0.089
0.042
0.043
0.015
0.020
0.094
0.043
0.043
0.014
Density
0.014
0.034
0.022
0.022
0.004
0.015
0.035
0.022
0.021
0.004
Components
27
64
44.431
43
8.063
25
66
46.000
46
7.448
Component rat.
0.935
1.000
0.997
1.000
0.012
0.93
1.000
0.997
1.000
0.011
Fragment.
0.932
0.982
0.969
0.970
0.009
0.931
0.980
0.969
0.971
0.009
Avg dist.
1.077
2.466
1.337
1.239
0.258
1.000
2.485
1.376
1.333
0.290
SD dist.
0.266
1.444
0.544
0.481
0.242
0.000
1.51
0.570
0.570
0.315
Diameter
2
6
2.725
2
0.961
1
7
2.902
3
1.204
Compact.
0.016
0.039
0.026
0.025
0.005
0.019
0.040
0.026
0.025
0.005
Mutual
0.000
0.001
0.000
0.000
0.000
0.000
0.001
0.000
0.000
0.000
Asymmetric
0.029
0.068
0.044
0.044
0.008
0.029
0.070
0.043
0.042
0.007
Null
0.932
0.971
0.955
0.956
0.008
0.930
0.971
0.957
0.958
0.007
Arc recipr.
0.000
0.042
0.002
0.000
0.009
0.000
0.042
0.004
0.000
0.011
Dyad recipr.
0.000
0.021
0.001
0.000
0.005
0.000
0.021
0.002
0.000
0.006
Cluster. coeff.
0.000
0.083
0.007
0.000
0.018
0.000
0.042
0.007
0.000
0.013
(continued)

3
Differential Evolution Dynamics Modeled by Social Networks
83
Table 3.1 (continued)
f6
f21
Characteristic
Min
Max
Mean
Median
Stdev
Min
Max
Mean
Median
Stdev
Nodes
15
53
34.275
34
8.398
28
63
47.490
46
7.417
Avg. deg.
0.778
1.019
0.917
0.923
0.058
0.833
1.220
0.983
0.981
0.076
Deg. centr.
0.009
0.118
0.047
0.045
0.019
0.021
0.083
0.047
0.047
0.015
Out-centr.
0.009
0.112
0.046
0.043
0.018
0.02
0.082
0.046
0.046
0.015
Density
0.019
0.057
0.029
0.028
0.008
0.017
0.032
0.022
0.022
0.003
Components
15
53
34.176
34
8.397
28
62
47.431
46
7.417
Component rat.
0.952
1
0.997
1.000
0.010
0.95
1.000
0.999
1.000
0.007
Fragment.
0.939
0.974
0.962
0.965
0.009
0.944
0.979
0.968
0.971
0.008
Avg dist.
1.000
1.689
1.259
1.25
0.176
1.000
2.49
1.419
1.324
0.309
SD dist.
0.000
0.910
0.447
0.433
0.217
0.000
1.509
0.623
0.554
0.299
Diameter
1
4
2.412
2
0.779
1
6
3.059
3
1.173
Compactness
0.024
0.057
0.033
0.031
0.008
0.019
0.036
0.026
0.025
0.004
Mutual
0.000
0.004
0.000
0.000
0.001
0.000
0.001
0.000
0.000
0.000
Asymmetric
0.038
0.114
0.058
0.055
0.015
0.033
0.063
0.043
0.043
0.006
Null
0.886
0.962
0.942
0.945
0.015
0.937
0.967
0.957
0.957
0.006
Arc recipr.
0.000
0.095
0.006
0.000
0.020
0.000
0.03
0.001
0.000
0.004
Dyad recipr.
0.000
0.05
0.003
0.000
0.010
0.000
0.015
0.000
0.000
0.002
Cluster. coeff.
0.000
0.090
0.010
0.000
0.020
0.000
0.050
0.010
0.000
0.010

84
L. Skanderová and I. Zelinka
Fig. 3.6 Illustration of the
representation of the positive
and negative relations
between actors [11]
groups according to their social status, education, work positions etc. For example,
in the employment, people occupy the different positions - boss, managers, secretary,
economists, workers etc. And it is usual that everybody in the employment knows
his supervisor. Generally, the ranking can be formal and informal. Formal ranking
use ofﬁcial symbols or insignias, for example army. The informal ranking is not
expressed by the ofﬁcial symbols, it is usually given by the opinions or feelings, for
example, in the school class, pupils can be divided according to their popularity. In
the social network analysis, the informal ranking is analyzed with the goal to assess
the positions to the actors. In the case that the formal ranking exists in the investigated
network, it is possible to compare the formal and informal ranking to observe the
deviations in the communication patterns [11].
As mentioned above, social networks can be represented by the directed or undi-
rected graph. Sometimes, the weighted edges are used to express the strength of
the relation between two individuals. The another way how to represent the social
network is the signed graph, where the positive relationships are represented by the
positive lines with the sign “+” and negative ones by the negative lines with the sign
“−”, see Fig.3.6. For example, in the case of the relationship “like”, the positive line
from a node i to a node j would mean that an actor i likes an actor j. The negative
line leading from a node i to a node j would then express that an actor i does not like
an actor j.
One of the most important characteristic of the signed networks relating with
ranking is its balance. The signed graph is considered to be balanced if all its closed
paths (cycles) are balanced, i.e. contain an even number of edges with the sign −. In
other words, a signed graph is balanced if it can be divided into two clusters such that
all ties within the clusters are positive and all ties between the clusters are negative.
The clusterability of a graph means that the graph can be divided into clusters (two
and more). The signed graph is clusterable if it is possible to divide it into clusters
such that positive ties are only between nodes within the same cluster and negative
ties are between nodes from different clusters.
In this work, the directed graphs are used instead of the signed graphs to model the
dynamics of the DE algorithm. To analyze the ranks in a simple directed network, the
dyadic analysis is replaced by the triadic analysis, which is based on the previously
mentioned balance theory, where the signed graph is clusterable, if it is possible
to divide it into the clusters such that the positive ties are within the graph and
the negative ties are between the clusters. In the simple directed graph, there is no
negative ties. To analyze the balance of such graphs, all absent ties are considered
to be negative. On the other hand, all present ties in the graph are considered to be

3
Differential Evolution Dynamics Modeled by Social Networks
85
positive. Becausetheabsent tiebetweentwonodes means thenegativetie, thepositive
ties between the nodes in the same cluster should be reciprocated [11]. Mutual ties
between two nodes (complete dyad) indicate the membership in the same group
while mutual absent ties between two nodes (null dyad) the membership in different
groups. The last kind of dyad is the asymmetric dyad, where there is a line from a
node i to a node j and the absent line from a node j to a node i. The asymmetric tie
between two nodes indicate the membership of the actors in different ranks.
In [11], sixteen types of triads and ﬁve models for the overall structure of a directed
network are described, see Fig.3.7 and Table3.2. In Fig.3.7, each triad is denoted by
three digits M-A-N and sometimes by a letter. The ﬁrst digit indicates the number
of mutual positive dyads, the second digit the number of asymmetric dyads, and the
third digit the number of null dyads. The letter then indicates the direction of the
asymmetric dyads – U for up, D for down, C for cyclic, and T for transitive.
In Table3.2, six balance-theoretic models are mentioned with their permitted
triads. A sign “+” means that for the given model all types of triads mentioned
for the previous model and the types of triads mentioned for the given model are
permitted. For example in the case of the model Clusterability, the triads 102, 300,
and 003 are permitted. In other words, each next model is less restrictive than the
previous one.
The Balance model can contain just two clusters and it is characterized by the
symmetric ties within a cluster and no ties between clusters. In the model Cluster-
ability, the number of triads is extended to three. Except the triad 102 and 300, the
triad 003 has been added, which means that the graph is not limited by the maximum
of the number of clusters as in the case in the Balance model. The model Ranked
Clusters has the same properties as the Clusterability model, moreover, the clusters
at different ranks are connected by the asymmetric dyads. Symmetric dyad indicates
that the nodes belong to the same cluster and null dyads occur in the case that the
nodes belong to the different clusters within the rank. In the case of the model Transi-
tivity, there are the symmetric ties within a cluster, no ties between clusters, maximal
number of clusters is not deﬁned, and null ties may occur between ranks. For the
Hierarchical Clusters the asymmetric dyads within a cluster are allowed if they are
acyclic [11]. The last mentioned model in Table3.2 contains so called forbidden
triads. These triads are incompatible with any of the above mentioned models. In the
case that these triads occur often in the network it is necessary to take into consider-
ation, whether the investigated data can be ranked according to the above mentioned
balance-theoretic principles [11].
3.5.2.1
Experiment
The motivation of this experiment is to investigate, which types of triads are created
on the basis of the DE algorithm dynamics. In the previous experiment, where some
network characteristics relating with the network cohesion are analyzed, it has been
shown that the algorithm DE/rand/1/bin create very small networks. We have also
concluded that the networks generated by the DE/rand/1/bin algorithm have very

86
L. Skanderová and I. Zelinka
Fig. 3.7 Sixteen types of triads. This ﬁgure has been taken from [11]
Table 3.2 Triad models and their permitted triads. This table is based on [11]
Model
Permitted triads
Balance
102, 300
Clusterability
+003
Ranked clusters
+021D, 021U, 030T, 120D, 120U
Transitivity
+012
Hierarchical clusters
+120C, 210
No-balance theoretic model (“Forbidden”)
021C, 111D, 111U, 030C, 201
small clustering coefﬁcient. On the basis of the principle of the SINs creation and the
previously mentioned results, we could anticipate that the DE algorithm will create
the certain kind of triad, for example 003, 012, 021D and 021U. In this experiment,
the numbers of all created triads will be mentioned and the triad model will be
assessed to the networks generated by the DE/rand/1/bin dynamics.
Four test functions from the benchmark set CEC 2013 have been selected on
the basis of the convergence results of the DE/rand/1/bin algorithm. We have used
the same test functions as in the previous experiment – two unimodal (f1, f5), one
multimodal (f6), and one composition (f21). For all test functions, 51 short-interval

3
Differential Evolution Dynamics Modeled by Social Networks
87
networks have been selected. The same networks, which have been investigated in
the previous experiment, are analyzed. For each SIN, the triad census is calculated.
At the end of the experiment, the SINs generated by the different DE variants are
classiﬁed by one of the above mentioned triad model.
3.5.2.2
Experimental Results
In Table3.3, the analysis of the triad census of the networks generated on the basis of
the DE/rand/1/bin algorithm is mentioned. For each kind of triad, minimal, maximal,
mean, median, and standard deviation of the number is mentioned. In Table3.4 the
triad ratio of all triads except the triad number 003 and 012 are mentioned. As well as
in the previous case, the minimum, maximum, mean, median, and standard deviation
of the triad ratio is mentioned.
3.5.3
Discussion and Conclusion
In Table3.3, the results for the networks generated on the basis of the dynamics of
the DE/rand/1/bin algorithm used to ﬁnd the global optimum of the four selected test
functions are mentioned. As we can see, the most frequently occurring triad is the
triad 003, in the case of the ﬁrst unimodal test function f1 it is in 88.23%, in the case
of the unimodal test function f5, 88.26% of all triads is the triad number 003. The
networks generated on the basis of the DE/rand/1/bin used to search for the global
optimum of the multimodal test function f6 have contained 85.61% of the triad 003,
and ﬁnally, in the case of the composition function f21, 88.18% of all triads was the
triad denoted as 003. The second most frequented kind of triad was the triad number
012–11.33% in the case of the unimodal test function f1, 11.30% in the networks
generated by the DE/rand/1/bin used to ﬁnd the global optimum of the unimodal
test function f5. In the case of the multimodal test function f6 and composition test
function f21, the triad 012 has occurred in 13.72% and 11.38%, respectively. The rest
of triads have been occurred sporadically.
With regard to the results mentioned in Table3.3, it is possible to assess the
triad model to the networks generated on the basis of the DE/rand/1/bin algorithm,
because the forbidden triads have occurred very sporadically in comparison with
the dominating triads. The model, which can be used to describe the triads of the
networks generated on the basis of the selected DE/rand/1/bin algorithm is the model
Transitivity, which is characterized by the symmetric ties within a cluster, no ties
between clusters, and null ties occurring between ranks. For this model, except the
triads 102, 300, 003, 021D, 021U, 030T, 120D, 120U, the triad 012 is typical. On
the basis of the results mentioned above, we can conclude that the triad 012 has been
the second most often occurring triad. The most frequented triad was the triad 003.
High occurrence of the triads 003 and 012 as well as some network characteristics
relating with the cohesion indicate very small density of the networks generated on

88
L. Skanderová and I. Zelinka
Table 3.3 The analysis of ranking of the 51 short-interval networks created on the basis of the DE/rand/1/bin algorithm used to search for the global optimum
of the unimodal test functions f1, f5, multimodal test function f6, and composition function f21
f1
f5
Triad
Min
Max
Mean
Median
Stdev
Min
Max
Mean
Median
Stdev
003
2356
38040
13448.569
10801
8137.293
1842.00
43783.00
14644.451
13511
7418.900
012
538
3544
1726.843
1581
691.413
433.00
3961.00
1874.706
1734
680.393
102
0
52
2.686
0
10.911
0.00
59.00
4.804
0
14.808
021D
1
18
8.588
8
4.07
2.00
25.00
10.000
9
4.678
021U
24
60
41.588
41
8.57
21.00
66.00
43.706
44
8.474
021C
3
33
13.157
12
7.768
0.00
45.00
14.020
14
8.950
111D
0
4
0.235
0
0.951
0.00
4.00
0.392
0
1.201
111U
0
1
0.020
0
0.14
0.00
2.00
0.078
0
0.392
030T
0
2
0.294
0
0.54
0.00
1.00
0.255
0
0.440
030C
0
1
0.020
0
0.14
0.00
0.00
0.000
0
0.000
201
0
0
0.000
0
0
0.00
0.00
0.000
0
0.000
120D
0
0
0.000
0
0
0.00
0.00
0.000
0
0.000
120U
0
0
0.000
0
0
0.00
0.00
0.000
0
0.000
120C
0
0
0.000
0
0
0.00
0.00
0.000
0
0.000
210
0
0
0.000
0
0
0.00
0.00
0.000
0
0.000
300
0
0
0.000
0
0
0.00
0.00
0.000
0
0.000
(continued)

3
Differential Evolution Dynamics Modeled by Social Networks
89
Table 3.3 (continued)
f6
f21
Triad
Min
Max
Mean
Median
Stdev
Min
Max
Mean
Median
Stdev
003
312
20770
6230.353
5069
4440.864
2394.00
35860
15524.000
13267
7751.066
012
130
2560
998.373
915
527.733
0.00
3802
2003.157
1949
782.667
102
0
36
2.784
0
8.853
0.00
56
1.412
0
8.112
021D
0
14
5.667
5
3.451
3.00
49
12.706
12
7.925
021U
12
52
31.137
30
8.908
10.00
70
45.647
46
10.530
021C
0
29
8.549
7
6.682
0.00
46
16.392
17
9.726
111D
0
4
0.392
0
1.201
0.00
4
0.078
0
0.560
111U
0
1
0.039
0
0.196
0.00
2
0.059
0
0.311
030T
0
2
0.176
0
0.478
0.00
2
0.471
0
0.644
030C
0
0
0.000
0
0
0.00
1
0.020
0
0.140
201
0
0
0.000
0
0
0.00
0
0.000
0
0.000
120D
0
0
0.000
0
0
0.00
0
0.000
0
0.000
120U
0
0
0.000
0
0
0.00
0
0.000
0
0.000
120C
0
0
0.000
0
0
0.00
0
0.000
0
0.000
210
0
0
0.000
0
0
0.00
0
0.000
0
0.000
300
0
0
0.000
0
0
0.00
0
0.000
0
0.000

90
L. Skanderová and I. Zelinka
Table 3.4 The analysis of ranking of the 51 short-interval networks created on the basis of the
DE/rand/1/bin algorithm used to ﬁnd the global optimum of the unimodal test functions f1, f5,
multimodal test function f6, and composition function f21. The triad ratio of all triads except the
triads number 003 and 012
f1
f5
Triad
Min
Max
Mean
Median
Stdev
Min
Max
Mean
Median
Stdev
102
0.000
0.357
0.021
0.000
0.083
0.000
0.407
0.035
0.000
0.109
021D
0.025
0.197
0.126
0.125
0.039
0.059
0.227
0.136
0.127
0.039
021U
0.364
0.818
0.658
0.672
0.105
0.368
0.923
0.640
0.639
0.125
021C
0.064
0.330
0.188
0.184
0.073
0.000
0.353
0.182
0.195
0.095
111D
0.000
0.035
0.002
0.000
0.007
0.000
0.037
0.003
0.000
0.009
111U
0.000
0.009
0.000
0.000
0.001
0.000
0.015
0.001
0.000
0.003
030T
0.000
0.050
0.005
0.000
0.010
0.000
0.020
0.003
0.000
0.006
030C
0.000
0.011
0.000
0.000
0.002
0.000
0.000
0.000
0.000
0.000
201
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
120D
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
120U
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
120C
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
210
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
300
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
f6
f21
102
0.000
0.436
0.038
0.000
0.118
0.000
0.331
0.011
0.000
0.054
021D
0.000
0.211
0.114
0.111
0.050
0.055
0.636
0.161
0.150
0.082
021U
0.373
0.947
0.679
0.682
0.129
0.130
0.857
0.621
0.632
0.114
021C
0.000
0.375
0.159
0.150
0.095
0.000
0.385
0.201
0.207
0.082
111D
0.000
0.093
0.006
0.000
0.019
0.000
0.024
0.000
0.000
0.003
111U
0.000
0.011
0.000
0.000
0.002
0.000
0.026
0.001
0.000
0.004
030T
0.000
0.038
0.003
0.000
0.009
0.000
0.024
0.006
0.000
0.008
030C
0.000
0.000
0.000
0.000
0.000
0.000
0.014
0.000
0.000
0.002
201
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
120D
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
120U
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
120C
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
210
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
300
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
the basis of the DE algorithms dynamics. However, we would like to know if the DE
algorithm tends to create (except the triads 003 and 012) the other types of triads
more often than the others. For this reason, in the following experiment the triads 003
and 012 have been neglected and triad census for the triads 102, 021D, 021U, 021C,
111D, and 111U, and 030T have been analyzed. The occurrence of the other types of
triads is occasional, therefore they have not be taken into consideration. To compare
the occurrences of the triads, the triad ratio for each type of the selected triads and

3
Differential Evolution Dynamics Modeled by Social Networks
91
each network generated by the DE algorithm has been calculated. On the basis of
the experimental results mentioned in Table 3.4 we have concluded that except the
triads 003 and 012, the triad 021U is the most frequently occurred triad. The next
relatively common triad is the triad number 021D and the forbidden triad 021C.
3.5.4
Aggregated Networks
Short-interval networks are capable to capture the state of the social network at
different points of time. In the case of the DE algorithm, each SIN represents one
generation. The cohesion analysis and the triad census analysis has shown some
important properties of the networks generated on the basis of the DE algorithm
dynamics. We have conﬁrmed that the DE/rand/1/bin version generates small net-
works with low density, average degree, compactness, and clustering coefﬁcient. On
the other hand, the component ratio as well as fragmentation were very high. Low
connectedness has been also conﬁrmed by the triad census analysis, where the dom-
inating triad was the triad number 003 – three separated nodes. All of these aspects
indicate that the number of individuals participating in the process of the population
evolution is very low as well as the number of new offspring, which is accepted to the
next generation. In the DE/rand/1/bin algorithm, the collaboration of the individuals
can be considered to be low.
In this subsection, the aggregated network generated on the basis of the dynam-
ics of the DE/rand/1/bin will be investigated. As mentioned above, the aggregated
network is considered to be an accumulation of all short-interval networks. In this
work, the aggregated network is composed by all SINs generated on the basis of
the DE/rand/1/bin algorithm such that the number of nodes reﬂects the number of
individuals, which have been ever used in the process of the population evolution.
In the case that the individual i has activated an individual j more than once during
the evolution process, the weight of the arc will correspond with the number of their
interactions. One weighted directed graph is created for the algorithm.
In such generated networks, the cohesion will be analyzed. The goal of this exper-
iment is to investigate, whether all individuals interact with each other during the
evolution process and whether there are some individuals, which have never been
used to create a mutation vector. In the second part of this experiment, the node
out-strength distribution will be investigated. From the principle of the networks
creation it is clear, that the out-strength of a node indicates, how often the individ-
ual represented by this node has been used to activate another individual during the
whole evolution process. In Sect.3.2, it is mentioned that the individuals are selected
randomly to activate a target vector (to create a mutation vectors), however, they are
not always successful. The node out-strength will indicate the success rate of the
activators (of the solution vectors to create a successful mutation vector).

92
L. Skanderová and I. Zelinka
3.5.4.1
Experiment
In this experiment, the settings of the DE algorithm is the same like in the previous
ones. The networks generated on the basis of the DE/rand/1/bin algorithm used to
search for the global optimum of two unimodal test functions f1, f5, multimodal
test function f6, and composition function f21 from the benchmark set CEC 2013
are analyzed. The aggregated networks are the uniﬁcation of the 3000 short-interval
networks. The analysis is focused on the cohesion and then on the node out-strength
distribution.
3.5.4.2
Experimental Results
In Table3.5, the cohesion analysis of four networks representing the dynamics of the
DE/rand/1/bin algorithm used to search for the global optimum of the test functions
f1, f5, f6, and f21 are mentioned. In Table3.6, the minimum, maximum, mean, median,
and standard deviation of the node out-strength are mentioned. In Fig.3.8a, b, c, and
d, the out-strength distribution is depicted.
Table 3.5 The cohesion analysis of the aggregated networks created on the basis of the
DE/rand/1/bin algorithm used to ﬁnd the global optimum of the unimodal test functions f1, f5,
multimodal test function f6, and composition function f21
f1
f5
f6
f21
Nodes
100
100
100
100
Avg. deg.
99.000
99.000
99.000
98.960
Deg. centr.
0.000
0.000
0.000
0.000
Out-centr.
0.000
0.000
0.000
0.000
Density
1.000
1.000
1.000
1.000
Components
1
1
1
1
Component rat.
0
0
0
0
Connected.
1
1
1
1
Fragment.
0
0
0
0
Avg dist.
1.000
1.000
1.000
1.000
SD dist.
0.000
0.000
0.000
0.020
Diameter
1
1
1
2
Mutual
1.000
1.000
1.000
0.999
Asymmetric
0.000
0.000
0.000
0.001
Null
0.000
0.000
0.000
0.000
Arc recipr.
1.000
1.000
1.000
1.000
Dyad recipr.
1.000
1.000
1.000
0.999
Weighted clust.
coeff.
15.716
13.589
12.232
8.810

3
Differential Evolution Dynamics Modeled by Social Networks
93
Table 3.6 The statistic analysis for the node-strength distribution for the aggregated networks
generated on the basis of the DE/rand/1/bin algorithm
Min
Max
Mean
Median
Stdev
f1
1452
1659
1555.86
1557.0
45.640
f5
1257
1474
1345.35
1343.5
49.708
f6
1104
1326
1211.01
1211.5
43.260
f21
757
999
872.22
869.5
47.997
1500
1550
1600
1650
0
5
10
15
20
1300
1350
1400
1450
1500
0
5
10
15
20
1100
1150
1200
1250
1300
0
5
10
15
20
800
850
900
950
1000
0
5
10
15
20
25
(a)
(b)
(d)
(c)
Fig.3.8 Nodeout-strengthdistribution.Thex-axisrepresentthestrengthofnode,y-axisthenumber
of nodes having the corresponding node out-strength
3.5.4.3
Discussion and Conclusion
As we can see in Table3.5, the number of nodes is 100 for all networks generated
on the basis of the DE/rand/1/bin algorithm, which means that all individuals have
been used to improve the population evolution. All network characteristics indicate
that the DE/rand/1/bin algorithm has generated the complete graphs. The weighted
clustering coefﬁcient is relatively small which conﬁrm the results of the cohesion
analysis of the short-interval networks, which indicates that the individuals of the
DE/rand/1/bin population do not tent to create tightly connected groups – clusters.
In Fig.3.8a, b, c, and d the node out-strength distribution of the networks generated
on the basis of the DE/rand/1/bin algorithm are depicted. The t-test has been used

94
L. Skanderová and I. Zelinka
to compare the node out-strength of the networks generated on the basis of the
DE algorithm used to ﬁnd out the global optimum of the different test functions
(each test function has been compared with each other). On the basis of the p-values
signiﬁcantly smaller than 0.05, we have concluded that the out-strength distribution
is different for each test functions. The highest values of the node out-strength have
been achieved in the case of the ﬁrst unimodal test function f1, see Table3.6. On the
other hand, the lowest node out-strength values have been measured in the case of the
test function f21. Considering the principle of the mutation generation – the solution
vectors are selected randomly with the uniform distribution – we can conclude that
the node-out strength reﬂects the number of individuals participating in the process of
the population evolution. The node out-strength distribution also relates with the DE
algorithm convergence. In the case of the ﬁrst unimodal test function, all individuals
have achieved the global optimum, which means that at the end of the algorithm,
the trial vectors with the same objective function value as the objective function
value of the target vector are accepted. This principle causes the incrementation of
the node-strength values. For this reason, the networks generated on the basis of the
DE algorithm used to search the global optimum of the test function f1 achieved the
highest values.
Many real-world networks have the degree distribution following a power law
and they are denoted as scale-free. In this work, we are aware that the networks
generated on the basis of the DE algorithms are limited by the small number of
individuals. Moreover, it would be useless to test the degree distribution because we
have conﬁrmed that the complete graphs have been generated. Nevertheless, we have
used the Shapiro Wilk test of normality to test the normality of the node out-strength
distribution. In the case of the test functions f1 (p-value = 0.774), f6 (p-value =
0.992) and f21 (p-value = 0.679) the null hypothesis, that the distribution of the node
out-strength follows the normal distribution, has been accepted. In the case of the
test function f5 (p-value = 0.037), it has been rejected.
3.5.5
Longitudinal Social Networks
In the previous sections, two principles of the network creation on the basis of the DE
algorithm have been discussed. The ﬁrst principle is based on so called short-interval
networks, where the social network is modeled by the set of the SINs reﬂecting the
state of the network at the different points of time, in our case, the state of the
individuals relationships in the consecutive generations. The second way, which has
been discussed, was the aggregated network, where for the DE algorithm, just one
weighted directed graph is generated.
The SNA of the short-interval networks has indicated some important aspects of
the individuals behavior. The SINs generated by the DE algorithm are very small and
they have a low density. The individuals in the population do not tend to create the
clusters. All these characteristics indicate that there is a small ratio of individuals,
which are participating in the process of the population evolution. The analysis of the

3
Differential Evolution Dynamics Modeled by Social Networks
95
aggregated network just conﬁrmed the results of the previous analysis of the SINs.
In this section, the representation of the DE dynamics by the longitudinal social
network will be discussed.
A LSN is composed by the different snapshots of a social network – SINs –
capturing the state of the social network at several points of time. The accumulation
of the SINs creates so called aggregated network. The main goal of the LSN analysis
is to explore changes in the network over a given time period [52]. In the case of
this work, where the SINs and aggregated networks are used to model the dynamics
of the social networks generated on the basis of the DE algorithm, it would seem,
that the analysis of the LSN has been done. However, according to Uddin et al. [52],
the dominant methods dealing with the analysis of the longitudinal social networks
are based on Markov models and multiagent simulation models, which have not
been discussed in this work yet. For this reason, the stochastic actor-based model
presented by Snijders et al. [48, 50], which is denoted in [28] as the most popular
parametrization, has been chosen to be used to analyze the LSN generated on the
basis of the DE algorithm.
The goal of this model is to represent network dynamics on the basis of the
observed longitudinal data and evaluate the data on the basis of the statistical infer-
ence paradigm. The model is capable to represent network dynamics as being driven
by many different tendencies, for example reciprocity, transitivity, homophily etc.
With the stochastic actor-based model it is possible to test hypothesis about these ten-
dencies and to estimate parameters describing their strengths. For more information,
please see [50].
3.5.5.1
Differential Evolution Dynamics and LSN
The short-interval networks for the LSN analysis by the stochastic actor-based model
have been crated on the basis of the different principle than the SINs in the ﬁrst exper-
iment. The main difference is the number of nodes, which is from the beginning of
the algorithm constant. For each generation, one SIN is generated such that all indi-
viduals are taken into consideration. The arcs are then created on the same principle
as described above meaning that in the case that the solution vectors have been used
to activate a target vector to move to a better position, the arcs leading from the
nodes representing the solution vectors to the node representing a target vector will
be created. Each SIN represents one generation. Each network contains the same
number of nodes, only arcs between them are changing.
3.5.5.2
Experiment
ThesettingsoftheDEalgorithmisthesameasinthecaseofthepreviousexperiments.
The LSNs generated on the basis of the DE algorithm used to search for the global
optimum of the four test functions- f1, f5. The number 5 is the index of f , f6, and
f21 from the benchmark set CEC 2013 are analyzed. For this experiment, 51 SINs

96
L. Skanderová and I. Zelinka
representing the same generations as in the case of the ﬁrst experiment have been
analyzed. To estimate the parameters of the LSN, the software RSiena (Siena in R
language) developed by Ripley, Boitmanis in collaboration with Snijders [41] has
been used.
3.5.5.3
Experimental Results
As mentioned 51 SINs represent 51 consecutive generations of the DE algorithm.
To calculate the distance between two consecutive networks, the Hamming distance
between these two networks is used, which indicate the changes in the LSN. The
RSiena for each two consecutive networks calculate the Jaccard distance between
the networks as follows:
N11
N01 + N10 + N11
,
(3.17)
where Nhk is the number of tie variables with value h in the ﬁrst network and value k
in the second one. More precisely, N11 is the number of ties present in both networks,
N10 is the number of ties newly created in the second network, and N01 is the number
of ties, which have been terminated in the second network. The Jaccard index is
considered to be a measure for stability. Only available data are taken into account
[49]. In [41] Jaccard index equal or greater than 0.3 is considered to be good. In the
case of the values lower than 0.2, the Jaccard index indicate that the estimation might
be problematic and values smaller than 0.1 are considered to be very low. In such
case, it is necessary to distinguish, why the Jaccard index achieves so low values.
For Siena method it is not problem to estimate the parameters in the case that the
low Jaccard coefﬁcient is caused by the increasing or decreasing number of ties or if
the networks are very sparse. However, in the case that the Jaccard indices are very
low and the average degree is nor increasing nor decreasing, the high turnover in
the network is indicated, which means that the data can not be considered to be an
evolving network and Siena method is not suitable [41].
3.5.5.4
Experimental Results and Discussion
In this experiment, 51 consecutive SINs representing 51 consecutive generations of
the DE algorithm used to search for the global optimum of the four test functions
f1, f5, f6, and f21 have been analyzed. For each two consecutive SINs, the Jaccard
index has been calculated according to the Eq. (3.17). For all test functions, the
Jaccard coefﬁcient has been signiﬁcantly smaller than 0.1. Considering the fact that
the average degree has been not increasing even nor decreasing in these networks, we
have concluded that there is very high turnover in the network and for this reason the
data can not be considered as the data of an evolving network. The stochastic actor-
based model then can not be used to estimate the strength of hypothetical tendencies
(reciprocity, transitivity, balance etc.) of the networks.

3
Differential Evolution Dynamics Modeled by Social Networks
97
3.6
Conclusion
In this chapter, representation of the differential evolution dynamics via social net-
works has been discussed. We have used three principles of the representation of the
social network. In the ﬁrst case, the short-interval networks with the different size
have been used, in the second one, the aggregated networks have been created, and
ﬁnally, in the third case, the longitudinal social network has been considered. On the
basis of the experiments, some conclusions have been made. The SINs generated
on the basis of the DE/rand/1/bin algorithm are very small. We have worked with
the population size 100 individuals and only about 50 individuals per generation
have been used to participate in the process of the population evolution. This can be
caused by two main aspects: diversity of the individuals is small and the settings of
the control parameters is not good (which can inﬂuence the small diversity of the
individuals). The SINs were very sparse. This indicates that there is a small number
of trial vectors accepted to the next generation and the number of solution vectors
used to activate more than one target vector is very small. We have also investigated
the reciprocity in arcs and dyads, which was also very small.
The analysis of the aggregated networks have conﬁrmed the results of the SINs
analysis. We have also analyzed the node out-strength distribution which was in the
three (f1, f6, f21) from four cases normal. The highest node out-strength has been
measured in the aggregated network generated by the DE algorithm dynamics used
to ﬁnd out the global optimum of the ﬁrst unimodal test function f1. On the other
hand the aggregated network generated on the basis of the DE algorithm dynamics
searching for the global optimum of the test function f21 has achieved the lowest
values of the node out-strength. It is given by the principle of the network creation as
well as the principle of the DE/rand/1/bin algorithm, where the trial vectors with the
objective function values not worse than a target vector objective function value are
accepted to the next generation. In three cases of the test functions, the aggregated
network has been represented by the complete graph.
The longitudinal social network has been created by the SIN representing the con-
secutive generations of the DE algorithm. Unlike in the case of the SIN in the ﬁrst
experiment, in the LSN network, the SINs have the constant number of nodes corre-
sponding with the number of individuals in the population. Because to analyze the
LSNs Markov models and multiagent simulation models are the dominant methods,
we have selected the stochastic actor-based model to analyze the LSNs generated on
the basis of the DE algorithm. This model has been selected to estimate the strength
of tendencies of the networks as reciprocity, transitivity, balance etc. However, on
the basis of the Jaccard indices, which were extremely low (lower than 0.1), and on
the basis of the SIN average degree, which is not increasing nor decreasing (which
could cause the small Jaccard index), we have concluded that the data used to create
the SINs can not be considered to be the data of the gradually evolving network. In
other words, there is a high turnover in the networks generated on the basis of the
DE/rand/1/bin dynamics and the representation of the dynamics of the DE algorithm

98
L. Skanderová and I. Zelinka
by the LSN is not suitable. Therefore, in the future work, the temporal networks will
be used to represent the dynamics of the DE algorithm dynamics.
Acknowledgements The following grants are acknowledged for the ﬁnancial support provided
to this research: Grant Agency of the Czech Republic - GACR P103/15/06700S, Grant of SGS
No. SGS 2016/175, VSB-Technical University of Ostrava. The Ministry of Education, Youth and
Sports from the National Programme of Sustainability (NPU II) project “IT4Innovations excellence
in science - LQ1602”.
References
1. Abbasi,A.,Chung,K.S.K.,Hossain,L.:Egocentricanalysisofco-authorshipnetworkstructure,
position and performance. Inf. Process. Manag. 48(4), 671–679 (2012)
2. Borgatti, S.P., Everett, M.G., Freeman, L.C.: Ucinet for Windows: Software for Social Network
Analysis (2002)
3. Breiger, R.L., Boorman, S.A., Arabie, P.: An algorithm for clustering relational data with
applications to social network analysis and comparison with multidimensional scaling. J. Math.
Psychol. 12(3), 328–383 (1975)
4. Brissette, I., Scheier, M.F., Carver, C.S.: The role of optimism in social network development,
coping, and psychological adjustment during a life transition. J. Person. Soc. Psychol. 82(1),
102 (2002)
5. Broder, A., Kumar, R., Maghoul, F., Raghavan, P., Rajagopalan, S., Stata, R., Tomkins, A.,
Wiener, J.: Graph structure in the web. Comput. Netw. 33(1), 309–320 (2000)
6. Carrington, P.J., Scott, J, Wasserman, S.: Models and Methods in Social Network Analysis,
vol. 28. Cambridge University Press, Cambridge (2005)
7. Centola, D.: The spread of behavior in an online social network experiment. Science 329(5996),
1194–1197 (2010)
8. Christakis, N.A., Fowler, J.H.: The spread of obesity in a large social network over 32 years.
New England J. Med. 357(4), 370–379 (2007)
9. Daly, E.M., Haahr, M.: Social network analysis for routing in disconnected delay-tolerant
manets. In: Proceedings of the 8th ACM International Symposium on Mobile ad Hoc Net-
working and Computing, pp. 32–40. ACM (2007)
10. Davendra, D., Zelinka, I., Senkerik, R., Pluhacek, M.: Complex network analysis of evolu-
tionary algorithms applied to combinatorial optimisation problem. In: Proceedings of the Fifth
International Conference on Innovations in Bio-Inspired Computing and Applications IBICA
2014, pp. 141–150. Springer, Berlin (2014)
11. De Nooy, W., Mrvar, A., Batagelj, V.: Exploratory Social Network Analysis with Pajek, vol. 27.
Cambridge University Press, Cambridge (2011)
12. Ellison, N.B., et al.: Social network sites: deﬁnition, history, and scholarship. J. Comput. Med.
Commun. 13(1), 210–230 (2007)
13. Fagiolo, G.: Clustering in complex directed networks. Phys. Rev. E 76(2), 026107 (2007)
14. Festinger, L., Back, K.W., Schachter, S.: Social Pressures in Informal Groups: A Study of
Human Factors in Housing. vol. 3. Stanford University Press (1950)
15. Fisher, D.: Using egocentric networks to understand communication. Int. Comput. IEEE 9(5),
20–28 (2005)
16. Forsyth, E., Katz, L.: A matrix approach to the analysis of sociometric data: preliminary report.
Sociometry 9(4), 340–347 (1946)
17. Fowler, J.H., Christakis, N.A.: Dynamic spread of happiness in a large social network: longi-
tudinal analysis over 20 years in the framingham heart study. Bmj, 337:a2338 (2008)
18. Freeman, L.C.: Centrality in social networks conceptual clariﬁcation. Soc. Netw. 1(3), 215–239
(1979)

3
Differential Evolution Dynamics Modeled by Social Networks
99
19. Granovetter, M.: The Strength of Weak Ties: A Network Theory Revisited. JSTOR (1981)
20. Granovetter, M.S.: The strength of weak ties. Am. J. Sociol. 1360–1380 (1973)
21. Hanneman, R.A., Riddle, M.: Introduction to Social Network Methods (2005)
22. Harary, F., Norman, R.Z.: Graph Theory as a Mathematical Model in Social Science (1953)
23. Haythornthwaite, C.: Social network analysis: an approach and technique for the study of
information exchange. Libr. Inf. Sci. Res. 18(4), 323–342 (1996)
24. Hite, J.M., Hesterly, W.S.: The evolution of ﬁrm networks: from emergence to early growth of
the ﬁrm. Strategic Manag. J. 22(3), 275–286 (2001)
25. Janostik, J., Pluhacek, M., Senkerik, R., Zelinka, I.: Particle swarm optimizer with diversity
measure based on swarm representation in complex network. In: Proceedings of the Second
International Afro-European Conference for Industrial Advancement AECIA 2015, pp. 561–
569. Springer, Berlin (2016)
26. Janostik, J., Pluhacek, M., Senkerik, R., Zelinka, I., Spacek, F.: Capturing inner dynamics of
ﬁreﬂy algorithm in complex network initial study. In: Proceedings of the Second International
Afro-European Conference for Industrial Advancement AECIA 2015, pp. 571–577. Springer,
Berlin (2016)
27. Jansson, O.: Using Social Network Analysis as a Tool to Create and Compare Mental Models
(2015)
28. Krivitsky, P.N., Handcock, M.S.: A separable model for dynamic networks. J. R. Stat. Soc. Ser.
B (Stat. Methodol.) 76(1):29–46 (2014)
29. Latora, V., Marchiori, M.: Efﬁcient behavior of small-world networks. Phys. Rev. Lett. 87(19),
198701 (2001)
30. Laumann, E.O., Knoke, D.: The Organizational State: Social Choice in National Policy
Domains. University of Wisconsin Press (1987)
31. Laumann, E.O., Pappi, U.: Networks of Collective Actions. New York (1976)
32. Law, J., Hassard, J.: Actor Network Theory and after (1999)
33. Liang, J.J., Qu, B.Y., Suganthan, P.N., Hernández-Díaz, A.G.: Problem deﬁnitions and eval-
uation criteria for the CEC: special session on real-parameter optimization. Computational
Intelligence Laboratory, Zhengzhou University, Zhengzhou, China and Nanyang Technologi-
cal University, Singapore, Technical Report 201212, 2013 (2013)
34. Lin, N., Bian, Y.: Getting ahead in urban China. Am. J. Sociol. 657–688 (1991)
35. Luce, R.D., Perry, A.D.: A method of matrix analysis of group structure. Psychometrika 14(2),
95–116 (1949)
36. Mallipeddi, R., Suganthan, P.N., Pan, Q-K., Tasgetiren, M.F.: Differential evolution algorithm
with ensemble of parameters and mutation strategies. Appl. Soft Comput. 11(2), 1679–1696
(2011)
37. Moreno, J.I.: Who Shall Survive, vol. 58. JSTOR (1934)
38. Morrison, E.W.: Newcomers’ relationships: the role of social network ties during socialization.
Acad. Manag. J. 45(6), 1149–1160 (2002)
39. Perry-Smith, J.E., Shalley, C.E.: The social side of creativity: a static and dynamic social
network perspective. Acad. Manag. Rev. 28(1), 89–106 (2003)
40. Pluhacek, M., Janostik, J., Senkerik, R., Zelinka, I., Davendra, D.: Pso as complex network
capturing the inner dynamics initial study. In: Proceedings of the Second International Afro-
European Conference for Industrial Advancement AECIA 2015, pp. 551–559. Springer, Berlin
(2016)
41. Ripley, R.M., Snijders, T.A.B., Preciado, P. et al.: Manual for RSIENA, vol. 1. University of
Oxford, Department of Statistics, Nufﬁeld College (2011)
42. Romney, K.A., Faust, K.: Predicting the structure of a communications network from recalled
data. Soc. Netw. 4(4), 285–304 (1982)
43. Scott, J.: Social Network Analysis. Sage (2012)
44. Shin, H., Ryan, A.M.: Early adolescent friendships and academic adjustment: examining selec-
tion and inﬂuence processes with longitudinal social network analysis. Develop. Psychol.
50(11), 2462 (2014)

100
L. Skanderová and I. Zelinka
45. Sijtsema, J.J., Ojanen, T., Veenstra, R., Lindenberg, S., Hawley, P.H., Little, T.D.: Forms and
functions of aggression in adolescent friendship selection and inﬂuence: a longitudinal social
network analysis. Soc. Develop. 19(3), 515–534 (2010)
46. Simpkins, S.D., Schaefer, D.R., Price, C.D., Vest, A.E.: Adolescent friendships, BMI, and phys-
ical activity: untangling selection and inﬂuence through longitudinal social network analysis.
J. Res. Adolesc. 23(3), 537–549 (2013)
47. Skanderova, L., Fabian, T.: Differential evolution dynamics analysis by complex networks.
Soft Comput. 1–15 (2015)
48. Snijders, T.A.B.: Models for longitudinal network data. Models Methods Soc. Netw. Anal. 1,
215–247 (2005)
49. Snijders, T.A.B., Steglich, C.E.G., van de Bunt, G.G.: Introduction to actor-based models for
network dynamics. Soc. Netw. (2008)
50. Snijders, T.A.B., Van de Bunt, G.G., Steglich, C.E.G.: Introduction to stochastic actor-based
models for network dynamics. Soc. Netw. 32(1), 44–60 (2010)
51. Storn, R., Price, K.: Differential Evolution-a Simple and Efﬁcient Adaptive Scheme for Global
Optimization Over Continuous Spaces, vol. 3. ICSI, Berkeley (1995)
52. Uddin, S., Khan, A., Piraveenan, M.: A set of measures to quantify the dynamicity of longitu-
dinal social networks. Complexity (2015)
53. Wang, X.F., Chen, G.: Complex networks: small-world, scale-free and beyond. IEEE Circuits
and Syst. Mag. 3(1), 6–20 (2003)
54. Wasserman, S., Faust, K.: Social Network Analysis: Methods and Applications, vol. 8. Cam-
bridge University Press, Cambridge (1994)
55. Watts, D.J., Strogatz. S.H.: Collective dynamics of small-world networks. Nature 393(6684),
440–442 (1998)
56. Zelinka, I., Davendra, D.D., Senkerik, R., Jasek, R.: Do evolutionary algorithm dynamics create
complex network structures? In: Proceedings of the 12th WSEAS International Conference on
Communications (2011)
57. Zelinka, I., Davendra, D., Skanderova, L.: Visualization of complex networks dynamics: case
study. In: Networking 2012 Workshops, pp. 145–150. Springer, Berlin (2012)

Chapter 4
Conversion of SOMA Algorithm
into Complex Networks
Lukáš Tomaszek and Ivan Zelinka
Abstract In this chapter we describe possibility how to create complex network
from SOMA algorithm and we describe what this network represents according to
algorithm. Also we look at the visualization of such networks and show basic global
complex network properties and how they look during the time.
4.1
Introduction
Evolutionary computation is a sub-discipline of computer science belonging to the
bio-inspired computing area. The main ideas of evolutionary computation have
been published [1] and widely introduced to the scientiﬁc community [5, 6]. The
most known evolutionary techniques are Genetic Algorithms (GA) introduced by
J. Holland [5, 6] based on ideas of A.M Turing [10] and based on ﬁrst computer
experiments by Barricelli in [2], Evolutionary Strategies (ES) by Schwefel [9] and
Rechenberg [8] and Evolutionary Programming (EP) by Fogel [4] for example.
4.2
Motivation
In our research, we attempt to convert the dynamics of evolution algorithm into a
complex network. The complex network then could be analyzed and gives us some
feedback. According to this feedback, we can attempt to improve the algorithm. The
whole process is captured in Fig.4.1.
L. Tomaszek (B) · I. Zelinka
Faculty of Electrical Engineering and Computer Science,
Department of Computer Science, VŠB – Technical University of Ostrava,
17. listopadu 15, 708 33 Ostrava-Poruba, Czech Republic
e-mail: lukas.tomaszek@vsb.cz
I. Zelinka
e-mail: ivan.zelinka@vsb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_4
101

102
L. Tomaszek and I. Zelinka
Fig. 4.1 Motivation
In this chapter, we focus on the phase of conversion from evolutionary algorithm
to the complex network. We show several options how to convert run of SOMA
algorithm into a complex network, and we will show how the networks look like.
How many edges networks have, how strong are the bonds between vertices and how
the network changes during the whole algorithm will be demonstrated.
In next two chapters, we will show some basic analysis of these networks, and we
will show how to improve the whole algorithm according to given complex network
properties.
4.3
Global Complex Network Properties
4.3.1
Average Network Strength
Strength Si of node i we count as a sum of weights of edges connected with this node
(4.1).
Si =
|V|

j
wij.
(4.1)
The average network strength is then given by the average of all strength of all
nodes (4.2).
Savg =
|V|
i
Si
|V|
(4.2)
4.3.2
Network Density
Network density shows how dense the network is. In other words how many edges
there are in the network compared to the maximum possible number of edges (4.3).

4
Conversion of SOMA Algorithm into Complex Networks
103
Fig. 4.2 Shifted and rotated
Rastrigins function
If the network is a complete graph, then the density equals to 1 and if the network
does not have any edge than the density equals to 0.
D =
|E|
|V| · (|V| −1)
(4.3)
4.4
Parameters and Cost Functions
During this experiment we use one run of CEC Benchmark function number 4. This
function is also known as Shifted and Rotated Rastrigins Function. This function
can be seen in Fig.4.2. For more information about this function please look at [7].
We set up parameters as follows: Dimension = 50, PathLength = 3.0, Step = 0.3,
PopSize = 50, PRT = 0.2, Migrations = 200.
4.5
SOMA Algorithm
SOMA is a stochastic optimization algorithm that is modeled based on the social
behavior of competitive-cooperating individuals [3, 11]. Before starting this algo-
rithm, we need to know cost function and parameters for a run. Parameters are shown
in Table4.1.
The run of algorithm starts with creating the starting population. This popula-
tion is randomly distributed over searching space. Then we commence migrating

104
L. Tomaszek and I. Zelinka
Table 4.1 SOMA parameters
Parameter name
Recommended range
Remark
PathLength
[1.1, 5]
Controlling parameter
Step
[0.11, PathLength]
Controlling parameter
PRT
[0, 1]
Controlling parameter
Dimension
Given by problem
Number of arguments in cost function
PopSize
[10, up to user]
Controlling parameter
Migrations
[10, up to user]
Stopping parameter
loops. In each migrating loop we ﬁrst select Leader. The Leader is the best individ-
ual (the individual with best cost value). After Leader is selected, each individual
jumps towards him according to (4.4), where xML+1
i,j
is value of ith individual’s jth
parameter in step t in migrating loop ML + 1. xML
i,j,start is value of ith individual’s jth
parameter staring position in actual migration loop. xML
L,j is the value of Leader’s jth
parameter in the actual migrating loop. t is a step from 0 by Step to PathLength.
PRTVector is a vector of ones and zeros depending on PRT. If the random number
is less than PRT then in PRTVector will be 1 otherwise 0.
xML+1
i,j
= xML
i,j,start + (xML
L,j −xML
i,j,start) t PRTVectorj
(4.4)
Each individual remembers all positions and value of cost function reached on this
position and after all jumps returns to the best position. Migrating loops are repeated
until we reached maximum number of migration loops or maximum number of
evaluations.
WecanseepseudocodeofSOMAalgorithmonAlgorithm1.Formoreinformation
about this algorithm please read [3, 11].
Input:
x: the initial randomly generated population
Controlling parameters
fcost: cost function (ﬁtness function)
begin
Evaluate initial population migrationCycle = 0
while numberOfEvaluation < Migrations do
Selection of the best individual - Leader while j ≤PopSize do
Selection of jth individual calculate fcost of the new positions save the best
solution of the jth individual on its trajectory in a new population
end
end
end
Algorithm 1: SOMA, strategy AllToOne

4
Conversion of SOMA Algorithm into Complex Networks
105
4.6
Complex Networks Created by Adding Edges
Construction of networks is described in a few levels. The ﬁrst level is really simple.
We just add an oriented edge from Leader l to individual i with timestamp ML if
jumping individual after all jumps, in migrating loop ML, reach better ﬁtness than is
the ﬁtness of Leader.
With this level, we get temporal complex network with ML windows. Some win-
dows equal to some migrating loops. Networks look like on Fig.4.3.
We can see that in each migrating loop (window), we create several edges from
Leader to some individuals. In next window one of these individuals becomes a
Leader and we also create several edges to some individuals. This temporal network
could be analyzed, or we can convert it to a static network.
We can create a static network from the temporal network as a merge of all
windows in the temporal network. In this case, there could be some edges, which are
in several windows. The count of occurrence of selected edge could be represented
as the weight of this edge. So if some edge occurs in ML windows, the weight of this
edge will be ML. Such network can look like in Fig.4.4.
In this example of network, the weights of the edges are represented by the size of
the edge. Higher weights are represented by thicker lines with bigger arrows. Lower
weights are represented by thinner edges with smaller arrows. In this example, we
Fig. 4.3 Windows for dynamical complex network for migrating loop number 1–6

106
L. Tomaszek and I. Zelinka
Fig. 4.4 Static network after
all migrating loop
can see that there is one very signiﬁcant edge. These two individuals (vertices), which
are connected by this edge, interact with each other very often and in many times
improve themselves. Also, we can see several vertices, which are not connected to
each other. These individuals did not improve the Leader and did not become Leaders.
Individuals sometimes improve Leader, but in a lot of cases they do not, and these
movements are not included into this network. In the next level, we also include
adverse changes in algorithm into a complex network.
4.7
Probabilistic Complex Networks
In SOMA algorithm we can reach three different types of movement.
• Improvement. In this type of movement individual improves Leader. After all
jumps individual reaches a position with better ﬁtness than the ﬁtness of Leader.
• Movement. In this type of movement, individual improves itself, but after all,
jumps its ﬁtness is worse than the ﬁtness of the Leader.
• Stagnation. In this last type of movement individual after all jump returns to the
starting position, so the individual does not move. The individual does not improve
Leader and does not improve itself.
In this level, we count a number of each type of move between two individuals.
Then we can create three different complex networks, each for one type of move, or
one for all moves.

4
Conversion of SOMA Algorithm into Complex Networks
107
Fig. 4.5 Improvement network
For three different complex networks the weight of edge wi,j from vertex i to
vertex j is given as some selected move SM when individual i jumps toward individ-
ual j divided by some migrating loops (4.5). In each network weight of edges then
represents the probability of selected move. The value of an edge is between 0 and
1.
wi,j =
NSM
i,j
|Migrations|
(4.5)
In Fig.4.5, we can see networks for improvement move. Network after 200 loops
is the same as the network with ﬁrst adding a level. The difference is only in edges
weights. In the ﬁrst level, there were integer weights. In this level, there are edges
with real values between 0 and 1. Real values between 0 and 1 offer us to study more
complex network properties without some conversion.
In these networks, we can also see, that during the time density is growing, but
the strength of edges is getting weaker. After 10 migrating loops the graph has few
very strong edges, but also there are a lot of vertices with degree equal to 0. After
100 migrating loops, the graph has more edges, but the strength of these edges is
signiﬁcantly lower according to graph after 10 loops. Still, there are several vertices,
which are not connected to each other. After 200 loops the network has many very
weak edges, and still, we can ﬁnd several vertices with degree equal to 0.
On Fig.4.6, we can see networks for movement. These networks are really dense
and during the time edges are weaker and weaker.
In the last Fig.4.7, we can see networks for stagnation. After 10 migrating loops
network has only one edge, but after 100 migrating loops algorithm created a dense
network. The network is denser, and the edges are stronger during its time develop-
ment.
Till now we just visualize the networks. Now lets look at the evolution of density
and strength during the whole algorithm. In Fig.4.8 we can see strength and density
of network in each migrating loop. Purple color represents move stagnation, green
color represents the movement, and blue color represents an improvement.

108
L. Tomaszek and I. Zelinka
(a) After 10 migrating loops (b) After 100 migrating loops (c) After 200 migrating loops
Fig. 4.6 Movement network
(a) After 10 migrating loops
(b) After 100 migrating loops
(c) After 200 migrating loops
Fig. 4.7 Stagnation network
Fig. 4.8 Properties for probabilistic complex network
We can see, that for stagnation in ﬁrst few migrating loops density and strength
is 0. So every individual moves or improves the Leader. Around migrating loop
number 20, both properties start growing. This means that during the migrating
loops the probability of ﬁnding better position decreases, so many individuals return
to the starting position and do not move. Improvement and movement create opposite

4
Conversion of SOMA Algorithm into Complex Networks
109
(a) After 10 migrating loops
(b) After 100 migrating loops (c) After 200 migrating loops
Fig. 4.9 Probabilistic network
process. In ﬁrst few migrating loops density is growing and the strength is high. Many
individuals have low ﬁtness, so the probability of ﬁnding a new better position with
better ﬁtness is high. During the time individuals have better ﬁtness, so the probability
decreases. Also the strength is falling, and density grows only a little.
As we wrote before, we can create three networks, each for one type of move
or we can create one network for all moves. If we want to create only one complex
network, the weight of edges will be a combination of all three types of move. We
can count weight according to Eq.(4.6). In this equation, the weight is given as some
improvements minus number of stagnation plus number of movements multiply by
constant k. This constant determines the weight we associate with the movement.
wi,j =
NI
i,j −NS
i,j + k · NM
i,j
|Migrations|
, k = < 0; 1 >
(4.6)
We can see a visualization of networks in Fig.4.9. Similarly, as for three networks
you can see networks after 10, 100 and 200 migrating loops. In this visualization
weights of edges are represented by color. Red colors represent positive weights,
blue colors represent negative weights, and yellow color represents values around 0.
After 10 migrating loops, all edges are red, so there is a lot of positive edges. After
100 and 200 migrating loops, red edges disappear, and all edges are yellow or blue,
so their weights are negative or somewhere around the value of 0.
Also, we can see strength and density for this network, Fig.4.10. On a plot with
strength there are 4 different curves each for different k. The purple one is for k
equal to 0.1; the green one is for k equal to 0.3, the blue one is for k equal to 0.5 and
orange is for k equal to 0.7. As we can see constant k does not change the shape of
curve only the maximum and minimum strength. On each curve, the strength is ﬁrst
few loops positive and does not change. Around migrating loop number 20 strength
starts falling and at the end of 200 migrating loops the strength is negative around
the value of −0.5. So in algorithm, this curve indicates, that from the beginning there
is a lot of positive changes, in the middle the strength starts falling, so there are less
positive interactions, and there are also some negative interactions, and at the end,
there is a lot of negative interactions and only a few positive ones.

110
L. Tomaszek and I. Zelinka
(a) Strength
(b) Density
Fig. 4.10 Properties for probabilistic complex network
We describe the second level based on probabilistic. We can create three networks,
each for one type of movement or we can create one network, where weights are a
combination of each type of movement. We show how the networks look like after
10, 100 and 200 migrating loops and show the strength and density of each network
during the whole algorithm.
This level could also be improved. The ﬁrst option is to use weighted probability
so that the last few migrating loops will be more important in the network than older
ones. So for example weight for move improvement, we can count according to (4.7).
wi,j =
|MigratingLoop|
ML=1

ML · NI
i,j(ML)

|MigratingLoop|
ML=1
ML
(4.7)
So weight wi,j between vertex i and vertex j is given as a sum of improvements
between individual i and individual j in migrating loop ML multiple by weight ML
divided by the sum of weights. This means that improvement in migrating loop ML
has weight ML, after each migrating loop the weight is increasing.
During the jumping, the individuals make several steps and evaluate cost value
in several different positions, so second possible improvement of this level could be
to involve every position into the equation. Thus during jumping, we do not have an
only summarization of travel but have more information about the move. Whether
there is only one improvement or whether there are several improvements and only
one was selected.
4.8
Complex Networks Inspired by Ant Swarm
Till now we count only positive interactions or moves, but we did not focus on the
size of improvement. The last level involves the size of improvement and is inspired
by ACO. When ants travel, they release pheromones. The further distance they travel,
more pheromones they release. The wind then vaporizes pheromones during the time.

4
Conversion of SOMA Algorithm into Complex Networks
111
Number of released pheromones RP in given according to distance d and we have
several options. We can say that number of released pheromones will be linear (4.8),
so the number of released pheromones is the same as distance. Second logarith-
mic (4.9) option changes the pheromones. It attenuates signiﬁcant improvements.
The last conversion of distance to pheromones is experimental. In this hyperbolic
equation (4.10) we can get a negative number of pheromones, so it means, that ants
not only release pheromones but also collect pheromones or release some negative
pheromones.
RPLin = d
(4.8)
RPLog = ln(d + 1)
(4.9)
RPHyp = tanh(d −1)
(4.10)
We can also create an exponential equation for releasing pheromones which
emphasize signiﬁcant improvement like (4.11), but as we can see the global strength
was high, so we do not include results and networks for this exponential level in this
chapter.
RPExp = ed −1
(4.11)
The last thing in this level is vaporization. In this case, we remove n percent of
all pheromones after each migrating loop.
Weights of edges in the complex network are given by pheromones, so the weight
of the edge between vertex i and vertex j is given as a sum of pheromones when
individual i travels to individual j minus vaporization after each migrating loop. Such
networks will be dense. In each migrating loop we add some value to popSize −1
edges, so when each individual becomes a Leader at least once, the network creates
a complete graph.
In Fig.4.11 you can see networks for linear distribution of pheromones after 10,
100 and 200 migrating loops. Edges with bigger weight are thicker. We can see
that after 10 migration loops there is one very strong edge. This edge represents the
fact that between these two vertices (individuals) there was very strong interaction
or interactions. Also, there are some a little bit weaker edges. After 100 migrating
loops, there are several stronger edges, but they are not as strong as after 10 migrating
loops. At the end of the algorithm, we can see one very strong edge similarly as after
10 migrating loops. It means that even at the end of an algorithm has to be at least
one improvement of a Leader.
We can also see networks for logarithmic distribution of pheromones, Fig.4.12. It
looks similar to networks for linear distribution, but stronger interactions are attenu-
ate, also at the end of the algorithm, after 200 migrating loops, we can see one strong
edge.
For the last level of pheromones distribution, we can see the network in Fig.4.13.
In this case, edges can be negative or positive, so the weight is represented by colors.
Red color represents the positive weights; blue color represents the negative edges
and edges with weight around 0 are represented by yellow color. After 10 migrating

112
L. Tomaszek and I. Zelinka
(a) After 10 migrating loops
(b) After 100 migrating loops
(c) After 200 migrating loops
Fig. 4.11 Complex network inspired by ants - linear
(a) After 10 migrating loops
(b) After 100 migrating loops (c) After 200 migrating loops
Fig. 4.12 Complex network inspired by ants - logarithmic
(a) After 10 migrating loops
(b) After 100 migrating loops
(c) After 200 migrating loops
Fig. 4.13 Complex network inspired by ants - hyperbolic
loops in the graph there are several positive edges, but there is also a lot of negative
edges, so there were some improvements of Leader, but also there were many negative
interactions between individuals. After 100 and 200 migrating loops there are only
negative edges and edges with a value around the value of 0, so there was a lot of
negative interactions and only a little or none positive interactions.
Similarly, as for probabilistic networks, we show how strength and density look
during the time. Plots can be seen in Fig.4.14. Strength has tree different curves. Each

4
Conversion of SOMA Algorithm into Complex Networks
113
(a) Strength
(b) Density
Fig. 4.14 Properties for complex network inspired by ants
for one type of pheromones distribution. Purple curve represents a linear distribution,
green logarithmic and blue hyperbolic. Density is for all levels the same.
This ant level can also be improved or changed. For instance, we can remove
edges from the network, when this weight is lesser than some value (for example
10−3), so we can say, that the pheromones have been vaporized and none remain.
In this improvement, the weight will represent the time, in other words how long
the edge will be visible. After this, we can analyze network as a static non-weighted
network.
Another possibility is to use different functions for conversion from a distance to
some released pheromones. Also, we can use some function for vaporization and not
remove any percentage.
4.9
Conclusion
In this chapter, we describe three possibilities how to convert SOMA algorithm into
a complex network. The ﬁrst case is very simple, we just add an edge between two
nodes, if there is an improvement of Leader. This network is temporal but can be
converted to a static net. The second level extends the ﬁrst one. We can create three
different networks for moves called improvement, movement, and stagnation or we
can create only one network. This network is weighted, and weight represents the
probability that the selected move will happen. The last level is based on ants. This
level captures the strength of interactions.
All three levels can be analyzed and may give us some feedback about the algo-
rithm. In this chapter, we mostly focus on global properties and how the network
looks like. We show strength and density for all levels. We show how these proper-
ties evolve during the whole algorithm. In probabilistic networks, strength is getting
weaker for movement and improvement and getting stronger for a move called stag-
nation. It is logical because during the time algorithm has a lower probability to

114
L. Tomaszek and I. Zelinka
ﬁnd a better solution, so more often individuals return to starting position. In ant
level, the strength ﬁrst sharply grows and then starts falling and stays around value
0, but in visualization, we saw one very signiﬁcant edge after 200 migrating loops.
Also, this shape of the curve is logical. Similarly, in the beginning, there was a lot of
strong improvements, so the strength sharply grew, but at the time there was a lower
probability to move or improve Leader, so the pheromones started to vaporize, and
strength started falling.
Also, we recommended some improvements to adjust or change presented levels,
to reach different results. In the probabilistic level, we can use weighted probability
so that latest migrating loops will have a bigger inﬂuence on the network, or we can
count each evaluation into probability not only summarize all steps of one individual.
In ant level, we can use different conversion of distance to some released pheromones
or add some equation for vaporization.
Acknowledgements The following grants are acknowledged for the ﬁnancial support provided to
this research: Grant Agency of the Czech Republic – GACR P103/15/06700S Grant of SGS No.
SGS 2017/134, VSB-Technical University of Ostrava The Ministry of Education, Youth and Sports
from the National Programme of Sustainability (NPU II) project “IT4Innovations excellence in
science - LQ1602”.
References
1. Back, T., Fogel, B., Michalewicz, Z.: Handbook of Evolutionary Computation. Institute of
Physics, London (1997)
2. Barricelli, N.: Esempi numerici di processi di evoluzione. Methodos. 45–68 (1954)
3. Davendra, D., Zelinka, I.: Self-Organizing Migrating Algorithm Methodology and Implemen-
tation. Springer, Berlin (2016) (in print)
4. Fogel, G., Corne, D.: Evolutionary Computation in Bioinformatics. Bioinformatics Artiﬁcial
Intelligence. Morgan Kaufmann, San Francisco (2003)
5. Holland, J.H.: Adaptation in Natural and Artiﬁcial Systems. The University of Michigan Press,
Ann Arbor (1975)
6. Holland, J.H.: Adaptation in Natural and Artiﬁcial Systems: An Introductory Analysis with
Applications to Biology, Control and Artiﬁcial Intelligence. MIT Press, Cambridge (1992)
7. Liang, J.J., Qu, B.Y., Suganthan, P.N., Chen, Q.: Problem deﬁnitions and evaluation criteria
for the cec 2015 competition on learning-based real-parameter single objective optimization.
Technical Report 201411A, Computational Intelligence Laboratory, Zhengzhou University,
Zhengzhou China and Technical Report, Nanyang Technological University, Singapore (2014)
8. Rechenberg, I.: Evolutionsstrategie: optimierung technischer systeme nach prinzipien der biol-
ogischen evolution. Frommann-Holzboog (1973)
9. Schwefel, H.P.: Numerische Optimierung von Computer-Modellen mittels der Evolution-
sstrategie. ISR, vol. 26. Birkhaeuser, Basel (1977)
10. Turing, A.M.: Intelligent machinery, unpublished report for national physical laboratory (1975)
11. Zelinka, I.: SOMA - self organizing migrating algorithm. In: Onwubolu, G.C., Babu, B. (eds.)
New Optimization Techniques in Engineering, pp. 167–218. Springer, New York (2004). ISBN
3-540- 20167X

Chapter 5
Analysis of SOMA Algorithm
Using Complex Network
Lukáš Tomaszek and Ivan Zelinka
Abstract In this chapter, that is a continuation of the previous one; we show some
basic complex network analysis of SOMA algorithm on selected cost functions. The
interesting facts, which can be used to improve the algorithm, are discussed here.
Also, comparison of different runs of SOMA algorithm on the same test functions is
presented here.
5.1
Introduction
As already mentioned in the previous chapter; evolutionary computation is a sub-
discipline of computer science belonging to the bio-inspired computing area. The
main ideas of evolutionary computation have been published [2] and widely intro-
duced to the scientiﬁc community [7, 8]. The most well known evolutionary tech-
niques are Genetic Algorithms (GA) introduced by J. Holland [7, 8] based on ideas
of A.M Turing [16] and based on ﬁrst computer experiments by Barricelli in [3], Evo-
lutionary Strategies (ES) by Schwefel [15] and Rechenberg [12] and Evolutionary
Programming (EP) by Fogel [5] for example. One of the main interest of researchers
is to improve algorithm performance, as various papers [1, 4, 9, 10, 13] shows. For
these reasons are used various techniques and test problems. Here, topic sketched
in the previous chapter is more discussed and investigated. In the previous chapter,
SOMA algorithm has been converted to the network. How such network can be
analyzed and what information one can expect, is discussed here.
L. Tomaszek (B) · I. Zelinka
Faculty of Electrical Engineering and Computer Science, Department of Computer Science,
VŠB – Technical University of Ostrava, 17. listopadu 15,
708 33 Ostrava-Poruba, Czech Republic
e-mail: lukas.tomaszek@vsb.cz
I. Zelinka
e-mail: ivan.zelinka@vsb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_5
115

116
L. Tomaszek and I. Zelinka
Fig. 5.1 Motivation
5.2
Motivation
In this research, a conversion of the evolution algorithm dynamics into a complex
network is the main topic. The complex network can be then analyzed and gives
some feedback. According to this feedback, algorithm performance can be improved.
Whole process is captured in Fig.5.1.
In the previous chapter, the ﬁrst phase, how to convert SOMA algorithm into a
complex network has been discussed, and algorithm in the previous chapter has been
introduced. In this chapter, we will focus on the analysis of complex networks (cre-
ated by ant colony optimization algorithm principles) for logarithmic pheromones
distribution presented in previous chapter.
We will attempt to analyze networks ﬁrst as unweighted and then as weighted.
For analysis, we used our code and tool called NetworkX [6]. To ensure that the
networks are not only growing, but we will also assume, that an edge exists if its
weight is bigger than 0.001. However, in such networks edge can also disappear, so
the density of a graph can also decrease.
First, we will focus on networks without weights. In this analysis, the weights of
edges determine the time of how long the edge exist. We will concentrate on basic
properties like degree and clustering coefﬁcient. Then we attempt to analyze same
data but as a weighted network. For weighted networks, we will focus on properties
strength and weighted clustering coefﬁcient.
5.3
Cost Functions and Parameters
During the next experiment we run three selected CEC benchmark functions (namely
Rotated Cigar Function, Shifted and Rotated Rastrigin’s Function and Composi-
tion Function 1). First one is unimodal, second one is multimodal and third one is

5
Analysis of SOMA Algorithm Using Complex Network
117
Fig. 5.2 Rotated cigar
function
Fig. 5.3 Shifted and rotated
Rastrigin’s function
composition function composed by 3 different functions. All function we can see in
Figs.5.2, 5.3 and 5.4. For more details about functions please look at [11].
We run each function twice to get 2 different runs of algorithm to see different
property evolution and we set up parameters as follows: Dim = 100, PathLength =
3, Step = 0.3, PopSize = 100, PRT = 0.3, MigratingLoops = 1000 and we set up
searching space [−500, 500]D.

118
L. Tomaszek and I. Zelinka
Fig. 5.4 Composition
function 1
5.4
Degree
One of the basic properties of complex networks is degree. The degree of vertex V
determines the number of connections the node has with other nodes. In directed
graphs, we differentiate In-degree and out a degree. In-degree, the sum represents
incoming edges. Out-degree represents edges leaving given node.
In SOMA algorithm In-degree represents how much the individuals were able to
improve Leaders, so the higher In-degree represents the individuals, which were able
to improve many Leaders or were able to ﬁnd a better solution during the jumping
procedure (search process). Lower degree then represents the fact that selected indi-
vidual returns to starting position or makes only small improvements according to
Leader many times.
In Fig.5.5 is In-degree for selected functions. The plot is given as heat map (or
better CML plot, see the ﬁrst chapter), so color represents the value of In-degree for
each individual in each migrating loop.
Cigar Function is an unimodal function. We can see that In-degree during ﬁrst 700
(respectively 800 for the second run) migrating loops is between value 20 and 60. So
in this interval individuals travel and also improve the Leader. After this range for the
ﬁrst run, In-degree falls, and In-degree for all individuals is around 0, so algorithm
stops working and individuals travel only a little. For the second run we can also see
fall off In-degree, but in this case, it is not as signiﬁcant as in the ﬁrst run. In this
case, there are more improvements, and they are stronger compared to the ﬁrst run,
but there are weaker according to ﬁrst 800 migrating loops.
The second function called Rastrigin’s function is a multimodal function. In this
plots around migrating loop number 80, we can see horizontal black lines. For the
ﬁrst run, there are lot small lines, and for second run we can see two very long

5
Analysis of SOMA Algorithm Using Complex Network
119
(a) Cigar Function run No. 1
(b) Cigar Function run No. 2
(c) Rastrigin’s Function run No. 1
(d) Rastrigin’s Function run No. 2
(e) Composition Function 1 run No. 1
(f) Composition Function 1 run No. 2
Fig. 5.5 In-degree for CEC functions during migrating loops
lines. These lines indicate degree equal to 0, so these individuals do not move, they
always return to starting position, they are stuck in some local extreme. Between
migrating loops, 550–650 In-degree falls and it ﬂuctuates around the value of 0 for
all individuals, so the algorithm stops. For the ﬁrst run after this fall degree grows
around loop number 700 to value around 20. Some movements of individuals cause
it. These movements are not so signiﬁcant compared to the previous run, and after
few loops, degree falls again.

120
L. Tomaszek and I. Zelinka
(a) Cigar Function run No. 1
(b) Cigar Function run No. 2
(c) Rastrigin’s Function run No. 1
(d) Rastrigin’s Function run No. 2
(e) Composition Function 1 run No. 1
(f) Composition Function 1 run No. 2
Fig. 5.6 Out-degree for CEC functions during migrating loops
The last function is composition function. We can see, that this function runs for
ﬁrst 250, respectively 150 migrating loops. Until now the degree was in the range
between 20 and 60, so individuals were very active. After this interval, the degree
falls, and it is around value 0, so there are only a few movements and improvements.
Similarly, as In-degree we can see Out-degree in Fig.5.6 for all selected functions.
Out-degree in SOMA algorithm represents how strong the Leader was. Also how
many individuals the Leader has improved.

5
Analysis of SOMA Algorithm Using Complex Network
121
As we can see for Cigar function, Leaders were very strong. Until migrating loop
number 700, respectively 800, Out-degree is high for many individuals. After the
individuals reached migrating loop 700, for run No. 1, Out-degree falls. Leaders
were not able to improve individuals; there were only a few improvements. For run
two the situation is a little bit different. When individuals reached migrating loop
number 800, Out-degree also falls, but in this case, Leaders were able to improve
some individuals, but the number of improvements is signiﬁcantly lower than during
the ﬁrst 800 loops, but this number is higher according to run No. 1 on the same
function. If we compare it with In-degree, we can state that here are some individuals,
which can improve, but there are also some individuals, that always return to starting
position.
We can divide Out-degree of Rastrigin’s function into 4 phases. In the ﬁrst phase,
up to migrating loop number 100, there are several individuals with high Out-degree
and lot of individuals with low Out-degree, so several individuals were Leaders and
help almost all individuals to improve. After migrating loop 100, Out-degree falls a
little and during next several migrating loops keeps between values of 60 and 80. For
the ﬁrst run, this second phase is bigger; the degree is lower for more migrating loops
than for run number two. This is also observable in the In-degree, there were many
individuals, that were not improved. In the third phase, Out-degree is high for many
nodes. Leaders were able to improve all individuals. In the last phase, the Out-degree
falls and is low. Around migrating loop 700 for the run No. 1, Out-degree grows for
few individuals, but after several loops fall again. In these several loops, we can see
that for 5 individuals degree is around maximal value, so these individuals were able
to improve the whole population.
Out-degree for last selected function (Composition function) is high in ﬁrst 300
migrating loops, respectively 150 migrating loops, but then falls and we can see
that Out-degree grows till the end only for several individuals and always for few
migrating loops. When we observe Out-degree in the ﬁrst run, in the end, we can
see 2 interrupted blue lines. This may indicate that those two individuals improved
themselves. They changed their Leadership.
5.5
Clustering Coefﬁcient
Clustering coefﬁcient represents the probability that neighbors of selected nodes are
also connected with edge. Clustering coefﬁcient of node n can be count according to
(5.1). |E(G1(n))| represents number of edges among nodes in 1-neighbourhood of
node n and deg represents degree of selected node. If degree of node n is equals to 0
or 1, then CC(n) = 0.
CC(n) =
2 |E(G1(n))|
deg(n) · (deg(n) −1)
(5.1)

122
L. Tomaszek and I. Zelinka
(a) Cigar Function run No. 1
(b) Cigar Function run No. 2
(c) Rastrigin’s Function run No. 1
(d) Rastrigin’s Function run No. 2
(e) Composition Function 1 run No. 1
(f) Composition Function 1 run No. 2
Fig. 5.7 Clustering coefﬁcient for CEC functions during migrating loops
In these experiments we look at the network as a undirected graph, so we do not
have regard to the orientation of the edge, so all edges are without direction.
In the optimal run of SOMA algorithm selected Leader always improves all indi-
viduals so that clustering coefﬁcient will be 1 for all individuals. So if the clustering
coefﬁcient is lower than 1 it signals that some Leader improved more individuals
than another. Clustering coefﬁcient for all selected functions can be seen in Fig.5.7.
As we can see clustering coefﬁcient for Cigar function is high during ﬁrst 700,
respectively 800 migrating loops. During these migrating loops also In-degree and
Out-degree were high. After this interval clustering coefﬁcient for the ﬁrst run falls

5
Analysis of SOMA Algorithm Using Complex Network
123
to 0 and only for few nodes stays higher, but for a second run there are several nodes
with clustering coefﬁcient equal to 0, but also many individuals with really high
clustering coefﬁcient. During this period In-degree and Out-degree were lower, but
clustering coefﬁcient is still high. Only for several nodes equal zero. It means that
algorithm does not stop, it only cannot improve the whole population, just some
individuals. Thus In-degree and also Out-degree are lower, but clustering coefﬁcient
is high, so there are many triangles in the network.
Clustering coefﬁcient for Rastrigin’s function copies In-degree property. Simi-
larly, we can see different behavior in ﬁrst 150 migrating loops, and also we can
see black lines, which indicate degree equals to zero, and also clustering coefﬁcient
equals to zero. In the ﬁrst run of the algorithm, we can also see how clustering coefﬁ-
cient grows around migrating loop number 650 and around migrating loop 750 falls
to 0. This property in this part ﬂuctuates around the value of 0.5 for all the individ-
uals, so there were some interactions, but these interactions were between different
pairs of individuals. These interactions do not create many triangles in the network
according to previous run or end of the second run on Cigar function.
For last Composition functions ﬁrst 250 migrating loops the clustering coefﬁcient
is high for all individuals. After this interval, only a few nodes have clustering greater
than zero. We can see here a yellow column around migrating loop number 500 for
run No. 1 or around loop 450 and 550 for run No. 2. This column most likely
indicates that two individuals positively interact with the same individuals. Also, we
can see here some red values, so clustering coefﬁcient equals to 0.5. This indicates
interactions between two individuals, but they do not create triangles in the graph,
so there were interactions between different pairs of individuals.
5.6
Strength
Until now we have worked with networks without weights. Now we look at similar
properties, but as networks with weights. One of the core properties of weighted
networks is a strength. It is based on degree, but In-strength, we do not count the
number of edges connected to a selected node. We sum the weight of edges connected
to selected node. Similarly, we distinguish In-strength and Out-strength. In-strength
represents the sum of weights directed to selected node and Out-strength represents
the sum of weight directed from selected node.
In following Fig.5.8 we can see In-strength for selected functions. In-strength in
SOMA algorithm represents how much the individuals were able to improve their
value during jumps towards the Leader. If In-strength is high, it means that individual
improves itself signiﬁcantly and a position, with cost value better than the cost value
of the Leader, was located.
If we look at In-strength for Cigar function, again we can see, that ﬁrst 700,
respectively 800 migrating loops the algorithm works. After this interval for run, 1
algorithm is In-strength similarly as the degree falls, but we can observe few small
blue dots of In-strength after migrating loop number 700. These dots represent some

124
L. Tomaszek and I. Zelinka
(a) Cigar Function run No. 1
(b) Cigar Function run No. 2
(c) Rastrigin’s Function run No. 1
(d) Rastrigin’s Function run No. 2
(e) Composition Function 1 run No. 1
(f) Composition Function 1 run No. 2
Fig. 5.8 In-strength for CEC functions during migrating loops
improvement in the algorithm, so the algorithm does not stop completely, there are
some improvements, but only a few and little. In run two we can see, that there are
some improvements after migrating loop number 800. Some are strong, but there are
also some individuals whose In-strength equals 0. These individuals have stopped
moving.
For Rastrigin’s function we can say, that ﬁrst 50 migrating loop the strength is low
ﬂuctuating around a value of 2. After loop number 50 we can see black lines again
because that many individuals did not move. For run number 1 there is a lot of them

5
Analysis of SOMA Algorithm Using Complex Network
125
(a) Cigar Function run No. 1
(b) Cigar Function run No. 2
(c) Rastrigin’s Function run No. 1
(d) Rastrigin’s Function run No. 2
(e) Composition Function 1 run No. 1
(f) Composition Function 1 run No. 2
Fig. 5.9 Out-strength for CEC functions during migrating loops
and several repeats after some migrating loops. For run number 2 lines are shorter, but
for 2 individuals it keeps In-strength on 0 during the almost whole algorithm. After
migrating loop number 500, In-strength falls and grows only for several windows
for run number 1.
For last function we can see, that In-strength is high ﬁrst 200 loops respectively
100 loops. After this interval, the In-strength is around the value of 0 and grows only
little for several individuals.
In all functions, we can see some yellow dots. These dots represent very signiﬁ-
cant improvements. Also, we know that In-strength comprises red vertical lines. For

126
L. Tomaszek and I. Zelinka
instance in run No. 1 on Cigar function around loop 300 or for run No. 2 around
loop 550. These lines indicate strong interactions during the whole population, so
during these windows, the population signiﬁcantly improves its cost value. These
yellow dots and red vertical lines are very beneﬁcial for the algorithm. With such
improvements, the whole algorithm works well.
Similarly, as the Out-degree, we can see Out-strength in Fig.5.9. It represents the
strength of Leaders, in other words, how much the Leaders were able to improve
individuals in the population.
As we can see in the heat map of Out-strength, it is mostly composed of dots.
Most signiﬁcant interactions are represented by yellow dots, less important by red
dots and others by blue dots. Therefore yellow dots represent that selected Leader
improved many individuals and it improved them signiﬁcantly.
Also, we can see where the Leaders improve other individuals the most. For
Cigar function, most improvements are made till migrating loop number 700, for
Rastrigin’s function most improvements can be found between loop 100 and 600
and for Composition function from the beginning of algorithm till migrating loop
number 200.
5.7
Weighted Clustering Coefﬁcient
Last weighted property in this chapter is the weighted clustering coefﬁcient [14].
Weighted clustering coefﬁcient is given as a geometric average of weights of edges.
We can count it according to (5.2). The symbol w represents weight between two
nodes and deg represents the degree of selected node. All weights are normalized by
the edge with the highest value.
CCw(n) =
1
deg(n) · (deg(n) −1))

nm
( ˆwnm ˆwnl ˆwml)
1
3
(5.2)
We suppose that the graph is undirected similarly as during classical clustering
coefﬁcient, edges are without orientation and its weight is given as a sum of both
oriented edges. Also if the degree of some node equals 0 or 1 than CCw is equal to
0.
We can see results for weighted clustering coefﬁcient in Fig.5.10.
As one can see, the weighted clustering coefﬁcient is signiﬁcantly lower during the
whole algorithm run for all individuals compared to classical clustering coefﬁcient.
Many individuals reached maximal value around 0.5, and there are only one or two
individuals who reached value 1 of weighted clustering coefﬁcient for few windows.
This value of 1 is represented by a small yellow dot in the heat map. For example,
we can ﬁnd it around migrating loop 800 for run No. 1 on Cigar function.
If we look closely at a heat map of Cigar function, we can see that weighted
clustering coefﬁcient ﬂuctuates around value 0 at the beginning. Classical clustering

5
Analysis of SOMA Algorithm Using Complex Network
127
(a) Cigar Function run No. 1
(b) Cigar Function run No. 2
(c) Rastrigin’s Function run No. 1
(d) Rastrigin’s Function run No. 2
(e) Composition Function 1 run No. 1
(f) Composition Function 1 run No. 2
Fig. 5.10 Weighted clustering coefﬁcient for CEC functions during migrating loops
coefﬁcient has signiﬁcantly higher values. Also here we can see how algorithm slows
down after migrating loop 700 for the ﬁrst run and changes behavior around migrating
loop 900 for the second run.
In Rastrigin’s function, we can see that weighted clustering coefﬁcient is low
from the beginning. For many individuals, it is equal to 0. During the run, it reaches
maximal value around 0.5, but only for few individuals. Also here we can see how
the algorithm stops after loop number 600 and starts working only for run No. 1 for
few windows.

128
L. Tomaszek and I. Zelinka
Weighted clustering coefﬁcient for the last function stays low for many individu-
als. In the ﬁrst 200 loops, it reaches maximal value about 0.2, and many individuals
have weighted clustering coefﬁcient 0. After loop 200 all individuals have weighted
clustering coefﬁcient value 0, and only for some individuals this value grows for few
loops.
5.8
Conclusion
In this chapter, we attempt to make some basic analysis of complex networks given
from SOMA algorithm. We show results of selected complex network properties ﬁrst
as unweighted network and then as a weighted network.
We mostly focus on basic properties, and we attempt to describe differences
between different functions and runs. However, also other than presented properties
can be used, or we can use different conversion as outlined in the previous chapter.
We show different properties on 3 selected functions and for 2 different runs.
We describe differences between functions and also between the various runs on the
same function. According to such analysis, we can get some more information about
the algorithm and how the algorithm works on various test functions. Moreover, we
can attempt to improve the whole algorithm with the help of such analysis.
Acknowledgements The following grants are acknowledged for the ﬁnancial support provided to
this research: Grant Agency of the Czech Republic – GACR P103/15/06700S Grant of No. SGS
2017/134, VSB-Technical University of Ostrava The Ministry of Education, Youth and Sports from
the National Programme of Sustainability (NPU II) project “IT4Innovations excellence in science
- LQ1602”.
References
1. Angeline, P.J.: Evolutionary optimization versus particle swarm optimization: Philosophy and
performance differences. In: Evolutionary programming VII, pp. 601–610. Springer, Berlin
(1998)
2. Back, T., Fogel, B., Michalewicz, Z.: Handbook of Evolutionary Computation. Institute of
Physics, London (1997)
3. Barricelli, N.: Esempi numerici di processi di evoluzione. Methodos. 45–68 (1954)
4. Caponetto, R., Fortuna, L., Fazzino, S., Xibilia, M.G.: Chaotic sequences to improve the per-
formance of evolutionary algorithms. IEEE Trans. Evol. Comput. 7(3), 289–304 (2003)
5. Fogel, G., Corne, D.: Evolutionary Computation in Bioinformatics. Bioinformatics Artiﬁcial
Intelligence. Morgan Kaufmann, San Francisco (2003)
6. Hagberg, A., Schult, D., Swart, P.: Network library developed at the Los Alamos national
laboratory labs library (DOE) by the University of California
7. Holland, J.H.: Adaptation in Natural and Artiﬁcial Systems. The University of Michigan Press,
Ann Arbor (1975)
8. Holland, J.H.: Adaptation in Natural and Artiﬁcial Systems: An Introductory Analysis with
Applications to Biology, Control and Artiﬁcial Intelligence. MIT Press, Cambridge (1992)

5
Analysis of SOMA Algorithm Using Complex Network
129
9. Karaboga, D., Basturk, B.: On the performance of artiﬁcial bee colony (ABC) algorithm. Appl.
soft comput. 8(1), 687–697 (2008)
10. Khare, V., Yao, X., Deb, K.: Performance scaling of multi-objective evolutionary algorithms.
In: International Conference on Evolutionary Multi-Criterion Optimization, pp. 376–390.
Springer, Berlin (2003)
11. Liang, J.J., Qu, B.Y., Suganthan, P.N., Chen, Q.: Problem deﬁnitions and evaluation criteria
for the cec 2015 competition on learning-based real-parameter single objective optimization.
Technical Report 201411A, Computational Intelligence Laboratory, Zhengzhou University,
Zhengzhou China and Technical Report, Nanyang Technological University, Singapore (2014)
12. Rechenberg, I.: Evolutionsstrategie: optimierung technischer systeme nach prinzipien der biol-
ogischen evolution. Frommann-Holzboog (1973)
13. Salomon, R.: Re-evaluating genetic algorithm performance under coordinate rotation of bench-
mark functions. a survey of some theoretical and practical aspects of genetic algorithms.
BioSystems 39(3), 263–278 (1996)
14. Saramäki, J., Kivelä, M., Onnela, J.P., Kaski, K., Kertesz, J.: Generalizations of the clustering
coefﬁcient to weighted complex networks. Phys. Rev. E 75(2), 027105 (2007)
15. Schwefel, H.P.: Numerische Optimierung von Computer-Modellen mittels der Evolution-
sstrategie. ISR, vol. 26. Birkhaeuser, Basel (1977)
16. Turing, A.M.: Intelligent machinery, unpublished report for national physical laboratory (1975)

Chapter 6
Improvement of SOMA Algorithm
Using Complex Networks
Lukáš Tomaszek and Ivan Zelinka
Abstract In this chapter, we focus on improvement of SOMA algorithm based on
the previous analysis. We show some possibilities how to improve SOMA algorithm
according to complex network analysis. At the end of the chapter, we show the best
possible option how to improve standard SOMA algorithm together with results of
a statistical test. Proposed improvements can be made (in principle) on arbitrary
algorithm, SOMA here is used only for demonstrative purposes.
6.1
Introduction
In the previous chapter, has been discussed the conversion of the SOMA algorithm
into a complex network, then its visualization as the heat map/CML system and
reviewed SOMA behavior on those maps. Here will be debated, how and how much
can be SOMA performance improved with that information. In fact, presented ideas
and methodologies can be used for any evolutionary algorithm, which is worldwide
used, as used and presented in [1–9]. Information from the complex network can be
analyzed and can be used as a feedback for algorithm improvement. According to
this feedback, we can try to improve the algorithm. The whole process is captured
in Fig.6.1.
InpreviouschaptersandwedescribepossibilitieshowtoconvertSOMAalgorithm
into a complex network. We also introduced SOMA algorithm in Sect. 4.5. We
show how such a network looks like and we also show some basic analyses. In this
L. Tomaszek (B) · I. Zelinka
Faculty of Electrical Engineering and Computer Science, Department of Computer Science,
VŠB – Technical University of Ostrava, 17. listopadu 15,
708 33 Ostrava-Poruba, Czech Republic
e-mail: lukas.tomaszek@vsb.cz
I. Zelinka
e-mail: ivan.zelinka@vsb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_6
131

132
L. Tomaszek and I. Zelinka
Fig. 6.1 Motivation
chapter, we focus on the last phase - how to improve SOMA algorithm. Some of
ideas presented here, are partially reported in [10–12].
6.2
Cost Functions
In this chapter we used CEC benchmark functions. Basic description can be seen
in Table6.1. For each function we set up searching range [−100, 100]D. For more
details, please look at [6].
Table 6.1 CEC 2015 benchmark functions
Type
No.
Description
Unimodal functions
CF1
Rotated high conditioned elliptic function
CF2
Rotated bent cigar function
Simple multimodal functions
CF3
Shifted and rotated ackleys function
CF4
Shifted and rotated rastrigins function
CF5
Shifted and rotated schwefels function
Hybrid functions
CF6
Hybrid function 1 (N = 3)
CF7
Hybrid function 2 (N = 4)
CF8
Hybrid function 3 (N = 5)
Composition functions
CF9
Composition function 1 (N = 3)
CF10
Composition function 2 (N = 3)
CF11
Composition function 3 (N = 5)
CF12
Composition function 4 (N = 5)
CF13
Composition function 5 (N = 5)
CF14
Composition function 6 (N = 7)
CF15
Composition function 7 (N = 10)

6
Improvement of SOMA Algorithm Using Complex Networks
133
6.3
Possibilities of Improvement
According to complex network analysis, we can state that one individual has some
better or worse properties than other or we can divide individuals into groups accord-
ing to some measures. It is also possible to say that some network is better or worse
than other. According to this, we have several options how to improve the algorithm.
• Change leader. In basic SOMA algorithm, we select the leader as an individual
with the best ﬁtness. When we have a complex network which describes SOMA
algorithm, we can count a property and say that the leader will be the individual
with the highest value of such property.
• Remove some individuals. Another option how to improve the algorithm is to
remove some individuals according to the analysis. Therefore we run several loops
of classical SOMA algorithm, afterward we ﬁgure out that some individuals have
worse properties than others, so we remove them and continue with a limited
population.
• Replace individuals. This improvement is similar to the previous one, but we
do not remove the individuals, we replace them. So we run SOMA algorithm for
several loops, then instead of removing the worst individuals we replace them with
new ones, and we hope they will be of a better quality.
• Change parameters. The last possible improvement which we describe here is
a change of parameters during the algorithm run according to analysis. We can
observe that networks during the algorithm run change, thus using this change we
can tune the parameters.
6.4
SOMA Complex Network
For improvement of the classical SOMA algorithm, we used the second option. After
several loops (time frame, windows), we remove some individuals. In this case, we
ﬁgure out that size of the connected component is low, and many individuals do not
improve leader or never become a leader. So in other words, there are many nodes
in the network which are not connected to each other, and their degree equals 0.
We create complex network according to the ﬁrst approach described in the previ-
ous chapter. We just add an oriented edge from leader l to individual i with timestamp
ML if jumping individual after all jumps, in migrating loop ML, it reaches better
ﬁtness than the ﬁtness of leader.
In Fig.6.2, we can see the size of the connected component of the network given
for one run of each CEC function. The size of the connected component represents
how many nodes are connected to each other, which also means how many paths are
there amongst the nodes.
We can see, that for many functions the algorithm does not create a component
with maximal possible size. In many cases, it does not even create the size of the
component with any reasonable size. In these runs, we used 70 individuals, so the
maximum possible size of the component is 70. We can see, that only for functions

134
L. Tomaszek and I. Zelinka
Fig. 6.2 Size of component for CEC functions
2, 14 and 15, the algorithm creates a network where the components size equals to
70. Function 2 is unimodal function and functions 14, and 15 behave more like an
unimodal than a multimodal function. Functions 1, 4, 7 and 9 create a network with
a component of almost maximal size. Remaining functions then create a component
with lower size.

6
Improvement of SOMA Algorithm Using Complex Networks
135
This permits us to improve SOMA algorithm by changing of how is population
manipulated. This version is then called SOMA Remove. In this algorithm, we run
standardSOMAalgorithmfor N migratingloops.Duringthis N loopswearecreating
a complex network. After we reach Nth loop, we count the degree property and
remove vertices with degree equal to 0. We, therefore, remove individuals who are
not useful. These individuals were never leaders and never improved the leader. Then
we continue with a limited population. This Nth loop we call ReduceInCycle.
During the experiments, we set up ReduceInCycle 10 and 30. This number is
really low, so there is some possibility that the size of the component could be small.
It is therefore vital to check that the size of the component has at least 5 nodes. If not,
we just raise the RaduceInCycle property. The pseudocode of SOMA algorithm
using the removing strategy can be seen in Algorithm 1.
begin
Generate initial population
Evaluate initial population
migrationCycle = 0
while numberOfEvaluation < maximumEvaluation do
if migrationCycle == reduceInCycle then
if exists component with 5 nodes then
Remove individuals with degree equals to 0
else
r
end
educeInCycle ++
end
end
Get leader individual forall the individual i in population do
if individual i != leader individual then
Moving individual i towards leader individual
Save best found solution to a new population
end
end
migrationCycle ++
end
end
Algorithm 1: SOMA, strategy Remove
6.5
Parameters
During the tests we used two most common setups of parameters. One for dense
search where we set PathLength = 3, Step = 0.11, PRT = 0.2 and one for less
dense search where we set PathLength = 3, Step = 0.3 and PRT = 0.3. We run both
algorithms on all CEC benchmarks functions for D = 10, 30 and 50 and we set up
max function evaluation (MaxFES) as D · 104 for dense search and D·104
2
for less
dense search. Parameter PopSize we setup as D + 40 for all functions and we run
each function 51 times. Errors lesser than 10−8 are taken as 0.

136
L. Tomaszek and I. Zelinka
Table 6.2 Results for D = 10 for SOMA Remove and SOMA AllToOne for all CEC functions
Parameters: D = 10, PathLength = 3, Step = 0.11, PopSize = 50, PRT = 0.2, MaxFES = 1,00,000, ReduceInCycle = 10
SOMA Remove
SOMA AllToOne
F
Best
Worst
Median
Mean
Std
Best
Worst
Median
Mean
Std
1
0.00E+00
5.42E-04
8.00E-08
2.03E-05
6.91E-09
+++
2.25E-03
6.94E-01
4.18E-02
9.23E-02
8.90E-01
2
0.00E+00
1.10E-04
2.00E-08
3.93E-06
2.46E-10
+++
4.28E-05
3.44E-02
9.47E-04
2.78E-03
1.52E-03
3
1.65E+00
2.01E+01
2.01E+01
1.93E+01
8.44E+00
=
3.62E-02
2.01E+01
2.01E+01
1.89E+01
1.04E+03
4
9.95E-01
7.08E+00
3.05E+00
3.65E+00
2.09E+00
=
1.55E-01
8.53E+00
3.98E+00
4.13E+00
1.76E+02
5
2.50E-01
2.44E+02
2.20E+01
4.82E+01
3.39E+03
+
1.28E-01
2.98E+02
4.80E+01
7.20E+01
2.58E+05
6
3.01E+00
4.80E+03
1.48E+02
5.04E+02
7.72E+05
+++
8.15E+00
4.10E+03
4.82E+02
9.24E+02
5.83E+07
7
2.92E-02
1.02E+00
8.46E-02
1.81E-01
7.38E-02
=
2.38E-02
1.03E+00
9.33E-02
2.36E-01
5.51E+00
8
9.95E-06
1.25E+02
8.03E-01
1.08E+01
4.05E+02
=
3.22E-02
1.78E+01
7.29E-01
3.62E+00
2.03E+03
9
1.00E+02
1.10E+02
1.05E+02
1.06E+02
3.86E+00
=
1.02E+02
1.10E+02
1.05E+02
1.05E+02
1.36E+02
10
1.06E+01
1.38E+03
3.19E+02
5.04E+02
2.03E+05
++
2.71E+01
1.19E+03
4.16E+02
5.59E+02
8.11E+06
11
4.21E-01
2.00E+02
1.56E+00
9.47E+00
1.52E+03
=
5.38E-01
2.00E+02
1.41E+00
9.15E+00
7.22E+04
12
1.02E+02
1.06E+02
1.03E+02
1.04E+02
9.81E-01
=
1.02E+02
1.05E+02
1.03E+02
1.04E+02
3.36E+01
13
7.88E+00
3.24E+01
1.68E+01
1.75E+01
2.01E+01
=
8.68E+00
2.51E+01
1.67E+01
1.72E+01
4.47E+02
14
1.00E+02
2.79E+03
2.00E+02
5.03E+02
8.04E+05
=
1.00E+02
2.73E+03
1.00E+02
2.88E+02
1.91E+07
15
2.05E+02
2.05E+02
2.05E+02
2.05E+02
1.29E-05
=
2.05E+02
2.05E+02
2.05E+02
2.05E+02
6.63E-04
(continued)

6
Improvement of SOMA Algorithm Using Complex Networks
137
Table 6.2 (continued)
Parameters: D = 10, PathLength = 3, Step = 0.11, PopSize = 50, PRT = 0.2, MaxFES = 1,00,000, ReduceInCycle = 10
SOMA Remove
SOMA AllToOne
F
Best
Worst
Median
Mean
Std
Best
Worst
Median
Mean
Std
Parameters: D = 10, PathLength = 3, Step = 0.3, PopSize = 50, PRT = 0.3, MaxFES = 50,000, ReduceInCycle = 30
1
3.17E-05
6.26E-01
1.08E-02
3.80E-02
9.22E-03
+++
1.14E-02
3.85E+01
8.82E-01
2.98E+00
1.90E+03
2
8.68E-06
1.77E-01
8.77E-03
2.43E-02
1.23E-03
+++
3.52E-03
9.51E-01
5.53E-02
1.27E-01
1.38E+00
3
3.00E-08
2.02E+01
2.01E+01
1.87E+01
2.45E+01
++
2.26E-03
2.03E+01
2.02E+01
1.88E+01
1.11E+03
4
1.99E+00
1.39E+01
4.97E+00
6.02E+00
7.76E+00
=
1.99E+00
1.29E+01
4.98E+00
5.61E+00
3.14E+02
5
1.37E+01
6.75E+02
1.97E+02
2.31E+02
2.46E+04
=
1.27E+01
6.77E+02
2.53E+02
2.62E+02
1.61E+06
6
4.26E+00
6.23E+03
2.58E+02
5.41E+02
1.01E+06
+
2.05E+01
3.81E+03
3.58E+02
6.67E+02
3.78E+07
7
6.98E-02
2.07E+00
3.96E-01
6.11E-01
2.20E-01
=
9.74E-02
1.74E+00
6.64E-01
6.72E-01
8.39E+00
8
9.26E-02
1.06E+03
1.58E+00
3.10E+01
2.16E+04
- -
2.91E-01
5.96E+01
2.54E+00
9.62E+00
6.63E+03
9
1.03E+02
1.16E+02
1.07E+02
1.07E+02
7.48E+00
=
1.03E+02
1.16E+02
1.07E+02
1.07E+02
3.32E+02
10
8.19E+00
1.19E+03
2.86E+02
5.59E+02
2.25E+05
++
1.59E+01
1.22E+03
3.79E+02
5.94E+02
9.81E+06
11
7.82E-01
3.06E+00
1.64E+00
1.67E+00
2.25E-01
=
8.63E-01
2.79E+00
1.60E+00
1.66E+00
1.12E+01
12
1.02E+02
1.06E+02
1.03E+02
1.03E+02
7.00E-01
=
1.02E+02
1.07E+02
1.04E+02
1.04E+02
3.67E+01
13
9.60E+00
3.04E+01
2.24E+01
2.14E+01
1.81E+01
+++
1.49E+01
3.03E+01
2.35E+01
2.27E+01
6.97E+02
14
1.00E+02
2.79E+03
1.00E+02
5.42E+02
9.20E+05
+++
1.00E+02
2.79E+03
1.00E+02
5.42E+02
4.60E+07
15
2.05E+02
2.54E+02
2.05E+02
2.06E+02
4.68E+01
=
2.05E+02
2.54E+02
2.05E+02
2.06E+02
2.34E+03

138
L. Tomaszek and I. Zelinka
Table 6.3 Results for D = 30 for SOMA Remove and SOMA AllToOne for all CEC functions
Parameters: D = 30, PathLength = 3, Step = 0.11, PopSize = 70, PRT = 0.2, MaxFES = 3,00,000, ReduceInCycle = 10
SOMA Remove
SOMA AllToOne
1
4.93E+04
6.43E+05
2.16E+05
2.43E+05
2.43E+10
+++
1.84E+05
2.63E+06
1.25E+06
1.26E+06
1.80E+13
2
0.00E+00
0.00E+00
0.00E+00
0.00E+00
0.00E+00
+++
3.70E-07
5.72E-05
6.21E-06
1.12E-05
8.27E-09
3
2.04E+01
2.06E+01
2.05E+01
2.05E+01
4.28E-03
+++
2.05E+01
2.07E+01
2.06E+01
2.06E+01
7.50E-02
4
3.69E+01
9.05E+01
6.65E+01
6.31E+01
1.52E+02
+++
3.45E+01
1.01E+02
7.35E+01
7.13E+01
1.16E+04
5
2.56E+03
4.72E+03
3.71E+03
3.62E+03
2.02E+05
+++
3.87E+03
4.82E+03
4.37E+03
4.36E+03
2.95E+06
6
6.41E+04
1.80E+06
5.59E+05
7.28E+05
2.40E+11
=
1.34E+05
1.87E+06
6.75E+05
7.45E+05
8.74E+12
7
3.03E+00
9.38E+00
5.99E+00
6.15E+00
3.52E+00
- -
3.10E+00
8.39E+00
5.70E+00
5.58E+00
1.05E+02
8
3.55E+03
4.12E+05
5.65E+04
8.63E+04
6.69E+09
=
9.19E+03
3.00E+05
5.02E+04
7.09E+04
1.96E+11
9
2.01E+02
2.01E+02
2.01E+02
2.01E+02
1.13E-02
+++
2.01E+02
2.01E+02
2.01E+02
2.01E+02
3.05E-01
10
1.20E+04
2.12E+05
6.63E+04
7.87E+04
3.04E+09
=
1.07E+04
2.31E+05
6.09E+04
7.46E+04
1.10E+11
11
2.02E+02
2.06E+02
2.03E+02
2.04E+02
1.27E+00
+++
2.03E+02
2.08E+02
2.05E+02
2.05E+02
6.59E+01
12
1.10E+02
1.13E+02
1.11E+02
1.11E+02
4.24E-01
=
1.09E+02
1.13E+02
1.11E+02
1.11E+02
2.08E+01
13
8.75E+01
1.11E+02
1.01E+02
1.02E+02
2.42E+01
+++
9.41E+01
1.13E+02
1.06E+02
1.05E+02
8.78E+02
14
2.73E+04
3.23E+04
2.74E+04
2.88E+04
4.00E+06
=
2.73E+04
3.24E+04
2.74E+04
2.87E+04
1.98E+08
15
2.74E+02
2.76E+02
2.74E+02
2.74E+02
2.56E-01
- -
2.74E+02
2.76E+02
2.74E+02
2.74E+02
4.64E+00
(continued)

6
Improvement of SOMA Algorithm Using Complex Networks
139
Table 6.3 (continued)
Parameters: D = 30, PathLength = 3, Step = 0.11, PopSize = 70, PRT = 0.2, MaxFES = 3,00,000, ReduceInCycle = 10
SOMA Remove
SOMA AllToOne
Parameters: D = 30, PathLength = 3, Step = 0.3, PopSize = 70, PRT = 0.3, MaxFES = 1,50,000, ReduceInCycle = 30
1
5.59E+04
1.58E+06
3.49E+05
4.19E+05
1.38E+11
+++
1.01E+05
3.55E+06
6.32E+05
8.23E+05
2.32E+13
2
1.00E-08
2.50E-05
4.60E-07
1.69E-06
1.92E-11
+++
1.80E-07
2.48E-04
6.28E-06
1.73E-05
7.02E-08
3
2.06E+01
2.08E+01
2.08E+01
2.08E+01
2.68E-03
++
2.06E+01
2.09E+01
2.08E+01
2.08E+01
1.28E-01
4
1.59E+01
7.76E+01
4.18E+01
4.37E+01
1.48E+02
=
1.59E+01
7.07E+01
4.05E+01
4.31E+01
7.07E+03
5
2.19E+03
5.81E+03
4.68E+03
4.53E+03
8.65E+05
+++
7.69E+02
6.24E+03
5.42E+03
5.09E+03
6.55E+07
6
1.28E+04
2.05E+06
2.09E+05
3.07E+05
1.41E+11
+++
4.35E+04
2.02E+06
3.69E+05
4.85E+05
8.53E+12
7
2.67E+00
1.31E+01
6.02E+00
6.63E+00
5.55E+00
=
2.63E+00
1.21E+01
6.17E+00
6.56E+00
2.48E+02
8
1.14E+03
1.70E+05
2.36E+04
2.94E+04
8.15E+08
=
1.50E+03
1.01E+05
2.65E+04
3.17E+04
2.44E+10
9
1.49E+02
2.02E+02
2.01E+02
2.00E+02
5.38E+01
+
1.52E+02
2.02E+02
2.01E+02
2.00E+02
2.35E+03
10
5.71E+03
3.34E+05
2.81E+04
4.30E+04
2.63E+09
++
6.49E+03
4.34E+05
4.15E+04
6.02E+04
2.28E+11
11
2.03E+02
5.40E+02
2.05E+02
2.31E+02
7.50E+03
=
2.02E+02
5.38E+02
2.04E+02
2.29E+02
3.44E+05
12
1.10E+02
1.14E+02
1.12E+02
1.12E+02
8.41E-01
=
1.09E+02
1.14E+02
1.12E+02
1.12E+02
4.12E+01
13
9.10E+01
1.15E+02
1.06E+02
1.06E+02
2.82E+01
++
1.00E+02
1.18E+02
1.11E+02
1.10E+02
9.49E+02
14
2.73E+04
3.23E+04
3.08E+04
2.97E+04
3.84E+06
=
2.73E+04
3.24E+04
3.08E+04
2.95E+04
2.10E+08
15
2.74E+02
2.77E+02
2.75E+02
2.75E+02
5.79E-01
=
2.74E+02
2.78E+02
2.75E+02
2.75E+02
2.69E+01

140
L. Tomaszek and I. Zelinka
Table 6.4 Results for D = 50 for SOMA Remove and SOMA AllToOne for all CEC functions
Parameters: D = 50, PathLength = 3, Step = 0.11, PopSize = 90, PRT = 0.2, MaxFES = 5,00,000, ReduceInCycle = 10
SOMA Remove
SOMA AllToOne
F
Best
Worst
Median
Mean
Std
Best
Worst
Median
Mean
Std
1
6.45E+05
1.25E+07
4.04E+06
4.24E+06
6.13E+12
+++
2.13E+06
1.44E+07
5.42E+06
5.57E+06
2.4E+14
2
1.67E-04
2.84E+00
3.82E-02
1.96E-01
2.12E-01
+++
1.28E-01
6.19E+03
1.10E+02
6.24E+02
6.55E+07
3
2.07E+01
2.09E+01
2.09E+01
2.09E+01
1.73E-03
++
2.08E+01
2.10E+01
2.09E+01
2.09E+01
5.17E-02
4
5.71E+01
2.39E+02
1.46E+02
1.39E+02
2.18E+03
+++
7.13E+01
2.34E+02
1.76E+02
1.71E+02
8.58E+04
5
6.54E+03
1.05E+04
9.57E+03
9.45E+03
5.43E+05
+++
8.98E+03
1.10E+04
1.04E+04
1.03E+04
7.41E+06
6
1.09E+05
2.01E+06
7.08E+05
7.99E+05
1.73E+11
=
3.22E+05
1.70E+06
7.62E+05
8.08E+05
4.37E+12
7
7.25E+00
8.47E+01
4.63E+01
5.66E+01
3.35E+02
-
8.27E+00
8.44E+01
4.49E+01
5.39E+01
1.71E+04
8
1.58E+05
2.85E+06
1.09E+06
1.26E+06
4.41E+11
=
3.89E+05
2.28E+06
1.15E+06
1.11E+06
1.00E+13
9
2.02E+02
2.03E+02
2.02E+02
2.02E+02
1.77E-02
+++
2.02E+02
2.03E+02
2.02E+02
2.02E+02
1.03E+00
10
5.58E+03
5.24E+05
9.42E+04
1.16E+5
1.11E+10
+++
4.92E+04
1.10E+06
3.34E+05
3.60E+05
2.36E+12
11
2.08E+02
1.62E+03
7.32E+02
7.09E+2
1.28E+05
- - -
2.12E+02
1.46E+03
5.55E+02
5.00E+02
2.81E+06
12
1.10E+02
1.13E+02
1.11E+02
1.11E+2
5.13E-01
=
1.10E+02
1.13E+02
1.11E+02
1.11E+02
2.89E+01
13
1.84E+02
2.03E+02
1.95E+02
1.94E+2
2.38E+01
+++
1.81E+02
2.09E+02
2.00E+02
1.99E+02
1.45E+03
14
2.98E+04
2.98E+04
2.98E+04
2.98E+4
1.99E-09
+++
2.98E+04
2.98E+04
2.98E+04
2.98E+04
1.10E-02
15
2.84E+02
2.87E+02
2.85E+02
2.85E+2
2.13E+01
+++
2.84E+02
2.88E+02
2.86E+02
2.86E+02
5.17E-01
(continued)

6
Improvement of SOMA Algorithm Using Complex Networks
141
Table 6.4 (continued)
Parameters: D = 50, PathLength = 3, Step = 0.11, PopSize = 90, PRT = 0.2, MaxFES = 5,00,000, ReduceInCycle = 10
SOMA Remove
SOMA AllToOne
F
Best
Worst
Median
Mean
Std
Best
Worst
Median
Mean
Std
Parameters: D = 50, PathLength = 3, Step = 0.3, PopSize = 90, PRT = 0.3, MaxFES = 2,50,000, ReduceInCycle = 30
1
9.30E+05
1.24E+07
3.18E+06
3.90E+06
7.67E+12
+++
1.09E+06
1.25E+07
3.82E+06
4.74E+06
4.16E+14
2
7.25E-01
1.58E+04
4.20E+02
2.05E+03
1.18E+07
+++
2.71E+00
4.24E+04
2.81E+03
6.70E+03
3.85E+09
3
2.09E+01
2.11E+01
2.10E+01
2.10E+01
2.25E-03
+++
2.10E+01
2.11E+01
2.11E+01
2.11E+01
5.89E-02
4
5.87E+01
1.49E+02
1.03E+02
1.04E+02
4.44E+02
=
6.77E+01
1.39E+02
9.95E+01
1.01E+02
1.49E+04
5
5.93E+03
1.24E+04
1.04E+04
1.01E+04
2.68E+06
+++
6.07E+03
1.28E+04
1.19E+04
1.11E+04
1.33E+08
6
4.51E+04
6.13E+05
1.90E+05
2.31E+05
2.05E+10
+++
7.86E+04
9.92E+05
3.25E+05
3.71E+05
1.97E+12
7
1.17E+01
1.29E+02
7.79E+01
6.66E+01
5.44E+02
=
1.04E+01
1.29E+02
8.09E+01
6.88E+01
2.63E+04
8
1.00E+05
1.57E+06
5.01E+05
5.44E+05
1.05E+11
+++
1.47E+05
2.56E+06
7.89E+05
8.91E+05
1.26E+13
9
2.02E+02
2.04E+02
2.03E+02
2.03E+02
9.95E-02
=
2.02E+02
2.04E+02
2.03E+02
2.03E+02
3.97E+00
10
2.10E+04
5.21E+05
1.54E+05
1.91E+05
1.60E+10
+++
2.11E+04
9.48E+05
3.47E+05
3.64E+05
1.90E+12
11
2.09E+02
1.26E+03
9.57E+02
9.19E+02
3.01E+04
=
2.11E+02
1.17E+03
9.48E+02
9.04E+02
1.31E+06
12
1.10E+02
1.15E+02
1.12E+02
1.12E+02
1.27E+00
=
1.10E+02
1.14E+02
1.12E+02
1.12E+02
4.72E+01
13
1.71E+02
2.14E+02
2.01E+02
1.98E+02
1.02E+02
+++
1.91E+02
2.14E+02
2.05E+02
2.05E+02
1.64E+03
14
2.98E+04
7.30E+04
2.98E+04
3.32E+04
1.30E+08
+++
2.98E+04
7.25E+04
2.98E+04
3.24E+04
4.95E+09
15
2.85E+02
2.89E+02
2.87E+02
2.87E+02
1.28E+00
=
2.85E+02
2.90E+02
2.87E+02
2.87E+02
5.28E+01

142
L. Tomaszek and I. Zelinka
6.6
Results
In next Tables6.2, 6.3 and 6.4 we can see results for all CEC benchmark functions for
classical SOMA algorithm and SOMA algorithm with Remove strategy for dimen-
sions 10, 30 and 50.
Moreover, above we can see the comparison of those two algorithms by two-
sample Wilcoxon test. The + symbol represents that SOMA Remove is signiﬁcantly
better than SOMA AllToOne, - symbol signiﬁes the opposite. The count of the
sign symbols corresponds to the achieved signiﬁcance level of the rejection of null
hypothesis (0.05, 0.01, 0.001).
To ensure that runs of algorithms are comparable, we setup same seed for random
generator, so after ReduceInCycle migrating loop, the algorithms have the identical
population and same starting position. Algorithms then continue separately, but the
generated PRT vectors are identical, so we just jump with different individuals but
according to the same PRT vector.
As we can see, the performance of the SOMA Remove is better on many functions.
Only on a few test functions improvement is not observable. On dimension 10 SOMA
Remove is better in 5, respectively 7, out of 15 functions. For dimension 30 SOMA
Remove is better in 8 test functions and in dimension 50 SOMA Remove reached
better results on 10, respectively 9 functions. We can see that with bigger dimensions
SOMA remove reaches better results on more functions according to standard SOMA
algorithm.
In total SOMA algorithm with Remove strategy was worse only on 5 functions
out of 90 compared to SOMA AllToOne.
6.7
Conclusion
In this chapter, we described possibilities how we could improve SOMA algorithm
according to previous analysis, and one signiﬁcant improvement, based on the size
of component and node degree that we called SOMA Remove, was presented.
Also, we compared standard SOMA algorithm with this new version of SOMA
with remove strategy by two-sample Wilcoxon test. As we can see, SOMA Remove
reached same or better results on most test functions. In total, SOMA Remove was
better on 47 out of 90 comparisons and worse on 5 out of 90 comparisons in dimen-
sions 10, 30 and 90.
Acknowledgements The following grants are acknowledged for the ﬁnancial support provided to
this research: Grant Agency of the Czech Republic – GACR P103/15/06700S Grant of SGS No.
SGS 2017/134, VSB-Technical University of Ostrava The Ministry of Education, Youth and Sports
from the National Programme of Sustainability (NPU II) project “IT4Innovations excellence in
science - LQ1602”.

6
Improvement of SOMA Algorithm Using Complex Networks
143
References
1. Back, T., Fogel, B., Michalewicz, Z.: Handbook of Evolutionary Computation, Institute of
Physics. Institute of Physics, London (1997)
2. Barricelli, N.: Esempi numerici di processi di evoluzione. Methodos, p. 4568 (1954)
3. Fogel, G., Corne, D.: Evolutionary Computation in Bioinformatics. Bioinformatics artiﬁcial
intelligence, Morgan Kaufmann (2003)
4. Holland, J.H.: Adaptation in Natural and Artiﬁcial Systems. The University of Michigan Press,
Ann Arbor (1975)
5. Holland, J.H.: Adaptation in Natural and Artiﬁcial Systems: An Introductory Analysis with
Applications to Biology Control and Artiﬁcial Intelligence. MIT Press, Cambridge, MA, USA
(1992)
6. Liang, J.J., Qu, B.Y., Suganthan, P.N., Chen, Q.: Problem deﬁnitions and evaluation criteria
for the CEC 2015 competition on learning-based real-parameter single objective optimization.
Technical Report 201411A, Computational Intelligence Laboratory, Zhengzhou University,
Zhengzhou China and Technical Report, Nanyang Technological University, Singapore (2014)
7. Rechenberg, I.: Evolutionsstrategie: optimierung technischer systeme nach prinzipien der biol-
ogischen evolution. Frommann-Holzboog (1973)
8. Schwefel, H.P.: Numerische Optimierung von Computer-Modellen mittels der Evolution-
sstrategie. ISR, vol. 26. Birkhaeuser, Basel/Stuttgart (1977)
9. Turing, A.M.: Intelligent Machinery, Unpublished Report for National Physical Laboratory
(1975)
10. Ivan, Z., Tomaszek, L., Snasel, V.: On evaluation of evolutionary networks using new tem-
poral centralities algorithm. In: 2015 International Conference on Intelligent Networking and
Collaborative Systems (INCOS), pp. 334–339. IEEE (2015)
11. Ivan, Z., Tomaszek, L., Kojecky, L.: On evolutionary dynamics modeled by ant algorithm. In:
2016 International Conference on Intelligent Networking and Collaborative Systems (INCoS),
pp. 193–198. IEEE (2016)
12. Ivan, Z., Tomaszek, L.: Competition on learning-based real-parameter single objective opti-
mization by SOMA swarm based algorithm with SOMARemove strategy. In: 2016 IEEE
Congress on Evolutionary Computation (CEC), pp. 4981–4987. IEEE (2016)

Chapter 7
Complex Networks in Particle Swarm
Michal Pluhacek, Roman Šenkeˇrík, Adam Viktorin and Tomas Kadavy
Abstract This chapter presents an proposal of methodology for converting the inner
dynamics of PSO algorithm into complex network. The motivation is in the recent
trend of adaptive and learning methods for improving the performance of evolu-
tionary computational techniques. It seems very likely that the complex network
and its statistical characteristics can be used within those adaptive approaches. The
network analysis also provides usefull insight into the inner dynamic of PSO. The
methodology described in this chapter uses the communication in the swarm for
construction of the network.
7.1
Introduction
In this chapter we present a process of constructing a complex network from inner
dynamic of popular swarm intelligence algorithm - the Particle Swarm Optimization
(PSO) [1]. In contrast to many other evolutionary based methods the communication
and information sharing in the PSO is very restricted and therefore the methodology
fornetworkconstructiondiffersincomparisonwithotherevolutionarycomputational
techniques (ECTs).
M. Pluhacek (B) · R. Šenkeˇrík · A. Viktorin · T. Kadavy
Regional Research Centre CEBIA-Tech, Tomas Bata University in Zlín,
Nad Stránˇemi 4511, 76005 Zlín, Czech Republic
e-mail: pluhacek@fai.utb.cz
R. Šenkeˇrík
e-mail: senkerik@fai.utb.cz
A. Viktorin
e-mail: aviktorin@fai.utb.cz
T. Kadavy
e-mail: kadavy@fai.utb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_7
145

146
M. Pluhacek
7.2
Particle Swarm Optimization Algorithm
The PSO algorithm is probably the most prominent, popular and widely used rep-
resentative of the Swarm Intelligence (SI) category and shares notable similarities
with almost all other SI methods. For these reason this algorithm has been chosen as
the most suitable for this work. The PSO algorithm takes inspiration from the natural
swarm behavior of birds and ﬁsh. It was ﬁrstly introduced by Eberhart and Kennedy
in 1995 [1]. The membership of PSO into the ECTs is to this day widely discussed
in the community [2]. Some say that the Swarm Intelligence [3] is an entirely dif-
ferent group of methods and others count these methods as sub-set of ECTs. For the
purposes of this research the PSO is considered as one the ECTs and also SI methods.
In the PSO algorithm each particle in the population (swarm) represents a candi-
date solution for the optimization problem that is deﬁned by its mathematical repre-
sentation - the cost function (CF). In every iteration of the algorithm a new location
(combination of CF parameters) for the particle is calculated based on its previous
location and so called velocity vector (velocity vector contains particle velocity for
each dimension of the problem).
According to the method of selection of the swarm or sub-swarm for best solution
information spreading, the PSO algorithms are noted as global PSO (GPSO) or local
PSO (LPSO) [4]. The advantages and disadvantages of both approaches are discussed
in detail in [4]. In this research the GPSO is used.
The new velocity of particle is given by (7.1); the velocity directly affects the
position of each particle in the next iteration.
vt+1
i, j = w · vt
i, j + c1 · Rand1 · (pBestt
i, j −xt
i, j) + c2 · Rand2 · (gBestt
j −xt
i, j)
(7.1)
Notation:
c1, c2 - acceleration constants typically set to 2.
Rand1, Rand2 - random numbers from interval [0, 1]. In chaos PSO version this is
the only place that chaotic pseudo-random number generators (CPRNGs) are used.
vt+1
i, j - New velocity of the ith particle in iteration t+1. (component j of the dimen-
sion D).
vt
i, j - Current velocity of the ith particle in iteration t. (component j of the
dimension D).
xt
i, j - Current position of the ith particle in iteration t. (component j of the dimen-
sion D).
pBestt
i, j - Local (personal) best solution found by the ith particle in iteration t.
(component j of the dimension D).
gBestt
j - Best solution found in a population in iteration t. (component j of the
dimensionD).
w – inertia weight value.
The maximum velocity is typically limited to 0.2 times the range. The new position
of each particle is then given by (7.2).

7
Complex Networks in Particle Swarm
147
Xt+1
i
= Xt
i + V t+1
i
(7.2)
where:
Xt+1
i
= (xt+1
i,1 , xt+1
i,2 , . . . , xt+1
i,D ) - position of the ith particle in iteration t + 1.
Xt
i = (xt
i,1, xt
i,2, . . . , xt
i,D) - position of the ith particle in iteration t.
Vt+1
i
= (vt+1
i,1 , vt+1
i,2 , . . . , vt+1
i,D ) - velocity of the ith particle in iteration t + 1.
Based on the method of velocity and position update it is recognized the synchro-
nous (velocity and position updated after iteration cycle) and asynchronous (immi-
nent velocity and position update) PSO [5]. In this study the imminently updating
(asynchronous) PSO was utilized. As is discussed in [6] it may be beneﬁcial to ini-
tialize the population with zero velocity. Therefore this advice was followed in this
research.
Finally the linear decreasing inertia weight [7–9] is used in the typically referred
GPSO design that was used in this research. The dynamic inertia weight is meant to
slow the particles over time thus to improve the local search capability in the later
phase of the optimization. The inertia weight has two control parameters wstart and
wend. A new w for each iteration is given by (7.3), where t stands for current iteration
number and n stands for the total number of iterations. The values used in this study
were wstart = 0.9 and wend = 0.4.
w = wstart −((wstart −wend) · t)
n
(7.3)
The default setting of control parameters of the algorithm was based on most
typically used PSO designs in literature. Different settings are also possible and
sometimes preferable. Some of these settings are proved to lead to convergent
trajectories [10].
7.3
Creating the Network
In this study the inner dynamics and communication in the PSO algorithm was
observed. The communication between particles in the basic PSO (described pre-
viously) is realized through the shared knowledge of global best solution (gBest).
In this study the index of the particle that triggered the gBest update is recorded.
Subsequently the link is created between the particle that triggered the last gBest
update and the particle that triggers a new gBest update. The self-loops (when new
gBest is found by same particle as previous gBest) are omitted.
Directed edges are used in this study. The link is directed from the particle that
triggeredthenewgBestupdatetotheparticlethattriggeredthepreviousgBestupdate.
The number of nodes in the network is similar to the size of the population minus
particles that failed to trigger single gBest update (no link was created).

148
M. Pluhacek
7.4
Experiment 1
In the following experiment the well known Sphere function, Schwefel function
and Rastrigin function were used as a CF for PSO. We observe the characteristics
of the network constructed according to previous section. The visualization of the
network is presented alongside with highlighted communities and histograms of
the centralities. The in-built network statistics package in Wolfram Mathematica
software was used for discovering communities.
In the ﬁrst experiment a single run of the PSO algorithm for each test function
was evaluated. The population size was set to 40, dim: 10 and the total number of
CF evaluation (MaxFEs) was set to 40,000.
Fig. 7.1 Interaction network - sphere function

7
Complex Networks in Particle Swarm
149
Fig. 7.2 Interaction network - sphere function - comunities
Fig. 7.3 Betweenness
centrality histogram - sphere
function
0
20
40
60
80
100
120
140
0
2
4
6
8
10
12
14
7.4.1
Sphere Function
Here we present the visualization of the constructed network for Sphere function
Fig.7.1. The density of the network seems very high. Eight communities were dis-

150
M. Pluhacek
Fig. 7.4 Closeness
centrality histogram - sphere
function
0.35
0.40
0.45
0.50
0.55
0.60
0
1
2
3
4
5
6
7
Fig. 7.5 Degree centrality
histogram - sphere function
5
10
15
20
25
30
0
1
2
3
4
5
6
Table 7.1 Network statistics
- sphere function
Avg. betweenness centrality
37.2368
Avg. closeness centrality
0.507687
Avg. degree centrality
15.6842
No. of communities
8
covered in the network (Fig.7.2). The betweenness centrality histogram shows that
in majority the value of the centrality is under 40 (Fig.7.3). The closeness centrality
(Fig.7.4) is distributed mostly around the value 0.55. Finally the degree centrality
distribution is presented in Fig.7.5. The statistical overview is given in Table7.1.
7.4.2
Schwefel Function
The visualization of the constructed network for Schwefel function is given in
Fig.7.6. The density of the network seems lower than in previous case. Six com-
munities were discovered in the network (Fig.7.7). There are notable differences in

7
Complex Networks in Particle Swarm
151
Fig. 7.6 Interaction network - Schwefel function
the betweenness centrality histogram (Fig.7.8) for Schwefel function and Sphere
function. The closeness centrality histogram (Fig.7.9) shows even more signiﬁcant
differences. Also the degree centrality Fig.7.10 shows differences. Again the statis-
tical overview is given in Table7.2.
7.4.3
Rastrigin Function
In the last scenario the network was constructed for rastrigin function. The visual-
ization is given in Fig.7.11. Again six communities were discovered in the network
(Fig.7.12). For further comparison the centralities histograms are given in Figs.7.13,
7.14 and 7.15 shows differences. The statistical overview is given in Table7.3.

152
M. Pluhacek
Fig. 7.7 Interaction network - Schwefel function - comunities
Fig. 7.8 Betweenness
centrality histogram -
Schwefel function
0
50
100
150
0
2
4
6
8
10
7.5
Experiment 2
In the second experiment the multi-swarm PSO algorithm was used. The network was
constructed the same way as in previous experiment. The population was divided into
two equally sized sub swarms. The Schwefel function was used in this experiment.

7
Complex Networks in Particle Swarm
153
Fig. 7.9 Closeness
centrality histogram -
Schwefel function
0.30
0.35
0.40
0.45
0.50
0.55
0
1
2
3
4
5
6
7
Fig. 7.10 Degree centrality
histogram - Schwefel
function
5
10
15
20
0
2
4
6
8
Table 7.2 Network statistics
- Schwefel function
Avg. betweenness centrality
45.0303
Avg. closeness centrality
0.423635
Avg. degree centrality
9.57576
No. of communities
6
Again we observe the centralities and communities in the network. In Fig.7.16 the
sub swarms members are distinguished by blue and green color. It is interesting to
note that according to Fig.7.17 the communities are unevenly distributed between
the sub swarms. The centralities histograms are presented in Figs.7.18, 7.19 and
7.20. The network statistics are presented i Table7.4;
7.6
Discussion
In above presented experiments the single swarm and multi-swarm PSO was used
to construct a complex network. According to presented visualizations the networks

154
M. Pluhacek
Fig. 7.11 Interaction network - Rastrigin function
created by single-swarm PSO do not differ signiﬁcantly on ﬁrst look. It is possible to
ﬁnd multiple communities in these networks and the distributions of centrality values
are different for different cost functions. This can prove usefull in future research.
The network constructed from multi-swarm PSO provides interesting insight into
the distribution of comunities between the sub swarms.
In all networks it is possible to track the ﬂow of communication in the population
and better understand the inner dynamic of PSO. Among the statistical values the
avarage centralities values seems problem and algorithm dependant, however this
needs further clariﬁcation in large-scale study.
7.7
Conclusion
In this chapter we outlined the possibility of creating complex networks from the Par-
ticle Swarm Optimization inner dynamic. There are several notable network statistics
that might prove useful for further use.
The ideas for future research include:
• Using the network analysis as ﬁtness landscape classiﬁer.

7
Complex Networks in Particle Swarm
155
Fig. 7.12 Interaction network - Rastrigin function - comunities
Fig. 7.13 Betweenness
centrality histogram -
Rastrigin function
0
50
100
150
200
250
0
5
10
15
• Using the communities information for swarm size decrease and specimen archiv-
ing.
• Using statistical measures of the network for adaptive setting of control parameters
of PSO during the optimization.

156
M. Pluhacek
Fig. 7.14 Closeness
centrality histogram -
Rastrigin function
0.30
0.35
0.40
0.45
0.50
0.55
0
2
4
6
8
Fig. 7.15 Degree centrality
histogram - Rastrigin
function
5
10
15
20
0
1
2
3
4
5
6
7
Table 7.3 Network statistics
- Rastrigin function
Avg. betweenness centrality
48.4167
Avg. closeness centrality
0.428772
Avg. degree centrality
10.6667
No. of communities
6
Table 7.4 Network statistics
- multi-swarm PSO -
Schwefel function
Avg. betweenness centrality
42.2632
Avg. closeness centrality
0.433763
Avg. degree centrality
9.21053
No. of communities
6
• Dynamic swarm topology based on the complex network.
• Creating complex networks with demanded characteristics by PSO.
• And more...

7
Complex Networks in Particle Swarm
157
Fig. 7.16 Interaction network - multi-swarm PSO - Schwefel function
Fig. 7.17 Interaction network - multi-swarm PSO - Schwefel function - comunities
Fig. 7.18 Betweenness
centrality histogram -
multi-swarm PSO - Schwefel
function
0
50
100
150
200
250
300
0
5
10
15

158
M. Pluhacek
Fig. 7.19 Closeness
centrality histogram -
multi-swarm PSO - Schwefel
function
0.3
0.4
0.5
0.6
0.7
0
2
4
6
8
Fig. 7.20 Degree centrality
histogram - multi-swarm
PSO - Schwefel function
5
10
15
20
0
2
4
6
8
Acknowledgements This work was supported by Grant Agency of the Czech Republic GACR
P103/15/06700S, further by the Ministry of Education, Youth and Sports of the Czech Republic
within the National Sustainability Programme Project no. LO1303 (MSMT-7778/2014. Also by the
European Regional Development Fund under the Project CEBIA-Tech no. CZ.1.05/2.1.00/03.0089
and by Internal Grant Agency of Tomas Bata University under the Project no. IGA/CebiaTech/
2016/007.
References
1. Kennedy J., Eberhart R.: Particle swarm optimization. In: Proceedings of IEEE International
Conference on Neural Networks. vol. 4, pp. 1942–1948 (1995)
2. Engelbrecht A.: Particle swarm optimization: where does it belong? In: Proceedings of the
IEEE Swarm Intelligence Symposium (2006)
3. Eberhart, R., Kennedy, J.: Swarm Intelligence. The Morgan Kaufmann Series in Artiﬁcial
Intelligence. Morgan Kaufmann, San Francisco (2001)
4. Engelbrecht A.: Particle swarm optimization: global best or local best? In: Submitted to BRICS-
CCI (2013)
5. Engelbrecht A.: Particle swarm optimization: iteration strategies revisited. In: Proceedings of
the BRICS Conference on omputational Intelligence (2013)
6. Engelbrecht A.: Particle swarm optimization: velocity initialization. In: Proceedings of the
IEEE Congress on Evolutionary Computation (2012)

7
Complex Networks in Particle Swarm
159
7. Shi Y.H., Eberhart R.C.: A modiﬁed particle swarm optimizer. In: IEEE International Confer-
ence on Evolutionary Computation, Anchorage Alaska, pp. 6973 (1998)
8. Nickabadi, A., Ebadzadeh, M.M., Safabakhsh, R.: A novel particle swarm optimization algo-
rithm with adaptive inertia weight. Appl. Soft Comput. 11(4), 3658–3670 (2011). ISSN 1568-
4946
9. Eberhart R., Shi Y.: Comparing inertia weights and constriction factors in particle swarm
optimization, In: Proceedings of the IEEE Congress on Evolutionary Computation, vol. 1, pp.
8488 (2000)
10. van den Bergh, F., Engelbrecht, A.P.: A study of particle swarm optimization particle trajecto-
ries. Inf. Sci. 176(8), 937–971 (2006)

Chapter 8
Comparison of Vertex Centrality Measures
in Complex Network Analysis Based
on Adaptive Artiﬁcial Bee Colony Algorithm
Magdalena Metlicka and Donald Davendra
Abstract Evolutionary algorithms are a powerful tool for difﬁcult optimization
problems infeasible for conventional approach. Unfortunately, many of them are
not free of problems of premature convergence and stagnation. The algorithm design
constantly strives for improved performance. Next to the efforts of developing EAs
based on entirely new principles, the existing EAs are being improved with advanced
techniques, which seek to remedy the afore mentioned problems in existing algo-
rithms, either employing the parameter adaptation techniques, or utilizing the infor-
mation obtained from overall population analysis to control its development. As
discovered earlier, the population dynamics of many evolutionary algorithms exhibit
complex network properties. The analysis of such network can be used to obtain
the meaningful information about population development in time. Based on these
ideas, an adaptive mechanism was implemented inside swarm based ABC algo-
rithm, employing complex network analysis, vertex centralities of degree, closeness
and betweenness in particular, to enhance algorithm’s performance. However, since
both versions of algorithm were originally using all three of the chosen centralities
in combination, the impact of individual centralities on algorithm performance was
not clear. This chapter provides insight into this, by comparing and analysing the
results of Adaptive ABC algorithm using single selected centrality.
M. Metlicka (B)
College of Information and Computer Sciences, University of Massachusetts Amherst. 140
Governors Dr., Amherst, Massachusetts 01003, USA
e-mail: mmetlicka@umass.edu
D. Davendra
Department of Computer Science, Central Washington University, 400 E. University Way,
Ellensburg, Washington 98926-7520, USA
e-mail: DonaldD@cwu.edu; donald.davendra@vsb.cz
D. Davendra
Faculty of Electrical Engineering and Computer Science, Department of Computer
Science VŠB – Technical University of Ostrava, 17. listopadu 15,
708 33 Ostrava-Poruba, Czech Republic
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_8
161

162
M. Metlicka and D. Davendra
8.1
Introduction
Evolutionary algorithms have been successfully used in the past decades to ﬁnd the
close-to-optimal solution for many difﬁcult optimization problems where the con-
ventional approach fails due to irregularities of cost function and other problems. The
key elements of such algorithms are the exploration, the search for the new promis-
ing solutions around the entire search space, and exploitation, the improvement of
existing solution and search in its vicinity. The success of evolutionary algorithm lies
in its ability to balance between the two [1]. Unfortunately, many of the evolutionary
algorithms are not free of problems of premature convergence and stagnation.
In an effort to develop more efﬁcient search techniques in the past, the algorithm
design primarily concentrated on the new combination structures and mutation oper-
ators. More recently, the existing algorithms were being improved with the parameter
self-adaptive techniques, as in [2, 3]. Yet another approach towards the enhancement
of evolutionary algorithms is based on the effort to control the population develop-
ment as such, using topology, clustering or hierarchy (for example in [4] or [5]).
The classical statistical methods of population analysis can be, however, costly,
as the population development is continual in time, and the statistics therefore have
to be recalculated frequently. To approach this problem in a different way, the new
method of population analysis was suggested in [6].
The population dynamics of evolutionary algorithms can be modelled as network
of communication amongst solutions. It was shown earlier in (SOMA [7], ABC [8],
and also DE [9]), that this network has complex network properties. Useful informa-
tion can be obtained by applying standard complex network analysis methods. This
information can be used to steer the population development in order to avoid afore
mentioned problems of stagnation and premature convergence.
The application of coupled map lattice control for this purpose was proposed in
[10]. The possibilities of analysis and visualisation of such network were described
in [11, 12], while the analysis of population dynamics using these techniques for
the evolutionary algorithms applied to combinatorial optimisation problems, SOMA
and DE, was presented in [7], and respectivly in [9].
Stemming from these ideas, the adaptive mechanism for ABC algorithm based on
complex network analysis was developed by the same authors [8], where the solu-
tions of the population are mapped to the vertices, and weighted adjacency matrix is
being recorded throughout algorithm iterations, maintaining the information about
the information exchange leading to improvement amongst solutions. After a few
iterations, the network is analysed by calculating vertex centralities. The lowest cen-
trality solutions are considered the least useful and as such replaced by the randomly
generated new solutions. Hence the population is refreshed, enabling further explo-
ration of search space while removing the inefﬁcient old solutions.
This approach was subsequently further enhanced, presenting the new and
improved mechanism of solution selection and replacement, incorporating into deci-
sion mechanism also quality of a solution as such. Both of the works on the Adaptive
ABC algorithm were using three selected vertex centralities; the weighted degree,

8
Comparison of Vertex Centrality Measures in Complex Network Analysis …
163
closeness and betweenness, in combination. The population was split either logically,
or fully, using ensemble approach (adapted from [13]), into three parts. Each part was
assigned different centrality, and evaluated separately. However, the newer work pre-
sented also the version of Adaptive ABC with a single centrality measure, selectable
by parameter, to enable the comparison of the original ABC to the Adaptive ABC
with the simplest implementation of the adaptive mechanism possible.
Nonetheless, from the previous work, the impact of different centrality choices
on the performance of the Adaptive ABC algorithm was not quite clear. This chapter
seeks to remedy this by presenting the experimentation and analysis of Adaptive
ABC running with different centrality measures, comparing the different centrality
options against one another.
The chapter is designed as follows: Sect.8.2 provides a brief introduction into
complex networks and describes the used vertex centralities. Section8.3, giving
the description of the original ABC algorithm designed by Karaboga. Section8.4
describes the Adaptive ABC algorithm with single centrality, Sect.8.5 gives overview
of benchmark functions and the experimentation results. Finally, the outcome is sum-
marized in conclusion (Sect.8.6).
8.2
Complex Networks
As well as in many real world networks, the network modelling the evolutionary
algorithm population dynamics in many cases shows the complex network proper-
ties. This was experimentally proven for DE [7], SOMA [9], and later for ABC [8]
algorithm. There are many different ways of analysing the complex networks. In
this chapter, continuing with the previous work, the vertex centralities were chosen
as a means of accomplishing this goal: the unweighted degree centrality was newly
added to the previously used weighted degree, closeness and betweenness.
Unweighted Degree Centrality
The simplest of all, the degree centrality counts the number of edges incident with
the node (Eq.8.1).
CD(i) =
n

j=1
ai j
(8.1)
CD(i) is unweighted degree centrality of vertex i, ai j equals to 1 if edge between
vertices i and j exists, 0 otherwise, n is the total number of vertices in the network.
Weighted Degree Centrality
Weighted degree centrality (strength) is a measure of local connectivity of vertex,
equal to the sum of weights incident with a vertex, given by the following Eq.(8.2).

164
M. Metlicka and D. Davendra
CS(i) =
n

j=1
ai jwi j
(8.2)
CS(i) is weighted degree centrality for vertex i, ai j and n have the same meaning
as in Eq.8.1, wi j is the weight of an edge [14].
Closeness Centrality
Closeness of a vertex provides a measure of how accessible the vertex is, or equiv-
alently, how close the vertex on average is to all of the other vertices (considering
the shortest paths). It is the inverse of average shortest distance between a selected
vertex and each of the others (Eq.8.3).
CC(i) =
n −1

j∈{1..N}, j̸=i di j
(8.3)
CC(i) is closeness centrality of vertex i, n is the number of vertices in the network,
di j is the shortest path between vertices i and j [15].
Betweenness Centrality
Betweenness of a vertex is a measurement of how much a vertex lies between other
vertices of the network. The high betweenness means high probability that the vertex
will be a mediator in the information ﬂow between the other vertices. Betweenness
of a vertex is deﬁned as a ratio of the shortest paths between other vertices passing
through the vertex, to the total number of shortest paths between vertices (Eq.8.4).
CB(i) =

k, j∈{1..N},k̸= j̸=i
σk, j(i)
σk, j
(8.4)
CB(i) is betweenness of vertex i, σk, j is the total number of the shortest paths
between vertices k and j, and σk, j(i) is the number of shortest paths between i and
j, passing through i [15].
8.3
Artiﬁcial Bee Colony Algorithm
Artiﬁcial Bee Colony Algorithm designed by Karaboga [16] is a powerful swarm
intelligence stochastic algorithm for multi-variable multi-modal continuous optimi-
sation, with the advantage of fewer control parameters, compared to other classical
evolutionary algorithms, such as PSO [17], SOMA [18, 19] and AIA [20].
The inspiration of ABC algorithm comes from the intelligent behaviour of for-
aging honey bee swarm. The population consists of several solutions, called food
sources, operated on by the employed bees. The employed bees are trying to improve
solutions one at a time (extracting a nectar from a food source), while onlooker bees

8
Comparison of Vertex Centrality Measures in Complex Network Analysis …
165
are waiting in the hive. When the employed bees return, the onlooker bees decide
which food source to visit, based on the information obtained from the employed
bees. Should the food source be exhausted, the associated employed bee turns into
scout bee, looking for a new one.
The top-level ABC pseudocode is given in Sect.8.3. After the initialization, the
single iteration of algorithm consists of three phases, named after the three kinds of
bees: employed bee, onlooker bee and scout bee phase. These phases are performed
in succession, until the stopping criterion is met.
initialize
repeat
send employed bees to food sources
send onlooker bees to selected food sources
send scout bees to search for new food sources
memorize best solution
until terminating criterion met
Algorithm 1: ABC top-level pseudocode
The solution in continuous space, represented as numerical vector of dimension
D, consists of values of decision variables (optimised parameters of a function). The
population contains FS solutions. Each solution has associated its limit of unsuccess-
ful attempts of improvement, after which it is considered exhausted. When the new
solution is created, the limit is set to Limit value, and decremented after each failed
improvement attempt. The Limit, FS and terminating criterion are the algorithm
parameters, D is set by the optimized function.
8.3.1
Initialisation
The population is initialized either using some heuristic method, or randomly:
xi, j = L j + (U j −L j) · ri, j
(8.5)
xi, j denotes j-th element of i-th vector. L j, U j are lower and upper bounds for
j-th dimension, j ∈{1, 2, . . . , D}, i ∈{1, 2, . . . , FS}. ri, j is a random number in
range [0, 1].
8.3.2
Employed Bee Phase
Inemployedbeephase,anemployedbeei makesanattempttoimprovetheassociated
solution xi, applying Eq.8.6. The resulting candidate solution ni is evaluated. If the

166
M. Metlicka and D. Davendra
new solution ni is better than or equal to the previous xi, it replaces the latter one
(greedy selection method).
ni, j = xi, j + (xi, j −xk, j) · ri, j
(8.6)
xi is previous solution in the population, ni is the candidate solution, i ∈
{1, 2, . . . , FS}, j is random number from range [1, D], k is random number from
[1, FS], k ̸= i. ri, j is a real random number in [−1, 1].
8.3.3
Onlooker Bee Phase
Each onlooker bee selects one of the solutions {x1, x2, . . . , xFS}, with the probability
pi, i ∈{1, 2, . . . , FS}, given by Eq.8.7. The operator in Eq.8.6 is applied to selected
solution, and the greedy selection is performed in the same way as in employed bee
phase.
pi =
fi
FS

k=1
fk
(8.7)
pi is probability, fi ﬁtness of i −th solution, i ∈{1, 2, . . . , FS}. FS is total
number of solutions in the population.
8.3.4
Scout Bee Phase
When the limit of attempts to improve the solution is exceeded (in either of employed
or onlooker bee phases), the scout bee is sent to generate the new solution - exhausted
solution is replaced by a randomly created one, using the Eq.8.5. This happens at
most once per iteration of algorithm to prevent the excessive randomization of search.
8.4
Centralities Based Artiﬁcial Bee Colony Algorithm
The Adaptive ABC algorithm is based on the adaptive mechanism utilizing analysis
of complex network modelling the population dynamics. The network represents
the solutions (vertices), while (directed) edges represent the successful transfer of
information from one solution to the other (i.e. application of an operator which uses
one or more of the source solutions to successfully generate the improvement of
a target solution). The successful information exchange is recorded by creating an
edge between solutions, or incrementing the edge weight, if edge already existed.

8
Comparison of Vertex Centrality Measures in Complex Network Analysis …
167
The network thus created is analysed after every ﬁxed number of iterations by
calculating the selected vertex centrality for each solution (vertex). The solutions with
low centrality are then considered unimportant to the population and are replaced
with the new ones. The selected vertex centralities for this purpose are the weighted
degree (strength), closeness, betweenness and unweighted degree centrality.
In order to decide, which of the solutions have relatively low centrality, the vertices
are ﬁrst sorted according to the centrality value, and the ﬁxed ratio of solutions
corresponding to the lowest centrality ranking vertices are replaced. The network
(represented as adjacency matrix) is afterwards reset. This process is repeated until
algorithm terminates. The Figs.8.1 and 8.2 of a recorded network before and after
low centrality vertices conceptual removal illustrate this method.
The Adaptive ABC algorithm presented in this chapter (described in Sect.8.4)
follows the afore described method. The number of generations between complex
network evaluations is given by a parameter C N.Gen. The algorithm takes the
Fig. 8.1 Complex network formed after 5 generations, with labels showing Closeness centrality
values

168
M. Metlicka and D. Davendra
Fig. 8.2 Complex network after symbolical low-centrality ranking nodes removal (here 6 nodes
of total 30 were removed, corresponding to Cutoff value of 0.eps
centrality measure to be calculated as another parameter, C N.M. The ratio of vertices
to be removed after every analysis of network is provided in parameter C N.Cutof f ,
the total number of vertices removed is C N.Cutof f × FS, where FS is the num-
ber of solutions in the population. C N.S parameter determines the replacement
method to be used - C N.S = 1 replaces solutions with the randomly recreated ones,
while C N.S = 2 replaces solutions by applying to them the ABC mutation operator.
C N.S = 3 enables the probabilistic selection between the two, based on the quality
of a solution, so that the better the solution, the higher the probability of applying
the mutation operator instead of the random replacement.
Parameters C N.Etype and C N.E enable the preservation of a ﬁxed ratio C N.E
of best solutions in the population during network analysis phase. C N.Etype deter-
mines whether or not the elitism will be used, and which approach will be taken
towards population ﬁltering. The variants are described in Algorithms 3, 4 and 5.

8
Comparison of Vertex Centrality Measures in Complex Network Analysis …
169
Input:
Limit : ABC limit parameter
FS : number of solutions in the population
CN.Gen : number of generations for network creation
CN.Cutoff : ratio of low centrality ranking nodes to be recreated
CN.Etype : type of elitism to be used
CN.E : ratio of solutions to keep if elitism is used
CN.S : replacement strategy
CN.M : centrality measure type to be used
begin
generate initial population X of FS solutions
initialise the network N
initialise generation counter GenC
initialise network generation counter CN.GenC
repeat
send Employed bees and update the N
send Onlooker bees and update the N
send Scout bees (Limit)
memorize the best solution
if CN.GenC == CN.Gen then
if CN.Etype==0 then
// no elitism
analyseNetwork1(N, X, FS, Cutoff, CN.M, CN.S)
end
if CN.Etype==1 then
analyseNetwork2(N, X, FS, Cutoff, CN.M, CN.S, CN.E)
end
if CN.Etype==2 then
analyseNetwork3(N, X, FS, Cutoff, CN.M, CN.S, CN.E)
end
reset N and CN.GenC
end
increase GenC
increase CN.GenC
until stopping criterion not satisﬁed
end
Algorithm 2: Adaptive ABC
8.5
Experimentation and Analysis
Seventeen problems selected for the experimentation are the test functions taken from
[21]. The more detailed description can be found in [22]. All of them are dimension-
wise scalable, except for the Shekel’s Foxhole ( f17), with max. n = 10 decision
variables. Functions f2 – f5 are unimodal, the remaining functions are multimodal.
TheTable8.1givesoverviewofthefunctionsusedintheexperimentation.Theﬁrst
two columns give the test function number and name, second and third columns pro-
vide global optima coordinates and value (where known and reasonably presentable),
the ﬁfth column contains the problem dimensions used in the experimentation, the
last column holds the boundaries of test function for each dimension.

170
M. Metlicka and D. Davendra
Input:
N : Network, X : Population, FS : Number of solutions, CN.Cutoff : Cutoff ratio, CN.M :
Centrality measure, CN.S : Replacement strategy
begin
/* calculate centrality CN.M of all nodes
*/
c = centrality(CN.M,N)
/* sort nodes by centrality in ascending order
*/
sc=sort(c)
/* recreate lowest FS × CN.Cutoff solutions
*/
for i =1 to FS × CN.Cutoff do
si = sci
/* replace solution using selected strategy CN.S
*/
Xsi = replaceSolution(CN.S,X)
end
end
Algorithm 3: Network analysis - variant 1, without elitism. Only the solution’s
centrality ranking is considered when deciding which solutions to remove
Input:
N : Network, X : Population, FS : Number of solutions, CN.Cutoff : Cutoff ratio, CN.M :
Centrality measure, CN.S : Replacement strategy, CN.E : Elite ratio
begin
/* calculate centrality CN.M of all nodes
*/
c = centrality(CN.M,N)
/* sort nodes by centrality in ascending order
*/
sc=sort(c)
/* sort nodes by corresponding solutions fitness value in
ascending order
*/
sf = sortCost( X )
/* recreate lowest FS × CN.Cutoff solutions: if solution
in FS × CN.E best solutions, skip solution
*/
for i =1 to FS × CN.Cutoff do
si = sci
ﬁ= ﬁnd(sf, si)
if ﬁ> FS × CN.E then
Xsi = replaceSolution(CN.S,X)
end
// else skip node
end
end
Algorithm 4: Network analysis - variant 2. If the solution is amongst CN.E × FS
best solutions, it is skipped on removal

8
Comparison of Vertex Centrality Measures in Complex Network Analysis …
171
Input:
N : Network, X : Population, FS : Number of solutions, CN.Cutoff : Cutoff ratio, CN.M :
Centrality measure, CN.S : Replacement strategy, CN.E : Elite ratio
begin
/* calculate centrality CN.M of all nodes
*/
c = centrality(CN.M,N)
/* sort nodes by centrality in ascending order
*/
sc=sort(c)
/* sort nodes by corresponding solutions fitness value in
ascending order
*/
sf = sortCost( X )
/* recreate FS × CN.Cutoff solutions: if solution in FS ×
CN.E best solutions, recreate next lowest centrality
solution instead
*/
r=0 ; i=1
while (r < FS × CN.Cutoff) and (i ≤FS) do
si = sci
ﬁ= ﬁnd(sf, si)
if ﬁ> FS × CN.E then
Xsi = replaceSolution(CN.S,X)
r = r+1
end
i=i+1
end
end
Algorithm 5: Network analysis - variant 3. If the solution is amongst CN.E × FS
best solutions, the next lowest ranking solution is chosen for removal instead
8.5.1
Experiments
The goal of the experimentation is to analyse the effects of different centrality mea-
sures. The results of Adaptive ABC using weighted degree, closeness, betweenness
and unweighted degree are compared against one another. Each of the experiments for
given problem and dimension (number of decision variables) was evaluated 30 times
to obtain sufﬁciently large sample for statistical analysis. Experiments were con-
ducted on the server at Media Research Lab (MRL) at the VŠB-Technical University
of Ostrava, with the following CPU speciﬁcations: Intel Xeon CPU E5-2640 v2 with
2.00GHz frequency.
The parameters were set to the values as given in Table8.2. The terminating
criteria was set to max. 50 × n generations and 5,000 ×n function evaluations (n is a
problem dimension). The population size was set to 30 solutions. Limit for Adaptive
ABCs was set 10-times higher than the recommended value for standard ABC, as
the adaptive mechanism complements the scout bee phase to an extent.

172
M. Metlicka and D. Davendra
Table 8.1 Experiments
Name
Global
Optimum x∗
f (x∗)
Dimensions
Range
f1
Schwefel
(420.9687,
420.9687,
. . . , 420.9687)
−418.9829n
10, 20, 30
[−512, 512]n
f2
De Jong 1
o
0
10, 20, 30
[−100, 100]n
f3
De Jong 3
o
0
10, 20, 30
[−100, 100]n
f4
De Jong 4
o
0
10, 20, 30
[−100, 100]n
f5
Rosenbrock’s
Saddle
(1, 1, . . . , 1)
0
10, 20, 30
[−100, 100]n
f6
Rastrigin
o
−200n
10, 20, 30
[−30, 30]n
f7
Griewangk
o
0
10, 20, 30
[−500, 500]n
f8
Sine Envelope
Sine Wave
−
−1.4915(n −1)
10, 20, 30
[−30, 30]n
f9
Stretch V Sine
Wave
o
0
10, 20, 30
[−30, 30]n
f10
Ackley One
−
−7.54276 −
2.91867(n −3)
10, 20, 30
[−32, 32]n
f11
Ackley Two
o
0
10, 20, 30
[−32, 32]n
f12
Egg Holder
−
−
10, 20, 30
[−500, 500]n
f13
Rana
−
−
10, 20, 30
[−500, 500]n
f14
Pathological
−
−
10, 20, 30
[−100, 100]n
f15
Michalewicz
−
0.966n
10, 20, 30
[0, π]n
f16
Masters’ Cosine
Wave
o
1 −n
10, 20, 30
[−30, 30]n
f17
Shekel’s Foxhole
−
−
10
[0, 10]n
Table 8.2 Parameters settings
Parameter
Name
Value
Number of Solutions
FS
30
Limit
Limit
500
Number of CN Generations
CN.Gen
15
Cutoff Ratio
CN.Cutoff
0.1
Replacement Strategy *1
CN.S
1
Elite Ratio
CN.E
0.6
Elitism Type *2
CN.Etype
1
Centrality Measure *3
CN.M
0, 1, 2, 3
*1: Replacement Strategy: 1 = Random, 2 = Mutation operator, 3 = Probabilistic
*2: Elitism type: 0 = No elitism, 1 = Replace or skip, 2 = Replace or move to next lowest ranking
*3: Centrality Measure: 0 = Degree, 1 = Closeness, 2 = Betweenness, 3 = Unweighted Degree

8
Comparison of Vertex Centrality Measures in Complex Network Analysis …
173
Table 8.3 Experiments results: n = 10
10
Weighted Degree
Closeness
Betweenness
Unweighted Degree
f
mean
std
median
time[s]
mean
std
median
time[s]
mean
std
median
time[s]
mean
std
median
time[s]
1
-4174.9
35.823 -4189.829
0.027 -4172.117
40.670 -4189.829
0.034 -4165.968
46.743 -4189.828
0.029 -4169.613
42.514 -4189.801
0.022
2
0
0.000
0.000
0.008
0.000
0.000
0.000
0.016
0.000
0.000
0.000
0.015
0.000
0.000
0.000
0.008
3
0
0.000
0.000
0.008
0.000
0.000
0.000
0.016
0.000
0.000
0.000
0.017
0.000
0.000
0.000
0.008
4
0
0.000
0.000
0.039
0.000
0.000
0.000
0.045
0.000
0.000
0.000
0.044
0.000
0.000
0.000
0.040
5
1.19047
1.882
0.348
0.017
1.902
2.155
1.178
0.022
1.789
2.616
0.711
0.023
1.568
2.403
0.673
0.016
6
-2000
0.000 -2000.000
0.021 -2000.000
0.000 -2000.000
0.028 -2000.000
0.000 -2000.000
0.029 -2000.000
0.000 -2000.000
0.021
7
0.00611
0.007
0.004
0.027
0.004
0.006
0.000
0.032
0.004
0.006
0.000
0.033
0.006
0.007
0.000
0.026
8
-13.44
0.013
-13.443
0.049
-13.440
0.010
-13.441
0.051
-13.442
0.013
-13.442
0.054
-13.443
0.011
-13.443
0.050
9
9.01701
0.009
9.015
0.091
9.021
0.013
9.019
0.092
9.016
0.011
9.013
0.092
9.016
0.007
9.015
0.095
10
-27.97
0.000
-27.970
0.041
-27.970
0.000
-27.970
0.047
-27.970
0.000
-27.970
0.051
-27.970
0.000
-27.970
0.046
11
0
0.000
0.000
0.050
0.000
0.000
0.000
0.056
0.000
0.000
0.000
0.059
0.000
0.000
0.000
0.052
12 -6816.9 203.720 -6812.641
0.037 -6892.945 235.759 -6878.120
0.041 -6874.090 274.407 -6816.255
0.040 -6833.789 297.500 -6798.087
0.037
13 -4200.2
87.640 -4217.225
0.064 -4210.437
93.262 -4199.760
0.067 -4199.966
72.393 -4198.978
0.067 -4211.567
90.807 -4199.974
0.063
14 0.67809
0.209
0.679
0.044
0.705
0.164
0.698
0.048
0.758
0.189
0.753
0.046
0.708
0.221
0.657
0.045
15 -9.6541
0.014
-9.660
0.059
-9.652
0.015
-9.660
0.065
-9.657
0.006
-9.660
0.068
-9.653
0.013
-9.660
0.060
16 -8.4953
0.500
-8.508
0.037
-8.543
0.455
-8.603
0.043
-8.556
0.457
-8.643
0.043
-8.482
0.436
-8.471
0.037
17 -4.8108
3.546
-3.165
0.168
-5.682
3.896
-3.182
0.174
-3.765
3.245
-2.131
0.177
-4.997
3.582
-3.194
0.174
*1
9
9
10
11
8
8
7
0
9
10
8
0
9
8
10
6
*2
0.53
0.53
0.59
0.65
0.47
0.47
0.41
0.00
0.53
0.59
0.47
0.00
0.53
0.47
0.59
0.35
Table 8.4 Experiments results: n = 20
20
Weighted Degree
Closeness
Betweenness
Unweighted Degree
f
mean
std
median
time[s]
mean
std
median
time[s]
mean
std
median
time[s]
mean
std
median
time[s]
1
-8248.53
66.282
-8264.756
0.074
-8229.346
82.558
-8242.592
0.087
-8263.970
78.021
-8264.902
0.088
-8255.813
81.860
-8264.903
0.074
2
0
0.000
0.000
0.020
0.000
0.000
0.000
0.034
0.000
0.000
0.000
0.035
0.000
0.000
0.000
0.021
3
0
0.000
0.000
0.021
0.000
0.000
0.000
0.036
0.000
0.000
0.000
0.038
0.000
0.000
0.000
0.021
4
0
0.000
0.000
0.145
0.000
0.000
0.000
0.159
0.000
0.000
0.000
0.156
0.000
0.000
0.000
0.145
5
3.23992
5.244
1.587
0.057
2.534
2.815
1.410
0.066
3.495
7.198
0.894
0.068
2.888
3.540
1.266
0.052
6
-8000
0.000
-8000.000
0.073
-8000.000
0.000
-8000.000
0.087
-8000.000
0.000
-8000.000
0.090
-8000.000
0.000
-8000.000
0.072
7
0.00074
0.002
0.000
0.090
0.002
0.004
0.000
0.098
0.001
0.003
0.000
0.104
0.001
0.003
0.000
0.084
8
-28.3111
0.044
-28.307
0.181
-28.288
0.047
-28.296
0.198
-28.312
0.037
-28.309
0.188
-28.300
0.038
-28.298
0.182
9
19.1079
0.038
19.098
0.383
19.119
0.036
19.117
0.373
19.108
0.033
19.114
0.376
19.118
0.047
19.116
0.373
10 -57.1515
0.000
-57.152
0.161
-57.152
0.000
-57.152
0.174
-57.152
0.000
-57.152
0.172
-57.152
0.000
-57.152
0.153
11
0
0.000
0.000
0.195
0.000
0.000
0.000
0.205
0.000
0.000
0.000
0.207
0.000
0.000
0.000
0.189
12 -13677.5 363.488 -13737.233
0.144 -13489.281 287.203 -13482.594
0.151 -13581.973 349.252 -13541.445
0.154 -13674.222 354.752 -13689.651
0.144
13 -8519.92 158.657
-8504.156
0.268
-8467.446 172.048
-8506.175
0.281
-8499.625 157.273
-8508.688
0.278
-8500.710 170.161
-8473.952
0.272
14
2.19789
0.302
2.216
0.174
2.262
0.309
2.268
0.182
2.241
0.254
2.321
0.178
2.219
0.246
2.206
0.175
15 -19.5199
0.048
-19.516
0.238
-19.521
0.044
-19.523
0.243
-19.527
0.046
-19.535
0.251
-19.533
0.040
-19.534
0.230
16 -16.6283
0.623
-16.514
0.156
-16.818
0.583
-16.769
0.158
-16.602
0.546
-16.653
0.157
-16.965
0.717
-16.860
0.148
*1
10
8
9
7
7
8
7
0
8
9
11
0
8
8
10
9
*2
0.63
0.50
0.56
0.44
0.44
0.50
0.44
0.00
0.50
0.56
0.69
0.00
0.50
0.50
0.63
0.56
8.5.2
Analysis
The Tables8.3, 8.4 and 8.5 present results for each problem size separately. The ﬁrst
column gives the test function number. For each of the four centrality measures, there
are four columns shown: mean value, standard deviation and median value of best
solution’s cost, followed by the mean running time (statistics are calculated over 30
experiments for given function). The best obtained values of mean, standard deviation
and median of solution’s cost for each row (each test function) are highlighted in
bold. The last two rows of each table present summary - total number of best results
the centrality measure has obtained out of all rows (row labelled *1), and the fraction
of best results (row *2).
As Table8.3 shows, for the problem size of ten decision variables, the best mean
value was achieved in nine out of seventeen cases using weighted and unweighted
degree as well as betweenness, in eight cases with closeness centrality. The best

174
M. Metlicka and D. Davendra
Table 8.5 Experiments results: n = 30
30
Weighted Degree
Closeness
Betweenness
Unweighted Degree
f
mean
std
median
time[s]
mean
std
median
time[s]
mean
std
median
time[s]
mean
std
median
time[s]
1
-12256.1
86.868 -12225.226
0.161 -12279.124
93.229 -12273.378
0.180 -12288.043
85.815 -12324.050
0.183 -12315.071 104.930 -12339.554
0.161
2
0
0.000
0.000
0.039
0.000
0.000
0.000
0.061
0.000
0.000
0.000
0.061
0.000
0.000
0.000
0.039
3
0
0.000
0.000
0.040
0.000
0.000
0.000
0.062
0.000
0.000
0.000
0.065
0.000
0.000
0.000
0.039
4
0
0.000
0.000
0.316
0.000
0.000
0.000
0.351
0.000
0.000
0.000
0.354
0.000
0.000
0.000
0.319
5
2.96212
5.291
0.853
0.108
1.512
1.708
0.852
0.130
2.162
2.722
0.776
0.132
4.727
7.698
1.385
0.108
6
-18000
0.000 -18000.000
0.166 -18000.000
0.000 -18000.000
0.187 -18000.000
0.000 -18000.000
0.181 -17999.932
0.366 -18000.000
0.159
7
0.00081
0.004
0.000
0.180
0.001
0.003
0.000
0.201
0.000
0.002
0.000
0.205
0.001
0.003
0.000
0.192
8
-43.1072
0.079
-43.116
0.418
-43.141
0.069
-43.139
0.421
-43.110
0.058
-43.116
0.417
-43.127
0.077
-43.118
0.405
9
29.2685
0.082
29.257
0.848
29.248
0.077
29.252
0.856
29.242
0.050
29.237
0.838
29.234
0.070
29.227
0.831
10 -86.3328
0.000
-86.333
0.345
-86.333
0.000
-86.333
0.374
-86.333
0.000
-86.333
0.371
-86.333
0.000
-86.333
0.352
11
0
0.000
0.000
0.429
0.000
0.000
0.000
0.445
0.000
0.000
0.000
0.448
0.000
0.000
0.000
0.430
12 -20215.6 413.376 -20236.784
0.347 -20394.018 574.904 -20400.028
0.354 -20219.684 400.092 -20262.397
0.342 -20127.910 437.990 -20105.401
0.333
13 -12749.1 224.486 -12715.448
0.638 -12831.546 272.120 -12789.526
0.649 -12691.113 189.801 -12608.879
0.641 -12842.591 265.292 -12847.348
0.629
14
3.87094
0.267
3.880
0.402
3.797
0.354
3.848
0.397
3.800
0.379
3.915
0.395
3.775
0.242
3.763
0.393
15 -29.3449
0.067
-29.350
0.528
-29.363
0.075
-29.372
0.546
-29.366
0.071
-29.367
0.546
-29.395
0.084
-29.408
0.531
16 -24.8807
0.722
-24.908
0.340
-25.108
0.964
-24.757
0.345
-25.025
0.920
-24.939
0.344
-25.044
0.885
-25.015
0.338
*1
6
8
7
6
9
6
9
0
6
11
8
0
10
6
13
10
*2
0.38
0.50
0.44
0.38
0.56
0.38
0.56
0.00
0.38
0.69
0.50
0.00
0.63
0.38
0.81
0.63
median value was achieved with weighted/unweighted degree for ten out of seventeen
problems, leaving betweenness and closeness with eight and seven cases.
For twenty variables (Table8.4), the best mean value was achieved in ten cases
out of sixteen by weighted degree centrality, in eight cases by betweenness and
unweighted degree and in seven cases by closeness. The best median value was
obtained in eleven cases by betweenness, ten, nine and seven cases by unweighted
degree, weighted degree and closeness respectively.
Results for 30 variables in Table8.5 show the best mean value obtained in ten cases
by unweighted degree, in nine cases by closeness and six cases by both weighted
degree and betweenness. The best median value was obtained in thirteen cases by
unweighted degree, nine cases by closeness, eight by betweenness and seven by
weighted degree.
Counting over all problem sizes, the best mean value was obtained in 55% of cases
by unweighted degree, in 51% cases by weighted degree, 49% by closeness and 47%
by betweenness. The best median value was obtained in 67% of cases by unweighted
degree, 55% by betweenness, 53% by weighted degree and 47% for closeness.
These results are quite tight. However, as can be observed from the tables, each
centrality performs markedly better for some of the problems and problem sizes,
while being outperformed by other centralities on the others. Hence each of the
centralities can be used more successfully on some, but not all, of the problems.
8.6
Conclusion
The Adaptive ABC based on the complex network analysis, using single vertex cen-
trality measure selectable as parameter, was utilized to conduct the experimentation
comparing the effects of different centrality measures on the algorithm performance
in this chapter. Four vertex centralities, Weighted Degree, Closeness, Betweenness
and Unweighted Degree, used as a choice of vertex centrality in the Adaptive ABC

8
Comparison of Vertex Centrality Measures in Complex Network Analysis …
175
algorithm, were evaluated on seventeen benchmark problems for problem dimension
of ten decision variables, and sixteen benchmark problems for twenty and thirty deci-
sion variables, summing up to 49 experiments for each centrality measure in total.
Each experiment was repeated 30 times to obtain the good statistical sample.
Theresultscomparingthemean,medianandstandarddeviationvalueshaveshown
that each of the four selected centralities outperforms the others for some of the
selected problems, while none of them strongly dominates the others. It can therefore
be concluded that each of the centrality option can be utilized successfully in different
type and size of problem. This suggests that the further steps for the future research
of this approach are either the utilization of the power of all at the same time, as
in the previously introduced ensemble Adaptive ABC algorithm, or some form of
self-adaptive mechanism to automatically determine the best possible choice of the
centrality measure parameter for the problem at hand.
References
1. Crepinsek, M., Liu, S.-H., Mernik, M.: Exploration and exploitation in evolutionary algorithms:
a survey. ACM Comput. Surv. 45(3) (2013)
2. Brest, J., Greiner, S., Boskovic, B., Mernik, M., Zumer, V.: Self-adapting control parameters
in differential evolution: a comparative study on numerical benchmark problems. IEEE Trans.
Evolut. Comput. 10(6), 646–657 (2006)
3. Qin, A.K., Huang, V.L., Suganthan, P.N.: Differential evolution algorithm with strategy adap-
tation for global numerical optimization. IEEE Trans. Evolut. Comput. 13(2), 398–417 (2009)
4. Yang, M., Cai Z., Li, C., Guan, J.: An improved adaptive differential evolution algorithm
with population adaptation. In: Proceedings of the 15th Annual Conference on Genetic and
Evolutionary Computation, GECCO 2013, New York, NY, USA, pp. 145–152. ACM (2013)
5. Halder, U., Das, S., Maity, D.: A cluster-based differential evolution algorithm with external
archive for optimization in dynamic environments. IEEE Trans. Cybern. 43(3), 881–897 (2013)
6. Zelinka, I., Davendra, D., Senkerik, R., Jasek, R.: Do evolutionary algorithm dynamics create
complex network structures? Complex Syst. 20, 127–140 (2011)
7. Davendra, D., Zelinka, I., Senkerik, R., Pluhacek, M.: Complex network analysis of discrete
self-organising migrating algorithm. In: Zelinka I., Suganthan, P.N., Chen, G., Snasel, V., Abra-
ham A., Rössler O., (eds.) Nostradamus 2014: Prediction Modeling and Analysis of Complex
Systems. Advances in Intelligent Systems and Computing, vol. 289, pp. 161–174. Springer
International Publishing, Berlin (2014)
8. Metlicka, M., Davendra, D.: Ensemble centralities based adaptive artiﬁcial bee algorithm. In:
IEEE Congress on Evolutionary Computation (CEC), Sendai, Japan (2015)
9. Davendra, D., Zelinka, I., Senkerik, R., Pluhacek, M.: Complex network analysis of evolu-
tionary algorithms applied to combinatorial optimisation problem. In: Krömer, P., Abraham,
A., Snášel, V. (eds.) Proceedings of the Fifth International Conference on Innovations in Bio-
Inspired Computing and Applications IBICA 2014. Advances in Intelligent Systems and Com-
puting, vol. 303, pp. 141–150. Springer International Publishing, Berlin (2014)
10. Zelinka, I., Saloun, P., Senkerik, R., Pavelch, M.: Controlling complexity. In: Zelinka, I.,
Sanayei, A., Zenil, H., Rssler, O.E. (eds.) How Nature Works. Emergence Complexity and
Computation, vol. 5, pp. 237–276. Springer International Publishing, Berlin (2014)
11. Zelinka, I., Davendra, D., Skanderova, L.: Visualization of complex networks dynamics: case
study. In: Becvar, Z., Bestak, R., Kencl, L. (eds.) NETWORKING 2012 Workshops. Lecture
Notes in Computer Science, vol. 7291, pp. 145–150. Springer, Berlin (2012)

176
M. Metlicka and D. Davendra
12. Zelinka, I., Skanderova, L., Saloun, P., Senkerik, R., Pluhacek, M.: Hidden complexity of
evolutionary dynamics: analysis. In: Sanayei, A., Zelinka, I., Rssler, O.E. (eds.) ISCS 2013:
Interdisciplinary Symposium on Complex Systems. Emergence Complexity and Computation,
vol. 8, pp. 29–46. Springer, Berlin (2014)
13. Fatih Tasgetiren, M., Suganthan, P.N., Pan, Q.-K.: An ensemble of discrete differential evolu-
tion algorithms for solving the generalized traveling salesman problem. Appl. Math. Comput.
215(9), 3356–3368 (2010)
14. Barrat, A., Barthélemy, M., Pastor-Satorras, R., Vespignani, A.: The architecture of complex
weighted networks. Proc. Natl. Acad. Sci. 101, 3747–3752 (2004)
15. Wang, J., Mo, H., Wang, F., Jin, F.: Exploring the network structure and nodal centrality of
china’s air transport network: a complex network approach. J. Transp. Geogr. 19(4), 712–721
(2011)
16. Karaboga, D., Basturk, B.: A powerful and efﬁcient algorithm for numerical function opti-
mization: artiﬁcial bee colony (ABC) algorithm. J. Glob. Optim. 39(3), 459–471 (2007)
17. Kennedy, J., Eberhart, R.: Particle swarm optimization. In: 1995 IEEE International Conference
on Neural Networks Proceedings, vol. 1–6, pp. 1942–1948 (1995)
18. Davendra, D., Zelinka, I., Bialic-Davendra, M., Senkerik, R., Jasek, R.: Discrete self-organising
migrating algorithm for ﬂow-shop scheduling with no-wait makespan. Math. Comput. Model.
57(1–2), 100–110 (2013)
19. Zelinka, I.: Soma - self-organizing migrating algorithm. New Optimization Techniques in
Engineering. Studies in Fuzziness and Soft Computing, vol. 141, pp. 167–217. Springer, Berlin
(2004)
20. Bagheri, A., Zandieh, M., Iraj Mahdavi, Yazdani, M.: An artiﬁcial immune algorithm for
the ﬂexible job-shop scheduling problem. Future Gener. Comput. Syst. Int. J. Grid Comput.
Escience 26(4), 533–541 (2010)
21. Zelinka, I., Oplatková, Z., Šeda, M., Ošmera, P., Vˇcelaˇr, F.: Evoluˇcní výpoˇcetní techniky -
principy a aplikace. BEN, Praha, 1. ˇceské vyd. edition (2009)
22. Whitley, D., Rana, S., Dzubera, J., Mathias, K.E.: Evaluating evolutionary algorithms. Artif.
Intell. 85(1–2), 245–276 (1996)

Chapter 9
Randomization and Complex Networks
for Meta-Heuristic Algorithms
Roman Šenkeˇrík, Ivan Zelinka, Michal Pluhacek, Adam Viktorin,
Jakub Janostik and Zuzana Kominkova Oplatkova
Abstract This chapter deals with the hybridization of the chaos driven heuristics
concept and complex networks framework for meta-heuristic. This research aims on
the experimental investigations on the time development and inﬂuence of different
randomization types, different strategies for Differential Evolution (DE) through the
analysisofcomplexnetworkasarecordofpopulationdynamicsandindicesselection.
The population is visualized as an evolving complex network, which exhibits non-
trivial features such as adjacency graph, centralities, clustering coefﬁcient and other
attributes showing efﬁciency of the network. Experiments were performed for dif-
ferent DE strategies, several different randomization types and simple test functions.
R. Šenkeˇrík (B) · A. Viktorin · J. Janostik · Z. Kominkova Oplatkova
Faculty of Applied Informatics, Department of Informatics and Artiﬁcial Intelligence,
Tomas Bata University in Zlín, Nad Stránˇemi 4511, 76005 Zlín, Czech Republic
e-mail: senkerik@fai.utb.cz
A. Viktorin
e-mail: viktorin@fai.utb.cz
J. Janostik
e-mail: janostik@fai.utb.cz
Z. Kominkova Oplatkova
e-mail: kominkovaoplatkova@fai.utb.cz
I. Zelinka
Department of Computer Science, Faculty of Electrical Engineering and Computer Science,
VŠB – Technical University of Ostrava, 17. listopadu 15, 708 33 Ostrava-Poruba, Czech Republic
e-mail: ivan.zelinka@vsb.cz
M. Pluhacek
Regional Research Centre CEBIA-Tech, Tomas Bata University in Zlín,
Nad Stránˇemi 4511, 76005 Zlín, Czech Republic
e-mail: pluhacek@fai.utb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_9
177

178
R. Šenkeˇrík et al.
9.1
Introduction
Currently, the utilisation of complex networks as a visualisation tool for the analysis
of population dynamics for evolutionary and swarm-based algorithms is becoming
an interesting open research task. The population is visualised as an evolving com-
plex network that exhibits non-trivial features – e.g. degree distribution, clustering,
centralities and in between. These features offer a clear description of the population
under evaluation and can be utilised for adaptive population as well as parameter
control during the metaheuristic run. The initial studies [1–3] describing the possi-
bilities of transforming population dynamics into complex networks, were followed
by the successful adaptation and control of the metaheuristic algorithm during the
run through the given complex networks frameworks [4–6].
This research represents the hybridisation of complex network frameworks using
the Differential Evolution (DE) [7].
Currently the DE is known as a powerful metaheuristic tool for many difﬁcult
and complex optimization problems. A number of modern DE variants have been
recently developed [8–10].
The organization of this chapter is following: Firstly, the motivation and the
concept of DE with complex network framework is brieﬂy described followed by
research workﬂow. Results, visualizations and conclusion follow afterwards.
9.2
Motivation
This research is an extension and continuation of the previous successful initial
experiment with transferring of the population dynamics of several variants of the
DEalgorithmappliede.g. totheﬂowshopschedulingproblem[2] andthepermutative
ﬂowshop scheduling problem [3]. The motivation for the research presented herein
can be summarised as follows:
• To brieﬂy discuss the possible utilisation of complex network attributes – e.g. adja-
cency graphs, centralities, clustering, etc. for adaptive population and parameter
control during the metaheuristic run.
• ToinvestigatethetimedevelopmentoftheinﬂuenceofindicesselectionsinsideDE.
• To experimentally investigate the impact of randomization type change to the
unique features of complex network created as the record of population dynamics
during the run of EA’s. To be more precise, this research investigates the inﬂuence
of different randomization variants for selection of individuals (indices) in DE
transferred into the complex network.
Related to the randomization issue, in this paper, the concept of chaos driven
DE strategy is experimentally investigated and hybridized with complex network
approach. A chaotic approach generally uses the chaotic map in the place of a pseudo
random number generator (PRNG) as the chaotic pseudo random number generator
(CPRNG).

9
Randomization and Complex Networks for Meta-Heuristic Algorithms
179
From the previous research with chaos driven DE [11], it follows that promis-
ing results were obtained through the utilization of Dissipative standard, Lozi, and
Burgers chaotic maps replacing the PRNG in DE. These discrete chaotic maps remain
averyintensesubject of researchintheareaof chaos drivenevolutionarycomputation
techniques thanks to their unique sequencing and other unique attributes.
The importance of randomization as a compensation of limited amount of search
moves is stated in the survey paper [12]. This idea has been carried out in subsequent
studies describing various techniques to modify the randomization process [13, 14],
where the sampling of the points is tested from modiﬁed distribution. The importance
and inﬂuence of randomization operations was also deeply experimentally tested in
simple adaptive parameter adjusting jDE strategy [15].
Finally regarding to the aforementioned facts, the aim of this research is to show
as to how different randomization, distribution of PRNG/CPRNG, sequencing of
pseudo-random numbers the time development during initial phase of optimization
aretransferredintocomplexnetworkanddiscusspossibleways,astohowtoimprove,
reset or change possible adaptation or learning process either through the random or
nonrandom processes inside heuristics.
9.3
Complex Networks Features
A complex network contains features, which are unique to the assigned problem.
These features are important markers for population used in Evolutionary/Swarm
based algorithms [2]. The following features are important for a quick analysis of
the network thus created.
9.3.1
Degree Centrality
Degree Centrality is deﬁned as the number of edges connected to a speciﬁc node.
Degree Centrality is an important distribution hub in the network since it connects
- and thereby, distributes most of the information ﬂowing through the network.
Together with the hybridisation of metaheuristic and complex network analysis, this
is one of the most important features under consideration. Using Degree Centrality,
one can actually analyse if stagnation or premature convergence is occurring within
the population. By analysing the graphs, it can be seen that the multiple nodes are
increasing (distinguished by their size), thereby emphasising their prominence in the
population - and, their effect in generating better individuals.

180
R. Šenkeˇrík et al.
9.3.2
Clustering Coefﬁcient
The average Clustering Coefﬁcient for the entire network is calculated from every
single local clustering coefﬁcient for each node. The Clustering Coefﬁcient of a
node shows how concentrated the neighbourhood of that node is. Mathematically,
it is deﬁned as the ratio of the number of actual edges between neighbours to the
number of potential edges between neighbours. For their utilisation in Computational
Intelligence, it is also very important to analyse the distribution of a clustering coef-
ﬁcient within an entire network, since we can assume that it can show the population
diversity, its compactness or tendency to form heterogeneous subgroups (subpopu-
lations).
9.3.3
Other Features
Network density and Network centralization are important features showing the
effectiveness of the network. Network density is deﬁned as a ratio of the number of
edges to the number of possible edges for particular node. Network centralization has
several deﬁnitions, but for EA’s research, it shows the possibility of creation nodes
with high degree values (hubs).
9.4
Differential Evolution with Complex Network
Framework
9.4.1
Canonical DE
DE is a population-based optimization method that works on real-number-coded
individuals [10]. DE is quite robust, fast, and effective, with global optimization
ability.
The basic concept of DE is to work with a randomly initialized population of
“vectors” - also known as “candidate solutions”, and which - in an evolutionary
manner, produce better solutions in future generations. This is due to mutation,
crossover, and elitism. In order to control the evolutionary process, DE uses four
control parameters – number of generations Gmax, population size NP, crossover rate
CR, and scaling factor F. Mutation, crossover, and elitism operations are repeated
NP times to produce the next generation G + 1 of candidate solutions until the ﬁnal
generation Gmax, is reached.

9
Randomization and Complex Networks for Meta-Heuristic Algorithms
181
9.4.1.1
Initialization
The control parameters are set by the DE user, and the initial population of NP
candidate solutions is randomly generated from an objective space.
9.4.1.2
Mutation
The mutation strategy used in canonical DE is “rand/1” and uses three mutually
different donor vectors at indexes r1, r2, and r3 (w.r.t. r1 ̸= r2 ̸= r3 ̸= i for vectors at
∀i ∈{1, 2, ..., NP}) from the current generation G population. The three vectors at
those indexes, using scaling factor F, are combined to produce mutated vector vi,G:
vi,G = xr1,G + F

xr2,G −xr3,G

.
(9.1)
9.4.1.3
Crossover and Elitism
Binomial crossover with the help of the CR value is used to produce trial vector
ui,G out of the original vector xi,G and trial vector vi,G, where index j is an index
of a component of a D-dimensional vector, ∀j ∈{1, 2, ..., D}, U [0, 1] and a ﬂoat-
ing point uniform random number generator between 0 and 1, and where jrand is a
randomly-generated index of a component which has to be selected from the mutated
vector:
u j,i,G =
 v j,i,G if U [0, 1] ≤CR or j = jrand
x j,i,G
otherwise
.
(9.2)
The objective function value of the trial vector, f (ui,G), is then compared with
the objective function value of original vector, f (xi,G); and if it is lower (in case
of minimization), the trial vector demonstrates elitism and is placed in the next
generation G + 1; otherwise, the original vector xi,G survives to the next generation:
xi,G+1 =
 ui,G if f

ui,G

< f

xi,G

xi,G
otherwise
.
(9.3)
In this research we have focused also on other most utilized DE strategy, which is
DE/Best/1/Bin, where only 2 indices are selected fully randomly and the third one
is given by the best individual solution in population and current generation G. The
strategy is given in (9.4).
vi,G = x Best + F

xr1,G −xr2,G

.
(9.4)

182
R. Šenkeˇrík et al.
9.4.2
DE with Complex Network Framework
In this research, we utilize the Adjacency graph approach in order to show the linkage
between different individuals in the population. Each individual in the population
can be taken as a node in the complex network graph, where its linkage speciﬁes the
successful exchange of information in the population. In each generation, the node
is only active for successful transfer of information i.e. if the individual is successful
in generating a new better individual, which is accepted for the next generation of
population.
In the case of DE algorithm, if the trial vector created either from three ran-
domly selected individuals (DE/Rand/1/Bin) or one Best and two random individuals
(DE/Best/1/Bin) is better than active individual, we establish connections between
new created individual and three sources; otherwise no connections are recorded to
the Adjacency matrix.
9.4.3
Randomization in DE - Concept of ChaosDE
The general idea of ChaosDE and CPRNG is to replace the default PRNG with the
discrete chaotic map. As the discrete chaotic map is a set of equations with a static
start position, in order to have different start positions for different experiments, a
random start position of the map has to be generated. Once the start position of the
chaotic map has been obtained, the map generates the next sequence using its current
position.
In this research an integer type of numbers is required in ChaosDE for selection
of indices for mutation, thus simple transformation techniques for chaotic pseudo
random sequences are used to obtain pseudorandom values between the speciﬁed
ranges.
Following three discrete dissipative chaotic maps were used as the multi-chaotic
pseudo random generators for ChaosDE: Dissipative standard map (9.5), Burgers
map (9.6), and Lozi map (9.7). Control parameters were set as suggested in [16, 17].
Xn+1 = Xn + Yn+1(mod2π)
Yn+1 = bYn + k sin Xn(mod2π)
(9.5)
Xn+1 = aXn −Y 2
n
Yn+1 = bYn + XnYn
(9.6)
Xn+1 = 1 −a |Xn| + bYn
Yn+1 = Xn
(9.7)

9
Randomization and Complex Networks for Meta-Heuristic Algorithms
183
Fig. 9.1 Histogram of the
distribution of real numbers
transferred into the range <0
– 1> generated by means of
the chaotic Dissipative
standard map – 5000 samples
0.2
0.4
0.6
0.8
1.0
Value
50
100
150
200
250
300
350
Frequency
Fig. 9.2 Histogram of the
distribution of real numbers
transferred into the range <0
– 1> generated by means of
the chaotic Burgers
map – 5000 samples
0.2
0.4
0.6
0.8
1.0
Value
500
1000
1500
Frequency
Fig. 9.3 Histogram of the
distribution of real numbers
transferred into the range <0
– 1> generated by means of
the chaotic Lozi map – 5000
samples
0.2
0.4
0.6
0.8
1.0
Value
100
200
300
400
Frequency
where maps parameter settings are: b = 0.1 and k = 8.8 (for Dissipative standard
map), a = 0.75 and b = 1.75 (for Burgers map), and ﬁnally a = 1.7 and b = 0.5 for
Lozi map (Fig.9.2).
The illustrative histograms of the distribution of real numbers transferred into the
range ⟨0, 1⟩generated by means of studied chaotic maps are in Figs.9.1, 9.2 and 9.3.

184
R. Šenkeˇrík et al.
9.5
Research Workﬂow
The novelty of this research represents the experimental investigation on the time
development of the complex network and inﬂuence of four different randomization
types transferred into the complex network analysis for DE algorithm. The experi-
ment encompasses two main case studies:
1. Closer look on the time development of the complex network analysis with
uniform randomization – default PRNG, for the strategies DE/Rand/1/Bin and
DE/Best/1/Bin and 3 different ﬂoating time windows: the ﬁrst 10, middle 10 and
the last 10 generations.
2. Complex network analysis with four different randomizations (uniform – default
PRNG, and three chaotic) for the strategies DE/Rand/1/Bin and DE/Best/1/Bin.
9.6
Experiment Design
For the purpose of generation of complex networks and experimental investigations,
Schwefel’s test function (9.9) (both case studies), and Ackley’s original function (9.8)
(only case study 2 – randomization) were used. Dimension was set to 30. Illustrative
3D plots of utilized test functions are depicted in Figs.9.4 and 9.5.
Fig. 9.4 Schwefel’s test function

9
Randomization and Complex Networks for Meta-Heuristic Algorithms
185
Fig. 9.5 Ackley’s test function
Fig. 9.6 Visualizations of complex networks graphs time development created by one run of canon-
ical DE strategy De/Rand/1/Bin. Schwefel’s function, NP = 50, Dim = 30; Time snapshots: The
ﬁrst 10 generations

186
R. Šenkeˇrík et al.
Fig. 9.7 Visualizations of complex networks graphs time development created by one run of canon-
ical DE strategy De/Rand/1/Bin. Schwefel’s function, NP = 50, Dim = 30; Time snapshots: Middle
10 generations
f (x) = 418.9829 · D−
D

i=1
−xi sin(

|x|)
(9.8)
Function minimum:
Position for En: (x1, x2…xn) = (420.969, 420.969,…, 420.969)
Value for En: y = 0, xi ∈⟨-500,500⟩
f (x) = −20 exp

−0.02

1
D
	D
i=1 (xi)2

−
exp

1
D
	D
i=1 cos 2π (xi)

+ 20 + exp (1)
(9.9)
Function minimum: Position for En: (x1, x2…xn) = (0, 0,…,0)
Value for En: y = 0, xi ∈⟨–30,30⟩

9
Randomization and Complex Networks for Meta-Heuristic Algorithms
187
Fig. 9.8 Visualizations of complex networks graphs time development created by one run of canon-
ical DE strategy De/Rand/1/Bin. Schwefel’s function, NP = 50, Dim = 30; Time snapshots: The
last 10 generations
Experiments were performed in the environment of C++ language, canonical
DE (with uniform - default randomization) therefore used the built-in C language
pseudo random number generator Mersenne Twister C representing traditional
pseudorandom number generators in all comparisons. The data from the DE runs
were analyzed and visualized in software Cytoscape. The maximum number of gen-
erations control parameter was ﬁxed at 50 with the population size NP = 50. This
allowed the possibility to analyze the progress of all studied DE variants within a
limited number of generations and cost function evaluations. Two DE control para-
meters for mutation and crossover were set identically for the both ChaosDE and
canonical DE (F = 0.5 and CR = 0.8).

188
R. Šenkeˇrík et al.
Fig. 9.9 Visualizations of complex networks graphs created by one run of Chaos DE/canonical DE
strategy De/Rand/1/Bin. Schwefel’s function, max.Gen = 50, NP = 50, Dim = 30; Randomizations
types: Canonical DE with uniform default PRNG (upper left), ChaosDE with Dissipative standard
map (upper right), ChaosDE with Lozi map (below left), ChaosDE with Burgers map (below right)
The visualizations of complex networks are depicted in Figs.9.6, 9.7, 9.8, 9.9
and 9.10 containing Adjacency graphs for particular case study. The value of Degree
centrality is highlighted by the size of the node, and the coloring of the node is
related to the distribution of Clustering coefﬁcient (light color-lower values through
blue/green to the red colors – higher values).
9.7
Case Study 1: Time Development of Complex Networks
For the time development closer look (simple case study 1) three different time
snapshots of complex network were visualized and analyzed. The ﬁrst 10 (Fig.9.6),
middle 10 (Fig.9.7) and the last 10 (Fig.9.8) generations. Since these small time
snapshots can be very dynamic for the one metaheuristic run and to conﬁrm the
robustness of presented approach, simpliﬁed average results of 10 runs are present in
Tables9.1 and 9.2. The theoretical maximum number of edges in the graph is given
by 3*NP*10 = 1500, i.e. the situation, when every active individual in population is
replaced by newly created one from three another individuals across limited number
of observed 10 generations.

9
Randomization and Complex Networks for Meta-Heuristic Algorithms
189
Fig. 9.10 Visualizations of complex networks graphs created by one run of Chaos DE/canonical DE
strategy De/Best/1/Bin. Schwefel’s function, max.Gen = 50, NP = 50, Dim = 30; Randomizations
types: Canonical DE with uniform default PRNG (upper left), ChaosDE with Dissipative standard
map (upper right), ChaosDE with Lozi map (below left), ChaosDE with Burgers map (below right)
Table 9.1 Time Development of complex networks created by canonical DE strategy De/Rand/
1/Bin, Schwefel’s function
Case
Avg. No. of edges
Avg. Success rate (%)
Avg. Clustering
coefﬁcient
First 10 gen.
558
37.20
0.390
Middle 10 gen.
468
31.20
0.341
Last 10 gen.
435
29.00
0.334
Table 9.2 Time Development of complex networks created by canonical DE strategy De/Best/
1/Bin, Schwefel’s function
Case
Avg. No. of edges
Avg. Success rate (%)
Avg. Clustering
coefﬁcient
First 10 gen.
1068
71.20
0.590
Middle 10 gen.
684
45.60
0.541
Last 10 gen.
612
40.80
0.484

190
R. Šenkeˇrík et al.
9.8
Case Study 2: Randomization Inﬂuence to DE
Strategies
For the randomization issue (case study 2) we have analyzed only one run of DE for
particular DE strategy and randomization type, no statistical results related to the cost
function values and no comparisons are given here, as it is not possible to compare
heuristic algorithms only from one run. The reason for analyzing only one run of DE
is to show direct inﬂuence of randomization for the complex network structure and
to analyze results more deeply for higher number of generations (not only ﬂoating
time-window). Analyses of the networks are given in Tables9.3, 9.4, 9.5 and 9.6.
These tables contain values of total number of edges in the graph (NE), the success
rate of evolution process (SR) in percentage showing the ratio between maximum
possible edges in graphs and the actual one. The theoretical maximum number of
edges in the graph is given by 3*NP*Generations = 7500, i.e. the situation, when
every active individual in population is replaced by newly created one from three
another individuals across all generations. Furthermore, the Tables9.3, 9.4, 9.5 and
9.6 show interesting complex networks properties as average clustering coefﬁcient
(Avg. CC), network centralization (NC) and density (ND); and avg. no. of neighbours
of nodes (Avg. NN); (See Sect.9.3 for details). Visualizations of created networks are
in Fig.9.9 and 9.10. The graphical outputs for Ackley’s test function are not present
here. Nevertheless, the differences between two studied test functions are visible
from numerical analysis presented in Tables9.3, 9.4, 9.5 and 9.6.
Table 9.3 Simple statistics of complex networks created by Chaos DE/canonical DE strategy
De/Rand/1/Bin, Schwefel’s function
Case
NE
SR (%)
Avg. CC
NC
Avg. NN
ND
Canonical DE - Uniform
1482
19.76
0.689
0.134
33.72
0.688
ChaosDE - Dissipative map 1371
18.28
0.690
0.196
33.76
0.689
ChaosDE – Lozi map
1497
19.96
0.715
0.174
33.80
0.690
ChaosDE – Burgers map
1650
22.00
0.677
0.427
28.92
0.590
Table 9.4 Simple statistics of complex networks created by Chaos DE/canonical DE strategy
De/Best/1/Bin, Schwefel’s function
Case
NE
SR (%)
Avg. CC
NC
Avg. NN
ND
Canonical DE - Uniform
3234
43.12
0.948
0.058
46.28
0.944
ChaosDE - Dissipative map 3351
44.68
0.946
0.060
46.16
0.942
ChaosDE – Lozi map
3363
44.84
0.941
0.066
45.88
0.936
ChaosDE – Burgers map
3594
47.92
0.937
0.071
45.68
0.932

9
Randomization and Complex Networks for Meta-Heuristic Algorithms
191
Table 9.5 Simple statistics of complex networks created by Chaos DE/canonical DE strategy
De/Rand/1/Bin, Ackley’s function
Case
NE
SR (%)
Avg. CC
NC
Avg. NN
ND
Canonical DE - Uniform
813
10.84
0.483
0.163
23.32
0.476
ChaosDE - Dissipative map
879
11.72
0.524
0.262
24.68
0.504
ChaosDE – Lozi map
702
9.36
0.492
0.246
20.44
0.417
ChaosDE – Burgers map
1140
15.02
0.620
0.520
23.56
0.481
Table 9.6 Simple statistics of complex networks created by Chaos DE/canonical DE strategy
De/Best/1/Bin, Ackley’s function
Case
NE
SR (%)
Avg. CC
NC
Avg. NN
ND
Canonical DE - Uniform
2934
39.12
0.924
0.084
45.04
0.919
ChaosDE - Dissipative map 2925
39.00
0.926
0.079
45.28
0.924
ChaosDE – Lozi map
2850
38.00
0.916
0.095
44.52
0.909
ChaosDE – Burgers map
2514
33.52
0.882
0.134
42.72
0.872
9.9
Results
Presented graphical and numerical data has fully manifested the inﬂuence of time
frameselectiontothefeaturesofcreatedcomplexnetwork.Thesefeaturescanbeused
in various adaptive or learning processes. Figure9.6 shows, that from the beginning
of evolutionary process there are no signiﬁcant effects in the network, since the
evolution itself is very successful from the start. Later on, the clusters, structures
of hubs supporting generation of succesfull solutions are more visible and can be
detected in the network and used for controlling of the metaheuristic.
Results also lend weigh to the argument that through the transferring of population
dynamics into the complex network, the inﬂuence of the different randomization with
connectiontoDEhasbeenrevealed.Therandomizationtypeshaveutilizedincreasing
chaotic dynamics from none (default uniform) through Dissipative standard map,
Lozi map to Burgers map (Figs.9.1,9.2 and9.3). The general ﬁndings related mostly
to the randomization issue can be summarized as follows:
• Transferring of the PRNG/CPRNG Distribution: Adjacency graphs (Fig.9.9) in
case study 2 for DE/Rand/1/Bin strategy, where all indices for trial vector are
selected fully randomly, show that degree centrality is very closely related to
the distribution of CPRNGs (Figs.9.1,9.2 and9.3). Whereas for DE/Best/1/Bin
strategy (Fig.9.10), where only two indices are selected randomly and the “best”
component in trial vector helps in better progress towards global extreme, the
traces of distribution transferred into complex networks are suppressed (See
pairs of Tables9.3, 9.4, 9.5 and 9.6). Nevertheless, still the inﬂuence of different
PRNG/CPRNG distribution can be visible through Network centralization feature.

192
R. Šenkeˇrík et al.
• Clustering Coefﬁcient: Together with the increase of chaotic dynamics in DE, the
distribution of clustering coefﬁcient is changing (even though the average value for
entire networks remains similar). Clustering is inﬂuenced due to the trial vectors
donors indices choosing distribution changes. This is clearly visible in Figs.9.11
and 9.12. Strong chaotic dynamics and sequencing may cause occurrence of clus-
tering inside population with either positive or negative impacts (diversiﬁcation
or stagnation in local extremes). Thus utilization of such a complex network fea-
ture has conﬁrmed ﬁndings from previous research, that strong chaotic dynamics
causes either strong progress towards global extreme or tendency to premature
stagnation.
• Total number of edges and avg. number of neighbours could give fast information
about success rate of evolution process and level of involvement of individuals
in population. We can easily pre-calculate the theoretical max. value of edges
in network with 100% success, thus it is possible to use this value for accuracy
improvement of adaptation or learning processes inside heuristic. On the other side
Avg. numbers of neighbours can be used for injection/removing or regeneration
of individuals in population.
• An interesting phenomenon was discovered in relation between clustering coef-
ﬁcient and degree centrality in higher chaotic (not-uniform randomization) envi-
ronment. Nodes (individuals) with higher degree centrality value thanks to the
not-uniform distribution mostly have the lowest values of clustering coefﬁcient.
This will require further research.
Fig. 9.11 Distribution of clustering coefﬁcient, case study 2, uniform randomization, Schwefel’s
function

9
Randomization and Complex Networks for Meta-Heuristic Algorithms
193
Fig. 9.12 Distribution of clustering coefﬁcient, case study 2, Burgers map randomization, Schwe-
fel’s function
• Results for the both test functions are on similar level, thus the robustness of
complex network approach might indicate this way.
9.10
Conclusions
This work was aimed at the experimental investigation on time development of com-
plex network and the inﬂuence of different randomization to the complex network
analysis of the population dynamics for DE algorithm. The population is visualized
as an evolving complex network, which exhibits non-trivial features. These features
can be used during the run of EA’s in various adaptive or learning processes, alterna-
tion, suppression or strengthening of driving randomization, changing and adaptation
of accessible parameters of chaotic systems used as CPRNGs, and many more.
This modern topic brings many open tasks, which will be solved in future research.
Another advantage is that this complex network framework can be used almost on
any evolutionary computation technique.
Acknowledgements This work was supported by the GACR Grant Agency of the Czech Republic
Project No.: P103/15/06700S; further, by the Ministry of Education, Youth and Sports of the Czech
Republic within the National Sustainability Programme, Project No.: LO1303 (MSMT-7778/2014)
and the RDF – CEBIA-Tech Project No.: CZ.1.05/2.1.00/03.0089; and by the Tomas Bata University
Internal Grant Agency Project No.: IGA/CebiaTech/2017/004. This work was also supported by
COST Action 15140.

194
R. Šenkeˇrík et al.
References
1. Zelinka, I., Davendra, D., Lampinen, J., Senkerik, R., Pluhacek, M.: Evolutionary algorithms
dynamics and its hidden complex network structures. In: Evolutionary Computation (CEC),
2014 IEEE Congress on, pp. 3246–3251. (2014)
2. Davendra, D., Zelinka, I., Metlicka, M., Senkerik, R., Pluhacek, M.: Complex network analysis
of differential evolution algorithm applied to ﬂowshop with no-wait problem. In: Differential
Evolution (SDE), 2014 IEEE Symposium on, pp. 1–8. (2014)
3. Davendra, D., Zelinka, I., Senkerik, R., Pluhacek, M.: Complex network analysis of evolu-
tionary algorithms applied to combinatorial optimisation problem. In: Kromer, P., Abraham,
A., Snasel, V. (eds) Proceedings of the Fifth International Conference on Innovations in Bio-
Inspired Computing and Applications IBICA, pp. 141-150. Springer International Publishing,
Berlin (2014)
4. Skanderova, L., Fabian, T.: Differential evolution dynamics analysis by complex networks.
Soft Comput. (2015). https://doi.org/10.1007/s00500-015-1883-2
5. Metlicka, M., Davendra, D.: Ensemble centralities based adaptive Artiﬁcial Bee algorithm. In:
Evolutionary Computation (CEC), 2015 IEEE Congress on, pp. 3370–3376. (2015)
6. Gajdos P, Kromer P, Zelinka I.: Network visualization of population dynamics in the differential
evolution. In: Computational Intelligence, 2015 IEEE Symposium Series on. pp. 1522–1528.
(2015)
7. Price, KV.: An introduction to differential evolution. In: Corne, D., Dorigo, M., Glover F (eds)
New Ideas in Optimization. pp 79–108. McGraw-Hill Ltd. (1999)
8. Qin, A.K., Huang, V.L., Suganthan, P.N.: Differential Evolution Algorithm With Strategy
Adaptation for Global Numerical Optimization. Evolut. Comput. IEEE Trans. 13(2), 398–417
(2009)
9. Mallipeddi, R., Suganthan, P.N., Pan, Q.K., Tasgetiren, M.F.: Differential evolution algorithm
with ensemble of parameters and mutation strategies. Appl. Soft Comput. 11(2), 1679–1696
(2011)
10. Das, S., Mullick, S.S., Suganthan, P.N.: Recent advances in differential evolution an updated
survey. Swarm Evolut. Comput. 27, 1–30 (2016)
11. Senkerik, R., Pluhacek, M., Kominkova Oplatkova, Z., Davendra, D.: On the parameter settings
for the chaotic dynamics embedded differential evolution. In Evolutionary Computation (CEC),
2015 IEEE Congress on. pp. 1410–1417 (2015)
12. Neri, F., Tirronen, V.: Recent advances in differential evolution: a survey and experimental
analysis. Artif. Intell. Rev. 33(1–2), 61–106 (2010)
13. Weber, M., Neri, F., Tirronen, V.: A study on scale factor in distributed differential evolution.
Inf. Sci. 181(12), 2488–2511 (2011)
14. Neri, F., Iacca, G., Mininno, E.: Disturbed exploitation compact differential evolution for
limited memory optimization problems. Inf. Sci. 181(12), 2469–2487 (2011)
15. Zamuda, A., Brest, J.: Self-adaptive control parameters × randomization frequency and prop-
agations in differential evolution. Swarm Evolut. Comput. 25, 72–99 (2015)
16. Lozi, R.: Engineering of mathematical chaotic circuits. In Zelinka, I., Chen, G., Rosler, OE.,
Snasel, V. Abraham, A., (eds) Nostradamus 2013: Prediction, Modeling and Analysis of Com-
plex Systems, pp. 17–29. Springer International Publishing, Berlin (2013)
17. Sprott, J.C.: Chaos and Time-Series Analysis. Oxford University Press, USA (2003)

Chapter 10
Gallery of Evolutionary Networks
Ivan Zelinka, Roman Šenkeˇrík and Michal Pluháˇcek
Abstract This chapter is a graphical overview - a gallery of selected networks that
have been obtained during our experiments. The gallery contains samples coming
from different algorithms with attention on its beauty (as we hope) and shall serve
as the visual motivation-inspiration for new experiments. Visualization of those net-
works has been done on different principles with only one aim: to show a variety
of visualizations. Beside standard visualization, are present also visualizations like
community, degree centralities, etc.
10.1
Gallery of Networks
The gallery consists of various evolutionary networks and three kinds of visualiza-
tions. The ﬁrst one is, in fact, static visualization, i.e., network represent the history
of evolution in one picture when it ends or represents the state of evolution after
certain time frame. Typical examples of this approach are Figs.10.1 and 10.11. The
second here applied on particle swarm optimization, shows the network that reﬂects
time development (usually since beginning to the end of evolution) of the algorithm.
It is depicted in the Figs.10.12, 10.13, 10.14, 10.15, 10.16, 10.17, 10.18 and 10.19.
Each color represents different time frame. The start is on the left and end on the
right. Linked are only local particles with itself in the previous iteration and with
the globally best particle. The last, third one, shows different visualizations of one
I. Zelinka (B)
Department of Computer Science, Faculty of Electrical Engineering and Computer Science,
VŠB – Technical University of Ostrava, 17. listopadu 15,
708 33 Ostrava-Poruba, Czech Republic
e-mail: ivan.zelinka@vsb.cz
R. Šenkeˇrík · M. Pluháˇcek
Department of Informatics and Artiﬁcial Intelligence, Faculty of Applied Informatics, Tomas Bata
University in Zlín, Nad Stránˇemi 4511, 76005 Zlín, Czech Republic
e-mail: senkerik@fai.utb.cz
M. Pluháˇcek
e-mail: pluhacek@fai.utb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_10
195

196
I. Zelinka et al.
Fig. 10.1 Ant colony optimization
algorithm as the network with different visualizations e.g. degree centrality, commu-
nities, etc. The SOMA algorithm has been used here, Figs.10.20, 10.21 and 10.22.
Another algorithms are visualized on Figs.10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8,
10.9 and 10.10.

10
Gallery of Evolutionary Networks
197
Fig. 10.2 Self-organizing migrating algorithm

198
I. Zelinka et al.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Fig. 10.3 Self-organizing migrating algorithm. The yellow individual is the best individual (the
most improved individual during the evolution - has the most incoming edges), green are balanced
(the same in-coming and out-coming number of edges), ping has more out-coming and white only
out-coming edges (newer has been improved)

10
Gallery of Evolutionary Networks
199
Fig. 10.4 Self-organizing migrating algorithm in 3D

200
I. Zelinka et al.
Fig. 10.5 Network based on swarm virus dynamics

10
Gallery of Evolutionary Networks
201
Fig. 10.6 Differential evolution

202
I. Zelinka et al.
Fig. 10.7 Artiﬁcial bee colony

10
Gallery of Evolutionary Networks
203
Fig. 10.8 Particle swarm - a total view

204
I. Zelinka et al.
Fig. 10.9 Particle swarm

10
Gallery of Evolutionary Networks
205
Fig. 10.10 Particle swarm
Fig. 10.11 Particle swarm

206
I. Zelinka et al.
Fig. 10.12 Particle swarm as the time developing system on Rastrigin test function in 10D
Fig. 10.13 Particle swarm as the time developing system on Rastrigin test function in 100D
Fig. 10.14 Particle swarm as the time developing system on Rosenbrock test function in 10D
Fig. 10.15 Particle swarm as the time developing system on Rosenbrock test function in 100D
Fig. 10.16 Particle swarm as the time developing system on Schwefel test function in 10D

10
Gallery of Evolutionary Networks
207
Fig. 10.17 Particle swarm as the time developing system on Schwefel test function in 100D
Fig. 10.18 Particle swarm as the time developing system on Sphere test function in 10D
Fig. 10.19 Particle swarm as the time developing system on Sphere test function in 100D

208
I. Zelinka et al.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
Fig.10.20 SOMAnetworkafter300migrations.Visualizedareonlyconnectionsthatwererenewed
> 10×. Three leading individuals are visible there (No. 2, 5 and 56)

10
Gallery of Evolutionary Networks
209
Fig. 10.21 Degree centrality from Fig.10.20

210
I. Zelinka et al.
Fig. 10.22 Community from Fig.10.20. Individuals No. 2, 5 and 56 visibly form small community
Acknowledgements The following grants are acknowledged for the ﬁnancial support provided
to this research: Grant Agency of the Czech Republic - GACR P103/15/06700S, Grant of SGS
No. SGS 2017/134, VSB-Technical University of Ostrava. The Ministry of Education, Youth and
Sports from the National Programme of Sustainability (NPU II) project “IT4Innovations excellence
in science - LQ1602”.

Part III
Miscellanies

Chapter 11
Swarm Virus, Evolution, Behavior
and Networking
Lubomir Sikora and Ivan Zelinka
Abstract In this chapter we would like to outline how behavior of malicious soft-
ware, i.e. computer virus can be connected with evolution and visualization of its
spreading as the network. The approach presented here is not based on single classi-
cal virus spreading, but more on hypothetical swarm virus and its dynamics of spread
in PC. The latest development of virus code shows, that CnC technology (command
and control) has been used as in the case of Stuxnet virus or Botnet malware. It is
logical to expect that development of the viral code will never stop at this level, but
will continue up to viruses that will evolve according to the Darwinian theory of
evolution and will mimic swarm in the nature, such as the swarm algorithms already
do. The aim of our research is not developing a swarm virus, but using its expectable
behavior we show that its dynamics can be then modeled as the network structure
and thus likely controlled and stopped, as our experiments in the ﬁrst part of this
book suggest. The same methodology can be used not only in laboratory conditions
on a single PC, but also on virus spreading over the network or Internet, if real data
is available. Ideas and results of this chapter were also presented on Post Graduation
in Cyber Security and Ciberdefense, Multinational Cyber Defence Education and
Training Project, NATO Smart Defence Project, Lisbon 2017.
11.1
Computer Virus - An Introduction
Theterm“virus”[1–6]isestablishedinsubconsciousofpeoplethemostandtherefore
it often refers to any type of inﬁltration, regardless of whether it really is a virus,
Trojan horse, or worm. Even some publications ignore this fact. The division of
L. Sikora (B) · I. Zelinka
Faculty of Electrical Engineering and Computer Science,
Department of Computer Science, VŠB – Technical University of Ostrava,
17. listopadu 15, 708 33 Ostrava-Poruba, Czech Republic
e-mail: lubomir.sikora@vsb.cz
I. Zelinka
e-mail: ivan.zelinka@vsb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_11
213

214
L. Sikora and I. Zelinka
inﬁltration is a problem, types of inﬁltrations often blend together. The following
division is therefore one of many options. The name is derived from certain biological
similarities with the original. Virus is capable of self-replication, but in the presence
of an enforceable host to which it is attached. Hosts can be for example executable
ﬁles, system area of the disc, or ﬁles that cannot be run directly but only by using
speciﬁc applications (Microsoft Word, Visual Basic scripts, etc.). Once the host is
running (performing), it performs also the virus code. During this moment, the virus
usually attempts to provide further self-replication by attaching to other suitable
hosts. It has already happened a couple of times, that journalists were cheering the
discovery of the ﬁrst virus that can infect ﬁles and MP3 format JPEG. In this case,
we cannot talk about infection, but a simple completely unusable code (virus body)
to the above mentioned format. Since the body of the virus is not adhered to the
original code, the player (in the case of MP3) or viewer (JPEG) have no common
structure, consider the body of the virus as “garbage”. In addition, JPEG and MP3
are data formats, while the body of the virus is a binary code. A related issue is
understanding the difference between the size of the ﬁle and its extension. If we talk
about the size, we talk about the internal structure of a chosen extensions it may not
actually responsible. Therefore, there are cases where, for example, are infected ﬁles
with a DAT extension (otherwise completely uninteresting by the virus), but only on
the grounds that its internal structure corresponds to EXE ﬁle format speciﬁcation.
According to the site of action viruses are divided into further categories:
• A ﬁle virus - it is distributed in the form of executable code. File virus then
can create copies, overwrite other ﬁles (overwriting viruses), or connect to other
executable ﬁles (parasitic viruses). The basic principle of so called appending virus
is on Fig.11.1.
• Boot viruses - they attack master boot record and the boot sector of removable
media. The virus will start as soon as it passes BIOS boot. It is loaded into memory
(andbecomesmemoryresident),castsaddresssystemservicesand,ofcourse,takes
the original system.
• Script Viruses - viruses created with the scripting language of the system. It is
possible to use only those options that are accessible through scripting language.
They are saved as a script inside a batch ﬁle and these viruses can be very easy
written.
• Macroviruses - some programs allow the user to automate and simplify the work
using the “maker”. Ofﬁce applications most often provides this function. They are
thus similar to the script viruses, but they serve other than the operating system
software. Macroviruses function use only the parent program and the target macro
language.
Viruses can be stored in other ways - such as data structures, but they must be
implemented in the application in which they are intended to run, otherwise they
become worthless.
The emergence of the ﬁrst virus (Brain) dates back to 1986. It was written by
two brothers Basit Farooq Alvi and Amjads from Pakistan – Lahore. Reportedly,

11
Swarm Virus, Evolution, Behavior and Networking
215
Fig. 11.1 The basic principle of appending virus
they gave it as a bonus to foreigners who were illegally buying software from them.
Needless to say, it was a very good work (use of “stealth” technology), which caused
a number of local epidemics. Brain was a boot virus, spreading across the disc, when
starting PC in the drive. We should not forget the experiments of Mr. Frank Cohen,
who published an article “Computer Viruses: Theory and Experiments” in 1983. His
ﬁrst experiments with viruses took place on 10 September 1983 on VAX 11/750
under UNIX, above which he lost control after half an hour.
In 1987, he gradually discovered several viruses. Lehigh, Stoned, Vienna, Cas-
cade. The last one named became literally anecdote about his famous falling letters
on the screen (like the virus requesting biscuits). In 1988, the famous virus Jerusalem
appeared and as Eugene Kaspersky mentions in his book, number of experts could not
believe in the existence of computer viruses. Even the legendary Sam Peter Norton
(Norton Commander and author of Symantec products) stated that no viruses exist.
Surprising is that few years later he created the Norton Anti-Virus.
Another important date is November 1988 when Cornell University student -
Robert T. Morris launched his “Morris worm”. Worms attacked around 6000 Unix
computer (he reportedly had “somehow” got it out of control), he blocked the network
for 36h and, indirectly, this event touched millions of people. The worm even got
to the Lawrence Livermore National Laboratory, where scientists worked on the
clandestine nuclear program in NASA and the damage amounted to 100 million
USD. Year 1988 also began era of antivirus programs. One of the oldest is McAfee
VirusScan, as well as Dr. Solomon AVTK. The last mentioned was later bought by

216
L. Sikora and I. Zelinka
the ﬁrst one. In December 1989, about 20 thousand copies of the “AIDS Information
Diskette Version 2.0.” were sent. In fact it was a Trojan horse that undermined the
data on the disk after being launched more than 90 times. It also demanded payment
of 189 USD per P.O. box in Panama.
In1990,polymorphicvirusesbegantoappear,thevirusesforwhicheachspecimen
looks different “on the outside”. Existing anti-virus companies had to develop new
detection methods, because they formerly reliable way to search by character strings
proved to be not working already. Lots and lots of viruses originated on the territory
of Bulgaria. The biggest part of the whole production was created by person called
“Dark Avenger”. It is not surprising that in the same state the ﬁrst BBS designed
exclusively for the exchange of viruses and source codes was established. In addition
to polymorphic viruses ’stealth’ viruses are increasingly showing, i.e. viruses that
can camouﬂage in the system. Example could be the virus Frodo, which watched
handling of ﬁles and presented harmless versions of these in fact infected ﬁles to the
user or to the antivirus. Demonstrational virus was also the ﬁrst multipartite virus
Tequila in 1991. Multipartite viruses can attack the system area of the disc as well as
the ﬁles. Tequila was moreover polymorphic and stealth as well. 1992 was the year of
the generator. Ordinary users have could create a custom virus in matter of seconds.
It was only about setting the parameters of future virus (disseminated, speech, etc.),
pressing “generate” and new virus according to the deﬁned requirements was born.
Especially PS-MPC generator signiﬁcantly expanded, otherwise it is impossible to
explain why several thousands of viruses were generated in PS-MPC.
During 1994 appeared one of the legends - virus One Half.3544.A. This powerful
polymorphic and multipartite virus from Slovakia caused a sensation. The fact that
it could not be wholly detected by antiviruses made it very famous. Decryption algo-
rithm of One Half virus was divided into several interconnected “islands” that were
“scattered” through the infected ﬁle. Then widespread antivirus McAfee VirusScan
failed to overcome this obstacle and even several months later a signiﬁcant part of
specimen remained outside detection. One Half progressively encoded contents of
your hard disc by a particular key, which it was carrying. If the One Half was removed
(including the key), it also meant losses of the encoded data. Even though the rise of
Windows 95 operating system promised termination of computer viruses, the future
was predetermined by Form boot virus, which the company distributed on ﬂoppy
discs with Microsoft Windows 95 to beta testers.
In August 1995, the Concept - macro virus ﬁrst appeared, spreading out in the
documents created by Microsoft Word. Macro language in Microsoft products was
so enforced so that it was even possible to create a self-replicating program - macro
virus. Concept of macro virus belonged for a long time to the most common viruses
also due to the fact that antiviruses have not been prepared for that type of inﬁltration.
The relative calm prevailed at the owner’s Czech version of Word, since localization
affected the names of each function of the macro language! Concept and another
large group of macro viruses was not able to operate under the Czech Word. This
“problem” solved with airing of MS Ofﬁce 97.
The ﬁrst true virus for Windows 95 virus was Win95/Boza.A in early 1996.
Although this was not a miracle program (Boza was able to operate only under

11
Swarm Virus, Evolution, Behavior and Networking
217
certain versions of Windows 95 in certain language versions), Boza was impulse for
the emergence of other viruses for Windows and rejected the argument that with the
launch of Windows 95 came an era of faith. During 1996 appeared the ﬁrst macro
virus for Microsoft Excel - Laroux and later the so-called “cross” macro viruses able
to spread as a Word document as well as Excel workbooks. At the end of the year
the ﬁrst “memory resident” virus for Windows 95 - Win95/Punch appeared, who
survived in the memory as a VxD driver and infected all the opening PE EXE ﬁles.
Development increasingly continued so in 1998 the ﬁrst 32-bit polymorphic
viruses for Windows 9x - Win95/HPS and Win95/Marburg were created. In June
of 1998, the virus Win95/CIH began to spread, who was later named as “Cher-
nobyl” by the journalists. Virus “Chernobyl” was interesting that with each April
26 (depended on the variant) tried to wipe the Flash BIOS on the motherboard and
in addition part of the data on the disc. If erasing of Flash BIOS was successful,
then the computer was not able to operate. Other than interference into the hardware
could not to solve this problem. Virus Win95/CIH thus partially disrupted until then
reliable claim that the virus could not damage the hardware. On the other hand, it
was possible in most cases to effectively solve this problem. In the same year ﬁrst
scripted viruses appear, speciﬁcally VBS/Rabbit or HTML/Internal. A year later,
in 1999, similar scripts begin to appear in “mass-mailing”. This opens a new era
of viruses spread by e-mail. One of the ﬁrst viruses was e-mail Happy99, followed
by the famous Macroviruses W97M/Melissa.A@mm. Since it was a macro virus,
logically it had to steal a Word document with every spread.
11.2
Experiment Design and Prerequisites
In this section, we propose an idea of hypothetic swarm virus, its structure, and
functionality, in order to simulate the behavior of such virus. It is clear, that after
CnC kind of viruses, it is logical to expect that viruses based on swarm intelligence
are going to be developed in near future. To withstand such threats, it is important
to understand how, in principle, such virus can work and mainly, how its behavior
can be recorded, analyzed and visualized. A part of our research, published here, is
basedontheinterdisciplinaryfusionofmalwaretechnology,swarm-basedalgorithms
like Ant Colony Optimization (ACO) [7] and complex networks [8, 9]. In following
sections are subsequently discussed topics like hypothetical swarm virus structure, its
functionality (data storage, communication inside swarm, etc.) and its visualization
based on ACO principles. All experiments has been done in laboratory conditions
with safely modiﬁed prototype.
Similar research has already been done in papers like use fusion of virus and
evolutionary algorithms for optimization problems solution, [10, 11] and malware
dynamics analysis with different methods, [12–27]. As visible, e.g. [19, 27], prelim-
inary research on that ﬁeld (i.e. virus and complex network) has already been done.
However approach discussed in this chapter is of different nature because (a) swarm
virus has not been observed yet (ofﬁcially), (b) visualization of its dynamics is joined

218
L. Sikora and I. Zelinka
with visualization and analysis via complex networks/graphs. Results reported here
are preliminary and selected from [28].
11.2.1
Swarm Virus
Swarm virus is a virus utilizing some attributes of the swarm systems in nature, or
swarm algorithms. These algorithms mimic the behavior of some other organisms
like birds, ﬁsh, ants, etc. in given situation like hunting or searching [29]. In the
dynamics of these algorithms intelligent like behavior emerges coming from a crowd.
Currently, there is some such algorithms, namely Particle Swarm Optimization (PSO)
[30], Ant Colony Optimization (ACO) [7], Self-Organizing Migration Algorithm
(SOMA) [31] and many others. These algorithms have one feature in common.
Optimize or solve problems they are facing to; they use principles that are observable
in natural swarm systems. For example, ACO is very efﬁcient when solving network-
like problems, such as Traveling Salesman Problem. PSO or SOMA are, on the other
hand, excellent in ﬁnding extremes in continuous functions and could be used for
example for training an artiﬁcial neural network, when a minimal global error of
learning is needed. On the other side, there exists a similar class of algorithms (older
than swarm one) called evolutionary algorithms. These algorithms do the same thing,
but use different techniques based on Darwins theory of evolution, and use mutation
and crossbreeding on optimized solutions. Some of these algorithms are Differential
Evolution (DE) [32], Evolution Strategy (ES) [33]. To study hypothetical swarm virus
and its behavior, at least in some basic version it must be created. That brings some
questions/problems, that has to be solved. These are virus movement (i.e. traveling
through PC environment), communication between virus instances (remember, in the
swarm is more individuals that can be in different state of activation), decentralized
behavior (whole swarm can act asynchronously), data storing (how to store and share
important information about activity and success of each virus individual), and the
most important one: monitoring and visualization of its behavior pattern.
11.2.2
Dynamics of Spreading
The dynamics of the virus obviously depends on the environment, in which virus
exist. For example two different environments like the Internet (usually worms and
CnC malware) or just a ﬁle in an operating system (classical viruses, see Fig.11.1),
[6]. Moving (i.e. virus path) on the Internet could be done by email as it was done
many times before. In this category are viruses like Melissa, or Loveletter also known
as ILOVEYOU. To follow swarm dynamics, observed in nature and its computational
variants [29], then it is important to realize, that swarm dynamics could be inﬂuenced
by using well-known techniques like prepending, appending or inserting into *.exe
ﬁles. Such virus spreading technologies must be done not only by infecting victim

11
Swarm Virus, Evolution, Behavior and Networking
219
ﬁle but also cleaning of this ﬁle when the virus is leaving it. It is important to realize,
that there is one difference between a simple virus and hypothetical swarm virus.
While classical virus spreads itself throughout PC and occupies all possible hosts
ﬁles, swarm virus behaves similarly as the worm its instances (i.e. individuals) jump
over the ﬁles in PC to fulﬁll its task. If the philosophy of jumping is not followed
and virus leaves its copies on all visited ﬁles/hosts, the virus becomes overpopulated,
and after a while, it will be difﬁcult to ﬁnd an uninfected host. If we need to operate
all virus instances simultaneously, too many virus instances could cause slowing
down the system and subsequent detection. Another difﬁculty is that if we move to
another host, the new virus instance does not have any data like previous location,
its quality (i.e. local extreme). If something interesting is detected, virus ID is used
to distinguish the virus instances from each other. ID is particularly useful when
debugging or for further behavior analysis, or scrum-based behavior like virus with
ID = 4 have to perform something, or contract-based behavior like someone has
to do this job and virus with ID = 7 accepts it. Command line arguments are used
for this data transaction between virus and its instances move. We can parse these
arguments and set some properties in new virus instance.
11.2.3
Communication
In communication, two options are there. The ﬁrst one is that every virus can create
an offspring (new virus instance) with a set of commands, distributed to it also
by command line arguments. It can have implemented few classes responsible for
behavior with the same interface and use command line arguments to tell which
one to instantiate. This behavior can be then classiﬁed like payload. We can specify
which one to instantiate by its ID. We can use this technique to determine other
aspects of behavior such as so-called infector or classes responsible for swarming
which is described later. In experiments reported here, this behavior has been used.
Anotherwayofcommunicationcouldbefeasiblebyusinganothersharedﬁle.That
ﬁle can contain commands what to do or contracts i.e. another important information
for swarm virus. As stated before, commands are lines such as Virus with ID = 1,
do something harmful to a ﬁle with path C:\Windows\System32\Something
Important.exe. Contracts are lines such as: someone do something harmful with
ﬁle C:\Windows\System32\SomethingImportant.exe. Both options are
applicable. In a swarm virus, multiple virus instances are there. System startup acti-
vates none of them (of course, it can be as well as by another system events). By
double clicking some infected host, other virus instances are wakened up. Assuming
that locations where other sleeping virus instances are, command line arguments
can be used to wake them up. For this is necessary to execute a host ﬁle, both virus
and the host ﬁle are executed then. So the initiating ﬁle must tell others to skip this
procedure because it belongs only to user executed host.

220
L. Sikora and I. Zelinka
The another difﬁculty to solve is a ﬁle access synchronization. The virus instances
are decentralized so that multiple ﬁle access can occur. It can be solved simply by
using ALOHA-like collision protocol, i.e. wait for the random amount of time to try
access to the given ﬁle.
11.2.4
Decentralized Behavior
In a hypothetical swarm, the virus can be expected centralized as well as decentralized
behavior. Let’s to be focused on decentralized one. When writing a swarm virus
algorithm, cycles to iterate throughout each virus/individual, are used. The behavior
for one instance is written-determined, and then its execution terminates. When
combined behavior of all swarm viruses prototype (SPV), then the ﬂowchart - states
of SVP and its transitions looks like in Fig.11.2. Let’s describe them closely now.
• Wake state: This state occurs when none of other virus instances are operating.
User executed host ﬁle sends a signal to others to wake up as described in the
section Communication.
• Infection state: This state can be implemented this way: create as many instances
as there is a total of N. It is also a defense mechanism in case antivirus recognizes
some of the virus instances and sends them to a chest. So this state maintains
constant count of the virus instances.
• Execution state: This is the just payload of the virus. This state operates only when
a trigger is pulled. If it is not, this state is ignored.
• Move state: All swarming logic is implemented in this state. Detailed description
can be found in section Behavior pattern.
Fig. 11.2 Virus instance behavior pattern

11
Swarm Virus, Evolution, Behavior and Networking
221
• Heal state: As stated in section Dynamics of spreading, there is need to remove
the old virus instance, thus instance occupying a ﬁle we want it to move from to
the next host.
The virus starts execution in various manners. If it was the very ﬁrst start after
operating system starts up, the execution begins in the Wake state. If the virus instance
was awakened by other virus instance, an execution in Infection state should be
started. If the virus instance was created and then started in consequence of moving
(i.e. leave ﬁle/host to jump/infect another one), we want to start in Heal state. More
complex virus behavior, using this ﬁnite automaton technique, can be created. This
way of implementing swarm virus is also development friendly, and it is easy to
imagine individual behavior from the general point of view.
11.2.5
Data Storing and Manipulation
This part is more about virus writing and sharing virus gathered experiences rather
than swarm intelligence. The remote server to communicate with SVP can be used,
but it can produce the suspicious amount of trafﬁc and premises to be online all the
time. Also, the probability to be revealed by antivirus is high. Another way is to use
alternate streams. These streams are hidden to the user, and most antiviruses do not
check them, but the user must have an NTFS ﬁle system. Alternate streams look like
a usual path but end with a colon followed by ﬁlename with data. It can look like
this: C:\Windows\System32\SomeFile.exe:hiddenData.txt. If you
use this technique, there is no way to distribute this virus with a memory stick, as
they are not usually formatted to the NTFS ﬁle system. Another way is using shadow
copy. The data is deleted and cannot appear in windows explorer, but physically it is
present in the storage.
11.2.6
Behavior Pattern - A Virus Network
Lets talk about behavior pattern because this is the most signiﬁcant topic in SVP
analysis and visualization. As it was said before, suitable behavior patterns come
from swarm intelligence algorithms like Particle Swarm Optimization, Ant Colony
Optimization or others. If SVP moves around in the ﬁle system, its tree structure is
not a suitable environment to move coordinately. In the tree structure, there are lots of
dead ends and no cycles. A good strategy to avoid this problem is to transform this tree
structure into some graph with cycles. It was tested in a way which uses Ant Colony
Optimization together with Bianconi–Barnabsi model that produces networks like
the one you can see in the Fig.11.3, [8, 9]. Simply, the tree ﬁle structure is mapped
into a complex network like structure.

222
L. Sikora and I. Zelinka
Fig. 11.3 Model of attaching
Figures11.4, 11.5 and 11.6 represents ﬁrst examples of such SVP network reﬂect-
ing its behavior. The intensity of the color represents a weight of an edge given by
1/distance in the ﬁle system. The distance is measured by the number of folders
between ﬁles (edges) +1. For example:
• Distance (C:/a/b.exe, C:/a/b.exe) = 0
• Distance (C:/a/b.exe, C:/a/e.exe) = 1
• Distance (C:/a/b.exe, C:/e.exe) = 2
• Distance (C:/a/b.exe, C:/d/e.exe) = 3
There are a few nodes in the network, which have more neighbors than others.
These nodes are more important and have greater ﬁtness value. Bianconi–Barnabsi
model produces community graphs. The basic model works on the principle that
some basic small graph exists as well as a set of vertexes that shall be added to it.
The ﬁrst link of the new vertex is attached to a random vertex i1 of the network.
The second link is attached to a random vertex of the network with a probability
1 −p, while with the probability p is attached to a node chosen randomly among
the neighbors of the node i1. The whole process of attaching new vertex is shown
in Fig.11.3. This model has two values to set. The probability p, and the number m
which determines how many links to attach for each new vertex. Bianconi–Barnabsi
model is enhanced with ﬁtness in this research chapter. It means that some vertexes

11
Swarm Virus, Evolution, Behavior and Networking
223
Fig. 11.4 Example of a network building
in the network are preferred more than others when creating a new link. The ﬁtness
is a value representing the quality of the ﬁle based on given objective, as ﬁles that are
bigger than the others or are executed more often than the others. These ﬁles become
centers in the network. That means they have many neighbors.
General network building process can be described as follows:
• Random initial spread of the virus instances in the ﬁle system.
• For each virus instance:
– Update TabooList (TabooList is a list of recently visited vertexes. Its purpose is
to prevent against circular movement amongst a small number of locations. Its
length is set to n, which means the virus instance must visit at least n different
vertexes in row).
– Map neighborhood (ﬁnding nearby host ﬁles).
– Add each host ﬁle, or some number of them from neighborhood into network,
if it has not been there yet.
– Vaporize pheromone from all edges
– Use any behavior pattern to determine where to move next.

224
L. Sikora and I. Zelinka
Fig. 11.5 The network after 5 iterations of 5 ants
– Add some additional links from that new location the way it is described in
Bianconi–Barnabasi model (ﬁrst link was not attached to random vertex, but to
actual position the virus instance currently stands)
– Lay pheromone between current and next vertex.
– Move to newly chosen location.
A pheromone, to prioritize some edges, as in ACO [7] can be used. The whole
process is graphically described in the Fig.11.4. The process starts from the center
of the star.

11
Swarm Virus, Evolution, Behavior and Networking
225
Fig. 11.6 Another example of network. The vertex size represents an importance of the vertex (ﬁle
through has passed more viruses, etc.)
11.2.7
Experiment Environment and Programming
Language
The common programming languages for virus implementation is C, C++ or Assem-
bler. The swarm virus presented here was written in a higher programming language
– C#. The resulting size of the virus was much greater, thus not very convenient
for its viral purpose. However, it was very convenient for purposes related to our
research. It is not hard at all to write the code in C/C++ when the goal is a real swarm
virus designed in order not to be detected by an antivirus due to its size. The virus,

226
L. Sikora and I. Zelinka
discussed this chapter, was tested under Windows 10. In following lines, we describe
details of the code and explain, why the code looks the way it looks.
11.2.7.1
Modules
The main functionality of this swarm virus prototype is based on modules. In modules
there are actual implementations of the technology. In this swarm virus, there are six
modules. Namely Infector, Objective, Payload, Swarm, Trigger and Communication.
• Infector: the infector contains four methods. Infect, Heal, IsInfected, and GetO-
riginalData. The Infect method implements the simplest infection technique
among others, that is prepending. It is possible to use other techniques, but for
the sake of simplicity, the prepending technique was chosen. The Heal method
is responsible for healing the host ﬁle. It is used after moving to a new location.
The IsInfected method checks, whether the ﬁle is infected or not. It is unwanted to
infect an already infected ﬁle. The last method gets original data from the infected
ﬁle. It is used for starting the original program when the user executes a host ﬁle.
• Objective: this module contains two methods. The SuitablePaths returns paths in
the ﬁle system, which are used to initial spread of the virus. The Fitness method
evaluates a ﬁle. It tells how suitable the ﬁle is regarding what we want to infect. It
was a tested variant with ﬁtness being a size of the ﬁle., i.e. bigger ﬁlesize, bigger
ﬁtness.
• Payload: the module with this name contains one method: the Run. In this swarm
virus, the payload is just some console output with debugging information, to test
the swarm functionality. No destructive payload has been applied.
• Trigger: the trigger is a just predicate if the payload should be performed. If the
condition is not satisﬁed, the whole execution state is ignored.
• Communication: module responsible for communication with external sources and
parsing signals. Its functionality is described in the next section.
• Swarm: this module contains the only method - NextPlace method. This is the
most important method in the swarm virus. It is so important that its functionality
is described in its own section called Swarming. The method returns the next place
to move.
11.2.7.2
External Sources
It is necessary to store some information. These are locations of all virus instances,
network, which is currently built, and a log ﬁle for testing purposes. The communi-
cation module is responsible for communication with these ﬁles. It contains methods
like AddHost, RemoveHost, GetHostList, ProcessSignal, WriteLogEntry. The only
external source the communication module is not responsible for is network XML.
Reading and writing XML with the network is performed in classes representing the

11
Swarm Virus, Evolution, Behavior and Networking
227
network, nodes, and edges. The XML format is, in fact, GEXF format readable by
software called Gephi. Gephi is network analysis software.
11.2.7.3
States
States were described in the previous section. Each state is Singleton and inherits
from AbstractState, which has only one method Run. Whole class looks like this:
public abstract class AbstractState<TType>:
IState where TType: AbstractState<TType>, new()
{
public static TType Instance { get; } = new TType();
public abstract void Run();
}
Listing 11.1 AbstractState class
The ﬁrst thing is, the class using a combination of self-referencing generic con-
straint and a new() constraint. That ensures that every child class will always have
a parameterless constructor, so TType Instance = new TType(); will always work.
This means that the Singleton pattern is reusable and its child classes will look like
this:
public class ConcreteState: AbstractState<ConcreteState
>
{
}
Listing 11.2 Singleton inheritance example
The class also must implement an IState interface with one method Run. This
simpliﬁes work with individual states. We do not want to implement the Run method
yet, so we promise to implement it later by tagging it as abstract. The concrete state
classes will implement the Run method. The concrete states in tested swarm virus
example are healed state, wake state, infection state, execution state and movement
state. Here is a detailed description of individual states and its usage.
• Heal state: the healing state calls two modules in its Run method - the infector and
the communication. The infector module is responsible for infection and healing
the host ﬁles and contains the Heal method. The communication module contains
method RemoveHost, to remove the host from our host-list mentioned earlier.
Calling this method allows correct start-up even after the computer restart.
• Wake state: the waking state contains additional two other methods besides the
Run method. WakeUp method, and a WakeUpAll method. The WakeUp method
by default starts the process of some host with only two signals. The Id signal and
the WakeUp signal. The method starts the process the way that it only starts the
virus part of the host. The WakeUpAll method just calls WakeUp for each host

228
L. Sikora and I. Zelinka
ﬁle given by the GetHostList method in communication module. The Run method
just calls WakeUpAll method.
• Infectionstate:thisstatecontainsfourmethods.GetFilesmethodtakes N randomly
picked ﬁles delivered from Objective modules SuitablePaths method. The method
InfectionRoutine infects a ﬁle by calling an Infect method from Infection module
and adds the ﬁle to the host-ﬁle by calling AddHost from the Communication
module. The StartInfecting method just cyclically calls the InfectionRoutine for
each ﬁle from GetFiles. The Run method only counts, how many ﬁles to infect and
infects them maintaining a constant number of virus instances. It might happen
that some virus instances will be found by antivirus.
• Execution state: the Run method of this state only calls the Run method of the
Payload Module.
• Movement state: this state contains only the Run method. The method gets a path to
move from Swarm modules NextPlace method and infects it by InfectionRoutine
from the Infection state. Then it calls the WakeUp method placed in the Wake
state and adds two more signals: The Heal signal containing a current path, and
Visited, containing an actual Taboo list. There is no point to continue the execution
in current location and the current process is terminated. Now the whole process
starts in a new location again and the whole life cycle of one virus instance in one
ﬁle is over.
Whole functionality is set in class called StateController. The controller looks like
this:
public abstract class AbstractStateController
{
private readonly Dictionary<IState, List<KeyValuePair<
Func<bool>, IState>>> _automaton;
public IState InitialState;
protected AbstractStateController()
{
_automaton = new Dictionary<IState, List<KeyValuePair<
Func<bool>, IState>>>();
}
public void Run()
{
var currentState = InitialState;
do
{
currentState.Run();
} while ((currentState = NextState(currentState)) !=
null);
}

11
Swarm Virus, Evolution, Behavior and Networking
229
protected IState NextState (IState currentState)
{
try
{
return _automaton[currentState].First(kv => kv.Key()).
Value;
}
catch (Exception)
{
return null;
}
}
public void AddState(IState state)
{
_automaton[state] = new List<KeyValuePair<Func<bool>,
IState>>();
}
public void AddTransition(IState fromState, Func<bool>
predicate,
IState toState)
{
_automaton[fromState].Add(new KeyValuePair<Func<bool>,
IState>(predicate, toState));
}
public void AddTransition(IState fromState, IState
toState)
{
AddTransition(fromState, () => true, toState);
}
}
Listing 11.3 AbstractStateController class
The controller is marked abstract for reason that is explained in section Behavior.
It is just a state automaton. It contains methods AddState for adding states. AddTran-
sition for adding transition amongst states with or without triggers. NextState for the
transition after execution of the current state is over. The run method is there to
start the whole process. InitialState is a property to start with. Exact code of the
StateController could look like this:

230
L. Sikora and I. Zelinka
public class StateController: AbstractStateController
{
public StateController()
{
AddState(HealState.Instance);
AddState(WakeState.Instance);
AddState(InfectionState.Instance);
AddState(ExecutionState.Instance);
AddState(MovementState.Instance);
AddTransition(HealState.Instance, InfectionState.
Instance);
AddTransition(WakeState.Instance, InfectionState.
Instance);
AddTransition(InfectionState.Instance, Virus.Trigger.
IsTrigged, ExecutionState.Instance);
AddTransition(ExecutionState.Instance, MovementState.
Instance);
}
}
Listing 11.4 Concrete StateController example
The InitialState depends on received signal. When the WakeUp ﬂag is present, the
InitialStatebecomesInfectionState.WhenthereistheHealsignal,theInitialStatewill
be the HealState. If no signal is present, the InitialState will be set to the WakeState,
that means an infected program was executed by the user. It is not possible to receive
more than one of these signals, thus the InitialState will be unambiguous.
This code corresponds to Fig.11.2. Dynamics of spreading is the most important
feature in this kind of virus. In this part, we describe how the NextPlace method in the
Swarm module is implemented. This swarm virus uses a combination of ant colony
behavior and slightly adjusted Bianconi–Barnabasi model for creating networks.
11.2.7.4
Ant Colony
As far as the moving part is concerned, picking the next place is inspired by an
ant colony algorithm [7] and its formula, see Eq.11.1 using so called pheromones.
Pheromone is not so important at this point. Parameter α related to the pheromone
could be set to 1. Vaporization factor should be set to a number which guarantees
slow vaporizations, so the vaporization factor should be somewhere around the value
0.97. The behavior of the tested ant colony utilizes the min-max variant so minimal
pheromone is 1 and maximal pheromone is 10. As we do not want cyclical visits of
the same group of nodes, the number specifying the length of the taboo list should
be high, perhaps 100. The q parameter depends on the ﬁtness. Because we want to

11
Swarm Virus, Evolution, Behavior and Networking
231
lay pheromone proportionally to the ﬁtness of the next node and tested ﬁtness was
somewhere in a rage 0–12 000 000 the formula to update the pheromone is Eq.11.1:
_calsNewPheromone = edge =>
Math.Min

Max Pheromone, edge.Pheromone + (edge.T oNode.Fitness∗edge.T oNode.Rank)
q

;
q = 10, 000.
(11.1)
11.2.7.5
Network
As it was mentioned before, network was created by Bianconi–Barnabasi model.
Although it had been slightly changed. The major change is the ﬁtness calculation.
Here the ﬁtness of the new node was known. So, each node was connected to the
network with probability equal to its ﬁtness. In fact it is not the real probability,
because the ﬁtness value could be way higher than 1. This type of selection, known
as the roulette wheel is described by following algorithm:
public static TType ProbabilitySelect<TType>(this
IEnumerable<Tuple<TType, double>> items)
{
double r = Random.NextDouble() * items.Sum(i => i.Item2
);
double wheelPosition = 0;
foreach (var item in items)
{
wheelPosition += item.Item2;
if (wheelPosition >= r) return item.Item1;
}
return default(T);
}
Listing 11.5 Roulette pick mechanism
The Bianconi–Barnabasi model has some parameters to set, only two has ben
used here. A probability of picking a neighbor p and a number of links to create
m. In practice, the p is set to a number near 1. That is because the model shall
create a network with community structure (see Fig.11.9b). The communities are
not important at this moment. More important is to collect and share information
about host ﬁle distributions, SVP success, and dynamics etc. (let’s call that further
swarm intelligence or swarm dynamics). In this case, the intelligence should be in
the network structure. The better the node is the higher should be its centrality. For
this purpose, the parameter p is set at least to 0.5. That means the probability of
connection with a neighbor is equal to the probability of connection with a random
node. The reason why the Bianconi–Barnabasi was chosen is that nearby ﬁles in

232
L. Sikora and I. Zelinka
a ﬁle system should be connected together, so they could create groups or they
should be connected to some important nodes in the network. The more connections
important nodes have the bigger their centrality. The collective knowledge is in
the network structure. Another parameter to set is the m parameter. The m tells,
how many connections it initially will have. Because parameter p was optimized
to create connections with the important nodes, the m parameter just multiplies
this optimization. Thus higher values are recommended. Numbers higher than 4
performed well. The lower the number, the lower the amount of information stored
in the structure of the network. If both numbers are set to a low number, the resulting
network contains a small amount of information. Networks tend to create centralities
even from not so important ﬁles, and important ﬁles are not registered as centralities.
11.3
Results
The goal was to test whether SVP create a network with certain properties from
a ﬁle system and visualize it. The main property was to have centralities in the
network representing more important ﬁles in the operating system. This property is
helpful when ﬁguring out which ﬁle to infect. Following graphs show dependence
between ﬁtness and some centralities. Then again, the ﬁtness is a value representing
the importance of a ﬁle. The ﬁtness function is set by a virus developer and depends
on his needs. The bigger the ﬁtness value, the better the ﬁle to infect. In this case, the
ﬁtness function is the just size of the ﬁle. In total only 10 SVP has been used and each
SVP has moved 10 times. On Figs.11.5, 11.6, 11.7, 11.8 and 11.9 are depicted some
examples of provided experiments for different m and p in different visualizations.
(a)
(b)
Fig. 11.7 Viral network examples I

11
Swarm Virus, Evolution, Behavior and Networking
233
(a)
(b)
Fig. 11.8 Viral network examples II
(a)
(b)
Fig. 11.9 Viral network examples III
Fig. 11.10 Dependency
between Fitness and
Closeness centrality, p = 0.3,
m = 2

234
L. Sikora and I. Zelinka
Fig. 11.11 Dependency
between Fitness and
Closeness centrality, p = 0.3,
m = 2
Fig. 11.12 Dependency
between Fitness and
Betweenness centrality, p =
0.3, m = 2
Fig. 11.13 Dependency
between Fitness and
PageRank centrality, p = 0.3,
m = 7
In graphs of Figs.11.10, 11.11, 11.12, 11.13, 11.14, 11.15, 11.16, 11.17, 11.18,
11.19, 11.20 and 11.21 are shown some basic dependencies between ﬁtness, page
rank, centralities etc. The reason is that the SVP is, in fact, a random walker. The
higher the page rank of a node, the higher the probability of visiting the node. The
goal is to visit the most important nodes in the network. Among other centralities,
the PageRank ﬁts into this scenario as the best. Other centralities are useful for
further analysis of the network too. This could be performed by the virus itself, or
the virus can send the network info to a hacker. We could see that ﬁles with the
highest ﬁtness also have higher centrality numbers. They are distinguishable from

11
Swarm Virus, Evolution, Behavior and Networking
235
Fig. 11.14 Dependency
between Fitness and
Closeness centrality, p = 0.3,
m = 7
Fig. 11.15 Dependency
between Fitness and
Betweenness centrality, p =
0.3, m = 7
Fig. 11.16 Dependency
between Fitness and
PageRank centrality, p = 0.5,
m = 7
others. Unimportant ﬁles have low centrality numbers. This means a random virus
instance walking the network has a higher probability of infecting a ﬁle with the
higher ﬁtness. Further and extensive analysis of such behavior is needed of course.
Experiments reported here are the ﬁrst one of its kind and were designed to conﬁrm
our idea whether SVP can create networks and how it can be analyzed.

236
L. Sikora and I. Zelinka
Fig. 11.17 Dependency
between Fitness and
Closeness centrality, p = 0.5,
m = 7
Fig. 11.18 Dependency
between Fitness and
Betweenness centrality, p =
0.5, m = 7
Fig. 11.19 Dependency
between Fitness and
PageRank centrality, p = 0.9,
m = 7

11
Swarm Virus, Evolution, Behavior and Networking
237
Fig. 11.20 Dependency
between Fitness and
Betweenness centrality, p =
0.9, m = 7
Fig. 11.21 Dependency
between Fitness and
PageRank centrality, p = 0.9,
m = 7
11.4
Conclusion
As the conclusion can be stated that it is possible to construct SVP (and thus this
threat is more likely and only a question of time when appearing really) and thus
more extensive defense strategies are needed for this threat. SVP dynamics has been
captured and visualized, as in Figs.11.4, 11.5, 11.6, 11.7, 11.8 and 11.9. Also, some
basic network attributes have been calculated, however, more dense SVP networks
and experiments are needed to get more precise results.
The intensity of colors in Figs.11.4, 11.5, 11.6, 11.7, 11.8 and 11.9 represents
amount of pheromone in an edge. The networks have some interesting properties:
• There are cycles in the network.
• Files close to each other in ﬁle tree system are also close to each other in the
network representation.
• Files with higher ﬁtness tend to have more neighbors (their page-rank is higher).
This swarm virus could utilize much more features than it already demonstrated.
One of them could be adding more subspecies of SVP. The virus already contains
those that explore ﬁle system and transform it to network with some information.
But a structure of the code enables the possibility to have more than that. It is not a
bad thing to have interface upon each module. It enables us to create version Move

238
L. Sikora and I. Zelinka
of them, so there can be more infectors, payloads, triggers and most importantly,
more swarming behavior. Now a different SVP species to perform a different role
can be created. Some SVP could explore, some of them can execute only a part of
the payload, some could do a different part of the payload. Some could even explore
with different behavior. It is enough only to add some other signals to specify, which
type of module to instantiate or how to set some parameters. A different approach is
to mutate a virus instance to achieve the desired result.
Behavior pattern can be used to simply explore and map the ﬁle system, but for
other work like malicious activities, different behavior pattern can be used. Lets
explain the behavior of Explorer SVP or just explorers. These explorers create a
network with some properties but with the different commonwealth, meanwhile, the
executor SVP or just executors, are responsible for a malicious activity. This activity
could be crypto-locking, data-manipulating etc. This activity is variable and depends
on creator only.
Embrace polymorphism or metamorphism or just create a different program. It is
enough to share information about the location of external sources. Also, Darwinian
evolution can be also applied to the evolution of SVP so that its quality will develop
independently of a human creator.
Usage of such technology seems obvious. You can use this code for malicious
purposes of course, but that is no challenge. The real challenge is using it differently.
For example, one can directly specify a topology of the network by downloading the
topology from the web. Creating it from *.exe ﬁles is up to SVP. The only drawback
is that an operating system must contain at least as many ﬁles as nodes in the desired
topology. When all of that is present, SVP can solve different tasks like traveling
salesman problem or other network related problems. It can be solved in a users
machine without his or her knowledge. The virus can just steal computation time for
higher purposes. It also could be used as antivirus, or espionage software but this is
a topic for further research.
Acknowledgements The following grants are acknowledged for the ﬁnancial support provided
to this research: Grant Agency of the Czech Republic - GACR P103/15/06700S, Grant of SGS
No. SGS 2017/134, VSB-Technical University of Ostrava. The Ministry of Education, Youth and
Sports from the National Programme of Sustainability (NPU II) project “IT4Innovations excellence
in science - LQ1602”.
References
1. Aycock, J.: Computer Viruses and Malware, vol. 22. Springer Science and Business Media
(2006)
2. Ligh, M., Adair, S., Hartstein, B., Richard, M.: Malware analyst’s cookbook and DVD: tools
and techniques for ﬁghting malicious code. Wiley Publishing (2010)
3. Sikorski, M., Honig, A.: Practical Malware Analysis: The Hands-on Guide to Dissecting Mali-
cious Software. no starch press (2012)
4. Skoudis, E., Zeltser, L.: Malware: Fighting Malicious Code. Prentice Hall Professional (2004)

11
Swarm Virus, Evolution, Behavior and Networking
239
5. Lee, W., Wang, C., Dagon, D. (eds.) Botnet Detection: Countering the Largest Security Threat.
Springer Science and Business Media (2007)
6. Szor, P.: The Art of Computer Virus Research and Defense. Pearson Education (2005)
7. Dorigo, M., Birattari, M., Stutzle, T.: Ant colony optimization. IEEE Comput. Intell. Mag.
1(4), 28–39 (2006)
8. Barabasi, A., Bonabeau, E.: Scale-free networks. Sci. Am. 50–59, May 2003
9. Watts, D.J., Strogatz, S.H.: Collective dynamics of ‘small-world’ networks. Nature 393(6684),
440–442 (1998)
10. Gao, F., Cui, G., Wu, Z.-B., Liu, H.-W., Yang, X.-Z.: Virus-evolutionary particle swarm opti-
mization algorithm for knapsack problem. J. Harbin Inst. Technol. 6, 024 (2009)
11. Gao, F., Liu, H., Zhao, Q., Cui, G.: Virus-evolutionary particle swarm optimization algorithm.
Adv. Natural Comput. 156–165 (2006)
12. Wang, W., Zhang, P., Tan, Y.: An immune concentration based virus detection approach using
particle swarm optimization. Adv. Swarm Intell. 347–354 (2010)
13. Reddy, D.K.S., Pujari, A.K.: N-gram analysis for computer virus detection. J. Comput. Virol.
2(3), 231–239 (2006)
14. Jordan, M.: System and method for computer virus detection utilizing heuristic analysis. U.S.
Patent 7,231,667, issued 12 June 2007
15. Kephart, J.O., White, S.R.: Measuring and modeling computer virus prevalence. In: Proceed-
ings 1993 IEEE Computer Society Symposium on Research in Security and Privacy 1993, pp.
2–15. IEEE (1993)
16. Zhu, Q., Yang, X., Ren, J.: Modeling and analysis of the spread of computer virus. Commun.
Nonlinear Sci. Numer. Simul. 17(12), 5117–5124 (2012)
17. Nachenberg, C.: Computer virus-coevolution. Commun. ACM 50(1), 46–51 (1997)
18. Al Daoud, E., Jebril, I.H., Zaqaibeh, B.: Computer virus strategies and detection methods. Int.
J. Open Problems Comptut. Math. 1(2), 12–20 (2008)
19. Pastor-Satorras, R., Vespignani, A.: Epidemic spreading in scale-free networks. Phys. Rev.
Lett. 86(14), 3200 (2001)
20. Zou, C.C., Gong, W., Towsley, D.: Code red worm propagation modeling and analysis. In:
Proceedings of the 9th ACM Conference on Computer and Communications Security, pp.
138–147. ACM (2002)
21. Serazzi, G., Zanero, S.: Computer virus propagation models. In: Performance Tools and Appli-
cations to Networked Systems, pp. 26–50. Springer, Berlin (2004)
22. Ren, J., Yang, X., Zhu, Q., Yang, L.-X., Zhang, C.: A novel computer virus model and its
dynamics. Nonlinear Anal. Real World Appl. 13(1), 376–384 (2012)
23. Chen, E., Sun, J., Chou, T., Deutsch, S., Havran, M.: Tracking and reporting of computer virus
information. U.S. Patent 7,496,960, issued 24 February 2009
24. Wierman, J.C., Marchette, D.J.: Modeling computer virus prevalence with a susceptible-
infected-susceptible model with reintroduction. Comput. Stat. Data Anal. 45(1), 3–23 (2004)
25. Austin, T.H., Filiol, E., Josse, S., Stamp, M.: Exploring hidden Markov models for virus
analysis: a semantic approach. In: 2013 46th Hawaii International Conference on System
Sciences (HICSS), pp. 5039–5048. IEEE (2013)
26. Tesauro, G.J., Kephart, J.O., Sorkin, G.B.: Neural networks for computer virus recognition.
IEEE Expert 11(4), 5–6 (1996)
27. Nikolopoulos,S.D.,Polenakis,I.:Agraph-basedmodelformalwaredetectionandclassiﬁcation
using system-call groups. J. Comput. Virology Hacking Tech. 1–18 (2016)
28. Sikora, L.: Swarm Malware, thesis of Computer Science at VSB-TU Ostrava (2017)
29. Engelbrecht, A.P.: Fundamentals of Computational Swarm Intelligence. Wiley (2006)
30. Clerc, M.: Particle Swarm Optimization, vol. 93. Wiley (2010)
31. Davendra, D., Zelinka, I.: Self-organizing Migrating Algorithm. New Optimization Techniques
in Engineering (2016)
32. Storn, R., Price, K.: Differential evolution simple and efﬁcient heuristic for global optimization
over continuous spaces. J. Global Optim. 11(4), 341–359 (1997)
33. Schwefel, H.-P.P.: Evolution and Optimum Seeking: The Sixth Generation. Wiley (1993)

Chapter 12
Simple Networks on Complex Cellular
Automata: From de Bruijn Diagrams
to Jump-Graphs
Genaro J. Martínez, Andrew Adamatzky, Bo Chen, Fangyue Chen
and Juan C. Seck-Tuoh-Mora
Abstract We overview networks which characterise dynamics in cellular automata.
These networks are derived from one-dimensional cellular automaton rules and
global states of the automaton evolution: de Bruijn diagrams, subsystem diagrams,
basins of attraction, and jump-graphs. These networks are used to understand prop-
erties of spatially-extended dynamical systems: emergence of non-trivial patterns,
self-organisation, reversibility and chaos. Particular attention is paid to networks
determined by travelling self-localisations, or gliders.
12.1
Introduction
Cellular automata (CA) are arrays of ﬁnite state machines, or cells. Each cell takes a
ﬁnite number of states. All cells update their states by the same rule simultaneously.
A cell updates its state depending on states of its immediate neighbours. The CA
G. J. Martínez (B) · A. Adamatzky
International Centre of Unconventional Computing, University of the West
of England, Bristol, UK
e-mail: genaro.martinez@uwe.ac.uk
A. Adamatzky
e-mail: andrew.adamatzky@uwe.ac.uk
G. J. Martínez
Escuela Superior de Cómputo, Instituto Politécnico Nacional, México City, México
B. Chen · F. Chen
School of Science, Hangzhou Dianzi University, Hangzhou, China
e-mail: chenbo4068922@126.com
F. Chen
e-mail: fychen@hdu.edu.cn
J. C. Seck-Tuoh-Mora
Área Académica de Ingeniería, Universidad Autónoma del Estado de Hidalgo,
Pachuca, Hidalgo, México
e-mail: jseck@uaeh.edu.mx
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_12
241

242
G. J. Martínez et al.
originated from Stanislaw Ulam problem on a parallel transformation of matrices,
and further developed in a context of self-reproduction by John von Neumann [20].
CA are apparently simple systems yet exhibiting sophisticated patterns of non-trivial
behaviour. They are now ubiquitous tools in studying complex systems and non-
linear dynamics in literally all ﬁelds of science and engineering, see e.g. a visual
guide of representative power of CA in [2]. Rules space and global dynamics of CA
are characterised by networks: the de Bruijn diagrams [15, 21], subsystem diagrams
[3, 6], basins of attraction [23], and jump-graphs [25]. We analyse predictive power
of the networks using two CA rules which exhibit complex space-time dynamics:
gliders, particles, waves, or localisations. The CA rules studied are the Rule 541 and
the Rule 110.2
12.2
Elementary Cellular Automata
A cell in elementary CA (ECA) takes two states from Σ = {0, 1}. A cell xi, 1 ≤i ≤
n, updates its state by local function ϕ depending on its own state and states of its
two immediate neighbours:
xt+1
i
= ϕ(xt
i−1, xt
i , xt
i+1).
There are 223 = 256 cell state transition rules. In 1983, Stephen Wolfram estab-
lished a classiﬁcation ECA rules [24], based on space-time development of automata
governed by the rules. The Wolfram classes are
Class I: evolution to uniform behaviour;
Class II: evolution to periodic behaviour;
Class III: evolution to chaotic behaviour;
Class IV: evolution to complex behaviour.
Wolfram’s classiﬁcation is not the only one, there are 17 classiﬁcations of CA rule
space [9], however it is fully adequate and it became a classic ‘item’ of CA theory.
The class III includes rules 54 and 110 (decimal representation of a binary rule-
string). Rules in class III are called ‘complex’ because the automata governed by
these rules have longer transient periods and more sensitive to initial conditions than
automata governed by rules form other classes. And, most importantly, they exhibit a
wide range of travelling and stationary localisations, interactions that are the reason
of ‘complexity’ of the ‘rules’ behaviour.3
We study two ECA complex rules: Rules 54 and 110.
1Repository Rule 54 http://uncomp.uwe.ac.uk/genaro/Rule54.html.
2Repository Rule 110 http://uncomp.uwe.ac.uk/genaro/Rule110.html.
3Complex
Cellular
Automata
Repository
http://uncomp.uwe.ac.uk/genaro/Complex_CA_
repository.html.

12
Simple Networks on Complex Cellular Automata …
243
The Rule 54 (‘54’ is a decimal representation of a binary string 00110110) automa-
ton typically exhibits a rich dynamics of mobile localisations and outcomes of their
collisions. Some of the mobile localisation collisions were used to demonstrate log-
ical universality of the rule in [10]. The Rule 54 is represented by a function:
ϕR54 =
1 if 101, 100, 010, 001
0 if 111, 110, 011, 000 .
(12.1)
Figure12.1 shows a typical evolution of ECA Rule 54 from a random initial
condition.
Rule 110 (‘110’ is a decimal representation of a binary string 01101110) is proved
to be computationally universal because it can simulate a cyclic tag system, which
in turns simulates a universal Turing machine [4]. The cell-state transition function
of the Rule 110 is
ϕR110 =
1 if 110, 101, 011, 010, 001
0 if 111, 100, 000
.
(12.2)
Figure12.2 shows a typical evolution of ECA Rule 110 from a random initial
condition.
Complexity of CA rules can be estimated using polynomial approximation bor-
rowed from the mean ﬁeld theory [18]. Mean ﬁeld theory techniques are efﬁcient
in discovering statistical properties of CA without analysing the whole evolution
space of individual rules. These techniques have been introduced in CA ﬁeld by
Howard Gutowitz in [7]. The approach assumes that cell-states do not correlate with
each other in the local function ϕ. Thus we can study probabilities of states in a
neighbourhood in terms of the probability of a single cell-state, and the probabil-
ity of a neighbourhood would be the product of the probabilities of each cell in it.
For one-dimensional CA with k-cell neighbourhood or radius r and k cell-states the
probability is calculated as follows:
pt+1 =
q2r+1−1

j=0
ϕ j(X)pv
t (1 −pt)n−v
(12.3)
where j of a neighbourhood state, q is a number of cell-states, X is a neighbourhood
xi−r, . . . , xi, . . . , xi+r, k is the number of cells in every neighbourhood, v indicates
how often state ‘1’ occurs in X, n −v shows how often state ‘0’ occurs in the
neighbourhood X, pt is the probability of a cell being in state ‘1’, and qt is the
probability of a cell being in state ‘0’; i.e., q = 1 −p. In our case of binary cell-
states and three-cell neighbourhood the probability is
pt+1 =
7

j=0
ϕ j(X)pv
t (1 −pt)n−v

244
G. J. Martínez et al.
Fig. 12.1 Complex behaviour derived from ECA Rule 54. Non-trivial patterns as mobile localisa-
tions emerge and collide in the system. This snapshot evolves from a random initial conﬁguration
of 869 cells to 1,078 generations at 50% of density. A ﬁlter is selected in the evolution for a better
view of localisations and interactions

12
Simple Networks on Complex Cellular Automata …
245
Fig. 12.2 Complex behaviour derived from ECA Rule 110. Non-trivial patterns as mobile locali-
sations emerge and collide in the system. This snapshot evolves from a random initial conﬁguration
of 869 cells to 1,078 generations at 50% of density. A ﬁlter is selected in the evolution for a better
view of localisations and interactions

246
G. J. Martínez et al.
Fig. 12.3 Mean ﬁeld curves for a Rule 54 and b Rule 110
In [12], Harold McIntosh proposed a classiﬁcation based on curves derived with
the mean ﬁeld approximation. A complex rule has a curve tangential to the identity,
and an unstable ﬁxed point that deﬁnes regions with unpredictable behaviour:
Class IV: mean ﬁeld curve horizontal plus diagonal tangency (no crossing the
identity, possibly complex dynamics).
Figure12.3a shows a mean ﬁeld curve for Rule 54 with a polynomial deﬁned as:
pt+1 = 3ptq2
t + p2
t qt.
(12.4)
The origin value is a stable ﬁxed point which guarantees the stable conﬁguration
in state zero. The maximum point p = 0.5281 is very close to the ﬁxed stable point in
p = 0.5. Complex dynamics in Rule 54 emerges on a periodic background with the
same number of states zero and one, thus the stable ﬁxed point well characterises the
local function (see Eq.12.1). Also, this ﬁxed point shows that a Rule 54 automaton
starting from low or high densities of state 1 cells, more likely will ﬁnish its evolution
with the same ratio of states (Fig.12.1).
Figure12.3b shows a mean ﬁeld curve for Rule 110 with polynomial deﬁned as:
pt+1 = 2ptq2
t + 3p2
t qt.
(12.5)
The maximum point p = 0.6311 is close to the ﬁxed stable point in p = 0.62. In
Rule110wecannotﬁndunstableﬁxedpoints.ComplexdynamicsinRule110emerge
quickly in few steps with a large number of mobile localisations and several chaotic
regions. The ﬁxed point characterises a periodic background that is often reached
by Rule 110 automata 300 to 500 steps of development. Although, the number of

12
Simple Networks on Complex Cellular Automata …
247
states 1 is close to 0.57, the ﬁxed point is reached because commonly an evolution
in Rule 110 frequently is accompanied by mobile self-localisations traveling to the
left (Fig.12.2). For full details about mobile localisations in Rule 110 see [16, 17].
12.3
de Bruijn Diagrams
For a one-dimensional CA of order (k,r) and a ﬁnite alphabet given Σ, its de Bruijn
diagram is a directed graph with k2r vertexes and k2r+1 edges calculated as follows.
Vertexes are labelled with elements of the alphabet of length 2r, i.e. neighbourhood
states. An edge is directed from vertex i to vertex j, if and only if, the 2r −1 ﬁnal
symbols of i are the same as 2r −1 initial symbols in j forming a neighbourhood of
2r + 1 states represented by i ⋄j. In this case, the edge connecting i to j is labelled
by ϕ(i ⋄j)(the value of the neighbourhood deﬁned by the local function) [21].
Thus the de Bruijn diagram is constructed as follow:
Mi, j =
1 if j = ki, ki + 1, . . . , ki + k −1 (mod k2r)
0 in other case
(12.6)
For ECA the module k2r = 22 = 4 represents the number of vertexes in the de
Bruijn diagram and j takes values from k ∗i = 2i to (k ∗i) + k −1 = (2 ∗i) + 2 −
1 = 2i + 1. The vertexes (indexes of M) are labelled by fractions of neighbourhoods
beginningwith00,01,10and11,theoverlapdetermineseachconnection(Fig.12.4a).
Paths in the de Bruijn diagram may represent chains, conﬁgurations, or classes of
conﬁgurations in the evolution space. Also fragments of the diagram itself are useful
in discovering periodic blocks of strings, pre-images, codes, and cycles [13].
After the de Bruijn diagram is completed, we can calculate an extended de Bruijn
diagram. An extended de Bruijn diagram takes into account more signiﬁcant overlap-
ping of neighbourhoods of length 2r. We represent M(2) by indexes i = j = 2r ∗n,
where n ∈Z+. The de Bruijn diagram grows exponentially, order k2rn, for each M(n).
We can calculate generic de Bruijn diagrams arranged in a circular pattern for r = 1
Fig.12.4a(basicdiagram),r = 2 Fig.12.4b,r = 3Fig.12.4c,r = 4Fig.12.4d,r = 5
Fig.12.4e, r = 6 Fig.12.4f (constructing a circle).
Generic diagrams calculate strings of different periods. These patterns are struc-
tures without displacements. The complement diagrams calculates periods plus dis-
placements. In these diagrams we can ﬁnd systematically any periodic structure,
including some mobile localisations.
For extended de Bruijn diagrams we have shift registers to the right (+) or to
the left (−). A mobile localisation can be identiﬁed as a cycle and the localisations
interaction will be a connection with other cycles. Diagram (2, 2) (x-displacements,
y-generations), displays periodic strings moving two cells to the right in two time
steps, i.e., period of a mobile localisation. This way, we can enumerate each string
for every structure in this domain.
The de Bruijn diagram than can calculate stationary localisations is of order M(4)
R54
because localisations have period four without displacements. These patterns can

248
G. J. Martínez et al.
Fig. 12.4 Generic de Bruijn diagrams for ECA. Each generic diagram follows the number of partial
neighbourhoods k2r for r = a 1, b 2, c 3, d 4, e 5, and f 6

12
Simple Networks on Complex Cellular Automata …
249
Fig. 12.5 de Bruijn diagram (0, 4) calculating stationary localisations in Rule 54. A snapshot for
every cycle is showed below of every diagram. This way, patterns are deﬁned as a code since its
initial condition obtained from diagram
be considered also as still life conﬁgurations. Figure12.5 shows the full de Bruijn
diagram (0, 4) used to calculate these stationary localisations. There are four main
cycles, two largest cycles represent phases of each stationary localisation plus its
periodic background; and two smaller cycles characterising two different periodic
patterns in Rule 54 including the stable state represented with a loop by vertex zero.
Space-time conﬁgurations of ECA derived from these diagrams are illustrated on the
left plate of Fig.12.5. Position of each mobile localisation and periodic background
follows arbitrarily routes into these cycles. Details on these regular expressions for
Rule 54 are presented in [11].
For Rule 110 we have calculated an extended de Bruijn diagram (4, 8) that deter-
mines non-stationary localisations. Figure12.6 shows a diagram than initially needs
65,536 vertexes. However, we can reduce the diagram just ﬁltering cycles, this way
we have a diagram of 145 vertexes and 153 links. This way, this diagram displays a

250
G. J. Martínez et al.
Fig. 12.6 de Bruijn diagram (4, 8) calculating non-stationary localisations in Rule 110. The left
evolution displays a fuse pattern produced by two mobile localisations colliding and both annihi-
lated, the center evolution displays a periodic pattern, and the right evolution displays a mobile
localisation with displacement to the left
stable state represented by loop zero and cycles deﬁne a phase of a mobile localisa-
tion, i.e., a string that determines how to input a mobile localisation into its initial
condition: left evolution shows mobile localisations colliding constantly, right evo-
lution shows mobile localisations moving to the left, and center evolution shows
a periodic pattern. This characteristic is very useful to control collisions of local-
isations in this automaton. Connections between cycles mean that you can con-
nect several structures on a same phase. Figure12.7 shows the de Bruijn diagram
(2,10) than calculates non-stationary localisations and periodic patterns coveting the

12
Simple Networks on Complex Cellular Automata …
251
Fig. 12.7 de Bruijn diagram (2,10) calculating non-stationary localisations in Rule 110. First,
the original diagram is calculated with 1,048,576 vertices. Below, an evolution of non-stationary
localisations beginning from the vertex 652,687 (left) and a periodic background deﬁning a small
mosaic

252
G. J. Martínez et al.
evolution space of Rule 110. This diagram surpass a million of vertexes and shows a
snapshot of a particular initial condition, coding several non-stationary localisations
beginning in a diverse number of phases, copies, and intervals. Details about these
regular expressions for Rule 110 can be found in [17].
de Bruijn diagrams contain all relevant information about of complex patterns
emerging in cellular automata de Bruijn diagrams can proof exhaustively the number
of periodic patterns that rule can yield. But they grown quickly, therefore not rarely
a second algorithm must be implemented to extract useful strings from a diagram.
12.4
Subsystem Diagrams
Let us focus on presenting an analytical characterisation of symbolic dynamics of
mobile localisations in Rule 110. For each mobile localisation, a particular subsystem
can be found through enumeration and exhaustive analysis. Directed graph theory
and transition matrix provide are powerful tools for studying each sub-shift of a ﬁnite
type — such as a glider — which is topologically mixing and possesses the positive
topological entropy on this subsystem. A positive topological entropy implies the
chaos in the sense of Li–Yorke [8, 22]. Devaney [5] and Li–Yorke types of chaos can
be deduced from topological mixing. Here we describe a non-stationary localisation,
other types of mobile localisations can be studied by analogy.
Particularly, a non-stationary localisation with velocity to 1/5 in Rule 1104 can
be represented as, A = {x ∈SZ|x[i−7,i+6] ∈A , ∀i ∈Z} is a sub-shift of a ﬁnite
type, its determinative system A = {9976, 3569, 7138, 14276, 12169, 7955, 15910,
15437, 14491, 12599, 8815, 1247, 2494, 4988, 8814, 1245, 2490, 4980, 9960, 3537,
7075, 14150, 11917, 7451, 14903, 13423, 10463, 4542, 9084, 1784, 2495, 4990,
9980, 3577, 7155, 14310, 12237, 8091, 16183, 15983, 15583, 14782, 13180, 3568,
7137, 14274, 12165, 7947, 15895, 15407, 14431, 12478, 8572, 760, 1521, 3042,
6084, 12168, 7953, 15907, 15431, 14479, 12574, 8764, 1144, 2289, 4578, 9156,
1929, 3859, 7718, 4989, 9979, 3575, 7150, 14300, 12217, 8051, 16103, 15823,
15263, 14142, 11900, 7416, 14833, 13282, 10180, 3977, 15436, 14489, 12595, 8806,
1228, 2457, 4914, 9828, 3273, 6547, 13094, 9805, 3227, 6455, 12911, 9439, 14301,
12219, 8055, 16111, 15839, 15295, 14206, 12028, 7672, 15345, 14306, 12228, 8073,
16147, 7139, 14279, 12174, 7965, 15930, 15477, 14571, 12758, 9132, 1880, 3761,
7522, 15044, 13705, 11027, 5670, 11341, 6299, 15931, 15479, 14574, 12764, 9144,
1904, 3809, 7618, 15236, 14089, 11795, 7206, 14413, 12443, 8503, 623, 2491,
4983, 9966, 3549, 7099, 14198, 12013, 7643, 15287, 14191, 11999, 7614, 15228,
14072, 11761}. Let x[i−7,i+6] denote a 14-bit string (xi−7, xi−6, xi−5, . . . , xi+5, xi+6)
over S = {0, 1} which is described by its decimal code expression, such as 9976
refers to the string (1,0,0,1,1,0,1,1,1,1,1,0, 0,0), and 3569 refers to the string
(0,0,1,1,0,1,1,1,1,1,0,0,0,1).
4Gliders in Rule 110 http://uncomp.uwe.ac.uk/genaro/rule110/glidersRule110.html.

12
Simple Networks on Complex Cellular Automata …
253
A fundamental method for constructing ﬁnite shifts starts with a ﬁnite, directed
graph and produces the collection of all bi-inﬁnite walks (i.e., strings of edges) on
the graph. The A can be described by a ﬁnite directed graph GA = {A , E}, where
each vertex (V ) is a string in A . Each edge e ∈E(G) starts at a string denoted by a =
(a0, a1, . . . , a13) ∈A and terminates at the string b = (b0, b1, . . . , b13) ∈V (G) if
and only if ak = bk−1, 1 ≤k ≤13. One can represent each element of A as a
certain path on the graph GA . The entire bi-inﬁnite walks on the graph constitute the
closed invariant subsystem A . The ﬁnite directed graph A , is shown in Fig.12.8.
A ﬁnite path P = v1 →v2 →· · · →vm on a graph G is a ﬁnite string of vertexes
vi from G. The length of P is |P| = m. A cycle is a path that starts and terminates
at the same vertex. A graph G is irreducible if for each ordered pair of vertexes I
and J there is a path in G starting at I and terminating at J. Each element of A is
a certain path on the graph GA .
v1
v2
v3
v4
v5
v6
v7
v8
v9
v10
v11
v12
v13
v14
v15
v16
v17
v18
v19
v20
v21
v22
v23
v24
v25
v26
v27
v28
v29
v30
v31
v32
v33
v34
v35
v36
v37
v38
v39
v40
v41
v42
v43
v44
v45
v46
v47
v48
v49
v50
v51
v52
v53
v54
v55
v56
v57
v58
v59
v60
v61
v62
v63
v64
v65
v66
v67
v68
v69
v70
v71
v72
v73
v74
v75
v76
v77
v78
v79
v80
v81
v82
v83
v84
v85
v86
v87
v88
v89
v90
v91
v92
v93
v94
v95
v96
v97
v98
v99
v100
v101
v102
v103
v104
v105
v106
v107
v108
v109
v110
v111
v112
v113
v114
v115
v116
v117
v118
v119
v120
v121
v122
v123
v124
v125
v126
v127
v128
v129
v130
v131
v132
v133
v134
v135
v136
v137
v138
v139
v140
v141
v142
v143
v144
v145
v146
v147
v148
v149
v150
v151
v152
v153
v154
v155
v156
v157
v158
v159
v160
v161
v162
v163
v164
v165
v166
v167
Fig. 12.8 Graph representation for the subsystem A of a non-stationary localisation with velocity
1/5, it is the same mobile localisation calculated with a de Bruijn diagram showed in Fig.12.7.
Where each vertex stands for the element of A by order, i.e., v1 = 9976, v2 = 3569, v3 = 7138,
. . ., v166 = 14072, v167 = 11761. All bi-inﬁnite walks on the graph constitute the closed invariant
subsystem A

254
G. J. Martínez et al.
Let S = {r0,r1, . . . ,r165,r166} be a new symbolic set, where ri, i = 0, . . . , 166,
stands for the element of A respectively. Then, one can construct a new sym-
bolic space SZ on S, where B = {(rr′)|r = (b0b1 . . . b13),r′ = (b′
0b′
1 . . . b′
13) ∈
S, ∀2 ≤j ≤13 s.t. b j = b′
j−1}. The two-order sub-shift B of σ is deﬁned
as B = {r = (. . . ,r−1,r∗
0,r1, . . .) ∈SZ|ri ∈S, (ri,ri+1) ≺B, ∀i ∈Z}. One can
calculate the transition matrix Y of the sub-shift B with Yi j = 1, if (i, j) ≺B;
otherwise Yi j = 0. We call the matrix Y positive if all of its entries are non-negative;
irreducible if ∀i, j, there exist n such that Y n
i j > 0; aperiodic if there exists N, such
that Y n
i j > 0, n > N, ∀i, j. Then, B is topologically mixing if and only if Y
is irreducible and aperiodic. Thus, the topologically conjugate relationship between
(A , σ) and a two-order sub-shift of ﬁnite type (B, σ) can be established. In addi-
tion, the transition matrix Y is relatively large (the order of D is 167). Therefore, we
only list the indexes (i, j) of nonzero elements. Y = {(1, 2), (1, 44), (2, 3), (2, 119),
(3, 4), (4, 5), (4, 58), (5, 6), (6, 7), (7, 8), (7, 89), (8, 9), (9, 10), (10, 11), (10, 15),
(11, 12), (12, 13), (12, 31), (13, 14), (13, 72), (14, 1), (15, 16), (16, 17), (16, 153),
(17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26),
(26, 27), (27, 28), (28, 29), (29, 30), (30, 2), (30, 44), (31, 32), (32, 33), (33, 34),
(34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 42), (42, 43),
(43, 1), (44, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50), (50, 51), (51, 52),
(52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 5), (57, 58), (58, 59), (59, 60),
(60, 61), (61, 62), (62, 63), (63, 64), (64, 65), (65, 66), (66, 67), (67, 68), (68, 69),
(69, 70), (70, 71), (71, 8), (71, 89), (72, 73), (73, 74), (74, 75), (75, 76), (75, 105),
(76, 77), (77, 78), (78, 79), (79, 80), (80, 81), (81, 82), (82, 83), (83, 84), (84, 85),
(85, 86), (86, 87), (87, 88), (88, 6), (89, 90), (90, 91), (91, 92), (92, 93), (93, 94),
(94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101), (101, 102),
(102, 103), (103, 104), (104, 13), (104, 31), (105, 106), (106, 107), (107, 108),
(108, 109), (109, 110), (110, 111), (111, 112), (112, 113), (113, 114), (114, 115),
(115, 116), (116, 117), (117, 118), (118, 7), (119, 120), (120, 121), (121, 122),
(122, 123), (122, 137), (123, 124), (124, 125), (125, 126), (126, 127), (127, 128),
(128, 129), (129, 130), (130, 131), (131, 132), (132, 133), (133, 134), (134, 135),
(135, 136), (136, 10), (137, 138), (138, 139), (139, 140), (140, 141), (141, 142),
(142, 143), (143, 144), (144, 145), (145, 146), (146, 147), (147, 148), (148, 149),
(149, 150), (150, 151), (151, 152), (152, 12), (153, 154), (154, 155), (155, 156),
(156, 157), (157, 158), (158, 159), (159, 160), (160, 161), (161, 162), (162, 163),
(163, 164), (164, 165), (165, 166), (166, 167), (167, 3), (167, 119)}.
Denote the elements of Y n as Y n
i, j, 1 ≤i, j ≤167. Y n
i, j indicates the number of
the whole paths from i-th vertex to j-th vertex whose length is n. Thus, Y n
i,i is the
number of all cycles of i-th vertex with the length n. As all Y n
i,i, 1 ≤i ≤167 are
positive for n = 39, it is easy to verify that each vertex possesses a particular cycle.
Hence, the non-wandering set of subsystem Ω(A ) = A .

12
Simple Networks on Complex Cellular Automata …
255
The topological dynamics of A is determined by the properties of its transi-
tion matrix Y . The characteristic equation of Y is −λ73 −λ84 −3λ95 + 5λ106 +
λ109 + 5λ120 + 15λ131 + 10λ142 + λ153 −λ167 = 0. The spectral radius ρ(Y ) is the
maximum positive real root λ∗of characteristic equation. We have ent(A ) =
log(ρ(Y )) = log(1.12316) = 0.116146. Recall that two topologically conjugate
systems have the same topological entropy and the topological entropy of σL on A
equals logρ(Y ). The topological entropy ent(A ) is positive.
The matrix (Y + I )n is positive for n ≥47, where I is a 167 × 167 identity
matrix. Y + I is aperiodic, and Y is irreducible. A is topologically transitive
because the transition matrix Y is irreducible.
A two-order sub-shift of a ﬁnite type A is topologically mixing if and only if
its transition matrix is irreducible and aperiodic. Meanwhile, it is easy to verify that
Y n is positive for n ≥225, which implies that Y is irreducible and aperiodic. The
A is topologically mixing.
In conclusion, the above discussions are summarised as the subsystem A is
chaotic in the sense of both Li–Yorke and Devaney.
12.5
Basins of Attraction
Basins of attraction or cycle diagrams calculate attractors in a dynamical system, as
was extensively studied by Andrew Wuensche in CA and random Boolean networks
[15, 23, 25].
Givenasequenceofcells xi wedeﬁneaconﬁgurationc ofthesystem.Anevolution
is represented by a sequence of conﬁgurations {c0, c1, c2, . . . , cm−1} given by the
global mapping,
Φ : Σn →Σn
(12.7)
and the global relation is given for the next function between conﬁgurations,
Φ(ct) →ct+1.
(12.8)
An attractor is represented as a number of ci states, these states are connected in
cycles in periods of global states.
To obtain cycles for a given automaton we enumerate all the rings of the desired
length, and follow up their evolution. In doing so task, various shortcuts can be taken,
such as generating the conﬁgurations in some order so that only a single cell changes
state from one to the next, this way a number of conﬁgurations can be compacted to
avoid calculating again the same string. Still life conﬁgurations and small oscillators
can be detected very quickly in this way. Comparison of successive generations
means that whenever the new generation is smaller, it has been already examined
and there is no need for further exploration [15].

256
G. J. Martínez et al.
The number of global states c is deﬁned by the length of the string nm. The
structure of an attractor is given in three parts. Leaves represent Garden of Eden
conﬁgurations for those global states, that means that these states have no ancestors.
Branches are conﬁgurations that have at least an ancestor and just one successor.
Height in branches determines the number of generations necessary before to reach
the attractor. So, the attractor is the ﬁnal state of a string of length n. Numbers
labelling vertices’s represent the decimal value for the string in study.
Some properties are immediate. An attractor period one (loop) determines an
evolution dominated just for one state of the alphabet. Basins constructed by cycles
for any n, they represent exactly reversible CA [14, 19], where you can move back
in the history of the system from any conﬁguration, and therefore any conﬁguration
has one ancestor.
Generally a basin can recognise CA also with chaotic or complex behaviour using
priorresultsonattractors[23].Thisway,WuenschediscoveredthatWolfram’sclasses
can be represented as a basin classiﬁcation. Talking about complex rules, a basin
will be deﬁned as:
Class IV: moderate transients, moderate-length periodic attractors, moderate
in-degree, very moderate leaf density (possibly complex dynamics).
Figure12.9 shows an attractor from a conﬁguration of length 16 for Rule 54.
This basin is made of 6,432 conﬁgurations with an attractor of four conﬁgurations.
Starting from any conﬁguration in the tree the ﬁnal conﬁguration is deﬁned by an
attractor of period four at the centre. This attractor represents concatenations of
conﬁgurations: 1000, 1101, 0010, and 0111. A small evolution (left-down) shows
its dynamics beginning from the state 48,230 and evolving during 20 generations to
reach its ﬁnal dynamics.
Figure12.10 displays an attractor from a conﬁguration of length 15 for Rule 54.
This basin shows a conﬁguration that eventually will reach to one stable state; the
attractor has period one. The tree has a mass of 1,583 conﬁgurations and a height of
20 generations.
Figure12.11 displays a large attractor from a conﬁguration of length 31 for Rule
110. This attractor included conﬁgurations with stationary localisations which can
be referred as a structure than does not move in the evolution space. It is known as a
still life conﬁguration, this name comes originally from the famous two-dimensional
binary CA Conway’s the Game of Life [1]. These mobile localisations are produced
from large and dense ramiﬁcations.
The history of a branch evolve quickly in chaotic regions with collisions of
mobile localisations before it reaches the attractor. In this case, the attractor is
a cycle period 7 on rings of 31 cells, with a mass of 54,875,513 conﬁgura-
tions to construct this basin, on a space of k31 deriving just 6,326 basins. The
attractorisdeﬁnedforthenextconﬁgurations:0110111111110001001101111100010
→1111100000010011011111000100110→1000100000110111110001001101111
→1001100001111100010011011111000→1011100011000100110111110001001
→1110100111001101111100010011011→0011101101011111000100110111110.

12
Simple Networks on Complex Cellular Automata …
257
Fig. 12.9 Cycle diagram length 16, period four, with a mass of 6,432 conﬁgurations for Rule 54
Some attractors of these lengths present periodic structures. The attractor can be
reached from many leaves, two of them are:
• 1111100001111100101000100000011 (branch 2,084,458,755),
• 1111100011101110001110111110100 (branch 2,088,181,236).
Its dynamics display fragments of stationary and non-stationary localisations
emerging during 500 and 800 generations. Starting from these conﬁgurations we
can see stationary localisations or collisions of them before to reach the attractor.
Figure12.12 displays patterns from the previous strings of length 31. Concatena-
tion of branch 2,084,458,755 yield stationary localisations (Fig.12.12a) and branch

258
G. J. Martínez et al.
Fig. 12.10 Cycle diagram length 15, period 1, with a mass of 1,583 conﬁgurations for Rule 54
2,088,181,236 yield a non-trivial synchronisation of mobile localisations colliding
(Fig.12.12b).
By calculating large attractors, we can discover landscapes of complexity in basins
featured with non-symmetric, high, and dense ramiﬁcations: these kind of ramiﬁ-
cations are indicators of ‘unpredictable’ behaviour on most large conﬁgurations.
Frequently chaotic rules tend to have symmetric basins.

12
Simple Networks on Complex Cellular Automata …
259
Fig. 12.11 Cycle diagram length 31, period 7, with a mass of 54,875,513 conﬁgurations for Rule
110
Fig. 12.12 Patterns formation from two conﬁgurations of length 31 (leaves) in Rule 110 calculated
in Fig.12.11. a stationary localisations. b non-trivial mobile localisations colliding. A ﬁlter is
selected to a better view of localisations

260
G. J. Martínez et al.
12.6
Jump-Graphs
Basins of attraction can be constructed into a meta network, called the ‘jump-graph’
by Wuensche [25]. Jump-graphs determine the next level of CA complexity by show-
ing a probability to jump to another attractor given a mutation on the same domain
of strings.
In a jump-graph the question is: What is the probability that a string wi could
mutate to another string w j? Which could induce a change of transition to another
attractor or itself (a loop, without change). This way, a conﬁguration can remains
in its attractor or jump to another attractor. We could ﬁnd connections that jump to
other attractor and later back to the original attractor with other mutation (a cycle
between basins).
Ψ (Φ(ci)) →Φ(c j)
(12.9)
Let us consider a one-bit value mutation [25]. We have a conﬁguration ci expressed
as a string wi = a0a1 . . . an−1, such than it can jump into other conﬁguration c j
expressed as a string w j = b0b1 . . . bn−1. Hence ai can mutate to one bi, where each
conﬁguration c belongs at the same ﬁeld of attractors Ψ . Also, if ai = bi, it represents
a loop in the same basin.
Figure12.13 shows a jump-graph for Rule 54 with conﬁgurations of length 20.
This ﬁeld is composed of 428 basins on a domain of k20. Each node has at least
one mutation and therefore they all are connected (it is a graph strongly connected),
determining 784,472 interconnections or mutations. For this automaton we have no
unreachable states, because all states are connected, consequently a global stability is
achieved in this system. This meta-diagram is a local universe containing basins with
volume from 62 to 29,990 conﬁgurations and they have periods oscillating between
4 to 86 conﬁgurations. Non-trivial structures emerge during these developments with
dozens of mobile localisations colliding in long transients; this implies a frequent
change of basins into this jump-graph.
Finally, Fig.12.14 shows a mutation in detail, extracted from the full jump-graph
calculated previously in Fig.12.13. There is a mutation between two attractors and
they determine a change of dynamics. This diagram displays a connection between
two basis (the basin three and the basin ﬁve as enumerated in DDLab5 [25]). The
mutation is expressed by the string x0001011111101000100 connecting both attrac-
tors where the change of dynamics implies a change of phase between stationary
mobile localisations in Rule 54.
5Discrete Dynamics Lab http://www.ddlab.org.

12
Simple Networks on Complex Cellular Automata …
261
Fig. 12.13 Jump-graph composed from a basin ﬁeld with conﬁgurations of 20 cells for ECA Rule
54. This meta-diagram consists of 428 basins yielding a ﬁeld of 784,472 interconnections given by
mutations of 1-bit value. Complex behaviour transits with a high density of connections between
basins in the full graph for this automaton

262
G. J. Martínez et al.
Ψ(Φ)
3
5
Fig. 12.14 A mutation between attractors characterised of a jump-graph in ECA Rule 54
(Fig.12.13) for strings of length 20. The ﬁrst basin (label with number three in DDLab) has a
period 18 with a mass of 6,866 conﬁgurations. The second basin (label with number ﬁve) has a
period 86 with a mass of 9,946 conﬁgurations. Both basins display dynamics with stationary local-
isations and synchronisations of small mobile localisations colliding in ECA Rule 54. Basins and
evolutions are rotated 90 degrees. A ﬁlter is selected for a better view

12
Simple Networks on Complex Cellular Automata …
263
12.7
Conclusions
CA have very low entry fee — anyone with basic coding skills can start experimenting
with CA — but very high exit fee — far from anyone can produce results publishable
in a reputable journal. This is because cell-start transition rules are appealingly sim-
ple yet space-time behaviour might be shockingly difﬁcult to analyse and predict.
There are few types of graphs/networks constructed over the cell-state transition rule
spaces which might facilitate understanding of emergence and dynamics of com-
plexity. They are de Bruijn diagrams, subsystems graphs, basins of attraction, and
jump-graphs. de Bruijn diagrams characterise interrelationships between strings rep-
resentation of the functions, they allows for some estimates of a distribution of states
in a stable conﬁguration. Subsystems graphs are determined by dynamics of travel-
ling localisations, gliders, especially by interactions between mobile localisations.
This is a promising representation especially when related to computational abilities,
in a sense of collision-based computing, of CA rules supporting mobile localisations.
Basins of attractions give us a straightforward visualisation of complexity: a number
of cycles and heigh and bushiness of trees growing on them reﬂects sensitivity and
‘chaoticity’ of the cell-state transition rules. Jump-graphs might be seen as charac-
terising rules’ tolerance to noise, mutations. There are two sides of the tolerance.
Either a noise-tolerant system is very dull and therefore difﬁcult to move to another
loci of a global state space, or the system is so sophisticated that it have an in-build
‘mechanism’ for dealing with mutation.
References
1. Adamatzky, A. (ed.): Game of Life Cellular Automata. Springer, London (2010)
2. Adamatzky, A., Martínez, G.J. (eds.): Designing Beauty: The Art of Cellular Automata.
Springer, Berlin (2016)
3. Chen, B., Chen, F., Martínez, G.J., Tong, D.: A symbolic dynamics perspective of the game of
three-dimensional life. Complex Syst. 25(1) (2016)
4. Cook, M.: Universality in elementary cellular automata. Complex Syst. 15(1), 1–40 (2004)
5. Devaney, R.: Chaotic Dynamical Systems. Addison-Wesley (1989)
6. Guan, J., Chen, F.: On symbolic representations of one-dimensional cellular automata. J. Cell.
Autom. 10(1–2), 53–63 (2015)
7. Gutowitz,H.A.,Victor,J.D.,Knight,B.W.:Localstructuretheoryforcellularautomata.Physica
D 28, 18–48 (1987)
8. Li, P., Li, Z., Halang, W.A., Chen, G.: Li–Yorke chaos in a spatiotemporal chaotic system.
Chaos, Solitons Fractals 33(2), 335–341 (2007)
9. Martínez, G.J.: A note on elementary cellular automata classiﬁcation. J. Cell. Autom. 8(3–4),
233–259 (2013)
10. Martínez, G.J., Adamatzky, A., McIntosh, H.V.: Phenomenology of glider collisions in cellular
automaton Rule 54 and associated logical gates. Chaos, Fractals Solitons 28(1), 100–111 (2006)
11. Martínez, G.J., Adamatzky, A., McIntosh, H.V.: Complete characterization of structure of rule
54. Complex Syst. 23(3), 259–293 (2014)
12. McIntosh, H.V.: Wolfram’s class IV automata and a good life. Physica D 45(1–3), 105–121
(1990)

264
G. J. Martínez et al.
13. McIntosh, H.V.: Linear cellular automata via de Bruijn diagrams. http://delta.cs.cinvestav.mx/
~mcintosh/cellularautomata/Papers_ﬁles/debruijn.pdf. Cited 10 August (1991)
14. McIntosh,
H.V.:
Reversible
cellular
automata.
http://delta.cs.cinvestav.mx/~mcintosh/
cellularautomata/Papers_ﬁles/rca.pdf. Cited 10 April (1991)
15. McIntosh, H.V.: One Dimensional Cellular Automata. Luniver Press, Bristol (2009)
16. Martínez, G.J., McIntosh, H.V., Mora, J.C.S.T.: Gliders in rule 110. Int. J. Unconv. Comput.
2(1), 1–49 (2006)
17. Martínez, G.J., McIntosh, H.V., Mora, J.C.S.T., Vergara, S.V.C.: Determining a regular lan-
guage by glider-based structures called phases ﬁ_1 in rule 110. J. Cell. Autom. 3(3), 231–270
(2008)
18. Martínez, G.J., Mora, J.C.S.T., Zenil, H.: Computation and universality: class IV versus class
III cellular automata. J. Cell. Autom. 7(5–6), 393–430 (2013)
19. Mora, J.C.S.T., Vergara, S.V.C., Martínez, G.J., McIntosh, H.V.: Procedures for calculating
reversible one-dimensional cellular automata. Physica D 202, 134–141 (2005)
20. von Neumann, J.: Theory of self-reproducing automata. In: Burks, A.W. (ed.) University of
Illinois Press, Urbana (1966)
21. Voorhees, B.H.: Computational Analysis of One-Dimensional Cellular Automata. World Sci-
entiﬁc Series on Nonlinear Science, Series A, vol. 15, Singapore (1996)
22. Tian, C., Chen, G.: Chaos in the sense of LiYorke in coupled map lattices. Physica A 376,
246–252 (2007)
23. Wuensche, A., Lesser, M.: The Global Dynamics of Cellular Automata. Santa Fe Institute
Studies in the Sciences of Complexity, Addison-Wesley Publishing Company (1992)
24. Wolfram, S.: Cellular Automata and Complexity. Addison-Wesley Publishing Company, Col-
orado (1994)
25. Wuensche, A.: Exploring Discrete Dynamics, 2nd edn. Luniver Press, Bristol (2016)

Chapter 13
A Hybrid Multi-objective Evolutionary
Approach for Power Grid Topology Design
Xiaowen Bi and Wallace K.S. Tang
Abstract Power grid is one of the critical infrastructures in human society. It is
highly complex in both structure and dynamics. In order to study its performance,
different models, such as Kuramoto oscillator network model, power ﬂow model,
cascading load model and so on, have been suggested. In this chapter, it is to demon-
strate how an evolutionary algorithm can be applied to effectively solve the topolog-
ical design problem in power grid based on the Kuramoto oscillator network model.
Recognizing that multiple criteria are commonly confronted in practice, a multi-
objective evolutionary algorithm is developed. Two objectives, namely the network
synchronizability and the cost, are considered in this work. In addition, since the
design problem is complex and nonlinear, a dedicated local searching mechanism is
embedded to enhance the searching capability of the algorithm. Finally, the effec-
tiveness of the proposed algorithm is conﬁrmed by extensive numerical simulations.
13.1
Introduction
The rapid development of complex network sciences in last two decades has greatly
enhanced the study of real-world systems. Systems, such as communication net-
works, transportation networks, social networks, biological networks, which possess
non-trivial topological features, can now be modelled as different kinds of complex
networks. Subsequently, in-depth analyses are conducted, which in turn reveal the
interaction of networked elements in these systems. Furthermore, diverse control and
design schemes are explored to achieve better system performance.
X. Bi (B) · W. K. S. Tang
Department of Electronic Engineering, City University of Hong Kong,
Kowloon, Hong Kong
e-mail: xiaowenbi2-c@my.cityu.edu.hk
W. K. S. Tang
e-mail: eekstang@cityu.edu.hk
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_13
265

266
X. Bi and W. K. S. Tang
Recently, power grid has become a major platform for the research in complex
network sciences. Being the most critical and largest artiﬁcial network on earth, dif-
ferent system models have been developed to investigate the characteristics of power
grid. For instance, [23] applied a cascading load model to study the phenomena of
cascading failure in power grid. In [26], based on power ﬂow model, an index derived
from a maximum-ﬂow concept is used to measure the vulnerability of transmission
lines. In [8] and [27], power grid is modelled as an oscillator network based on
Kuramoto-like model [15], and its synchronizability acts as a key to characterize the
stability of the power grid [4].
In addition to analyzing the reliability and stability of a power grid, work has
also been done for its planning and performance optimization. In [16], a self-healing
transmission network reconﬁguration algorithm is proposed to enable a stable operat-
ing state for power grid. In [6], an ordinal optimization scheme is applied to achieve
dynamic reconﬁguration of power grid distribution so that the power loss can be
reduced. Network protection strategy against cascading failure, which is realized
by switching off transmission line proactively, is proposed and optimized by multi-
objective evolutionary algorithm in [17].
As it is noticed, most of the previous researches only focus on a particular aspect
when the power grid is designed or improved. However, in practice, multiple criteria,
such as transmission efﬁciency, construction cost, synchronizability, robustness, etc.,
should be taken into consideration comprehensively. Moreover, the design problems
in related to power grid system are usually complex and highly nonlinear as the
dynamics of its elements cannot be simply ignored in many cases. Therefore, an
effective multi-objective optimization algorithm is urged.
On the other hand, evolutionary algorithm (EA) was ﬁrstly proposed in seventies
by considering the genetic evolution in biology. Inspired by the mechanism of evolu-
tionary process in nature, guided by the concept of “survival of the ﬁttest", EA adopts
genetic operators, such as crossover, mutation and selection, to solve an optimization
problem in a global sense. EA is particularly useful to handle problem with multi-
ple objectives and typical multi-objective evolutionary algorithms (MOEA) include
the multi-objective genetic algorithm (MOGA) [10], the niched Pareto genetic algo-
rithm (NPGA) [11], the non-dominated sorting genetic algorithm (NSGA-II) [3],
etc. Among all these, NSGA-II has received a lot of attention due to its efﬁcient
implementation and effective searching ability.
To further speed up the convergence of an evolutionary algorithm, it has been
suggested to combine with some local searching mechanisms. For example, [2] pro-
poses an EA-based approach to solve image denoising problem by applying state-of-
art denoising method and ﬁltering techniques as integrated local search and genetic
mutation, respectively. In [12], a hybrid evolutionary search for the minimum sum
coloring problem (MSCP) is presented, which mainly relies on the joint use of ded-
icated crossover operator and iterative double-phase tabu search.
Inthischapter,ahybridmulti-objectiveevolutionaryapproach,combiningNSGA-
II and a local greedy searching mechanism, is proposed to deal with the topology
design problem in power grid. As a case study, the proposed backbone of China
Ultra-High-Voltage (UHV) power grid [7] is considered and modelled by a Kuramoto

13
A Hybrid Multi-objective Evolutionary Approach …
267
oscillator network similar to those suggested in [8, 27]. In our design, two objec-
tives, namely the synchronizability and the construction cost, are considered, and the
effectivenessoftheproposedhybridGAiswelldemonstratedbyextensivesimulation
results.
The organization of this chapter is as follows. In Sect.13.2, the Kuramoto oscil-
lator network is brieﬂy introduced, and its use in modeling power grid is explained.
Using China UHV power grid as an example, the impact of topological structure
onto network synchronizability is studied. Moreover, the multi-objective topological
design problem is formulated in this section. In Sect.13.3, the design of the pro-
posed hybrid GA is described in details. Extensive simulations are performed, and
the results together with some discussions are given in Sect.13.4. Finally, the chapter
is concluded in Sect.13.5.
13.2
Power Grid and Kuramoto Oscillator Network
13.2.1
China Ultra-high-voltage Power Grid
To deal with the geographically uneven supply-and-demand power distribution, it is
essential to deliver electricity from place to place in a reliable and efﬁcient way. This
leads to the rapid development in power grid, which is now a major infrastructure for
supporting our daily life. According to the State Grid Corporation of China, China is
building a large scale of ultra-high-voltage (UHV) grid. In 2015, more than 11,900km
of UHV lines were built. Further developments in the next ﬁve years will result in
a project over seven hundred billion (HKD) [19]. Figure13.1 depicts the proposed
backbone topology of the plan of China UHV in year 2020 [7]. This infrastructure
acts as the backbone grid with North China, Mid China and East China being the
core, bringing power from remote west and north regions to main load cities, mostly
located at the east and south coasts.
13.2.2
Kuramoto Oscillator Network for Power Grid
In 1975, Kuramoto suggested a framework to study phase synchronization in coupled
oscillator networks [15]. Since then, many variants have been evolved to cope with
different practical situations, for example, with the existence of noise [1, 25], with
couplingdelayand/ortime-varyingcoupling[21],etc.Despitetheirsimplestructures,
Kuramoto models have been widely used in many real-world problems, particularly
the power grid.

268
X. Bi and W. K. S. Tang
Fig. 13.1 The proposed backbone topology of China UHV power grid plan in year 2020
The original oscillator model in [15] is of ﬁrst-order, which is expressed as:
˙θi = Ωi +
N

j=1
Kij sin(θj −θi) for i = 1, 2, · · · , N,
(13.1)
where θi and Ωi are the phase and the natural frequency of the i-th oscillator, respec-
tively; N is the total number of the oscillators in the network; Kij denotes the cou-
pling strength between oscillators i and j. The coupling is usually symmetrical, i.e.
Kij = Kji, and there is no separated cluster.
The ﬁrst-order model (13.1) has received a lot of attention because it is mathe-
matical tractable. However, in order to better represent the dynamics of the physical
devices, e.g. the generator in power grid, a second order oscillator has been adopted
as deﬁned by:
¨θi = Ωi −α ˙θi +
N

j=1
Kij sin(θj −θi)
(13.2)
where α is called the dissipation parameter.
The Kuramoto oscillator network (13.2) is particularly useful for evaluating power
grid systems [8]. This model has also been applied to study network breakdown,
facilitating the investigation of cascading failure in power grid [9, 14, 18, 24]. Hence,

13
A Hybrid Multi-objective Evolutionary Approach …
269
the second order oscillator is used in this chapter. To better reﬂect its relation with
power grid, (13.2) is rewritten as follows:
¨θi = Pi −α ˙θi + κ
N

j=1
aij sin(θj −θi)
(13.3)
where Pi is the power injection in the i-th oscillator such that Pi > 0 and Pi < 0 for a
generating node and a consuming node, respectively. In addition, according to power
conservation law, one has N
i=1 Pi = 0. κ is the coupling strength and A ≡{aij} is
the adjacency matrix of the underlined network which is undirected and connected.
Using the China UHV in Fig.13.1 as an example, it can be converted into a
network model as shown in Fig.13.2, where each node is represented by (13.3).
Considering a power grid with a set of generating nodes (V1) and a set of con-
suming nodes (V2), it is assumed that Pi = −1 for i ∈V2. The power injection of
a generating node is assumed to be proportional to its degree. Based on the power
Fig. 13.2 Kuramoto network model for 2020 China UHV power grid in Fig.13.1

270
X. Bi and W. K. S. Tang
Table 13.1 Power injection Pi of generating nodes in Fig.13.2
Node ID (i)
1
2
3
4
5
6
7
8
9
10
11
12
13
di
2
4
3
2
2
2
3
3
2
4
3
2
2
Pi
2.412 4.824 3.618 2.412 2.412 2.412 3.618 3.618 2.412 4.824 3.618 2.412 2.412
conservation law, Pi for i ∈V1, can be obtained by
Pi =
di|V2|

j∈V1 dj
(13.4)
where di is the degree of the i-th generator and |V2| is the size of the set V2. Referring
to the network in Fig.13.2, Table13.1 tabulates the degree and corresponding power
injection of the generating nodes.
13.2.3
Network Synchronizability and Topological Structure
The Kuramoto network model provides an effective framework to evaluate a power
grid system. In particular, the condition of synchronization is useful to investigate
the cascading failure and breakdown in power grid. Details can be referred to [4, 18,
24, 27].
A network of Kuramoto oscillators (13.3) is said to be in asymptotic complete
frequency synchronization (ACFS) or simply complete synchronization, when the
transversal frequency difference converges to zero asymptotically, i.e.
limt→∞
ωi(t) −ωj(t)
 = 0 ∀i, j
(13.5)
where ωi ≡˙θi is the angular frequency.
From the dynamical point of view, synchronization can be achieved if the cou-
pling strength κ is sufﬁciently large. There exists a critical value, Kc, such that when
κ ≥Kc, completely synchronization is obtained [20]. When κ is small, only portion
of the oscillators may be synchronized, which is usually referred as partial synchro-
nization. It is also common to have adjacent cluster synchronization when connected
oscillators with close natural frequency being synchronized before the complete
synchronization, yet it is not a must [13, 22].
Using the power grid model in Fig.13.2 as an example, when κ ≥Kc = 6.3109,
complete synchronization is achieved and the time response of θi is shown in
Fig.13.3a. In contrast, if κ < Kc, an unsynchronous state is observed as shown in
Fig.13.3b.

13
A Hybrid Multi-objective Evolutionary Approach …
271
Fig. 13.3 θi and ωi versus time t. a Synchronized state with κ = 6.3109 b Desynchronized state
with κ = 6.3000
13.2.4
Multi-objective Topological Design Problem
When a power grid is designed, several objectives have to be met. Typical ones
include the construction cost, the efﬁciency, the resistance to failures (eg. node failure
or link failure) and so on. Here, for illustrative purpose, only two main objectives are
focused. However, our design algorithm can be easily extended for cases with more
objectives.
In this work, a power grid with two types of elements, i.e. the power generating
unit and the consuming unit, is considered. It is represented by a graph G ≡(V, E)
where V = V1 ∪V2 is the set of nodes, and V1 and V2 denote the set of generating
units and the set of consuming units, respectively. E ⊆V × V is the set of edges to
specify the connectivity. If (i, j) ∈E, nodes i and j are connected and one also has
aij = 1 in the adjacency matrix A. Otherwise, nodes i and j are not connected and
aij = 0. (Note: Since G is undirected, we have aij = aji). In addition, each node i is
represented by the oscillator dynamical model (13.3) and it has a physical location
(xi, yi).
OP1: The design problem is then to ﬁnd a set of edges E (or the adjacency matrix
A) such that the following two objectives are optimized:
1. minimizing Kc for complete synchronization, which is to indicate the efﬁciency
of the power grid.

272
X. Bi and W. K. S. Tang
2. minimizing C = 
(i,j)∈E Dij, where Dij is the Euclidian distance between nodes i
and j based on their locations. Since the network construction cost is closely
related to the cable distance, Dij is to reﬂect the construction cost.
OP1 is highly complex and its dimension exponentially increases with the network
size. It is remarked that, although it is generally believed that removing an edge
from a network will reduce the synchronizability, and thus result in a larger Kc, the
actual relationship is non-trivial. Considering the network in Fig.13.2 as an example,
Fig.13.4 shows the resultant value of Kc after removing a particular edge from the
original graph. It shows that Kc reduces from its original value 6.3109 to 5.9313 if
edge (9, 11) is removed while increases to 8.3692 if edge (11, 44) is removed. Similar
result has also been reported in [27] for the British power grid.
Fig. 13.4 Resultant coupling threshold for synchronization (Kc) when a particular edge is removed
from the network in Fig.13.2. Note Edges colored gray are not considered as their removal will
lead to disconnected component

13
A Hybrid Multi-objective Evolutionary Approach …
273
13.3
Design of Hybrid Genetic Algorithm
In order to solve the complex and nonlinear optimization problem OP1, a hybrid
genetic algorithm (GA) has been designed. It combines the non-dominated sorting
genetic algorithm (NSGA-II) [3] and a local searching mechanism. The details of
the design are explained in the following sections.
13.3.1
Overview of NSGA-II
NSGA-II [3] is well-known for its effectiveness in solving multi-objective (MO)
problems. Dedicated operations, including fast non-dominated sorting, crowding
distance assignment, elitist strategy and so on, are applied to facilitate the searching
of the optimal solution set.
13.3.1.1
Dominance and Pareto Optimal Set
Generally, the solution set of a MO optimization problem is not a singleton. Instead, it
consists of all those solutions such that further improving of any objective will lead to
degradation of other objective(s). This is commonly referred as the Pareto optimality
and the set of solutions is called as the Pareto-optimal set. The Pareto solutions are
also termed as non-dominated solutions in which the deﬁnition of domination is
expressed below:
For an n-objective optimization problem (without loss of generality, minimization
problem is assumed), u is dominated by v if
∀i = 1, 2, · · · n, fi(u) ≥fi(v)
and
∃j = 1, 2, · · · , n, fj(u) > fj(v)
In practice, the real Pareto solution set is unknown. Therefore, it is approximated
by the non-dominated set of solutions acquired by the optimization algorithm, i.e.
NSGA-II here. During the search, the concept of dominance is applied in the ﬁtness
assignment process of NSGA-II. Solution set of each generation will be divided
into multiple non-dominated frontiers based on the dominance, and individuals will
be assigned with a ﬁtness ranking respectively depending on which frontier they
belong to. For example, the ﬁttest solutions, also known as rank-1 solutions, will be
contained in the ﬁrst non-dominated frontier, since they cannot be dominated by any
other solutions.

274
X. Bi and W. K. S. Tang
13.3.1.2
Chromosome Design
To apply NSGA-II for OP1, it is essential to encode the topological structure into a
chromosome structure. Since the adjacency matrix A in (13.3) is symmetric, only the
upper (or lower) triangle needs to be encoded. Here, a direct conversion is adopted,
in which a binary chromosome with length of 1
2N(N −1) is speciﬁed as follows:
I =

a12, a13, · · · , a1N, a23, · · · , a2N, · · · , aN−1,N

(13.6)
where N is the dimension of A. The chromosome I is transformed into A as shown
in Fig.13.5.
13.3.1.3
Repairing Mechanism
Repairing mechanism is needed because the network represented by a chromosome,
either randomly generated or obtained after the genetic operations, could be discon-
nected. The repairing mechanism is divided into two steps.
1. Connectivity inspection – The connectivity of network is ﬁrst checked by the
depth-ﬁrst search algorithm (DFS) which traverses and obtains the graph struc-
ture. If there exist m ≥2 disconnected clusters, the largest cluster is selected as
the backbone and others are connected to it by adding an edge with minimum
cost (i.e. minimum Euclidian distance).
2. Cost reduction – An edge removal process is applied to reduce the cost while
the connectivity is maintained. Edges are ﬁrstly sorted in the descending order of
cost, and then removed one by one provided that the network is still connected.
Fig. 13.5 Transformation of
a chromosome into an
adjacent matrix

13
A Hybrid Multi-objective Evolutionary Approach …
275
13.3.1.4
Operational Procedures of NSGA-II
In our design, NSGA-II is applied and its procedures are brieﬂy summarized in the
followings.
1. An initial population of chromosomes is randomly generated.
2. Each chromosome is repaired by the proposed repairing mechanism if needed,
and then the corresponding objective values (Kc and C) are computed.
3. Fast non-dominated sorting is applied to determine the non-dominated frontier
at which every chromosome is located. Afterwards, a corresponding rank value
is assigned.
4. In addition to the rank, crowding distance of each chromosome is further com-
puted to estimate the density of chromosomes surrounding. If the crowding dis-
tance is small, it means that many chromosomes with similar quality have been
found.
5. Binary tournament selection is adopted to select parents for later genetic oper-
ations (crossover and mutation). Two chromosomes are selected randomly each
time and
a. the one with smaller rank will be selected as parent;
b. if both have the same rank, the one with larger crowding distance will be
selected.
6. Offspring are generated from a group of selected parents based on crossover and
mutation operators.
7. Each offspring is repaired by the proposed repairing mechanism if needed, and
then the corresponding objective values (Kc and C) are computed.
8. Fast-non-dominated sorting is carried out again upon both offspring and the
current population. A new population is then formed for next generation based
on the following steps:
a. New population will be ﬁlled by the individuals in each frontier subsequently
until maximum population size is reached.
b. If the population size exceeds the maximum population size by adding all
members in the frontier, crowding distance will be further compared to pick
individuals from the frontier until maximum population size is reached.
9. Repeat Step 5 to Step 7 until maximum number of cycles is reached.
Further operational details of NSGA-II can be referred to [3].
13.3.2
Local Searching Mechanism
In order to solve OP1 more efﬁciently, a greedy approach is suggested to explore
solutions in local. However, it is time-consuming to evaluate each potential solution
as the computational load to obtain Kc is high. Fortunately, the studies of complex

276
X. Bi and W. K. S. Tang
networks [5] reveal that synchronizability of a graph G with N nodes is closely related
to the eigenratio R = λN
λ2 , where L is the Laplacian matrix of G and the eigenvalues
λi(L) are arranged as below:
0 = λ1 < λ2 ≤λ3 ≤... ≤λN
(13.7)
It is reported that the smaller R is, the easier the synchronization would be regard-
less of synchronized region. In our model, Kc provides the exact measure in synchro-
nizability of the oscillator network, while R could reﬂect the synchronizability of a
network from a more general sense.
The following local searching mechanism is then designed for a graph G, where
H is the number of rounds of local search.
1. Compute the eigenratio and the cost of G, recorded as R0 and C0, respectively.
Initialize Q = Γ = B = ∅for result storages and h = 0 for the iteration number.
2. For each edge ei ∈E, i = 1, 2, · · · , |E|, the following operations are performed.
The design idea is to remove one edge at a time, and then compare its impact to
the eigenvalue and the cost (Note: The cost is always reduced.).
a. Set i = 1.
b. Remove ei from G and obtain a new topology ˜G = (V, E\ei).
c. The connectivity of ˜G is checked by depth-ﬁrst search algorithm. If ˜G is
connected, go for step 2-d. Otherwise, discard
_
G and increment i by one. If
i ≤|E|, return to step 2-b; otherwise go to step 3.
d. Compute the eigenratio and the cost of the network ˜G, denoted by Ri and
Ci respectively. Store the computed results and update Q = Q ∪{(Ri, Ci)}.
Then increment i by one, and return to step 2-b if i ≤|E|.
3. For each {(Ri, Ci)} ∈Q, a metric βi is deﬁned and computed as follows:
βi = e
Ri−R0
C0−Ci
(13.8)
Store βi by updating Γ = Γ ∪{βi}.
4. Remove es from G where βs is minimum in Γ . A new topology Gs = (V, E\es)
is then obtained, and B is updated by B = B ∪Gs. Increment h by one, and if
h ≤H, go back to Step 1 with topology G = Gs.
5. Finally, ranking all the topologies in B in terms of dominance. Among all rank-1
candidates, one is randomly selected as the output of the local search.
Remark 13.1 Since edge removal assures the decrease of cost while it generally
leads to an increase of eigenratio R, a good trade-off means that the removal of a
certain edge results in a topology with a relatively signiﬁcant decrease in cost but
slightly increase in eigenratio. Therefore, edge is removed from the topology with
a minimal βi as deﬁned in (13.8). It is also remarked that, if βi < 1, the obtained
topologies are better in both the eigenratio and the cost, because C0 is always larger
than Ci and now Ri < R0.

13
A Hybrid Multi-objective Evolutionary Approach …
277
Fig. 13.6 Flow chart of proposed hybrid genetic algorithm
13.3.3
Hybrid Genetic Algorithm
By integrating the local search mechanism into NSGA-II, a hybrid GA can be estab-
lished. In this design, every individual, who has just been repaired, will be undergone
the local search mechanism. The individual will be replaced if the output from local
search is even better. NSGA-II will then operate on a better population pool, mean-
ing that more good building blocks are available. This results in a higher possibility
of ﬁnding elitist solutions in terms of synchronizability and cost. An overall ﬂow
diagram is depicted in Fig.13.6.
13.4
Simulation Results and Discussions
13.4.1
Study of Operations
Firstly, the performance of NSGA-II is investigated. Both single-point crossover
and uniform crossover are tested, together with binary mutation operator. The gen-
eral genetic parameters are given in Table13.2. To save the computation time, the
eigenratio R is used as an objective instead of Kc.
The simulation results are depicted in Fig.13.7. For comparison purpose, the
original topology shown in Fig.13.2 is referred as topology A. From Fig.13.7, solu-
tions dominating A can be obtained. Moreover, uniform crossover is more effective
for searching the non-dominated solutions. Therefore, in the following simulations,
uniform crossover is applied.

278
X. Bi and W. K. S. Tang
Table 13.2 Parameter
settings of NSGA-II used in
simulations
Genetic parameters
Values
Population size
100
Probability of crossover
0.9
Probability of mutation
0.1
Number of generations
1000
Sub-population size (offspring)
30
Evaluation rounds of local search (H)
5
Fig. 13.7 Non-dominated solution sets obtained by NSGA-II using single point crossover and
uniform crossover
As discussed in Sect.13.3.2, the threshold Kc provides an exact metric for synchro-
nizability of the oscillator network while R gives a general one. Here, the correlation
between R and Kc is investigated. Firstly, the corresponding threshold Kc for each
solution is obtained. Figure13.8 shows the value of R against Kc, and a fairly close
relationship is noticed. To better quantify the correlation, Pearson coefﬁcient is used:
ρ(kc, r) =
1
n −1
n

i=1

(kci −μkc)
σkc
 	ri −μr
σr

(13.9)
wherenreferstothenumberofscalarobservationsofeachvariable,i.e.thepopulation
size for our case; μkc and σkc are the mean and standard deviation of kc respectively,
and μr and σr are those of r.
Based on the data in Fig.13.8, one has ρ(kc, r) = 0.9560, indicating a strong
correlation between Kc and R. Therefore, by considering R in local search, Kc would
also likely be optimized.

13
A Hybrid Multi-objective Evolutionary Approach …
279
Fig. 13.8 Kc versus R
13.4.2
Effectiveness of NSGA-II with Local Search
In order to verify the effectiveness of NSGA-II with local search (referred as NSGA-
II-LS hereinafter), simulations of 1000 generations of NSGA-II and NSGA-II-LS
are conducted respectively under the same experimental conditions as given in
Table13.2. Obviously, due to the additional procedures in the local searching mecha-
nism, the computational time required in NSGA-II-LS is more than that of NSGA-II.
As shown in Fig.13.9, there is about 17% of additional computational overhead when
local search is employed. However, as observed in the simulation results depicted
in Fig.13.10, the non-dominated set obtained by NSGA-II-LS after 100 generations
dominates nearly all solutions found by NSGA-II with 150 generations being lasted.
It is because the local search can greatly enhance the capability of NSGA-II-LS to
ﬁnd elitist solutions. Together with the computational time required, it can be con-
cluded that NSGA-II-LS outperforms NSGA-II, by ﬁnding better solutions with few
generations or less time.
For further investigation, the evolution of the non-dominated solution sets found
by NSGA-II-LS against generations is plotted in Fig.13.11. It is noticed that the qual-
ity of the solutions signiﬁcantly improves from the 50-th generation to the 150-th
generation. Afterwards, very little progress is observed. Therefore, it can be con-
cluded that the NSGA-II-LS has a fast convergence rate, while it should also be
remarked that the quality of the solutions are very good due to the local search
mechanism.

280
X. Bi and W. K. S. Tang
Fig. 13.9 Computational time versus generations for NSGA-II with and without local search
Fig. 13.10 Non-dominated solution sets obtained by NSGA-II with and without local search
13.4.3
Discussions
To further investigate the quality of the solution obtained, the topology of a non-
dominated solution with Kc = 4.7580 and C = 14126.62 is chosen and depicted
in Fig.13.12. For the ease of referencing, it is referred as Topology B. It can be

13
A Hybrid Multi-objective Evolutionary Approach …
281
Fig. 13.11 The evolution process of non-dominated sets obtained by NSGA-II with local search
Fig. 13.12 Topological structure of a non-dominated solution

282
X. Bi and W. K. S. Tang
observed that Topology B keeps some connections as in Topology A. However, some
connections look odd in Topology B as longer distance is taken. Referring to those
edges marked in red in Fig.13.12, the cost of edge (51, 52) is clearly smaller than
that of edge (46, 51). Similarly, it seems to be better to have edges (18, 19) and (9,
11) than edges (16, 19) and (8, 11), respectively.
Given that the costs of edges (51, 52) and (46, 51) are 278.53 and 322.97, respec-
tively, and denote B′ as the topology with edge (46, 51) being replaced by edge (51,
52), the reduction of total cost from B to B′ is C= 322.97 −278.53 = 44.44. On
the other hand, the K′
c of Topology B′ is equal to 4.9294. It is larger than that of
Topology B which is 4.7580. Similar results are obtained for the other two pairs of
edges. If edge (16, 19) is replaced by edge (18, 19), K′
c = 4.9100. If edge (8, 11) is
replaced by edge (9, 11), K′
c = 4.8165. Therefore, it is concluded that Topology B is
a compromised solution, favouring more to minimizing the threshold Kc.
13.5
Conclusions
In this chapter, a hybrid GA is proposed and applied for multi-objective topological
design problem. As a case study, the China UHV power grid is modelled as an oscilla-
tor network using the second-order Kuramoto model. The network synchronizability
and construction cost are selected as two optimization objectives, which are mea-
sured by the critical coupling strength and the total connection distance, respectively.
Since the problem is complex and highly nonlinear, a local searching mechanism is
embedded into the NSGA-II for the enhancement of searching capability. Moreover,
eigenratio is employed as a metric in the local search to speed up the process as
computing critical coupling strength can be time consuming. This is justiﬁed by the
correlation study between the eigenratio and the critical coupling strength. As shown
in the simulation results, better solution set is obtained in much fewer generations
by hybrid GA, compared to the conventional NSGA-II. In conclusion, when a multi-
objective topological design problem is confronted, a comprehensive utilization of
proposed local search mechanism and a global searching scheme like GA is useful
and effective.
Acknowledgements The work described in this chapter was supported by a grant from City Uni-
versity of Hong Kong (Project No. 7004422) and the Alexander von Humboldt Research Group
Linkage 3.4-IP-DEU/1009882.
References
1. Bag,B.C.,Petrosyan,K.G.,Hu,C.K.:Inﬂuenceofnoiseonthesynchronizationofthestochastic
Kuramoto model. Phys. Rev. E. 76, 056210 (2007)
2. de Paiva, J., Toledo, C., Pedrini, H.: An approach based on hybrid genetic algorithm applied
to image denoising problem. Appl. Soft Comput. 46, 778–791 (2016)

13
A Hybrid Multi-objective Evolutionary Approach …
283
3. Deb, K., Pratap, A., Agarwal, S., Meyarivan, T.: A fast and elitist multiobjective genetic algo-
rithm: NSGA-II. IEEE Trans. Evol. Comput. 6, 182–197 (2002)
4. Dorﬂer, F., Chertkov, M., Bullo, F.: Synchronization in complex oscillator networks and smart
grids. Proc. Natl. Acad. Sci. USA 110(6), 2005–2010 (2013)
5. Duan, Z., Chen, G., Huang, L.: Complex network synchronizability: analysis and control. Phys.
Rev. E. 76, (2007)
6. El Ramli, R., Awad, M., Jabr, R.: Ordinal optimization for dynamic network reconﬁguration.
Electr. Power Compon. Syst. 39, 1845–1857 (2011)
7. Figure of the planning propsoal of China UHV power grid in 2020. http://upload.zgswcn.com/
2014/0516/1400221373552.png. Accessed 21 Sep 2016
8. Filatrella, G., Nielsen, A., Pedersen, N.: Analysis of a power grid using a Kuramoto-like model.
Eur. Phys. J. B. 61, 485–491 (2008)
9. Gajduk, A., Todorovski, M., Kocarev, L.: Improved steady-state stability of power grids with
a communication infrastructure. arXiv:1410.2168 (2014)
10. Fonseca, C.M., Fleming, P.J.: Multiobjective optimization and multiple constraint handling
with evolutionary algorithms - Part I: a uniﬁed formulation. IEEE Trans. Syst. Man Cybern.
Part A Syst. Hum 28(1), 26–37 (1998)
11. Horn, J., Nafpliotis, N., Goldberg, D.E.: A niched Pareto genetic algorithm for multiobjecitve
optimization. 1st IEEE Conf. Evolut. Comput. 82–87 (1994)
12. Jin, Y., Hao, J.: Hybrid evolutionary search for the minimum sum coloring problem of graphs.
Inf. Sci. 352, 15–34 (2016)
13. Judd, K.: Networked dynamical systems with linear coupling: synchronisation patterns, coher-
ence and other behaviours. Chaos 23, 043112 (2013)
14. Ko, Y., Warnier, M., Van Mieghem, P., Kooij, R., Brazier, F.: A topological investigation of
phase transitions of cascading failures in power grids. Physica A 415, 273–284 (2014)
15. Kuramoto, Y.: Self-entrainment of a population of coupled non-linear oscillators. In: Interna-
tional Symposium on Mathematical Problems in Theoretical Physics, pp. 420–422. Springer,
Berlin (1975)
16. Li, Y., Sansavini, G., Zio, E.: Non-dominated sorting binary differential evolution for the multi-
objective optimization of cascading failures protection in complex networks. Reliab. Eng. Syst.
Saf. 111, 195–205 (2013)
17. Lin, Z., Wen, F., Xue, Y.: A restorative self-healing algorithm for transmission systems based
on complex network theory. IEEE Trans. Smart Grid 7, 2154–2162 (2016)
18. Menck, P., Heitzig, J., Kurths, J., Joachim Schellnhuber, H.: How dead ends undermine power
grid stability. Nat. Commun. 5, (2014)
19. Moreno, Y., Pacheco, A.F.: Synchronization of Kuramoto oscillators in scale-free networks.
Europhys. Lett. 68, 603–609 (2004)
20. Ng, E.: China’s under-utilised ultra-high-voltage power lines no silver bullet to rid grid of bot-
tlenecks, South China morning post. http://www.scmp.com/business/article/1912878/chinas-
under-utilised-ultra-high-voltage-power-lines-no-silver-bullet-rid (2016). Accessed 04 Sep
2016
21. Nordenfelt, A., Wagemakers, A., Sanjuan, M.A.F.: Frequency dispersion in the time delayed
Kuramoto model. Phys. Rev. E. 89, 032905 (2014)
22. Pecora, L.M., Sorrentino, F., Hagerstrom, A.M., Murphy, T.E., Roy, R.: Cluster synchronization
and isolated desynchronization in complex networks with symmetries. Nat. Commun. 5, 4079
(2014)
23. Ren, H., Song, J., Yang, R., Baptista, M., Grebogi, C.: Cascade failure analysis of power grid
using new load distribution law and node removal rule. Physica A. 442, 239–251 (2016)
24. Sakaguchi, H., Matsuo, T.: Cascade failure in a phase model of power grids. J. Phys. Soc. Jpn.
81, 074005 (2012)

284
X. Bi and W. K. S. Tang
25. Vlasov, V., Macau, E.E.N., Pikovsky, A.: Synchronization of oscillators in a Kuramoto-type
model with generic coupling. Chaos 24, 023120 (2014)
26. Wang, Z., Chen, G., Hill, D., Dong, Z.: A power ﬂow based model for the analysis of vulnera-
bility in power networks. Physica A 460, 105–115 (2016)
27. Witthaut, D., Timme, M.: Braess’s paradox in oscillator networks, desynchronization and power
outage. New J. Phys. 14, 083036 (2012)

Chapter 14
Dynamic Analysis of Genetic Regulatory
Networks with Delays
Zhi-Hong Guan and Guang Ling
Abstract Many biological systems have the conspicuous property to present more
than one stable state and diverse rhythmic behaviors. A closed relationship has been
witnessed by the pioneering works between these complex dynamic behaviors and
cyclic genetic structures. This chapter analyzes the stability and bifurcation criteria of
cyclicgeneticregulatorynetworkswithtimedelays.Notonlythesinglecyclicgenetic
regulatory network but also a typical coupled cyclic genetic regulatory network
through direct communication mechanism are introduced to enlighten further the
dynamical evolution of living things.
14.1
Introduction
Genetic regulatory networks (GRNs) are complex dynamic systems which describe
interaction relationships in gene expression of living cells. By a succession of
processes of translating genotype into phenotype, GRNs provide cells with a mech-
anism to respond to environmental challenges.
Cyclic GRNs (CGRNs) refer to the ring-structured genetic networks where each
protein activates or represses another one in a cyclic way [4, 5]. Depending on
whether the gain of a network is positive or negative, CGRNs are divided into two
different classes, that is, positive CGRNs and negative CGRNs. Multistability means
that a system has the ability to present more than one stable state, especially when
two stable states exist, it is called bistability [1]. Many pioneering works have wit-
nessed the closed relationship between the cyclic genetic structure and multistability
as well as periodic oscillations [2, 4–9]. Smith studied the asymptotical behaviors
Z.-H. Guan (B)
College of Automation, Huazhong University of Science and Technology,
Wuhan 430074, P. R. China
e-mail: zhguan@mail.hust.edu.cn
G. Ling
School of Science, Wuhan University of Technology,
Wuhan 430070, P. R. China
e-mail: ling_guang0@163.com
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_14
285

286
Z.-H. Guan and G. Ling
of CGRNs whose all functions between different genes are repressions, and showed
that multistability can appear for even number of genes, while periodic oscillations
may happen for odd number of genes [10]. Elowitz et al. designed and constructed
a synthetic bacterial cyclic network in Escherichia coli which is called ‘repressila-
tor’ [26]. The repressilator consists of three genes (Tet, CI and lac) and each one
represses its downstream node. It is one of the ﬁrst attempts to generate oscillatory
phenomena in synthetic gene networks. With the theory of monotone dynamical
system, Kobayashi et al. studied the asymptotical behaviors of cyclic genetic net-
works with only positive loops [27], and Qiu studied the asymptotical behaviors of
K-repressive and K-inducible CGRNs [8]. If the nodes in a CGRN can be divided
into two subgroups, K-inducible GRNs refer to the kind of networks that the genes
within each group activate one another, but repress the nodes in the other group.
The situation in K-repressive GRNs is opposite. Wu investigated the delay depen-
dent local stability and Hopf bifurcations of a general structure of CGRNs [4]. Only
discrete time delays are taken into account in his analysis. El-Samad et al. presented
the existence conditions of periodic oscillations which were expressed explicitly in
terms of biochemical parameters [9]. Their works were based on CGRNs with three
nodes, and the mathematical deduction would be different to complete when the node
number gets larger. Hori et al. proposed a general framework to formulate negative
CGRNs using control theoretic tools, and many fruitful results about the stability
and oscillation existence in negative CGRNs are obtained [2, 5, 6].
Besides the intrinsic structure itself, the kinetics behavior of a cell is obviously
affected by its environment and the synergism of neighboring units. Diverse biochem-
ical kinetics emerge under the functions of complex external factors and thousands
of coupled cellular units with quite distinct topologies [29]. The communication
mechanism between cells is also one of the most important factors which affect
the stability and periodic rhythms of GRNs. In [30, 31], a synthetic multicellular
clock with repressilators through quorum-sensing mechanism was introduced, and
its diverse dynamics (including multistability, chaos, and so on) were illustrated. In
[32], the periodic collective behaviours of the zebraﬁsh segmentation clock through
the Delta-Notch pathway was exploited, and the inﬂuences of both Delta-Notch
coupling and intercellular coupling delays on synchronization of the segmentation
clock were analyzed. In [33], the synchronization of collective period regulated by
intercellular delays in repressively coupled negative CGRNs with quorum-sensing
mechanism was studied.
Time delays are omnipresent in many actual complex systems, such as biological,
physical, and chemical systems [19, 34]. The main processes of gene expression and
coupled functions between cells are transcription, translation and translocation. All of
the three processes exist delays due to the ﬁnite speed of biochemical and physical
reactions. It has been accepted that delays may play an important role in GRN
dynamics [20, 22, 23]. Many biological phenomena such as periodic oscillations
are usually regarded to be related with delays, as well as more rich and complicated
behaviors including multi-stability, and chaotic phenomena [20, 21]. To emphasize
the coupled interaction of the two repressilators, coupling delays between each unit
are introduced rather than in the internal connection within the units or both.

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
287
The work of this chapter is to exploit the existence criteria of local stability and
bifurcations in CGRNs [1, 25]. Both positive and negative gains are discussed to
enable us to understand the dynamics of this cyclic genetic structure as well a typical
structure of coupled CGRNs. Differential equation model is usually introduced to
describe the dynamical behaviors of GRNs. In this model, variables represent the
concentrations of mRNAs and proteins [23].
14.2
Stability Analysis for Single CGRN
Time delays signiﬁcantly exist in GRNs, and it is also widely being studied as an
important factor affecting GRN dynamics [3–5, 23]. However, for some reason many
researches focus on discrete time delays. More realistically, the function that past
statesinﬂuencethepresentshouldlastoveranintervaloftime,whichcanbepresented
by distributed time delays [11–13]. Gamma distribution delay kernel is one of the
most commonly used kernel in biological applications. The use of Gamma type
kernel in delay differential model of CGRNs in this chapter is not only because of
the attraction from the point of mathematical modelling and analytical tractability,
but also of its good description of delays in real production process of proteins and
the changes in membrane potential in cellular organisms [14–16]. In this part, we
introduce mixed time delays (discrete and Gamma type distributed delays) to mark
off the different delay processes between and inside the genes as well as to reveal
the different functions of them.
14.2.1
Problem Formulation
The dynamic relationships between different nodes with mixed time delays are for-
mulated as follows [4, 14]
˙mi (t) = −kmimi (t) + ci
 ∞
0
pi−1 (t −τ) φi−1 (τ) dτ

,
˙pi (t) = −kpi pi (t) + dimi (t −τmi) ,
i = 1, 2, . . . , n,
(14.1)
where n is the node number, when i = 1, let i −1 = n. mi and pi denote the con-
centrations of mRNA and protein of node i, respectively. kmi and kpi stand for the
degradation rates of mRNA i and protein i, respectively. di is the translation rate.
All of the above parameters are positive. τmi is the discrete time delay for protein i
and τ =
n
i=1
τmi indicate the total discrete time delays.

288
Z.-H. Guan and G. Ling
The delay kernel φi (t) is a nonnegative continuous function deﬁned on [0, +∞)
satisfying
 ∞
0 φi (τ) dτ = 1,
 ∞
0 τφi (τ) dτ < +∞. Take all φi (t) as the form of
Gamma distribution delay kernel [14, 17]
φ (t) = βq+1 tqe−βt
q!
, t ∈(0, +∞) , q = 0, 1, . . . ,
(14.2)
where β is a positive parameter representing the decay rate of the effects of past
memories. q is a shape parameter affecting the importance of a certain time, that is,
whether the current events have the most importance or a particular time in the past
is more important.
ci (pi−1 (t)) is a nonlinear monotonic function of Hill form
ci (pi−1 (t)) =
⎧
⎪⎪⎨
⎪⎪⎩
ai
 pi−1(t)
bi
hi
1+
 pi−1(t)
bi
hi , if gene i −1 is an activator of gene i;
ai
1
1+
 pi−1(t)
bi
hi , if gene i −1 is a repressor of gene i,
where hi is Hill coefﬁcient indicating the degree of cooperativity. ai and bi are
transcription coefﬁcients. Introduce a class of structure variables si, and let si = 1,
when gene i −1 is an activator of gene i, otherwise, si = 0. ci(pi−1) can be written
into
ci (pi−1) =
(−1)siaibi hi
bi hi + (pi−1)hi + siai.
(14.3)
Let
s = n −
n

i=1
si
indicate the total number of repressors in the whole cyclic system. When the total
number of repressors s is odd, the CGRN is equivalent to a negative gain network
topologically, and it is a negative CGRN, otherwise, it is a positive CGRN.
14.2.2
Stability Analysis for Positive CGRNs
The existence of unique equilibrium for a negative CGRN and at least one equi-
librium for a positive CGRN have respectively been shown by Poincar-Bendixson
theorem and theory of monotone system. Let N denote the number of equilibriums
in a CGRN. When N ≥1, (m∗, p∗) indicates an arbitrary equilibrium where m∗=

m∗
1, m∗
2, . . . , m∗
n

and p∗=

p∗
1, p∗
2, . . . , p∗
n

, especially when N = 1, (m∗, p∗)
indicates the unique equilibrium. If N > 1, the equilibrium l is denoted as

ml∗, pl∗

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
289
(l = 1, . . . , N). (m0, p0) indicates a certain initial condition. Let ρi = kmikpi
aidi indicate
the ratio between degradation effects and polymerization functions in node i. Let
γ =
n
i=1
hi

1 −ρi pi
∗
,
ζ = βn(q+1)
n
i=1
kmikpihi

1 −ρi pi
∗
=βn(q+1)γ
n
i=1
kmikpi
be continued products of biochemical parameters, distributed delays and concentra-
tion level of a certain equilibrium in all nodes.
For a positive CGRN, the number of repressors s is even. The system may have
more than one equilibrium, the characteristic equation of the linearized system at
arbitrary equilibrium is
Δ1 (λ) = (λ + β)n(q+1)
n
i=1
(λ + kmi)

λ + kpi

−ζe−λτ = 0.
(14.4)
Theorem 14.2.1 For an arbitrary equilibrium in a positive CGRN (14.1) with mixed
time delays, if γ > 1, the CGRN is unstable at the equilibrium for any discrete time
delay τ ≥0; and the system presents a saddle-node bifurcation when γ = 1.
Theorem 14.2.2 For an arbitrary equilibrium in a positive CGRN (14.1) with mixed
time delays, the system is locally stable if and only if γ < 1.
Based on Theorems 14.2.1 and 14.2.2, whether a equilibrium of a positive CGRN
is locally stable or unstable is totally decided by the value of γ , which is composed
of biochemical parameters and the equilibrium itself. The stability has no direct
relationship with time delays including both discrete and distributed time delays.
14.2.3
Stability Analysis of Negative CGRNs
A negative CGRN refers to the network whose number of repressors s is odd. Unique
equilibrium exists for this kind of genetic structure, and the characteristic equation
at its equilibrium is
Δ2 (λ) = (λ + β)n(q+1)
n
i=1
(λ + kmi)

λ + kpi

+ ζe−λτ = 0.
(14.5)
The stability and Hopf bifurcation conditions under three different situations can
be established as follows.

290
Z.-H. Guan and G. Ling
Theorem 14.2.3 For a negative CGRN (14.1) with distributed time delays but with-
out discrete time delays τ = 0, if γ > 1, there must exist a ζ0
ζ0 =

β2 + ω0
2 n(q+1)
2
n
i=1

kmi 2 + ω02

kpi 2 + ω02,
(14.6)
where ω0 satisﬁes
n (q + 1) arctan ω0
β +
n

i=1

arctan ω0
kmi
+ arctan ω0
kpi

= π,
(14.7)
such that the following conclusions hold:
• The negative CGRN is locally stable at its equilibrium when ζ ∈(0, ζ0);
• When ζ = ζ0, the system presents a Hopf bifurcation, which results in periodic
oscillations.
Theorem 14.2.4 For a negative CGRN (14.1) with distributed time delays and any
discrete time delay τ ̸= 0, if γ > 1 and ζ < ζ0 (deﬁned as Eq.(14.6)), there must
exist a τ0
τ0 = π −∠g ( jσ0)
σ0
,
(14.8)
where σ0 is the only root of equation

β2 + σ02 n(q+1)
2
n
i=1

kmi 2 + σ02

kpi 2 + σ02 = ζ,
such that the following conclusions hold:
• The negative CGRN is locally stable at its equilibrium when τ ∈(0, τ0);
• The negative CGRN presents a Hopf bifurcation at τ = τ0, and when τ > τ0 the
system demonstrates periodic oscillations.
Theorem 14.2.5 For a negative CGRN with mixed time delays (14.1), the system is
locally stable if and only if γ ≤1.
There exist two important comprehensive parameters for the stability and oscil-
lation behaviors in a negative CGRN, that is, γ and ζ. The critical values for the two
parameters respectively are 1 and ζ0, where ζ0 decided by Eq.(14.6) depending on
the system size, biochemical parameters and distributed time delays.
When γ < 1, the equilibrium is delay independently stable for any mixed time
delay. While if γ > 1 and ζ < ζ0, a critical discrete time delay τ0 existes which is
decreasing with ζ. Under this situation, discrete time delays play an important role
in changing the system stability. The equilibrium can keep its stable state only when
discrete time delays are short enough, concretely, τ < τ0. At last, when ζ > ζ0, the
negative CGRN will always present oscillation behaviors for any discrete delay.

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
291
(a)
(b)
Fig. 14.1 Tri-node CGRN examples: a a positive CGRN; b a negative CGRN
14.2.4
Examples for CGRNs
As noted earlier, dynamic representation of a CGRN depends on its structure size,
biochemical parameters and equilibriums. Two speciﬁc CGRNs with three nodes are
introduced to test our results and assist our further explanation. One is a synthetic
positive CGRN, and the other is ‘repressilator’ - a synthetic negative CGRN in
Escherichia coli [26]. Their structures are illustrated in Fig.14.1 where ‘⊣’ denotes
the repression function and ‘→’ stands for activation. Simulation procedures describ-
ing the behaviors of the two CGRNs with Gamma type distributed delay kernel are
carried out by ‘linear chain trick’ [18].
The equilibrium concentrations of mRNAs and proteins are decided by structure
size n, Hill coefﬁcients hi and the ratios between degradation and polymerization
function ρi (i = 1, 2, . . . , n) in all nodes. As more than one equilibrium may exist
for a positive CGRN, the equilibrium may be not a single valued function about the
parameters.
The parameter γ pays a decisive role in its equilibrium stability. As the deﬁnition
of γ , the local stability of positive CGRNs depends on n, hi, ρi as well as the
equilibrium concentration itself p∗
i , but has no direct relationship with time delays
including both discrete and distributed time delays. The critical value of γ is 1 and
the CGRN is locally stable for a certain equilibrium if and only if the corresponding
γ < 1. The larger the value of γ is, the more unstable the system becomes. The
concrete effects of related parameters are analyzed though the following example.
Example 2.1. Consider the positive CGRN illustrated by Fig.14.1a and its differential
equation model is
˙m1 (t) = −kmm1 (t) +
a
1 +
 ∞
0
p3 (t −τ) φ (τ) dτ
h ,
˙m2 (t) = −kmm2 (t) +
a
1 +
 ∞
0
p1 (t −τ) φ (τ) dτ
h ,

292
Z.-H. Guan and G. Ling
0
2
4
6
8
10
0
1
2
3
4
5
6
7
8
9
Transcription coefficient a
Concentration of protein 1
(a) Stability variation with a (h = 2).
1
1.5
2
2.5
3
3.5
4
4.5
5
0
1
2
3
4
5
6
Hill coefficient h
Concentration of protein 1
(b) Stability variation with h (a = 5).
Fig. 14.2 Sanddle-node bifurcations for the positive CGRN (14.9) with different typical parameters
˙m3 (t) = −kmm3 (t) +
a
 ∞
0
p2 (t −τ) φ (τ) dτ
h
1 +
 ∞
0
p2 (t −τ) φ (τ) dτ
h ,
˙pi (t) = −kp pi (t) + dmi (t −τm) ,
i = 1, 2, 3.
(14.9)
In this positive CGRN, h1 = h2 = h3 = h and ρ1 = ρ2 = ρ3 = ρ = kmkp
ad . To
study the role played by ρ, ﬁx km = 1, kp = 0.2, d = 0.2 and ρ = 1/a. The role
played by ρ is opposite to that of a. Fig.14.2 shows the equilibrium existence with
the two parameters h and a. The equilibrium concentration of protein 1 is depicted
representatively. The blue marker ’·’ indicates that the corresponding equilibrium
concentration is locally stable and the red marker ’∗’ means unstability.
From Fig.14.2, there is a unique equilibrium for small values of both a and h. With
the increasing of two parameters, saddle-node bifurcations will occur, and then the
CGRN will exist three equilibriums. Two of the equilibriums are always stable and
the other is unstable no matter how large values the two parameters read. Obviously,
the larger the system size is, the more possible the system has multiple equilibriums.
The number of the system nodes determines the polynomial exponent to solve the
equilibrium concentrations, and so decides the largest number of equilibriums the
system may have. When more than one equilibrium exists, the stability of each
equilibrium may be different and the system has the ability to present multistability.
Forexample,leta = 5,h = 2andtheGammatypedistributedkernelφ (t) = te−t,
all the other parameters are the same. Three equilibriums exist for the positive CGRN

m1∗, p1∗
= (0.2088, 4.7911, 4.7913, 0.2088, 4.7911, 4.7913) ,

m2∗, p2∗
= (3.3939, 0.3994, 0.6879, 3.3939, 0.3994, 0.6879) ,

m3∗, p3∗
= (4.7913, 0.2087, 0.2087, 4.7913, 0.2087, 0.2087) .

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
293
0
50
100
150
200
250
300
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Concentration of proteins
t
protein 1
protein 2
protein 3
(a) Evolution trajectories of proteins
0
1
2
3
4
5
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Concentration of protein 1
Concentration of mRNA 1
(b) Phase diagram of node 1
Fig. 14.3 Dynamics of the positive CGRN (14.9) with discrete delays τm = 3 and initial condition
(m0, p0) = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1)
0
50
100
150
200
250
300
350
400
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Concentration of proteins
t
(a) Evolution trajectories of protein 1
0
1
2
3
4
5
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Concentration of proteins
Concentration of mRNAs
(b) Phase diagram of node 1
Fig. 14.4 Bistability of the positive CGRN (14.9) with random initial conditions and τm = 3
The ratio ρ = 0.2, and the parameter γ for the three equilibriums are γ1 =
0.0134 < 1,γ2 = 2.0392 > 1,γ3 = 0.3066 < 1,respectively.FromTheorem14.2.2,
the positive CGRN is locally stable at 1st and 3rd equilibriums but unstable at 2nd
equilibrium. Which state does the system converge to in the long run depends on
different initial conditions. Fig.14.3 illustrates the local stability of 1st equilibrium
by dynamics trajectories and phase diagram of mRNA and protein in node 1. The
initial condition is (m0, p0) = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1) and discrete time delays
τm = 3 are taken. The bistability of the positive CGRN with random initial con-
ditions is shown in Fig.14.4 in which the red marker ’*’ indicates equilibrium
concentrations of mRNA and protein. The positive CGRN converges to the 1st and
3rd equilibrium positions with several random initial conditions.
For a negative CGRN, unique equilibrium exists. The equilibrium is a single
valued function of related parameters and is entirely decided by them. So the
effect of equilibrium itself doesnot be discussed here. There are two comprehensive

294
Z.-H. Guan and G. Ling
parameters γ and ζ for the stability criteria of negative CGRNs, and both of them
are decided by structure size n, Hill coefﬁcients hi, the ratios between degradation
and polymeric rates ρi and distributed delay kernel φ (t). The following example is
introduced to understand the effects of related parameters.
Example 2.2. The kinetic mathematical model of the negative CGRN ‘repressilator’
shown by Fig.14.1b with mixed time delays is expressed as
˙mi (t) = −kmmi (t) +
a
1 +
 ∞
0
pi−1 (t −τ) φ (τ) dτ
h ,
˙pi (t) = −kp pi (t) + dmi (t −τmi) ,
i = 1, 2, 3.
(14.10)
The repressilator is cyclically symmetrical, h1 = h2 = h3 = h, ρ1 = ρ2 = ρ3 =
ρ = kmkp
ad
and the equilibrium satisﬁes m∗
1 = m∗
2 = m∗
3, p∗
1 = p∗
2 = p∗
3. Similar to
the analysis of Example 2.1, let km = 2, kp = 2.5, d = 1. The function played by ρ
is also discussed though a whose effect tendency is opposite.
Discrete time delays play a critical role in changing the system stability when
γ > 1 and ζ < ζ0, while for Gamma type distributed delays, the function is different.
Three different situations of stability and bifurcation are illustrated to test our results
further. Still let parameters km = 2, kp = 2.5, h = 3, d = 1 and Gamma distributed
delay kernel φ (t) = e−t. The initial condition is (m0, p0) = (1, 1, 1, 1, 1, 1). The
various dynamic phenomena are shown with different a (Figs.14.5, 14.6, and 14.7).
When a = 5, the only equilibrium of the negative CGRN is

m∗
1, m∗
2, m∗
3, p∗
1, p∗
2, p∗
3

= (1.8112, 1.8112, 1.8112, 0.7245, 0.7245, 0.7245) .
0
50
100
150
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4
Concentration of mRNA and protein in node 1
t
mRNAs
protein
(a) Evolution trajectories
1
1.2
1.4
1.6
1.8
2
2.2
2.4
0.4
0.5
0.6
0.7
0.8
0.9
1
Concentration of protein 1
Concentration of mRNA 1
(b) Phase diagram
Fig. 14.5 The local stable concentrations of mRNA and proteins in 1st node when γ < 1
(τm = 2, a = 5)

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
295
0
20
40
60
80
100
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4
t
Concentration of mRNA and protein in node 1
mRNA
protein
(a) τ = 0
0
500
1000
1500
0
0.5
1
1.5
2
2.5
3
Concentration of mRNA and protein in node 1
t
mRNA
protein
(b) τ = 24 > τ0
Fig. 14.6 The concentration evolutions of mRNA and protein in 1st node with different discrete
time delays τ when γ > 1 and ζ < ζ0 (a = 6)
0
100
200
300
400
500
600
700
0.5
1
1.5
2
2.5
3
3.5
Concentration of mRNA and protein in node 1
t
mRNAs
protein
Fig. 14.7 The concentration evolutions of mRNA and protein in 1st node when ζ > ζ0 (a = 7.7)
The parameter γ = 0.5646 < 1. Based on Theorem 14.2.5, the negative CGRN is
stable for any discrete time delay. Fig.14.5 shows its local stability with discrete
delays τmi = 2 for each i = 1, 2, 3.
When a = 6, the equilibrium of the negative CGRN is

m∗
1, m∗
2, m∗
3, p∗
1, p∗
2, p∗
3

= (1.9921, 1.9921, 1.9921, 0.7968, 0.7968, 0.7968).
The critical value for Hopf bifurcation without discrete time delay ζ0 = 239.1829,
and parameters γ = 1.0239 > 1, ζ = 127.9880 < ζ0. Based on Theorem 14.2.4, a
critical discrete time delay τ0 = 23.9754 exists, when the total discrete time delays
satisfy τ < τ0, the system is locally stable, while when τ = τ0, a Hopf bifurcation

296
Z.-H. Guan and G. Ling
happens. Fig.14.6a illustrates the stable evolution of mRNA and protein in node 1
without discrete delays, and (b) shows their periodic oscillations with τ = 24 > τ0.
Here τmi = 7, 8, 9 for i = 1, 2, 3, respectively.
When a = 7.7, the equilibrium of the negative CGRN is

m∗
1, m∗
2, m∗
3, p∗
1, p∗
2, p∗
3

= (2.2397, 2.2397, 2.2397, 0.8959, 0.8959, 0.8959).
The parameters γ = 1.9757 > 1 and ζ = 246.9660 > ζ0 = 239.1829. By Theorem
14.3.3, both mRNA and protein in each node present periodic oscillations for any
discrete time delay, which are shown by Fig.14.7. Very small discrete time delays
τmi = 0.01, 0.02, 0.01 (i = 1, 2, 3) are taken.
14.3
Stability Analysis for Coupled CGRNs
As referred above, CGRNs are a kind of GRNs in which all nodes are organized in a
ring structure. The integrated network can be treated as a unit at the cellular level. The
coupled CGRNs consisting of two units is analyzed in our paper whose topology can
bedemonstratedasFig.14.8,where“→”standsforthearbitraryrelationshipbetween
internal nodes inside each CGRNs, either activation or repression function, “”
means some nodes are omitted here, and “⊣” means repression function between the
two subunits.
In this part, we exploit the dynamical evolution of coupled CGRN through two
examples. One is a double-negative feedback loop with positive autoregulations
(DNFLPAs) which is the simplest structure of coupled positive CGRNs. Another one
is double-negative feedback loop with negative autoregulations whose subnetwork
has only one node with negative gain. Both are very common in developmental
transcription networks [28]. The last example is the inhibitory coupled repressilators.
The repressilator is a typical negative CGRN which is ﬁrst synthesized to study the
oscillatory phenomena [26].
Fig. 14.8 Schematic representation of the inhibitory coupled CGRNs

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
297
Fig. 14.9 Double-negative
feedback loop with positive
autoregulations
14.3.1
Dynamical Pattern for DNFLPAs
The structure of the DNFLPAs is shown in Fig.14.9 in which “→” stands for acti-
vation function, and “⊣” still means repression function. The mathematical model
of DNFLPAs is
˙m1 (t) = −kmm1 (t) +
α p1h (t)
1 + p1h (t) +
γ
1 + p2h (t −τc),
˙m2 (t) = −kmm2 (t) +
α p2h (t)
1 + p2h (t) +
γ
1 + p1h (t −τc),
˙pi (t) = −kp pi (t) + dmi (t) ,
i = 1, 2.
Based on Theorem 2.1 in [24], the existence conditions for multiple equilibriums
are
max

g

ud
2

, 0

< k2 < g

ud
1

, k1 >
√
3,
(14.11)
where g (u) = 2
9

3 −k2
1

u + 1
9k1, ud
1,2 =
k1±√
k2
1−3
3
. For arbitrary equilibrium (m1∗,
m2∗, p1∗, p2∗), the stability criteria are
(k1 + k2) ζ1 < 1,
(14.12)
where k1 =
αd
kmkp , k2 =
γ d
kmkp .
To understand the mechanism of each biochemical parameter on multistability of
our subject, an explanation for the theorems is given combined with some numerical
simulations.
When Eq.(14.11) is satisﬁed, the DNFLPAs have three equilibriums. When a sys-
tem has the ability to represent more than one stable states, different initial conditions
x0 may change the dynamics of the system completely. Let km = kp = d = 1, a =
2.5, γ = 0.06, h = 2, it is easy to see that k1 = a = 2.5, k2 = γ = 0.06. Three pos-
itive equilibriums exist for the system which are (2.0196, 2.0196, 2.0196, 2.0196),
(0.4076, 0.4076, 0.4076, 0.4076), (0.0729, 0.0729, 0.0729, 0.0729), separately.
Both the two equilibriums with larger and smaller value are stable and the middle
equilibrium is unstable. Figure14.10 demonstrates the evolution of related biochem-
ical products x = x(x0, t) under different initial conditions x0. In the ﬁgure, solid
blue lines stand for the evolution of related biochemical products and the red sym-
bols mark the points of three equilibriums. All the initial conditions are produced
randomly and the system represents bistability.

298
Z.-H. Guan and G. Ling
0
5
10
15
20
25
0
0.5
1
1.5
2
2.5
Concentration of protein 1
t
(a) trajectory chart
0
0.5
1
1.5
2
2.5
3
0
0.5
1
1.5
2
2.5
3
Concentration of protein 1
Concentration of mRNA 1
(b) phase diagram
Fig. 14.10 System bistability with parameters km = kp = d = 1, a = 2.5, γ = 0.06, h = 2
0
5
10
15
20
25
0
0.5
1
1.5
2
2.5
Concentration of protein 1
t
(a) trajectory chart
0
0.5
1
1.5
2
2.5
3
0
0.5
1
1.5
2
2.5
3
Concentration of protein 1
Concentration of mRNA 1
(b) phase diagram
Fig. 14.11 System monostability with parameters km = kp = d = 1, a = 2.5, γ = 0.6, h = 2
Let γ = 0.6 with all the other parameters unchanged, that is, km = kp = d = 1,
a = 2.5, γ = 0.6, h = 2. The system only has one positive equilibrium (2.1662,
2.1662, 2.1662, 2.1662) and its values of stability judgment condition kmkp −
(α + γ ) dζ1 = 0.5855. The system has and only has one stable positive equilib-
rium and represent monostability. Figure14.11 shows the evolutions of protein 1
under different random initial conditions x0.
14.3.2
Dynamical Pattern for Coupled Repressilators
As stated above, repressilators are a kind of GRNs synthesized in Escherichia coli
wherein the plasmid upstream has a repressing function on its downstream one [26].
The coupled repressilators consisting of two units is introduced in this part whose

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
299
Fig. 14.12 The new coupled
repressilators
topology can be demonstrated as Fig.14.12 for simpliﬁcation. Each repressilator can
be treated as a unit at the cellular level and inhibits the other in a direct way. The
study of the new coupled structure can help us understand the interacting mechanism
between different cells better.
The key biochemistry processes of gene expression in repressilators are transcrip-
tion and translation, i.e., DNAs are ﬁrst copied to mRNAs, and then the mRNAs are
translated into proteins [1, 28]. It is natural to use differential equation model to
describe the dynamical behaviors of GRNs [26]. Here we treat all the nodes as iden-
tical for simplicity, and the dynamics of the coupled repressilators can be formulated
as
˙m1 (t) = −m1 (t) +
α
1 + p3h (t) +
γ
1 + p4h (t −τ),
˙m4 (t) = −m4 (t) +
α
1 + p6h (t) +
γ
1 + p1h (t −τ),
˙mi (t) = −mi (t) +
α
1 + pi−1h (t),
i = 2, 3, 5, 6,
˙pi (t) = −β pi (t) + βmi (t) ,
i = 1, 2, . . . , 6,
(14.13)
where mi ∈[0, +∞) and pi ∈[0, +∞) denote the mRNA and protein concentra-
tions of the ith node, respectively. α is the maximal transcription rate and γ indi-
cates coupling strength between repressilators. The nonlinear function f (p) =
1
1+ph
reﬂects the synthesis mechanism of mRNAs from proteins. h is Hill coefﬁcient and
h = 2 in the original repressilator model. β is a ratio between the decay rates of
proteins and mRNAs. All of the above parameters are positive. τ ∈[0, +∞) is the
nonnegative coupling delay.
Theorem 14.3.1 For the coupled repressilators (14.13), unique positive equilibrium
exists.

300
Z.-H. Guan and G. Ling
If there is no coupling delay in the coupled repressilators (14.13), i.e. τ = 0, the
characteristic equation of the system is
Δ± (λ) = (λ + 1)3(λ + β)3 + δ ± η(λ + 1)2(λ + β)2=0,
(14.14)
where δ = α3β3
3
i=1
ζi, η = γβζ1. That is
Δ± (λ) = λ6 + a5λ5 + a4
±λ4 + a3
±λ3 + a2
±λ2 + a1
±λ + a0
±,
(14.15)
where
a5 = 3 + 3β,
a4
± = 3 + 9β + 3β2 ± η
a3
± = 1 + 9β + 9β2 + β3 ± 2η ± 2ηβ,
a2
± = 3β + 9β2 + 3β3 ± η ± 4ηβ ± ηβ2,
a1
± = 3β2 + 3β3 ± 2ηβ ± 2ηβ2,
a0
± = β3 + δ ± ηβ2.
(14.16)
Remark 14.1 a4± indicates two separate number a4+ and a4−, which is same with
notation Δ±, speciﬁcally a4+ = 3 + 9β + 3β2 + η and a4−= 3 + 9β + 3β2 −η.
This also holds for the other ai ±, i = 0, 1, 2, 3 and other related symbols in the
following text.
For biochemical signiﬁcance, a5 is always positive. Denote that
D1
± =

a5
1
a3± a4±
 ,
D2
± =

a5
1
0
a3± a4± a5
a1± a2± a3±

,
D3
± =

a5
1
0
0
a3± a4± a5
1
a1± a2± a3± a4±
0 a0± a1± a2±

,
D4
± =

a5
1
0
0
0
a3± a4± a5
1
0
a1± a2± a3± a4± a5
0 a0± a1± a2± a3±
0
0
0 a0± a1±

,
D5
± =

a5
1
0
0
0
0
a3± a4± a5
1
0
0
a1± a2± a3± a4± a5
1
0 a0± a1± a2± a3± a4±
0
0
0 a0± a1± a2±
0
0
0
0
0 a0±

=a0
±D4
±.

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
301
Based on Routh-Hurwitz criterion, the following conclusion holds without proof.
Theorem 14.3.2 The equilibrium of coupled repressilators (14.13) without coupling
delay is stable if and only if Di ± > 0 for each i = 1, . . . , 5.
When coupling delays in coupled repressilators satisfy τ ̸= 0. The lemma is intro-
duced to analyze the stability of equilibrium [35].
Lemma 14.3.1 Consider the exponential polynomial
P

λ, e−λτ1, . . . , e−λτm
= λn + p(0)
1 λn−1 + · · · + p(0)
n−1λ + p(0)
n
+

p(1)
1 λn−1 + · · · + p(1)
n−1λ + p(1)
n

e−λτ1 + · · ·
+

p(m)
1 λn−1 + · · · + p(m)
n−1λ + p(m)
n

e−λτm,
(14.17)
where τi ≥0 (i = 1, . . . , m) and p(i)
j (i = 0, 1, . . . , m; j = 1, 2, . . . , n) are con-
stants. As (τ1, τ2, . . . , τm) vary, the sum of the orders of the zeros of P

λ, e−λτ1
, . . . , e−λτm
on the open right half plane can change only if a zero appears on or
crosses the imaginary axis.
This lemma tells that it is important to investigate the root distribution of system
characteristic equation, especially when the equation has a zero root or pairs of pure
imaginary roots. However, for the coupled repressilators, we need not pay much
attention to the zero characteristic root based on prior works [1].
The characteristic equation of coupled repressilators with coupling delays is
Δ± (λ) = (λ + 1)3(λ + β)3 + α3β3
3

i=1
ζi ± γβζ1e−λτ(λ + 1)2(λ + β)2=0.
(14.18)
Let λ = ±jω (ω > 0) be a pair of pure imaginary roots, j is the imaginary unit.
(jω + 1)3(jω + β)3 + δ ± ηe−jωτ(jω + 1)2(jω + β)2 = 0.
(14.19)
where δ, η are the same with the deﬁnition of Eq.(14.14). Separate the real and
imaginary part
b1 + b2 cos (ωτ) +b3 sin (ωτ) = 0,
b4 −b2 sin (ωτ) + b3 cos (ωτ) = 0,
where

302
Z.-H. Guan and G. Ling
b1 =

1 −3ω2 
β3 −3βω2
−

3ω −ω3 
3β2ω −ω3
+ δ,
b2 = ±η

1 −ω2 
β2 −ω2
−4ω2β

,
b3 = ±2ηω

1 −ω2
β + β2 −ω2
,
b4 =

1 −3ω2 
3β2ω −ω3
+

3ω −ω3 
β3 −3βω2
.
It follows that
sin (ωτ) = b2b4 −b1b3
b2
2 + b2
3
,
cos (ωτ) = −b1b2 + b3b4
b2
2 + b2
3
.
(14.20)
As explained before, the imaginary roots of the Eq.(14.18) play an important role
in stability changes. Based on equation (14.19), the dependence on imaginary roots
of Eq.(14.18) is decided by Eq.(14.20) which contains two elements, that is, ω and
τ. Whether Eq.(14.20) has positive root ω reﬂects the existence of both imaginary
roots ±jω in Eq.(14.18) and the critical coupling delay τ at which moment local
stability may change.
To solve the two element nonlinear equation(14.20), let sin2(ωτ) + cos2(ωτ) =
1, it deduces that
ω20 + c9ω18 + c8ω16 + c7ω14 + c6ω12
+ c5ω10 + c4ω8 + c3ω6 + c2ω4 + c1ω2 + c0 = 0,
(14.21)
where
c9 = 5β2 + 5,
c8 = 10β4 + 25β2 + 10 −η2,
c7 = 10β6 + 50β4 +

50 −4η2
β2 −4η2 −2δ + 10,
c6 = 5β8 + 50β6 +

100 −6η2
β4 +

50 + 2δ −16η2
β2 + 2δ + 5
+18βδ −6η2,
c5 = β10 + 25β8 +

100 −4η2
β6 +

10δ + 100 −24η2
β4 + 30βδ
+30δβ3 +

25 −24η2 −2δ

β2 −4η2 + 1 + 10δ,
c4 = 5β10 +

50 −η2 
β8 +

6δ −16η2 + 100

β6 + 6β5δ + 50β3δ
+

50 −10δ −36η2
β4 +

5 −16η2 −10δ

β2 + δ2 + 6δ −η2
+6βδ,
c3 = 10β10 +

50 −4η2
β8 −6β7δ +

50 −6δ −24η2
β6 + 10β5δ
+

10 −24η2 −50δ

β4 + 10β3δ +

2δ2 −4η2 −6δ

β2 −6βδ
+2δ2,

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
303
c2 = 10β10 +

25 −6η2
β8 −10β7δ +

10 −30δ −16η2
β6 + 2β5
×δ +

δ2 −30δ −6η2
β4 −10β3δ + 4δ2β2 + δ2,
c1 = 5β10 +

5 −4η2
β8 −2β7δ −

4η2 + 18δ

β6 −2β5δ + 2δ2β4
+2δ2β2,
c0 = β10 −η2β8 + 2β7δ + δ2β4.
Denote z = ω2, Eq.(14.21) becomes
z10 + c9z9 + c8z8 + c7z7
+ c6z6 + c5z5 + c4z4 + c3z3 + c2z2 + c1z + c0 = 0.
(14.22)
The number of positive roots of Eq. (14.22) reﬂects the pair number of pure
imaginary roots of Eq. (14.21) which inﬂuences greatly on the kinetics of coupled
repressilators. The critical delay also can be obtained naturally by Eq. (14.20).
Let N stand for the number of positive roots. Suppose that N ≥1, Eq.(14.21)
at least has one pair of pure imaginary roots. Denote ±jωi is one pair of them,
for i = 1, . . . , N. Each ωi satisﬁes equation(14.20). Introduce arctangent function
arctan (ωiτ), the two branches of critical coupling delays of the function (14.18) are
obtained by adding multiples of π or 2π respectively. With the sign of cos (ωiτ), we
have
τi,k = 1
ωi
⎧
⎨
⎩
arctan b1b3−b2b4
b1b2+b3b4 + (2k + 1) π, b1b2 + b3b4 > 0,
arctan b1b3−b2b4
b1b2+b3b4 + 2kπ,
b1b2 + b3b4 < 0,
(14.23)
where k = 0, 1, 2, . . . and at the same time these branches should yield τi,k > 0.
Especially when N = 1, denote
τ0 = min

τ1,k, k = 0, 1, 2, . . .

.
(14.24)
Make the derivative of λ with respect to τ in Eq.(14.18)
dλ
dτ =
±ηe−λτλϕ (λ)
3ϕ (λ) (2λ + β + 1) ± ηe−λτ [−τϕ (λ) + 4λ + 2β + 2]
=
−λϕ (λ)

ϕ3 (λ) + δ

3ϕ3 (λ) (2λ + β + 1) +

ϕ3 (λ) + δ

[τϕ (λ) −4λ −2β −2]
=
−λϕ (λ)

ϕ3 (λ) + δ

ϕ3 (λ) (τϕ (λ) + 2λ + β + 1) + δ [τϕ (λ) −4λ −2β −2].
(14.25)
where ϕ (λ) = (λ + 1) (λ + β). The transversality conditions are

304
Z.-H. Guan and G. Ling
TC

ωi, τi,k

= dRe (λ)
dτ

λ=jωi,τ=τi,k
= Re

dλ
dτ

λ=jωi,τ=τi,k

.
(14.26)
The sign of the transversality condition at τi,k reﬂects the change in the number
of existed characteristic roots with positive real parts. If the sign is positive, the
number of roots with positive real parts increases, and the equilibrium tends to lose
its stability.
Based on the above analysis and previous work [36], the following theorem can
be established.
Theorem 14.3.3 For the new coupled repressilators (14.13), if each Di ± > 0 (i =
1, . . . , 5) satisﬁes, then
(i) If N = 0, no positive root of Eq. (14.22) exists. All characteristic roots of Eq.
(14.18) have negative real parts and the equilibrium is asymptotically locally stable
for any coupling delay τ;
(ii) If N = 1, only one positive root of Eq. (14.22) exists. At the same time, if the
signof transversalityconditionat τ0 is positive, for eachτ ∈[0, τ0), all characteristic
values have negative real parts and the equilibrium of coupled repressilators is
asymptotically locally stable. The coupled repressilators (14.13) represent a Hopf
bifurcation at τ = τ0;
(iii) If N ≥2, at least two positive roots of Eq. (14.22) exist. A ﬁnite number of
intervals for τ exist. The equilibrium is asymptotically locally stable in these inter-
vals, and unstable outside them. The intervals are decided by the sign of Eq.(14.26).
The ﬁrst several smaller τi,k where the sign of transversality condition is positive will
be the left endpoints of these internals and vice versa. Especially, the equilibrium is
unstable when coupling delays are large enough.
Stability of coupled repressilators has close relationship with the sign of D±
i
and the existence of positive roots of Eq. (14.22). When D±
i > 0 holds for each
i = 1, . . . , 5 and there is no positive root in Eq.(14.22), the equilibrium of coupled
repressilators is asymptotically locally stable for any coupling delay, which is called
delay-independently stable. If the number of positive roots in Eq.(14.22) is not zero,
the stability of equilibrium may change with certain coupling delay, which is called
delay-dependently stable.
Take β = 1, α = 3, γ = 6, the equilibrium is delay-dependently stable. The
coupled structure is asymptotically locally stable at its equilibrium without coupling
delay, which is shown in Fig.14.13.
The effect of coupling delays on kinetic behaviors is illustrated subsequently. By
calculation, the positive roots of Eq. (14.22) are ω1 = 0.2966 and ω2 = 0.5896. It
means N = 2 and two pairs of pure imaginary roots exist in Eq.(14.18) which are
±jω1 = ±0.2966j and ±jω2 = ±0.5896j. By Theorem 14.3.3 (iii), two bounded
intervals of coupling delays can be found in which the coupled repressilator structure
is locally stable at its equilibrium

0, τ2,1
+
∪

τ1,1
−, τ2,2
+
= (0, 3.4994) ∪(9.8504, 14.1553) ,

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
305
0
50
100
150
200
1
1.5
2
2.5
Concentration of protein 1
t
(a) Evolution dynamics of protein 1
1
1.2
1.4
1.6
1.8
2
2.2
2.4
2.6
2.8
1
1.5
2
2.5
Concentration of protein 1
Concentration of mRNA 1
(b) Phase diagram of node 1
Fig. 14.13 Locally stable without τ under α = 3, γ = 6, β = 1
and the system is unstable out of them. That is, the unstable intervals of coupling
delays are

τ2,1
+, τ1,1
−
∪

τ2,2
+, +∞

= (3.4994, 9.8504) ∪(14.1553, +∞) ,
where τi,k is deﬁned and calculated in Eq.(14.23). The sign at top right corner of
τi,k indicates whether the according transversality condition (14.26) is positive or
negative. The exact transversality condition values are listed as follows
TC

ω2, τ2,1

= 0.0240 > 0,
TC

iω1, τ1,1

= −0.0031 < 0,
TC

ω2, τ2,2

= 0.0033 > 0.
In this situation, the coupled repressilators represent three Hopf bifurcations at
τ2,1, τ1,1, τ2,2. The ﬁnal dynamics of the coupled system will change three times
with the increase of coupling delays τ (that is, stable state →limit cycle →stable
state →limit cycle). We take τ = 3, 5, 12, 15 typically lied in the four different
intervals. Switches between stable state and limit cycle are illustrated in Fig.14.14.
In the ﬁgure, only concentration evolution of protein 1 and phase diagram of node 1
are depicted for simplicity.
In fact, coupling delays play an important role in kinetics of coupled repressi-
lators. Not only they can change the stability of equilibrium, but also can change
the oscillation rhythm when the system is unstable. Take Fig.14.14c, g for example,
different oscillation rhythms appear under different coupling delays.

306
Z.-H. Guan and G. Ling
0
200
400
600
800
1000
0.5
1
1.5
2
2.5
3
3.5
4
Concentration of protein 1
t
(a) Protein evolution with τ = 3
0.5
1
1.5
2
2.5
3
3.5
4
1
1.5
2
2.5
3
3.5
4
Concentration of protein 1
Concentration of mRNA 1 
(b) Phase diagram with τ = 3
0
200
400
600
800
1000
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Concentration of protein 1
t
(c) Protein evolution with τ = 5
0.5
1
1.5
2
2.5
3
3.5
4
4.5
0.5
1
1.5
2
2.5
3
3.5
4
Concentration of protein 1
Concentration of mRNA 1 
(d) Phase diagram with τ = 5
0
500
1000
1500
2000
0.5
1
1.5
2
2.5
3
3.5
4
Concentration of protein 1
t
(e) Protein evolution with τ = 12
0.5
1
1.5
2
2.5
3
3.5
4
0.5
1
1.5
2
2.5
3
3.5
4
Concentration of protein 1
Concentration of mRNA 1 
(f) Phase diagram with τ = 12
0
500
1000
1500
2000
0.5
1
1.5
2
2.5
3
3.5
4
Concentration of protein 1
t
(g) Protein evolution with τ = 15
0.5
1
1.5
2
2.5
3
3.5
4
0.5
1
1.5
2
2.5
3
3.5
4
Concentration of protein 1
Concentration of mRNA 1 
(h) Phase diagram with τ = 15
Fig. 14.14 Stability switches with different τ under α = 3, γ = 6, β = 1

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
307
14.4
Conclusion
In this chapter, analytical existence criteria of local stability and bifurcations for
general CGRNs and a coupled CGRN structure are established. Whether the number
of repressors is even or odd plays an important role in system stability.
For a positive CGRN whose repressor number is even, there may exist more than
one equilibrium and the stability criteria for each equilibrium are only related with
the Hill coefﬁcient h, the ratio ρ between degradation and polymeric rates as well as
the equilibrium itself. When the system has more than one equilibrium, the stability
may be different for different equilibriums, and the system may present multistability.
For a negative CGRN whose repressor number is odd, a unique equilibrium exists.
The stability criteria for the equilibrium are determined by the network size n, Hill
coefﬁcient h, the ratio ρ between degradation and polymeric rates and mixed time
delays. Discrete time delays can change the equilibrium stability under certain con-
ditions.
For a inhibitory coupled CGRNs with direct communication mechanism, the
kinetics of the coupled system depends crucially on the gains of each subnetwork
and coupling delays. When the subnetwork is with positive gain, the coupled system
may have more than one equilibrium, and present multistability. Otherwise there
is a unique equilibrium in the coupled negative CGRNs whose stability inﬂuenced
greatly by coupling delays and is possible to present a series of Hopf bifurcations.
Acknowledgements This work was partially supported by the National Natural Science Founda-
tion of China under Grants 61272069, 61503282 and 61633011.
References
1. Ling, G., Guan, Z.H., He, D.X., Liao, R.Q., Zhang, X.H.: Stability and bifurcation analysis of
new coupled repressilators in genetic regulatory networks with delays. Neural Netw. 60(C),
222–231 (2014)
2. Hori, Y., Kim, T.H., Hara, S.: Existence criteria of periodic oscillations in cyclic gene regulatory
networks. Automatica 47(6), 1203–1209 (2011)
3. Verdugo,A.,Rand,R.: Hopfbifurcationina dde model ofgene expression.Commun.Nonlinear
Sci. Numer. Simul. 13(2), 235–242 (2008)
4. Wu, F.X.: Stability and bifurcation of ring-structured genetic regulatory networks with time
delays. IEEE Trans. Circuits Syst. I Reg. Pap. 59(59), 1312–1320 (2012)
5. Hori, Y., Takada, M., Hara, S.: Biochemical oscillations in delayed negative cyclic feedback:
existence and proﬁles. Automatica 49(9), 2581–2590 (2013)
6. Kim, T.H., Hori, Y., Hara, S.: Robust stability analysis of gene-protein regulatory networks
with cyclic activation-repression interconnections. Syst. Control Lett. 60(6), 373–382 (2011)
7. Wang, R., Jing, Z., Chen, L.: Modelling periodic oscillation in gene regulatory networks by
cyclic feedback systems. Bull. Math. Biol. 67(2), 339–367 (2005)
8. Qiu, Z.: The asymptotical behavior of cyclic genetic regulatory networks. Nonlinear Anal. Real
World Appl. 11(2), 1067–1086 (2010)
9. El Samad, H., Del Vecchio, D., Khammash, M.: Repressilators and promotilators: loop dynam-
icsinsyntheticgenenetworks.InProceedingsofthe2005,AmericanControlConference,2005,
pp. 4405–4410 (2005)

308
Z.-H. Guan and G. Ling
10. Smith, H.: Oscillations and multiple steady states in a cyclic gene model with repression. J.
Math. Biol. 25(2), 169–190 (1987)
11. Zhang, W., Fang, J.A., Tang, Y.: Stochastic stability of Markovian jumping genetic regulatory
networks with mixed time delays. Appl. Math. Comput. 217(17), 7210–7225 (2011)
12. Liu, N., Guan, Z.H.: Chaotiﬁcation for a class of cellular neural networks with distributed
delays. Phys. Lett. A 375(3), 463–467 (2011)
13. He, W., Cao, J.: Robust stability of genetic regulatory networks with distributed delay. Cognit.
Neurodyn. 2(4), 355–361 (2008)
14. Rateitschak, K., Wolkenhauer, O.: Intracellular delay limits cyclic changes in gene expression.
Math. Biosci. 205(2), 163–179 (2007)
15. Josi´c, K., L´opez, J.M., Ott, W., Shiau, L., Bennett, M.R.: Stochastic delay accelerates signaling
in gene networks. PLoS Comput. Biol. 7(11), e1002264 (2011)
16. Gupta, C., L´opez, J.M., Azencott, R., Bennett, M.R., Josi´c, K., Ott, W.: Modeling delay in
genetic networks: from delay birth-death processes to delay stochastic differential equations.
J. Chem. Phys. 140(20), 204108 (2014)
17. Yuan, Y., B´elair, J.: Stability and Hopf bifurcation analysis for functional differential equation
with distributed delay. SIAM J. Appl. Dyn. Syst. 10(2), 551–581 (2011)
18. MacDonald, N.: Time Lags in Biological Models. Lecture Notes in Biomathematics, Springer,
Berlin (1978)
19. Chen, W.H., Guan, Z.-H., Lu, X.: Delay-dependent exponential stability of neural networks
with variable delays. Phys. Lett. A 326(5), 355–363 (2004)
20. Ding, J.M., Buchanan, G.F., Tischkau, S.A., Chen, D., Kuriashkina, L., et al.: A neuronal ryan-
odine receptor mediates light-induced phase delays of the circadian clock. Nature 394(6691),
381–384 (1998)
21. Mao, X.: Stability switches, bifurcation, and multi-stability of coupled networks with time
delays. Appl. Math. Comput. 218(11), 6263–6274 (2012)
22. Wu, F.X.: Delay-independent stability of genetic regulatory networks with time delays. Adv.
Complex Syst. 12(01), 3–19 (2009)
23. Chen, L., Aihara, K.: Stability of genetic regulatory networks with time delay. IEEE Trans.
Circuits Syst. I Fundam. Theory Appl. 49(5), 602–608 (2002)
24. Ling, G., He, D.X., Guan, Z.H., Zhang, X.H., Zhang, X.S.: On bistability in genetic double-
negative feedback loop with positive autoregulations. In: Proceedings of the 33rd Chinese
Control Conference (CCC), pp. 2872–2876 (2014)
25. Ling, G., Guan, Z.H., Liao, R.Q., Cheng, X.M.: Stability and bifurcation analysis of cyclic
genetic regulatory networks with mixed time delays. SIAM J. Appl. Dyn. Syst. 14(1), 202–220
(2015)
26. Elowitz, M.B., Leibler, S.: A synthetic oscillatory network of transcriptional regulators. Nature
403(6767), 335–338 (2000)
27. Kobayashi, T., Chen, L., Aihara, K.: Modeling genetic switches with positive feedback loops.
J. Theor. Biol. 221(3), 379–399 (2003)
28. Alon, U.: An introduction to systems biology: design principles of biological circuits. Chapman
& Hall/CRC, Boca Raton (2006)
29. Potapov, I., Volkov, E., Kuznetsov, A.: Dynamics of coupled repressilators: the role of mRNA
kinetics and Transcription cooperativity. Phys. Rev. E 83(3), 031901 (2011)
30. Garcia-Ojalvo, J., Elowitz, M.B., Strogatz, S.H.: Modeling a synthetic multicellular clock:
repressilators coupled by quorum sensing. Proc. Nat. Acad. Sci. U.S.A. 101(30), 10955–10960
(2004)
31. Potapov, I., Zhurov, B., Volkov, E.: Quorum sensing generated multistability and chaos in a
synthetic genetic oscillator. Chaos: an interdisciplinary. J. Nonlinear Sci. 22(2), 023117 (2012)
32. Herrgen, L., Ares, S., Morelli, L.G., Schr¨oter, C., Jlicher, F., Oates, A.C.: Intercellular coupling
regulates the period of the segmentation clock. Curr. Biol. 20(14), 1244–1253 (2010)
33. Wang, Y., Hori, Y., Hara, S., Doyle, F.J.: Intercellular delay regulates the collective period of
repressively coupled gene regulatory oscillator networks. IEEE Trans. Autom. Control 59(1),
211–216 (2014)

14
Dynamic Analysis of Genetic Regulatory Networks with Delays
309
34. Guan, Z.H., Chen, G., Qin, Y.: On equilibria, stability, and instability of Hopﬁeld neural net-
works. IEEE Trans. Neural Netw. 11(2), 534–540 (1999)
35. Ruan, S., Wei, J.: On the zeros of transcendental functions with applications to stability of
delay differential equations with two delays. Dyn. Contin. Discret. Impulsive Syst. Ser. A 10,
863–874 (2003)
36. Cheng, C.Y.: Induction of Hopf bifurcation and oscillation death by delays in coupled net-
works[J]. Phys. Lett. A 374(2), 178–185 (2009)
37. Hale, J.K., Lunel, S.M.V.: Introduction to Functional Differential Equations. Springer Science
& Business Media, Berlin (2013)
38. Bu¸se, O., Kuznetsov, A., Pérez, R.A.: Existence of limit cycles in the repressilator equations.
Int. J. Bifurc. Chaos 19(12), 4097–4106 (2009)
39. Kuznetsov, A., Afraimovich, V.: Heteroclinic cycles in the repressilator model. Chaos, Solitons
Fractals 45(5), 660–665 (2012)

Chapter 15
Frontiers
Ivan Zelinka
15.1
Frontiers
This book is dedicated to unconventional view on the swarm and evolutionary
algorithm dynamics. The main aim was to introduce the main ideas, the most impor-
tant steps and report selected experiments we have done on that ﬁeld. The book does
not present all possible visualizations, conversions, and experiments on control of
algorithm dynamics via approach proposed here. Despite the fact that almost all ideas
presented here were in the detailed form published on various conferences journals
and also books as the book chapter, still, a lot of open questions is there. Let’s discuss
a bit those topics now, as our opinion and possible inspiration for further research.
Dynamic conversion. As already reported, the conversion of an algorithm dynam-
ics to the network has been outlined generally, and exact algorithms needed speciﬁc
mapping of its dynamics, usually unique one. It is caused by the fact that each
algorithm has a different inherent nature, i.e., principles that govern it. Thus it is
likely impossible to create a universal cookbook that encompasses whole class of
swarm algorithms. On the other side, it can be done at least for the same kind of
algorithm like differential evolution strategies, etc. Also a selection of what part
of dynamics (i.e., individuals, processes of crossover, …) shall be converted to the
what network attributes (page ranking, centralities, …) are fully up to the user and
his/her needs. This seems to be “restrictively uncertain”, however, on the other, other
side, it gives more space to creativity and fantasy and thus become to be the art-like
expected approach. This seems to be better for future research in this ﬁeld because
the researcher is not bound by already deﬁned boundaries and guidelines “how-to”.
I. Zelinka (B)
Faculty of Electrical Engineering and Computer Science, Department of Computer Science,
VŠB – Technical University of Ostrava, 17. Listopadu 15, 70833
Ostrava-Poruba, Czech Republic
e-mail: ivan.zelinka@vsb.cz
© Springer-Verlag GmbH Germany 2018
I. Zelinka and G. Chen (eds.), Evolutionary Algorithms, Swarm Dynamics
and Complex Networks, Emergence, Complexity and Computation 26,
https://doi.org/10.1007/978-3-662-55663-4_15
311

312
I. Zelinka
As we hope, it is more about researcher fantasy, imagination, and creativity. At least
now, when this topic deserves more intensive research and is not closed yet.
Besides conversion and analysis also the topic of algorithm control via its network
analysis or associated CML is still open. We have shown that it can be used via
network attributes analysis as well as via CML systems. However again, a lot of new
questions arises here. What shall be converted to the CML representation? Page rank?
Degree centrality? Communities? Which one is suitable for what aim of the control?
How to interpret controlled CML state back to the algorithm? In our experiments
is visible, that it is impossible to use classical control law due to internal non-static
CML interactions amongst CML sites (i.e., individuals interact among themselves
in an unpredictable way) and thus scholar examples of control algorithms (based
on solid and in time not changing CML structure) do not work here. Paradoxically
evolutionary algorithms can as it is working with control of CML as of the black-box
problem. In fact, ad absurdum, in this case, evolution is controlling evolution (or
swarm control swarm).
Analysis of obtained networks can also be done ex-post, i.e., after all when algo-
rithm under investigation stopped. That gives us the certain view on its dynamics
structure, however, more interesting is to analyze networks as it develops in time
and correlates it with algorithm progress on given task. Many interesting conclu-
sions have been given there, and much more is waiting for future research. Not only
how given algorithm is doing on given task or class of tasks, but also whether its
speciﬁc dynamics is projected to the network dynamics. For example deterministic
chaos. It has been proven and demonstrated many times, that evolutionary/swarm
algorithms exhibit chaotic regimes. What is an impact of its existence on algorithm
performance? Is it also visible in a related network? What about quite a hot topic
of nonlinear dynamics today so-called hidden attractors? Do they exist in algorithm
dynamics too? Obviously yes. What is then its impact and relation to algorithm
progress?
Inverse problem. If only (arbitrary) network and its dynamics (i.e., time develop-
ment) are present, can we reconstruct at least a class of algorithms that are behind it
or can be identiﬁed what algorithm can be selected as a representative one? If yes,
then at least short prediction of the network behavior can be done.
Obviously, this topic is a multidisciplinary intersection of various interesting ﬁelds
of research and deserve further investigation. We did our best to select the most
important ﬁndings and ideas to inspire readers for his/her research. Despite the fact
that today’s science is unfortunately under press “publish or perish” and sometimes
remind a factory production, leaving a beautiful art-like approach (so common and
very natural up to 20th century), we tried to follow this art-like approach as much
as possible. We hope that readers will be enjoyed by ideas released in this book and
will be interested in another our research on that ﬁeld, that was published in different
journals, conferences, and books and accept this “philosophical” end of the book.
We believe that question that generates other questions are more important than just
getting only answers, as well as that knowledge without fantasy and creativity, is the
only encyclopedia.

