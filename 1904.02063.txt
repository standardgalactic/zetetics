arXiv Preprint, December 13, 2019.
Generalized Variational Inference:
Three arguments for deriving new Posteriors
Jeremias Knoblauch
j.knoblauch@warwick.ac.uk
The Alan Turing Institute
Dept. of Statistics
University of Warwick
Coventry, CV4 7AL, UK
Jack Jewson
j.e.jewson@warwick.ac.uk
The Alan Turing Institute
Dept. of Statistics
University of Warwick
Coventry, CV4 7AL, UK
Theodoros Damoulas
t.damoulas@warwick.ac.uk
The Alan Turing Institute
Depts. of Computer Science & Statistics
University of Warwick
Coventry, CV4 7AL, UK
Editor: Leslie Pack Kaelbling
Abstract
In this paper we advocate an optimization-centric view on Bayesian statistics and
introduce a novel generalization of Bayesian inference. On both counts, our inspiration is
the representation of Bayes‚Äô rule as an inÔ¨Ånite-dimensional optimization problem as shown
independently by Csisz√°r (1975); Donsker and Varadhan (1975); Zellner (1988). First, we use
this representation to prove a surprising optimality result of standard Variational Inference
(VI) methods: Under the proposed view, the standard Evidence Lower Bound (ELBO)
maximizing VI posterior is always preferable to alternative approximations of the Bayesian
posterior. Next, we argue for an optimization-centric generalization of standard Bayesian
inference. The need for this generalization arises in situations of severe misalignment between
reality and three assumptions underlying the standard Bayesian posterior: (1) Well-speciÔ¨Åed
priors, (2) well-speciÔ¨Åed likelihood models and (3) the availability of inÔ¨Ånite computing
power. In response to this observation, our generalization is deÔ¨Åned by three arguments and
named the Rule of Three (RoT). Each of its three arguments relaxes one of the assumptions
underlying standard Bayesian inference. We axiomatically derive the RoT and recover
existing methods as special cases, including the Bayesian posterior and its approximation
by standard Variational Inference (VI). In contrast, alternative approximations to the
Bayesian posterior maximizing other ELBO-like objectives violate these axioms. Finally, we
introduce a special case of the RoT that we call Generalized Variational Inference (GVI).
GVI posteriors are a large and tractable family of belief distributions speciÔ¨Åed by three
arguments: A loss, a divergence and a variational family. GVI posteriors possess appealing
theoretical properties, including consistency and an interpretation as an approximate ELBO.
c‚Éù2019 Jeremias Knoblauch, Jack Jewson and Theo Damoulas.
arXiv:1904.02063v4  [stat.ML]  12 Dec 2019

Knoblauch, Jewson and Damoulas
The last part of the paper explores some attractive applications of GVI in popular machine
learning models, including robustness and more appropriate marginals. After deriving black
box inference schemes for GVI posteriors, their predictive performance is investigated on
Bayesian Neural Networks and Deep Gaussian Processes, where GVI can comprehensively
improve upon existing methods.
Keywords:
Bayesian Inference, Generalized Bayesian Inference, Variational Inference,
Bayesian Neural Networks, Deep Gaussian Proceses
1. Introduction
Though famously Ô¨Årst discovered in Bayes (1763), the version of Bayes‚Äô Theorem that a
modern audience would be familiar with is much closer to the one in De Laplace (1774).
Bayes‚Äô Theorem (or Bayes‚Äô rule) is one of the most fundamental results in probability theory
and states that for a probability measure P and two events A, B, it holds that
P (A|B) = P (B|A) P (A)
P (B)
.
As usual, P (A|B) denotes the conditional probability of event A given that event B occured.
It would take nearly two more centuries for this mathematical result to be used as the basis
for an entire school of statistical inference (Fienberg, 2006). More precisely, Fisher (1950)
makes the Ô¨Årst mention of the term Bayesian in our modern understanding (David, 1998).
Bayesian statistics uses Bayes‚Äô Theorem to conduct inference on an unknown and unob-
servable event A. SpeciÔ¨Åcally, suppose that one can compute for an observable event B the
probability P(B|A) and has a prior belief P(A) about the event A before observing B. In this
situation, Bayes‚Äô rule tells us that we should be able to draw probabilistic inferences on A|B
by computing the probability P(A|B). In practice, the events A quantify the uncertainty
about a parameter of interest Œ∏ ‚ààŒò and so are of the form A ‚äÇŒò. The prior beliefs
about events A are usually speciÔ¨Åed by some probability density œÄ : Œò ‚ÜíR+ inducing the
probability measure P(A) =
R
A dœÄ(Œ∏). This leaves us with the need to specify a probability
distribution P (B|A) that relates the (unobserved) parameter Œ∏ to the (observable) event B.
In practice, one typically sets B = x1:n to correspond to n observations x1:n. The next step
is to deÔ¨Åne a distribution of B|A. This amounts to positing a likelihood function pn(x1:n|Œ∏)
and setting P(B|A) = pn(x1:n|Œ∏). Put together, this yields the standard Bayesian posterior
that we denote as q‚àó
B(Œ∏) throughout the paper and which is given by
q‚àó
B(Œ∏) = pn(x1:n|Œ∏)œÄ(Œ∏)
Z
.
Here, Z =
R
Œò pn(x1:n|Œ∏)dœÄ(Œ∏) is the normalizing constant‚Äîalso known as partition function‚Äî
whose computation generally makes the Bayesian posterior intractable.
Bayesian inference is appealing both conceptually and practically: Unlike frequentist
inference, Bayesian methods allow inferences to be informed by domain expertise in form of a
carefully speciÔ¨Åed prior belief œÄ(Œ∏). Further, Bayesian inference produces belief distributions
(rather than point estimates) over the parameter of interest Œ∏ ‚ààŒò that best Ô¨Åts the observed
data x1:n while taking into account a prior belief œÄ(Œ∏) about appropriate values of Œ∏. As
a consequence, Bayesian inferences automatically quantify uncertainty about Œ∏. This is
practically useful in many situations, but especially if one uses Œ∏ predictively: Integrating
2

Generalized Variational Inference
over q‚àó
B(Œ∏) avoids being over-conÔ¨Ådent about the best value of Œ∏, substantially improving
predictive performance (see e.g. Aitchison, 1975). Amongst other beneÔ¨Åts, it is this enhanced
predictive performance that has cast Bayesian inference as one of the predominant paradigms
in contemporary large-scale statistical inference and machine learning.
While Bayesian methods automatically quantify the uncertainty about their inferences,
this comes at a cost: In the translation of Bayes‚Äô rule into the Bayesian posterior q‚àó
B(Œ∏),
we have made three implicit but crucial assumptions. Firstly, we have assumed that the
modeller has a prior belief œÄ(Œ∏) which is worth being taken into account and which the
modeller is capable of writing out mathematically. Secondly, we speciÔ¨Åed the likelihood
function pn(x1:n|Œ∏) as a conditional probability. In other words, we have assumed that the
model is correctly speciÔ¨Åed, which is to say that pn(x1:n|Œ∏‚àó) = dP(x1:n) for some unknown
value of Œ∏‚àó‚ààŒò. Thirdly, we have assumed the availability of enough computational power
to compute and perform exact inference based upon the generally intractable posterior q‚àó
B(Œ∏).
In many situations, these three assumptions built into q‚àó
B(Œ∏) are harmless. For modern
large-scale statistical machine learning tasks however, they are frequently violated.
To address this, the current paper takes a step back from Bayes‚Äô Theorem and the
standard Bayesian posterior q‚àó
B(Œ∏) to deÔ¨Åne a generalized class of posterior belief distributions.
Throughout, we motivate this with the tension between the three main assumptions underlying
standard Bayesian inference on the one hand and the requirement of many contemporary
statistical applications on the other hand. To resolve this tension, we deÔ¨Åne a generalization
of Bayesian inference that we call the Rule of Three (RoT). The RoT is speciÔ¨Åed by an
optimization problem over the space of probability measures P(Œò) on Œò with three arguments.
These arguments are a loss function ‚Ñì, a divergence D measuring the deviation of the posterior
from the prior and a space Œ† ‚äÜP(Œò) of feasible solutions. Together, these three ingredients
deÔ¨Åne posterior beliefs of the form
q‚àó(Œ∏) = arg min
q‚ààŒ†
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(q‚à•œÄ)
)
def
= P(‚Ñì, D, Œ†).
(1)
This recovers previous generalizations of Bayesian inference, including those inspired by Gibbs
posteriors (e.g. Ghosh and Basu, 2016; Bissiri et al., 2016; Jewson et al., 2018; Nakagawa and
Figure 1: A taxonomy of some important belief distributions as special cases of the RoT.
3

Knoblauch, Jewson and Damoulas
Hashimoto, 2019; Ch√©rief-Abdellatif and Alquier, 2019), tempered posteriors (e.g. Gr√ºnwald,
2011, 2012; Holmes and Walker, 2017; Gr√ºnwald and Van Ommen, 2017; Miller and Dunson,
2019), as well as PAC-Bayesian approaches (for a recent overview, see Guedj, 2019). we
illustrate this taxonomy in Figure 1. Unlike any of these previous generalizations however,
posteriors taking the form P(‚Ñì, D, Œ†) may be non-multiplicative. One of the most important
implications of this is that in contrast to previous generalizations, the RoT can recover
standard Variational Inference (VI) posteriors based on minimizing the Kullback-Leibler
Divergence (KLD) to q‚àó
B(Œ∏). Notably, this is true even though standard VI is derived as
an approximation to the Bayesian posterior q‚àó
B(Œ∏).
Even more remarkably, variational
approximations to the Bayesian posterior that are constructed by minimizing divergences
other than the KLD are not recovered by the RoT. This inspires us to deÔ¨Åne and investigate
Generalized Variational Inference (GVI), the tractable special case for the RoT in which
Œ† = Q = {q(Œ∏|Œ∫) : Œ∫ ‚ààK} ‚äÇP(Œò) is chosen to be a variational family. Various theoretical
and empirical Ô¨Åndings lead us to conclude that GVI posteriors are well-suited to real world
inference problems and are an exciting Ô¨Årst step on the way to derive generalized and tractable
posterior belief distributions. The paper draws these conclusions in Ô¨Åve steps.
Section 2: We recapitulate the standard approach to Bayesian inference and various
variational approximation schemes for q‚àó
B(Œ∏). Unconventionally, we do so through the
lens of inÔ¨Ånite-dimensional optimization. This view provides a number of interesting
insights: For example, it enables a natural breakdown of variational approximation
methods. Further, it reveals that relative to the inÔ¨Ånite-dimensional optimization
problem whose solution is the Bayesian posterior, the standard Variational Inference
(VI) posterior is the optimal solution in its Ô¨Ånite-dimensional variational family. Per-
haps surprisingly, this also implies that for any Ô¨Åxed variational family, alternative
approximations in the same variational family are sub-optimal.
Section 3: We explain why a generalized view on Bayesian inference is necessary. To
this end, we Ô¨Årst give a brief overview over the three assumptions that justify Bayesian
inference: The availability of both an appropriately speciÔ¨Åed prior belief and likelihood
as well as suÔ¨Écient computational power to address the intractability of q‚àó
B(Œ∏). We then
proceed to contrast these three assumptions with the realities of modern day large-scale
statistical inference and use three examples to explain the real world problems arising
from this misalignment between assumptions and reality.
Section 4: We derive a generalized representation of Bayesian inference that we
call the Rule of Three (RoT) based on three simple axioms. The RoT is inspired
by our optimality Ô¨Ånding regarding standard VI in Section 2. Thus, unlike previous
generalizations it deÔ¨Ånes an optimization-centric outlook on Bayesian inference. We
discuss the RoT and explain how it can address the adverse eÔ¨Äects of violating the
assumptions underlying standard Bayesian inference. Further, we connect the RoT
to existing Bayesian methods, the information bottleneck method and PAC-Bayesian
approaches.
Section 5: Translating the conceptual contribution of the RoT into a methodological
one, we introduce Generalized Variational Inference (GVI). We explain how to use
GVI for robust inference and more appropriate marginal variances. We also point to
4

Generalized Variational Inference
some theoretical Ô¨Åndings, including frequentist consistency and an interpretation of
GVI as approximate evidence lower bound. Lastly, we discuss computation of GVI
posteriors. While special cases permit closed form objectives, one generally needs to
rely on stochastic Black Box GVI (BBGVI).
Section 6: We reinforce the conceptual and methodological appeal of GVI with two
large-scale inference applications: Bayesian Neural Networks (BNNs) and Deep Gaussian
Processes (DGPs). In diÔ¨Äerent ways, both model classes are representative for the
diÔ¨Äerent ways in which contemporary large-scale inference is often misaligned with the
assumptions underlying the standard Bayesian posterior. We show that appropriately
addressing this misalignment dramatically improves performance.
Throughout, we radically simplify the presentation for improved readability: For example,
we do not incorporate latent variables into our notation in spite of demonstrating GVI on
a Deep Gaussian Process (DGP) latent variable model in Section 6.2. Further, we assume
that losses are additive, homogeneous and such that the i-th loss term ‚Ñì(Œ∏, xi) only depends
on xi. None of these assumptions are necessary, and one could replace ‚Ñì(Œ∏, xi) by ‚Ñìi(Œ∏, x1:i)
or ‚Ñìi(Œ∏, xnbh(i)) for some neighbourhood nbh(i) ‚äÇ{1, 2, . . . n} throughout the paper without
violating the principles of the RoT or GVI1.
2. An optimization-centric view on Bayesian inference
Before presenting our main Ô¨Åndings, we set the stage by introducing an optimization-centric
view on (generalized) Bayesian inference. SpeciÔ¨Åcally, we draw attention to an isomorphism
between the Bayesian posterior and an inÔ¨Ånite-dimensional optimization problem and discuss
three implications of this relationship.
Section 2.2: Committing to any exact Bayesian posterior is equivalent to committing
to a particular optimization problem over the space of probability measures
Section 2.3: Taking an optimization-centric view of Bayesian inference and holding
the variational family Ô¨Åxed, standard Variational Inference (VI) produces optimal
approximations of the exact Bayesian posterior.
Section 2.4: non-standard VI methods based on alternative divergences are suboptimal
approximations of the exact Bayesian posterior.
2.1 Preliminaries
Given a prior belief œÄ(Œ∏) about the parameter and observations x1:n linked to Œ∏ via a
likelihood function p(xi|Œ∏), the standard Bayesian posterior belief q‚àó
B(Œ∏) is computed
through a multiplicative updating rule with ‚Ñì(Œ∏, xi) = ‚àílog p(xi|Œ∏) as
q‚àó
B(Œ∏) ‚àùœÄ(Œ∏)
n
Y
i=1
exp{‚àí‚Ñì(Œ∏, xi)}.
(2)
1.
For the interested reader, we note that the appropriate notational extension of GVI to latent variables
and non-homogeneous losses is formalized in Knoblauch (2019a), see e.g. Assumption 1 and Remarks 1,2
and 3 therein.
5

Knoblauch, Jewson and Damoulas
While this way of writing Bayes rule might seem cumbersome, it reveals that the multiplicative
structure is in principle applicable to any loss function. This leads to the development of
a generalized Bayesian posterior by replacing the negative log likelihood with any loss
‚Ñì: Œò √ó X ‚ÜíR. If the normalizer of eq. (2) exists, such treatment provides a coherent and
principled way to update beliefs about an arbitrary parameter Œ∏ (Bissiri et al., 2016).
To make this generalization tangible, imagine that Œ∏ denotes the median for the data
generating mechanism that produced x1:n and that one wishes to update beliefs about it
in a Bayesian manner. A loss-based Bayesian treatment of this problem would combine
a prior belief œÄ about the median with the loss ‚Ñì(Œ∏, xi) = |Œ∏ ‚àíxi|1. Together, these two
ingredients yield a generalized Bayesian posterior belief about the median as given above.
For some applications with ‚Ñì(Œ∏, xi) Ã∏= ‚àílog p(xi|Œ∏), see Ghosh and Basu (2016); Alquier et al.
(2016); Gr√ºnwald and Van Ommen (2017); Jewson et al. (2018); Knoblauch et al. (2018);
Ch√©rief-Abdellatif and Alquier (2019) or Nakagawa and Hashimoto (2019).
Throughout this paper, we do not notationally distinguish standard and generalized
Bayesian posteriors. Unless we make the distinction explicit, we subsume both types of belief
distributions under the name Bayesian posterior and denote any posterior belief computed
as in eq. (2) by q‚àó
B(Œ∏). The asterisk superscript in q‚àó
B(Œ∏) emphasizes an observation we
make next and that will be a recurrent theme throughout the paper: Any posterior belief
distribution is the result of an appropriately speciÔ¨Åed optimization problem.
2.2 Bayesian inference as inÔ¨Ånite-dimensional optimization
The traditional perspective on Bayesian posteriors derives from the basic laws of probability
and in particular Bayes‚Äô Theorem: If p(xi|Œ∏) denotes the conditional density of xi given Œ∏
and œÄ(Œ∏) denotes the density of Œ∏, the conditional probability of Œ∏ given x1:n is given by
q‚àó
B(Œ∏) in eq. (2) with ‚Ñì(Œ∏, xi) = ‚àílog p(xi|Œ∏). This multiplicative update rule is motivated
slightly diÔ¨Äerently for generalized Bayesian posteriors, but the inherent logic largely remains
the same: By imposing coherence, one forces the priors and losses into an exponentially
additive relationship (see also Section 4.4.2). One interpretation of this is that one treats
the loss terms exp{‚àí‚Ñì(Œ∏, xi} as quasi-likelihoods, rendering the resulting posteriors at very
strongly inspired by conditionalization and the fundamental rules of probability that underlie
Bayes‚Äô rule2.
While Bayes‚Äô rule and eq. (2) are well-known, there is a conceptually rather diÔ¨Äerent
path for arriving at q‚àó
B(Œ∏): Dating back at least to Csisz√°r (1975) and Donsker and Varadhan
(1975), it was shown that Bayesian inference can be recast as the solution to an inÔ¨Ånite-
dimensional optimization problem. This result was rediscovered in statistics by Zellner (1988)
and states that for P(Œò) denoting the space of all probability measures on Œò, the Bayesian
posterior is given by
q‚àó
B(Œ∏) = arg min
q‚ààP(Œò)
(
Eq(Œ∏)
"
‚àí
n
X
i=1
log(p(xi|Œ∏))
#
+ KLD (q||œÄ)
)
,
2. Note that the literature on PAC-Bayesian procedures can provide diÔ¨Äerent justiÔ¨Åcations for multiplicative
update rules (see e.g. Germain et al., 2016; Guedj, 2019).
6

Generalized Variational Inference
where KLD is the Kullback-Leibler divergence (Kullback and Leibler, 1951) given by
KLD(q||œÄ) = Eq(Œ∏)

log
 q(Œ∏)
œÄ(Œ∏)

= Eq(Œ∏) [log q(Œ∏)] ‚àíEq(Œ∏) [log œÄ(Œ∏)] .
Similarly, the generalized Bayesian posteriors of Bissiri et al. (2016) solve the optimization
problem given by
q‚àó
B(Œ∏) = arg min
q‚ààP(Œò)
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ KLD (q||œÄ)
)
.
(3)
This objective allows a re-interpretation of Bayesian inference as regularized optimization:
As in maximum likelihood inference or other empirical risk minimization tasks, one wishes
to minimize some loss function over the data. Unlike with frequentist methods however, one
wishes to quantify uncertainty and obtain a belief distribution rather than a point estimate.
Consequently, one adds the KLD regularization term. Note that if this KLD term were absent
from eq. (3), the solution of the optimization problem would simply be a Dirac mass Œ¥bŒ∏n(Œ∏)
at the empirical risk minimizer bŒ∏n, since Œ¥bŒ∏n(Œ∏) ‚ààP(Œò).
For completeness‚Äô sake, we now provide a self-contained proof of eq. (3) which is based on
the one in the supplementary material of Bissiri et al. (2016). This encompasses the original
result of (Csisz√°r, 1975) and (Donsker and Varadhan, 1975) for ‚Ñì(Œ∏, xi) = ‚àílog p(xi|Œ∏).
Theorem 1 If Z =
R
Œò exp {‚àíPn
i=1 ‚Ñì(Œ∏, xi)} œÄ(Œ∏)dŒ∏ < ‚àû, then the solution of eq. (3) exists
and is equivalent to the generalized Bayesian posterior q‚àó
B(Œ∏) as given in eq. (2).
Proof One may rewrite the objective in eq. (3) as
q‚àó(Œ∏) = arg min
q‚ààP(Œò)
(Z
Œò
"
log
 
exp
( n
X
i=1
‚Ñì(Œ∏, xi)
)!
+ log
 q(Œ∏)
œÄ(Œ∏)
#
q(Œ∏)dŒ∏
)
= arg min
q‚ààP(Œò)
Z
Œò
log

q(Œ∏)
œÄ(Œ∏) exp {‚àíPn
i=1 ‚Ñì(Œ∏, xi)}

q(Œ∏)dŒ∏

.
As one only cares about the minimizer q‚àó(Œ∏) (and not the objective value), it also holds that
for any constant Z > 0, the above is equal to
q‚àó(Œ∏) = arg min
q‚ààP(Œò)
Z
Œò
log

q(Œ∏)
œÄ(Œ∏) exp {‚àíPn
i=1 ‚Ñì(Œ∏, xi)} Z‚àí1

q(Œ∏)dŒ∏ ‚àílog Z

= arg min
q‚ààP(Œò)
(
KLD
 
q(Œ∏)
œÄ(Œ∏) exp
(
‚àí
n
X
i=1
‚Ñì(Œ∏, xi)
)
Z‚àí1
!)
.
Lastly, one sets Z =
R
Œ∏ exp {‚àíPn
i=1 ‚Ñì(Œ∏, xi)} œÄ(Œ∏)dŒ∏ and notes that as the KLD is a statistical
divergence, it is minimized uniquely if its two arguments are the same, so q‚àó(Œ∏) = q‚àó
B(Œ∏).
The result in Theorem 1 implies an important isomorphism that drives much of the current
paper‚Äôs development: Any commitment to a (standard or generalized) Bayesian posterior is
always a commitment to an optimization objective. In other words, the Bayesian posterior
for a given inference problem is adequate if and only if the objective in eq. (3) is.
7

Knoblauch, Jewson and Damoulas
Observation 1 (Isomorphism) Suppose an agent A wishes to conduct inference based
upon the Bayesian posterior q‚àó
B(Œ∏) in eq. (2). Then agent A conducts inference by solving an
optimization problem, namely the one in eq. (3).
The above observation implies that computing the Bayesian posterior q‚àó
B(Œ∏) is equivalent to
assuming that the objective of eq. (3) is appropriate for producing belief distributions. In
Section 3, we will explain why the usefulness of the standard Bayesian posterior‚Äîand thus
of the objective in eq. (3)‚Äîis at least doubtful for many contemporary statistical machine
learning problems.
Remark 2 The sceptical reader may notice that given the Bayesian posterior, eq. (3) is not
the unique solution-inducing problem. SpeciÔ¨Åcally, suppose that D is a statistical divergence.
Then D(q‚à•p) ‚â•0 and D(q‚à•p) = 0 if and only if q(Œ∏) = p(Œ∏) almost everywhere. Hence, one
could object that in fact any optimization problem of the form
q‚àó(Œ∏) = arg min
q‚ààP(Œò)
D(q‚à•q‚àó
B)
(4)
will be solved setting q‚àó(Œ∏) = q‚àó
B(Œ∏). While true, this is tautological: In particular, such
optimization problems shed no light on how q‚àó
B(Œ∏) was arrived at. By their very construction,
problems of this form pre-suppose that q‚àó
B(Œ∏) is the posterior belief one wishes to obtain.
Thus, while there exist inÔ¨Ånitely many optimization problems whose solution is q‚àó
B(Œ∏),
some are more meaningful than others. SpeciÔ¨Åcally, whenever one seeks to solve an objective
of the form given in eq. (4), the Bayesian posterior appears deus ex machina. This does not
allow us any interpretation about what q‚àó(Œ∏) itself stands for and why it is a desirable belief
distribution to target. In contrast, eq. (3) shows that the Bayesian posterior arises as the
solution of a clearly interpretable optimization problem.
2.3 Optimality of standard Variational Inference
While Bayesian posteriors of the form given in eq. (2) are analytically available up to a
normalizing constant, this is not immediately useful. SpeciÔ¨Åcally, (asymptotically) exact
computations of expectations and integrals with respect to these posteriors are in general only
possible through sampling methods and incur a large computational burden. To alleviate this
problem, numerous approximations to the exact Bayesian posterior have been proposed. The
principal idea of any such approximation is to force the posterior belief into some parametric
form. SpeciÔ¨Åcally, one seeks to approximate q‚àó
B(Œ∏) ‚âàq‚àó
A(Œ∏), where q‚àó
A(Œ∏) ‚ààQ and
Q = {q(Œ∏|Œ∫) : Œ∫ ‚ààK}
(5)
denotes a family of distributions parameterized by Œ∫. It is obvious that this signiÔ¨Åcantly
reduces the computational burden, as it transforms the optimization from an inÔ¨Ånite-
dimensional into a Ô¨Ånite-dimensional one.
The literature on approximations of this sort is large and has diverse origins. Their
development arguably started with Laplace Approximations (see e.g. the seminal papers of
Tierney and Kadane, 1986; Shun and McCullagh, 1995; MacKay, 1998), which have recently
been reÔ¨Åned substantially into Integrated Nested Laplace Approximations (Rue et al., 2009).
8

Generalized Variational Inference
(a) DVI interpretation of VI
(b) Interpretation of VI as in Theorem 3
Figure 2: Best viewed in color. Depicted is a schematic to clarify the conceptual distinction
between two interpretations of VI. DVI methods interpret VI as the KLD-projection of
q‚àó
B(Œ∏) into the variational family Q. New methods are then derived by replacing the KLD
with alternative projection operators.
In contrast, Theorem 3 interprets VI posteriors
as best solutions to a constrained optimization problem. Rather than Ô¨Ånding the global
optimum q‚àó
B(Œ∏) of the optimization problem in eq. (3), VI Ô¨Ånds the best solution in the
subset Q ‚äÇP(Œò). This optimization-centric view on variational methods is also the logic
underlying GVI posteriors.
A second family of approximation methods known as Expectation Propagation (Opper and
Winther, 2000; Minka, 2001) was motivated through factor graphs and message passing
(Minka, 2005). The third and arguably most successful approach originated by connecting the
Expectation-Maximization algorithm (Dempster et al., 1977) and the variational free energy
from physics (Neal and Hinton, 1998), culminating in Variational Inference (VI) (Jordan
et al., 1999; Beal, 2003). For these methods, Q in eq. (5) is called the variational family.
Traditionally, two main interpretations of VI prevail. Firstly, one can derive its objective
function as an Evidence Lower Bound (ELBO). Secondly, one can show that the same
objective function minimizes the KLD between Q and q‚àó
B(Œ∏). In this paper, we introduce and
advocate a third‚Äìto the best of our knowledge novel‚Äîview on VI: Relative to the objective
in eq. (3), VI corresponds to the best Q-constrained solution.
2.3.1 VI as log evidence bound
A standard way of deriving VI is the following: Since one wishes to obtain the posterior
maximizing the evidence in the data, a reasonable objective is to pick the element in the
approximating family Q that maximizes the evidence. This logic is operationalized by
9

Knoblauch, Jewson and Damoulas
observing that for Z the normalizing constant (or partition function) and any q(Œ∏) ‚ààQ,
log p(x1:n) = log
 Z
Œò
Z‚àí1 exp{‚àí
n
X
i=1
‚Ñì(Œ∏, xi)}œÄ(Œ∏)dŒ∏
!
= log
 Z
Œò
exp{‚àí
n
X
i=1
‚Ñì(Œ∏, xi)}œÄ(Œ∏)
q(Œ∏) q(Œ∏)dŒ∏
!
‚àílog Z
JIE
‚â•
Z
Œò
log
 
exp
(
‚àí
n
X
i=1
‚Ñì(Œ∏, xi)
)
œÄ(Œ∏)
q(Œ∏)
!
q(Œ∏)dŒ∏ ‚àílog Z
(6)
where we have applied Jensen‚Äôs Inequality in the last step. The right hand side of eq. (6)
is called the Evidence Lower Bound (ELBO), and maximizing it over Q is independent of
Z. With this, one Ô¨Ånally obtains the standard VI posterior as solution to an optimization
problem given by
q‚àó
VI(Œ∏) = arg min
q‚ààQ
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ KLD (q||œÄ)
)
.
(7)
Here, q‚àó
VI(Œ∏) = q(Œ∏|Œ∫‚àó) for some optimal parameter Œ∫‚àó‚ààK.
Taking inspiration from the Evidence Lower Bound interpretation of the VI objective,
alternative approximation methods produce VI posteriors maximizing generalized Evidence
Lower Bounds (e.g. Chen et al., 2018; Domke and Sheldon, 2018; Burda et al., 2016). For
some bound log p(x1:n) ‚â§G-ELBO(q) on the evidence, such methods produce posteriors as
q‚àó
G‚àíELBO(Œ∏) = arg min
q‚ààQ
{G-ELBO(q)} .
2.3.2 VI as KLD-minimization & Discrepancy VI (DVI)
A second well-known perspective on standard VI posteriors is motivated by rewriting the
objective in eq. (7) in terms of the Kullback-Leibler Divergence (KLD) as follows:
q‚àó
VI(Œ∏) = arg min
q‚ààQ
n
KLD

q(Œ∏)
q‚àó
B(Œ∏)
o
The relevant algebraic arguments are similar to the ones used in the proof of Theorem 1. In
eÔ¨Äect, the resulting re-arrangement of terms above shows that standard VI Ô¨Ånds the element
q‚àó
VI(Œ∏) ‚ààQ closest to the Bayesian posterior belief in the KLD-sense.
This insight has produced a growing body of literature seeking to minimize (local or
global) discrepancies D between Q and q‚àó
B(Œ∏) that are diÔ¨Äerent from the KLD (e.g. Minka,
2001; Opper and Winther, 2000; Li and Turner, 2016; Saha et al., 2019; Dieng et al., 2017;
Hern√°ndez-Lobato et al., 2016; Yang et al., 2019; Cichocki and Amari, 2010; Ranganath
et al., 2016; Wang et al., 2018). For a disrepancy measure D : P(Œò) √ó P(Œò) ‚ÜíR, methods
of this kind compute approximations to q‚àó
B(Œ∏) based on objectives of the form
q‚àó
DVI(Œ∏) = arg min
q‚ààQ
n
D

q(Œ∏)
q‚àó
B(Œ∏)
o
.
Throughout the remainder of this paper, we call procedures of this nature with D Ã∏= KLD
Discrepancy Variational Inference (DVI) methods. Their logic and intuitive appeal is
summarized in Figure 2a.
10

Generalized Variational Inference
2.3.3 VI as constrained optimization
While the interpretations of VI as optimizing over an evidence lower bound and as minimizing
a discrepancy are well-known, this paper presents a third interpretation: VI posteriors are
also the Q-optimal solutions to the optimization problem in eq. (3) characterizing Bayesian
inference. To spot this, simply compare eq. (3) to eq. (7) and notice that the optimization
problem only diÔ¨Äers through the space over which optimization is performed: As opposed to
the set of all probability measures P(Œò) as in eq. (3), eq. (7) only considers the parameterized
subset Q. This observation is rather signiÔ¨Åcant and bears important implications summarized
in the following Theorem and Figure 2b.
Theorem 3 (Optimality of standard VI) Relative to the inÔ¨Ånite-dimensional optimiza-
tion problem over P(Œò) characterizing Bayesian inference and a Ô¨Åxed Ô¨Ånite-dimensional
variational family Q, standard VI produces the optimal posterior belief in Q.
Proof First, notice that the VI posterior belief distribution q‚àó
VI(Œ∏) and the Bayesian posterior
belief distribution q‚àó
B(Œ∏) both seek to minimize
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ KLD(q‚à•œÄ)
over q(Œ∏). Second, notice that q‚àó
VI(Œ∏) is the minimizer of this objective relative to Q while
q‚àó
B(Œ∏) is the minimizer relative to P(Œò). Third, note that Q ‚äÇP(Œò).
Remark 4 The result of Theorem 3 is important: As Observation 1 explained, committing
to a Bayesian posterior q‚àó
B(Œ∏) is equivalent to committing to the objective function in eq. (3).
In other words, if we judge the posterior belief q‚àó
B(Œ∏) to be desirable, we are also saying that
the objective function in eq. (3) encodes properties that we want our posterior belief to adhere
to. Accordingly, once we restrict our posterior beliefs to be in a subset Q ‚äÇP(Œò), we should
want to compute the best possible solution to the same objective in Q. As Theorem 3 shows,
this is exactly what VI does. Importantly, this has two implications: Firstly, it gives another
meaningful interpretation to standard VI approximations to q‚àó
B(Œ∏). Secondly, it provides
important insights into the suboptimality of alternative approximation methods summarized
in the following Corollary.
Corollary 5 (Suboptimality of alternative methods) Relative to the inÔ¨Ånite-dimensional
optimization problem over P(Œò) characterizing Bayesian inference and a Ô¨Åxed Ô¨Ånite-dimensional
variational family Q, methods diÔ¨Äerent from standard VI produce sub-optimal posterior beliefs.
Proof We prove this by contradiction: Suppose the posterior belief q‚àó
A(Œ∏) was produced by
some alternative method A that is not equivalent to standard VI. Suppose also that q‚àó
A(Œ∏) is
the Q-optimal posterior relative to eq. (3). By deÔ¨Ånition of standard VI, it then holds that
that for any sequence of observations x1:n and for all n,
Eq‚àó
VI(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ KLD (q‚àó
VI||œÄ) ‚â§Eq‚àó
A(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ KLD (q‚àó
A||œÄ) .
11

Knoblauch, Jewson and Damoulas
Suppose the inequality is strict. This immediately yields a contradiction with the supposition
that q‚àó
A(Œ∏) is the Q-optimal posterior relative to eq. (3). Alternatively, suppose the inequality
is an equality for any sequence of observations x1:n and for all n. This too immediately yields
a contradiction: In particular, it violates the supposition that the method producing q‚àó
A(Œ∏)
is not equivalent to standard VI. Thus, the desired contradiction is obtained.
Remark 6 Corollary 5 implies that once the variational family Q is Ô¨Åxed, producing an
approximation to q‚àó
B(Œ∏) which does not correspond to standard VI posteriors is sub-optimal
under an optimization-centric view on Bayesian inference. This notion of optimality is
important because Theorem 1 and Observation 1 expose the isomorphic relationship between the
optimization problem in eq. (3) and the exact Bayesian posterior. An immediate consequence
of Corollary 5 is thus that methods built around generalized evidence lower bound formulations,
alternative Discrepancy Variational Inference ( DVI) methods or Expectation Propagation
( EP) approaches (e.g. Minka, 2001; Opper and Winther, 2000) are sub-optimal relative to
standard VI: If one wishes to minimize the objective that deÔ¨Ånes the Bayesian posterior
q‚àó
B(Œ∏), it is irrational to pick any q ‚ààQ not produced by standard VI.
2.4 Reconciling (sub)optimality with empirical evidence
At Ô¨Årst glance, the conclusions from Corollary 5 and Remark 5 seem to contradict numerous
landmark Ô¨Åndings in the area of approximate Bayesian inference: Firstly, there are various
issues with standard VI that are well-known and hinder its eÔ¨Äectiveness in certain situations
(see e.g. Turner and Sahani, 2011). For this reason, various alternative approximations have
proven successful in practice (e.g. Minka, 2001; Rue et al., 2009) and often produce more
desirable posterior inferences. All this seems to contradict the (sub)optimality results in
Theorem 3 and Corollary 5.
This contradiction resolves itself upon closer examination. SpeciÔ¨Åcally, the practical
relevance of any optimality result hinges on two crucial assumptions that are typically
violated in practice: Firstly, one needs to assume that the original objective in eq. (3) is
appropriately speciÔ¨Åed. Secondly, one needs the variational family Q to be rich enough so
that the statement q‚àó
VI(Œ∏) ‚âàq‚àó
B(Œ∏) is not completely vacuous. Conversely, this means that
q‚àó
A(Œ∏) can produce more desirable approximations to q‚àó
B(Œ∏) than q‚àó
VI(Œ∏) whenever one of the
following holds:
(i) the original objective in eq. (3) is misspeciÔ¨Åed and does not reÔ¨Çect the belief distribution
we wish to compute;
(ii) The approximating family Q is inappropriately speciÔ¨Åed so that the statement q(Œ∏) ‚âà
q‚àó
B(Œ∏) is vacuous for any q ‚ààQ.
Under (i), q‚àó
A(Œ∏) will outperform q‚àó
VI(Œ∏) whenever its objective implicitly encodes desirable
properties for the posterior belief distribution that are not part of the objective in eq. (3).
Similarly, if q‚àó
A(Œ∏) is designed to accommodate speciÔ¨Åc choices of Q that q‚àó
VI(Œ∏) struggles
with, it will perform well under (ii).
For example, virtually all posteriors produced within the DVI family (e.g. Li and Turner,
2016; Hern√°ndez-Lobato et al., 2016; Dieng et al., 2017; Regli and Silva, 2018) are designed
12

Generalized Variational Inference
to address (ii): In particular, these methods prevent unimodal approximations from focusing
too strongly around the empirical risk minimizer of Œ∏. For standard VI, this phenomenon
is common whenever Q is the mean Ô¨Åeld variational family, which explains why DVI often
empirically outperforms standard VI for this popular choice of Q. Taking the optimization-
centric view on posterior beliefs, this implies that in spite of being sub-optimal relative
to eq. (3), DVI methods pose objectives that are often better-suited to produce belief
distributions in Q. This raises an interesting question: Rather than thinking of inference in
a subset Q ‚äÇP(Œò) as approximate, can we adapt a radical optimization-centric view and
directly design appropriately speciÔ¨Åed objectives to generate posterior beliefs with desirable
properties? The remainder of this paper gives an aÔ¨Érmative answer to this question in the
form of Generalized Variational Inference (GVI).
Taking inspiration from (i) and (ii), the next section Ô¨Årst takes a step back and explores
the conditions under which such alternative GVI posteriors could be desirable. As we shall
see, the isomorphic relationship between eq. (3) and the Bayesian posterior provides a
comprehensive answer to this question: SpeciÔ¨Åcally, we explain the ways in which the assump-
tions underpinning the traditional Bayesian paradigm giving rise to the Bayesian posterior
q‚àó
B(Œ∏) and eq. (3) are often misaligned with the realities of contemporary statistical machine
learning. This misalignment problem has three important dimensions: The information
contained in the prior belief (P), the role of the likelihood model (L), and the availability of
computational resources (C).
3. A reality check: Re-examining the traditional Bayesian paradigm
In the following section, we illuminate the misalignment between the assumptions underlying
the traditional Bayesian paradigm and the way in which modern statistical machine learning
uses (approximate) Bayesian posteriors to conduct inference.
First, Section 3.1 recalls and elaborates on the three crucial assumptions underlying
the standard Bayesian posterior: An appropriate prior (P) and likelihood (L) and an
inÔ¨Ånite computational budget (C).
Next, Section 3.2 exposes the misalignment of these three assumptions with inferential
practices in contemporary statistical machine learning and large-scale inference.
Lastly, Sections 3.3‚Äì3.5 illustrates the adverse real-world consequences arising from
violating these assumptions.
3.1 The traditional Bayesian paradigm
Due to their direct correspondence with the fundamental rules of probability, Bayesian
posteriors q‚àó
B(Œ∏) are desirable objects to be basing inference on. To see why, suppose the
following three conditions hold true.
(P) The Prior œÄ(Œ∏) is correctly speciÔ¨Åed: It encodes the best available judgement about Œ∏
based on all information available to the modeller. Crucially, the distribution œÄ(Œ∏) is
assumed to reÔ¨Çect this prior belief exactly. This implies that œÄ(Œ∏) should completely
reÔ¨Çect all information available to the modeller such as previously observed observations
13

Knoblauch, Jewson and Damoulas
x‚àím:0 of the same phenomenon or domain expertise relating to the problem domain
and the statistical model.
(L) There exists an (unknown but Ô¨Åxed) Œ∏‚àómaking the Likelihood model equivalent to
the data generating mechanism of xi. This is to say that xi ‚àºp(xi|Œ∏‚àó).3
(C) The budget for Computation is inÔ¨Ånite, so the complexity of computing the belief
q‚àó
B(Œ∏) can be ignored.
If (L), (P) and (C) are satisÔ¨Åed, it immediately follows that the best belief for the event
{Œ∏‚àó= Œ∏}|{x1:n = x1:n} is simply given by the analytically available posterior
dP (Œ∏|x1:n) ‚àùdP (Œ∏)
n
Y
i=1
dP (xi|Œ∏) = œÄ(Œ∏)
n
Y
i=1
p(xi|Œ∏) = q‚àó
B(Œ∏).
(8)
Note that (P) and (L) lend a meaningful interpretation to Bayes‚Äô rule in form of conditional
probability updates. Complementing this, (C) ensures that it is feasible to compute the
generally intractable solution q‚àó
B(Œ∏) of eq. (3). Accordingly, (C) generally is interpreted to
mean that a Markov Chain Monte Carlo algorithm can be run for long enough to accuratley
represent? q‚àó
B(Œ∏). In summary, if (P), (L) and (C) hold, q‚àó
B(Œ∏) is the only desirable posterior
belief distribution.
But how well does reality align with (P), (L) and (C)? Turning attention to (C) Ô¨Årst,
most traditional scientiÔ¨Åc disciplines have little need to worry about computational complexity
and will resort to sampling schemes for two reasons: Firstly, the models are often relatively
simple and thus straightforward to infer. Secondly, even for more complicated models the
experimental setup and data collection typically outweighs the cost of computation by orders
of magnitude. As for (P) and (L), neither prior nor likelihood are ever perfect reÔ¨Çections
of one‚Äôs full prior beliefs (see e.g. Goldstein, 1990; O‚ÄôHagan and Oakley, 2004; Goldstein,
2006) or the data generating mechanism (see e.g. Bernardo, 2000). In other words, (P) and
(L) are invariably violated when interpreted literally. However and as enshrined in Box‚Äôs
aphorism that all models are wrong, but some are useful, this is not a problem so long as
these violations are suÔ¨Éciently small. In traditional statistics, ensuring that these violations
are small has typically been enforced through a simple recursion (e.g. Box, 1980; Berger
et al., 1994). SpeciÔ¨Åcally, until you are conÔ¨Ådent that both (P) and (L) are close enough
to the truth, repeat the following: Check if (L) or (P) are violated severely. If they are,
3.
We note here that to keep the presentation simpler, we are giving conditions that are stricter than
what is required for Bayesian analysis. In particular, (L) corresponds to an objectivist treatment of the
likelihood and can be weakened under the subjectivist paradigm for Bayesian analysis. In this paradigm,
the treatment of the likelihood mirrors that of the prior: It now simply corresponds to the modeller‚Äôs
belief about the process that generated the data. While this Ô¨Årst sounds like a weaker requirement, it
ends up producing the same misspeciÔ¨Åcation problems as (L). SpeciÔ¨Åcally, a subjectivist treatment of
the likelihood requires the modeller to express her beliefs about the likelihood function exactly. This
forces her to make more probability statements than she realistically has time or introspection for (see
e.g. Goldstein, 1990; O‚ÄôHagan and Oakley, 2004; Goldstein, 2006). The result is that the likelihood
function supplied by the modeller is at best going to be an approximate description of the modeller‚Äôs
beliefs. This provides the subjectivist interpretation of misspeciÔ¨Åcation. Notice that it directly mirrors
the objectivist interpretation of misspeciÔ¨Åcation in (L): The likelihood function supplied is at best going
to be an approximate description of the true data generating mechanism.
14

Generalized Variational Inference
choose a more appropriate likelihood and prior. In order to operationalize this iterative logic,
batteries of descriptive statistics, tests and model selection criteria have been developed over
the years.
In summary then, ignoring the computational overhead and iteratively reÔ¨Åning likelihoods
and priors is rightfully the predominant inferential strategy for traditional scientiÔ¨Åc endeavours.
Not only is domain expertise relevant for designing priors and likelihood, but the process of
Ô¨Ånding an appropriate model often provides valuable insights in itself. Further, the expensive
part of the analysis is typically data collection. Consequently, it is typically not prohibitive
to perform inference even with the most computationally expensive of sampling schemes. In
line with this, most methodological contributions in statistical sciences rely to a substantial
degree on (P), (L) and (C).
3.2 Machine Learning: Challenging the traditional paradigm
Contemporary large-scale inference applications have frequently turned the traditional
schematic of statistical model design upside down: Rather than carefully designing an
appropriate likelihood model p(xi|Œ∏) for a speciÔ¨Åc data domain, statistical machine learning
research is typically characterized by the search of a Ô¨Çexible algorithm that can Ô¨Åt any
data set x1:n well enough to produce useful inferences. The resulting likelihood models are
typically not attempting to describe any data generating processes in the sense of (L). Rather,
they are highly over-parameterized functions of Œ∏ and typically un-identiÔ¨Åable, meaning that
Œ∏‚àóis neither interpretable nor unique. Such statistical machine learning models have three
major issues under the traditional paradigm of Bayesian inference that are readily identiÔ¨Åed:
(EP) Invariably, the Prior is misspeciÔ¨Åed. Two factors compound this issue: Firstly, the
large number of parameters over-parameterizing the likelihoods of many statistical
machine learning models are no longer interpretable. This often prohibits domain
experts to carry out carefully guided prior elicitation. Secondly, priors are typically
selected at least in part for their computational feasibility. This fundamentally alters
the interpretation of the prior: Rather than the result of an attempt to capture the
modeller‚Äôs knowledge before observing the data, the prior takes the role of a reference
measure or regularizer. To make matters worse, the number of parameters is often
large relative to n. In turn, this implies that the priors have a disproportional eÔ¨Äect on
inference via q‚àó
B(Œ∏), a problem we will discuss in Example 1 in the context of Bayesian
Neural Networks.
(EL) Clearly, the Likelihood is misspeciÔ¨Åed. This often has adverse side eÔ¨Äects: While
using an oÔ¨Ä-the-shelf and often over-parameterized likelihood function can provide a
good Ô¨Åt for the typical behaviour of the data, it often causes severe problems with
heterogeneous or untypical data points. We will demonstrate this phenomenon on a
changepoint problem in Example 2.
(EC) With increasingly complex statistical models, (C) has proven an increasingly infeasible
description of reality. Accordingly, this problem has inspired numerous directions
of research, including variational methods and Laplace approximations. Example 3
illustrates this for the case of Gaussian Processes.
15

Knoblauch, Jewson and Damoulas
Under the challenges outlined in (EP), (EL) and (EC), standard Bayesian posteriors often
do not provide appropriate belief distributions. In the remainder, we will explain how and
why this is the case for many parts of modern large-scale inference.
0
2
misspecified
d=50
d=100
d=250
KLD
D( )
AR, 
= 0.5
0
2
well-specified
KLD
D( )
AR, 
= 0.5
KLD
D( )
AR, 
= 0.5
qGVI(
true
1
1)
GVI posteriors and prior specification
Figure 3: Best viewed in color. Taken from Knoblauch (2019a), the plot shows the impact
of diÔ¨Äerent prior beliefs on inference in a Bayesian normal mixture model with n = 50
observations and mixture components in Rd for diÔ¨Äerent choices of d. SpeciÔ¨Åcally, the
plot compares inference outcomes under a misspeciÔ¨Åed prior (Top) against those under
a well-speciÔ¨Åed prior (Bottom). It does so by depicting the average absolute diÔ¨Äerence
between the true parameter values and their MAP estimate on the y-axis. Here, the solid
whiskers‚Äô length corresponds to one standard deviation of the underlying posterior. The plot
shows that using the KLD as uncertainty quantiÔ¨Åer as in standard Variational Inference
(VI) will produce undesirable uncertainty quantiÔ¨Åcation under misspeciÔ¨Åed prior beliefs.
In contrast, Generalized Variational Inference (GVI) with R√©nyi‚Äôs Œ±-divergence as
uncertainty quantiÔ¨Åer produces desirable uncertainty quantiÔ¨Åcation in both settings.
3.3 Prior misspeciÔ¨Åcation
For most Ô¨Ånite-dimensional parameters, even severely misspeciÔ¨Åed priors can often be harmless.
Sometimes, this expresses itself in theoretical results: For example, prior misspeciÔ¨Åcation is
typically no problem in the asymptotic sense. SpeciÔ¨Åcally, so long as (L) holds, it suÔ¨Éces
that œÄ(Œ∏‚àó) > 0 for the standard Bayesian posterior to contract around Œ∏‚àóat rate O(n‚àí1/2)
(see e.g. Ghosal, 1998; Ghosal et al., 2000; Shen and Wasserman, 2001; Walker, 2004, and
references therein).
Oftentimes, these results are used as an apology to neglect the role of prior speciÔ¨Åcation.
While it is reassuring that the sequence of standard Bayesian posteriors shrinks to the
population-optimum as n ‚Üí‚àû, this does not describe the real world: In particular, n is
usually Ô¨Åxed and only a single posterior is computed. Note that whenever n is Ô¨Åxed, it is
possible to specify an arbitrarily bad prior belief. This means that once one departs from
assuming that (P) is at least approximately correct, the standard Bayesian posterior belief
about Œ∏‚àócan be made arbitrarily inappropriate‚Äîeven if (L) still holds. Figure 3 illustrates
this on a Bayesian Mixture Model and also shows how Generalized Variational Inference
16

Generalized Variational Inference
(GVI) can solve this problem. As the Figure shows, Ô¨Ånite data can make prior misspeciÔ¨Åcation
a more serious issue, even more so if (i) the parameter space is large relative to n or (ii) it is
impossible to specify priors in a principled way. As we discuss in the next example, a model
invariably aÔ¨Äected by both problems is the Bayesian Neural Network (BNN).
Example 1 (Deep Bayesian models as violations of (P)) Bayesian Neural Networks
( BNNs) (MacKay, 1996; Neal, 2012) seek to combine Deep Learning models with Bayesian
uncertainty quantiÔ¨Åcation. For the parameter vector Œ∏ of weights, let F(Œ∏) be the non-linear
composition of activation functions speciÔ¨Åed by a Neural Network. A conceptually appealing
way of thinking about BNNs is as an arbitrarily Ô¨Çexible likelihood function with a large
number of parameters d = |Œò|. This is to say that one believes that (at least approximately),
xi ‚àºp(xi|F(Œ∏‚àó)) for some Œ∏‚àó‚ààŒò. For a prior œÄ(Œ∏) about Œ∏, this means that BNNs seek to
do inference on the posterior given by
q‚àó(Œ∏) ‚àùœÄ(Œ∏)
n
Y
i=1
p(xi|F(Œ∏)).
At Ô¨Årst, this approach seems conceptually appealing: Not only does one circumvent most
issues with ( L) by making the likelihood function almost arbitrarily Ô¨Çexible, but one also
quantiÔ¨Åes uncertainty in the usual Bayesian manner. While both observations are correct,
they mask a potentially severe issue with this approach: Namely, specifying the prior œÄ(Œ∏) in
a principled way and in (approximate) accordance with ( P) is impossible in practice: Firstly,
because the vector Œ∏ indexes a black box model, its entries do not correspond to interpretable
quantities. Accordingly, building prior beliefs based on domain expertise about the data x1:n
is not feasible. Secondly, since computational aspects are a major concern for BNNs, one is
typically constrained to choosing priors that factorize over Œ∏. As a consequence, practitioners
often resort to choosing default priors which are not motivated as prior beliefs in the original
sense or by an attempt to approximately satisfy ( P). SpeciÔ¨Åcally, one typically just picks
œÄ(Œ∏) = Qd
j=1 œÄj(Œ∏j), where œÄj(Œ∏j) is a standard normal distribution for all j. Choosing
priors in this ad-hoc fashion violates the principles underlying classical Bayesian modelling
(see also Section 5.2.1). This is especially problematic whenever n is small relative to d: In
these situations, prior inÔ¨Çuence serves as a strong source of information about Œ∏. Thus, if the
prior is misspeciÔ¨Åed and n is small relative to d, the (incorrect) information contained in the
prior often overshadows the information in the data. At the same time, reliable uncertainty
quantiÔ¨Åcation is most important whenever n is small relative to d. Indeed, this is a well-known
issue and is addressed in various contributions by up-weighting the likelihood (down-weighting
the KLD term in the ELBO), see Bowman et al. (2016); Zhang et al. (2018); Rossi et al.
(2019a,b); S√∏nderby et al. (2016).
For completeness, we note that the current paper does not discuss uninformative and
so-called objective priors (see, e.g. JeÔ¨Äreys, 1961; Zellner, 1977; Bernardo, 1979; Berger
and Bernardo, 1992; Jaynes, 2003; Berger, 2006). Priors of this kind are constructed to be
as uninformative as possible and thus in some ways objective. In many ways, they are a
principled and natural response to the critique of ill-informed priors. Generally however,
their construction results in so-called improper priors‚Äìdensities that do not correspond to a
Ô¨Ånite measure and thus do not integrate to one. While this is not generally prohibitive, it
17

Knoblauch, Jewson and Damoulas
would severely complicate the developments of Section 4 because most divergences are not
well-deÔ¨Åned for improper priors4.
3.4 Likelihood MisspeciÔ¨Åcation
While prior misspeciÔ¨Åcation aÔ¨Äects inference adversely, the issue for inferential practice
is even more serious if (L) is violated thoroughly: Whenever the likelihood model for xi
is severely misspeciÔ¨Åed, inference outcomes suÔ¨Äer dramatically. Moreover, not even the
asymptotic regime oÔ¨Äers a remedy and the adverse eÔ¨Äects of misspeciÔ¨Åcation persist as
n ‚Üí‚àû. The traditional approach to addressing this issue is straightforward: If the likelihood
model p(xi|Œ∏) is misspeciÔ¨Åed, simply investigate why exactly it Ô¨Åts the data poorly. After
residual analysis, intense study of descriptive statistics and consultation with domain experts,
redesign it to arrive at a likelihood model p‚Ä≤(xi|Œ∏‚Ä≤), which hopefully provides a better Ô¨Åt to
the data and (approximately) satisÔ¨Åes (L). In other words, the traditional view is that any
problem with misspeciÔ¨Åcation is really a problem with careless modelling.
As outlined in Section 3.2, this strategy is neither practiced nor feasible with contemporary
large-scale models. The naive interpretation of likelihood functions as corresponding to an
appropriately good description of the true data generating process in the sense of (L) is thus
wholly inappropriate. This is especially important as many large-scale models are mainly
interested in capturing the typical behaviour of the data‚Äîrather than fully modelling every
aspect of a population. While this may appear to be a minor point at Ô¨Årst glance, it has
serious consequences for inferential practice. To see why, suppose a population contains
a small number of outlying observations, local heterogeneities or spiky noise. The naive
interpretation of the likelihood as in (L) assumes that these untypical aspects are encoded
in the likelihood function. Hence, if xi is an outlier so that p(xi|Œ∏) is very close to zero
for some value of Œ∏ constructed to Ô¨Åt the rest of the data, the inference machinery of
traditional statistics interprets this as a strong signal: After all, if the likelihood model is an
approximately correct description of the data generating mechanism, the most informative
observations are those that do not Ô¨Åt the model Ô¨Åtted to the rest of the data. It follows that
aberrant parts of the data will have a disproportional impact on inference outcomes‚Äîleading
standard inference methods to break down (see also Jewson et al., 2018).
While it is in general hard to visualize this issue, inÔ¨Çuence functions provide a concise
way of showcasing the problem. Roughly speaking, inÔ¨Çuence functions in a Bayesian context
quantify the impact the (n + 1)-th observation xn+1 has on the posterior distribution q‚àó
B(Œ∏)
constructed using the Ô¨Årst n observations (Peng and Dey, 1995). This discrepancy is measured
by computing a divergence between the posteriors based on x1:n and on x1:(n+1). Using the
Fisher-Rao divergence (for its geometric properties as explained in Kurtek and Bharath,
2015), Figure 4 compares the inÔ¨Çuence of a standard Bayesian posterior with that of a
posterior belief computed using Generalized Variational Inference (GVI). The left side of the
Figure formalizes the intuition we have just developed: In the standard Bayesian case, the
inÔ¨Çuence of xn+1 on the posterior belief grows stronger and stronger the more untypical it is
relative to previously observed data. Similarly, the right side shows the adverse eÔ¨Äect this
4. The KLD is the exception to this rule: As it depends on the log normalizer of œÄ(Œ∏) in an additive fashion,
improper priors can still be admissible so long as eq. (3) yields a solution for the unnormalized version of
the KLD as given in Cichocki and Amari (2010).
18

Generalized Variational Inference
has on the posterior predictive. To make the implications of inÔ¨Çuence functions for inferential
practice more tangible, we additionally demonstrate the outlier problem in Example 2.
0
2
4
6
8
10
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
Standard Deviations from the Posterior Mean
InÔ¨Çuence/Density
‚àílog(p(x; Œ∏))
LŒ≤
p(x, Œ∏), Œ≤ = 1.05
LŒ≤
p(x, Œ∏), Œ≤ = 1.1
LŒ≤
p(x, Œ∏), Œ≤ = 1.25
N(0,1)
-5
0
5
10
15
0.0
0.1
0.2
0.3
0.4
x
Density
(1 ‚àíœµ)N(0, 1)
œµN(8, 1)
VI, ‚àílog(p(x; Œ∏))
GVI, LŒ≤
p(x, Œ∏)
Contamination
Figure 4: Best viewed in color. The plots compare inÔ¨Çuence functions (Left) and predictive
posteriors (Right) of a standard Bayesian against a GVI posterior. Left: The inÔ¨Çuence
functions of scoring the normal likelihood with a standard negative log likelihood against
a robust scoring rule derived from Œ≤-divergences. Right: A univariate normal is Ô¨Åtted
using all the data depicted, including the outlying contamination. The posterior predictive
corresponding to the robust scoring rule is able to ignore these outliers. This stands in
contrast to the posterior predictive based on standard, which assigns increasingly large
inÔ¨Çuence to outlying observations.
Example 2 (Outliers as violations of (L)) While there exist many formalizations of the
notion of an outlier, the conceptually most useful one is probably the Œµ-contamination model.
In the Œµ-contamination model, the data points xi are generated according to a contaminated
density composed additively as
ptrue(xi) = (1 ‚àíŒµ) ¬∑ p(xi|Œ∏‚àó) + Œµ ¬∑ o(xi),
for some small and Ô¨Åxed 0 < Œµ < 1, a Ô¨Åxed parameter value Œ∏‚àóof interest and a contaminating
outlier-generating density o. An obvious violation of ( L) for this case would be Ô¨Åtting the
data only to the non-contaminated component p(xi|Œ∏) in order to infer Œ∏‚àó.
Considering this type of model misspeciÔ¨Åcation is especially poignant in Bayesian On-line
Changepoint Detection ( BOCPD), a well-studied family of models that yield computationally
eÔ¨Écient algorithms (see e.g. Adams and MacKay, 2007; Fearnhead and Liu, 2007; Wilson
et al., 2010; Saat√ßi et al., 2010; Caron et al., 2012; Turner et al., 2013; Knoblauch and
19

Knoblauch, Jewson and Damoulas
Damoulas, 2018; Knoblauch et al., 2018). BOCPD aims to segment a data stream in real
time and achieves this via an eÔ¨Écient recursion updating the Bayesian posterior with each
newly arriving observation. A canonical application example of BOCPD is the well-log data
set Ô¨Årst discussed by O‚ÄôRuanaidh (1994). Its observations describe the abruptly changing
nuclear responses of rock stratiÔ¨Åcation during the course of drilling a well. Generally, the
diÔ¨Äerent rock strata are clearly distinguishable from one another. However, rock formation
processes are noisy and sometimes interrupted by extraordinary events such as tsunamis,
earth quakes or eruptions. Accordingly, the data points generated are surprisingly close to
an Œµ-contaminated normal distribution within each of the clearly distinguishable rock strata.
Figure 5 is taken from Knoblauch et al. (2018) and shows how this phenomenon renders
vanilla BOCPD an unreliable algorithm. It also shows that this issue can be remedied by
constructing alternative posterior belief distributions via a Generalized Variational Inference
( GVI) procedure relying on a robust loss function derived from the Œ≤-divergence.
0
500
1000
1500
2000
2500
3000
3500
4000
Time
80000
100000
120000
140000
Nuclear Response
Figure 5: Best viewed in color. Inference outcomes of BOCPD on the well log data set
using the standard Bayesian posterior and a GVI posterior constructed with robust
losses based on the Œ≤-divergence. Solid vertical lines correspond to Maximum A Posteriori
(MAP) segmentation of GVI posterior, dashed vertical lines mark incorrect changepoints
additionally detected under standard Bayesian inference.
3.5 Computation mismatch
As Theorem 1 shows, the Bayesian posterior q‚àó
B(Œ∏) is the result of an optimisation problem
over the inÔ¨Ånite-dimensional space P(Œò).
Generally therefore, the posterior itself also
does not have a closed form expressed in a Ô¨Ånite-dimensional parameter.In fact, the only
case in which q‚àó
B(Œ∏) can be represented through a Ô¨Ånite-dimensional parameter is when
prior and likelihood are conjugate to one another. Accordingly, performing inference with
q‚àó
B(Œ∏) is in general a hard problem, which manifests itself through the need to compute the
generally intractable normalizing constant. To circumvent this problem, it is common to
leverage Markov Chain Monte Carlo algorithms that produce an exact representation of
q‚àó
B(Œ∏) if the chain runs indeÔ¨Ånitely and collects inÔ¨Ånitely many (correlated) samples. In
practice, collecting a Ô¨Ånite number of samples from the chain will often yield a reasonable
approximation to the posterior so long as d = |Œò| is not too large. For large values of d
however, the number of samples required to make the approximation useful is often too
large to make sampling a computationally viable strategy: For example, in the best case
scenario, Random Walk Metropolis Hastings scales like O(d2) (Roberts et al., 1997), the
20

Generalized Variational Inference
Metropolis-adjusted Langevin algorithm like O(d4/3) (Roberts and Rosenthal, 1998) and
Hamiltonian Monte Carlo like O(d5/4) (Beskos et al., 2013). Note that these results assume
independence and Gaussiantiy‚Äîso in practice scaling rates are typically much worse.
An alternative way of avoiding the computation of a normalizing constant are various
approximation strategies seeking to project q‚àó
B(Œ∏) into some parameterized subset Q ‚äÇP(Œò).
This strategy will produce approximations q‚àó
A(Œ∏) of high quality only if the set Q is chosen
to be suÔ¨Éciently rich so that the statement q‚àó
A(Œ∏) ‚âàq‚àó
B(Œ∏) is not completely vacuous.
Importantly however, most posterior belief distributions q‚àó
A(Œ∏) that are regularly computed
this way barely deserve to be called approximations to q‚àó
B(Œ∏). For example, consider the
mean Ô¨Åeld normal variational family given by
QMFN =
Ô£±
Ô£≤
Ô£≥
d
Y
j=1
N(Œ∏j|¬µj, œÉ2
j ) : ¬µj ‚ààR, œÉ2
j ‚ààR>0 for all j
Ô£º
Ô£Ω
Ô£æ.
(9)
For most interesting non-trivial posterior distributions q‚àó
B(Œ∏), there will not exist any element
in QMFN that could be considered an approximation to q‚àó
B(Œ∏) in any meaningful way: After all,
this variational family directly assumes O(d2) independence relationships in the approximate
posterior belief for Œ∏. Worse still: As approximations are particularly attractive when |Œò| = d
is large, in practice we will resort to these insuÔ¨Éciently expressive ‚Äúapproximations‚Äù to q‚àó
B(Œ∏)
precisely when the elements in QMFN are structurally most dissimilar from q‚àó
B(Œ∏). As we
proceed to explain in the remainder of the paper, we think it is often unhelpful to think of
posterior beliefs q‚àó
A(Œ∏) computed in this way as approximations to q‚àó
B(Œ∏). Rather, we think
of them as deÔ¨Åning a new and distinct posterior belief distribution in their own right.
To make the preceding discussion more tangible and highlight the importance that the
frequent violation of (C) has played in research on statistical machine learning, Example 3
illuminates the importance of computational considerations for Gaussian Processes.
Example 3 (large-scale Gaussian processes as violations of (C)) Many Bayesian ma-
chine learning models prohibit exact computation. One particularly interesting case are
Gaussian Processes ( GPs): Even in the special cases where they admit closed form pos-
teriors, it may well be impossible to compute them exactly for suÔ¨Éciently large inference
problems. The reason is that for n observations, direct computation of the associated GP
posterior takes O(n3) time. As a consequence, an entire literature is dedicated to bringing
down this prohibitive computational complexity (see for instance Williams and Seeger, 2001;
Qui√±onero-Candela and Rasmussen, 2005; Snelson and Ghahramani, 2006; Titsias, 2009)
and developing software or computer-architecture speciÔ¨Åc methods geared towards inference
with GPs (e.g. Matthews et al., 2017; Gardner et al., 2018; Balandat et al., 2019; Wang
et al., 2019). Furthermore, with deep (i.e., hierarchical) approaches to GPs introduced in
Damianou and Lawrence (2013) and extended in various directions (e.g. Dai et al., 2016;
Hegde et al., 2019), this challenge has only become more important (see e.g. Bui et al., 2016;
Cutajar et al., 2017b; Salimbeni and Deisenroth, 2017).
4. The Rule of Three: A new Bayesian paradigm
As the last sections have shown, the assumptions which form the core of traditional Bayesian
inference are often not a good basis for modern large-scale statistical inference. In response
21

Knoblauch, Jewson and Damoulas
to this observation, the following section seeks to generalize the Bayesian paradigm. As we
shall see, the way in which we do so is strongly inspired by the preceding development in two
important ways: Firstly, as we did in Section 2, we take inspiration from an optimization-
centric view on Bayesian inference. Secondly, since we saw in Section 3 that there are
three potentially problematic assumptions underlying Bayesian inference, we construct our
generalization in order to address each of these concerns directly and modularly. This
development proceeds in three steps.
Section 4.1 sets out axioms that are a minimal requirement for any posterior belief
distribution. In accordance with these axioms, we derive the Rule of Three (RoT).
Sections 4.2 & 4.3 discuss the RoT as a recipe for producing posterior belief distri-
butions and elaborate on its three interpretable ingredients. We also show how the
RoT can directly address the concerns associated with imposing (P), (L) and (C).
Section 4.4 demonstrates that the axiomatic development is both helpful and useful
by comparing the RoT with existing methods that generate belief distributions.
4.1 An axiomatic foundation for Bayesian inference
In this section, we set out to produce a novel axiomatic foundation for Bayesian inference
that is Ô¨Çexible enough to deal with contemporary real-world challenges. Before doing so, we
deÔ¨Åne two core concepts required in their development.
DeÔ¨Ånition 7 (Loss Function) Losses are functions ‚Ñì: Œò √ó X ‚ÜíR which for any obser-
vation sequence x1:n ‚ààX n have empirical risk minimizers
bŒ∏n = arg min
Œ∏‚ààŒò
( n
X
i=1
‚Ñì(Œ∏, xi)
)
.
DeÔ¨Ånition 8 (Statistical Divergence) Statistical divergences are functions D : P(Œò) √ó
P(Œò) ‚ÜíR‚â•0 which satisfy that D(q‚à•œÄ) ‚â•0 and D(q‚à•œÄ) = 0 if and only if q(Œ∏) = œÄ(Œ∏)
almost everywhere.
In the axiomatic development to follow, we will avoid introducing measure-theoretic notation.
Thus, for simplicity we will assume that all densities are deÔ¨Åned with respect to the Lebesgue
measure on Rd. To the same end, we will also slightly abuse notation in two ways. Firstly,
we will write that q‚àó‚ààP(Œò) for probability densities q‚àó(Œ∏) on Œò, even though probability
densities are not in P(Œò). However, q‚àó(Œ∏) induces a measure ¬µq‚àó‚ààP(Œò) as ¬µq‚àó(A) =
R
A dq‚àó(Œ∏) for any measurable set A ‚äÇŒò. Thus, whenever we write q‚àó‚ààP(Œò), what we
mean is that ¬µq‚àó‚ààP(Œò). Similarly, we will sometimes write q‚àó
1 Ã∏= q‚àó
2 to mean that there
exists a measurable set A ‚ààŒò such that ¬µq‚àó
1(A) Ã∏= ¬µq‚àó
2(A). We are now Ô¨Ånally ready to state
the axiomatic foundations. To avoid confusion, note that Axioms will build on each other in
the order in which they are stated.
Axiom I
(Representation)
The posterior q‚àó‚ààP(Œò) is constructed by solving an
optimization problem over some space Œ† ‚äÜP(Œò). The optimization seeks to minimize exactly
two criteria that do not interact:
22

Generalized Variational Inference
(i) The in-sample loss Pn
i=1 ‚Ñì(Œ∏, xi) to be expected under q‚àó(Œ∏).
(ii) The deviation from the prior œÄ(Œ∏) as measured by the magnitude of some statistical
divergence D.
Remark 9 By inspecting eq. (3), it becomes clear that the above axiom is a generalization
of traditional Bayesian inference: Firstly, eq. (3) reveals that standard Bayesian inference
solves an optimization problem over Œ† = P(Œò). Secondly, eq. (3) also shows that (i) of the
above Axiom also holds for standard Bayesian posteriors. In traditional Bayesian inference,
the loss to be minimized is a negative log likelihood, while more recent iterations have allowed
for broader classes of losses (e.g. Bissiri et al., 2016; Jewson et al., 2018). Thirdly, eq. (3)
demonstrates that (ii) is also satisÔ¨Åed for standard Bayesian inference: The Kullback-Leibler
Divergence ( KLD) penalizes large deviations of q‚àó
B(Œ∏) from the prior œÄ(Œ∏).
Reiterating the essence of Observation 1, the previous axiom formalizes our understanding
of Bayesian inference as an optimization problem over a potentially inÔ¨Ånite-dimensional
function space. In fact, it already tells us that for a Ô¨Åxed prior, posterior beliefs derived
under our new axiomatic approach have three distinct ingredients: The loss ‚Ñì, the divergence
D(¬∑‚à•œÄ) and the space Œ†. Making this insight more precise immediately yields the following
representation Theorem.
Theorem 10 (Form 1) Under Axiom I, posterior belief distributions can be written as
q‚àó(Œ∏) = arg min
q‚ààŒ†
(
f
 
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
, D(q||œÄ)
!)
,
where f : R2 ‚ÜíR is some function which is non-decreasing in both its arguments.
Proof This follows directly from Axiom I: Firstly, any posterior belief distribution q‚àó(Œ∏)
is the solution to an optimization problem over Œ†. Thus, for an appropriately structured
objective Obj, one can write
q‚àó(Œ∏) = arg min
q‚ààŒ†
{Obj(q)} .
Hence, the question becomes what the objective looks like. The answer is provided by parts
(i) and (ii) of Axiom I: By (i), the optimization‚Äôs objective depends on Eq(Œ∏)[‚Ñì(Œ∏, xi)]. Further,
by (ii) it also depends on the divergence D between prior and q, i.e. on D(q||œÄ). Clearly
then, for some function f : R2 ‚ÜíR,
Obj(q) = f
 
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
, D(q||œÄ)
!
.
Noting that both arguments are not allowed to interact and are to be minimized, it is clear
that f is non-decreasing in both arguments, which completes the proof.
This result is a Ô¨Årst and helpful step, but in itself does not suÔ¨Éce to yield objectives that are
useful in practice. SpeciÔ¨Åcally, we need to get a handle on the function f. It is clear that
23

Knoblauch, Jewson and Damoulas
under Axiom I alone, very little can be said about f. The next two axioms seek to address
this very issue. The Axiom II is imposed for a simple purpose: We want posteriors to be
invariant to uninformative components of the loss ‚Ñìas well as the divergence term D. In
other words, adding a constant C to the loss or the divergence from the prior should not
change our inferences about Œ∏.
Axiom II (Information Equivalence) Take any two constants C, M ‚ààR>0 and let the
posteriors q‚àó
1, q‚àó
2 ‚ààP(Œò) be computed based on the same optimization problem, but with two
diÔ¨Äerent loss functions ‚Ñì(1) and ‚Ñì(2) as well as two diÔ¨Äerent divergences D(1), D(2) so that
D(1) = D(2) + M and so that ‚Ñì(1) = ‚Ñì(2) + C. Then, q‚àó
1(Œ∏) = q‚àó
2(Œ∏) (almost everywhere).
Remark 11 At this point, one may pause and wonder if one would not like the above axiom
to be stronger. SpeciÔ¨Åcally, would one want diÔ¨Äerent posteriors if ‚Ñì(1) = w ¬∑ ‚Ñì(2) for some
w Ã∏= 1? Since we want our methods to recover existing Bayesian inference techniques as
special cases, this question is readily answered. In particular, notice that many Bayesian
inference techniques do attach information to pre-multiplying losses with a constant. For
example, in the Power Bayesian framework (e.g. Gr√ºnwald, 2011, 2012; Holmes and Walker,
2017; Gr√ºnwald and Van Ommen, 2017; Miller and Dunson, 2019) one wishes to down-weight
the information in the likelihood terms by considering the pseudo-likelihood terms p(xi|Œ∏)w for
some w ‚àà(0, 1) instead of p(xi|Œ∏). This procedure is attractive since it produces alternative
posterior beliefs that contract to a point mass at a slower rate than the standard posteriors.
Re-examining eq. (3), it becomes clear that relative to standard Bayes rule, power likelihoods
are in fact a simple re-weighting scheme. SpeciÔ¨Åcally, one replaces ‚Ñì(Œ∏, xi) = ‚àílog p(xi|Œ∏) by
the weighted version ‚Ñì(Œ∏, xi) = ‚àíw log p(xi|Œ∏).
We are now ready to state the last axiom. Observe that Axiom III determines conditions
under which the posterior must not be aÔ¨Äected by changing inputs. Complementing this, we
still require suÔ¨Écient conditions under which the posteriors are guaranteed to diÔ¨Äer.
Axiom III (Generalized Likelihood Principle) Suppose the posteriors q‚àó
n, q‚àó
n+m ‚ààŒ†
are computed based on an optimization problem satisfying Axiom I. Assume that the same
optimization problem is used for both posteriors, except for a diÔ¨Äerence in the samples x1:n
and x1:n+m and potentially diÔ¨Äerent loss functions ‚Ñì(1) and ‚Ñì(2) that are used, respectively.
(i) Provided that there is an information diÔ¨Äerence between x1:n and x1:n+m for m > 0, the
posteriors are diÔ¨Äerent. In other words, Pn
i=1 ‚Ñì(1) (Œ∏, xi) Ã∏= Pn+m
i=1 ‚Ñì(2) (Œ∏, xi) implies
that q‚àó
n Ã∏= q‚àó
n+m, even if ‚Ñì(1) = ‚Ñì(2).
(ii) Provided that there is a diÔ¨Äerence in the measure of information between ‚Ñì(1) and ‚Ñì(2),
the posteriors are diÔ¨Äerent. In other words, ‚Ñì(1) Ã∏= ‚Ñì(2) implies that q‚àó
n Ã∏= q‚àó
n+m, even if
m = 0 so that x1:n = x1:n+m.
Remark 12 This axiom has a particularly interesting interpretation as a generalized version
of the well-known likelihood principle associated with standard Bayesian inference. Roughly
speaking, the likelihood principle says that all information in x1:n relevant to conducting
inference on the model parameters is contained in the likelihood functions evaluated at x1:n.
Similarly, Axiom III says that all information the sample x1:n contains about Œ∏ is contained
in the loss function evaluated on the relevant data sample.
24

Generalized Variational Inference
Remark 13 Notice that part (ii) of Axiom III requires that ‚Ñì(1) and ‚Ñì(2) measure information
diÔ¨Äerently, which precludes that ‚Ñì(1) = ‚Ñì(2) + C for some C ‚ààR>0 by Axiom II.
Recalling the discussion of Remark 11, we next state a result showing that our axiomatic
approach respects the logic of Power Bayes and related procedures. SpeciÔ¨Åcally, re-weighting
the likelihood (or the losses more generally) will yield diÔ¨Äerent posteriors.
Corollary 14 If Axiom III holds, and if the posteriors q‚àó
1 ‚ààŒ† and q‚àó
2 ‚ààŒ† are based on the
same observations and losses ‚Ñìand w ¬∑ ‚Ñìfor w ‚ààR>0 \ {1}, respectively, then q‚àó
1 Ã∏= q‚àó
2.
Proof This follows from part (ii) of Axiom III.
Finally, we investigate how the axiomatic developments set out above simplify the structure
of objectives producing posterior belief distributions. To achieve this, it is clear that we need
to re-investigate f : R2 ‚ÜíR as in Theorem 10. Since we want f to recover the standard
Bayesian posterior of eq. (3) as well as the standard VI posterior in eq. (2.3.1), it is natural
to restrict attention to elementary operations. Doing so produces the following representation
result that is both stricter and more useful than Theorem 10.
Theorem 15 Suppose the posterior belief q‚àó‚ààP(Œò) satisÔ¨Åes Axiom I. Recall from Theorem
10 that this is equivalent to saying that for some Œ† ‚äÜP(Œò), some loss function ‚Ñì: Œò√óX ‚ÜíR
and some divergence D(¬∑‚à•œÄ) : P(Œò) ‚ÜíR‚â•0, the posterior can be written as
q‚àó(Œ∏) = arg min
q‚ààŒ†
(
f
 
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
, D(q‚à•œÄ)
!)
,
where f is some function f : R2 ‚ÜíR. If f(x, y) = x ‚ó¶y is an elementary operation on R
and q‚àó‚ààP(Œò) satisÔ¨Åes Axiom II, this objective is uniquely identiÔ¨Åed as
q‚àó(Œ∏) = arg min
q‚ààŒ†
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(q‚à•œÄ)
)
.
(10)
Proof The elementary operations are addition, subtraction, multiplication and division.
Consider the losses ‚Ñì(1) and ‚Ñì(2) = ‚Ñì(1) + C for C ‚ààR>0 a constant. It is straightforward to
see that Axiom II is violated if ‚ó¶is multiplication:
arg min
q‚ààŒ†
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(2)(Œ∏, xi)
#
¬∑ D(q‚à•œÄ)
)
= arg min
q‚ààŒ†
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(1)(Œ∏, xi)
#
¬∑ D(q‚à•œÄ) + C ¬∑ D(q‚à•œÄ)
)
Ã∏= arg min
q‚ààŒ†
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(1)(Œ∏, xi)
#
¬∑ D(q‚à•œÄ)
)
and similarly if ‚ó¶is division. However, it is straightforward to see that the optimization
problem is invariant to adding constants to the loss or the divergence if ‚ó¶is addition or
25

Knoblauch, Jewson and Damoulas
subtraction. Finally, subtracting the prior regularizer is a direct and obvious violation of
part (ii) in Axiom I, it follows that addition is the only elementary operation on R satisfying
both Axioms and the result follows.
The last result is of crucial importance for the further development of the paper: SpeciÔ¨Åcally,
eq. (10) provides a generic and Ô¨Çexible recipe for the design of novel posterior distributions.
In fact, it is this equation that we discuss next.
4.2 The Rule of Three
Following from the axiomatic developments of the last section that culminated in Theorem 15,
we next discuss the interpretations and theoretical properties of posterior belief distributions
generated from objectives as in eq. (10). To simplify the representation throughout the
remainder, we Ô¨Årst deÔ¨Åne notation for posteriors of this form.
DeÔ¨Ånition 16 (Rule of Three (RoT)) Take observations x1:n, a prior œÄ(Œ∏), a space Œ† ‚äÜ
P(Œò), a loss function ‚Ñì: Œò √ó X ‚ÜíR and a divergence D(¬∑‚à•œÄ) : Œ† ‚ÜíR‚â•0. With this in
hand, we say that posteriors have been constructed via the Rule of Three ( RoT) if they
can be written as
q‚àó(Œ∏) = arg min
q‚ààŒ†
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(q‚à•œÄ)
)
= P(‚Ñì, D, Œ†).
Here, P(‚Ñì, D, Œ†) is a short-hand notation for the RoT suppressing dependence on n and œÄ.
Remark 17 Before moving on, note that in the RoT, D determines the shape of the uncer-
tainty, i.e. how exactly uncertainty is quantiÔ¨Åed. To see that this is true, consider eq. (3) but
leave out the KLD from the optimization problem. This yields the (non-RoT) problem
bq(Œ∏) = arg min
q‚ààP(Œò)
(
Eq
" n
X
i=1
‚Ñì(Œ∏, xi)
#)
.
(11)
Denoting bŒ∏n = arg minŒ∏‚ààŒò {Pn
i=1 ‚Ñì(Œ∏, xi)} as the empirical risk minimizer (maximum likeli-
hood estimate if the loss is a negative log likelihood) and Œ¥y(x) as the Dirac measure at y, it
is immediately clear that bq(Œ∏) = Œ¥bŒ∏n(Œ∏), which holds as Œ¥bŒ∏n ‚ààP(Œò).
The RoT is a corner stone of our contribution: Based on the axiomatic development, we
argue that posteriors should take the form P(‚Ñì, D, Œ†). The most practically feasible versions
of these problems correspond to the case where Œ† is a Œ∫-parameterized family of distributions
Q = {q(Œ∏|Œ∫) : Œ∫ ‚ààK}. Beliefs of this form are Generalized Variational Inference (GVI)
posteriors. They are a special case of the RoT that we explore in Section 5.
On top of the axiomatic foundation from which the RoT directly originates, the next
two subsections provide additional reasons for designing posterior beliefs according to the
form P(‚Ñì, D, Œ†). First, we give an interpretation of the three components of the RoT. In
particular, we show that they directly address the three issues (EP), (EL) and (EC) via an
intuitive modularity result. Second, we recover some existing Bayesian methods as special
cases of the RoT. We discuss the meaning of a Bayesian method (not) being representable
via P(‚Ñì, D, Œ†) and use this as a springboard to motivate GVI.
26

Generalized Variational Inference
4.3 Modularity of the Rule of Three
Taking another look at the constituent parts of P(‚Ñì, D, Œ†), it becomes clear that each
component of the optimization problem serves a speciÔ¨Åc and separate purpose. In particular,
posteriors generated by the RoT have three ingredients.
(¬≠L) A loss ‚Ñì: Œò √ó X ‚ÜíR. The loss deÔ¨Ånes the parameter of interest Œ∏ by linking it to the
observations x1:n. Throughout, we make a number of assumptions on the loss. None of
these assumptions are required, but they signiÔ¨Åcantly simplify the presentation: Firstly,
we assume that the losses are additive and identical over all observations5. Secondly, we
assume that the loss depends on a parameter Œ∏ rather than a latent variable6. Thirdly,
we assume that the losses are deterministic and do not depend on unknown (local or
global) latent variables7.
(¬≠P) A divergence D : P(Œò) √ó P(Œò) ‚ÜíR+ that imposes a cost for the posterior to deviate
too much from the prior œÄ(Œ∏). Recalling Remark 17 and speciÔ¨Åcally eq. (11), it is
clear that D determines how uncertainty about Œ∏ is quantiÔ¨Åed with the posterior.
Accordingly, we also call D the uncertainty quantiÔ¨Åer.
(¬≠C) A set of feasible posteriors Œ† ‚äÜP(Œò) the objective speciÔ¨Åed by the RoT is minimized
over. The word ‚Äúfeasible‚Äù here is used in the optimization sense: As the form of
P(‚Ñì, D, Œ†) reveals, any q(Œ∏) ‚ààŒ† is a feasible solution (i.e. posterior).
From this, it is clear that P(‚Ñì, D, Œ†) has a modular interpretation and decomposes into three
parts with distinct functions. Moreover, taking another glance at the problems (EP), (EL)
and (EC), observe that each of the arguments of P(‚Ñì, D, Œ†) addresses one of the concerns
raised in Section 3: Firstly, as the loss ‚Ñìdetermines the parameter, it can be used to tackle
model misspeciÔ¨Åcation and other violations of (L). Secondly‚Äîand assuming one has already
speciÔ¨Åed the best possible prior belief that is available and/or computationally feasible‚Äîthe
uncertainty quantiÔ¨Åer D can be deployed to change the way in which priors inÔ¨Çuence inference,
directly tackling issues surrounding (P). Accordingly, changing D shifts the uncertainty
quantiÔ¨Åcation about Œ∏. Thirdly, the space of potential posterior beliefs Œ† can be chosen in
such a way as to address the problems with (C): The more computational power is available,
the more complex Œ† can become. In fact, making this modularity conceptually more precise,
we arrive at the following result:
Theorem 18 (RoT modularity) Hold n, œÄ(Œ∏) and Œ† Ô¨Åxed and take q‚àó
1(Œ∏) ‚ààŒ† as a pos-
terior computed via P(‚Ñì, D, Œ†). If one wishes to derive an alternative posterior q‚àó
2(Œ∏) ‚ààŒ†
through the RoT
(1) which avoids or is robust to model misspeciÔ¨Åcation, this amounts to changing ‚Ñì.
5.
The losses are in fact not required to be identical and we can easily replace ‚Ñì(Œ∏, xi) by ‚Ñìi(Œ∏, xi). For
example, one can set ‚Ñìi(Œ∏, xi) = ‚Ñì(Œ∏, xi|x1:i‚àí1). Here, the xi-th observation is conditioned on the Ô¨Årst i‚àí1
observations as is common in time series models. More generally, any conditional dependence structure is
easily incorporated into the RoT at the expense of complicating notation, see also Knoblauch (2019a).
6.
Except in the experiments on Deep Gaussian Processes in Section 6. Here, the losses are in fact directly
deÔ¨Åned relative to latent variables.
7. While latent variable models are not the focus of the current paper, the RoT and GVI are easily extended
to the latent variable case, see Knoblauch (2019a).
27

Knoblauch, Jewson and Damoulas
(2) which is robust to prior misspeciÔ¨Åcation without changing the parameter of interest,
this amounts to changing D.
(3) which aÔ¨Äects uncertainty quantiÔ¨Åcation without changing the parameter of interest, this
amounts to changing D.
Remark 19 The proof can be found in the Appendix C. While it is easy to prove, it requires
carefully deÔ¨Åning robustness to model misspeciÔ¨Åcation as in Tukey (1960) and thus is somewhat
laborious.
Method
‚Ñì(Œ∏, xi)
D
Œ†
Standard Bayes
‚àílog p(xi|Œ∏)
KLD
P(Œò)
Power Likelihood Bayes1
‚àílog p(xi|Œ∏)
1
w KLD, w < 1
P(Œò)
Composite Likelihood Bayes2
‚àíwi log p(xi|Œ∏)
KLD
P(Œò)
Divergence-based Bayes3
divergence-based ‚Ñì
KLD
P(Œò)
PAC/Gibbs Bayes4
any ‚Ñì
KLD
P(Œò)
VAE5,‚Ä†
‚àílog pŒ∂(xi|Œ∏)
KLD
Q
Œ≤-VAE6,‚Ä†
‚àílog pŒ∂(xi|Œ∏)
Œ≤ ¬∑ KLD, Œ≤ > 1
Q
Bernoulli-VAE7,‚Ä†
continuous Bernoulli
KLD
Q
Standard VI
‚àílog p(xi|Œ∏)
KLD
Q
Power VI8
‚àílog p(xi|Œ∏)
1
w KLD, w < 1
Q
Utility VI9
‚àílog p(xi|Œ∏) + log u(h, xi)
KLD
Q
Regularized Bayes10
‚àílog p(xi|Œ∏) + œÜ(Œ∏, xi)
KLD
Q
Gibbs VI11
any ‚Ñì
KLD
Q
Generalized VI
any ‚Ñì
any D
Q
Table 1: Relationship of P(‚Ñì, D, Q) to a selection of existing methods. 1(e.g. Gr√ºnwald, 2011,
2012; Holmes and Walker, 2017; Gr√ºnwald and Van Ommen, 2017; Miller and Dunson, 2019),
2(e.g. Varin et al., 2011; Pauli et al., 2011; Ribatet et al., 2012; Hamelijnck et al., 2019),
3(e.g. Hooker and Vidyashankar, 2014; Ghosh and Basu, 2016; Futami et al., 2018; Jewson
et al., 2018; Ch√©rief-Abdellatif and Alquier, 2019), 4(Bissiri et al., 2016; Germain et al., 2016;
Guedj, 2019), 5(Kingma and Welling, 2013), 6(Higgins et al., 2017), 7(Loaiza-Ganem and
Cunningham, 2019) 8(e.g. Yang et al., 2017; Huang et al., 2018) 9(e.g. Ku≈õmierczyk et al.,
2019; Lacoste-Julien et al., 2011) 10(Ganchev et al. (2010), but only if the regularizer can
be written as Eq(Œ∏) [œÜ(Œ∏, x)] as in Zhu et al. (2014)), 11(e.g. Alquier et al., 2016) ‚Ä†For the
VAE entries in the table, we abuse notation by denoting the local latent variable for xi as Œ∏.
Further, Œ∂ denote the generative parameters.
4.4 Connecting the Rule of Three to existing methods
Beyond axiomatic foundations and the interpretable modularity result of the last section,
the form P(‚Ñì, D, Œ†) also sheds light on existing methods. As we will see, most existing
28

Generalized Variational Inference
Bayesian methods are special cases of the RoT. However, certain posterior beliefs derived as
approximations to q‚àó
B(Œ∏) are not. This section explains this distinction, how it is relevant and
why it provides a theoretical argument for the construction of posterior belief distributions
through Generalized Variational Inference (GVI).
As Table 1 shows, an impressive array of Bayesian methods are recovered by the RoT.
This includes a wide range of approxiate Bayesian methods and in particular standard VI.
In contrast, alternative approximation methods such as Laplace Approximations, Discrepancy
Variational Inference (DVI), Expectation Propagation (EP) or VI posteriors derived from
Generalized Evidence Lower Bounds do not satisfy these axiomatic desiderata.
4.4.1 Methods as special cases of the RoT
Unsurprisingly, as the RoT was constructed as a strict generalization of standard Bayesian
inference methods, most existing Bayesian methods are recovered as special cases. Further,
by virtue of incorporating the space Œ† into the objective, P(‚Ñì, D, Œ†) also recovers many
posterior beliefs that are constructed as approximations to the Bayesian posterior. Table 1
gives a non-exhaustive overview over some of belief distributions the RoT recovers as special
cases.
One of the key Ô¨Åndings of the table is that standard VI satisÔ¨Åes the axiomatic foundations
underlying the RoT. In other words, the RoT does not judge the belief distribution of eq. (2)
derived from Bayes rule to be preferable to certain classes of approximations by default. The
reason for this is simple: Unlike the traditional Bayesian paradigm, the RoT can explicitly
encode the availability of Ô¨Ånite or inÔ¨Ånite computational resources through the argument
Œ†. Hence, the moment the computational resources are scarce and posterior beliefs can
only be computed over a parameterized subset Q ‚äÇP(Œò), standard VI produces the best
computationally feasible posteriors relative to the objective in eq. 3. In this sense, the RoT
respects the optimality result of standard VI presented in Theorem 3.
4.4.2 Coherence and the RoT
Another insightful observation is that unlike previous generalizations such as the Generalized
Bayesian update in eq. (2), posterior belief distributions generated under the RoT are allowed
to break a property referred to as coherence or Bayesian additivity (e.g. Bissiri et al., 2016;
Fong and Holmes, 2019). In a nutshell, coherence says that posterior beliefs have to be
generated according to some function œà : R2 ‚ÜíR which for the prior œÄ(Œ∏) and loss terms
‚Ñì(Œ∏, x1), ‚Ñì(Œ∏, x2) behaves as
œà (‚Ñì(Œ∏, x2), œà (‚Ñì(Œ∏, x1), œÄ(Œ∏))) = œà (‚Ñì(Œ∏, x1), ‚Ñì(Œ∏, x2), œÄ(Œ∏)) .
EÔ¨Äectively, this property ends up enforcing a multiplicative update rule and exponential
additivity as in eq. (2). Recalling the construction of the standard Bayesian posterior in
Section 3.1, it should be clear that the desirability of coherence is a direct result of assuming
(P) and (C). To see that this intuition is accurate, note that treating the prior belief according
to (P) and assuming inÔ¨Ånite computational power via (C) is exactly equivalent to setting
D = KLD and Œ† = P(Œò). Next, solving eq. (3) with these speciÔ¨Åcations as in the proof of
Theorem 1, one obtains the coherent exponentially additive update rule in eq. (2). In other
words, generating posteriors that can violate coherence is identical to generating posteriors
29

Knoblauch, Jewson and Damoulas
that do not have to rely on (P) and (C). Since this is precisely what we set out to do in the
Ô¨Årst place, this is in fact a desirable property for posteriors generated by the RoT.
4.4.3 Links to information theory and PAC-Bayes
It will be worthwhile exploring the interesting links between the RoT and alternative methods
for the construction of belief distributions in the future. Here, we simply note in passing
that special cases of the form P(‚Ñì, D, Œ†) were arrived at with strong theoretical arguments
starting from at least two completely diÔ¨Äerent paradigmatic bases.
PAC-Bayes:
While PAC-Bayesian results often have intimate links with Bayesian inference
(see e.g. Germain et al., 2016; Gr√ºnwald and Van Ommen, 2017), their motivations and origins
are distinct (see e.g. Shawe-Taylor and Williamson, 1997; Guedj, 2019): Unlike Bayesian
inference, PAC-Bayesian results are not constructed based on (P) and (L). Rather, their aim
is the derivation of generalization bounds for belief distributions q(Œ∏) ‚ààP(Œò) deÔ¨Åned over
some hypothesis space (corresponding to the parameter space Œò) relative to a loss function
(corresponding to ‚Ñì). For example, under a prior belief œÄ(Œ∏), a loss ‚Ñìand a data generating
mechanism for x1:n satisfying appropriate regularity conditions and for any q(Œ∏) ‚ààP(Œò)
as well as for any Ô¨Åxed value of Œµ > 0, a rescaled version of McAllester‚Äôs seminal bound
(McAllester, 1999a,b) says that with probability at least 1 ‚àíŒµ,
Eq(Œ∏)
"
n ¬∑ Ex1:n
"
1
n
n
X
i=1
‚Ñì(Œ∏, xi)
##
‚â§Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
s
KLD(q, œÄ) + log 2‚àön
Œµ
2n‚àí0.5
.
Minimizing the right hand side of this bound with respect to q(Œ∏) over some set Œ† ‚äÜP(Œò)
immediately recovers a special case for the RoT given by P(‚Ñì, DMcAllester, Œ†). Here, DMcAllester
is just the KLD term of the original bound with a subtracted constant:
DMcAllester(q‚à•œÄ) =
s
KLD(q, œÄ) + log 2‚àön
Œµ
2n‚àí0.5
‚àí
s
log 2‚àön
Œµ
2n‚àí0.5
This is done to ensure that DMcAllester(q‚à•œÄ) = 0 if and only if œÄ(Œ∏) = q(Œ∏) (almost everywhere).
Note that it does not eÔ¨Äect the minimizer of the right hand side. A similar logic can be applied
to virtually all PAC-Bayesian bounds, including bounds based on alternative divergences
(B√©gin et al., 2016; Alquier and Guedj, 2018).
This suggests that there are insightful
connections between PAC-Bayes and the RoT. Further, GVI‚Äîthe tractable case when Œ† = Q
is a parameterized subset of P(Œò)‚Äîis a promising way forward to scale and operationalize
PAC-Bayesian learning. In fact, Letarte et al. (2019) constitutes the Ô¨Årst step in this direction
and we will explore these connections in future work.
Information Theory:
Another strong link exists between the RoT and results derived
from Information Theory and speciÔ¨Åcally the predictive Information Bottleneck (see Tishby
et al., 2000; Bialek et al., 2001; Alemi, 2019). The name arises from the fact that this
problem seeks to compress all information of the (possibly inÔ¨Ånitely many) observations in
xP into the Ô¨Ånite-dimensional quantity Œ∏ which maximizes the amount of information about
(possibly inÔ¨Ånitely many) future observations denoted as xF . More concisely, the predictive
30

Generalized Variational Inference
Information Bottleneck is given by the inÔ¨Ånite-dimensional optimization problem
max
p(Œ∏|xP ) I(Œ∏; xF )
s.t.
I(Œ∏; xP ) = I0.
Here, I denotes predictive information of some kind‚Äîtypically mutual information‚Äîso that
I(Œ∏; xF ) quantiÔ¨Åes the amount of information the quantity Œ∏ can tell us about the future
while I(Œ∏; xP ) is a measure of its complexity. As shown in Alemi (2019), a straightforward
application of Lagrangian optimization together with a natural variational bound readily
transforms this problem into an optimization problem of the form P(‚Ñì, D, Œ†).
5. Generalized Variational Inference (GVI)
The next section Ô¨Ånally introduces a version of the RoT that is feasible for real-world inference
and that we call Generalized Variational Inference (GVI). As the name suggests, GVI is any
posterior distribution generated from P(‚Ñì, D, Q), where Q is a parameterized subset of P(Œò)
as given in eq. (5). The remainder proceeds as follows:
Section 5.1 motivates why GVI procedures generate conceptually appealing and
coherent posterior belief distributions.
Section 5.2 focuses on the main applications of GVI in the current paper. In particular,
we explain how GVI can be used for inferences that (i) are robust to model misspeci-
Ô¨Åcation, (ii) are robust to prior misspeciÔ¨Åcation and (iii) produce more appropriate
marginal distributions.
Section 5.3 discusses two strong theoretical guarantees for GVI: Frequentist consistency
and an interpretation as an approximate lower bound on the evidence of a (generalized)
Bayesian posterior.
Section 5.4 focuses on strategies for inference. First, we derive a closed form objective
for a particular set of GVI posteriors that are robust to model misspeciÔ¨Åcation. Second,
we introduce black box inference for GVI and prove more results on closed form
expressions.
5.1 Advantages of GVI over alternative VI methods
As Table 1 shows, posteriors derived via P(‚Ñì, D, Œ†) recover many Bayesian methods motivated
as approximations to the Bayesian posterior.
Crucially however, a large collection of
approximation strategies for the standard Bayesian posterior are not special cases of the
RoT. Unsurprisingly, these are the exact same methods that are suboptimal relative to the
objective deÔ¨Åning Bayesian inference (see Corollary 5). They encompass a variety of strategies
we elaborated on in Section 2.3.1 and 2.3.2. The most prominent of these include VI based
on generalized ELBO formulations, Laplace approximations, Expectation Propagation (EP)
as well as Discrepancy Variational Inference (DVI).
We stress that we do not claim that these alternative posterior approximations are
always performing worse than VI in practice‚Äîthis is not what Corollary 5 says. What
we do claim and prove is that such alternative approximations do not provide the optimal
31

Knoblauch, Jewson and Damoulas
posterior relative to eq. (3)‚Äîan equation that is isomorphic with the Bayesian posterior.
This is an important distinction because it means that the empirical success of alternative
approximations has a theoretically appealing interpretation: As explained in some detail
in Section 2.4, if alternative approximations q‚àó
A(Œ∏) to the Bayesian posterior q‚àó
B(Œ∏) perform
better than the standard variational approximation q‚àó
VI(Œ∏), the objective underlying q‚àó
A(Œ∏)
must be targeting a more appropriate posterior belief. Thus, undesirable inference outcomes
with standard VI are synonymous with an inappropriately designed objective. Following
this line of reasoning, the most transparent way to improve poor performance of standard
VI posteriors is a direct adjustment of the objective that generated them. Conveniently,
the axiomatic development of Section 4 provides a solution of precisely this kind: The RoT,
which deÔ¨Ånes a versatile and modular family of objectives useful for interpretably adapting
the standard VI objective, a technique we call Generalized Variational Inference (GVI).
DeÔ¨Ånition 20 (Generalized Variational Inference (GVI)) Solving any RoT of form
P(‚Ñì, D, Q) for Q = {q(Œ∏|Œ∫) : Œ∫ ‚ààK} a parameterized subset of P(Œò) (also called a
variational family) constitutes a procedure we call Generalized Variational Inference ( GVI).
Remark 21 Notice that GVI posteriors satisfy Axioms I, II and III by deÔ¨Ånition. It
immediately follows that they also inherit the modularity result in Theorem 18. By the same
token, approximations q‚àó
A(Œ∏) to the Bayesian posterior that cannot be rewritten as a GVI
procedure will violate the Axioms set out in Section 4.1. Clearly, this need not be a problem
if Q is a suÔ¨Éciently rich set of approximating distributions: In this case, the approximation
q‚àó
A(Œ∏) ‚âàq‚àó
B(Œ∏) is very reliable. As q‚àó
B(Œ∏) itself satisÔ¨Åes the Axioms in Section 4.1, q‚àó
A(Œ∏) will
not violate the Axioms in a practically meaningful way.
In practice however, Q is typically hopelessly restrictive. Consequently, it does not contain
any qualitatively good approximations to q‚àó
B(Œ∏). In this case, violation of the Axioms is often
a serious problem. Example 4 and Figure 6 illustrate this on a Bayesian Mixture Model
( BMM). We also revisit this issue with our experiments in Section 6.1, where we observe its
real world consequence on Bayesian Neural Networks.
Example 4 (Label switching and multi-modality) A recurrent theme in the research
on variational approximations q‚àó
A(Œ∏) to q‚àó
B(Œ∏) is the observation that standard VI with a mean
Ô¨Åeld normal family will center closely around the maximum likelihood estimate (e.g. Turner
and Sahani, 2011). This phenomenon is often referred to as the zero-forcing behaviour of
the KLD (Minka, 2005). Its eÔ¨Äect are undesirably overconÔ¨Ådent variational posteriors q‚àó
VI(Œ∏).
Moreover, this problem is especially pronounced when the approximated posterior beliefs q‚àó
B(Œ∏)
are multi-modal. Popular approaches to address this issue are Expectation Propagation ( EP)
(Minka, 2001; Opper and Winther, 2000) and Divergence Variational Inference ( DVI) methods
as introduced in Section 2.3.2 (e.g. Hern√°ndez-Lobato et al., 2016; Li and Turner, 2016; Dieng
et al., 2017). All of these approaches seek to (locally or globally) minimize an alternative zero-
avoiding divergence D between q‚àó
A(Œ∏) and q‚àó
B(Œ∏). Unfortunately, none of these approaches
satisfy the Axioms set out in 4.1. An immediate consequence is that the modularity encoded
by Theorem 18 does not apply to EP or DVI. This may seem inconsequential, but it really is
not: Unlike with GVI, changing the divergence in the DVI-sense no longer aÔ¨Äects
uncertainty quantiÔ¨Åcation alone. In other words, we may accidentally interfere with the
loss and warp the way the goodness of a parameter value Œ∏ is assessed in undesirable ways.
32

Generalized Variational Inference
Using Bayesian mixture models ( BMMs), we show that problems associated with violating
the Axioms or Section 4.1 indeed occur in practice. BMMs produce multi-modal posteriors
because the likelihood function is invariant to switching parameter labels. In other words,
BMMs have multiple parameter values that constitute equally good Ô¨Åts to the data. With this
in mind, we simulate n = 100 observations from the model
p (x|Œ∏ = (¬µ1, ¬µ2)) = 0.5 ¬∑ N(x|¬µ1, 0.652) + 0.5 ¬∑ N(x|¬µ2, 0.652)
for two diÔ¨Äerent settings of Œ∏ = (¬µ1, ¬µ2). For inference, we use the well-speciÔ¨Åed prior
belief ¬µj ‚àºN(0, 22), j = 1, 2. Using the correctly speciÔ¨Åed likelihood function ‚Ñì(Œ∏, xi) =
‚àílog p (xi|Œ∏ = (¬µ1, ¬µ2)), we then compare the standard Bayesian posterior q‚àó
B(Œ∏), the standard
VI posterior, the DVI posterior based on R√©nyi‚Äôs Œ±-divergence ( D(Œ±)
AR) (Li and Turner, 2016)
and the GVI posterior using D = D(Œ±)
AR as uncertainty quantiÔ¨Åer. For all posteriors produced
by variational methods, we use the mean Ô¨Åeld normal family for Q.
Figure 6 shows the results. Clearly, q‚àó
B(Œ∏) is multi-modal because there are two equally
good parameter values describing the data by virtue of the fact that p (x|Œ∏ = (¬µ1, ¬µ2)) =
p (x|Œ∏ = (¬µ2, ¬µ1)). Because we enforce uni-modality through Q, the variational posteriors
have a clear interpretation: Firstly, their means have the interpretation of (one of the two)
best parameter values of Œ∏ = (¬µ1, ¬µ2). Secondly, their variances quantify the uncertainty
about this best value. For both settings of the true value for Œ∏, DVI produces a posterior that
reÔ¨Çects a highly undesirable belief: In particular, the mode of the DVI posterior is located
at a (locally) worst value of Œ∏. Unsurprisingly and as the bottom right plot shows, this has
adverse consequences for predictive performance. This behaviour is entirely attributable to
the fact that unlike GVI posteriors, DVI posteriors violate the axiomatic foundation set out
in Section 4.1 and thus do not inherit the modularity result of Theorem 18. In other words:
In the GVI framework, changing the KLD to another divergence only changes uncertainty
quantiÔ¨Åcation and does not aÔ¨Äect the way the best parameter is found. In sharp contrast,
the DVI framework comes with no such guarantee. Accordingly, posteriors produced with
DVI may conÔ¨Çate uncertainty quantiÔ¨Åcation and the way the best parameter is found. In
this context, Figure 6 serves as a morality tale: The modularity of standard VI and GVI
ensures transparency. In contrast, DVI methods have no such guarantees and can easily end
up conÔ¨Çating the search for the best parameter with uncertainty quantiÔ¨Åcation8.
5.2 GVI use cases: Robust inference & better marginals
Summarizing the Ô¨Åndings of the last paragraphs, saying that the standard VI posterior
produces undesirable inferences or inappropriate uncertainty quantiÔ¨Åcation amounts to
saying that the objective in eq. (7) is inappropriate for the inference task at hand. By virtue
of the modularity result in Theorem 18, it is also clear that GVI is uniquely positioned to
deÔ¨Åne alternative objectives to address this in a direct and targeted fashion. Inspired by this,
we next focus on three situations that cause problems for standard VI, but are easily solved
by GVI: Prior misspeciÔ¨Åcaton (EP), model misspeciÔ¨Åcation (EL), and marginal variances.
8. Clearly, this problem is not guaranteed to occur: As Remark 21 explains, the conÔ¨Çation of loss and
uncertainty quantiÔ¨Åcation will not be a problem so long as Q is suÔ¨Éciently rich to produce approximations
that endow the statement q‚àó
A(Œ∏) ‚âàq‚àó
B(Œ∏) with meaning.
33

Knoblauch, Jewson and Damoulas
-0.5
0.0
0.5
1.0
0.0
1.0
2.0
3.0
¬µ1
Density
Exact Posterior
VI
F-VI, F = D(0.5)
AR
GVI, Œ± = 0.25
MLE
-0.5
0.0
0.5
1.0
0.0
1.0
2.0
3.0
¬µ2
Density
-1
0
1
2
3
0.0
1.0
2.0
3.0
¬µ1
Density
-2
-1
0
1
2
3
4
0.0
0.1
0.2
0.3
0.4
0.5
x
Density
Figure 6: Best viewed in color. Depicted are the outcomes of inference in a BMM model,
namely the (multimodal) exact Bayesian inference posterior, standard VI, DVI with D(Œ±)
AR
(Li and Turner, 2016) and GVI with D(Œ±)
AR as uncertainty quantiÔ¨Åer. Top: Posterior marginals
for ¬µ1 = 0, ¬µ2 = 0.75. The Maximum A Posteriori estimate of the DVI posterior yields a
locally worst value for Œ∏ relative to the exact Bayesian posterior. In contrast, standard
VI and GVI respect the loss: They produce a posterior belief centered around one (of the
two) values of Œ∏ minimizing the loss. Bottom left: Posterior marginal for ¬µ1 = 0, ¬µ2 = 2.
The eÔ¨Äects of the top row become even stronger as the modes move further apart. Bottom
right: Posterior predictive for ¬µ1 = 0, ¬µ2 = 2 against the histogram depicting the actual
data. VI, GVI and exact Bayesian inference perform well and almost identically. DVI
performs poorly and captures none of the two mixture components of the BMM.
5.2.1 GVI and prior misspecification
Section 3.3 outlines the problems associated with violating (P): If the prior does not even
approximately reÔ¨Çect the best available judgement, inference outcomes are adversely aÔ¨Äected.
This phenomenon is particularly pronounced whenever the prior is speciÔ¨Åed according to
some default setting. For example, in the case of Bayesian Neural Networks (BNNs), a
typical choice of prior is a standard normal distribution that factorizes over the network
weights. While this may seem harmless or even uninformative, a supposedly uninformative
prior speciÔ¨Åcation of this kind actually encompasses a large degree of information, e.g.
34

Generalized Variational Inference
(U) The prior belief is unimodal. In other words, we believe that there exists a uniquely
most likely parameterization of the network before observing any data.
(I) The prior belief is that all network weights of a BNN are uncorrelated. In fact, we even
believe that all network weights of a BNN are both pairwise and mutually independent.9
The above implications are in direct and strong contradiction to our best possible judgements
about BNNs and thus violate (P):
(EU) Neural Networks are well-understood to have multiple parameter settings that are
equally good (e.g. Choromanska et al., 2015). The unimodality assumption outlined in
(U) is thus clearly not a reÔ¨Çection of the best judgement available: A prior belief in
accordance with (P) would encode multimodality.
(EI) By construction, Neural Networks encode a signiÔ¨Åcant degree of dependence in their
parameters: The best values for parameters in the l-th layer will strongly depend on
the best values for parameters in the (l ‚àí1)-th layer (and vice versa). Hence, assuming
uncorrelatedness (much less so independence!) directly contradicts our best judgement.
From this, it is obvious that a fully factorized normal distribution is hardly an appropriate
default prior for BNNs in the sense of (P) in Section 3.1. At the same time, it is often
prohibitive or computationally infeasible to construct alternative prior beliefs that reÔ¨Çect
our best judgements more accurately. In other words, we are stuck with a sub-optimal prior.
Under the standard Bayesian paradigm, this is not an acceptable position. In contrast, the
new paradigm outlined in Section 4.1 does not require the prior to be Ô¨Çawless. Using GVI,
we can thus use our very imperfect prior to design more appropriate posterior beliefs: Simply
adapt the argument D which regularizes the posterior belief against the prior. In particular,
we want to adapt D such that the resulting posteriors satisfy two criteria: Firstly, they
should be more robust to priors which strongly contradict the observed data. Secondly, they
should still provide reliable uncertainty quantiÔ¨Åcation.
As the toy example in Figure 3 shows, this can be achieved by picking a robust replacement
Drobust for the KLD. A recent overview of robust divergences was provided by Cichocki and
Amari (2010). Such divergences are constructed with a hyperparameter that regulates
the degree of robustness and which recovers the KLD as a limiting case. In the current
paper, all robust divergences are parameterized such that one recovers the KLD as the
hyperparameter approaches unity. For example, R√©nyi‚Äôs Œ±-divergence‚Äîhenceforth denoted
D(Œ±)
AR and introduced by R√©nyi (1961)‚Äîis such a robust alternative to the KLD. Using the
parameterization in Cichocki and Amari (2010), it is given by
D(Œ±)
AR(q‚à•œÄ) =
1
Œ±(Œ± ‚àí1) log
 
Eq(Œ∏)
"œÄ(Œ∏)
q(Œ∏)
1‚àíŒ±#!
.
(12)
Originally, R√©nyi‚Äôs Œ±-divergence was motivated as the geometric mean information to dis-
criminate between the two hypotheses Œ∏ ‚àºœÄ(Œ∏) and Œ∏ ‚àºq(Œ∏) of order Œ±, for some Œ± ‚àà(0, 1).
Similarly, the original motivations for the KLD was its interpretation as the arithmetic mean
information to discriminate between Œ∏ ‚àºœÄ(Œ∏) and Œ∏ ‚àºq(Œ∏) (Kullback and Leibler, 1951).
9. For joint normal distributions, variables are uncorrelated if and only if they are independent.
35

Knoblauch, Jewson and Damoulas
Since geometric means are more robust measures of central tendency than arithmetic
means, the D(Œ±)
AR will generally be a more robust measure of discrepancy between œÄ(Œ∏)
and q(Œ∏) so long as Œ± ‚àà(0, 1). Clearly, the degree of this robustness will depend on Œ±.
Generally, picking lower values of Œ± ‚àà(0, 1) will produce more prior-robust measures of
discrepancy. Indeed, D(Œ±)
AR(q‚à•œÄ) recovers KLD(q‚à•œÄ) as Œ± ‚Üí1 and KLD(œÄ‚à•q) as Œ± ‚Üí0. A
host of other divergences behave similarly, including Œ±-, Œ≤- and Œ≥-divergences as well as
their generalizations (Cichocki and Amari, 2010). We plot their magnitude for two Normal
Inverse Gamma distributions with diÔ¨Äerent divergence hyperparameter values in Figure
7. The plot illustrates that (i) hyperparameter values below (above) unity impose larger
(smaller) penalties than the KLD and that (ii) all robust divergences recover the KLD as
their hyperparameters approach one. Importantly, a larger regularization term does not
necessarily imply that a misspeciÔ¨Åed prior dominates inference: In fact, Figure 3 shows that
the contrary holds using the example of D(Œ±)
AR with Œ± = 0.5. As Appendix B demonstrates
in great detail, R√©nyi‚Äôs Œ±-divergence is representative of the behaviour displayed by various
robust divergences. To keep things simple, we thus focus on D(Œ±)
AR in the remainder of the
paper.
5.2.2 GVI and model misspecification
Section 3.4 explains how and why (EL) can severely impede the usefulness of the Bayesian
posterior: Assuming that the likelihood is an accurate reÔ¨Çection of the data generating
mechanism makes inferences susceptible to outliers, heterogeneity and other adversarial
aspects of the data. Further recalling the isomorphism between eq. (3) and eq. (8), it also is
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
hyperparameter value
0
10
20
30
40
50
magnitude of D(q| )
D =
-divergence (DB)
D = -divergence (DG)
D = Renyi's -divergence (D( )
AR)
KLD
Figure 7: Depicted is the magnitude D(q‚à•œÄ) for diÔ¨Äerent robust divergences D and the
KLD for two Normal Inverse Gamma distributions given by q(Œ∏) = NI‚àí1(Œ∏; ¬µq, Vq, aq, bq)
and œÄ(Œ∏) = NI‚àí1(Œ∏; ¬µœÄ, VœÄ, aœÄ, bœÄ) with ¬µœÄ = (0, 0)T , VœÄ = 25 ¬∑ I2, aœÄ = 500, bœÄ = 500 and
¬µq = (2.5, 2.5)T , Vq = 0.3 ¬∑ I2, aq = 512, bq = 543.
36

Generalized Variational Inference
clear that treating the likelihood model as (approximately) correct is synonymous to using
the log score ‚Ñì(Œ∏, xi) = ‚àílog p(xi|Œ∏) to assess how well the model Ô¨Åts the data.
Based on this observation, a promising line of work has sought to produce more robust
scoring rules for probability models (see e.g. Dawid et al., 2016, and references therein).
While there are other ways to derive proper scoring rules, the conceptually most appealing
constructions are arguably based on statistical divergences.
The intuition behind this
approach consists in two observations: First, if n is large enough, one can invoke the law of
large numbers and rewrite the parameter value bŒ∏n minimizing the log score as
bŒ∏n =
min
Œ∏‚ààŒò
(
1
n
n
X
i=1
‚àílog p(xi|Œ∏)
)
n‚Üí‚àû
‚âà
min
Œ∏‚ààŒò {EPx [‚àílog p(x|Œ∏)]}
= min
Œ∏‚ààŒò

EPx

‚àílog
 p(x|Œ∏)
dPx(x)

=
min
Œ∏‚ààŒò
KLD (dPx‚à•p(x|Œ∏)) .
In other words, the log score targets the parameter value Œ∏ which is best in the KLD-sense.
Second, as it is well-known that the KLD is not robust (e.g. Cichocki and Amari, 2010), it is
often advantageous to Ô¨Ånd a robust alternative divergence Drobust to reverse-engineer the
above derivation and arrive at some robust scoring rule Lrobust(Œ∏, xi).
The Ô¨Årst developments in this direction started with the family of Œ≤-divergences by
Basu et al. (1998); Mihoko and Eguchi (2002), but the idea has since been extended to
various other discrepancies. This includes the Fisher divergence (Hyv√§rinen, 2005), the family
of Œ≥-divergences (e.g. Fujisawa and Eguchi, 2008; Hung et al., 2018) as well as Minimum
Stein Discrepancies (Barp et al., 2019). The Generalized Bayesian posterior associated with
this procedure then arises from replacing the negative log likelihood in eqs. (2) and (3)
by Lrobust(Œ∏, xi). A growing literature has focused on using the scoring rules derived from
these divergences to perform Generalized Bayesian inference of precisely this sort (see e.g.
Hooker and Vidyashankar, 2014; Ghosh and Basu, 2016; Ch√©rief-Abdellatif and Alquier,
2019). Jewson et al. (2018) provides a recent survey of this Ô¨Åeld and connects it to the
idea of Bissiri et al. (2016). As Figures 4 and 5 demonstrate for the scoring rule LŒ≤(Œ∏, xi)
derived from the Œ≤-divergence, this produces reliably robust posterior inferences. We state
the analytic form of LŒ≤(Œ∏, xi) and another robust scoring rule LŒ≥(Œ∏, xi) derived from the
Œ≥-divergence (see Hung et al., 2018) in Section 6.2, where we show how they can be used to
robustify Deep Gaussian Processes.
5.2.3 GVI and marginal variances
The standard VI objective can be inappropriate even in situations where assuming appropri-
ately speciÔ¨Åed priors (P) and likelihood functions (L) underlying the traditional Bayesian
paradigm are a useful working assumption. For instance, the uncertainty quantiÔ¨Åcation of
standard VI is often inappropriate when Q is a mean Ô¨Åeld variational family factorizing
dimension-wide over Œ∏ and the individual entries of Œ∏ exhibit strong dependence (e.g. Turner
and Sahani, 2011). Oftentimes, this phenomenon is referred to as mode seeking behaviour
(e.g. Minka, 2005). The name itself also reveals that this problem is intimately linked to
unimodal‚Äîand thus in practice mean Ô¨Åeld normal‚Äîvariational families Q. Again, the
modularity result of Theorem 18 can be helpful: Provided that one has no Ô¨Çexibility about
the choice of Q and has Ô¨Åxed the prior œÄ(Œ∏), one can adapt the GVI posterior‚Äôs uncertainty
37

Knoblauch, Jewson and Damoulas
0
1
2
3
4
5
1
0.00
0.25
0.50
0.75
1.00
1.25
1.50
Density
D = Renyi's -divergence (D( )
AR)
Exact posterior
= 1.25
Standard VI
= 0.5
= 0.025
MLE
0
1
2
3
4
5
1
D = -divergence (DG)
Exact posterior
= 1.5
Standard VI
= 0.75
= 0.15
MLE
0
1
2
3
4
5
1
D =
-divergence (DB)
Exact posterior
= 1.5
Standard VI
= 0.75
= 0.5
MLE
Figure 8: Best viewed in color. Marginal VI compared to diÔ¨Äerent GVI posteriors for the
coeÔ¨Écient Œ∏1 of data simulated from a Bayesian linear model (see Appendix B for details).
For all posteriors, the loss ‚Ñìis the correctly speciÔ¨Åed negative log likelihood of the true data
generating mechanism. Further, for all variational posteriors the belief is constrained to lie
inside a mean Ô¨Åeld normal family Q. Due to high correlation between the coeÔ¨Écients for the
exact posterior, standard VI produces undesirably over-concentrated belief distributions.
In contrast, appropriately choosing the hyperparameters of alternative robust divergences
D Ã∏= KLD provides more desirable uncertainty quantiÔ¨Åcation.
quantiÔ¨Åcation properties by changing D = KLD to an alternative divergence. Figure 8
illustrates this Ô¨Çexibility of GVI by comparing the uncertainty quantiÔ¨Åcation properties of
three diÔ¨Äerent robust divergences to standard VI.
5.3 Theoretical properties of GVI
Clearly, the principal appeal of GVI lies in its modularity and the associated subjective choices
of ‚Ñì, D and Q. Because of this increased need for the statistical modeller to provide sensible
problem speciÔ¨Åcation, one may worry about producing inferences that are non-sensical. The
following section studies two theoretical Ô¨Åndings that impose meaningful limits to the damage
a badly speciÔ¨Åed GVI posterior can do: Firstly, we point to novel results showing that GVI
posteriors are consistent in the frequentist sense: As more and more data are observed,
the GVI posterior will collapse to the population optimum regardless of D. Secondly, we
show that GVI posteriors with uncertainty quantiÔ¨Åers based on robust divergences can be
interpreted as approximations to Bayesian posteriors with a power likelihood.
5.3.1 Frequentist consistency
Knoblauch (2019a) shows that GVI posteriors are consistent in the Frequentist sense. In
other words, they collapse to a point mass at the population-optimal value as the number of
observations tends to inÔ¨Ånity. This holds under a wide range of extremely mild regularity
conditions on the arguments ‚Ñì, D and Q. Here, we state a simple version of the result for
independent data with the mean Ô¨Åeld normal variational family.
38

Generalized Variational Inference
KLD
D( )
AR, 
= 0.5
JD
Reverse KLD
FD
10
8
6
4
2
0
2
qGVI(
true
1
1)
n=10
KLD
D( )
AR, 
= 0.5
JD
Reverse KLD
FD
n=25
KLD
D( )
AR, 
= 0.5
JD
Reverse KLD
FD
n=50
KLD
D( )
AR, 
= 0.5
JD
Reverse KLD
FD
n=500
KLD
D( )
AR, 
= 0.5
JD
Reverse KLD
FD
n=2500
KLD
D( )
AR, 
= 0.5
JD
Reverse KLD
FD
n=25000
 
 
 
 
 
 
 
Figure 9: Best viewed in color. Marginal VI and diÔ¨Äerent GVI posteriors for the Ô¨Årst
coeÔ¨Écient of a simulated 20-dimensional Bayesian Linear Model based on n observations.
The loss ‚Ñìis the correctly speciÔ¨Åed negative log likelihood of the true data generating
mechanism and the uncertainty quantiÔ¨Åer is varied along the x-axis. Depicted uncertainty
quantiÔ¨Åers are the forward and reverse KLD, R√©nyi‚Äôs Œ±-divergence (D(Œ±)
AR), JeÔ¨Ärey‚Äôs Divergence
(JD) as well as the Fisher Divergence (FD). All posteriors are members of the mean Ô¨Åeld
normal family Q. Because all inferred posterior beliefs are normals, dots are used to mark out
the posterior mean and whiskers to denote the posterior standard deviation. All posteriors
are re-centered around the true value of the coeÔ¨Écient, so that the y-axis shows how far the
posterior belief is from the truth.
Theorem 22 (Frequentist consistency of GVI) Suppose that Assumption 1 in Knoblauch
(2019a) holds. Choosing Q to be the mean Ô¨Åeld normal family and letting D be lower-semi-
continuous in its Ô¨Årst argument, suppose that D(q‚à•œÄ) < ‚àûfor all q ‚ààQ. Further, let Px be
the true probability measure of some random variable x and suppose that the observations
x1:n are independent and identically distributed draws from x. If the prior is not inÔ¨Ånitely
bad for the population of x (which is to say that EœÄ [EPx [‚Ñì(Œ∏, x)]] < ‚àû), then
q‚àó
GVI,n(Œ∏)
D
‚àí‚ÜíŒ¥Œ∏‚àó(Œ∏),
where q‚àó
GVI,n(Œ∏) is the GVI posterior corresponding to the problem P(‚Ñì, D, Q) based on n
observations and Œ∏‚àó= arg minŒ∏ [EPx [‚Ñì(Œ∏, x)]] is the population-optimal parameter value.
Remark 23 This Theorem is a straightforward invocation of Corollary 1 in Knoblauch
(2019a). Assumption 1 guarantees a number of conditions that are required to make GVI a
well-deÔ¨Åned optimization problem. For example, it ensures that the sum of the losses has
minimizers for any Ô¨Ånite n and in the large data limit and that the loss expected under Px is
Ô¨Ånite.
This Ô¨Ånding is illustrated in Figure 9, which is taken from Knoblauch (2019a). The plot
shows that as the theory suggests, the posteriors collapse to a point mass under mild
regularity conditions on the uncertainty quanitÔ¨Åer D. Unsurprisingly, speed and nature of
the convergence depends on the choice of D.
39

Knoblauch, Jewson and Damoulas
5.3.2 GVI as a posterior approximation
Although the axiomatic development in Section 4.1 shows that GVI produces a posterior
belief distribution that is valid in its own right, one can also interpret certain GVI posteriors
as approximations to (generalized) Bayesian posteriors as in eq. (2). In particular, we
show that for robust divergences D(œÅ)
robust parameterized by some hyperparameter œÅ so that
limœÅ‚Üí1 D(œÅ)
robust = KLD, the GVI objective constitutes a lower bound on the evidence of a
(generalized) Bayesian posterior. Results of this form can be shown to hold for R√©nyi‚Äôs
Œ±-divergence (D(Œ±)
AR), the Œ≥-divergence (D(Œ≥)
G ) as well as the Œ≤-divergence (D(Œ≤)
B ). As they are
structurally similar, we only state the bound corresponding to D = D(Œ±)
AR and defer the results
for D(Œ≥)
G and D(Œ≤)
B
as well as all proofs to Appendix D.
Theorem 24 (GVI as approximate Evidence Lower bound with D = D(Œ±)
AR) The ob-
jective of a GVI posterior based on P(‚Ñì, D(Œ±)
AR, Q) has an interpretation as lower bound on the
c(Œ±)-scaled (generalized) evidence lower bound of P(w(Œ±) ¬∑ ‚Ñì, KLD, P(Œò)):
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(Œ±)
AR(q||œÄ) ‚â•‚àíc(Œ±) ¬∑ ELBOw(Œ±)‚Ñì(q) + S1(Œ±, q, œÄ)
(13)
where ELBOw(Œ±)‚Ñìdenotes the Evidence Lower Bound associated with standard VI relative to
the generalized Bayesian posterior given by
qw(Œ±)‚Ñì
B
(Œ∏) ‚àùœÄ(Œ∏) exp
 
‚àíw(Œ±)
n
X
i=1
‚Ñì(Œ∏, xi)
!
,
where c(Œ±) = min{1, Œ±‚àí1}, w(Œ±) = max{1, Œ±} and S1(Œ±, q, œÄ) is an interpretable slack term.
Remark 25 The take-away from the bound in eq. (13) is that the slack term S1(Œ±, q, œÄ)
introduces the main diÔ¨Äerence between P(‚Ñì, D(Œ±)
AR, Q) and P(w(Œ±) ¬∑ ‚Ñì, KLD, Q). As Appendix
D shows, is possible but rather tedious to make analytically more concise statements about
S1(Œ±, q, œÄ). SpeciÔ¨Åcally, the main function of the slack term is the introduction of more
conservative uncertainty quantiÔ¨Åcation. Studying this empirically reveals that for R√©nyi‚Äôs
Œ±-divergence, this has the eÔ¨Äect of enabling prior robust inference. This point is demonstrated
in Figure 3 and elaborated upon in Section 5.2.1, but is perhaps best summarized in Figure 10:
Since c(Œ±) = 1 for Œ± ‚àà(0, 1), the left hand side of the plot corresponds to P(‚Ñì, D(Œ±)
AR, Q) and the
right-hand side to P(w(Œ±) ¬∑ ‚Ñì, KLD, Q). The plot shows the diÔ¨Äerence between minimizing the
GVI and the ELBO objectives in eq. (13): relative to the ELBO objective P(w(Œ±) ¬∑ ‚Ñì, KLD, Q),
the belief distributions P(‚Ñì, D(Œ±)
AR, Q) based on the D(Œ±)
AR are much less sensitive to badly speciÔ¨Åed
priors. In fact, the GVI posteriors implicitly determine if it is worth taking the prior into
account: On the one hand, the uncertainty quantiÔ¨Åcation with D = D(Œ±)
AR is less aÔ¨Äected
than standard VI for badly speciÔ¨Åed priors. On the other hand, GVI posteriors with D = D(Œ±)
AR
are still more conservative than standard VI for well speciÔ¨Åed priors.
40

Generalized Variational Inference
1
0
1
2
3
4
5
1
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Density
Standard VI with  D = KLD
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
D = Renyi's -divergence (D( )
AR) 
= 0.75
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
D = Renyi's -divergence (D( )
AR) 
= 0.5
= 3.0
= -5.0
= -20.0
= -50.0
MLE
Figure 10: Best viewed in color. Marginal VI compared to diÔ¨Äerent GVI posteriors for the
coeÔ¨Écient Œ∏1 of data simulated from a d-dimensional Bayesian linear model with diÔ¨Äerent
priors (see Appendix B for details). The prior for the coeÔ¨Écients is a Normal Inverse Gamma
distribution given by ¬µ ‚àºNI‚àí1(¬µœÄ ¬∑ 1d, vœÄ ¬∑ Id, aœÄ, bœÄ) with vœÄ = 4 ¬∑ Id, aœÄ = 3, bœÄ = 5
and various values for ¬µœÄ. For all posteriors, the loss ‚Ñìis the correctly speciÔ¨Åed negative
log likelihood of the true data generating mechanism. Further, all variational posteriors
are constrained to lie inside a mean Ô¨Åeld normal family Q. Notice that the standard VI
posterior corresponds to the ELBO component on the right hand side of the bound in eq.
(13). In contrast, the GVI posteriors are obtained by maximizing the left hand side of the
same bound.
5.4 Inference with Generalized Variational Inference (GVI)
This section outlines two powerful inference strategies for GVI: Quasi-conjugate and fully
black box inference. Built on earlier Ô¨Åndings in Knoblauch et al. (2018), we show that a
class of GVI posteriors based on robust likelihood scoring rules admits closed form objectives.
Because this closed form objective emerges when the non-robust counterpart of the likelihood
is conjugate to the prior, we call the resulting inference procedure quasi-conjugate. For more
complicated models, closed form objectives will not be available. To address this, we also
introduce a black box inference procedure for arbitrary choices of ‚Ñìand D.
5.4.1 Quasi-conjugate inference
This paper so far has given little attention to specifying the constraining family for a GVI
problem. One interesting interdependence between loss function and variational family was
studied in Knoblauch et al. (2018): When applying the robust scoring rule LŒ≤ (Basu et al.,
1998) derived from the Œ≤-divergence (D(Œ≤)
B ) to a likelihood associated with a conjgate prior
œÄ(Œ∏|Œ∫0), there is a considerable advantage in taking Q to be the family of the conjugate prior.
Since LŒ≤(Œ∏, xi) ‚Üí‚àílog p(xi|Œ∏) as Œ≤ ‚Üí1, the (generalized) Bayesian posterior
qŒ≤
B(Œ∏) ‚àùœÄ(Œ∏)
n
Y
i=1
exp
n
‚àíLŒ≤(Œ∏, xi)
o
41

Knoblauch, Jewson and Damoulas
is contained in Q as Œ≤ ‚Üí1. The results in Knoblauch et al. (2018) and intuition thus
suggest that so long as |Œ≤ ‚àí1| < Œµ for some suÔ¨Éciently small value Œµ > 0 and D = KLD,
constraining the posterior to be in Q still produces excellent approximations to qŒ≤
B(Œ∏). Beyond
the approximation quality, choosing the quasi-conjugate variational family oÔ¨Äers tangible
computational advantages: As Theorem 2 in Knoblauch et al. (2018) shows, under these
circumstances the objective deÔ¨Åning P(LŒ≤, KLD, Q) is available in closed form. Consequently,
no sampling or approximation is required and the optimum is usually found within a very
small number of iterations.
Complementing this Ô¨Ånding, Proposition 26 extends quasi-conjugacy to the robust scoring
rule LŒ≥ derived from the Œ≥-divergence (D(Œ≥)
G ) as provided for in Hung et al. (2018). Similarly
to LŒ≤, LŒ≥(Œ∏, xi) ‚Üí‚àílog p(xi|Œ∏) as Œ≥ ‚Üí1, so that the same intuition that applied to LŒ≤ also
applies here. Note that the conditions for LŒ≥ in Proposition 26 are slightly more restrictive
than those derived for LŒ≤. This is due to the fact that while the same integral term appears
in both, it is additive for LŒ≤ but multiplicative for LŒ≥. While the proof is conceptually
straightforward, it is notationally cumbersome and thus deferred to Appendix E.
Proposition 26 (Closed form GVI objectives with LŒ≥) Let LŒ≥(Œ∏, ¬∑) be the Œ≥-divergence
based scoring rule for likelihood p(¬∑|Œ∏). Suppose p(¬∑|Œ∏) admits conjugacy relative to the expo-
nential distributions given by Q and let the conjugate prior œÄ(Œ∏|Œ∫0) ‚ààQ. Writing
p(x|Œ∏) = h(x) exp

g(x)T T(Œ∏) ‚àíB(x)
	
,
q(Œ∏|Œ∫) = h(Œ∏) exp

Œ∑(Œ∫)T T(Œ∏) ‚àíA(Œ∑(Œ∫))
	
,
N = {Œ∫ : exp{A(Œ∑(Œ∫))} < ‚àû} ,
the objective of P(LŒ≥, KLD, Q) has closed form if for observations x1:n and all q ‚ààQ
I(Œ≥)(Œ∏) =
Z
X
p(x|Œ∏)Œ≥dx,
F1(Œ∫) =
Z
Œò
T(Œ∏)q(Œ∏|Œ∫)dŒ∏,
F2(Œ∫) =
Z
Œò
I(Œ≥)(Œ∏)
1‚àíŒ≥
Œ≥ q(Œ∏|Œ∫)dŒ∏
are closed form functions of Œ∏ and Œ∫ and if for all xi, (Œ∑(Œ∫) + (Œ≥ ‚àí1)g(xi)) ‚ààN.
5.4.2 Additional details on Black-Box GVI (BBGVI)
Standard VI is scalable using doubly stochastic, model-agnostic optimization techniques
(e.g. Paisley et al., 2012; HoÔ¨Äman et al., 2013; Titsias and L√°zaro-Gredilla, 2014; Salimans
and Knowles, 2014; Wu et al., 2019) collectively known as black box VI (Ranganath et al.,
2014). We extend these methods to black box GVI (BBGVI), an inference algorithm directly
inheriting the modularity of the posteriors deÔ¨Åned by P(‚Ñì, D, Q). This makes it easy to
build BBGVI into existing software: For example, adapting the Deep Gaussian Process
implementation of Salimbeni and Deisenroth (2017) required <100 lines of Python code.
Suppose Q = {q(Œ∏|Œ∫) : Œ∫ ‚ààK} and that for all (Œ∫, Œ∏) ‚àà(K, Œò), one can sample
Œ∏ ‚àºq(Œ∏|Œ∫). Suppose also that the derivatives ‚àáŒ∫ log(q(Œ∏|Œ∫)) and ‚àáŒ∫D(q||œÄ) exist (q-almost
surely). For many choices of D, Q and œÄ, ‚àáŒ∫D(q||œÄ) is available in closed form. In this case,
BBGVI is particularly attractive and GVI posteriors can be computed through an unbiased
gradient estimate given as
‚àáŒ∫ ÀÜL(q|‚Ñì, D, Q) = 1
S
S
X
s=1
( n
X
i=1
‚Ñì(Œ∏(s), xi) ¬∑ ‚àáŒ∫ log(q(Œ∏(s)|Œ∫))
)
+ ‚àáŒ∫D(q||œÄ)
(14)
42

Generalized Variational Inference
and relying on an independent sample Œ∏(1:S) i.i.d
‚àºq(Œ∏|Œ∫). If a closed form for ‚àáŒ∫D(q||œÄ) is
not available but D(q||œÄ) = Eq(Œ∏|Œ∫)

‚ÑìD
Œ∫,œÄ(Œ∏)

for a function ‚ÑìD
Œ∫,œÄ : Œò ‚ÜíR, one can use the
alternative unbiased gradient estimate
‚àáŒ∫ ÀÜL(q|‚Ñì, D, Q) = 1
S
S
X
s=1
(" n
X
i=1
‚Ñì(Œ∏(s), xi) + ‚ÑìD
Œ∫,œÄ(Œ∏(s))
#
¬∑ ‚àáŒ∫ log(q(Œ∏(s)|Œ∫)) + ‚àáŒ∫‚ÑìD
Œ∫,œÄ(Œ∏(s))
)
.(15)
This can be deployed for most divergences of interest, including the family of f-divergences.
In some cases however, divergences will not be linear in the argument Œ∏ so that one has
D(q‚à•œÄ) = œÑ
 Eq(Œ∏|Œ∫)

‚ÑìD
Œ∫,œÄ(Œ∏)

for some non-linear function œÑ : R ‚ÜíR. In this case, BBGVI
can be performed based on the biased gradient estimate
‚àáŒ∫ ÀÜL(q|‚Ñì, D, Q) = 1
S
S
X
s=1
( n
X
i=1
‚Ñì(Œ∏(s), xi) ¬∑ ‚àáŒ∫ log(q(Œ∏(s)|Œ∫))
)
+
œÑ
 
1
S
S
X
s=1
‚ÑìD
Œ∫,œÄ(Œ∏(s))
!
¬∑ 1
S
S
X
s=1
‚àáŒ∫‚ÑìD
Œ∫,œÄ(Œ∏(s)).
(16)
Any gradient form admits black box variance reduction through some control variate h
(Ranganath et al., 2014; Wu et al., 2019), see Appendix F for details. Algorithm 1 summarizes
a generic BBGVI procedure.
As gradient estimates based on eq. (14) will have strictly lower variance than estimates
based on eq. (15) or eq. (16), one may wonder under which conditions closed forms for
‚àáŒ∫D(q‚à•œÄ) are available. Proposition 27 clariÔ¨Åes this for robust divergences.
Proposition 27 (Closed form D) Let q, œÄ with natural parameters Œ∑q, Œ∑œÄ be in the expo-
nential family Q = {q(Œ∏|Œ∑) = h(Œ∏) exp {Œ∑‚Ä≤T(Œ∏) ‚àíA(Œ∑)} : Œ∑ ‚ààN} with natural parameter
space N = {Œ∑ : exp{A(Œ∑)} < ‚àû}. Then,
(1) D(Œ±)
A (q||œÄ) and D(Œ±)
AR(q||œÄ) have a closed form if Œ± ‚àà(0, 1) or if Œ±Œ∑q + (1 ‚àíŒ±)Œ∑œÄ ‚ààN
(2) D(Œ≤)
B (q||œÄ) has a closed form if h(Œ∏) = h does not depend on Œ∏ and additionally,
(Œ≤ ‚àí1) ¬∑ Œ∑1 + Œ∑2 ‚ààN for any Œ∑1, Œ∑2 ‚ààN (amongst others, this holds for Beta, Gamma,
Gaussian, exponential or Laplace distributions)
(3) D(Œ≥)
G (q||œÄ) has closed form if D(Œ≤)
B (q||œÄ) does for Œ≤ = Œ≥.
6. Experiments
Having introduced an inference strategy that is generic enough to work on high-dimensional,
black box Bayesian models, the remainder of the paper studies GVI on two applications of
interest in Bayesian Deep Learning. Before doing so, notice that as indicated in Table 1,
previous work constitutes various interesting special cases of GVI with other strong empirical
results (e.g., Futami et al., 2018; Knoblauch et al., 2018; Higgins et al., 2017; Ch√©rief-
Abdellatif and Alquier, 2019; Jankowiak et al., 2019) We add to this body of evidence by
deploying GVI on Bayesian Neural Networks (BNNs) and Deep Gaussian Processes (DGPs) to
address the particular ways in which these two models challenge the assumptions underlying
the standard Bayesian paradigm. All code used for generating the experiments is available
from https://github.com/JeremiasKnoblauch/GVIPublic.
43

Knoblauch, Jewson and Damoulas
Algorithm 1 Black box GVI (BBGVI)
Input: x1:n, œÄ, D, ‚Ñì, Q, h, StoppingCriterion, Œ∫0, K, S, t = 0, LearningRate
done ‚ÜêFalse
while not done do
// STEP 1: Get a subsample from x1:n of size K
œÅ1:K ‚ÜêSampleWithoutReplacement(1 : n, K)
x(t)1:K ‚ÜêxœÅ1:K
// STEP 2: Sample from q(Œ∏|Œ∫t) and compute losses
Œ∏(1:S) i.i.d.
‚àºq(Œ∏|Œ∫t)
‚Ñìi,s ‚Üê‚Ñì(Œ∏(s), x(t)i) ¬∑ ‚àáŒ∫t log q(Œ∏(s)|Œ∫t) for all s = 1, 2, . . . S and i = 1, 2, . . . , K
‚Ñìs ‚Üên
K
PK
i=1 ‚Ñìi,s for all s = 1, 2, . . . S
// STEP 3: Compute uncertainty quantiÔ¨Åer
if D(q‚à•œÄ) admits closed form then
‚Ñìs ‚Üê‚Ñìs + ‚àáŒ∫D(q‚à•œÄ) for all s = 1, 2, . . . S
else if D(q‚à•œÄ) = Eq[‚ÑìD
Œ∫,œÄ(Œ∏)] then
‚Ñìs ‚Üê‚Ñìs + ‚ÑìD
Œ∫,œÄ(Œ∏(s))‚àáŒ∫t log q(Œ∏(s)|Œ∫t) + ‚àáŒ∫t‚ÑìD
Œ∫t,œÄ(Œ∏(s)) for all s = 1, 2, . . . S
else if D(q‚à•œÄ) = œÑ
 Eq[‚ÑìD
Œ∫,œÄ(Œ∏)]

then
‚Ñìs ‚Üê‚Ñìs + œÑ

1
S
PS
s=1 ‚ÑìD
Œ∫t,œÄ(Œ∏(s))

¬∑ ‚àáŒ∫t‚ÑìD
Œ∫t,œÄ(Œ∏(s)) for all s = 1, 2, . . . S
// STEP 4: Apply variance reduction via h if desired
if h Ã∏= None then
hs ‚Üêh(Œ∏(s), ‚Ñìs)
‚Ñìs ‚Üê‚Ñìs ‚àíhs for all for all s = 1, 2, . . . S
// STEP 5: Update Œ∫t and stopping criterion
œÅt ‚ÜêLearningRate(t)
L ‚Üê1
S
PS
s=1 ‚Ñìs
Œ∫t+1 ‚ÜêŒ∫t + œÅt ¬∑ L
done ‚ÜêStoppingCriterion(Œ∫t+1, Œ∫t, t)
t ‚Üêt + 1
6.1 Bayesian Neural Network Regression
As alluded to in Example 1 and Section 5.2.1, BNN models should be expected to suÔ¨Äer from
prior misspeciÔ¨Åcation. Focusing on the regression case, we wish to alleviate this problem
using GVI‚Äôs modularity and thus focus on varying D. Accordingly, we Ô¨Åx the loss function
44

Generalized Variational Inference
to the usual negative log likelihood ‚Ñì(Œ∏, yi, xi, œÉ2) = ‚àílog pN (yi|xi, œÉ2, F(Œ∏)) for
pN (yi|xi, œÉ2, F(Œ∏)) = N(yi|F(Œ∏), xi, œÉ2),
and choose Q = QMFN as the normal mean Ô¨Åeld variational family given in eq. (9). With
this in hand, we compare three diÔ¨Äerent constructions of posterior beliefs:
(1) Standard VI as described in Section 2.3;
(2) DVI methods introduced as approximations to the standard Bayesian posterior q‚àó
B(Œ∏)
that Ô¨Ånd q‚àó
A(Œ∏) = arg minq‚ààQ D(q‚à•q‚àó
B(Œ∏)) with D being the Œ±-divergence (Hern√°ndez-
Lobato et al., 2016)10 and R√©nyi‚Äôs Œ±-divergence (Li and Turner, 2016);
(3) GVI with D = D(Œ±)
AR.
To make comparisons as fair as possible, our implementation is built on top of that used
for the results of Li and Turner (2016) and only changes the objective being optimized.
Similarly, all settings and data sets for which the methods are compared are unchanged
and taken directly from Li and Turner (2016) and Hern√°ndez-Lobato et al. (2016): We
use a single-layer network with 50 ReLU nodes on all experiments. Inference is performed
via probabilistic back-propagation (Hern√°ndez-Lobato and Adams, 2015) and the ADAM
optimizer (Kingma and Ba, 2014) with its default settings, 500 epochs and a batch size of
32. Priors and variational posteriors are both fully factorized normal distributions. Further,
the results are also evaluated on the same selection of UCI data sets (Lichman, 2013) and
in the same way as they were in Li and Turner (2016) and Hern√°ndez-Lobato et al. (2016):
Using 50 random splits of the relevant data into training (90%) and test (10%) sets, the
inferred models are evaluated predictively on the test sets using the average negative log
likelihood (NLL) as well as the average root mean square error (RMSE). For each of the 50
splits, predictions are computed based on 100 samples from the variational posterior.
We summarize the two main results of our experiments as follows: First, Figure 11
depicts what appears to be the most typical relationship between VI, DVI and GVI on
BNNs. Second, Figure 12 explores a surprising Ô¨Ånding about the typical relationship further
and connects it back to the modularity result in Theorem 18. The Appendix contains a small
number of further results.
6.1.1 Typical patterns (Figure 11)
As Figure 11 demonstrates, several Ô¨Åndings form a consistent pattern across a range of data
sets. Three Ô¨Åndings are most poignant.
(A) DVI can often achieve a performance gain for the NLL relative to standard VI, but
much less so for RMSE. On both metrics, there is no clear pattern of improvement.
(B) Relative to standard VI, GVI signiÔ¨Åcantly improves performance for both NLL and
RMSE if Œ± > 1. Conversely, GVI worsens performance if Œ± ‚àà(0, 1). In other words,
larger posterior variances adversely aÔ¨Äect predictive quality.
10. We align the parameterization of the D(Œ±)
A
with the current paper, meaning 1‚àíŒ±current = Œ±H.-L. et al. (2016)
45

Knoblauch, Jewson and Damoulas
4.00
4.05
4.10
D(0.5)
AR
KLD (VI)
D(1.5)
AR
D(2.0)
AR
D(2.5)
AR
D(0.5)
AR
D(0.5)
A
D(0.0)
A
DVI
GVI
power
1.2
1.4
1.6
energy
3.0
3.2
3.4
boston
5.00
5.25
5.50
5.75
concrete
0.8
1.0
1.2
yacht
2.80
2.82
D(0.5)
AR
KLD (VI)
D(1.5)
AR
D(2.0)
AR
D(2.5)
AR
D(0.5)
AR
D(0.5)
A
D(0.0)
A
DVI
GVI
1.6
1.8
2.0
2.5
2.6
2.7
3.05
3.10
3.15
3.20
1.7
1.8
1.9
Figure 11: Best viewed in color. Top row depicts RMSE, bottom row the NLL across a range
of data sets using BNNs. Dots correspond to means, whiskers to standard errors. The further
to the left, the better the predictive performance. For the depicted selection of data sets,
a clear common pattern exists for the performance diÔ¨Äerences between standard VI, DVI
and GVI.
(C) GVI performance is a clear banana-shaped function of Œ± across all data sets: While
predictive performance beneÔ¨Åts as Œ± gets larger than one, the improvement Ô¨Çattens
out and bends back in a banana shape as Œ± grows too large.
Finding (B) has a straightforward interpretation: Since it holds that D(Œ±)
AR ‚â§KLD for Œ± > 1
(see Van Erven and Harremos (2014)11 and Figure 7), the GVI posteriors associated with D(Œ±)
AR
for Œ± > 1 are more concentrated than the standard VI posteriors, a phenomenon also depicted
on toy models in Figure 8. In other words: Ignoring more of the poorly speciÔ¨Åed prior and
consequently being closer to a point mass at the empirical risk minimizer is beneÔ¨Åcial for
predictive performance. As alluded to in Example 1, this is perhaps to be expected: Not
only is the likelihood function of a BNN extremely Ô¨Çexible so that even a point estimate is
likely to produce decent predictions, but it is also doubtful if a literal interpretation of the
prior as in (P) is appropriate for BNNs. As Ô¨Ånding (C) shows however, this does not mean
that point estimates are preferable to posterior beliefs: Increasing the value of Œ± shrinks the
variances too much, eventually impeding predictive performance.
6.1.2 The surprising benefits of modularity (Figure 12)
While Ô¨Åndings (B) and (C) should not come as a surprise by themselves, they do raise
an interesting question: In particular, GVI for D(Œ±)
AR with Œ± = 0.5 is the worst-performing
setting across the board. This is remarkable because this setting also constructs the only
11.
Note that their result holds for a diÔ¨Äerent parameterization of the D(Œ±)
AR, but it is easy to show that our
parameterization is strictly smaller than theirs for Œ± > 1.
46

Generalized Variational Inference
0.0
0.1
0.2
GVI,  D(0.5)
AR
0.0
0.1
0.2
Standard VI
0.0
0.1
0.2
DVI,  D(0.5)
AR
0.0
0.1
0.2
DVI,  D(0.5)
A
7
14
21
28
0.0
0.1
0.2
DVI,  D(0.0)
A
7
14
21
28
7
14
21
28
14
21
28
35
p(yi|xi) (posterior predictives)
0.0
0.12
0.24
0.36
GVI,  D(0.5)
AR
0.0
0.12
0.24
0.36
Standard VI
0.0
0.12
0.24
0.36
DVI,  D(0.5)
AR
0.0
0.12
0.24
0.36
DVI,  D(0.5)
A
7
14
21
28
0.0
0.12
0.24
0.36
DVI,  D(0.0)
A
7
14
21
28
7
14
21
28
14
21
28
35
p( |xi) (parameter posterior pushforwards)
Figure 12: Best viewed in color.
Depicted are test set predictions based on posterior
predictives (top panel) and parameter posterior pushforwards (bottom panel) with four
observations in the boston data set. Each column shows one observation (dashed line). The
predictive distributions (histogram) and their means (solid line) for each row correspond to
standard VI, DVI and GVI.
47

Knoblauch, Jewson and Damoulas
GVI posteriors in our experiments with wider variances than standard VI. At the same time,
producing wider variances and more conservative uncertainty quantiÔ¨Åcation is one of the
main motivations for Expectation Propagation (EP) the presented DVI methods, see for
example Figure 1(a) in Li and Turner (2016) or Figure 8 in Hern√°ndez-Lobato et al. (2016).
This is puzzling: Are wider variances for Œ∏ somehow beneÔ¨Åcial for DVI posteriors‚Äô predictive
performance while damaging that of GVI posteriors? As it turns out, this is not the case.
Rather, while both GVI with Œ± = 0.5 and all DVI produce parameter posteriors with larger
variances, in the case of DVI this does not translate into predictive uncertainty.
This phenomenon is depicted in Figure 12, which clearly shows that the additional
uncertainty in the DVI parameter posteriors q‚àó
DVI(Œ∏|Œ∫‚àó) is completely overshadowed by an
extreme degree of variance shrinkage in the corresponding posterior predictives. In other
words, the increased uncertainty in Œ∏ is outweighed by extremely small values for œÉ2. The
plot demonstrates this by comparing the push-forward F#q‚àó
DVI(¬∑|Œ∫‚àó) with the posterior
predictives. Formally, the push-forward is given by
p(¬µ|xi) = (F#q‚àó
DVI(¬∑|Œ∫‚àó)) (¬µ),
where the operation # is simply a formalization of the following two operations: (i) sample
Œ∏ ‚àºq‚àó
DVI(Œ∏|Œ∫‚àó), (ii) compute ¬µ = F(Œ∏).
The posterior predictive then integrates the
push-forward measure p(¬µ|xi) over the likelihood function as
p(yi|xi) =
Z
Œò
pN (yi|xi, œÉ2, F(Œ∏))q‚àó
DVI(Œ∏|Œ∫‚àó)dŒ∏ =
Z
R
pN (yi|xi, œÉ2, ¬µ)p(¬µ|xi)d¬µ.
As Figure 12 shows, the push-forward behaves as expected for both GVI and DVI. For DVI,
the same cannot be said for the posterior predictive: Interestingly, they generally have much
less variance than for standard VI.
This surprising phenomenon is due to hyperparameter optimization for œÉ2 and has an
intimate link with the modularity result of Theorem 18. Since variational inference on œÉ2
complicates the DVI objectives, both Hern√°ndez-Lobato et al. (2016) and Li and Turner
(2016) do not infer œÉ2 probabilistically. Instead, it is optimized over their objectives. This
approach poses an optimization problem which for D = D(Œ±)
A
and D = D(Œ±)
AR is given by
bœÉ2, q‚àó
DVI(Œ∏|Œ∫‚àó) = arg min
œÉ2
(
arg min
q‚ààQ
D(q(Œ∏|Œ∫)||q‚àó
B(Œ∏|œÉ2, x1:n, y1:n))
)
.
(17)
Crucially, the inner part of this objective conditions on the exact Bayesian posterior for a
Ô¨Åxed value of œÉ2 and then seeks to approximate the posterior belief given by
q‚àó
B(Œ∏|œÉ2, x1:n, y1:n) ‚àùœÄ(Œ∏)
n
Y
i=1
pN (yi|xi, œÉ2, F(Œ∏)).
At the same time however, the outer part of the objective seeks to Ô¨Ånd a value for œÉ2 which
makes the posterior q‚àó
B(Œ∏|œÉ2, x1:n, y1:n) as easily approximable as possible. In other words,
an objective which is explicitly motivated as a projection of q‚àó
B(Œ∏|œÉ2, x1:n, y1:n) into Q also
changes the very point from which to project into Q.
48

Generalized Variational Inference
Though it would be computationally easy to perform probabilistic inference on œÉ2 within
GVI, we also optimize œÉ2 as a hyperparameter for comparability. Thus, we pose the alternative
optimization problem
bœÉ2, q‚àó
GVI(Œ∏|Œ∫‚àó) = arg min
œÉ2
(
arg min
q‚ààQ
(
Eq
" n
X
i=1
‚àílog pN (yi|xi, œÉ2, F(Œ∏))
#
+ D(Œ±)
AR(q||œÄ)
))
.(18)
As Figure 12 shows, the outcomes are drastically diÔ¨Äerent: Unlike in the DVI case, the
predictive uncertainty for the GVI posteriors move in the same direction as parameter
uncertainty as Œ± varies. The modularity of GVI makes it obvious what the optimization over
œÉ2 corresponds to in eq. (18): Rather than choosing the best posterior q‚àó
B(Œ∏|œÉ2, x1:n, y1:n)
from which to project into Q, the optimization problem simply seeks to Ô¨Ånd the best possible
loss ‚ÑìœÉ2(yi|xi, F(Œ∏)) = ‚àílog p(yi|xi, œÉ2, F(Œ∏)) over all œÉ2 ‚ààR+.
6.2 Deep Gaussian Processes
Deep Gaussian Processes (DGPs) were introduced by Damianou and Lawrence (2013) and
extend the logic of deep learning to the nonparametric Bayesian setting. The principal idea
is to construct a hierarchy of Gaussian Process (GP) priors over latent spaces. Unlike with
the BNNs presented in the last section, the priors in DGPs are usually reÔ¨Åned at run-time
by using various hyperparameter optimization schemes. This is in fact crucial for DGPs to
provide good inferences: Indeed, it ensures that the inputs X are mapped into latent spaces
which are informative for the outputs Y . As a consequence, unlike with BNNs we expect
there to be comparatively little merit in varying the uncertainty quantiÔ¨Åer D for DGPs‚Äîa
suspicion we experimentally conÔ¨Årm in Appendix H.2.3. Accordingly, we instead focus on
experiments that vary the loss ‚Ñì. More speciÔ¨Åcally, we consider replacing the negative log
score with a robust scoring rule for the likelihood which is derived from the Œ≥-divergence
(Hung et al., 2018), which drastically improves predictive performance.
In the remainder, we Ô¨Årst introduce DGPs (Section 6.2.1). Next, we provide a brief
overview of the doubly stochastic inference procedure in Salimbeni and Deisenroth (2017)
(Section 6.2.2) and show how to adapt DGPs to GVI (Section 6.2.3). Lastly, we present
numerical experiments and their results (Section 6.2.4). These Ô¨Åndings are also summarized
with a higher level of detail in a separate technical report (Knoblauch, 2019b).
6.2.1 Preliminaries for DGPs
Given observations (X, Y ) where X ‚ààRn√óDx and Y ‚ààRn√óp, a DGP of L layers introduces
L latent functions {F l}L
l=1. Here, F l is matrix-valued and of dimension Dl √ó Dl+1. Setting
F 0 = X, D0 = Dx and Dl+1 = p, one can write the DGP construction as
Y |F L
‚àº
p
 Y
 F L
F L|F L‚àí1 = fL(F L‚àí1)
‚àº
GP
 ¬µL(F L‚àí1), KL(F L‚àí1, F L‚àí1)

. . .
F 1|F 0 = f1(F 0)
‚àº
GP
 ¬µ1(F 0), K1(F 0, F 0)

,
where the mean and covariance functions are ¬µl : RDl ‚ÜíRDl+1 and Kl : RDl√óDl ‚Üí
RDl+1√óDl+1. Scalable inference strategies for this model generally rely on VI (Damianou and
49

Knoblauch, Jewson and Damoulas
Lawrence, 2013; Dai et al., 2016; Salimbeni and Deisenroth, 2017; Hensman and Lawrence,
2014), Monte Carlo methods (Vafa, 2016; Wang et al., 2016) or more specialized approaches
(Cutajar et al., 2017a).
In the remainder, we discuss the implications of Generalized
Variational Inference (GVI) in relation to the arguably most promising VI approach of
Salimbeni and Deisenroth (2017).
Unlike previous VI methods, it encodes conditional
dependence into the variational family Q and comprehensively outperformed Expectation
Propagation (EP) based alternatives (Bui et al., 2016).
6.2.2 Doubly stochastic VI in DGPs
First, deÔ¨Åne m inducing points Zl = (zl
1, zl
2, . . . , zl
m)T and their function values U l =
(fl(zl
1), fl(zl
2), . . . , fl(zl
m))T (for details on inducing points, see Snelson and Ghahramani,
2006; Titsias, 2009; Bonilla et al., 2019; Matthews et al., 2016). For improved readability, we
drop X and Zl from the conditioning sets and denote the i-th row of F l as f L
i . With this,
the joint distribution of the DGP is
p

Y , {F l}L
l=1, {U l}L
l=1

=
n
Y
i=1
p(yi|f L
i )
|
{z
}
likelihood
√ó
L
Y
l=1
p

F l U l, F l‚àí1, Zl‚àí1
p

U l Zl‚àí1
|
{z
}
(DGP) prior
.
The posteriors p
 {F l}L
l=1, {U l}L
l=1

and p
 {F l}L
l=1

are intractable. The VI method proposed
in Salimbeni and Deisenroth (2017) overcomes this with the variational family given by
q

{F l}L
l=1, {U l}L
l=1

=
L
Y
l=1
p

F l U l, F l‚àí1, Zl‚àí1
q

U l
;
q

U l
= N

U l ml, Sl

.
This allows for exact integration over the inducing points {U l}L
l=1, yielding
q

{F l}L
l=1

=
L
Y
l=1
N

F l ¬µl, Œ£l

.
As shown in Salimbeni and Deisenroth (2017), this enables a doubly stochastic minimization
of the negative Evidence Lower Bound (ELBO) given by
Eq(F L)
" n
X
i=1
‚àílog p(yi|F L)
#
+ KLD

q({F l}L
l=1, {U l}L
l=1)
p({F l}L
l=1, {U l}L
l=1)

= ‚àí
n
X
i=1
Eq(f L
i )

log p(yi|f L
i )

+
L
X
l=1
KLD(q(U l)||p(U l)).
(19)
For optimization, the samples for F l are drawn using the variational posteriors from the
previous layers so that approximating the expectations over q(f L
i ) induces the Ô¨Årst layer of
stochasticity. The second layer is due to drawing mini-batches from X = F 0 and Y . Because
of this large degree of stochasticity, it is appealing if Eq(f L
i )

log p(yi|f L
i )

is available in
closed form, which is for instance the case if p = pN is a normal likelihood.
50

Generalized Variational Inference
6.2.3 Adaption to GVI
The objective in eq. (19) suggests itself naturally to a GVI variant. This raises two questions:
(D) Is it theoretically coherent with the meaning and function of D in the axiomatic
development of Section 4.1 to simply replace the KLD-terms layer-wise?
(‚Ñì) Can one derive closed forms for the expectations when the log scoring rule is replaced
by robust alternatives LŒ≤ or LŒ≥ derived from the Œ≤- and Œ≥-divergence?
As shown next, we can give a positive answer to both these questions.
(D)
Conveniently and as shown in Salimbeni and Deisenroth (2017),
KLD

q({F l}L
l=1, {U l}L
l=1)
p({F l}L
l=1, {U l}L
l=1)

=
L
X
l=1
KLD(q(U l)||p(U l)).
(20)
A natural question is whether one can reverse-engineer this Ô¨Ånding: If we simply pick a collec-
tion of other divergences Dl(q(U l)||p(U l)) for each layer l and combine them additively, does
the result deÔ¨Åne a valid divergence between q({F l}L
l=1, {U l}L
l=1) and p({F l}L
l=1, {U l}L
l=1)?
As the next Corollary shows, one can prove that reverse-engineering prior regularizers in-
spired by eq. (20) is feasible so long as the layer-speciÔ¨Åc divergences Dl are f-divergences or
monotonic transformations of f-divergences. The proof relies on a technical Lemma and is
given in Appendix H.2.1
Corollary 28 In the DGP construction of eq. (19), replacing the sum of KLD-terms by
L
X
l=1
Dl(q(U l)||p(U l))
deÔ¨Ånes a valid divergence between q({F l}L
l=1, {U l}L
l=1) and p({F l}L
l=1, {U l}L
l=1) so long as Dl
is an f-divergence or a divergence obtained as a monotonic transform g of an f-divergence
for all l = 1, 2, . . . L.
(‚Ñì)
Next, we turn attention to modifying the loss terms in eq. (19). First, note that
Eq(F L)
" n
X
i=1
‚àílog p(yi|F L)
#
= ‚àí
n
X
i=1
Eq(f L
i )

log p(yi|f L
i )

.
This identity still holds if one replaces the negative log with other scoring rules. As the next
Proposition shows, we even retain closed forms for the regression case and the scoring rules
LŒ≤
p(f L
i , yi) = ‚àí
1
Œ≤ ‚àí1p(yi|f L
i )Œ≤‚àí1 + Ip,Œ≤(f L
i )
Œ≤
LŒ≥
p(f L
i , yi) = ‚àí
1
Œ≥ ‚àí1p(yi|f L
i )Œ≥‚àí1 ¬∑
Œ≥
Ip,Œ≥(f L
i )‚àíŒ≥‚àí1
Œ≥
.
Crucially, the integral term Ip,c(f L
i ) =
R
p(y|f L
i )cdy is generally available in closed form for
exponential families. As the notation suggests, LŒ≤
p is linked to the Œ≤-divergence in the same
51

Knoblauch, Jewson and Damoulas
way we linked the log score to the KLD in Section 5.2.2, see also Basu et al. (1998). Similarly,
LŒ≥
p is derived from the Œ≥-divergence as explained in Hung et al. (2018). As also alluded to in
Section 5.4.1, LŒ≥
p (LŒ≤
p) recovers the log score as Œ≥ ‚Üí1 (Œ≤ ‚Üí1) and produces robust inferences
for Œ≥ > 1 (Œ≤ > 1). Figure 4 depicts this for LŒ≤
p, and the behaviour is very similar for LŒ≥
p.
Proposition 29 (Closed forms for robust DGP regression) If it holds that yi ‚ààRd,
p(yi|f L
i ) = N
 yi; f L
i , œÉ2Id

;
q(f L
i ) = N(f L
i ; ¬µ, Œ£),
then for the quantities given by
eŒ£‚àí1 =
 c
œÉs Id + Œ£‚àí1
;
e¬µ =
 c
œÉ2 yi + Œ£‚àí1¬µ

;
I(c) = (2œÄœÉ2)‚àí0.5dcc‚àí0.5d
and for
E(c) = 1
c
 2œÄœÉ2‚àí0.5dc |eŒ£|0.5
|Œ£|0.5 exp

‚àí1
2
 c
œÉ2 yT
i yi + ¬µT Œ£‚àí1¬µ ‚àíe¬µT eŒ£e¬µ

the following expectations are available in closed form:
Eq(f L
i )

LŒ≤
p(f L
i , yi)

= ‚àíE(Œ≤ ‚àí1) + I(Œ≤)
Œ≤
Eq(f L
i )

LŒ≤
p(f L
i , yi)

= ‚àíE(Œ≥ ‚àí1) ¬∑
Œ≥
I(Œ≥)
Œ≥
Œ≥‚àí1
As shown in Appendix H.2.2, it is easy but tedious to derive this result. While the results of
using LŒ≤
p and LŒ≥
p are often virtually identical (see for instance Figure 22 in Appendix H.1),
our experiments on DGPs will exclusively use the LŒ≥
p. This is done because unlike for LŒ≤
p,
computations with LŒ≥
p can be performed in its numerically more stable log form.
6.2.4 Results
As with the experiments on BNNs in the previous section, we make comparisons as fair
as possible by using the gpflow (Matthews et al., 2017) implementation of Salimbeni and
Deisenroth (2017). Further, we use the same settings, meaning that all experiments use
20,000 iterations of the ADAM optimizer (Kingma and Ba, 2014) with a learning rate of 0.01
and default settings for all other hyperparameters. We perform inference for each of the UCI
data sets (Lichman, 2013) after normalization using the RBF kernel with dimension-wise
lengthscales, 100 inducing points, with batch sizes of min(1000, n) and Dl = min(Dx, 30).
As before, we use 50 random splits with 90% training and 10% test data to assess predictive
performance in terms of negative log likelihood (NLL) and root mean square error (RMSE).
With this, we compare two inference schemes:
(1) The state of the art standard VI techniques of Salimbeni and Deisenroth (2017);
(2) A GVI variant of the same inference method which replaces the log score with the
robust Œ≥-divergence based scoring rule LŒ≥
p.
52

Generalized Variational Inference
2.8
3.0
3.2
L = 3
L = 2
L = 1
= 1.01, L = 3
= 1.01, L = 2
= 1.01, L = 1
= 1.05, L = 3
= 1.05, L = 2
= 1.05, L = 1
GVI
VI
boston
4.5
5.0
5.5
concrete
0.50
0.75
1.00
1.25
1.50
energy
0.06
0.07
0.08
0.09
kin8mn
2.4
2.5
2.6
L = 3
L = 2
L = 1
= 1.01, L = 3
= 1.01, L = 2
= 1.01, L = 1
= 1.05, L = 3
= 1.05, L = 2
= 1.05, L = 1
GVI
VI
2.9
3.0
3.1
0.75
1.00
1.25
1.50
1.75
1.4
1.3
1.2
1.1
1.0
0.62
0.63
L = 3
L = 2
L = 1
= 1.01, L = 3
= 1.01, L = 2
= 1.01, L = 1
= 1.05, L = 3
= 1.05, L = 2
= 1.05, L = 1
GVI
VI
wine
0.00025 0.00030 0.00035
naval
0.4
0.6
0.8
yacht
3.8
4.0
power
1.80
1.85
1.90
protein
0.93
0.94
0.95
0.96
L = 3
L = 2
L = 1
= 1.01, L = 3
= 1.01, L = 2
= 1.01, L = 1
= 1.05, L = 3
= 1.05, L = 2
= 1.05, L = 1
GVI
VI
6.8
6.6
0.5
1.0
2.75
2.80
2.0
2.1
2.2
2.3
Figure 13: Best viewed in color. Top rows depict RMSE, bottom rows the NLL across a
range of data sets using DGPs. Dots correspond to means, whiskers to standard errors. The
further to the left, the better the predictive performance. For the depicted selection of data
sets, GVI comprehensively outperforms standard VI.
For choosing Œ≥, we note that inferences are robust for Œ≥ > 1 and that LŒ≥
p recovers the log
score as Œ≥ ‚Üí1. At the same time, the scoring rule will grow increasingly happy to ignore
virtually all of the data as Œ≥ ‚Üí‚àû. Accordingly, one will typically want to pick
Œ≥ = 1 + Œµ
53

Knoblauch, Jewson and Damoulas
for a small Œµ > 0.
Choosing Œ≥ in this way encodes the intuition that a good scoring
rule will behave like the log score for all but the most extreme outliers. We thus pick
Œµ ‚àà{0.01, 0.05}, a range of values also successfully used in (Jankowiak et al., 2019). We note
that hyperparameter optimization might appear to be the natural choice for picking Œ≥, but
will not perform well in practice: Rather than producing robust inferences, this will select
for a value of Œ≥ generally producing the smallest GVI objective values across Q12.
The results are depicted in Figure 13 and conÔ¨Årm our two main intuitions about robustness:
Firstly, the robust scoring rule provides a signiÔ¨Åcant performance improvement. Secondly,
the smaller value of Œ≥ (which will be closer to the log score) generally outperforms the larger
value of Œ≥, though both choices are equally good in many data sets13. We believe that the
performance gains of the robust scoring rule is due to large parts of the latent spaces being
non-informative. This implies that it is beneÔ¨Åcial to implicitly down-weight the inÔ¨Çuence
of these non-informative parts of the latent space. It is clear that robust scoring rules do
exactly that (see for instance Figure 4), which explains their superior performance in the
DGP experiments. This intuition is further bolstered by the following observation: Generally,
performance improves with a larger number of layers L under the robust score LŒ≥
p, but
worsens under the log score. In other words: The more dispersed the prior over the latent
space (i.e., the DGP) becomes, the more inferential outcomes beneÔ¨Åt from implicitly ignoring
its non-informative regions. In Appendix H.2 we provide a small batch of additional results
showing that as expected, modifying the uncertainty quantiÔ¨Åer D is less beneÔ¨Åcial for DGPs
than it is for BNNs. Most likely, this is due to hyperparameter optimization for the kernels
of the DGP. Together with the fact that Gaussian Processes are far more informative priors
than fully factorized normals, careful selection of the hyperparameters ensures that unlike in
the BNN case, the prior is well-speciÔ¨Åed.
7. Discussion & Conclusion
In this work, we re-examined the working assumptions that have proven powerful and useful
in spreading Bayesian inference into virtually all domains of scientiÔ¨Åc endeavour. Studying
the challenges of contemporary inference, we concluded that the traditional assumptions
underlying Bayesian statistics are misaligned with the realities of modern large-scale problems.
At the same time, we adopted an optimization-centric view on Bayesian inference that allows
us to prove a novel optimality result for standard Vatiational Inference (VI). In spite of
this theoretical result, we pointed out that belief distributions computed as alternative
approximations to the Bayesian posterior often perform better in practice. We explained
that this is because standard VI is optimal only relative to a particular objective function‚Äî
speciÔ¨Åcally, an objective function whose origins are the very assumptions that are misaligned
with reality. Inspired by this insight, we proceed to derive a new class of posterior belief
distributions that do not rely on these assumptions. To do so, we Ô¨Årst set out a new axiomatic
foundation for Bayesian inference culminating in the Rule of Three (RoT). The RoT is an
12. In practice, this means that hyperparameter optimization pushes Œ≥ ‚Üí1 or Œ≥ ‚Üí‚àû, depending on the
magnitudes of {p(yi|f L
i )}n
i=1.
13.
We expect this second Ô¨Ånding about Œ≥ to generalize to new settings so long as the inputs are normalized
and the outputs are not high-dimensional (see also Figure 22 for some empirical evidence of this on
BNNs), which would make Œ≥ = 1.01 a decent default choice in such scenarios.
54

Generalized Variational Inference
optimization problem with three arguments, each of which addresses one of the shortcomings
of the standard Bayesian assumptions. Yet, while it deÔ¨Ånes a much larger family of posteriors,
the RoT also recovers the standard Bayesian update rule as a special case. Building on this
novel generalized class of posteriors, we introduce Generalized Variational Inference (GVI).
In essence, GVI restricts attention to the tractable subset of RoT posterior beliefs contained
within a variational family. Next, we show that GVI satisÔ¨Åes a number of desirable theoretical
properties: It is modular (in the sense of Theorem 18) and consistent in the frequentist sense.
Moreover, the objectives for a sub-class of GVI posteriors form an approximate evidence
lower bound on a generalized Bayesian posterior. On the practical side, we show three
generic applications of GVI in the broad context of customized uncertainty quantiÔ¨Åcation and
robustness. SpeciÔ¨Åcally, we demonstrate how GVI can be used to adjust posterior variances
and produce inferences that are robust to model and prior misspeciÔ¨Åcation. Lastly, we
demonstrate GVI‚Äôs power, usefulness and versatility on two model classes that encapsulate
the misalignment between the assumptions underlying the traditional Bayesian paradigm
and the realities of modern large-scale Bayesian inference: Bayesian Neural Networks (BNNs)
and Deep Gaussian Processes (DGPs).
The current work makes two major contributions. The Ô¨Årst of these is conceptual: We
propose a generalization of Bayesian inference through the Rule of Three (RoT). This aspect
of our work stands in the tradition of previous generalizations of Bayesian inference such
as the one in Bissiri et al. (2016) and Jewson et al. (2018). Unlike previous work however,
we take the Ô¨Årst step in the development of Bayesian inference procedures that generalize
beyond multiplicative belief updates. Indeed, this step is natural once one observes the
intimate connection between Bayesian inference and inÔ¨Ånite-dimensional optimization as
set out in Observation 1. As explained in Sections 2 and 4, an immediate consequence of
this generalization is a meaningful taxonomy of various variational inference procedures:
Unlike most other variational approximations to the Bayesian posterior, standard Variational
Inference (VI) is a special case of the RoT. This special standing of standard VI also
expresses itself in Theorem 3, which endows standard VI with an (objective-dependent)
quality guarantee that is absent from alternative approximation procedures.
The second contribution is methodological and consists in making the RoT useful for real
world inference problems via Generalized Variational Inference (GVI). We show that GVI
modularly addresses the three shortcomings associated with traditional Bayesian inference.
This is done by linking it to the literature on generalized Bayesian inference and robust
scoring rules as well as to the literature on robust divergences. As Section 6 shows with two
applications on large-scale inference problems, GVI posteriors of this form can yield signiÔ¨Åcant
predictive performance improvements in modern statistical machine learning models.
With the provision of a new optimization-centric generalization on Bayesian inference, the
current paper is only the Ô¨Årst step on a long road to designing posteriors that conform with
the demands of contemporary models and inferential problems. In the wake of this, several
important questions have been left unanswered. For example, it is unclear how to choose
hyperparameters occurring in the loss or uncertainty quantiÔ¨Åer beyond simplistic (albeit well-
working) rules of thumb. Further, we have not characterized the class of posteriors satisfying
the axioms in Section 4.1 uniquely. Though the RoT is unique when restricting attention to
elementary functions and is arguable the most desirable form due to its relationship to the
standard Bayesian and variational posteriors, we are convinced that the uniqueness result
55

Knoblauch, Jewson and Damoulas
of Theorem 15 can be derived under much stronger conditions. GVI also has an obvious
intimate connections with PAC-Bayesian approaches that we will be exploring in the near
future. Moreover, the Ô¨Çexibility in choosing diÔ¨Äerent uncertainty quantiÔ¨Åers D brings about
another interesting question: Given that frequentist consistency holds, what impact does D
have on the contraction rate? And do certain special cases of D endow GVI with compelling
geometric interpretations?
In summary, the current work is but the start of an investigation into the theoretical,
methodological and applied consequences of the RoT and GVI. It is clear that the ideas
introduced in the current paper‚Äîwhile barely scratching the surface of the possible‚Äîhave
produced valuable insights and shown much promise in all three of these regards. Consequently,
it is with much excitement that we look forward to future contributions on questions of
theory, methodology and practice surrounding the RoT and GVI.
Acknowledgments
We would like to cordially thank Edwin Fong, Benjamin Guedj, Chris Holmes, David Dunson,
Mark van der Wilk, Giles Hooker and Alex Alemi for fruitful discussions, insights, comments
and pointers that were invaluable for improving the paper. JK and JJ are funded by EPSRC
grant EP/L016710/1 as part of the Oxford-Warwick Statistics Programme (OxWaSP). JK is
additionally funded by the Facebook Fellowship Programme and the London Air Quality
project at the Alan Turing Institute for Data Science and AI. TD acknowledges funding
from EPSRC grant EP/T004134/1, the Lloyd‚Äôs Register Foundation programme on Data
Centric Engineering, and the London Air Quality project at the Alan Turing Institute for
Data Science and AI. This work was furthermore supported by The Alan Turing Institute for
Data Science and AI under EPSRC grant EP/N510129/1 in collaboration with the Greater
London Authority.
56

Generalized Variational Inference
Appendix A. DeÔ¨Ånitions for robust divergences
The following is an overview of deÔ¨Ånitions for the most important divergences that are used
throughout the paper.
DeÔ¨Ånition 30 (The Œ±Œ≤Œ≥-divergence D(Œ±,Œ≤,r)
G
(Cichocki and Amari, 2010)) The Œ±Œ≤Œ≥-
divergence D(Œ±,Œ≤,r)
G
Cichocki and Amari (2010) takes the form
D(Œ±,Œ≤,r)
G
(q(Œ∏)||œÄ(Œ∏)) =
1
Œ±(Œ≤ ‚àí1)(Œ± + Œ≤ ‚àí1)r
h
ÀúD(Œ±,Œ≤)
G
(q(Œ∏)||œÄ(Œ∏)) + 1
r
‚àí1
i
where r > 0, Œ± Ã∏= 0, Œ≤ Ã∏= 1 and
ÀúD(Œ±,Œ≤)
G
(q(Œ∏)||œÄ(Œ∏)) =
Z 
Œ±q(Œ∏)Œ±+Œ≤‚àí1 + (Œ≤ ‚àí1)œÄ(Œ∏)Œ±+Œ≤‚àí1 ‚àí(Œ± + Œ≤ ‚àí1)q(Œ∏)Œ±œÄ(Œ∏)Œ≤‚àí1
dŒ∏
Below we list some well-known special cases of the family of divergences deÔ¨Åned by D(Œ±,Œ≤,r)
G
that we use in the main paper. This exposition is a summary of the review conducted in
Cichocki and Amari (2010).
DeÔ¨Ånition 31 (The Œ±-divergence (D(Œ±)
A ) (ChernoÔ¨Ä, 1952; Amari, 2012)) The Œ±-divergence
is deÔ¨Åned as
D(Œ±)
A (q(Œ∏)||œÄ(Œ∏)) =
1
Œ±(1 ‚àíŒ±)

1 ‚àí
Z
q(Œ∏)Œ±œÄ(Œ∏)1‚àíŒ±dŒ∏

,
where Œ± ‚ààR \ {0, 1}. Note that D(Œ±)
A
is recovered from D(Œ±,Œ≤,r)
G
when r = 1 and Œ≤ = 2 ‚àíŒ±.
D(Œ±)
A
is also a member of the f-divergence family.
DeÔ¨Ånition 32 (R√©nyi‚Äôs Œ±-divergence (D(Œ±)
AR) (R√©nyi, 1961)) R√©nyi‚Äôs Œ±-divergence is de-
Ô¨Åned as
D(Œ±)
AR(q(Œ∏)||œÄ(Œ∏)) =
1
Œ±(Œ± ‚àí1) log
Z
q(Œ∏)Œ±œÄ(Œ∏)1‚àíŒ±dŒ∏

,
where Œ± ‚ààR \ {0, 1}. D(Œ±)
AR is recovered from D(Œ±,Œ≤,r)
G
in the limit as r ‚Üí0 and Œ≤ = 2 ‚àíŒ±.
Note that we use the rescaled version proposed by Liese and Vajda (1987); Cichocki and
Amari (2010) rather than the original parameterization of R√©nyi (1961) because it links the
divergence more closely to other robust alternatives of the KLD.
DeÔ¨Ånition 33 (The Œ≤-divergence (D(Œ≤)
B ) (Basu et al., 1998; Mihoko and Eguchi, 2002))
The Œ≤-divergence (Mihoko and Eguchi, 2002) was originally introduced under the name ‚Äùden-
sity power divergence‚Äú and is deÔ¨Åned as
D(Œ≤)
B (q(Œ∏)||œÄ(Œ∏)) =
1
Œ≤(Œ≤ ‚àí1)
Z
q(Œ∏)Œ≤dŒ∏ + 1
Œ≤
Z
œÄ(Œ∏)Œ≤dŒ∏ ‚àí
1
Œ≤ ‚àí1
Z
q(Œ∏)œÄ(Œ∏)Œ≤‚àí1dŒ∏,
where Œ≤ ‚ààR \ {0, 1}. D(Œ≤)
B
is recovered from D(Œ±,Œ≤,r)
G
when r = Œ± = 1. D(Œ≤)
B
is a member of the
Bregman-divergence family.
57

Knoblauch, Jewson and Damoulas
DeÔ¨Ånition 34 (The Œ≥-divergence (D(Œ≥)
G ) (Fujisawa and Eguchi, 2008)) The Œ≥-divergence
(Fujisawa and Eguchi, 2008) is deÔ¨Åned as
D(Œ≥)
G (q(Œ∏)||œÄ(Œ∏)) =
1
Œ≥(Œ≥ ‚àí1) log
 R
q(Œ∏)Œ≥dŒ∏
  R
œÄ(Œ∏)Œ≥dŒ∏
Œ≥‚àí1
 R
q(Œ∏)œÄ(Œ∏)Œ≥dŒ∏
Œ≥
,
where Œ≥ ‚ààR \ {0, 1}. D(Œ≥)
G
is recovered from D(Œ±,Œ≤,r)
G
in the limit as r ‚Üí0, Œ± = 1 and Œ≤ = Œ≥.
The D(Œ≥)
G
can be shown to be generated from the D(Œ≤)
B
applying the following transformation
c0
Z
g(x)c1f(x)c2dx ‚Üíc0 log
Z
g(x)c1f(x)c2dx
to all three of the D(Œ≤)
B
terms. This is of interest because the D(Œ±)
AR is generated by the D(Œ±)
A
by
applying the same transformation of its two terms.
Remark 35 (Recovering the KLD) The D(Œ±)
A , D(Œ±)
AR, D(Œ≤)
B
and D(Œ≥)
G
all recover the KLD in
the limit as Œ± = Œ≤ = Œ≥ ‚Üí1. This can be shown using the replica trick:
lim
x‚Üí0
Zx ‚àí1
x
= log(Z).
Appendix B. Comparing robust divergences as uncertainty quantiÔ¨Åers
In order to understand the impact the choice of divergence used for regularization and its
hyperparameter have on the inference, this section studies variations in the argument D.
This investigation is conducted on a simple Bayesian linear regression example with two
highly correlated predictors given by
œÉ2 ‚àºIG(a0, b0)
Œ∏|œÉ2 ‚àºN2
 ¬µ0, œÉ2V0

(21)
yi|Œ∏, œÉ2 ‚àºN
 XiŒ∏, œÉ2
.
We choose this example because it provides a closed form exact Bayesian posteriors and closed
form objectives for the variational objectives of VI and GVI. Consequently, no sampling is
required‚Äîneither for calculating the exact posterior nor for the optimization of the GVI and
VI posteriors‚Äîso that numerical errors and uncertainties are kept to a minimum.
Studying the exact closed form Bayesian (normal) posterior for Œ∏ = (Œ∏1, Œ∏2)T , one observes
that if the two predictors are correlated, then the posterior covariance of Œ∏ will inherit this
correlation. As we wish to investigate the underestimation of marginal variances for standard
VI as well as the way in which GVI can address this, our numerical studies leverage this
Ô¨Ånding. In particular, we simulate the highly correlated predictors
(x1, x2)T ‚àºN2
0
0

,
 1
0.9
0.9
1

58

Generalized Variational Inference
0
1
2
3
4
5
1
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
Density
D =
-divergence (D( )
A )
Exact posterior
= 1.25
Standard VI
= 0.95
= 0.5
= 0.01
MLE
Figure 14: Best viewed in color. Marginal VI and GVI posterior for the Œ∏1 coeÔ¨Écient
of a Bayesian linear model under the D(Œ±)
A
prior regularizer for diÔ¨Äerent values of Œ±. The
boundedness of the D(Œ±)
A causes GVI posteriors to severely over-concentrate if Œ± is not carefully
speciÔ¨Åed. Prior SpeciÔ¨Åcation: œÉ2 ‚àºIG(20, 50), Œ∏1|œÉ2 ‚àºN(0, 25œÉ2) and Œ∏2|œÉ2 ‚àºN(0, 25œÉ2).
and compare the performance of the diÔ¨Äerent GVI and VI posteriors on the resulting Bayesian
linear regression. All posteriors are based on the the mean Ô¨Åeld normal variational family
Q = {q(Œ∏1|œÉ2, Œ∫n)q(Œ∏2|œÉ2, Œ∫n)q(œÉ2|Œ∫n)} so that Œ∫n = (an, bn, ¬µ1,n, ¬µ2,n, v1,n, v2,n)T
with an, bn, v1,n, v2,n > 0 and ¬µ1,n, ¬µ2,n ‚ààR
q(œÉ2|Œ∫n) = IG(œÉ2|an, bn)
q(Œ∏1|œÉ2, Œ∫n) = N
 Œ∏1|¬µ1,n, œÉ2v1,n

q(Œ∏2|œÉ2, Œ∫n) = N
 Œ∏2|¬µ2,n, œÉ2v2,n

.
For all experiments, n = 25 observations are simulated from eq. (22) with Œ∏ = (2, 3) and
œÉ2 = 4. We use the negative log-likelihood of the correctly speciÔ¨Åed model as given in eq.
(22) as loss function. To investigate GVI‚Äôs behaviour across diÔ¨Äerent uncertainty quantiÔ¨Åers,
we vary its choice as D ‚àà

D(Œ±)
A , D(Œ≤)
B , D(Œ±)
AR, D(Œ≥)
G
	
. The results are depicted in Figs. 14 and
16-20. We summarize the most interesting results from these plots in the following three
subsections.
B.1 A cautionary tale: The boundedness of the Œ±-divergence (D(Œ±)
A )
Of the alternative divergences to the KLD contained within the D(Œ±,Œ≤,r)
G
family deÔ¨Åned in
Appendix A, D(Œ±)
A
is arguably the most well known. Our results in Figure 14 show that
in spite of its popularity in other contexts, the D(Œ±)
A
is not a reliable uncertainty quantiÔ¨Åer
59

Knoblauch, Jewson and Damoulas
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
hyperparameter value
0
10
20
30
40
50
magnitude of D(q| )
D =
-divergence (D( )
A )
KLD
Figure 15: A comparison of the size of D(Œ±)
A
for various values of Œ± between two bivariate
Normal Inverse Gamma distributions with an = 512, bn = 543, ¬µn = (2.5, 2.5), Vn =
diag(0.3, 2) and a0 = 500, b0 = 500, ¬µ0 = (0, 0), V0 = diag(25, 2).
within GVI, at least for Œ± ‚àà(0, 1). In particular, the plot shows that the solutions to
P(‚Ñì, D(Œ±)
A , Q) can produce essentially degenerate posteriors if Œ± ‚àà(0, 1). Note also that this
happens in spite of the relatively small sample size of n = 25. For example, when Œ± = 0.5,
P(‚Ñì, D(Œ±)
A , Q) is visually indistinguishable from a point mass at the maximum likelihood
estimate. This is a consequence of the boundedness of D(Œ±)
A
for Œ± ‚àà(0, 1): SpeciÔ¨Åcally, it
holds that D(Œ±)
A
‚â§(Œ±(1 ‚àíŒ±))‚àí1 for Œ± ‚àà(0, 1). As Œ± decreases from 1, this upper-bound
initially also decreases until reaching its minimum for Œ± = 0.5. As a result, decreasing Œ±
from unity to 0.5 signiÔ¨Åcantly decreases the maximal penalty for posterior beliefs far from
the prior. In turn, this forces the posterior to focus mostly on minimising the in-sample loss.
This phenomenon is depicted in Figure 15, which also shows that the divergence magnitude
increases again as Œ± approaches zero or if Œ± > 1. Comparing the plot with that in Figure
7, it is clear why hyperparameter selection for the other members of the D(Œ±,Œ≤,r)
G
family of
divergences is a less complicated endeavour than for the Œ±-divergence. This does not mean
that the D(Œ±)
A
cannot be used for producing GVI posteriors: For example, in Figure 14, the
D(Œ±)
A
is able to achieve marginal variances that more closely correspond to the exact posterior
for Œ± = 1.25 and Œ± = 0.01. Generally speaking, for values of Œ± close to zero or above
unity, it is possible to achieve more conservative uncertainty quantiÔ¨Åcation. Yet, the D(Œ±)
A
also functions primarily as a cautionary tale: Without understanding the properties of the
uncertainty quantiÔ¨Åer D suÔ¨Éciently well, GVI may well yield unsatisfactory posteriors.
B.2 Larger divergences produce larger marginal variances
In this section, we summarize the impact that a selection of robust divergences have on the
marginal variances of the solution to P(‚Ñì, D, Q), again using the Bayesian Linear regression
model from before. For a range of robust divergences, Figure 16 illustrates the impact that
60

Generalized Variational Inference
changes in D have on the marginal variances of the resulting posteriors. As one should expect
from re-examining Figure 7, the plot shows that D(Œ≤)
B , D(Œ±)
AR and D(Œ≥)
G
are able to produce
larger posterior variances for Œ≤, Œ±, Œ≥ < 1 and smaller posterior variances for Œ≤, Œ±, Œ≥ > 1. This
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
Density
D = w
1 KLD
Exact posterior
w = 2.0
Standard VI
w = 0.5
w = 0.125
MLE
D = Renyi's -divergence (D( )
AR)
Exact posterior
= 1.25
Standard VI
= 0.5
= 0.025
MLE
0
1
2
3
4
5
1
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
Density
D = -divergence (DG)
Exact posterior
= 1.5
Standard VI
= 0.75
= 0.15
MLE
0
1
2
3
4
5
1
D =
-divergence (DB)
Exact posterior
= 1.5
Standard VI
= 0.75
= 0.5
MLE
Figure 16: Best viewed in color. Marginal VI and GVI posterior for the Ô¨Årst coeÔ¨Écient of a
Bayesian linear model under the D(Œ±)
AR, D(Œ≤)
B , D(Œ≥)
G and
1
wKLD prior regularizers for diÔ¨Äerent
uncertainty quantiÔ¨Åers. Correlated covariates cause dependency in the exact Bayesian
posterior of the coeÔ¨Écients and as a result VI underestimates marginal variances. GVI
has the Ô¨Çexibility to produce wider marginal variances. Prior SpeciÔ¨Åcation: œÉ2 ‚àºIG(20, 50),
Œ∏1 ‚àºN(0, 52) and Œ∏2 ‚àºN(0, 52).
61

Knoblauch, Jewson and Damoulas
is a manifestation of the posterior being penalized more heavily (Œ≤, Œ±, Œ≥ < 1) or less heavily
(Œ≤, Œ±, Œ≥ > 1) for deviating from the prior than under the traditional VI. It follows that by
choosing the divergence appropriately, GVI can allow greater control over the uncertainty
quantiÔ¨Åcation characteristics of the resulting posterior than what is possible under standard
VI. Note that Figure 16 also compares the robust divergences against the re-weighted
KLD. While the re-weighted KLD can prove a successful alternative for producing desirable
variational posteriors with larger variances robust divergences if the prior is well-speciÔ¨Åed,
this is no longer the case if the information contained in the prior cannot be relied upon. We
study this and related Ô¨Åndings surrounding robustness to the prior in the next section.
B.3 Robustness to the prior
Next, we compare the impact of changing the uncertainty quantiÔ¨Åer on the posterior‚Äôs
sensitivity to appropriate speciÔ¨Åcation of the prior. SpeciÔ¨Åcally, we consider and compare
D(Œ≤)
B , D(Œ±)
AR, D(Œ≥)
G
and
1
w KLD. When comparing
1
w KLD with D(Œ±)
AR and D(Œ≥)
G , we Ô¨Åxed Œ± = Œ≥ = w.
Setting the values of these various hyperparameters to be the same is intuitively appealing
for comparison due to GVI‚Äôs interpretation as approximate Evidence Lower Bound (ELBO),
see Theorems 24 and 40. For the D(Œ≤)
B , diÔ¨Äerent values of Œ≤ had to be selected to ensure its
availability in a closed form.
B.3.1 weighted KLD ( 1
w KLD)
Figure 17 examines how changing the weight w aÔ¨Äects the posteriors P(‚Ñì, 1
w KLD, Q). Notice
that this is equivalent to changing the negative log likelihood to a power likelihood with power
w. Further, it should be clear that choosing w < 1 leads to posteriors that encourage larger
variances, making them amenable to conservative uncertainty quantiÔ¨Åcation. Unfortunately
and again unsurprisingly, this comes at the price of making posteriors more sensitive to the
prior: After all, one up-weights the term penalizing deviations from the prior. Conversely,
w > 1 will result in posteriors that are less sensitive to the prior than standard VI. At the
same time, they will also be more concentrated around the Maximum Likelihood Estimator.
This makes D =
1
w KLD less attractive than it could be: Setting w to smaller values will yield
larger posteriors variances (at the expense of not being robust to the prior), while setting
w to larger values will make the posterior more robust to misspeciÔ¨Åed priors (but at the
expense of far more concentrated posteriors). As we shall see, this undesirable trade-oÔ¨Äis
not shared by the other (robust) divergences considered in this section. Unlike the
1
w KLD,
they often provide a way to have your cake and eat it, too.
B.3.2 R√©nyi‚Äôs Œ±-divergence (D(Œ±)
AR)
Figure 18 demonstrates the sensitivity of P(‚Ñì, D(Œ±)
AR, Q) to prior speciÔ¨Åcation. For 0 < Œ± < 1,
the posterior exhibits the kind of behaviour that is diÔ¨Écult to attain with standard VI: It
both produces larger marginal variances and is robust to badly speciÔ¨Åed priors. This is no
longer true if Œ± > 1: For Œ± > 1, D(Œ±)
AR ‚â§KLD, so that it is more sensitive to the prior than
the KLD. This Ô¨Çip in robustness as Œ± crosses from (0, 1) into values larger than one may
seem strange, but can be understood by investigating the form of the D(Œ±)
AR:
D(Œ±)
AR(q(Œ∏)||œÄ(Œ∏)) =
1
Œ±(Œ± ‚àí1) log
Z
q(Œ∏)Œ±œÄ(Œ∏)1‚àíŒ±dŒ∏ =
1
Œ±(Œ± ‚àí1) log
Z
q(Œ∏)Œ±
œÄ(Œ∏)Œ±‚àí1 dŒ∏.
62

Generalized Variational Inference
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Density
D = w
1 KLD w = 1.25
= 3.0
= -5.0
= -20.0
= -50.0
MLE
D = w
1 KLD w = 1
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Density
D = w
1 KLD w = 0.75
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
D = w
1 KLD w = 0.5
= 3.0
= -5.0
= -20.0
= -50.0
MLE
Figure 17: Best viewed in color. Marginal VI and GVI posterior for the coeÔ¨Écient of a
Bayesian linear model under diÔ¨Äerent priors using D =
1
w KLD as uncertainty quantiÔ¨Åer
( 1
w KLD recovers KLD for w = 1). The prior speciÔ¨Åcation is given by Œ∏1|œÉ2 ‚àºN(¬µœÄ, œÉ2) with
œÉ2 ‚àºIG(3, 5).
63

Knoblauch, Jewson and Damoulas
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Density
D = Renyi's -divergence (D( )
AR) 
= 1.25
= 3.0
= -5.0
= -20.0
= -50.0
MLE
D = Renyi's -divergence (D( )
AR) 
= 1
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Density
D = Renyi's -divergence (D( )
AR) 
= 0.75
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
D = Renyi's -divergence (D( )
AR) 
= 0.5
= 3.0
= -5.0
= -20.0
= -50.0
MLE
Figure 18: Best viewed in color. Marginal VI and GVI posterior for the coeÔ¨Écient of
a Bayesian linear model under diÔ¨Äerent priors using D = D(Œ±)
AR as uncertainty quantiÔ¨Åer
(D(Œ±)
AR recovers KLD as Œ± ‚Üí1). The prior speciÔ¨Åcation is given by Œ∏1|œÉ2 ‚àºN(¬µœÄ, œÉ2) with
œÉ2 ‚àºIG(3, 5).
64

Generalized Variational Inference
It is clear that the magnitude of the divergence is determined by a ratio of two densities.
Glancing closer, for Œ± > 1 this means that if q(Œ∏) is large in an area where œÄ(Œ∏) is not, then
a severe penalty is incurred. This limits how far the q(Œ∏) can move from the prior and thus
results in lack of prior robustness. Conversely, if Œ± ‚àà(0, 1), then œÄ(Œ∏)Œ±‚àí1 > œÄ(Œ∏) for regions
where œÄ(Œ∏) < 1, which allows the posterior to spread its mass in a less concentrated way
than for Œ± > 1. In fact, this very Ô¨Ånding is also implicitly stated in Theorem 24.
B.3.3 Œ≤-divergence (D(Œ≤)
B )
Figure 19 demonstrates the sensitivity of P(‚Ñì, D(Œ≤)
B , Q) to prior speciÔ¨Åcation. The plot shows
that Œ≤ > 1 is able to achieve extreme robustness to the prior, while Œ≤ < 1 causes extreme
sensitivity to the prior. This phenomenon is a result of the fact that the D(Œ≤)
B decomposes into
three integrals, one containing just the prior, one containing just q(Œ∏) and one containing an
interaction between them.
D(Œ≤)
B (q(Œ∏)||œÄ(Œ∏)) = 1
Œ≤
Z
œÄ(Œ∏)Œ≤dŒ∏ ‚àí
1
Œ≤ ‚àí1
Z
œÄ(Œ∏)Œ≤‚àí1q(Œ∏)dŒ∏ +
1
Œ≤(Œ≤ ‚àí1)
Z
q(Œ∏)Œ≤dŒ∏ (22)
The integral depending only on the prior does not depend q(Œ∏), so we can ignore it (since the
prior is Ô¨Åxed across the diÔ¨Äerent values of Œ≤). If Œ≤ increases substantially above 1, the second
term which expresses an interaction between œÄ(Œ∏) and q(Œ∏) will have a relatively smaller
weight in the optimisation than the term only involving q(Œ∏). As a result, the optimisation
will focus on decreasing
R
qŒ≤(Œ∏)dŒ∏ rather than increasing
R
œÄŒ≤‚àí1(Œ∏)q(Œ∏)dŒ∏. We note that
this is closely linked to the so-called ignorance to the data phenomenon as discussed in
Jewson et al. (2018). The uncertainty quantiÔ¨Åcation for large values of Œ≤ is therefore largely
controlled by the third term, which only depends on q(Œ∏). This third integral will become
very large if the variance of q(Œ∏) gets very small, which prevents it from quickly converging
to a point mass at the maximuml likelihood estimate. As a consequence, the D(Œ≤)
B
is able to
provide virtually prior-invariant uncertainty quantiÔ¨Åcation for beta > 1. For Œ≤ ‚àà(0, 1), the
opposite eÔ¨Äect is observed: Here, the third integral term depending only on q(Œ∏) has smaller
weight relative to the interaction between œÄ(Œ∏) and q(Œ∏) given by
R
œÄŒ≤‚àí1(Œ∏)q(Œ∏)dŒ∏. As a
result, the corresponding posterior will be very close to the prior. (In fact, notice that that
two of the four posteriors for Œ≤ = 0.75 favour the prior so much that the density around the
maximum likelihood estimate is virtually zero.)
B.3.4 Œ≥-divergence (D(Œ≥)
G )
Lastly, Fig. 20 demonstrates the sensitivity of P(‚Ñì, D(Œ≥)
G , Q) to prior speciÔ¨Åcation. For Œ≥ < 1
it appears as though the D(Œ≥)
G reacts similarly to the
1
w KLD for w < 1. The D(Œ≥)
G with Œ≥ > 1
produces greater robustness to the prior than the
1
w KLD uncertainty quantiÔ¨Åer with w > 1,
but this robustness is less extreme as it was for D = D(Œ≤)
B . The reason for this is that although
the D(Œ≥)
G consists of the same three integral terms as the D(Œ≤)
B , these terms are now transformed
into the logarithmic scale. This means that the three integrals are combined multiplicatively
(in the D(Œ≥)
G ) rather than additively (in the D(Œ≤)
B ), which makes the variation across Œ≥ much
smoother than across Œ≤: Unlike for the D(Œ≤)
B , minimising the D(Œ≥)
G no longer disregards any
one term in order to minimise the others.
65

Knoblauch, Jewson and Damoulas
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
Density
D =
-divergence (DB) 
= 1.25
= 3.0
= -5.0
= -20.0
= -50.0
MLE
D =
-divergence (DB) 
= 1
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
Density
D =
-divergence (DB) 
= 0.9
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
D =
-divergence (DB) 
= 0.75
= 3.0
= -5.0
= -20.0
= -50.0
MLE
Figure 19: Best viewed in color. Marginal VI and GVI posterior for the coeÔ¨Écient of
a Bayesian linear model under diÔ¨Äerent priors using D = D(Œ≤)
B
as uncertainty quantiÔ¨Åer
(D(Œ≤)
B
recovers KLD as Œ≤ ‚Üí1). The prior speciÔ¨Åcation is given by Œ∏1|œÉ2 ‚àºN(¬µœÄ, œÉ2) with
œÉ2 ‚àºIG(3, 5).
66

Generalized Variational Inference
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
Density
D = -divergence (DG) = 1.25
= 3.0
= -5.0
= -20.0
= -50.0
MLE
D = -divergence (DG) = 1
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
Density
D = -divergence (DG) = 0.75
= 3.0
= -5.0
= -20.0
= -50.0
MLE
1
0
1
2
3
4
5
1
D = -divergence (DG) = 0.5
= 3.0
= -5.0
= -20.0
= -50.0
MLE
Figure 20: Best viewed in color. Marginal VI and GVI posterior for the coeÔ¨Écient of
a Bayesian linear model under diÔ¨Äerent priors using D = D(Œ≥)
G
as uncertainty quantiÔ¨Åer
(D(Œ≥)
G
recovers KLD as Œ≥ ‚Üí1). The prior speciÔ¨Åcation is given by Œ∏1|œÉ2 ‚àºN(¬µœÄ, œÉ2) with
œÉ2 ‚àºIG(3, 5).
67

Knoblauch, Jewson and Damoulas
Appendix C. Proof of Theorem 18
Before we can prove Theorem 18, we Ô¨Årst formally deÔ¨Åne the notion of robustness to model
misspeciÔ¨Åcation. Our understanding of robustness to model misspeciÔ¨Åcation is aligned with
Hampel et al. (2011) and Tukey (1960). In the words of the latter, robustness stands for
a tacit hope in ignoring deviations from ideal models was that they would not matter;
that statistical procedures which are optimal under the strict model would still be
approximately optimal under the approximate model. Unfortunately, it turned out that
this hope was often drastically wrong; even mild deviations often have much larger
eÔ¨Äects than were anticipated by most statisticians.
Formalizing this, we arrive at the following deÔ¨Ånition.
DeÔ¨Ånition 36 (Robustness) Let Mj = P(Dj, ‚Ñìj, Œ†) with Œ∏‚àó
j = arg minŒ∏ {EX [‚Ñìj(Œ∏, X)]}
for j = 1, 2. Then, M1 is more robust for Œ∏ than M2 relative to the (implicit) assumptions
A on the data generating mechanism of X if (i) Œ∏‚àó
1 is a better result than Œ∏‚àó
2 if A is untrue
and (ii) Œ∏‚àó
1 = Œ∏‚àó
2 if A is true.
Remark 37 It is hard to say what a better result means, but we note that regardless of
its precise meaning, this deÔ¨Ånition requires that robust inference directly aÔ¨Äects Œ∏‚àó, i.e.
that Œ∏‚àó
1 Ã∏= Œ∏‚àó
2 unless A is true. While one could substantially strengthen this deÔ¨Ånition by
formalizing what exactly a better result means, this would necessarily be context-dependent,
complicate matters substantially and obfuscate the point of robustness.
Proof
First, we prove claim (i) about robustness to model misspeciÔ¨Åcation: By Def-
inition 36, robustness implies a change in Œ∏‚àó= arg minŒ∏ {EX [‚Ñì(Œ∏, X)]} if distributional
assumptions about X are incorrect.
Notice that Œ∏‚àóis not aÔ¨Äected by D or Œ†, but is
aÔ¨Äected by ‚Ñì.
Next, we turn to the claims (ii) and (iii) about uncertainty quantiÔ¨Å-
cation and prior robustness: First, note that Œ† and œÄ are not allowed to change by
assumption and so cannot aÔ¨Äect uncertainty quantiÔ¨Åcation. Next, while ‚Ñìis allowed to
change, the parameter of interest it not allowed to change. In other words, ‚Ñìmay only
be changed in a ways that leave ÀÜŒ∏n and Œ∏‚àóunaÔ¨Äected. Notice that changing ‚Ñìto ‚Ñì‚Ä≤ will
aÔ¨Äect ÀÜŒ∏n = arg minŒ∏
 1
n
Pn
i=1 ‚Ñì(Œ∏, xi)
	
and Œ∏‚àó= EX [‚Ñì(Œ∏, x)] unless ‚Ñì‚Ä≤ = C + w ¬∑ ‚Ñìfor some
constants C and w > 0. Since P(‚Ñì, D, Œ†) = P(‚Ñì+ C, D, Œ†) for any C by Axiom II, we can
disregard C and turn to w. Indeed, the uncertainty quantiÔ¨Åcation of P(‚Ñì, D, Œ†) will be
diÔ¨Äerent from that of P(w ¬∑ ‚Ñì, D, Œ†) for any constant w Ã∏= 1. However, dividing by w in eq.
(10) shows that P(w ¬∑ ‚Ñì, D, Œ†) = P(‚Ñì, 1
wD, Œ†). Hence, any change in the loss that does not
aÔ¨Äect ÀÜŒ∏n and Œ∏‚àócan be rewritten as a change in D. It follows that changing the uncertainty
quantiÔ¨Åcation or making the RoT robust to the prior belief must amount to changing D.
Appendix D. Proof of Theorem 24 and additional lower bounds
This section of the Appendix provides proofs for the lower bound interpretation of certain
GVI objectives. First, we prove the result stated in the main paper. Next, we show equivalent
results for the case of the Œ≤-divergence (D(Œ≤)
B ) and Œ≥-divergence (D(Œ≥)
G ). While the following
68

Generalized Variational Inference
results and corresponding proofs are somewhat tedious to read, they are conceptually simple:
In fact, all that is needed to derive the results is some basic algebra, Jensen‚Äôs inequality and
a further inequality involving the logarithm, see Lemma 38.
D.1 Proof for D(Œ±)
AR (Theorem 24)
Firstly, we provide explicit forms for the function quoted in Theorem 24
S1(Œ±, q, œÄ) =
(
D(Œ±)
AR(q(Œ∏)||œÄ(Œ∏) ‚àíKLD(q(Œ∏)||œÄ(Œ∏))
if 0 < Œ± < 1
0
if Œ± > 1.
(23)
Next we provide a proof of the Theorem
Proof For this proof we have to consider two cases for Œ± as the positivity and negativity of
Œ± ‚àí1 aÔ¨Äect the results that can be used.
Case 1) Œ± > 1: Jensen‚Äôs inequality and the concavity of the natural logarithm give us that
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ±(Œ± ‚àí1) log Eq(Œ∏)
" q(Œ∏)
œÄ(Œ∏)
Œ±‚àí1#
‚â•Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ 1
Œ±Eq(Œ∏)

log
 q(Œ∏)
œÄ(Œ∏)

= 1
Œ±
KLD(q(Œ∏)||œÄŒ±‚Ñì(Œ∏|x)) ‚àí1
Œ± log
Z
œÄ(Œ∏) exp
 
‚àíŒ±
n
X
i=1
‚Ñì(Œ∏, xi)
!
dŒ∏.
Case 2) 0 < Œ± < 1: Here the negativity of
1
Œ±(Œ±‚àí1) means we cannot apply Jensen‚Äôs inequality
in the above way. Instead, we can write
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(Œ±)
AR(q(Œ∏)||œÄ(Œ∏))
= Eq(Œ∏) [log(œÄ(Œ∏))] ‚àíEq(Œ∏)

log

œÄ(Œ∏) exp(‚àíPn
i=1 ‚Ñì(Œ∏, xi))
R
œÄ(Œ∏) exp(‚àíPn
i=1 ‚Ñì(Œ∏, xi))dŒ∏

‚àílog
Z
œÄ(Œ∏) exp(‚àí
n
X
i=1
‚Ñì(Œ∏, xi))dŒ∏ + D(Œ±)
AR(q(Œ∏)||œÄ(Œ∏))
= KLD(q(Œ∏)||œÄ‚Ñì(Œ∏|x)) ‚àílog
Z
œÄ(Œ∏) exp(‚àí
n
X
i=1
‚Ñì(Œ∏, xi))dŒ∏
+D(Œ±)
AR(q(Œ∏)||œÄ(Œ∏)) ‚àíKLD(q(Œ∏)||œÄ(Œ∏)).
Combined these two cases provides the term in Eq. (13) and (23)
Next we state, prove and interpret equivalent results for the D(Œ≤)
B
and D(Œ≥)
G
prior regularisers.
But before we do so we need the following lemma
Lemma 38 (A Taylor series bound for the natural logarithm) The natural logarithm
of a positive real number Z can be bounded as follows
(
log(Z) ‚â§Zx‚àí1
x
if x > 0
log(Z) ‚â•Zx‚àí1
x
if x < 0.
69

Knoblauch, Jewson and Damoulas
Proof Using the series expansion of exp(x) and the Lagrange form of the remainder we see
that
Zx ‚àí1
x
= exp (x log Z) ‚àí1
x
= (x log Z) + 1
2! (x log Z)2 + 1
3! (x log Z)3 + . . .
x
= (x log Z) + 1
2 exp(c) (x log Z)2
x
= log Z +
1
2! exp(c) (x log Z)2
x
where c ‚àà[0, x log(Z)]. Now the numerator of the remainder term
1
2! exp(c)(x log Z)2
x
is always
positive and therefore the sign of x determines whether this remainder term forms an upper
or lower bound for log(Z).
D.2 The D(Œ≤)
B
prior regulariser
Theorem 39 (GVI as approximate Evidence Lower bound with D = D(Œ≤)
B ) The ob-
jective of a GVI posterior based on P(‚Ñì, D(Œ≤)
B , Q) has an interpretation as lower bound on the
c(Œ≤)-scaled (generalized) evidence lower bound of P(w(Œ≤) ¬∑ ‚Ñì, KLD, P(Œò)):
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(Œ≤)
B (q(Œ∏)||œÄ(Œ∏)) ‚â•‚àíc(Œ≤)ELBOw(Œ≤)‚Ñì(q) + S1(Œ≤, q, œÄ)
(24)
where ELBOw(Œ≤)‚Ñìdenotes the Evidence Lower Bound associated with standard VI relative to
the generalized Bayesian posterior given by
qw(Œ≤)‚Ñì
B
(Œ∏) ‚àùœÄ(Œ∏) exp
 
‚àíw(Œ≤)
n
X
i=1
‚Ñì(Œ∏, xi)
!
,
where c(Œ≤) = min{1, Œ≤‚àí1}, w(Œ≤) = max{1, Œ≤} and where S1(Œ≤, q, œÄ) is a closed form slack
term with
S1(Œ≤, q, œÄ) =
(
1
Œ≤(Œ≤‚àí1)Eq(Œ∏)

q(Œ∏)Œ≤‚àí1
‚àíEq(Œ∏) [log q(Œ∏)] ‚àí
1
Œ≤‚àí1
if 0 < Œ≤ < 1
1
Œ≤Eq(Œ∏) [log œÄ(Œ∏)] ‚àí
1
Œ≤‚àí1Eq(Œ∏)

œÄ(Œ∏)Œ≤‚àí1
‚àí
1
Œ≤(Œ≤‚àí1)
if Œ≤ > 1.
(25)
Proof Firstly we note that the objective function associated with the RoT P(D(Œ≤)
B , ‚Ñìn, Q)
can be simpliÔ¨Åed by removing the terms in the D(Œ≤)
B
that don‚Äôt depend on q(Œ∏)
arg min
q‚ààQ
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(Œ≤)
B (q(Œ∏)||œÄ(Œ∏))
)
=arg min
q‚ààQ
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ≤(Œ≤ ‚àí1)Eq(Œ∏)
h
q(Œ∏)Œ≤‚àí1i
‚àí
1
(Œ≤ ‚àí1)Eq(Œ∏)
h
œÄ(Œ∏)Œ≤‚àí1i)
.
We have to consider two cases for Œ≤ as the positivity and negativity of Œ≤ ‚àí1 aÔ¨Äect which
part of Lemma 38 we use.
70

Generalized Variational Inference
Case 1) 0 < Œ≤ < 1: Lemma 38 gives us that for Œ≤ ‚àí1 < 0, ZŒ≤‚àí1
Œ≤‚àí1 ‚â§log(Z) +
1
Œ≤‚àí1 therefore
= Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ≤(Œ≤ ‚àí1)Eq(Œ∏)
h
q(Œ∏)Œ≤‚àí1i
‚àí
1
(Œ≤ ‚àí1)Eq(Œ∏)
h
œÄ(Œ∏)Œ≤‚àí1i
‚â•Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ≤(Œ≤ ‚àí1)Eq(Œ∏)
h
q(Œ∏)Œ≤‚àí1i
‚àíEq(Œ∏) [log(œÄ(Œ∏))] ‚àí
1
Œ≤ ‚àí1
= KLD(q(Œ∏)||œÄ‚Ñì(Œ∏|x)) ‚àílog
Z
exp(‚àí
n
X
i=1
‚Ñì(Œ∏, xi))œÄ(Œ∏)dŒ∏
+
1
Œ≤(Œ≤ ‚àí1)Eq(Œ∏)
h
q(Œ∏)Œ≤‚àí1i
‚àíEq(Œ∏) [log(q(Œ∏))] ‚àí
1
Œ≤ ‚àí1.
Case 2) Œ≤ > 1: Lemma 38 gives us that for Œ≤ ‚àí1 > 0, ZŒ≤‚àí1
Œ≤‚àí1 ‚â•log(Z) +
1
Œ≤‚àí1 therefore
= Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ≤(Œ≤ ‚àí1)Eq(Œ∏)
h
q(Œ∏)Œ≤‚àí1i
‚àí
1
(Œ≤ ‚àí1)Eq(Œ∏)
h
œÄ(Œ∏)Œ≤‚àí1i
‚â•Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ 1
Œ≤

Eq(Œ∏)

log

q(Œ∏)œÄ(Œ∏)
œÄ(Œ∏)

+
1
Œ≤ ‚àí1

‚àí
1
(Œ≤ ‚àí1)Eq(Œ∏)
h
œÄ(Œ∏)Œ≤‚àí1i
= 1
Œ≤
KLD(q(Œ∏)||œÄŒ≤‚Ñì(Œ∏|x)) ‚àí1
Œ≤ log
Z
œÄ(Œ∏) exp(‚àíŒ≤
n
X
i=1
‚Ñì(Œ∏, xi))dŒ∏
+ 1
Œ≤ Eq(Œ∏) [log(œÄ(Œ∏))] ‚àí
1
(Œ≤ ‚àí1)Eq(Œ∏)
h
œÄ(Œ∏)Œ≤‚àí1i
+
1
Œ≤(Œ≤ ‚àí1).
Combined these two cases provides the term in Eq. (24) and (25)
D.3 The D(Œ≥)
G
prior regulariser
Theorem 40 (GVI as approximate Evidence Lower bound with D = D(Œ≥)
G ) The ob-
jective of a GVI posterior based on P(‚Ñì, D(Œ≥)
G , Q) has an interpretation as lower bound on the
c(Œ≥)-scaled (generalized) evidence lower bound of P(w(Œ≥) ¬∑ ‚Ñì, KLD, P(Œò)):
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(Œ≥)
G (q(Œ∏)||œÄ(Œ∏)) = ‚àíc(Œ≥)ELBOw(Œ≥)‚Ñì(q) + S(Œ≥, q, œÄ)
(26)
where ELBOw(Œ≥)‚Ñìdenotes the Evidence Lower Bound associated with standard VI relative to
the generalized Bayesian posterior given by
qw(Œ≥)‚Ñì
B
(Œ∏) ‚àùœÄ(Œ∏) exp
 
‚àíw(Œ≥)
n
X
i=1
‚Ñì(Œ∏, xi)
!
,
where c(Œ≥) = min{1, Œ≥‚àí1}, w(Œ≥) = max{1, Œ≥} and where S1(Œ≥, q, œÄ) is a closed form slack
term with
S1(Œ≥, q, œÄ) =
(
1
Œ≥(Œ≥‚àí1) log Eq(Œ∏)

q(Œ∏)Œ≥‚àí1
‚àíEq(Œ∏) [log q(Œ∏)]
if 0 < Œ≥ < 1
1
Œ≥ Eq(Œ∏) [log œÄ(Œ∏)] ‚àí
1
Œ≥‚àí1 log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
if Œ≥ > 1.
(27)
71

Knoblauch, Jewson and Damoulas
Proof
Firstly we note that the objective function associated with P(D(Œ≥)
G , ‚Ñìn, Q) can be
simpliÔ¨Åed by removing the terms in the D(Œ≥)
G that don‚Äôt depend on q(Œ∏)
arg min
q‚ààQ
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ D(Œ≥)
G (q(Œ∏)||œÄ(Œ∏))
)
=
arg min
q‚ààQ
(
Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ≥(Œ≥ ‚àí1) log Eq(Œ∏)

q(Œ∏)Œ≥‚àí1
‚àí
1
(Œ≥ ‚àí1) log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
)
.
We have to consider two cases for Œ≥ as the positivity and negativity of Œ≥ ‚àí1 aÔ¨Äect the results
we can use.
Case 1) 0 < Œ≥ < 1: Jensen‚Äôs inequality and the concavity of the natural logarithm applied
to Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
provides
= Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ≥(Œ≥ ‚àí1) log Eq(Œ∏)

q(Œ∏)Œ≥‚àí1
‚àí
1
(Œ≥ ‚àí1) log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
‚â•Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ≥(Œ≥ ‚àí1) log Eq(Œ∏)

q(Œ∏)Œ≥‚àí1
‚àíEq(Œ∏) [log œÄ(Œ∏)]
= KLD(q(Œ∏)||œÄ‚Ñì(Œ∏|x)) ‚àílog
Z
œÄ(Œ∏) exp
 
‚àí
n
X
i=1
‚Ñì(Œ∏, xi)
!
dŒ∏
+
1
Œ≥(Œ≥ ‚àí1) log Eq(Œ∏)

q(Œ∏)Œ≥‚àí1
+ ‚àíEq(Œ∏) [log q(Œ∏)] .
Case 2) Œ≥ > 1: Jensen‚Äôs inequality and the concavity of the natural logarithm applied to
Eq(Œ∏)
h
q(Œ∏)Œ≥‚àí1 œÄ(Œ∏)Œ≥‚àí1
œÄ(Œ∏)Œ≥‚àí1
i
provides
= Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+
1
Œ≥(Œ≥ ‚àí1) log Eq(Œ∏)

q(Œ∏)Œ≥‚àí1
‚àí
1
(Œ≥ ‚àí1) log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
‚â•Eq(Œ∏)
" n
X
i=1
‚Ñì(Œ∏, xi)
#
+ 1
Œ≥ Eq(Œ∏)

log q(Œ∏)œÄ(Œ∏)
œÄ(Œ∏)

‚àí
1
(Œ≥ ‚àí1) log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
= 1
Œ≥
KLD(q(Œ∏)||œÄŒ≥‚Ñì(Œ∏|x)) ‚àí1
Œ≥
Z
œÄ(Œ∏) exp
 
‚àíŒ≥
n
X
i=1
‚Ñì(Œ∏, xi)
!
dŒ∏
+1
Œ≥ Eq(Œ∏) [log œÄ(Œ∏)] ‚àí
1
(Œ≥ ‚àí1) log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
.
Combined these two cases provides the term in Eq. (26) and (27)
D.3.1 Interpretation
Theorems 39 and 40 provide a lower bound on an objective function that is to be minimised
so that interpreting this lower bound provides some insight into the behaviour of the GVI
72

Generalized Variational Inference
posterior. First, we investigate the case where the hyperparameters Œ≤ and Œ≥ are in (0, 1). As
expected, the form of the GVI objective leads us to conclude that the variance will be larger
than that for standard VI within this range of values. Next, we investigate the case where
the hyperparameters Œ≤ and Œ≥ are > 1. Again unsurprisingly, this leads to a shrinkage of the
posterior variance relative to standard VI.
Case 1: 0 < Œ≤ = Œ≥ < 1.
For 0 < Œ≤ = Œ≥ < 1 the terms c(Œ≤) = c(Œ≥) and w(Œ≤) = w(Œ≥)
produce an objective equivalent to standard VI. This suggests that GVI continues to minimise
the KLD between the variational and standard Bayesian posterior. Unlike standard VI
however, GVI with D = D(Œ≤)
B
or D = D(Œ≥)
G additionally minimises the slack terms S1(Œ≤, q, œÄ)
or S1(Œ≥, q, œÄ). It is easy to show that the these adjustment terms encourage the solution to
P(D(Œ≤)
B , ‚Ñì, Q) with 0 < Œ≤ < 1 and P(D(Œ≥)
G , ‚Ñì, Q) with 0 < Œ≥ < 1 to have greater variance than
the standard VI posterior given by P(KLD, ‚Ñìn, Q). For the D(Œ≤)
B , we can see this by rewriting
S(0,1)(Œ≤, q, œÄ) = ‚àí1
Œ≤ h(Œ≤)
T (q(Œ∏)) + hKLD(q(Œ∏)) + 1 ‚àíŒ≤
Œ≤
.
Here, hKLD(q(Œ∏)) is the Shannon entropy of q(Œ∏) and h(Œ≤)
T (q(Œ∏)) is the Tsallis entropy of q(Œ∏)
with parameter Œ≤. Again applying Lemma 38, we Ô¨Ånd that for 0 < Œ≤ < 1, h(Œ≤)
T (q(Œ∏)) >
hKLD(q(Œ∏)). It immediately follows that minimising ‚àí1
Œ≤h(Œ≤)
T (q(Œ∏))+hKLD(q(Œ∏)) for 0 < Œ≤ < 1
will make h(Œ≤)
T (q(Œ∏)) large‚Äîan eÔ¨Äect that is achieved by increasing the variance of q(Œ∏).
Applying the same type of logic to the D(Œ≥)
G , one can rewrite
S(0,1)(Œ≥, q, œÄ) = ‚àí1
Œ≥ h(Œ≥)
R (q(Œ∏)) + hKLD(q(Œ∏)).
As before, hKLD(q(Œ∏)) is the Shannon entropy of q(Œ∏), but unlike before h(Œ≥)
R (q(Œ∏)) is now the
R√©nyi entropy of q(Œ∏) with parameter Œ≥. With this, one can extend Theorem 3 in Van Erven
and Harremos (2014) to show that h(Œ≥)
R (q(Œ∏)) is decreasing in Œ≥. Since it is also well-known
that limŒ≥‚Üí1 h(Œ≥)
R (q(Œ∏)) = hKLD(q(Œ∏)), it follows that minimising ‚àí1
Œ≥ h(Œ≥)
R (q(Œ∏)) + hKLD(q(Œ∏))
for 0 < Œ≥ < 1 will make h(Œ≥)
R (q(Œ∏)) large‚Äîan eÔ¨Äect that is again achieved by increasing the
variance of q(Œ∏).
Case 2: Œ≤ = Œ≥ = k > 1.
For k = Œ≥ = Œ≤ > 1, c(k) =
1
k and w(k) = k.
Minimis-
ing KLD(q||q‚àó
k) for k > 1 will encourage P(D(Œ≤)
B , ‚Ñì, Q) or P(D(Œ≥)
G , ‚Ñì, Q) to be more concen-
trated around the empirical risk minimizer ÀÜŒ∏n of ‚Ñìthan the standard VI posterior given by
P(KLD, ‚Ñì, Q). Additionally, one can show that minimising the adjustment term also favours
shrinking the variance of q(Œ∏). To see this for the case of D(Œ≤)
B , rewrite
S(1,‚àû)(Œ≤, q, œÄ) = 1
Œ≤ Eq(Œ∏) [log(œÄ(Œ∏))] ‚àí
1
Œ≤ ‚àí1Eq(Œ∏)
h
œÄ(Œ∏)Œ≤‚àí1 ‚àí1
i
‚àí1
Œ≤ .
(28)
Applying Lemma 38 then shows that for Œ≤ > 1,
1
Œ≤ ‚àí1Eq(Œ∏)
h
œÄ(Œ∏)Œ≤‚àí1 ‚àí1
i
‚â•Eq(Œ∏) [log(œÄ(Œ∏))] ‚â•1
Œ≤ Eq(Œ∏) [log(œÄ(Œ∏))] .
From this, it follows that minimising Eq. (28) will make
1
Œ≤‚àí1Eq(Œ∏)

œÄ(Œ∏)Œ≤‚àí1
large. Fixing
œÄ(Œ∏), maximising
1
Œ≤‚àí1Eq(Œ∏)

œÄ(Œ∏)Œ≤‚àí1
plus 1
Œ≤√ó the Tsallis entropy of q(Œ∏) is equivalent to
73

Knoblauch, Jewson and Damoulas
minimising D(Œ≤)
B (q(Œ∏)||œÄ(Œ∏)). Because D(Œ≤)
B
is a divergence, this maximization would naturally
seek to choose q(Œ∏) close to œÄ(Œ∏). The Tsallis entropy term in this formulation would have
acted to increase the variance of q(Œ∏). But since we maximize only
1
Œ≤‚àí1Eq(Œ∏)

œÄ(Œ∏)Œ≤‚àí1
‚Äîi.e.
without adding the Tsallis entropy of q(Œ∏)‚Äîchoices of Œ≤ > 1 will lead to shrinking the
variance of q(Œ∏) relative to standard VI.
For the D(Œ≥)
G , Jensen‚Äôs inequality shows that for Œ≥ > 1,
1
Œ≥ ‚àí1 log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
‚â•Eq(Œ∏) [log(œÄ(Œ∏))] ‚â•1
Œ≥ Eq(Œ∏) [log(œÄ(Œ∏))] .
As a result, minimising S(1,‚àû)(Œ≥, q, œÄ) will seek to make
1
Œ≥‚àí1 log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
large. Fixing
again œÄ(Œ∏), maximising
1
Œ≥‚àí1 log Eq(Œ∏)

œÄ(Œ∏)Œ≤‚àí1
plus 1
Œ≥ √ó the R√©nyi entropy of q(Œ∏) is equiva-
lent to minimising D(Œ≥)
G (q(Œ∏)||œÄ(Œ∏)), and thus seeks q(Œ∏) close to œÄ(Œ∏). The R√©nyi entropy
term would have acted to increase the variance of q(Œ∏). Therefore and similarly to the case
of D(Œ≤)
B , maximising
1
Œ≥‚àí1 log Eq(Œ∏)

œÄ(Œ∏)Œ≥‚àí1
without adding the R√©nyi entropy will lead to
shrinkage of the variance of q(Œ∏).
Appendix E. Proof of Proposition 26
Proof Proposition 26 considers the following forms of the prior and likelihood
œÄ(Œ∏|Œ∫0) = h(Œ∏) exp

Œ∑(Œ∫0)T T(Œ∏) ‚àíA(Œ∑(Œ∫0))
	
q(Œ∏|Œ∫) = h(Œ∏) exp

Œ∑(Œ∫)T T(Œ∏) ‚àíA(Œ∑(Œ∫))
	
p(x|Œ∏) = h(Œ∏) exp(g(x)T T(Œ∏) ‚àíB(x)),
where A(Œ∑(Œ∫)) = log
R
h(Œ∏) exp

Œ∑(Œ∫)T T(Œ∏))
	
dŒ∏ and h(Œ∏) =
1
R
exp(g(x)T T(Œ∏)‚àíB(x))dx.
The GVI objective function in this scenario, which we term an ELBO as we use the KLD
prior regulariser is
ELBO(Œ∫) = Eq(Œ∏|Œ∫)
" n
X
i=1
‚Ñì(Œ≥)
G (Œ∏, xi)
#
+ KLD(q(Œ∏|Œ∫)||q(Œ∏|Œ∫0))
=
n
X
i=1
Z
‚Ñì(Œ≥)
G (Œ∏, xi)
|
{z
}
C1(Œ∫,Œ∏,xi)
q(Œ∏|Œ∫)dŒ∏
|
{z
}
C2(Œ∫,xi)
+ KLD(q(Œ∏|Œ∫)||œÄ(Œ∏|Œ∫0))
|
{z
}
C3(Œ∫,Œ∫0)
.
We have decomposed this into three terms that we need to check are closed forms of Œ∫.
Firstly
C1(Œ∫, Œ∏, xi) = ‚Ñì(Œ≥)
G (xi, Œ∏) = ‚àí
1
Œ≥ ‚àí1p(xi; Œ∏)Œ≥‚àí1
Œ≥
R
p(z; Œ∏)Œ≥dz
 Œ≥‚àí1
Œ≥
,
and in order for this to be a closed form function of Œ∫, Œ∏, and xi requires that
I(Œ≥)(Œ∏) =
Z
p(z|Œ∏)Œ≥dz =
Z
h(Œ∏)Œ≥ exp(Œ≥g(z)T T(Œ∏) ‚àíŒ≥B(z))dz,
74

Generalized Variational Inference
where the theorem statement ensures that I(Œ≥)(Œ∏) is a closed form function of Œ∏. Next
C2(Œ∫, xi)
= ‚àí
Œ≥
Œ≥ ‚àí1
Z
h(Œ∏)Œ≥‚àí1 exp((Œ≥ ‚àí1)g(xi)T T(Œ∏) ‚àí(Œ≥ ‚àí1)B(xi))
1

h(Œ∏)Œ≥I(Œ≥)(Œ∏)
 Œ≥‚àí1
Œ≥
q(Œ∏|Œ∫)dŒ∏
= ‚àí
Œ≥
Œ≥ ‚àí1
exp ((1 ‚àíŒ≥)B(xi) + A (Œ∑(Œ∫) + (Œ≥ ‚àí1)g(xi)))
exp (A(Œ∑(Œ∫)))
Eq(Œ∏|(Œ∑(Œ∫)+(Œ≥‚àí1)g(xi)))
h
I(Œ≥)(Œ∏)
1‚àíŒ≥
Œ≥
i
,
where the theorem statement ensures that (Œ∑(Œ∫n) + (Œ≥ ‚àí1)g(xi)) ‚ààN for all xi and that
F2(Œ∫‚àó) = Eq(Œ∏|Œ∫‚àó)
h
I(Œ≥)(Œ∏)
1‚àíŒ≥
Œ≥
i
is closed form function of Œ∫‚àófor all Œ∫‚àó‚ààN. Lastly
C3(Œ∫, Œ∫0) =
Z
h(Œ∏) exp

Œ∑(Œ∫)T T(Œ∏) ‚àíA(Œ∑(Œ∫))
	
log h(Œ∏) exp

Œ∑(Œ∫)T T(Œ∏) ‚àíA(Œ∑(Œ∫))
	
h(Œ∏) exp {Œ∑(Œ∫0)T T(Œ∏) ‚àíA(Œ∑(Œ∫0))}dŒ∏
=A(Œ∑(Œ∫0)) ‚àíA(Œ∑(Œ∫)) + (Œ∑(Œ∫) ‚àíŒ∑(Œ∫0))T Eq(Œ∏|Œ∫) [T(Œ∏)] ,
where the theorem statement ensures that F1(Œ∫‚àó) = Eq(Œ∏|Œ∫‚àó) [T(Œ∏)] is a closed form function
of Œ∫‚àófor all Œ∫‚àó‚ààN .
Appendix F. Black Box GVI (BBGVI)
The following sections Ô¨Årst recall the (implicit and explicit) assumptions one typically makes
for black box VI. They are then compared to assumptions that are reasonable for black box
GVI (BBGVI). The corresponding methods, their special cases and the relevant black box
variance reduction techniques are then derived and elaborated upon. While there are many
black box VI strategies, we center attention on the framework provided for by Ranganath
et al. (2014). Throughout, we denote q(Œ∏) = q(Œ∏|Œ∫) as a posterior distribution in a set of
variational families Q and parameterized by some parameter Œ∫ ‚ààK.
F.1 Preliminaries and assumptions
The variance reduction techniques of Ranganath et al. (2014) crucially rely on three implicit
assumptions that are reasonable for many applications of standard VI.
(A1) Structured mean-Ô¨Åeld variational inference is used, which means that we can factorize
the variational family as Q = {q(Œ∏|Œ∫) = Qk
j=1 qj(Œ∏j|Œ∫j) : Œ∫j ‚ààKj for all j}.
(A2) For all factors Œ∏j, we have a Markov blanket Œ∏(j) for which we can additively decompose
‚Ñì(Œ∏, xi) = ‚Ñì(j)(Œ∏j, Œ∏(j), xi) + ‚Ñì(‚àíj)(Œ∏‚àíj, xi). Here, ‚Ñì(j) is an additive component of the
loss ‚Ñìthat only depends on the j-th factor and its Markov blanket, while ‚Ñì(‚àíj) is
an additive component of the loss that may depend on all of Œ∏ except for its j-th
factor. Note that such additivity holds for standard VI for which the likelihood and
the prior are such that the components Œ∏j are conditionally independent. In this case,
the conditioning set is the Markov blanket.
(A3) D = 1
w ¬∑ KLD (with w = 1 for standard VI).
75

Knoblauch, Jewson and Damoulas
Note that (A1) is always satisÔ¨Åed for both standard VI and GVI, because any variational
family factorizes into at least a single factor. In contrast, note that (A2) does not even
necessarily hold for standard VI unless one imposes some conditional independence structure
on the Œ∏j. For GVI, both (A2) and (A3) do not necessarily hold. If they do however, they
can greatly simplify BBGVI or improve its numerical performance. In the remainder of this
section, we discuss diÔ¨Äerent constellations of assumptions and their consequences for BBGVI.
F.2 Standard black box VI with (A2) and (A3)
If the regularizer used is still a rescaled version of the KLD, one recovers an internally rescaled
version of the objective in (Ranganath et al., 2014). Namely, the gradient is given by
Eq(Œ∏|Œ∫)

‚àáŒ∫ log(q(Œ∏|Œ∫))

‚àí
n
X
i=1
‚Ñì(Œ∏, xi) ‚àíwœÄ(Œ∏) ‚àíw log(q(Œ∏|Œ∫))

.
and can be approximated in a smart way by sampling from q(Œ∏|Œ∫), see for instance Ranganath
et al. (2014) for details and the viable strategies for variance reduction. Next, we turn attention
to the cases that are more interesting: If (A3) does not hold (so that D Ã∏= KLD) and when the
losses are not necessarily negative log likelihoods, meaning that (A2) requires more careful
consideration.
F.3 BBGVI under (A2)
If the losses are decomposable along the factors, two cases need to be distinguished:
(D1) ‚àáŒ∫D(q‚à•œÄ) has closed form for all q ‚ààQ;
(D2) D(q‚à•œÄ) = Eq(Œ∏|Œ∫)

‚ÑìD
Œ∫,œÄ(Œ∏)

for some function ‚ÑìD
Œ∫,œÄ : Œò ‚ÜíR.
Under each condition, we Ô¨Ånd a diÔ¨Äerent solution using as much of the available information
as possible to improve inference outcomes. For simplicity, we Ô¨Årst explain how the derivation
works without using the additional information that (A2). In a second step, we shall see how
this additional information can be used for variance reductions in the Rao-Blackwellization
spirit also used by Ranganath et al. (2014).
F.3.1 Gradients if (D1) holds, not using (A2)
In this case, we can obtain the objective given in the main paper. DeÔ¨Åne L(q) to be the GVI
objective function of q(Œ∏|Œ∫). It holds that
‚àáŒ∫L(q) = ‚àáŒ∫
"Z
Œ∏
n
X
i=1
‚Ñì(Œ∏, xi)q(Œ∏|Œ∫)dŒ∏ + D(q||œÄ)
#
=
Z
Œ∏
‚Ñìn(Œ∏, x)‚àáŒ∫q(Œ∏|Œ∫)dŒ∏ + ‚àáŒ∫D(q||œÄ)
= Eq(Œ∏|Œ∫)
" n
X
i=1
‚Ñì(Œ∏, xi)‚àáŒ∫ log(q(Œ∏|Œ∫))
#
+ ‚àáŒ∫D(q||œÄ).
76

Generalized Variational Inference
Correspondingly, the gradient can then be estimated without bias and computing the
corresponding sample average 1
S
PS
s=1 G(Œ∏(s)), where the individual terms are given by
G(Œ∏(s)) =
n
X
i=1
‚Ñì(Œ∏(s), xi)‚àáŒ∫ log(q(Œ∏(s))) + ‚àáŒ∫D(q||œÄ)
F.3.2 Gradients if (D2) holds, not using (A2)
If the uncertainty quantiÔ¨Åer is not available in closed form, one instead can rely on
‚àáŒ∫L(q) = ‚àáŒ∫
"Z
Œ∏
" n
X
i=1
‚Ñì(Œ∏, xi) + ‚ÑìD
Œ∫,œÄ(Œ∏)
#
q(Œ∏|Œ∫)dŒ∏
#
=
Z
Œ∏
" n
X
i=1
‚Ñì(Œ∏, xi) + ‚ÑìD
Œ∫,œÄ(Œ∏)
#
‚àáŒ∫q(Œ∏|Œ∫)dŒ∏ +
Z
Œ∏

‚àáŒ∫‚ÑìD
Œ∫,œÄ(Œ∏)

q(Œ∏|Œ∫)dŒ∏
= Eq(Œ∏|Œ∫)
" n
X
i=1
‚Ñì(Œ∏, xi) + ‚ÑìD
Œ∫,œÄ(Œ∏)
!
‚àáŒ∫ log(q(Œ∏|Œ∫))
#
+ Eq(Œ∏|Œ∫)

‚àáŒ∫‚ÑìD
Œ∫,œÄ(Œ∏)

.
This derivation is a more general case of the one given in Ranganath et al. (2014), but further
simpliÔ¨Åes to the one therein if D = KLD. The gradient is estimated without bias by sampling
Œ∏(1:S) from q(Œ∏|Œ∫) and again computing 1
S
PS
s=1 G(Œ∏(s)) for the slightly diÔ¨Äerent
G(Œ∏(s)) =
" n
X
i=1
‚Ñì(Œ∏(s), xi) + ‚ÑìD
Œ∫,œÄ(Œ∏(s))
#
‚àáŒ∫ log(q(Œ∏(s)|Œ∫)) + ‚àáŒ∫‚ÑìD
Œ∫,œÄ(Œ∏(s)).
F.3.3 Rao-Blackwellization for variance reduction, using (A2)
If the losses deÔ¨Åne a markov blanket over the factors Œ∏j, one can employ Rao-Blackwellization
for variance reduction. This is done by rewriting for q‚àíj(Œ∏‚àíj|Œ∫‚àíj) = Qk
l=1,lÃ∏=j ql(Œ∏l|Œ∫l) the
partial derivatives as
‚àáŒ∫jL(q) = ‚àáŒ∫jEqj(Œ∏j|Œ∫j)
h
Eq‚àíj(Œ∏‚àíj|Œ∫‚àíj) [L(q)|Œ∏j]
i
.
The hope is then to get around computing as many of the inner expectations over q‚àíj(Œ∏‚àíj|Œ∫‚àíj)
as possible. Assume for the moment that at least (D2) holds. Further, denote q‚àíj(Œ∏‚àíj|Œ∫‚àíj) =
q‚àíj, qj(Œ∏j|Œ∫j) = qj, and in similar fashion the distributions q(j), q‚àí(j), q. Moreover, denote
‚Ñìi = ‚Ñì(Œ∏, xi), ‚ÑìD = ‚ÑìD
Œ∫,œÄ(Œ∏) and in a similar fashion ‚Ñì(j)
i , ‚Ñì‚àí(j)
i
. Now, assuming that (A2)
holds relative to the factors Œ∏j of the variational family Q, one Ô¨Ånds
‚àáŒ∫jL(q) = Eqj
"
‚àáŒ∫j log(qj)
 
Eq‚àíj
" n
X
i=1
‚Ñì(j)
i
#
+ Eq‚àíj[‚Ñì‚àíj
n ] + Eq‚àíj[‚ÑìD]
!#
+ Eq‚àíj[‚àáŒ∫j‚ÑìD].
Observing that Eqj[‚àáŒ∫j log(qj)] = 0 and that Eq‚àíj[‚Ñì‚àí(j)] is constant in Œ∏j by (A2), this
drastically simpliÔ¨Åes to
‚àáŒ∫jL(q) = Eqj
"
‚àáŒ∫j log(qj)Eq‚àíj
" n
X
i=1
‚Ñì(j)
i
#
+ Eq‚àíj

‚ÑìD + ‚àáŒ∫j‚ÑìD
#
.
77

Knoblauch, Jewson and Damoulas
Next, observe that by virtue of how ‚Ñì(j) was constructed, it holds that we can also simplify
Eqj
"
‚àáŒ∫j log(qj)Eq‚àíj
" n
X
i=1
‚Ñì(j)
i
##
= Eq(j)
" n
X
i=1
‚Ñì(j)
i
#
.
Putting the above together, we Ô¨Ånally arrive at
‚àáŒ∫jL(q) = Eqj
"
‚àáŒ∫j log(qj)
 
Eq‚àíj
" n
X
i=1
‚Ñì(j)
i
#
+ Eq‚àíj[‚ÑìD]
!
+ Eq‚àíj[‚àáŒ∫j‚ÑìD]
#
= Eq(j)
"
‚àáŒ∫j log(qj)
n
X
i=1
‚Ñì(j)
i
#
+ Eq

‚àáŒ∫j log(qj)‚ÑìD + ‚àáŒ∫j‚ÑìD
.
which is the Ô¨Ånal form under (D1). Should (D1) to hold, one can instead use the lower
variance estimate
‚àáŒ∫jL(q) = Eq(j)
"
‚àáŒ∫j log(qj)
n
X
i=1
‚Ñì(j)
i
#
+ ‚àáŒ∫jD(q‚à•œÄ).
These derivations are very similar to the ones in the supplement of Ranganath et al. (2014),
but importantly the former are restricted to negative log likelihood losses. The more general
version presented here holds for arbitrary decomposable losses. The J terms ‚àáŒ∫jL(q) can be
combined into a global gradient estimate simply by setting
‚àáŒ∫L(q) = (‚àáŒ∫1L(q), ‚àáŒ∫2L(q), . . . ‚àáŒ∫JL(q))T .
To make the meaning of (A2) more tangible for the case of general losses, we next provide a
short example in the context of multivariate regression.
Example 5 (Markov blankets without conditional independence) Suppose each xi =
(xi,1, xi,2, xi,3)‚Ä≤ consists of three measurements that we wish to relate to some other observables
yi through
xi,1 = a + yib + Œæ1
xi,2 = b + yic + Œæ2
xi,3 = d + Œæ3
where Œæj are unknown slack variables (or errors), the parameters of interest are Œ∏ =
(a, b, c, d, e) and we wish to produce a belief distribution over Œ∏ that is informative about good
values of Œ∏ relative to some prediction loss
‚Ñì(Œ∏, xi) = ‚à•f1
1 (Œ∏1, Œ∏(1), yi) ‚àíxi,1‚à•p
p + ‚à•f2
2 (Œ∏1, Œ∏(1), yi) ‚àíxi,2‚à•p
p + ‚à•f3
2 (Œ∏2, Œ∏(2), yi) ‚àíxi,3‚à•p
p,
where ‚à•¬∑ ‚à•p
p denotes some p-norm for p ‚â•1 and fj
l seeks to predict only the l-th dimension
of xi by means of the l-th factor of Œ∏ and its blanket. Suppose that fj
l will correspond to the
78

Generalized Variational Inference
l-th row written down in the above model for xi (excluding of course the error term), which
means that
f1
1 (Œ∏1, Œ∏(1)) = a + yib
f2
2 (Œ∏1, Œ∏(1), yi) = b + yic
f3
2 (Œ∏2, Œ∏(2), yi) = d
In this case, the two factors of Œ∏ will clearly be given by
Œ∏1 = (a, b, c)T ,
Œ∏2 = (d).
As before, one will in practice need to approximate the gradients with a sample Œ∏(1:S) drawn
from q(Œ∏|Œ∫). For one of the Ô¨Åxed samples Œ∏(s), the relevant terms are computed as
Gj(Œ∏(s)) = ‚àáŒ∫j log(qj(Œ∏(s)
j |Œ∫j))
n
X
i=1
‚Ñì(j)(Œ∏(s)
j , Œ∏(s)
(j), xi) + eD(s, j)
for some function eD(s, j). If (D2) holds and there is no closed form for the uncertainty
quantiÔ¨Åer, this function is given by
eD(s, j) = ‚àáŒ∫j log(qj(Œ∏(s)
j |Œ∫j))‚ÑìD
œÄ,Œ∫(Œ∏(s)) + ‚àáŒ∫j‚ÑìD
œÄ,Œ∫(Œ∏(s))
and in case the stricter requirement (D1) holds, it is simply given by the closed form
eD(s, j) = ‚àáŒ∫jD(q‚à•œÄ).
F.4 BBGVI if neither (A2) nor (A3) hold
It is of course possible that neither (A2) nor (A3) hold.
Alternatively, it may simply
be convenient to build an implementation that can work reliably without imposing any
assumptions. In this case, one will have to use the naive version of BBGVI that is given in
the main paper and only depends on the distinction between (D2) and (D1). However‚Äîeven
though we do not do so in our experiments‚Äìthere still are valid black box variance reduction
techniques for this case. The next section presents these techniques, again by adapting
notation and logic from Ranganath et al. (2014).
F.5 Generically applicable variance reduction
While the Rao-Blackwellization variance reduction will generally be more eÔ¨Äective, some
variance reduction techniques can work in circumstances where Rao-Blackwellization does
not. Conversely, this means that if the Rao-Blackwellization is applicable, one can actually
deploy two variance reduction schemes at once to substantially speed up convergence. The
control variate we use is simply
h(Œ∏) = ‚àáŒ∫ log q(Œ∏|Œ∫)
with an optimal scaling parameter that can be estimated as
ÀÜa‚àó=
PS
s=1 d
Cov(L(Œ∏(s)), h(Œ∏(s)))
PS
s=1 d
Var(h(Œ∏(s)))
.
79

Knoblauch, Jewson and Damoulas
Based on this, one may now compute the variance reduced term GVR(Œ∏(s)) from G(Œ∏(s)) as
GVR(Œ∏(s)) = G(Œ∏(s)) ‚àíÀÜa‚àó¬∑ h(Œ∏(s)).
Of course, the exact same logic can be applied to the Rao-Blackwellized terms Gj(Œ∏(s)) to
reduce the variance a second time.
Appendix G. Closed forms for divergences & proof of Proposition 27
This section proves various closed forms for the uncertainty quantiÔ¨Åers in the GVI problem.
We do so by proving conditions for closed forms of the Œ±Œ≤Œ≥-divergence (D(Œ±,Œ≤,r)
G
) introduced
in Appendix A. Note that the special case of these results for the D(Œ±)
AR has been derived
before (see Gil et al., 2013; Gil, 2011; Liese and Vajda, 1987). Unlike previous work, our
results apply to a range of other divergences, too. This is convenient because all other robust
divergences we discuss throughout the paper are special cases of D(Œ±,Œ≤,r)
G
.
G.1 High-level overview of results and preliminaries
Summarizing some of the most important Ô¨Åndings of this section, we Ô¨Ånd that if both q(Œ∏)
and œÄ(Œ∏) are in the same exponential variational family Q,
‚Ä¢ D(Œ±)
AR(q||œÄ) and D(Œ±)
A (q|œÄ) are always available in closed form if Œ± ‚àà(0, 1) (see Corollary
45)
‚Ä¢ D(Œ±)
AR(q||œÄ) and D(Œ±)
A (q|œÄ) are available in closed form if Œ± > 1 for most exponential
families (see again Corollary 45)
‚Ä¢ D(Œ≤)
B (q||œÄ) and D(Œ≥)
G (q||œÄ) are available in closed form for Œ≤ > 1 and Œ≥ > 1 for most
exponential families (See Corollary 51).
We note that these Ô¨Åndings are interesting because closed forms for the divergence term
drastically reduce the variance of black box GVI, see also Appendix F. The remainder of this
section is devoted to tedious but rigorous derivations of these Ô¨Åndings. Before stating any
results, it is useful to state the deÔ¨Ånition of an exponential family and its natural parameter
space upon which the proofs rely.
DeÔ¨Ånition 41 (Exponential families) Object Œ∏ ‚ààŒò ‚äÇRd, d ‚â•1 has an exponential
family distribution with parameters Œ∫ ‚ààK ‚äÇRp‚Ä≤, p‚Ä≤ ‚â•1 if there exist functions Œ∑ : K ‚Üí
N ‚äÇRp, p ‚â•1, T : Œò ‚ÜíT ‚äÇRp, h : Œò ‚ÜíR‚â•0 and A : N ‚ÜíR such that
p(Œ∏|Œ∑(Œ∫)) = h(Œ∏) exp

Œ∑(Œ∫)T T(Œ∏) ‚àíA(Œ∑(Œ∫))
	
,
where A(Œ∑(Œ∫)) = ‚àílog
 R
h(Œ∏) exp

Œ∑(Œ∫)T T(Œ∏)
	
dŒ∏

.
The set N is called the natural
parameter space and is deÔ¨Åned to ensure p(Œ∏|Œ∑(Œ∫)) is a normalised probability density,
N = {Œ∑(Œ∫) : A(Œ∑(Œ∫)) < ‚àû}.
Throughout the rest of this section, we assume that the following condition holds for both
the prior and the variational family Q.
Condition 1 (The prior and variational families) It holds that
80

Generalized Variational Inference
i) the variational family Q = {q(Œ∏|Œ∑(Œ∫))} is an exponential family of the form given by
DeÔ¨Ånition 41
ii) the prior œÄ(Œ∏|Œ∑(Œ∫0)) is a member of that variational family.
Amongst other things, this implies that the log-normalising constant is a closed form function
of the natural parameters and that we can derive generic conditions for closed forms by using
the canonical representation of exponential families.
To showcase the implications of the derived results, we use the Mulitvariate Gaussian (MVN)
to provide examples along the way.
DeÔ¨Ånition 42 (The MVN exponential family) The density of the MVN exponential
family for vector Œ∏ of dimension d is p(Œ∏|Œ∑(Œ∫)) = h(Œ∏) exp

Œ∑(Œ∫)T T(Œ∏) ‚àíA(Œ∑(Œ∫))
	
where
Œ∑(Œ∫) =
 V ‚àí1¬µ
‚àí1
2V ‚àí1

T(Œ∏)=
 Œ∏
Œ∏Œ∏T

h(Œ∏) = (2œÄ)‚àíd/2
A(Œ∑(Œ∫))=
1
2 log |V | + 1
2¬µV ‚àí1¬µ

and the natural parameter space requires that ¬µ is a real valued vector of the same dimension
as Œ∏ and V is a d √ó d symmetric semi-positive deÔ¨Ånite matrix.
G.2 Results, proofs & examples
The remainder of this section is structued as follows: First, we give the main result for the
Œ±Œ≤Œ≥-divergence (D(Œ±,Œ≤,r)
G
) in Proposition 43. This ‚Äúmaster result‚Äù is then applied to various
special cases for D(Œ±,Œ≤,r)
G
that are of practical interest, namely the Œ±-divergence (D(Œ±)
A ), R√©nyi‚Äôs
Œ±-divergence (D(Œ±)
AR), the Œ≤-divergence (D(Œ≤)
B ) as well the Œ≥-divergence (D(Œ≥)
G ).
G.2.1 Master result for D(Œ±,Œ≤,r)
G
While the following result and corresponding proof are somewhat tedious to read, they are
conceptually simple: In fact, all that is needed to derive the results is some basic algebra
and the canonical form of the exponential family.
Proposition 43 (Closed form D(Œ±,Œ≤,r)
G
between exponential families) The D(Œ±,Œ≤,r)
G
be-
tween a variational posterior q(Œ∏|Œ∫n) and prior œÄ(Œ∏|Œ∫0) is available in closed form under the
following conditions
i) Œ∑(Œ∫0), Œ∑(Œ∫n) ‚ààN ‚áí(Œ±Œ∑(Œ∫0) + (Œ≤ ‚àí1)Œ∑(Œ∫n)) ‚ààN;
ii) Ep(Œ∏|Œ∑(Œ∫))

h(Œ∏)Œ±+Œ≤‚àí2
is a closed form function of Œ∑(Œ∫) ‚ààN.
If these conditions hold the D(Œ±,Œ≤,r)
G
can be written as
ÀúD(Œ±,Œ≤)
G
(q(Œ∏|Œ∫n)||œÄ(Œ∏|Œ∫0))
= Œ±B(Œ∫n, (Œ± + Œ≤ ‚àí1))E(Œ∫n, (Œ± + Œ≤ ‚àí1)) + (Œ≤ ‚àí1)B(Œ∫0, (Œ± + Œ≤ ‚àí1))E(Œ∫0, (Œ± + Œ≤ ‚àí1))
‚àí(Œ± + Œ≤ ‚àí1)C(Œ∫n, Œ∫0, Œ±, (Œ≤ ‚àí1)) ÀúE(Œ∫n, Œ∫0, Œ±, (Œ≤ ‚àí1))
81

Knoblauch, Jewson and Damoulas
where
B(Œ∫, Œ¥) = exp {A(Œ¥Œ∑(Œ∫))}
exp {A(Œ∑(Œ∫))}Œ¥ ,
C(Œ∫1, Œ∫2, Œ¥1, Œ¥2) =
exp {A (Œ¥1Œ∑(Œ∫1) + Œ¥2)Œ∑(Œ∫2))}
exp {A(Œ∑(Œ∫1))}Œ¥1 exp {A(Œ∑(Œ∫2))}Œ¥2
E(Œ∫, Œ¥) = Ep(Œ∏|Œ¥Œ∑(Œ∫))
h
h(Œ∏)Œ¥‚àí1i
,
ÀúE(Œ∫1, Œ∫2, Œ¥1, Œ¥2) = Ep(Œ∏|Œ¥1Œ∑(Œ∫1)+Œ¥2Œ∑(Œ∫2))
h
h(Œ∏)Œ¥1+Œ¥2‚àí1i
we suppress the dependence of these functions on A(¬∑) and h(¬∑) as these derive form the
deÔ¨Ånition of the exponential family (DeÔ¨Ånition 41).
Proof The D(Œ±,Œ≤,r)
G
is a closed form function of ÀúD(Œ±,Œ≤)
G
given in DeÔ¨Ånition 30. Hence if ÀúD(Œ±,Œ≤)
G
is available in closed form, then so is D(Œ±,Œ≤,r)
G
. In order to ensure that ÀúD(Œ±,Œ≤)
G
(q(Œ∏|Œ∫n)||œÄ(Œ∏|Œ∫0))
has closed form, we need to make sure the three integrals below are available in closed form
for the exponential family.
G1 :=
Z
q(Œ∏|Œ∫n)Œ±+Œ≤‚àí1dŒ∏,
G2 :=
Z
œÄ(Œ∏|Œ∫0)Œ±+Œ≤‚àí1dŒ∏,
G3 :=
Z
q(Œ∏|Œ∫n)Œ±œÄ(Œ∏|Œ∫0)Œ≤‚àí1dŒ∏.
First we tackle G1.
G1 =
Z
h(Œ∏)Œ±+Œ≤‚àí1 exp

(Œ± + Œ≤ ‚àí1)Œ∑(Œ∫n)T T(Œ∏) ‚àí(Œ± + Œ≤ ‚àí1)A(Œ∑(Œ∫n))
	
dŒ∏
= exp {A((Œ± + Œ≤ ‚àí1)Œ∑(Œ∫n)) ‚àí(Œ± + Œ≤ ‚àí1)A(Œ∑(Œ∫n))} Ep(Œ∏|(Œ±+Œ≤‚àí1)Œ∑(Œ∫n)
h
h(Œ∏)Œ±+Œ≤‚àí2i
,
where condition (i) with Œ∑(Œ∫0) = Œ∑(Œ∫n) ensures that
A((Œ± + Œ≤ ‚àí1)Œ∑(Œ∫n)) =
Z
h(Œ∏) exp

(Œ± + Œ≤ ‚àí1)Œ∑(Œ∫n)T T(Œ∏)
	
dŒ∏ < ‚àû,
which in turn ensures that p(Œ∏|(Œ± + Œ≤ ‚àí1)Œ∑(Œ∫n) is a normalised probability density and that
Ep(Œ∏|(Œ±+Œ≤‚àí1)Œ∑(Œ∫n)

h(Œ∏)Œ±+Œ≤‚àí2
is a valid expectation. Now, condition (ii) guarantees this is a
closed form function of Œ∑(Œ∫n). Similarly for G2,
G2 =
Z
h(Œ∏)Œ±+Œ≤‚àí1 exp

(Œ± + Œ≤ ‚àí1)Œ∑(Œ∫0)T T(Œ∏) ‚àí(Œ± + Œ≤ ‚àí1)A(Œ∑(Œ∫0))
	
dŒ∏
= exp {A((Œ± + Œ≤ ‚àí1)Œ∑(Œ∫0)) ‚àí(Œ± + Œ≤ ‚àí1)A(Œ∑(Œ∫0))} Ep(Œ∏|(Œ±+Œ≤‚àí1)Œ∑(Œ∫0)
h
h(Œ∏)Œ±+Œ≤‚àí2i
,
where in analogy to G1, conditions (i) and (ii) with Œ∑(Œ∫k) = Œ∑(Œ∫0) ensure this has a closed
form. Lastly for G3,
G3 =
Z
h(Œ∏)Œ± exp

Œ±Œ∑(Œ∫n)T T(Œ∏) ‚àíŒ±A(Œ∑(Œ∫n))
	
¬∑h(Œ∏)Œ≤‚àí1 exp

(Œ≤ ‚àí1)Œ∑(Œ∫0)T T(Œ∏) ‚àí(Œ≤ ‚àí1)A(Œ∑(Œ∫0))
	
dŒ∏
= exp {A (Œ±Œ∑(Œ∫n) + (Œ≤ ‚àí1)Œ∑(Œ∫0)) ‚àíŒ±A(Œ∑(Œ∫n)) ‚àí(Œ≤ ‚àí1)A(Œ∑(Œ∫0))}
¬∑Ep(Œ∏|(Œ±Œ∑(Œ∫n)+(Œ≤‚àí1)Œ∑(Œ∫0))
h
h(Œ∏)Œ±+Œ≤‚àí2i
,
where once again in analogy to G1 and G2, conditions (i) and (ii) ensure this is a closed form
function of Œ∑(Œ∫n) and Œ∑(Œ∫0).
82

Generalized Variational Inference
Therefore, provided conditions (i) and(ii) hold, the integrals G1, G2 and G3 are available
in closed form, implying that the same holds for D(Œ±,Œ≤,r)
G
(q(Œ∏|Œ∫n)||œÄ(Œ∏|Œ∫0)).
Remark 44 (Conditions of Proposition 43 for the MVN exponential family) In or-
der to illuminate the meaning and generality of the conditions of Theorem 43, we apply them
to the MVN exponential family described in DeÔ¨Ånition 42. In this case the two conditions
become:
i) For ¬µ‚àó:=
(
¬µ1 + ¬µ2 ‚àí
  1
Œ±V1
‚àí1 +

1
Œ≤‚àí1V2
‚àí1‚àí1   1
Œ±V1
‚àí1 ¬µ2 +

1
Œ≤‚àí1V2
‚àí1
¬µ1
)
we require that
Œ±
V ‚àí1
1
¬µ1
‚àí1
2V ‚àí1
1

+ (Œ≤ ‚àí1)
V ‚àí1
2
¬µ2
‚àí1
2V ‚àí1
2

=
Ô£´
Ô£¨
Ô£≠
  1
Œ±V1
‚àí1 ¬µ1 +

1
Œ≤‚àí1V2
‚àí1
¬µ2
‚àí1
2
  1
Œ±V1
‚àí1 +

1
Œ≤‚àí1V2
‚àí1
Ô£∂
Ô£∑
Ô£∏
=
Ô£´
Ô£¨
Ô£¨
Ô£≠
  1
Œ±V1
‚àí1 +

1
Œ≤‚àí1V2
‚àí1
¬µ‚àó
‚àí1
2
  1
Œ±V1
‚àí1 +

1
Œ≤‚àí1V2
‚àí1
Ô£∂
Ô£∑
Ô£∑
Ô£∏‚ààN
ii) Ep(Œ∏|Œ∑(Œ∫))
h
(2œÄ)‚àíd/2(Œ±+Œ≤+2)i
= (2œÄ)‚àíd/2(Œ±+Œ≤+2) = f(Œ∑(Œ∫)) where f is a closed form
function.
Part ii) shows that the second condition is trivially satisÔ¨Åed for the MVN exponential family.
Part i) shows that for the MVN exponential family, the Ô¨Årst condition is satisÔ¨Åed provided
(V ‚àó)‚àí1 =
  1
Œ±V1
‚àí1 +

1
Œ≤‚àí1V2
‚àí1
is a positive deÔ¨Ånite matrix. This condition is enough
to ensure that V ‚àóis invertible and thus that ¬µ‚àóis well-deÔ¨Åned. We elaborate further on what
this means for certain parametrisations below.
G.2.2 Corollary: The special cases of D(Œ±)
A , D(Œ±)
AR
Next, we consider the D(Œ±)
A
and D(Œ±)
AR special cases of the D(Œ±,Œ≤,r)
G
family. DeÔ¨Ånitions 31 and 32
can be used to show that the D(Œ±)
AR is available as the following closed form function of the
D(Œ±)
A . In particular, it holds that
D(Œ±)
AR(q(Œ∏)||œÄ(Œ∏)) =
1
Œ±(Œ± ‚àí1) log

1 + Œ±(1 ‚àíŒ±)D(Œ±)
A (q(Œ∏)||œÄ(Œ∏))
	
.
(29)
Thus, as demonstrated in Corollary 46 below, the D(Œ±)
A
being available in closed form
immediately provides the D(Œ±)
AR in closed form. Before stating these results, we note that Gil
et al. (2013); Gil (2011); Liese and Vajda (1987) have shown our closed form results for the
D(Œ±)
AR (and thus implicitly the D(Œ±)
A ) before. We nevertheless think there is merit in stating
them, since our results refer to the D(Œ±,Œ≤,r)
G
and thus are more general, recovering both the
D(Œ±)
A
and D(Œ±)
AR only as a special case.
83

Knoblauch, Jewson and Damoulas
Corollary 45 (Closed form D(Œ±)
A
for exponential families) The D(Œ±)
A
between a varia-
tional posterior q(Œ∏|Œ∫n) and prior œÄ(Œ∏|Œ∫0) is available in closed form under the following
conditions
i) (Œ±Œ∑(Œ∫n) + (1 ‚àíŒ±)Œ∑(Œ∫0)) ‚ààN
and in this case the D(Œ±)
A
can be written as
D(Œ±)
A (q(Œ∏|Œ∫n)||œÄ(Œ∏|Œ∫0) =
1
Œ±(1 ‚àíŒ±) [1 ‚àíC(Œ∫n, Œ∫0, Œ±, (1 ‚àíŒ±))] ,
where C(Œ∫1, Œ∫2, Œ¥1, Œ¥2) was deÔ¨Åned in Proposition 43 .
Proof Following Cichocki and Amari (2010) the single-parameter D(Œ±)
A
is recovered as a
member of the D(Œ±,Œ≤,r)
G
family when r = 1 and Œ≤ = 2 ‚àíŒ±. In this situation, Condition (ii) of
Theorem 43 holds automatically and we are left with Condition (i). Substituting Œ≤ = 2 ‚àíŒ±
provides Condition (i) of the Theorem above.
If Œ± ‚àà(0, 1) then the convexity of the natural parameter space ensures that providing
Œ∑(Œ∫n) ‚ààN and Œ∑(Œ∫0) ‚ààN then Œ±Œ∑(Œ∫n) + (1 ‚àíŒ±)Œ∑(Œ∫0) ‚ààN. If Œ± < 0 or Œ± > 1, then this
can no longer be guaranteed.
Corollary 46 is then an immediate consequence of Corollary 45.
Corollary 46 (Closed form D(Œ±)
AR for exponential families) The D(Œ±)
AR between a varia-
tional posterior q(Œ∏|Œ∫n) and prior œÄ(Œ∏|Œ∫0) will have closed form providing the D(Œ±)
A
between
the same two densities for the same value of Œ± has closed form.
Proof The proof of this follows immediately from the fact that the D(Œ±)
AR can be recovered
using the closed form function of the D(Œ±)
A
shown in eq. (29)
Remark 47 (Conditions for Corollary 45 for the MVN exponential family) The con-
dition that Œ±Œ∑(Œ∫n) + (1 ‚àíŒ±)Œ∑(Œ∫0) ‚ààN can only be guaranteed for Œ± ‚àà(0, 1). However we
can see from Remark 44 that provided V ‚àó=
  1
Œ±V1
‚àí1 +

1
Œ≤‚àí1V2
‚àí1‚àí1
is a symmetric
semi-positive deÔ¨Ånite ( SPD) matrix for Œ≤ = 2 ‚àíŒ± then this condition will be satisÔ¨Åed. For
Œ± > 1 or Œ± < 0 we cannot guarantee that V ‚àóis SPD. However, we implement the D(Œ±)
AR to
quantify uncertainty for Œ± > 1 in the main paper. Corollary 45 demonstrates that these
parameters will still produce a closed form divergence provided the prior has suÔ¨Éciently large
variance, which can always be guaranteed to hold in practice.
G.2.3 Corollary: The special cases of D(Œ≤)
B , D(Œ≥)
G
Next, we turn attention to the Œ≤- and Œ≥-divergence families. DeÔ¨Ånition 34 shows that the D(Œ≥)
G
can be recovered as a closed form function of the terms of the D(Œ≤)
B
and thus, as demonstrated
in Corollary 49 below, the D(Œ≤)
B
being available in closed form immediately provides that the
D(Œ≥)
G is available in closed form While the conditions for these are slightly more restrictive
than they were for the D(Œ±)
A
and D(Œ±)
AR, one can still obtain closed form uncertainty quantiÔ¨Åers
for a large range of settings.
84

Generalized Variational Inference
Corollary 48 (Closed form D(Œ≤)
B
for exponential families) The D(Œ≤)
B
between a varia-
tional posterior q(Œ∏|Œ∫n) and prior œÄ(Œ∏|Œ∫0) is available in closed form under the following
conditions
i) Œ∑(Œ∫1), Œ∑(Œ∫2) ‚ààN ‚áí((Œ≤ ‚àí1)Œ∑(Œ∫1) + Œ∑(Œ∫2)) ‚ààN
ii) Ep(Œ∏|Œ∑(Œ∫))

h(Œ∏)Œ≤‚àí1
is a closed form function of Œ∑(Œ∫) ‚ààN.
and in this case the D(Œ≤)
B
can be written as
D(Œ≤)
B (q(Œ∏|Œ∫n)||œÄ(Œ∏|Œ∫0)) =
1
Œ≤(Œ≤ ‚àí1)B(Œ∫n, Œ≤)E(Œ∫n, Œ≤) + 1
Œ≤ B(Œ∫0, Œ≤)E(Œ∫0, Œ≤)
‚àí
1
(Œ≤ ‚àí1)C(Œ∫n, Œ∫0, 1, (Œ≤ ‚àí1)) ÀúE(Œ∫n, Œ∫0, 1, (Œ≤ ‚àí1)),
where the functions B(Œ∫, Œ¥), C(Œ∫1, Œ∫2, Œ¥1, Œ¥2), E(Œ∫, Œ¥) and ÀúE(Œ∫1, Œ∫2, Œ¥1, Œ¥2) are deÔ¨Åned in
Proposition 43.
Proof Following Cichocki and Amari (2010), the single-parameter D(Œ≤)
B
is recovered as a
member of the D(Œ±,Œ≤,r)
G
family when r = 1 and Œ± = 1. In this situation, Condition (i)-(ii) of
Theorem 43 become (i)-(ii) above.
Corollary 49 is then an immediate consequence of Corollary 48.
Corollary 49 (Closed form D(Œ≥)
G
for exponential families) The D(Œ≥)
G
between a varia-
tional posterior q(Œ∏|Œ∫n) and prior œÄ(Œ∏|Œ∫0) will have closed form providing the D(Œ≤)
B
between
the same two densities with Œ≤ = Œ≥ has closed form.
Proof The proof of this follows immediately from the fact that the D(Œ≥)
G can be recovered
from the D(Œ≤)
B
using closed form function as outlined in DeÔ¨Ånition 34.
Remark 50 (Conditions for Corollary 48 under the MVN exponential family)
Fol-
lowing Remark 44, Corollary 48 is satisÔ¨Åed providing V ‚àó=

(Vn)‚àí1 +

1
Œ≤‚àí1V0
‚àí1‚àí1
is a
symmetric SPD matrix. The sum of two symmetric SPD matrices is symmetric SPD and
additionally the inverse of a symmetric SPD matrix is also SPD. Therefore provided Œ≤ > 1 we
can be sure that Condition iii) will be satisÔ¨Åed. Similarly to Remark 47, when Œ≤ < 1 closed
forms will require that the prior has a suÔ¨Éciently large variance.
In fact Remark 50 can be extended to many other exponential families if we constrain
Œ≤ = Œ≥ > 1, this is formalised in Corollary 51.
Corollary 51 (Closed form D(Œ≤)
B
and D(Œ≥)
G
for exponential families when Œ≤ = Œ≥ > 1)
When Œ≤ = Œ≥ > 1, the conditions for Corollary 48 are satisÔ¨Åed by any exponential family
whose h(Œ∏) is a constant function of Œ∏ and whose natural parameter space is closed under
addition and scalar multiplication. This includes the Beta, Gamma, Gaussian, exponential
and Laplace families.
Proof The proof of Corollary 51 follows straight from that of Corollary 48.
85

Knoblauch, Jewson and Damoulas
0.07750
0.07875
0.08000
D(0.5)
AR
KLD (VI)
D(2.0)
AR
D(2.5)
AR
D(0.5)
AR
D(0.5)
A
D(0.0)
A
DVI
GVI
kin8mn
0.630
0.635
0.640
wine
0.000
0.002
0.004
0.006
naval
1.20
1.18
1.16
1.14
1.12
D(0.5)
AR
KLD (VI)
D(2.0)
AR
D(2.5)
AR
D(0.5)
AR
D(0.5)
A
D(0.0)
A
DVI
GVI
0.95
0.96
0.97
0.98
6.5
6.0
5.5
5.0
4.5
4.0
Figure 21: Top row depicts RMSE, bottom row the NLL across a range of data sets using
BNNs. Dots correspond to means, whiskers the standard errors. The further to the left,
the better the predictive performance. For the depicted selection of data sets, no common
pattern exists for the performance diÔ¨Äerences between standard VI, DVI and GVI.
Appendix H. Experiments
While the most interesting Ô¨Åndings of our numerical studies can be found in the main paper,
here we give a brief overview over additional results. More importantly, we state the proofs
for the theoretical groundwork necessary to deploy GVI on DGPs.
H.1 Bayesian Neural Networks (BNNs)
We provide two more sets of experiments for further insights into BNNs. The Ô¨Årst set consists
in three more data sets with the same settings as used in the main paper. While these Ô¨Åndings
do not change the overall picture, they do require more careful analysis and dissemination.
The second set of results investigates the interaction between robustifying inference relative
to the loss with robustifying it relative to the prior. The results suggest a clear relationship
for predictive performance as measured by the root mean square error: If robust losses are
used, the KLD generally performs better. Moreover, the combination of robust loss and
D = KLD outperforms VI and the investigated DVI methods on all data sets studied. The
relationship is less clear for the predictive negative log likelihood, both between loss and
uncertainty quantiÔ¨Åer as well as between the performance to be expected under GVI, VI and
DVI.
H.1.1 First set of additional experiments (Figure 21)
Figure 21 provides the predictive outcomes on three more data sets using the exact same
settings and experimental setup as described in the main paper. The Ô¨Åndings generally
86

Generalized Variational Inference
2.9
3.0
3.1
3.2
KLD (VI)
D(0.5)
AR ,
= 1.01
KLD,
= 1.01
D(0.5)
AR ,
= 1.01
KLD,
= 1.01
D(0.5)
AR
D(0.5)
A
D(0.0)
A
DVI
GVI
boston
5.0
5.1
5.2
5.3
5.4
concrete
1.2
1.3
1.4
energy
0.8
1.0
1.2
yacht
2.5
2.6
2.7
KLD (VI)
D(0.5)
AR ,
= 1.01
KLD,
= 1.01
D(0.5)
AR ,
= 1.01
KLD,
= 1.01
D(0.5)
AR
D(0.5)
A
D(0.0)
A
DVI
GVI
3.1
3.2
3.3
1.5
1.6
1.7
1.8
1.70
1.75
1.80
Figure 22: Top row depicts RMSE, bottom row the NLL across a range of data sets using
BNNs. Dots correspond to means, whiskers the standard errors. The further to the left, the
better the predictive performance. For the depicted selection of data sets, patterns exists for
the interplay between the loss and uncertainty quantiÔ¨Åer for GVI.
reinforce the Ô¨Åndings of the main paper. First, while the GVI methods with Œ± > 1 still
perform as good as or better than standard VI on the kin8mn data set, DVI methods show
a clear performance gain relative to either of the two. Crucially, it is not clear what leads
to this improvement gain, though the fact that the best-performing DVI method is the one
recovering EP (D(Œ±)
A
for Œ± = 0) suggests that there is tangible merit in producing mass-
covering approximations to the posterior of Œ∏ on this data set. While the deployment of
DVI methods looks tempting on the kin8mn data set, the results on the naval data set are a
reminder that the behaviour of these methods is in many ways unpredictable. Moreover, it
shows that the risks we identiÔ¨Åed in Example 4 readily translate into real world applications:
By using DVI methods, we may accidentally conÔ¨Çate the role of the loss and the role of
uncertainty quantiÔ¨Åcation. If the loss is well-suited for the data at hand‚Äîas the RMSE
panel suggests it is in the naval case‚Äîthe mass-covering behaviour of DVI methods can
be extremely detrimental. Lastly, the wine data set provides a very similar picture to the
results in Figure 11: Varying Œ± introduces a banana-shaped curve for the GVI methods. As
it so happens, the ideal choice of Œ± on the wine data set appears to be around Œ± = 1 (i.e.,
standard VI). Taking into account the predictive uncertainty in form of the whiskers, it is
doubtful if any of the methods is dominating another one on wine. Presumably, the reason
for this is that the true posterior is relatively well approximated with the mean Ô¨Åeld normal
family, yielding very similar results across all settings.
87

Knoblauch, Jewson and Damoulas
H.1.2 Second set of additional experiments (Figure 22)
In a second set of additional experiments, we varied the loss function to be a robust scoring
rule. SpeciÔ¨Åcally, we used scoring rules based on the Œ≤-divergence and the Œ≥-divergence.
See Section 6.2.3 for the deÔ¨Ånition and more detail on these robust scoring rules. As for
the DGP examples, we choose values of the scoring rule that are close to the log score, but
suÔ¨Éciently far to induce robust behaviour. All settings for optimization, initialization as
well as the code are the same as for the results provided in the main paper. Figure 22 shows
the results: For the RMSE, the results are unambiguous: Combining a robust scoring rule
with the standard uncertainty quantiÔ¨Åer D = KLD appears to be the winning combination
across all four data sets. The picture is less clear for the NLL: Relative to both VI and DVI,
the performance gains depend on the data set. Even within the class of GVI posteriors, it is
data-set dependent which uncertainty quantiÔ¨Åer should be chosen: For example, it is clearly
beneÔ¨Åcial to choose the D(Œ±)
AR as uncertainty quantiÔ¨Åer in the boston and concrete data sets,
but the opposite is true on the yacht data set. Above all other things, this highlights the
need for a good selection strategy of GVI hyperparameters: Oftentimes, intuitions about the
correct uncertainty quantiÔ¨Åer or the appropriate loss may be incorrect.
H.2 Deep Gaussian Processes (DGPs)
Unlike BNNs, DGPs require some theoretical groundwork before they are amenable to changes
in the loss and uncertainty quantiÔ¨Åer. SpeciÔ¨Åcally, we need to show that it is valid to deÔ¨Åne
new divergences layer-wise. Moreover, while not required it is beneÔ¨Åcial if one can obtain
closed forms for the robustiÔ¨Åed likelihood terms. The following sections proceed to do both.
Thereafter, we also show an additional short example to illustrate the eÔ¨Äect of changing the
uncertainty quantiÔ¨Åer in DGPs.
H.2.1 Proof of Corollary 28
We Ô¨Årst prove a Lemma that plays a key role in the proof of Corollary 28.
Lemma 52 (Divergence recombination) Let Dl be divergences and cl > 0 scalars for
l = 1, 2, . . . , L.
Further, denote Œ∏‚àíl = Œ∏1:l‚àí1,l+t:L and let ql(Œ∏l|Œ∏‚Ä≤
‚àíl) and œÄl(Œ∏l|Œ∏‚Ä≤
‚àíl) be
the conditional distributions of Œ∏l for q(Œ∏) and œÄ(Œ∏) conditioned on Œ∏‚àíl = Œ∏‚Ä≤
‚àíl.
Then,
DŒ∏‚Ä≤(q||œÄ) = PL
l=1 clDl
 ql(Œ∏l|Œ∏‚Ä≤
‚àíl)||œÄl(Œ∏l|Œ∏‚Ä≤
‚àíl)

is a divergence between q(Œ∏) and œÄ(Œ∏) if (i)
DŒ∏‚ó¶(q||œÄ) = DŒ∏‚Ä≤(q||œÄ) for all conditioning sets Œ∏‚ó¶, Œ∏‚Ä≤ and (ii) a Hammersley-CliÔ¨Äord Theorem
holds for the collection of conditionals œÄl(Œ∏l|Œ∏‚Ä≤
‚àíl) and ql(Œ∏l|Œ∏‚Ä≤
‚àíl).
Proof First, observe by deÔ¨Ånition of a divergence, Dl(ql(Œ∏l|Œ∏‚Ä≤‚àíl)||œÄl(Œ∏l|Œ∏‚Ä≤‚àíl)) = 0 for all l
and over all potential conditioning sets Œ∏‚Ä≤ holds if and only if ql(Œ∏l|Œ∏‚Ä≤‚àíl) = œÄl(Œ∏l|Œ∏‚Ä≤‚àíl). Next,
note that we have assumed that DŒ∏‚Ä≤(q||œÄ) = DŒ∏‚ó¶(q||œÄ) for all conditioning sets Œ∏‚Ä≤, Œ∏‚ó¶. In other
words, if DŒ∏‚Ä≤(q||œÄ) = 0 for some Œ∏‚Ä≤, then it will also be 0 for any conditioning set Œ∏‚ó¶. This
immediately entails that for arbitrary Œ∏‚Ä≤, DŒ∏‚Ä≤(q||œÄ) = 0 if and only if ql(Œ∏l|Œ∏‚Ä≤
‚àíl) = œÄl(Œ∏l|Œ∏‚Ä≤
‚àíl)
for all l and for any choice of Œ∏‚Ä≤‚àíl. In other words, the conditionals are the same. Since
the positivity condition holds, we can then apply the Hammersley-CliÔ¨Äord Theorem to
conclude that the conditionals fully specify the joint. This Ô¨Ånally yields the desired result:
DŒ∏‚Ä≤(q||œÄ) = 0 if and only if q(Œ∏) = œÄ(Œ∏).
88

Generalized Variational Inference
With this technical result in hand, one can now prove Corollary 28, which shows that reverse-
engineering prior regularizers inspired by eq. (20) is feasible so long as the layer-speciÔ¨Åc
divergences Dl are f-divergences or monotonic transformations of f-divergences.
Proof Suppressing again Zl and X for readability, Ô¨Årst recall that
q({U l}L
l=1, {F l}L
l=1) =
L
Y
l=1
p(F l|U l, F l‚àí1)q(U l)
p({U l}L
l=1, {F l}L
l=1) =
L
Y
l=1
p(F l|U l, F l‚àí1)p(U l)
and write for a Ô¨Åxed conditioning set {F l
‚ó¶}L
l=1 the new divergence
D{F l
‚ó¶}L
l=1  q({Ul}L
l=1, {Fl}L
l=1)‚à•p({Ul}L
l=1, {Fl}L
l=1)

=
L
X
l=1
Dl 
p(F l|U l, F l‚àí1
‚ó¶
)q(U l)‚à•p(F l|U l, F l‚àí1
‚ó¶
)p(U l)

=
L
X
l=1
Dl 
q(U l)‚à•p(U l)

The Ô¨Årst equality is simply the deÔ¨Ånition of the new divergence. The second equality follows
by virtue of Dl being a monotonic function of an f-divergences or an f-divergence for all l,
which ensures that the l-th term is given by
Dl 
p(F l|U l, F l‚àí1
‚ó¶
)q(U l)‚à•p(F l|U l, F l‚àí1
‚ó¶
)p(U l)

(30)
= g

Ep(F l|Ul,F l‚àí1
‚ó¶
)p(Ul)

f
p(F l|U l, F l‚àí1
‚ó¶
)q(U l)
p(F l|U l, F l‚àí1
‚ó¶
)p(U l)

.
= g

Ep(Ul)

f
q(U l)
p(U l)

= Dl 
q(U l)‚à•p(U l)

.
Now note that we can invoke Lemma 52: The Ô¨Årst condition is satisÔ¨Åed because the derivation
was independent of the chosen {F l
‚ó¶}L
l=1. The second condition is satisÔ¨Åed as both conditionals
satisfy the positivity condition required for the Hammersley-CliÔ¨Äord Theorem to hold.
H.2.2 Proof of Proposition 29
Proof The likelihood is Gaussian with a Ô¨Åxed variance parameter œÉ2, i.e. for yi ‚ààRd with
i = 1, 2, . . . , n
p(yi|f L
i ) = (2œÄœÉ2)‚àí0.5d exp

‚àí1
2œÉ2 (yi ‚àíf L
i )T (yi ‚àíf L
i )

With this, note that integrating out the normal density yields
Ip,c(f L
i ) = (2œÄœÉ2)‚àí0.5dcc‚àí0.5d.
(31)
Note in particular that this is a constant and does not depend on f, which makes computing
the expectation over q(f L
i ) depend only on the power likelihood. Next, we show that the
89

Knoblauch, Jewson and Damoulas
power likelihood is also available in closed form. This is laborious but not diÔ¨Écult and relies
on the same algebraic tricks in the Appendix of Knoblauch et al. (2018). To simplify notation,
we write f = f L
i . Note also that the variational parameters ¬µ and Œ£ are (stochastic)
functions of the draws of f 1:L‚àí1
i
from the previous layers, but we suppress this dependency,
again for readability.
Eq(f|¬µ,Œ£)
1
cp(yi|f)c

= 1
c(2œÄœÉ2)‚àí0.5dc ¬∑ Eq(f|¬µ,Œ£)
h
exp
n
‚àíc
2œÉ2 (yT
i yi + f T f ‚àí2f T yi)
oi
= 1
c(2œÄœÉ2)‚àí0.5dc exp
n
‚àíc
2œÉ2 yT
i yi
o
¬∑ Eq(f|¬µ,Œ£)
h
exp
n
‚àíc
2œÉ2 (f T f ‚àí2f T yi)
oi
= 1
c(2œÄœÉ2)‚àí0.5dc(2œÄœÉ2)‚àí0.5d|Œ£|‚àí0.5 exp
n
‚àíc
2œÉ2 yT
i yi
o
√ó
Z
exp

‚àí1
2
 c
œÉ2 f T f ‚àí2c
œÉ2 f T yi + (f ‚àí¬µ)T Œ£‚àí1(f ‚àí¬µ)

df
= 1
c(2œÄœÉ2)‚àí0.5dc(2œÄ)‚àí0.5d|Œ£|‚àí0.5 exp

‚àí1
2
 c
œÉ2 yT
i yi + ¬µT Œ£‚àí1¬µ

√ó
Z
exp

‚àí1
2
 c
œÉ2 f T f ‚àí2c
œÉ2 f T yi + f T Œ£‚àí1f ‚àí2f T Œ£‚àí1¬µ

df
The integral suggests one can obtain a closed form through the Gaussian integral by completing
the squares. DeÔ¨Åning eŒ£‚àí1 =
  c
œÉs Id + Œ£‚àí1
, e¬µ =
  c
œÉ2 yi + Œ£‚àí1¬µ

, b¬µ = eŒ£e¬µ, one indeed has
c
œÉ2 f T f ‚àí2c
œÉ2 f T yi + f T Œ£‚àí1f ‚àí2f T Œ£‚àí1¬µ = f T 
Id
c
œÉ2 + Œ£‚àí1
f ‚àí2f T  c
œÉ2 yi + Œ£‚àí1¬µ

= (f ‚àíb¬µ)T eŒ£‚àí1 (f ‚àíb¬µ) ‚àíe¬µT eŒ£e¬µ,
which allows us to Ô¨Ånally rewrite the integral as
Z
exp

‚àí1
2
 c
œÉ2 f T f ‚àí2c
œÉ2 f T yi + f T Œ£‚àí1f ‚àí2f T Œ£‚àí1¬µ

df
= exp

‚àí1
2 e¬µT eŒ£e¬µ
 Z
exp

‚àí1
2 (f ‚àíb¬µ)T eŒ£‚àí1 (f ‚àíb¬µ)

df = exp
1
2 e¬µT eŒ£e¬µ

(2œÄ)0.5d|eŒ£|0.5.
Putting everthing together and simplifying expressions, this means that
Eq(f|¬µ,Œ£)
1
cp(yi|f)c

= 1
c
 2œÄœÉ2‚àí0.5dc |eŒ£|0.5
|Œ£|0.5 exp

‚àí1
2
 c
œÉ2 yT
i yi + ¬µT Œ£‚àí1¬µ ‚àíe¬µT eŒ£e¬µ

Depending on whether one uses the Œ≤- or Œ≥-divergence for robustifying the loss, one thus
obtains the closed form expressions
Eq(f|¬µ,Œ£)

‚àí
1
Œ≤ ‚àí1p(yi|f)Œ≤‚àí1 + Ip,Œ≤(f)
Œ≤

= Eq(f|¬µ,Œ£)

‚àí
1
Œ≤ ‚àí1p(yi|f)Œ≤‚àí1

+ Ip,Œ≤(f)
Œ≤
Eq(f|¬µ,Œ£)
"
‚àí
1
Œ≥ ‚àí1p(yi|f)Œ≥‚àí1 ¬∑
Œ≥
Ip,Œ≥(f)
Œ≥‚àí1
Œ≥
#
= Eq(f|¬µ,Œ£)

‚àí
1
Œ≥ ‚àí1p(yi|f)Œ≥‚àí1

¬∑
Œ≥
Ip,Œ≥(f)
Œ≥‚àí1
Œ≥
,
with the expectation over q(f|¬µ, Œ£) as in and the integrals Ip,Œ≤(f), Ip,Œ≥(f) as deÔ¨Åned above.
Note that we have derived the general case for yi ‚ààRd, where Œ£, f and ¬µ are matrix- and
90

Generalized Variational Inference
4.5
5.0
5.5
6.0
6.5
D3 = D(0.5)
AR
1/w=2.0
VI (1/w = 1.0)
1/w=0.5
p,
= 1.01, D3 = D(0.5)
AR
p,
= 1.01, 1/w = 2.0
p,
= 1.01, 1/w = 1.0
p,
= 1.01, 1/w = 0.5
p,
= 1.05, D3 = D(0.5)
AR
p,
= 1.05, 1/w = 2.0
p,
= 1.05, w = 1.0
p,
= 1.05, 1/w = 0.5
concrete
0.50
0.75
1.00
1.25
1.50
1.75
energy
0.060 0.061 0.062 0.063 0.064 0.065 0.066
kin8mn
3.0
3.5
4.0
4.5
5.0
5.5
D3 = D(0.5)
AR
1/w=2.0
VI (1/w = 1.0)
1/w=0.5
p,
= 1.01, D3 = D(0.5)
AR
p,
= 1.01, 1/w = 2.0
p,
= 1.01, 1/w = 1.0
p,
= 1.01, 1/w = 0.5
p,
= 1.05, D3 = D(0.5)
AR
p,
= 1.05, 1/w = 2.0
p,
= 1.05, w = 1.0
p,
= 1.05, 1/w = 0.5
concrete
0.75
1.00
1.25
1.50
1.75
2.00
energy
1.38
1.36
1.34
1.32
1.30
1.28
kin8mn
Figure 23: Best viewed in color. Top row depicts RMSE, bottom row the NLL across a range
of data sets using DGPs with L = 3 layers. Dots correspond to means, whiskers the standard
errors. The further to the left, the better the predictive performance.
vector-valued.
In fact, we can simplify everything even further in the univariate case. We summarize this in
the next part.
Remark 53 Since the derivation of Salimbeni and Deisenroth (2017) shows that one in
fact only needs to integrate over the marginals f L
i , if d = 1 (as in all experiments in both
this paper and (Salimbeni and Deisenroth, 2017)), the computation corresponding to the
expression above simpliÔ¨Åes considerably as no matrix inverses and determinants are needed.
In particular, denoting the uni-variate mean and variance parameters as ¬µ, Œ£ and deÔ¨Åning
eŒ£ =
1
c
œÉs + 1
Œ£ and e¬µ =
  cyi
œÉ2 + ¬µ
Œ£

, the expectation term over the posterior q simpliÔ¨Åes to
Eq(f|¬µ,Œ£)
1
cp(yi|f)c

= 1
cs
 2œÄœÉ2‚àí0.5c
s
eŒ£
Œ£ ¬∑ exp

‚àí1
2
cy2
i
œÉ2 + ¬µ2
Œ£ ‚àíe¬µ2eŒ£

.
91

Knoblauch, Jewson and Damoulas
H.2.3 Additional experiments varying D (Figure 23)
While we showed that DGPs allow for the variation of both losses and uncertainty quantiÔ¨Åers,
the main paper did not use the Ô¨Çexibility aÔ¨Äorded by varying D. The main reason for this is
that much like for the BNNs, the results when jointly varying loss and uncertainty quantiÔ¨Åer
are less intuitively interpretable. We showcase this in Figure 23, which compares a number
of diÔ¨Äerent GVI posteriors for DGPs with L = 3 layers. The loss is either the robust loss LŒ≥
p
for Œ≥ ‚àà{1.01, 1.05} (top 8 entries in each row) or the standard log score (bottom 4 entries
in each row). We also compare D = 1
w KLD for w = 2.0, 1.0, 0.5 as well as the composite
layer-wise divergence
D(q‚à•œÄ) =
3
X
l=1
Dl(ql‚à•œÄl),
D1 = D2 = KLD, D3 = D(Œ±)
AR for Œ± = 0.5.
Aligned with the intuition that the priors in DGPs are rather informative due to various
hyperparameter optimization schemes, changing the uncertainty quantiÔ¨Åer from the KLD
to the D(Œ±)
AR generally typically has either fairly little or even adverse impact. Similarly, up-
or down-weighting the KLD seems not to be beneÔ¨Åcial across the board and will depend on
the loss function. For the case of the log score however, we Ô¨Ånd a consistent improvement
for down-weighting the KLD: Predictively, it improves the predictions on both metrics
and across all data sets relative to standard VI. Similarly, up-weighting the KLD term is
counterproductive under the log score and yields a performance deterioration across all data
sets. This indicates that despite best eÔ¨Äorts to the contrary, DGPs are probably violating (P)
so that their predictive performance can be enhanced by ignoring more prior information,
ensuring posteriors that are concentrated around the empirical risk minimizer.
References
Ryan Prescott Adams and David J. C. MacKay. Bayesian online changepoint detection.
arXiv preprint arXiv:0710.3742, 2007.
James Aitchison. Goodness of prediction Ô¨Åt. Biometrika, 62(3):547‚Äì554, 1975.
Alexander A. Alemi. Variational predictive information bottleneck. In Workshop on Infor-
mation Theory, Advances in Neural Information Processing Systems, 2019.
Pierre Alquier and Benjamin Guedj. Simpler PAC-Bayesian bounds for hostile data. Machine
Learning, 107(5):887‚Äì902, 2018.
Pierre Alquier, James Ridgway, and Nicolas Chopin.
On the properties of variational
approximations of Gibbs posteriors. The Journal of Machine Learning Research, 17(1):
8374‚Äì8414, 2016.
Shun-ichi Amari. DiÔ¨Äerential-geometrical methods in statistics, volume 28. Springer Science
& Business Media, 2012.
Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, An-
drew Gordon Wilson, and Eytan Bakshy. BoTorch: Programmable Bayesian optimization
in PyTorch. arXiv preprint arXiv:1910.06403, 2019.
92

Generalized Variational Inference
Alessandro Barp, Francois-Xavier Briol, Andrew B. Duncan, Mark Girolami, and Lester
Mackey. Minimum Stein discrepancy estimators. Advances in Neural Information Processing
Systems, 2019.
Ayanendranath Basu, Ian R. Harris, Nils L. Hjort, and M. C. Jones. Robust and eÔ¨Écient
estimation by minimising a density power divergence. Biometrika, 85(3):549‚Äì559, 1998.
Thomas Bayes. An essay towards solving a problem in the doctrine of chances. Philosophical
Transactions of the Royal Society of London, 53:370‚Äì418, 1763.
Matthew James Beal. Variational algorithms for approximate Bayesian inference. University
College London, 2003.
Luc B√©gin, Pascal Germain, Fran√ßois Laviolette, and Jean-Francis Roy. PAC-Bayesian bounds
based on the R√©nyi divergence. In ArtiÔ¨Åcial Intelligence and Statistics, pages 435‚Äì444,
2016.
James O. Berger. The case for objective Bayesian analysis. Bayesian analysis, 1(3):385‚Äì402,
2006.
James O Berger and Jos√© M Bernardo. On the development of the reference prior method.
Bayesian statistics, 4(4):35‚Äì60, 1992.
James O. Berger, El√≠as Moreno, Luis Raul Pericchi, M. Jes√∫s Bayarri, Jos√© M. Bernardo,
Juan A. Cano, Juli√°n De la Horra, Jacinto Mart√≠n, David R√≠os-Ins√∫a, Dasgupta A. Betr√≤,
Bruno, Paul Gustafson, Larry Wasserman, Joseph B. Kadane, Cid Srinivasan, Michael
Lavine, Anthony O‚ÄôHagan, Wolfgang Polasek, Christian P. Robert, Constantinos Goutis,
Fabrizio Ruggeri, Gabriella Salinetti, and Siva Sivaganesan. An overview of robust Bayesian
analysis. Test, 3(1):5‚Äì124, 1994.
Jose M. Bernardo. Reference posterior distributions for Bayesian inference. Journal of the
Royal Statistical Society: Series B (Methodological), 41(2):113‚Äì128, 1979.
Jos√© M. Bernardo. Bayesian theory. Wiley Series in Probability and Statistics. 23 cm. 586
p., 2000.
Alexandros Beskos, Natesh Pillai, Gareth Roberts, Jesus-Maria Sanz-Serna, and Andrew
Stuart. Optimal tuning of the hybrid Monte Carlo algorithm. Bernoulli, 19(5A):1501‚Äì1534,
2013.
William Bialek, Ilya Nemenman, and Naftali Tishby. Predictability, complexity, and learning.
Neural computation, 13(11):2409‚Äì2463, 2001.
Pier Giovanni Bissiri, Chris Holmes, and Stephen Walker. A general framework for up-
dating belief distributions. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 78(5):1103‚Äì1130, 2016.
Edwin V. Bonilla, Karl Krauth, and Amir Dezfouli. Generic inference in latent Gaussian
process models. Journal of Machine Learning Research, 20(117):1‚Äì63, 2019.
93

Knoblauch, Jewson and Damoulas
Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy
Bengio. Generating sentences from a continuous space. In Proceedings of The 20th SIGNLL
Conference on Computational Natural Language Learning, pages 10‚Äì21, Berlin, Germany,
August 2016. Association for Computational Linguistics.
George E. P. Box. Sampling and Bayes‚Äô inference in scientiÔ¨Åc modelling and robustness.
Journal of the Royal Statistical Society. Series A (General), pages 383‚Äì430, 1980.
Thang Bui, Daniel Hern√°ndez-Lobato, Jose Hernandez-Lobato, Yingzhen Li, and Richard
Turner. Deep Gaussian processes for regression using approximate expectation propagation.
In International Conference on Machine Learning, pages 1472‚Äì1481, 2016.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders.
In International Conference on Learning Representations, 2016.
Fran√ßois Caron, Arnaud Doucet, and Raphael Gottardo. On-line changepoint detection and
parameter estimation with application to genomic data. Statistics and Computing, 22(2):
579‚Äì595, 2012.
Liqun Chen, Chenyang Tao, Ruiyi Zhang, Ricardo Henao, and Lawrence Carin Duke.
Variational inference and model selection with generalized evidence bounds. In International
Conference on Machine Learning, pages 892‚Äì901, 2018.
Badr-Eddine Ch√©rief-Abdellatif and Pierre Alquier. MMD-Bayes: Robust Bayesian estimation
via maximum mean discrepancy. arXiv preprint arXiv:1909.13339, 2019.
Herman ChernoÔ¨Ä. A measure of asymptotic eÔ¨Éciency for tests of a hypothesis based on the
sum of observations. The Annals of Mathematical Statistics, 23(4):493‚Äì507, 1952.
Anna Choromanska, Mikael HenaÔ¨Ä, Michael Mathieu, G√©rard Ben Arous, and Yann LeCun.
The loss surfaces of multilayer networks. In ArtiÔ¨Åcial Intelligence and Statistics, pages
192‚Äì204, 2015.
Andrzej Cichocki and Shun-ichi Amari. Families of alpha-beta-and gamma-divergences:
Flexible and robust measures of similarities. Entropy, 12(6):1532‚Äì1568, 2010.
Imre Csisz√°r. I-divergence geometry of probability distributions and minimization problems.
The Annals of Probability, pages 146‚Äì158, 1975.
Kurt Cutajar, Edwin V Bonilla, Pietro Michiardi, and Maurizio Filippone. Random feature
expansions for deep Gaussian processes. In Proceedings of the 34th International Conference
on Machine Learning-Volume 70, pages 884‚Äì893. JMLR, 2017a.
Kurt Cutajar, Edwin V Bonilla, Pietro Michiardi, and Maurizio Filippone. Random feature
expansions for deep Gaussian processes. In Proceedings of the 34th International Conference
on Machine Learning-Volume 70, pages 884‚Äì893. JMLR. org, 2017b.
Z. Dai, A. Damianou, J. Gonzalez, and N. Lawrence. Variational auto-encoded deep Gaussian
processes. In International Conference on Learning Representations, 2016.
94

Generalized Variational Inference
Andreas Damianou and Neil Lawrence. Deep Gaussian processes. In ArtiÔ¨Åcial Intelligence
and Statistics, pages 207‚Äì215, 2013.
Herbert Aron David. First (?) occurrence of common terms in probability and statistics‚Äîa
second list, with corrections. The American Statistician, 52(1):36‚Äì40, 1998.
A Philip Dawid, Monica Musio, and Laura Ventura.
Minimum scoring rule inference.
Scandinavian Journal of Statistics, 43(1):123‚Äì138, 2016.
Pierre-Simon De Laplace. M√©moire sur la probabilit√© des causes par les √©v√©nements. M√©m.
de math. et phys. pr√©sent√©s √† l‚ÄôAcad. roy. des sci, 6:621‚Äì656, 1774.
Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from in-
complete data via the EM algorithm. Journal of the Royal Statistical Society: Series B
(Methodological), 39(1):1‚Äì22, 1977.
Adji Bousso Dieng, Dustin Tran, Rajesh Ranganath, John Paisley, and David Blei. Variational
inference via œá upper bound minimization. In Advances in Neural Information Processing
Systems, pages 2732‚Äì2741, 2017.
Justin Domke and Daniel R. Sheldon. Importance weighting and variational inference. In
Advances in neural information processing systems, pages 4470‚Äì4479, 2018.
Monroe D Donsker and SR Srinivasa Varadhan. Asymptotic evaluation of certain Markov
process expectations for large time, i. Communications on Pure and Applied Mathematics,
28(1):1‚Äì47, 1975.
Paul Fearnhead and Zhen Liu. On-line inference for multiple changepoint problems. Journal
of the Royal Statistical Society: Series B (Statistical Methodology), 69(4):589‚Äì605, 2007.
Stephen E Fienberg. When did Bayesian inference become "Bayesian"? Bayesian analysis, 1
(1):1‚Äì40, 2006.
Ronald Aylmer Fisher. Contributions to mathematical statistics. 1950.
Edwin Fong and Chris Holmes. On the marginal likelihood and cross-validation. arXiv
preprint arXiv:1905.08737, 2019.
Hironori Fujisawa and Shinto Eguchi. Robust parameter estimation with a small bias against
heavy contamination. Journal of Multivariate Analysis, 99(9):2053‚Äì2081, 2008.
Futoshi Futami, Issei Sato, and Masashi Sugiyama. Variational inference based on robust
divergences. In Proceedings of the Twenty-First International Conference on ArtiÔ¨Åcial
Intelligence and Statistics, volume 84 of Proceedings of Machine Learning Research, pages
813‚Äì822. PMLR, 2018.
Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. Posterior regularization for struc-
tured latent variable models. Journal of Machine Learning Research, 11:2001‚Äì2049, 2010.
95

Knoblauch, Jewson and Damoulas
Jacob Gardner, GeoÔ¨ÄPleiss, Kilian Q. Weinberger, David Bindel, and Andrew G. Wilson.
Gpytorch: Blackbox matrix-matrix Gaussian process inference with GPU acceleration. In
Advances in Neural Information Processing Systems, pages 7576‚Äì7586, 2018.
Pascal Germain, Francis Bach, Alexandre Lacoste, and Simon Lacoste-Julien. PAC-Bayesian
theory meets Bayesian inference. In Advances in Neural Information Processing Systems,
pages 1884‚Äì1892, 2016.
Subhashis Ghosal. A review of consistency and convergence rates of posterior distributions.
In Proc. Varanasi Symp. on Bayesian Inference, 1998.
Subhashis Ghosal, Jayanta K Ghosh, and Aad W Van Der Vaart. Convergence rates of
posterior distributions. Annals of Statistics, 28(2):500‚Äì531, 2000.
Abhik Ghosh and Ayanendranath Basu. Robust Bayes estimation using the density power
divergence. Annals of the Institute of Statistical Mathematics, 68(2):413‚Äì437, 2016.
Manuel Gil. On R√©nyi divergence measures for continuous alphabet sources. PhD thesis,
2011.
Manuel Gil, Fady Alajaji, and Tamas Linder. R√©nyi divergence measures for commonly used
univariate continuous distributions. Information Sciences, 249:124‚Äì131, 2013.
M Goldstein. InÔ¨Çuence and belief adjustment. InÔ¨Çuence Diagrams, Belief Nets and Decision
Analysis, pages 143‚Äì174, 1990.
Michael Goldstein. Subjective Bayesian analysis: principles and practice. Bayesian Analysis,
1(3):403‚Äì420, 2006.
Peter Gr√ºnwald. Safe learning: bridging the gap between Bayes, MDL and statistical learning
theory via empirical convexity. In Proceedings of the 24th Annual Conference on Learning
Theory, pages 397‚Äì420, 2011.
Peter Gr√ºnwald. The safe Bayesian. In International Conference on Algorithmic Learning
Theory, pages 169‚Äì183. Springer, 2012.
Peter Gr√ºnwald and Thijs Van Ommen. Inconsistency of Bayesian inference for misspeciÔ¨Åed
linear models, and a proposal for repairing it. Bayesian Analysis, 12(4):1069‚Äì1103, 2017.
Benjamin Guedj. A primer on PAC-Bayesian learning. arXiv preprint arXiv:1901.05353,
2019.
Oliver Hamelijnck, Theodoros Damoulas, Kangrui Wang, and Mark Girolami. Multi-resolution
multi-task gaussian processes. In Advances in Neural Information Processing Systems,
2019.
Frank R Hampel, Elvezio M Ronchetti, Peter J Rousseeuw, and Werner A Stahel. Robust
statistics: the approach based on inÔ¨Çuence functions, volume 196. John Wiley & Sons,
2011.
96

Generalized Variational Inference
Pashupati Hegde, Markus Heinonen, Harri L√§hdesm√§ki, and Samuel Kaski. Deep learning
with diÔ¨Äerential gaussian process Ô¨Çows. In The 22nd International Conference on ArtiÔ¨Åcial
Intelligence and Statistics, pages 1812‚Äì1821, 2019.
James Hensman and Neil D. Lawrence. Nested variational compression in deep Gaussian
processes. stat, 1050:3, 2014.
Jos√© Miguel Hern√°ndez-Lobato and Ryan Adams. Probabilistic backpropagation for scalable
learning of Bayesian neural networks. In International Conference on Machine Learning,
pages 1861‚Äì1869, 2015.
Jos√© Miguel Hern√°ndez-Lobato, Yingzhen Li, Mark Rowland, Daniel Hern√°ndez-Lobato,
Thang D Bui, and Richard E Turner. Black-box Œ±-divergence minimization. In Proceedings
of the 33rd International Conference on International Conference on Machine Learning-
Volume 48, pages 1511‚Äì1520, 2016.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew
Botvinick, Shakir Mohamed, and Alexander Lerchner.
beta-vae: Learning basic vi-
sual concepts with a constrained variational framework. In International Conference on
Learning Representations, volume 3, 2017.
Matthew D HoÔ¨Äman, David M Blei, Chong Wang, and John Paisley. Stochastic variational
inference. The Journal of Machine Learning Research, 14(1):1303‚Äì1347, 2013.
Chris Holmes and Stephen Walker. Assigning a value to a power likelihood in a general
bayesian model. Biometrika, 104(2):497‚Äì503, 2017.
Giles Hooker and Anand N Vidyashankar. Bayesian model robustness via disparities. Test,
23(3):556‚Äì584, 2014.
Chin-Wei Huang, Shawn Tan, Alexandre Lacoste, and Aaron C. Courville. Improving
explorability in variational inference with annealed variational objectives. In Advances in
Neural Information Processing Systems, pages 9724‚Äì9734, 2018.
Hung Hung, Zhi-Yu Jou, and Su-Yun Huang. Robust mislabel logistic regression without
modeling mislabel probabilities. Biometrics, 74(1):145‚Äì154, 2018.
Aapo Hyv√§rinen. Estimation of non-normalized statistical models by score matching. Journal
of Machine Learning Research, 6:695‚Äì708, 2005.
Martin Jankowiak, GeoÔ¨ÄPleiss, and Jacob R Gardner. Sparse gaussian process regression
beyond variational inference. arXiv preprint arXiv:1910.07123, 2019.
Edwin T. Jaynes. Probability theory: The logic of science. Cambridge university press, 2003.
H. JeÔ¨Äreys. Theory of probability: Oxford Univ. Press (earlier editions 1939, 1948), 1961.
Jack Jewson, Jim Smith, and Chris Holmes. Principles of Bayesian inference using general
divergence criteria. Entropy, 20(6):442, 2018.
97

Knoblauch, Jewson and Damoulas
Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An
introduction to variational methods for graphical models. Machine learning, 37(2):183‚Äì233,
1999.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In
International Conference on Learning Representations, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. In International
Conference on Learning Representations, 2013.
Jeremias Knoblauch. Frequentist consistency of generalized variational inference. arXiv
preprint arXiv:1912.04946, 2019a.
Jeremias Knoblauch. Robust deep Gaussian processes. arXiv preprint arXiv:1904.02303,
2019b.
Jeremias Knoblauch and Theodoros Damoulas. Spatio-temporal Bayesian on-line changepoint
detection with model selection. In Proceedings of the 27th International Conference on
Machine Learning (ICML), 2018.
Jeremias Knoblauch, Jack Jewson, and Theodoros Damoulas. Doubly robust Bayesian
inference for non-stationary streaming data using Œ≤-divergences. In Advances in Neural
Information Processing Systems (NeurIPS), pages 64‚Äì75, 2018.
Solomon Kullback and Richard A Leibler. On information and suÔ¨Éciency. The annals of
mathematical statistics, 22(1):79‚Äì86, 1951.
Sebastian Kurtek and Karthik Bharath. Bayesian sensitivity analysis with the Fisher‚ÄìRao
metric. Biometrika, 102(3):601‚Äì616, 2015.
Tomasz Ku≈õmierczyk, Joseph Sakaya, and Arto Klami. Variational Bayesian decision-making
for continuous utilities. In Advances in Neural Information Processing Systems, 2019.
Simon Lacoste-Julien, Ferenc Husz√°r, and Zoubin Ghahramani. Approximate inference for
the loss-calibrated Bayesian. In Proceedings of the Fourteenth International Conference on
ArtiÔ¨Åcial Intelligence and Statistics, pages 416‚Äì424, 2011.
Ga√´l Letarte, Pascal Germain, Benjamin Guedj, and Fran√ßois Laviolette. Dichotomize and
generalize: Pac-bayesian binary activated deep neural networks. In Advances in Neural
Information Processing Systems, 2019.
Yingzhen Li and Richard E Turner. R√©nyi divergence variational inference. In Advances in
Neural Information Processing Systems, pages 1073‚Äì1081, 2016.
Moshe Lichman. UCI machine learning repository, 2013.
F Liese and I Vajda. Convex statistical distances, volume 95 of teubner texts in mathematics.
BSB BG Teubner Verlagsgesellschaft, Leipzig, 1987.
98

Generalized Variational Inference
Gabriel Loaiza-Ganem and John P. Cunningham. The continuous Bernoulli: Ô¨Åxing a pervasive
error in variational autoencoders. In Advances in Neural Information Processing Systems,
2019.
David J. C. MacKay. Bayesian methods for backpropagation networks. In Models of neural
networks III, pages 211‚Äì254. Springer, 1996.
David J. C. MacKay. Choice of basis for Laplace approximation. Machine learning, 33(1):
77‚Äì86, 1998.
Alexander G. de G. Matthews, James Hensman, Richard Turner, and Zoubin Ghahramani.
On sparse variational methods and the Kullback-Leibler divergence between stochastic
processes. Journal of Machine Learning Research, 51:231‚Äì239, 2016.
Alexander G. de G. Matthews, Mark Van Der Wilk, Tom Nickson, Keisuke Fujii, Alexis
Boukouvalas, Pablo Le√≥n-Villagr√°, Zoubin Ghahramani, and James Hensman. GpÔ¨Çow: A
Gaussian process library using tensorÔ¨Çow. The Journal of Machine Learning Research, 18
(1):1299‚Äì1304, 2017.
David A. McAllester. Some PAC-Bayesian theorems. Machine Learning, 37(3):355‚Äì363,
1999a.
David A. McAllester. PAC-Bayesian model averaging. In Proceedings of the twelfth annual
conference on Computational learning theory, pages 164‚Äì170. ACM, 1999b.
Minami Mihoko and Shinto Eguchi. Robust blind source separation by beta divergence.
Neural computation, 14(8):1859‚Äì1886, 2002.
JeÔ¨Ärey W. Miller and David B. Dunson. Robust Bayesian inference via coarsening. Journal
of the American Statistical Association, 114(527):1113‚Äì1125, 2019.
Thomas Minka. Divergence measures and message passing. Technical report, Technical
report, Microsoft Research, 2005.
Thomas P Minka. Expectation propagation for approximate Bayesian inference. In Proceedings
of the Seventeenth conference on Uncertainty in artiÔ¨Åcial intelligence, pages 362‚Äì369.
Morgan Kaufmann Publishers Inc., 2001.
Tomoyuki Nakagawa and Shintaro Hashimoto. Robust Bayesian inference via Œ≥-divergence.
Communications in Statistics-Theory and Methods, pages 1‚Äì18, 2019.
Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science &
Business Media, 2012.
Radford M Neal and GeoÔ¨Ärey E Hinton. A view of the EM algorithm that justiÔ¨Åes incremental,
sparse, and other variants. In Learning in graphical models, pages 355‚Äì368. Springer, 1998.
Anthony O‚ÄôHagan and Jeremy E Oakley. Probability is perfect, but we can‚Äôt elicit it perfectly.
Reliability Engineering & System Safety, 85(1):239‚Äì248, 2004.
99

Knoblauch, Jewson and Damoulas
Manfred Opper and Ole Winther. Gaussian processes for classiÔ¨Åcation: Mean-Ô¨Åeld algorithms.
Neural computation, 12(11):2655‚Äì2684, 2000.
Joseph J. K. O‚ÄôRuanaidh. Numerical Bayesian methods applied to signal processing. PhD
thesis, University of Cambridge, 1994.
John Paisley, David M. Blei, and Michael I. Jordan. Variational Bayesian inference with
stochastic search. In Proceedings of the 29th International Coference on International
Conference on Machine Learning, pages 1363‚Äì1370, 2012.
Francesco Pauli, Walter Racugno, and Laura Ventura. Bayesian composite marginal likeli-
hoods. Statistica Sinica, pages 149‚Äì164, 2011.
Fengchun Peng and Dipak K Dey. Bayesian analysis of outlier problems using divergence
measures. Canadian Journal of Statistics, 23(2):199‚Äì213, 1995.
Joaquin Qui√±onero-Candela and Carl Edward Rasmussen. A unifying view of sparse ap-
proximate Gaussian process regression. Journal of Machine Learning Research, 6(Dec):
1939‚Äì1959, 2005.
Rajesh Ranganath, Sean Gerrish, and David Blei. Black box variational inference. In
ArtiÔ¨Åcial Intelligence and Statistics, pages 814‚Äì822, 2014.
Rajesh Ranganath, Dustin Tran, Jaan Altosaar, and David Blei. Operator variational
inference. In Advances in Neural Information Processing Systems, pages 496‚Äì504, 2016.
Jean-Baptiste Regli and Ricardo Silva. Alpha-beta divergence for variational inference. arXiv
preprint arXiv:1805.01045, 2018.
Alfr√©d R√©nyi. On measures of entropy and information. In Proceedings of the Fourth Berkeley
Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the
Theory of Statistics. The Regents of the University of California, 1961.
Mathieu Ribatet, Daniel Cooley, and Anthony C Davison. Bayesian inference from composite
likelihoods, with an application to spatial extremes. Statistica Sinica, pages 813‚Äì845, 2012.
Gareth O Roberts and JeÔ¨Ärey S Rosenthal. Optimal scaling of discrete approximations
to Langevin diÔ¨Äusions. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 60(1):255‚Äì268, 1998.
Gareth O Roberts, Andrew Gelman, and Walter R Gilks. Weak convergence and optimal
scaling of random walk Metropolis algorithms. The annals of applied probability, 7(1):
110‚Äì120, 1997.
Simone Rossi, Sebastien Marmin, and Maurizio Filippone. Walsh-Hadamard variational
inference for Bayesian deep learning. arXiv preprint arXiv:1905.11248, 2019a.
Simone Rossi, Pietro Michiardi, and Maurizio Filippone. Good initializations of variational
Bayes for deep models. In Proceedings of the 36th International Conference on Machine
Learning, volume 97, pages 5487‚Äì5497, 2019b.
100

Generalized Variational Inference
H√•vard Rue, Sara Martino, and Nicolas Chopin. Approximate Bayesian inference for latent
Gaussian models by using integrated nested Laplace approximations. Journal of the royal
statistical society: Series b (statistical methodology), 71(2):319‚Äì392, 2009.
Yunus Saat√ßi, Ryan D. Turner, and Carl E. Rasmussen. Gaussian process change point
models. In Proceedings of the 27th International Conference on Machine Learning, pages
927‚Äì934, 2010.
Abhijoy Saha, Karthik Bharath, and Sebastian Kurtek. A geometric variational approach to
bayesian inference. Journal of the American Statistical Association, pages 1‚Äì25, 2019.
Tim Salimans and David A Knowles. On using control variates with stochastic approximation
for variational Bayes and its connection to stochastic linear regression. arXiv preprint
arXiv:1401.1022, 2014.
Hugh Salimbeni and Marc Deisenroth. Doubly stochastic variational inference for deep
Gaussian processes. In Advances in Neural Information Processing Systems, pages 4588‚Äì
4599, 2017.
John Shawe-Taylor and Robert C Williamson. A PAC analysis of a Bayesian estimator. In
Annual Workshop on Computational Learning Theory: Proceedings of the tenth annual
conference on Computational learning theory, volume 6, pages 2‚Äì9, 1997.
Xiaotong Shen and Larry Wasserman. Rates of convergence of posterior distributions. The
Annals of Statistics, 29(3):687‚Äì714, 2001.
Zhenming Shun and Peter McCullagh. Laplace approximation of high dimensional integrals.
Journal of the Royal Statistical Society: Series B (Methodological), 57(4):749‚Äì760, 1995.
Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs.
In Advances in neural information processing systems, pages 1257‚Äì1264, 2006.
Casper Kaae S√∏nderby, Tapani Raiko, Lars Maal√∏e, S√∏ren Kaae S√∏nderby, and Ole Winther.
Ladder variational autoencoders. In Advances in neural information processing systems,
pages 3738‚Äì3746, 2016.
Luke Tierney and Joseph B Kadane. Accurate approximations for posterior moments and
marginal densities. Journal of the american statistical association, 81(393):82‚Äì86, 1986.
Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottleneck method.
arXiv preprint physics/0004057, 2000.
Michalis Titsias. Variational learning of inducing variables in sparse Gaussian processes. In
ArtiÔ¨Åcial Intelligence and Statistics, pages 567‚Äì574, 2009.
Michalis Titsias and Miguel L√°zaro-Gredilla. Doubly stochastic variational Bayes for non-
conjugate inference. In International Conference on Machine Learning, pages 1971‚Äì1979,
2014.
John W Tukey. A survey of sampling from contaminated distributions. Contributions to
probability and statistics, pages 448‚Äì485, 1960.
101

Knoblauch, Jewson and Damoulas
R. E. Turner and M. Sahani. Two problems with variational expectation maximisation for
time-series models. In Bayesian time series models. Cambridge University Press, 2011.
Ryan D. Turner, Steven Bottone, and Clay J. Stanek. Online variational approximations
to non-exponential family change point models: with application to radar tracking. In
Advances in Neural Information Processing Systems, pages 306‚Äì314, 2013.
Keyon Vafa. Training deep Gaussian processes with sampling. In NIPS 2016 Workshop on
Advances in Approximate Bayesian Inference, 2016.
Tim Van Erven and Peter Harremos. R√©nyi divergence and Kullback-Leibler divergence.
IEEE Transactions on Information Theory, 60(7):3797‚Äì3820, 2014.
Cristiano Varin, Nancy Reid, and David Firth. An overview of composite likelihood methods.
Statistica Sinica, pages 5‚Äì42, 2011.
Stephen Walker. New approaches to Bayesian consistency. The Annals of Statistics, 32(5):
2028‚Äì2043, 2004.
Dilin Wang, Hao Liu, and Qiang Liu. Variational inference with tail-adaptive f-divergence.
In Advances in Neural Information Processing Systems, pages 5742‚Äì5752, 2018.
Ke Alexander Wang, GeoÔ¨ÄPleiss, Jacob R Gardner, Stephen Tyree, Kilian Q Weinberger,
and Andrew Gordon Wilson. Exact Gaussian processes on a million data points. arXiv
preprint arXiv:1903.08114, 2019.
Yali Wang, Marcus Brubaker, Brahim Chaib-Draa, and Raquel Urtasun. Sequential inference
for deep Gaussian process. In ArtiÔ¨Åcial Intelligence and Statistics, pages 694‚Äì703, 2016.
Christopher KI Williams and Matthias Seeger. Using the Nystr√∂m method to speed up kernel
machines. In Advances in neural information processing systems, pages 682‚Äì688, 2001.
Robert C Wilson, Matthew R Nassar, and Joshua I Gold. Bayesian online learning of the
hazard rate in change-point problems. Neural computation, 22(9):2452‚Äì2476, 2010.
Mike Wu, Noah Goodman, and Stefano Ermon. DiÔ¨Äerentiable antithetic sampling for variance
reduction in stochastic variational inference. In Proceedings of Machine Learning Research,
volume 89, pages 2877‚Äì2886, 2019.
Yue Yang, Ryan Martin, and Howard Bondell. Variational approximations using Fisher
divergence. arXiv preprint arXiv:1905.05284, 2019.
Yun Yang, Debdeep Pati, and Anirban Bhattacharya. Œ±-variational inference with statistical
guarantees. arXiv preprint arXiv:1710.03266, 2017.
Arnold Zellner. Maximal data information prior distributions. New developments in the
applications of Bayesian methods, pages 211‚Äì232, 1977.
Arnold Zellner.
Optimal information processing and Bayes‚Äôs theorem.
The American
Statistician, 42(4):278‚Äì280, 1988.
102

Generalized Variational Inference
Guodong Zhang, Shengyang Sun, David Duvenaud, and Roger Grosse. Noisy natural gradient
as variational inference. In Jennifer Dy and Andreas Krause, editors, Proceedings of the
35th International Conference on Machine Learning, volume 80, pages 5852‚Äì5861, 2018.
Jun Zhu, Ning Chen, and Eric P Xing. Bayesian inference with posterior regularization and
applications to inÔ¨Ånite latent svms. The Journal of Machine Learning Research, 15(1):
1799‚Äì1847, 2014.
103

