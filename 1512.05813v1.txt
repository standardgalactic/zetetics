arXiv:1512.05813v1  [cs.LO]  17 Dec 2015
An Introduction to Eﬀectus Theory
Kenta Cho, Bart Jacobs, Bas Westerbaan, Abraham Westerbaan
Institute for Computing and Information Sciences (iCIS),
Radboud University Nijmegen, The Netherlands.
Email: {K.Cho,bart,bwesterb,awesterb}@cs.ru.nl
December 21, 2015
Abstract
Eﬀectus theory is a new branch of categorical logic that aims to cap-
ture the essentials of quantum logic, with probabilistic and Boolean logic
as special cases. Predicates in eﬀectus theory are not subobjects having a
Heyting algebra structure, like in topos theory, but ‘characteristic’ func-
tions, forming eﬀect algebras. Such eﬀect algebras are algebraic models
of quantitative logic, in which double negation holds. Eﬀects in quantum
theory and fuzzy predicates in probability theory form examples of eﬀect
algebras.
This text is an account of the basics of eﬀectus theory. It includes the
fundamental duality between states and eﬀects, with the associated Born
rule for validity of an eﬀect (predicate) in a particular state.
A basic
result says that eﬀectuses can be described equivalently in both ‘total’
and ‘partial’ form. So-called ‘commutative’ and ‘Boolean’ eﬀectuses are
distinguished, for probabilistic and classical models. It is shown how these
Boolean eﬀectuses are essentially extensive categories. A large part of the
theory is devoted to the logical notions of comprehension and quotient,
which are described abstractly as right adjoint to truth, and as left adjoint
to falisity, respectively. It is illustrated how comprehension and quotients
are closely related to measurement. The paper closes with a section on
‘non-commutative’ eﬀectus theory, where the appropriate formalisation is
not entirely clear yet.
1

Contents
1
Introduction
3
2
Notation
7
3
Eﬀectuses
11
3.1
Examples of eﬀectuses . . . . . . . . . . . . . . . . . . . . . . . .
18
4
The structure of partial maps and predicates
26
5
State and eﬀect triangles
35
6
Eﬀectuses from biproduct categories
41
7
Kernels and images
45
7.1
Kernels
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
7.2
Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
8
Relating total and partial maps
58
8.1
FinPACs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
8.2
FinPACs with eﬀects . . . . . . . . . . . . . . . . . . . . . . . . .
60
9
Commutative and Boolean eﬀectuses
65
10 Monoidal eﬀectuses
75
10.1 Commutative eﬀectuses via copiers . . . . . . . . . . . . . . . . .
80
11 Comprehension
82
12 Quotients
96
13 Boolean eﬀectuses and extensive categories
106
14 Combining comprehension and quotients
114
15 Towards non-commutative eﬀectus theory
130
15.1 Uniqueness of assert maps, in von Neumann algebras . . . . . . . 138
16 Conclusions and future work
143
References
145
Notation Index
150
Subject Index
152
2

1
Introduction
Eﬀectus theory is a new branch of categorical logic that started with [Jac15a].
The theory is already used in several other publications, such as [JWW15,
Cho15, CJWW15, Ada14, AJ15], and is being actively developed. Therefore
we think that it is appropriate to provide a systematic, accessible introduction
to this new area.
The aim of eﬀectus theory is to axiomatise the categorical characteristics
of quantum computation and logic. This axiomatisation should include proba-
bilistic and classical computation and logic as special cases. The relevant logical
structure is described in terms of eﬀect algebras. Such algebras have been in-
troduced in theoretical physics to describe generalised (quantum) probability
theories, see [FB94], and also [CK95, GG94]. Eﬀect algebras generalise both
classical logic, in the form of Boolean algebras, and quantitative logic, with the
unit interval [0, 1] of real numbers as main example. The double negation law
holds in such eﬀect algebras. One of the basic insights of [Jac15a] is that cer-
tain elementary categorical structure — involving coproducts and pullbacks —
provides predicates with eﬀect algebra structure.
In the usual set-theoretic world one can deﬁne predicates on a set X as
subsets P ⊆X or equivalently as characteristic functions p: X →2, where
2 = 1+1 = {0, 1} is the two-element set. The ‘subset’ or ‘spatial’ approach is the
basis for much of categorical logic where predicates are described as subobjects
P ֌ X.
In topos theory, there is a bijective correspondence between such
subobjects of X and characteristic maps X →Ωto a distinguished ‘classiﬁer’
object Ω. These predicates on an object X in a topos form a Heyting algebra,
a basic formalisation of intuitionistic logic, in which the double negation law
fails. Topos theory has developed into a rich area of mathematics, combining
geometry and logic, see for instance the handbooks [MM92] or [Joh02].
Eﬀectus theory breaks with this spatial approach and uses maps of the form
X →1 + 1 as predicates. Negation then corresponds to swapping of outcomes
in 1 + 1, so that the double negation law immediately holds. As mentioned,
predicates in an eﬀectus are not Heyting algebras, but eﬀect algebras: their
logic is completely diﬀerent.
The current text provides an introduction to this new area. It starts with
some basic results from the original source [Jac15a]. But it diﬀers from [Jac15a]
in that it combines the total and partial perspectives on eﬀectuses right from
the beginning, working towards the equivalence of these two approaches, as
developed in [Cho15]. Similarly, this article provides a systematic description
of quotients and comprehension in eﬀectuses, which are neatly described as a
chain of four adjunctions in a row, which quotients as left adjoint to falsity,
and comprehension as right adjoint to truth. This extends [CJWW15] where
quotients and comprehension are described only concretely, in speciﬁc examples.
This paper contains several deﬁnitions and results that have not been pub-
lished before, such as:
• the construction of eﬀectuses from ‘grounded’ biproduct categories in Sec-
tion 6;
• the deﬁnition of commutative (probabilistic) eﬀectuses and Boolean (clas-
3

sical) eﬀectuses in Section 9, giving a picture:
☛
✡
✟
✠
Boolean
eﬀectuses
⊆
☛
✡
✟
✠
commutative
eﬀectuses
⊆
☛
✡
✟
✠
(non-commutative)
eﬀectuses
The adjective ‘non-commutative’ means ‘arbitrary’; it is only used to dis-
tinguish the general case from the two special subcases.
• the equivalence between a Boolean eﬀectus with comprehension and the
well-known notion of extensive category; this gives many examples of
(Boolean) eﬀectuses, including categories of (compact Hausdorﬀ) topo-
logical spaces, and of measurable spaces; also, the opposite CRngop of
the category of commutative rings is an example, see [CJWW15, Jac15a];
• the ﬁrst steps in non-commutative — properly quantum — eﬀectus theory.
A recurring topic in eﬀectus theory is the association of an ‘assert’ partial
map asrtp : X →X + 1 with a predicate p: X →1 + 1. This assert map is
the ‘action’ of the predicate and is typical for a quantum setting, where an
observation, determined by a predicate, may have a side-eﬀect and disturb the
system under observation. In a commutative or Boolean eﬀectus one does have
such action maps asrtp, but they are side-eﬀect free.
This is formalised by
saying that these assert maps are below the identity, in a suitable partial order
on partial maps. Indeed, the identity map does nothing, so maps below the
identity also do not change the state. This predicate-action correspondence is
one of the main topics.
Four running examples are used throughout the text, namely:
1. the category Sets of sets and functions, which is a Boolean eﬀectus;
2. the Kleisli category Kℓ(D) of the distribution monad D on Sets, which is
a commutative eﬀectus, modeling discrete probabilistic computation;
3. the opposite OUGop of the category OUG of order unit groups, which is
used as a relatively simple toy example to illustrate some basic notions;
4. the opposite vNAop of the category vNA of von Neumann algebras, which
is the prime example of a non-commutative eﬀectus.
The last two categories occur in opposite form because they incorporate Heisen-
berg’s view where quantum computations are predicate transformers which op-
erate in opposite direction, transforming predicates on the post-state to predi-
cates on the pre-state.
The insight that these diverse examples are all instance of the notion of
eﬀectus has signiﬁcant value. It allows us to grasp in these examples what,
for instance, the comprehension or quotient structure of an eﬀectus amounts
to. These descriptions can be non-trivial and hard to understand without the
abstract categorical viewpoint. This applies in particular to von Neumann al-
gebras, where the ‘opposite’ interpretation can be confusing, and where no-
tions like support projection exist already for a long time (see e.g. [Sak71,
Dfn. 1.10.3]), but without their proper universal properties.
4

This text uses von Neumann algebras (or W ∗-algebras) instead of C∗-alge-
bras. The key aspect of von Neumann algebras that we use is that that pred-
icates/eﬀects form a directed complete poset. This allows us to deﬁne for an
arbitrary predicate/eﬀect p the least sharp predicate ⌈p⌉above p. This con-
struction is crucial for images, comprehension and for quotients. Additionally,
(normal) states separate predicates in von Neumann algebras, which is used
in the quotient construction. These two properties, directed completeness and
separation characterise von Neumann algebras among C∗-algebras, following
Kadison [Kad56, Dfn. 1 and Thm. 1] (see also [Ren14]).
Before starting, we would like to put eﬀectus theory in broader perspec-
tive. The Oxford school in categorical quantum theory started with [AC04],
see the recent books [HV15] and [CKar]. This approach takes the tensor ⊗
for parallel composition as the main ingredient of quantum theory — following
Schr¨odinger’s emphasis on composite systems, and not von Neumann’s focus
on measurement, see [CL13, §§2.2]. In the associated graphical calculus this
tensor is represented simply via paralell wires. This gives a powerful formalism
in which many protocols can be described. Coproducts (or biproducts) played
a role originally, but have become less prominent, probably because they do not
work well in a projective (i.e. ‘scalar-free’) setting [CD11] and make the graph-
ical calculus more complicated. The main examples for the Oxford school are
so-called dagger-compact closed monoidal categories, such as Hilbert spaces, sets
and relations, or ﬁnite-dimensional C∗-algebras and completely positive maps.
In contrast, in eﬀectus theory the coproduct + is taken as primitive construc-
tor (and not the tensor ⊗), leading to a strong emphasis on logic, validity and
measurement, with the category of von Neumann algebras as leading quantum
example. A connection with the Oxford school exists via the CP∗-categories
(with biproducts) of [CHK14]. Section 6 below shows that the causal maps in a
‘grounded’ biproduct category — including CP∗-categories — form an eﬀectus.
Tensors can be added to an eﬀectus, see Section 10, and lead to a much richer
theory, more closely connected to the Oxford school. But tensors are not essen-
tial for the deﬁnition of an eﬀectus theory, and for the associated logic of eﬀect
algebras.
Other connections are emerging in recent work [Tul16] on operational prob-
abilistic theories [CDP10] and eﬀectuses.
This makes it possible to transfer
methods and results in existing quantum theory and eﬀectus theory back and
forth.
One may ask: is eﬀectus theory the new topos theory? It is deﬁnitely too
early to say. But what hopefully becomes clear from this introduction is that
eﬀectus theory is a rich novel direction in categorical logic that promises to cap-
ture essential aspects of the quantum world and to provide a unifying framework
that includes the probabilistic and Boolean worlds as special cases.
This text gives a survey of ﬁrst results in the theory of eﬀectuses. Some
parts focus more on explaining ideas and examples, and some parts serve as
reference for basic facts — with long series of results. We brieﬂy discuss the
contents of the various sections. First, a separate section is devoted to notation,
where distinct notation is introduced and explained for total and partial maps.
Then, Section 3 introduces the central notion of eﬀectus, as a category with
coproducts (+, 0) and a ﬁnal object 1 satisfying certain elementary axioms. This
same section describes categorical consequences of these axioms, in particular
about partial projections and pairing, and introduces the leading examples of
5

eﬀectuses. Section 4 continues the exploration and focuses on the partial monoid
structure (>, 0) on partial maps X →Y + 1 in an eﬀectus. Predicates X →
1 + 1 are a special case and have additional structure: it is shown that they
form eﬀect algebras with scalar multiplication — making them eﬀect modules.
Subsequently, Section 5 shows that states 1 →X of an object X in an eﬀectus
form convex sets, and that the basic adjunction between eﬀect modules and
convex sets gives what is called a state-and-eﬀect triangle of the form:
(EModM)op
Hom(−,M)
-
⊤
ConvM
Hom(−,M)
m
B
Hom(−,1+1)=Pred
e❑❑❑❑❑❑❑❑❑❑
Stat=Hom(1,−)
;✇
✇
✇
✇
✇
✇
✇
✇
✇
where B is an eﬀectus and M = Pred(1) is the eﬀect monoid of scalars in B,
see Theorem 28 for details. In this situation we can describe the Born rule for
validity ω |= p of a predicate p: X →1 + 1 and a state ω: 1 →X simply via
composition, as scalar p ◦ω: 1 →1 + 1.
Section 6 describes a new construction — inspired by CP∗-categories [CHK14]
— to obtain an eﬀectus as the subcategory of ‘causal’ maps in a biproduct cate-
gory with special ground maps
. Many examples of eﬀectuses can be obtained
(and understood) in this way, where, for instance, causal maps correspond to
the unital ones. Subsequently, Section 7 is more auxiliary: it introduces kernels
and images in an eﬀectus and collects many basic results about them that will be
used later on. A basic result in the theory of eﬀectuses, namely the equivalence
of the descriptions in terms of total and partial maps, is the topic of Section 8,
following [Cho15]. It plays a central role in the theory, and once we have seen it,
we freely switch between the two descriptions, by using phrases like an ‘eﬀectus
in total form’, or an ‘eﬀectus in partial form’.
Special axioms in an eﬀectus are identiﬁed in Section 9 that capture proba-
bilistic models and Boolean models as special cases. Section 10 describes tensors
⊗in an eﬀectus, for parallel composition. These tensors come equipped with
projections X ←X ⊗Y →Y , for weakening/discarding. But these tensors do
not have copiers/diagonals X →X ⊗X, since contraction/duplication/cloning
does not exist in the quantum world. We show that if copiers exist, then the
eﬀectus becomes commutative.
The subsequent two Sections 11 and 12 introduce the important notions of
comprehension {X|p} and quotients X/p for a predicate p on an object X in
an eﬀectus. These notions are nicely captured categorically as right adjoint to
truth and as left adjoints to falisity, in a chain of comprehesions:
quotient ⊣falsity ⊣forget ⊣truth ⊣comprehension
Such chains exist in all our leading examples, see also [CJWW15]. The combi-
nation of comprehension and quotients is studied in Section 14.
Inbetween, Section 13 returns to Boolean eﬀectuses and gives a new charac-
terisation: it shows that Boolean eﬀectuses with comprehension are essentially
the same as extensive categories. The latter are well-known kinds of categories
in which ﬁnite coproducts (+, 0) are well-behaved.
Our ﬁnal Section 15 is of a diﬀerent nature because it describes some unclar-
ities in the theory of eﬀectuses which require further research. What is unclear
6

is the precise formalisation of the general non-commutative case that captures
the essentials of quantum theory. This involves the intruiging relations between
the predicate-action correspondence for measurement on the one hand, and quo-
tients and comprehension on the other. We show that the ‘assert’ action maps
are uniquely determined by postulates in von Neumann algebras, but we cannot,
at this stage, prove uniqueness at a general, axiomatic level. More directions
for future research are collected in Section 16.
2
Notation
In the theory of eﬀectuses, both total and partial maps play an important role.
When reasoning in an eﬀectus one often switches between total and partial maps.
Since this may lead to confusion, we address this topic explicitly in the current
section, before introducing the notion of eﬀectus itself in the next section.
There are two equivalent ways of deﬁning eﬀectuses, see Section 8 for details.
1. The ‘total’ approach starts from a category of total maps, and introduces
partial maps as special, Kleisli maps for the lift monad (−) + 1 in a larger
enveloping Kleisli category. This is how eﬀectuses were originally intro-
duced in [Jac15a].
2. The ‘partial’ approach starts from a category of partial maps, and de-
scribes the total maps via a smaller ‘wide’ subcategory with the same
objects where the total maps are singled out via a special property. This
approach comes from [Cho15].
In both cases we have a faithful functor between two categories with the same
objects:
 
total
maps
!
 
/
 
partial
maps
!
These categories each have their own form of composition. In order to disam-
biguate them we shall use diﬀerent notation, for the time being, namely
and
. In fact, we shall also use diﬀerent notation for morphisms, namely →and
→, and also for sums of maps, namely + and +. These notational diﬀerences
are relevant as long as we have not established the precise relationship between
total and partial maps, see Theorem 53. Once we know the relationship, we
re-evaluate the situation in Discussion 54.
Only at that stage do we see clearly how to switch back-and-forth, and can
decide whether to take total or partial maps as ﬁrst class citizens.
Total maps
Let B be a category with ﬁnite coproducts (+, 0) and a ﬁnal object 1 ∈B. We
consider the maps in B as total, and we write the coprojections κi and cotupling
[−, −] as maps:
X1
κ1 / X1 + X2
X2
and
X1 + X2
κ2
o
[f1,f2] / Y
for
Xi
fi / Y
The sum of two maps f : X →A, g : Y →B is written as f + g = [κ1
f, κ2
g]: X + Y →A + B. The n-fold coproduct X + · · · + X of the same object
7

X is usually written as n · X, and called a copower.
We use the notation
∇= [id, id]: X + X →X for the codiagonal.
For an arbitrary object X ∈B we write !X, or simply !, both for the unique
map from 0 to X, and for the unique map from X to 1, as in:
0
!
/ X
X
!
/ 1
Partial maps
A partial map is a map of the form X →Y +1. As is well-known, the assignment
X 7→X + 1 forms a monad on the category B. It is often called the lift or the
maybe monad. The unit of this monad is the ﬁrst coprojection κ1 : X →X + 1,
and the multiplication is the cotuple [id, κ2]: (X + 1) + 1 →X + 1. We shall
write Par(B) for the Kleisli category of this lift monad.
Its objects are the
objects of B, and its maps from X to Y , written as X →Y , are morphisms
X →Y + 1 in B. Thus, (ordinary) maps in Par(B) are partial maps in B.
Composition of f : X →Y and g : Y →Z in Par(B) is written as g f : X →Z,
and is described in Par(B) and in B as:
g
f =

X
f / Y
g / Z

=

X
f / Y + 1
[g,κ2]
/ Z + 1

.
Each map h: X →Y in B gives rise to a map ‹h›: X →Y in Par(B), namely:
‹h› =

X
h
/ Y
κ1
/ Y + 1

.
We call such maps in Par(B) of the form ‹h› total, and write them with this (sin-
gle) guillemet notation ‹−›. Later on, in Lemma 7, we shall see an alternative
characterisation of total maps, which will be much more useful.
The identity on X in Par(B) is then the (total) map ‹idX› = κ1 : X →X.
There is an identity-on-objects functor B →Par(B), which we simply write as
‹−›. It preserves composition, since:
‹k›
‹h› = [κ1
k, κ2] κ1
h = κ1
k h = ‹k h›.
It is also not hard to see that:
g
‹h› = g
h
and
‹k›
f = (k + id) f.
The initial object 0 ∈B is a zero object in Par(B), because there are unique
maps 0 →X and X →0 in Par(B), namely the maps !: 0 →X + 1 and
!: X →0 + 1 ∼= 1 in B. Hence, for each pair of objects X, Y there is a special
zero map between them in Par(B), deﬁned as:

X
0 / Y

=

X
! / 1
κ2 / Y + 1

.
Notice that 0
g = 0 = f
0 for all (partial) maps f, g. Notice that we write
this zero map 0 in bold face, in order to distinguish it from the zero object 0.
In general, we shall write the top and bottom element of a poset as such bold
8

face 1 and 0. Frequently, the zero map is indeed the bottom element in a poset
structure on homsets.
The presence of this zero map 0 allows us to deﬁne kernel and cokernel maps
in Par(B), like in Abelian categories, namely as (co)equaliser of a map X →Y
and the zero map 0: X →Y . This will appear later.
The coproducts (+, 0) in B also form coproducts in Par(B). The coprojec-
tions in Par(B) are:
X1
‹κ1›=κ1 κ1
/ X1 + X2
X2
‹κ2›=κ1 κ2
o
The cotuple [f, g] in Par(B) is the same as in B. For two maps f : X →A and
g : Y →B there is thus a sum of maps f + g : X + Y →A + B in Par(B), which
is deﬁned in B as:
f + g =

X + Y
[(κ1+id) f,(κ2+id) g]
/ (A + B) + 1

.
It is not hard to see that:

‹f›, ‹g›

= ‹[f, g]›
and
‹h› + ‹k› = ‹h + k›.
The coproduct X1 +X2 in Par(B) comes with ‘partial projections’ ✄i : X1 +
X2 →Xi, described in B as:
X1 + 1
X1 + X2
✄1=id+!
o
✄2=[κ2 !,κ1] / X2 + 1
(1)
Equivalently they can be described in Par(B) via the zero map 0 as cotuples:
X1
X1 + X2
✄1=[id,0]
o
✄2=[0,id]
/ X2
(2)
These partial projections are natural in Par(B), in the sense that:
✄i
(f1 + f2) = fi
✄i.
(3)
It is easy to deﬁne these projections ✄i : X1 + · · · + Xn →Xi for n-ary coprod-
ucts.
The coproduct + in Par(B) forms what is sometimes called a ‘split product’
or ‘butterﬂy’ product (see e.g. [Gra12, 2.1.7]): the following triangles commute
in Par(B), where the two diagonals are zero maps:
X
❘
❘
❘
❘
‹κ1›
(❘
❘
❘
❘
Y
❧❧❧❧
‹κ2›
v❧❧❧❧
X + Y
❧❧❧❧
✄1
v❧❧❧❧
❘
❘
❘
❘
✄2
(❘
❘
❘
❘
X
Y
(4)
In particular, the coprojections ‹κi› are split monos, and the projections ✄i are
split epis in Par(B).
In this diagram (4) we write ‹κ1›: X →X + Y for the coprojection in a
category of partial maps Par(B). Similarly we have written ‹id› for the identity
in Par(B). From now on we shall omit these guillemets ‹−› for coprojections
and identities when the context is clear. Thus we simply write κ1 : X →X + Y
and id : X →X for a coprojection or identity map in Par(B).
9

Predicates and predicate transformers
In the context of eﬀectus theory a predicate on an object X is a total map of
the form X →1 + 1, or equivalently, a partial map X →1. The predicates 1
for true and 0 for false are given by:
1 =

X
! / 1
κ1 / 1 + 1

0 =

X
! / 1
κ2 / 1 + 1

.
The zero predicate on X is thus the zero map X →1. The negation, called
orthosupplement in this setting, of a predicate p: X →1 + 1 is obtained by
swapping the outcomes:
p⊥=

X
p / 1 + 1
[κ2,κ1]
∼
=
/ 1 + 1

.
(5)
Clearly, p⊥⊥= p and 1⊥= 0. One may expect that these predicates X →1+1
form a Boolean algebra, but this is not true in general. When B is an eﬀectus,
the predicates on X form an eﬀect algebra.
This is one of the fundamental
results of eﬀectus theory, see Section 4 for details. The double negation law
p⊥⊥= p always holds in an eﬀect algebra.
We use two kinds of re-indexing or substitution operations for a map, each
transferring predicates on the codomain to predicates on the domain. For total
maps f : Y →X and partial maps g : Y →X we write:
f ∗(p) =

Y
f / X
p / 1 + 1

g✷(p) =

Y
g / X + 1
[p,κ1] / 1 + 1

.
(6)
The idea is that f ∗(p) is true on an input to f iﬀp is true on its output.
Similarly, g✷(p) is true on an input to g iﬀeither g does not terminate, or g
terminates and p is true on its output (i.e. if g terminates then p is true on the
output). The ‘box’ notation g✷suggests this modal reading, see also the De
Morgan dual g✸in point (4) below.
The next result collects some basic observations. The proofs are easy and
left to the reader.
Exercise 1. The two substitution (or modal) operations (−)∗and (−)✷for total
and partial maps satisfy:
1. id∗(p) = p and (f2
f1)∗(p) = f ∗
1
 f ∗
2 (p)

;
2. ‹id›✷(p) = p and (g2
g1)✷(p) = g✷
1
 g✷
2 (p)

;
3. ‹f›✷(p) = f ∗(p);
4. g✷(p) = (p⊥
g)⊥= g✸(p⊥)⊥, if we deﬁne g✸(q) = q
f;
5. f ∗(p⊥) = f ∗(p)⊥and f ∗(1) = 1, and thus also f ∗(0) = 0;
6. g✷(1) = 1.
□
10

3
Eﬀectuses
In this section we give the deﬁnition of eﬀectus, we provide several leading
examples, and we prove some basic categorical results about eﬀectuses. The
deﬁnition below is slightly simpler than the original one in [Jac15a]. We shall
show that the requirements used below are equivalent to the original ones, see
Lemma 3 (1). There is no clear intuition behind the nature of the axioms below:
they ensure that coproducts are well-behaved and provide the logical structure
that will be described in Section 4.
Deﬁnition 2. An eﬀectus is a category B with ﬁnite coproducts (+, 0) and a
ﬁnal object 1, such that both:
1. diagrams of the following form are pullbacks in B:
X + Y
id+! /
!+id

X + 1
!+id

X
!
/
κ1

1
κ1

1 + Y
id+! / 1 + 1
X + Y
!+! / 1 + 1
(7)
2. the following two maps are jointly monic in B:
(1 + 1) + 1
···
··✎✎=[[κ1,κ2],κ2]
-
···
··✴✴✎✎✎✎=[[κ2,κ1],κ2]
1 1 + 1
(8)
Joint monicity means that if f, g satisfy ···
··✎✎
f = ···
··✎✎
g and ···
··✴✴✎✎✎✎
f = ···
··✴✴✎✎✎✎
g,
then f = g.
A map of the form X →1 + 1, or equivalently X →1, will be called a
predicate on X ∈B. We write Pred(X) for the collection of predicates on X.
Predicates of the special form 1 →1 + 1 are also called scalars.
A state is a total map of the form 1 →X, and a substate is a partial map
1 →X. We write Stat(X) and SStat(X) for the collections of such states and
substates of X.
The diagram on the left in (7) provides a form of partial pairing for compat-
ible partial maps, see Lemma 6 below; the diagram on the right ensures that
coprojections are disjoint, see Proposition 4 below. The joint monicity require-
ment (8) is equivalent to joint monicity of partial projections, see Lemma 5
below. It captures a form of cancellation. The symbols ···
··✎✎and ···
··✴✴✎✎✎✎should suggest
what these two maps do, as functions from a 3-element set to a 2-element set,
read downwards.
The diagram on the right in (7) only mentions the ﬁrst coprojection κ1 : X →
X + Y . A corresponding pullback exists for the second coprojection κ2 : Y →
X + Y since it is related to κ1 via the swap isomorphism X + Y ∼= Y + X.
Similarly, the results below only mention the ﬁrst (co)projection, but hold for
the second one as well.
An important property of eﬀectuses is that predicates in an eﬀectus have
the logical structure of an eﬀect module. This will be elaborated in the next
few sections.
11

The next few results describe some categorical consequences of the structure
in an eﬀectus.
They focus especially on pullbacks.
We recall the following
general result, known as the Pullback Lemma: consider a situation with two
commuting squares A and B,
·
/

·
/

·

A
B
·
/ ·
/ ·
Then: if B is a pullback, then A is a pullback if and only if the outer rectangle
is a pullback.
Lemma 3. Let B be a category with ﬁnite coproducts and a ﬁnal object, in
which the squares (7) in the deﬁnition of an eﬀectus are pullbacks.
1. Rectangles of the following forms are also pullbacks in B.
X + Y
id+g /
f+id

X + B
f+id

X
f
/
κ1

A
κ1

A + Y
id+g / A + B
X + Y
f+g / A + B
(9)
2. In the category Par(B) of partial maps the following squares are pullbacks,
where f : X →A and g : Y →B are total maps.
X + Y
id+‹g›/
‹f›+id

X + B
‹f›+id

X + Y
‹f›+id/
✄1

A + Y
✄1

A + Y
id+‹g›/ A + B
X
‹f›
/ A
(10)
Recall that we write ✄i for the partial projection maps from (2).
The rectangles in (7) used to deﬁne eﬀectuses are instances of the more
general formulations (9) provided in this lemma.
Proof We start with the diagram on the left in (9). Suppose we have h: C →
A + Y and k: C →X + B satisfying (id + g)
h = (f + id)
k. Consider the
following diagram.
C
ℓ
#
h
!
k
%
(!+id) h
!
(id+!) k
%
X + Y
id+g /
f+id

X + B
f+id

id+! / X + 1
f+id

A + Y
id+g /
!+id

A + B
id+! /
!+id

A + 1
!+id

1 + Y
id+g / 1 + B
id+! / 1 + 1
12

The outer diagram commutes since:
(id + !) (id + g) (! + id) h = (id + !) (! + id) (id + g) h
= (id + !) (! + id) (f + id) k
= (! + id) (f + id) (id + !) k.
The outer rectangle, consisting of all four squares, is a pullback since it is
an instance of the pullback on the left in (7). Hence there is a unique map
ℓ: C →A + B with (! + id)
ℓ= (! + id)
h and (id + !)
ℓ= (id + !)
k. We
obtain (f + id)
ℓ= h by uniqueness of mediating maps, since the lower two
squares form a pullback, again by (7). Similarly (id + g) ℓ= k holds because
the two square on the right together form a pullback.
In a similar way we show that the diagram on the right in (9) is a pullback:
let h: C →X + Y and k: C →A satisfy (f + g) h = κ1
k. Then we have a
situation:
C
ℓ
#
h
"
k
$
!
$
X
f
/
κ1

A
κ1

!
/ 1
κ1

X + Y
f+g / A + B
!+! / 1 + 1
Since the two squares together and the square on the right form a pullback, as
on the right in (7). Hence we obtain a unique map ℓ: C →X with κ1
ℓ= h.
We get f
ℓ= k by uniqueness of mediating maps, using the pullback on the
right.
We turn to the diagram (10) in the category Par(B). We write α for the
standard associativity isomorphism U + (V + W) →(U + V ) + W in B, given
explicitly by α = [κ1
κ1, κ2 + id] and α−1 = [id + κ1, κ2
κ2]. For total maps
f : X →A and g : Y →B we have commuting diagrams in B:
X + (Y + 1)
f+id

α
∼
= / (X + Y ) + 1
[‹f›+id,κ2]

A + (Y + 1)
α
∼
= / (A + Y ) + 1
X + (Y + 1)
id+(g+id)/
α
∼
=

(X + B) + 1
α
∼
=

(X + Y ) + 1
[id+‹g›,κ2]
/ (X + B) + 1
As a result, the rectangle on the left below is a pullback in B, since it is related
via the associativity isomorphisms α to the rectangle on the right, which is a
pullback by (9).
(X + Y ) + 1
[id+‹g›,κ2]/
[‹f›+id,κ2]

(X + B) + 1
[‹f›+id,κ2]

X + (Y + 1)
id+(g+id)/
f+id

X + (B + 1)
f+id

(A + Y ) + 1
[id+‹g›,κ2]/ (A + B) + 1
A + (Y + 1)
id+(g+id)/ A + (B + 1)
The fact that the above rectangle on the left is a pullback in B implies that the
rectangle on the left in (10) is a pullback in Par(B).
13

We use basically the same trick for the diagram on the right in (10). Let
h: C →X and k: C →A + Y be (partial) maps with ‹g›
h = ✄1
k. When
translated to the category B the latter equation becomes (g+id) h = [✄1, κ2] k.
C
h
#
ℓ
%
α−1 k
(
X + (Y + 1)
f+id /
id+!

❴✤
A + (Y + 1)
id+!=[✄1,κ2] α

X + 1
f+id
/ A + 1
The rectangle is a pullback, as instance of the square on the left in (9). Then
ℓ′ = α ℓ: C →X + Y is the required mediating map in Par(B).
□
Proposition 4. In an eﬀectus coprojections κi : Xi →X1 + X2 are monic and
disjoint, and the initial object 0 is strict.
An easy consequence of this result is that for an eﬀectus B the canonical
functor ‹−›: B →Par(B) from B to the Kleisli category Par(B) of the lift
monad (−) + 1 is faithful. This is the case because ‹f› = κ1
f, and κ1 is
monic.
Proof The ﬁrst coprojection κ1 : A →A+ B is monic since, using the pullback
on the right in (9), we get a diagram as on the left below. Its two rectangles are
pullbacks, and so their combination too.
A❴✤
A❴✤
κ1
∼
=

A
κ1

A
κ1
∼
=
/
κ1
7
A + 0
id+! / A + B
0
■
■
■
■
∼
=
$■
■
■
■

/ X
κ2
∼
= 
!
κ2
~
0 + 0❴✤
/

0 + X
!+id 
A / κ1
∼
=
/
&
κ1
7
A + 0
id+! / A + X
The above diagram on the right shows that the intersection (pullback) of κ1, κ2
is the initial object 0: the small rectangle is a pullback since it is an instance of
the pullback on the left in (9). Hence the outer rectangle is a pullback via the
isomorphisms in the diagram.
Strictness of the initial object 0 means that each map f : X →0 is an
isomorphism. For such a map, we have to prove that the composite X →0 →X
14

is the identity. Consider the diagram:
X
f
$

κ2
!
# 0 ❴✤

κ1

0
κ1=κ2

0 + X
id+f /
[!,id]

0 + 0
X
The rectangle is a pullback, as on the right in (9). By initiality of 0, we have
κ1 = κ2 : 0 →0 + 0, so that the outer diagram commutes. Then we get the
dashed map, as indicated, which must be f : X →0. But now we are done:
! f = [!, id] κ1
f = [!, id] κ2 = id.
□
The next result shows that the joint monicity requirement in the deﬁnition
of an eﬀectus has many equivalent formulations.
Lemma 5. Let B be a category with ﬁnite coproducts and a ﬁnal object, in which
the squares in (7) are pullbacks. Then the following statements are equivalent.
1. The category B is an eﬀectus, that is, the two maps ···
··✎✎, ···
··✴✴✎✎✎✎: (1 + 1) + 1 →
1 + 1 in (8) are jointly monic in B.
2. The two partial projection maps ✄1, ✄2 : 1 + 1 →1 are jointly monic in
Par(B).
3. For each object X, the two partial projection maps ✄1, ✄2 : X + X →X
are jointly monic in Par(B).
4. For each pair of objects X1, X2, the two projections ✄i : X1 + X2 →Xi
are jointly monic in Par(B).
5. For each n-tuple of objects X1, . . . , Xn, with n ≥1, the n projections
✄i : X1 + · · · + Xn →Xi are jointly monic in Par(B).
Proof The implication (1) ⇒(2) is a simple reformulation, using that ···
··✎✎=
[✄1, κ2] and ···
··✴✴✎✎✎✎= [✄2, κ2].
For the implication (2) ⇒(3), let f, g : Y →X + X satisfy ✄i
f = ✄i
g : Y →X for i = 1, 2. Consider the following diagram in Par(B).
Y
f
!
g
(
X + X
❴✤
‹!›+id /
id+‹!›

✄2
(
✄1

1 + X❴✤
✄2
/
id+‹!›

X
‹!›

X + 1❴✤
‹!›+id
/
✄1

1 + 1
✄2
/
✄1

1
X
‹!›
/ 1
15

All rectangles are pullbacks in Par(B) by Lemma 3 (2). The deﬁnitions f ′ =
(‹!› + ‹!›)
f and g′ = (‹!› + ‹!›)
g yield equal maps Y →1 + 1 by point (2),
since ✄i
f ′ = ‹!›
✄i
f = ‹!›
✄i
g = ✄i
g′ by (3). But then:
(
(‹!› + id)
f = (‹!› + id)
g
by the upper right pullback
(id + ‹!›)
f = (id + ‹!›)
g
by the lower left pullback.
Hence f = g by the upper left pullback.
For the implication (3) ⇒(4) let f, g : Z →X1 + X2 satisfy ✄i
f = ✄i
g.
The trick is to consider (κ1 + κ2)
f, (κ1 + κ2)
g : Z →(X1 + X2) + (X1 + X2)
instead. They satisfy, by naturality (3) of the partial projections:
✄i
(κ1 + κ2)
f = κi
✄i
f
= κi
✄i
g
= ✄i
(κ1 + κ2)
g.
We obtain (κ1 + κ2)
f = (κ1 + κ2)
g from point (3). But then we are done:
f = ∇
(κ1 + κ2)
f = ∇
(κ1 + κ2)
g = g.
The implication (4) ⇒(5) is obtained via induction. Finally, the implication
(5) ⇒(1) is trivial.
□
In an eﬀectus these partial projections ✄i are projections for a ‘partial pair-
ing’ operation ⟨⟨−, −⟩⟩that will be described next. In fact one can understand
the pullback on the left in (7) in the deﬁnition of eﬀectus as precisely providing
such a pairing for maps which are suitably orthogonal to each other. Later on,
in Section 7 we can make this requirement more precise in terms of kernels that
are each other’s orthosupplement.
Lemma 6. In an eﬀectus, each pair of partial maps f : Z →X and g : Z →Y
with 1
f = (1
g)⊥, determines a unique total map ⟨⟨f, g⟩⟩: Z →X + Y with:
✄1
⟨⟨f, g⟩⟩= f
and
✄2
⟨⟨f, g⟩⟩= g.
Uniqueness gives equations:
⟨⟨f, g⟩⟩h = ⟨⟨f
h, g
h⟩⟩
and
⟨⟨✄1
k, ✄2
k⟩⟩= k
(11)
for each h: W →Z and k: Z →X + Y . Also, for total maps h, k we have:
(h + k) ⟨⟨f, g⟩⟩= ⟨⟨‹h›
f, ‹k›
g⟩⟩.
(12)
Note that the partial composite 1
f can be unfolded to:
1
f = [1, κ2] f = [κ1
!, κ2] f = (! + id) f.
This map 1
(−) plays an important role, see also Lemma 7 below. It is the
orthosupplement of the kernel operation, see Section 7 below.
16

Proof The assumption 1
f = (1
g)⊥says that the outer diagram commutes
in:
Z
[κ2,κ1] g
!
f
%
⟨⟨f,g⟩⟩
#
X + Y
id+! /
!+id

❴✤
X + 1
!+id

1 + Y
id+! / 1 + 1
The (inner) rectangle is a pullback by (7), yielding the pairing ⟨⟨f, g⟩⟩as the
unique total map with ✄1
⟨⟨f, g⟩⟩= (id + !) ⟨⟨f, g⟩⟩= f and:
✄2
⟨⟨f, g⟩⟩= [κ2, κ1] (! + id) ⟨⟨f, g⟩⟩= [κ2, κ1] [κ2, κ1] g = g.
Clearly, ⟨f, g⟩is the unique (mediating) total map Z →X + Y satisfying these
equations. The equations (11) follow directly from this uniqueness property.
Finally, the equation (12) is obtained from uniqueness of mediating maps in
pullback like the one above:
(id + !) (h + k) ⟨⟨f, g⟩⟩= (h + id) (id + !) ⟨⟨f, g⟩⟩
= (h + id) f
= ‹h›
f
(! + id) (h + k) ⟨⟨f, g⟩⟩= (id + k) (! + id) ⟨⟨f, g⟩⟩
= (id + k) [κ2, κ1] g
= [κ2, κ1] (k + id) g
= [κ2, κ1] (‹k›
g).
□
This partial pairing ⟨⟨−, −⟩⟩will be generalised later, see Lemma 43, and the
end of Discussion 54. It plays an important role in the sequel, for instance in
decomposition, see Lemma 83 (7), (8).
The following result is extremely simple but at the same time extremely
useful.
Lemma 7. Let f : X →Y be a partial map in an eﬀectus. Then:
1
f = 0 ⇐⇒f = 0
and
1
f = 1 ⇐⇒f is total.
Proof The implication (⇐) on the left is trivial, and for the implication (⇐)
on the right, let f be total, say f = κ1
g for g : X →Y . Then:
1
f = [κ1
!, κ2] κ1
g = κ1
! g = κ1
! = 1.
The two implications (⇒) follow from the following two diagrams.
X
f
!
!
$
#
X
f
!
!
$
#
1
κ2

❴✤
1
κ2

Y
κ1

!
/
❴✤
1
κ1

Y + 1
!+id / 1 + 1
Y + 1
!+id / 1 + 1
17

Both rectangles are pullbacks, as instances of the diagram on the right in (9)
— once for the second coprojection κ2.
□
3.1
Examples of eﬀectuses
Below we describe the running examples of eﬀectuses that will be used through-
out this text. We will not go into all details and proofs for these examples, but
just sketch the essentials.
Example 8. The category Sets of sets and functions has coproducts via disjoint
union: X +Y = {⟨x, 1⟩| x ∈X}∪{⟨y, 2⟩| y ∈Y }. The numbers 1 and 2 in this
set are used as distinct labels, to make sure that we have a disjoint union. The
coprojections κ1 : X →X + Y and κ2 : Y →X + Y are given by κ1x = ⟨x, 1⟩
and κ2y = ⟨x, 2⟩. For functions f : X →Z and g : Y →Z there is a cotuple
map [f, g]: X + Y →Z given by [f, g](κ1x) = f(x) and [f, g](κ2y) = g(y).
The emtpy set is the initial object 0 ∈Sets, precisely because for any set
X, there is precisely one function 0 →X, namely the empty function. Any
singleton set is ﬁnal in Sets. We typically write 1 = {∗} for (a choice of) the
ﬁnal object.
Predicates on a set X are ‘characteristic’ functions X →1 + 1 = 2 ∼= {0, 1},
which correspond to subsets of X. There is thus an isomorphism Pred(X) ∼=
P(X), where P(X) is the powerset. In particular, the set Pred(1) of scalars is
the two-element set of Booleans P(1) ∼= 2. A state is a function 1 →X, and
thus corresponds to an element of the set X.
Kleisli maps f : X →Y + 1 of the lift monad correspond to partial functions
from X to Y , written according to our convention as maps f : X →Y . We say
that f is undeﬁned at x ∈X if f(x) = ∗∈1 — or more formally, if f(x) = κ2∗.
It is easy to see that Kleisli composition corresponds to the usual composition
of partial functions.
Later, in Section 13, we shall see that the category Sets is an instance of an
extensive category, and that such extensive categories are instances of eﬀectuses,
that can be characterised in a certain way. In fact, every topos is an extensive
category, and thereby an eﬀectus.
Example 9. In order to capture (discrete) probabilistic models we use two mon-
ads on Sets, namely the distribution monad D and the subdistribution monad
D≤1.
For an arbitrary set X we write D(X) for the set of formal convex combina-
tions of elements in X. There are two equivalent ways of describing such convex
combinations.
• We can use expressions r1|x1 ⟩+ · · · + rn|xn ⟩where xi ∈X and ri ∈[0, 1]
satisfy P
i ri = 1.
The ‘ket’ notation |x⟩is syntactic sugar, used to
distinguish an element x ∈X from its occurrence in such sums.
The
expression P
i ri|xi ⟩= r1|x1 ⟩+ · · · + rn|xn ⟩∈D(X) may be understood
as: the probability of element xi is ri.
• We also use functions ω: X →[0, 1] with ﬁnite support supp(ω) = {x ∈
X | ω(x) ̸= 0}, and with property P
x ω(x) = 1. We can write this ω
as formal convex sum P
x ω(x)|x⟩. Conversely, each formal convex sum
P
i ri|xi ⟩yields a function X →[0, 1] with xi 7→ri, and x 7→0 for all
other x ∈X.
18

We shall freely switch between these two ways of describing formal convex com-
binations. Sometimes we use the phrase ‘discrete probability distribution’ for
such a combination.
The subdistribution monad D≤1 has ‘subconvex’ combinations P
i ri|xi ⟩∈
D≤1(X), where ri ∈[0, 1] satisfy P
i ri ≤1.
We write Kℓ(D) for the Kleisli category of the monad D. Objects of this
category are sets, and morphisms X →Y are functions X →D(Y ). If X, Y
are ﬁnite sets, such maps X →D(Y ) are precisely the stochastic matrices.
Such functions can be understood as Markov chains, describing probabilistic
computations. For functions f : X →D(Y ) and g : Y →D(Z) we deﬁne g
f : X →D(Z) essentially via matrix multiplication:
(g
f)(x) =
X
z
  P
y g(y)(z) · f(x)(y)
z

.
Notice that we have mixed the above two descriptions: we have used the ket-
notation for the distribution (g f)(x) ∈D(Z), but we have used the distributions
f(x) ∈D(Y ) and g(y) ∈D(Z) as functions with ﬁnite support, namely as
functions f(x): Y →[0, 1] and g(y): Z →[0, 1]. This allows us to multiply (and
add) the probabilities g(y)(z) ∈[0, 1] and f(x)(y) ∈[0, 1]. It can be checked
that the above deﬁnition yields a distribution again, and that the operation
is
associative.
We also need an identity map X →X in Kℓ(D). It is the function X →
D(X) that sends x ∈X to the ‘Dirac’ distribution 1|x⟩∈D(X). As function
X →[0, 1] this Dirac distribution sends x to 1, and any other element x′ ̸= x to
0. In this way Kℓ(D) becomes a category. The empty set 0 is initial in Kℓ(D),
and the singleton set 1 is ﬁnal, because D(1) ∼= 1.
The Kleisli category Kℓ(D) inherits ﬁnite coproducts from the underlying
category Sets. On objects it is the disjoint union X + Y , with coprojection
X →D(X + Y ) given by x 7→1|κix⟩. The cotuple is as in Sets. We leave it to
the reader to check that the requirements of an eﬀectus hold in Kℓ(D). Later,
in Example 33, we shall see that this example eﬀectus Kℓ(D) is an instance of
a more general construction.
Predicates on a set X are functions X →D(1 + 1) = D(2) ∼= [0, 1]. Hence
predicates in this eﬀectus are fuzzy: Pred(X) ∼= [0, 1]X. The scalars are the
probabilities from [0, 1]. A state 1 →X corresponds to a distribution ω ∈D(X).
Interestingly, the category Par(Kℓ(D)) of partial maps in the Kleisli category
of the distribution monad D is the Kleisli category Kℓ(D≤1) of the subdistri-
bution monad. The reason is that subdistribution in D≤1(Y ) can be identiﬁed
with a a distribution in D(Y + 1). Indeed, given a subdistribution P
i ri|yi ⟩,
we take r = 1 −(P
i ri) and get a proper distribution P
i ri|yi ⟩+ r| ∗⟩, where
1 = {∗}. Thus we often identify a partial map X →Y in Kℓ(D) with a function
X →D≤1(Y ).
We have used the distribution monad D on Sets, for discrete probability.
For continuous probability one can use the Giry monad G on the category of
measurable spaces, see [Jac15a, Jac13] for details. The Kleisli category Kℓ(G)
of this monad G is also an eﬀectus.
The next example of an eﬀectus involves order unit groups. It does not cap-
ture a form of computation, like Sets or Kℓ(D). Still this example is interesting
because it shares some basic structure with the quantum model given by von
19

Neumann algebras — see the subsequent Example 11 — but it is mathemati-
cally much more elementary. Hence we use it as an intermediate stepping stone
towards von Neumann algebras.
Example 10. We write Ab for the category of Abelian groups, with group
homomorphisms between them. An Abelian group G is called ordered if there
is a partial order ≤on G that satisﬁes: x ≤x′ implies x + y ≤x′ + y, for all
x, x′, y ∈G. One can then prove, for instance x ≤x′ iﬀ0 ≤x′ −x iﬀx + y = x′
for some y ≥0.
A homomorphism f : G →H of ordered Abelian groups is a group homomor-
phism that is monotone: x ≤x′ ⇒f(x) ≤f(x′). Such a group homomorphism
is monotone iﬀit is positive. The latter means: x ≥0 ⇒f(x) ≥0. We write
OAb for the category of ordered Abelian groups with monotone/positive group
homomorphisms between them. There is an obvious functor OAb →Ab which
forgets the order.
An ordered Abelian group G is called an order unit group if there is a positive
unit 1 ∈G such that for each x ∈G there is an n ∈N with −n · 1 ≤x ≤
n · 1. A homomorphism f : G →H of order unit groups is a positive group
homomorphisms which is ‘unital’, that is, it preserves the unit: f(1) = 1. We
often write ‘PU’ for positive unital. We obtain another category OUG of order
unit groups and PU group homomorphisms between them. We have a functor
OUG →OAb that forgets the unit.
It is easy to see that order unit groups are closed under ﬁnite products:
the cartesian product, commonly written as direct sum G1 ⊕G2, is again an
ordered Abelian group, with componentwise operations and order, and with the
pair (1, 1) as unit. The trivial singleton group {0} with 1 = 0 is ﬁnal in the
category OUG. The group of integers Z is initial in OUG, since for each order
unit group G there is precisely one map f : Z →G, namely f(k) = k · 1.
We now claim that the opposite OUGop of the category of order unit groups
is an eﬀectus. The direct sums (⊕, {0}) form coproducts in OUGop, and the
integers Z form the ﬁnal object. The eﬀectus requirements in Deﬁnition 2 can
be veriﬁed by hand, but they also follow from a general construction in Exam-
ple 34. This category is in opposite form since it incorporates Heisenberg’s view
where computations are predicate transformers, acting in opposite direction,
transforming ‘postcondition’ predicates on the codomain of the computation to
‘precondition’ predicates on the domain.
We elaborate on predicates and on partial maps since they can be described
in alternative ways that also apply in other settings.
1. A predicate on an order unit group G is formally a map p: G →1 + 1
in the eﬀectus OUGop. In the category OUG this amounts to a map
p: Z ⊕Z →G. We claim that such predicates correspond to eﬀects, that
is, to elements in the unit interval [0, 1]G = {x ∈G | 0 ≤x ≤1}. Indeed,
the element p(1, 0) is positive, and below the unit since p(1, 0) + p(0, 1) =
p(1, 1) = 1, where p(0, 1) is positive too. In the other direction, an eﬀect
e ∈[0, 1]G gives rise to a map pe : Z ⊕Z →G by pe(k, m) = k · e + m · e⊥,
where e⊥= 1 −e.
2. A partial map f : G →H in OUGop is a map f : G →H + 1, which
corresponds to a positive unital group homomorphism f : H ⊕Z →G. We
next claim that these homomorphisms f correspond to subunital positive
20

group homomorphisms g : H →G, where subunital means that g(1) ≤1.
This correspondence works as follows: given f, take f(y) = f(y, 0); and
given g, take g(y, k) = g(y) + k · g(1)⊥, where g(1)⊥= 1 −g(1). We use
the abbreviation ‘PsU’ for ‘positive subunital’.
Summarising, there are bijective correspondences for predicates and partial
maps:
G
/ 1 + 1
in OUGop
============
Z ⊕Z
/ G
in OUG
============
e ∈[0, 1]G
G
/ H
in Par(OUGop)
=============
G
/ H + 1
in OUGop
===============
H ⊕Z
/ G
in OUG
=============
H
PsU / G
(13)
A state of an order unit group G is a homomorphism G →Z.
Order unit groups provide a simple example of an eﬀectus, in which part
of the structure of more complex models — like von Neumann algebras, see
below — already exists.
Similar structures are order unit spaces.
They are
ordered vector spaces over the reals, which are at the same time an order unit
group. The category OUS of order unit spaces has positive unital linear maps
as homormorphisms.
It plays a promiment role in generalised probabilistic
theories, see e.g. [Wil12]. One can prove that the category OUSop is an eﬀectus
too. The states of an order unit space V are the homomorphisms V →R. They
carry much more interesting structure than the states of an order unit group.
For instance, this set of states Stat(V ) forms a convex compact Hausdorﬀspace.
More information about order unit groups can be found in [Goo86], and about
order unit spaces in [Nag74, JM12b].
Example 11. The mathematically most sophisticated example of an eﬀectus is
the opposite vNAop of the category vNA of von Neumann algebra, which pro-
vides a model for quantum computation. For example, the qubit is represented
by the von Neumann algebra of 2 × 2 complex matrices (see point 9 below).
For completeness, we give the deﬁnition of von Neumann algebra (in point 3),
and the morphisms of vNA (in point 7), but we refer the reader to [KR97,
Pau02, Sak71] for the intricate details.
1. The structure that invoked the study of von Neumann algebra is the set
B(H ) of bounded operators T : H →H on a Hilbert space H . Recall
that an operator T on H is bounded provided that:
∥T ∥= inf{b ∈[0, ∞) | ∀x ∈H . ∥T (x)∥≤b · ∥x∥} < ∞.
Not only is B(H ) a complex vector space (with coordinatewise opera-
tions), but it also carries a multiplication (namely composition of oper-
ators), an involution (viz. taking adjoint), and a unit (viz. the identity
operator), which interact appropriately, and B(H ) is therefor a unital
∗-algebra. The adjoint of an operator S ∈B(H ) is the the unique opera-
tor S∗∈B(H ) with ⟨S(x) | y⟩= ⟨x | S∗(y)⟩for all x, y ∈H .
We assume that every ∗-algebra has a unit (‘is unital’). A ∗-subalgebra
of a ∗-algebra A is a complex linear subspace S of A which is closed
21

under multiplication and involution, (−)∗, and contains the unit 1 of A .
An isomorphism between ∗-algebras is a linear bijection which preserves
multiplication, involution and unit.
2. Let H be a Hilbert space. A unital C∗-algebra of operators A on H is a
∗-subalgebra of B(H ) which is norm closed, that is, if (Tα)α is a net in A
and S ∈A such that ∥Tα−S∥→0, then S ∈A . A von Neumann algebra
of operators A on H is a ∗-subalgebra B(H ), which is weakly closed, that
is, if (Tα)α is a net in A and S ∈A such that ⟨x | (S −Tα)(x)⟩→0 for
all x ∈H , then S ∈A .
3. A unital C∗-algebra A is a ∗-algebra which is isomorphic to a unital
C∗-algebra of operators on some Hilbert space. (This is not the usual
deﬁnition, but it is equivalent, see [KR97, Thm. 4.5.6]). A von Neumann
algebra (also W ∗-algebra) A is a ∗-algebra which is isomorphic to a von
Neumann algebra of operators on some Hilbert space (cf. text above Exam-
ple 5.1.6 of [KR97]). Every von Neumann algebra is also a C∗-algebra, but
the converse is false. In this text we will deal mainly with von Neumann
algebras; we added the deﬁnition of C∗-algebra here only for comparison.
4. For every Hilbert space H , the ∗-algebra of operators B(H ) is a von
Neumann algebra. In particular, {0}, C, M2, M3, . . . are all von Neu-
mann algebras, where Mn is the ∗-algebra of n × n complex matrices.
The cartesian product, A ⊕B, of two von Neumann algebras is again
a von Neumann algebra with coordinatewise operations. In particular,
the complex plane C2 = C ⊕C is a von Neumann algebra. Given a von
Neumann algebra A the ∗-algebra Mn(A ) of n × n-matrices with entries
drawn from A is a von Neumann algebra.
5. An element a of a von Neumann algebra A is called positive if a = b∗· b
for some b ∈A , and self-adjoint if a∗= a. The set of positive elements
of A is denoted by A+ and the set of self-adjoint elements of A is denoted
by Asa. All positive elements of A are self-adjoint.
A von Neumann algebra A is partially ordered by: a ≤b iﬀb −a is
positive. The self-adjoint elements of a von Neumann algebra A form an
order unit space, Asa. For every positive element a ∈A of a von Neumann
algebra there is a unique positive element b ∈A with b2 = a, which is
denoted by √a.
In a von Neumann algebra every bounded directed net of self-adjoint ele-
ments D has a supremum W D in Asa. Both ‘bounded’ and ‘directed’ are
necessary, and the statement is false for C∗-algebras.
6. A linear map f : A →B between von Neumann algebras is called
(a) unital if f(1) = 1;
(b) subunital if f(1) ≤1;
(c) positive if f(a) ∈B+ for all a ∈A+;
(d) involutive if f(a∗) = f(a)∗for all a ∈A ;
(e) multiplicative if f(a · b) = f(a) · f(b) for all a, b ∈A ;
22

(f) completely positive (see [Pau02]) if for every n ∈N the map
Mn(A )
Mn(f) / Mn(B)
given by (Mn(f)(A))ij = f(Aij) for all A ∈Mn(A ) is positive;
(g) normal if f(W D) = W f(D) for every bounded directed set D ⊆Asa
(cf. [Sak71]).
7. We denote the category of von Neumann algebras and completely positive
normal unital maps by vNA. It has an initial object C, ﬁnal object {0},
and products given by ⊕(see point 4). The opposite category vNAop then
has ﬁnite coproducts and a ﬁnal object. In fact, vNAop is an eﬀectus for
almost the same reasons as OUSop and OUGop are an eﬀectuses (see
Example 10).
As is the case for OUSop, the predicates on a von Neumann algebra A
correspond to elements a ∈A with 0 ≤a ≤1, which are called eﬀects. In
fact, the map Pred(A ) →[0, 1]A given by p 7→p(1, 0) is an isomorphism
of eﬀect algebras, see the correspondences (13). Also, the partial maps
in Par(vNAop) correspond to the completely positive normal subunital
maps between von Neumann algebras.
8. A von Neumann algebra A is commutative if a · b = b · a for all a, b ∈A .
We write CvNA ֒→vNA for the full subcategory of commutative von
Neumann algebras.
We recall that a positive unital map A →B is
automatically completely positive when either A or B is commutative.
These commutative von Neumann algebras capture probabilistic models,
as special case of the general quantum models in vNA. Also the category
CvNAop is an eﬀectus.
9. For quantum computation the most important von Neumann algebra is
perhaps the ∗-algebra M2 of 2 × 2 matrices, because it models a qubit; it
is closely related to the Hilbert space C2, since M2 = B(C2).
A pure state of a qubit is a vector in C2 of length 1, and can thus be written
as α |0⟩+ β |1⟩, where |0⟩= (1, 0) and |1⟩= (0, 1) are base vectors in C2,
and α, β ∈C are scalars with |α|2 + |β|2 = 1. One says that any pure
state of a qubit is in a superposition of |0⟩and |1⟩. Two pure states
(α1, β1) and (α2, β2) of a qubit are equivalent if (z · α1, z · β1) = (α2, β2)
for some z ∈C (with |z| = 1).
A sharp predicate on a qubit is a linear subspace C of C2 which in turn
corresponds to a projection P ∈M2 (namely the orthogonal projection
onto C). For instance, the predicate “the qubit is in state |0⟩” is rep-
resented by the linear subspace {(α, 0): α ∈C} (the x-axis), and by the
projection ( 1 0
0 0 ).
10. Let C be a linear subspace of C2 (i.e. a sharp predicate of a qubit) with
orthogonal projection P ∈M2. Then P ⊥= I −P is again a projection,
onto the orthocomplement C⊥= {y ∈C2 | ∀x ∈C. ⟨x | y⟩= 0} of C.
Let x ∈C2 be a pure state of a qubit (so ∥x∥= 1). Then:
x ∈C ⇐⇒predicate C certainly holds in state x
x ∈C⊥⇐⇒predicate C certainly does not hold in state x.
23

However, if x /∈C∪C⊥, then the matter whether C holds in x is undecided.
The matter can, however, be pressed using measurement; it forces the
qubit to the state P(x) · ∥P(x)∥−1 with probability ∥P(x)∥2, and to the
state P ⊥(x) · ∥P ⊥(x)∥−1 with probability ∥P ⊥(x)∥2.
C
C⊥
x
P(x)
P ⊥(x)
Thus, using measurement one ﬁnds that the predicate C holds in state x
with probability ∥P(x)∥2. After measurement, the state of the qubit has
become a (probabilistic) mixture of P(x) · ∥P(x)∥−1 ∈C and P ⊥(x) ·
∥P ⊥(x)∥−1 ∈C⊥.
11. Any pure state x of a qubit gives rise to a state ωx : M2 →C of vNAop
given by ωx(A) = ⟨Ax | x⟩for all A ∈M2. The states of the form ωx
are precisely the extreme points of the convex set Stat(M2) of all states
on M2.
The states which are not extreme correspond to probabilistic
mixtures of pure states. For example, if one measures whether the pure
state |+⟩=
1
√
2(|0⟩+ |1⟩) is in the state |0⟩, then the resulting state is
1
2(ω|0⟩+ ω|1⟩), which not extreme, and corresponds to a qubit which is
either in state |0⟩or |1⟩with equal probability.
Any state of M2 can be written as a convex combination of extreme states.
But this is not true in general: a von Neumann algebra might have no
extreme states at all.
12. Any sharp predicate C of the qubit gives rise to a predicate on M2
in vNAop. To see this recall that the predicates on M2 in vNAop cor-
respond to the elements P ∈M2 with 0 ≤P ≤1.
Now, the sharp
predicate C corresponds to the orthogonal projection PC onto C.
The predicates on M2 of the form PC are precisely those predicates P with:
for every Q ∈M2 with 0 ≤Q ≤1, if Q ≤P and Q ≤P ⊥, then Q = 0.
13. Let us think about the conjunction of two sharp predicates C and D on
the qubit. Surely, it should be C ∩D. Is measuring whether C ∩D holds
simply a matter of ﬁrst measuring C and then measuring D?
Let P be the orthogonal projection on C, and let Q be the orthogonal
projection onto D. First note that if x ∈C2 is a state of the qubit, then
the probability to ﬁnd that C holds upon measurent, and then that D
holds up measurement is ∥Q(P(x))∥2, and the resulting state is Q(P(x)) ·
∥Q(P(x))∥−1. By the way, ∥Q(P(x))∥2 = ⟨P(Q(P(x))) | x⟩= ϕx(PQP),
so ﬁrst measuring C and then D corresponds in this formalism to the
operator PQP ∈M2 (and not to QP as one might have guessed).
24

C
D
x
Q(P(x))
P(Q(x))
Now, (by choosing C := {(α, 0): α ∈C} and D := {(α, α): α ∈C}) one
easily sees the following peculiar behaviour typical for quantum systems:
(a) Measurement disturbes the system: while P(x) · ∥P(x)∥−1 is in C,
the state Q(P(x)) · ∥Q(P(x))∥−1 need not be in C;
(b) The order of measurement matters for the probability of the outcome:
we might have ∥Q(P(x))∥2 ̸= ∥P(Q(x))∥2;
(c) The composition of two sharp measurements need not be sharp: PQP
need not be a projection.
Thus, measuring whether C ∩D holds is not always simply a matter of
measuring C and then measuring D.
The operator PQP is called the sequential product of P and Q and is
denoted by P & Q. More generally, if A is a von Neumann algebra, and
p, q ∈[0, 1]A , then the sequential product is given by p & q = √pq√p,
and it represents ﬁrst measuring p and then measuring q.
We will see in Theorem 110 that p & q can be deﬁned in vNAop using
only the language of category theory.
14. We have the following situation for a qubit:
{pure states} ⊆C2
{sharp predicates} ⊆M2.
This situation is typical: any Hilbert space H , representing a purely quan-
tum system, gives rise to the von Neumann algebra B(H ) of bounded
operators on H ; the elements of norm 1 in H are the pure states of
this quantum system, while the projections in B(H ) are the sharp pred-
icates, corresponding to closed linear subspaces of H . For instance, M3
represents a qutrit, and B(ℓ2) represents a quantum integer.
15. Let A be a von Neumann algebra. An important technical fact is that
the states on A in vNAop (usually called normal states in the literature)
are separating, that is, for all a, b ∈A we have a ≤b if and only if for
every ω: A →C in vNA we have ω(a) ≤ω(b).
This entails that the ultraweak topology—the least topology on A such
that all states on A in vNAop are continuous—is Hausdorﬀ. A net (ai)i∈D
of elements of A converges ultraweakly (i.e. with respect to the ultraweak
topology) to an element a ∈A iﬀ(ω(ai))i∈D converges to ω(a) for every
state ω on A in vNAop.
It is not hard to see that a positive linear map f : A →B between von
Neumann algebras is ultraweakly continuous if and only if f is normal. In
25

this sense the ultraweak topology plays the same role in the theory of von
Neumann algebras as the Scott topology plays in domain theory.
There is much more to be said about the ultraweak topology in particular,
and von Neumann algebras in general, but since we draw most (new)
results about von Neumann algebras from more specialized publications,
[WW15, Ren14, Cho14], we refrain from diverging any farther into the
theory of operator algebras.
4
The structure of partial maps and predicates
This section concentrates on the structure that exists on partial maps X →Y
in an eﬀectus. It turns out that they come equipped with a partial binary sum
operation, written as >, which has the zero map as unit and is commutative
and associative (in an appropriately partial sense).
Abstractly, the relevant
observation is that the category Par(B) of partial maps of an eﬀectus B is
enriched over the category PCM of partial commutative monoids.
We ﬁrst
describe what such PCMs are.
The section continues with predicates, as special case. The main result of
this section states that these predicates in an eﬀectus form an eﬀect module, in
a functorial way.
Deﬁnition 12. A partial commutative monoid,abbreviated as PCM, is given
by a set M with a zero element 0 ∈M and a partial binary operation > on M,
satisfying the following requirements — where we call x, y and orthogonal and
write x ⊥y when x > y is deﬁned.
1. x ⊥0 and x > 0 = x, for each x ∈M;
2. if x ⊥y then y ⊥x and x > y = y > x, for all x, y ∈M;
3. if x ⊥y and (x > y) ⊥z, then y ⊥z and x ⊥(x > z), and moreover
(x > y) > z = x > (y > z), for all x, y, z ∈M.
A homomorphism f : M →N between two PCMs is a function that preserves 0
and >, in the sense that:
1. f(0) = 0;
2. if x ⊥y in M, then f(x) ⊥f(y) in N and f(x > y) = f(x) > f(y).
We write PCM for the resulting category.
This notion of PCM shows up in the following way. Sums > are deﬁned
for parallel partial maps, via bounds. These deﬁnitions work well and satisfy
appropriate properties via the categorical structure in eﬀectuses, as identiﬁed
in the previous section.
Proposition 13 (From [Cho15]). Let B be an eﬀectus.
1. Each homset Par(B)
 X, Y

of partial maps X →Y is a PCM in the
following way.
26

• f ⊥g iﬀthere is a ‘bound’ b: X →Y + Y with ✄1
b = f and
✄2
b = g. By Lemma 5 such a bound b, if it exists, is necessarily
unique.
• if f ⊥g via bound b, then we deﬁne f >g = ∇b = (∇+id) b: X →
Y .
2. This PCM-structure is preserved both by pre- and by post-composition in
Par(B).
The latter statement can be stated more abstractly as: Par(B) is enriched
over PCM.
This works since the category PCM is symmetric monoidal,
see [JM12a, Thm. 8]. Another way is to say that Par(B) is a ﬁnitely partially
additive category (abbreviated as ‘FinPAC’), using the terminology of [AM80]
(and [Cho15]). The original deﬁnition involves countable sums, whereas we only
use ﬁnite sums, see Subsection 8.1.
More results about these partial homsets follow, in Proposition 41.
Proof For an arbitrary map f : X →Y we can take b = κ1
f : X →Y + Y as
bound for f ⊥0, showing f >0 = f. If f ⊥g via b: X →Y +Y , then swapping
the outcomes of b yields a bound for g ⊥f, proving f > g = g > f. The more
diﬃcult case is associativity.
So assume f ⊥g via bound a, and (f > g) ⊥h via bound b. We then have:







✄1
a = f
✄2
a = g
∇
a = f > g
and







✄1
b = f > g
✄2
b = h
∇
b = (f > g) > h.
Consider the diagram below, where the rectangle is a pullback in Par(B), as
instance of the diagram on the right in (10). Here we use that the codiagonal
∇= [‹id›, ‹id›] = ‹[id, id]› is total in Par(B).
X
b
'
a
#
c
%
(Y + Y ) + Y
∇+id /
✄1

❴✤
Y + Y
✄1

Y + Y
∇
/ Y
We now take c′ = (✄2 + id)
c: X →Y + Y . This c′ is a bound for g and h,
giving g ⊥h since:
✄1
c′ = ✄1
(✄2 + id)
c
✄2
c′ = ✄2
c
= ✄2
✄1
c
= ✄2
(∇+ id)
c
= ✄2
a
= ✄2
b
= g
= h.
27

Next, the map c′′ = [id, κ2]
c: X →Y + Y is a bound for f and g > h since:
✄1
c′′ = [✄1
id, ✄1
κ2]
c
✄2
c′′ = [✄2
id, ✄2
κ2]
c
= [✄1, 0]
c
= [✄2, id]
c
= ✄1
[id, 0]
c
= ∇
(✄2 + id)
c
= ✄1
✄1
c
= ∇
c′
= f
= g > h.
We now obtain the associativity of >:
f > (g > h) = ∇
c′′ = ∇
[id, κ2]
c = [∇, id]
c
= ∇
(∇+ id)
c
= ∇
b
= f > (g > h).
Finally we check that > is preserved by pre- and post-composition.
Let
f ⊥g via bound b: X →Y + Y .
• For h: Z →X it is easy to see that b
h is a bound for f
h and g
h,
giving (f
h) > (g
h) = (f > g)
h.
• For k: Y →Z we claim that (k + k) b is a bound for k f and k g. This
follows from naturality (3) of the partial projections ✄i. In this way we
get (k
f) > (k
g) = k
(f > g).
□
Here is a concrete illustration: the two partial projections ✄1, ✄2 : X +X →
X in an eﬀectus are orthogonal, via the identity map X + X →X + X. This is
obvious. Hence we have as sum ✄1 > ✄2 = ∇.
We brieﬂy show what this PCM-structure is in our leading examples.
Example 14. In the category Par(Sets) of partial maps of the eﬀectus Sets
two partial maps f, g : X →Y + 1 are orthogonal if they have disjoint domains
of deﬁnition. That is:
f ⊥g ⇐⇒∀x ∈X. f(x) = ∗∨g(x) = ∗.
In that case we have:
(f > g)(x) =
(
f(x)
if g(x) = ∗
g(x)
if f(x) = ∗
In the eﬀectus Kℓ(D) for discrete probability, orthogonality of two partial
maps f, g : X →D≤1(Y ) is given by:
f ⊥g ⇐⇒∀x ∈X. P
y∈Y f(x)(y) + g(x)(y) ≤1.
In that case we have (f > g)(x)(y) = f(x)(y) + g(x)(y).
In the eﬀectus OUGop of order unit groups two subunital positive maps
f, g : G →H are orthogonal if f(1) + g(1) ≤1. In that case we simply have
(f > g)(x) = f(x) + g(x). The same description applies in the eﬀectus vNAop
of von Neumann algebras.
28

The PCM-structure on partial maps X →Y from Proposition 13 exists in
particular for predicates — which are maps of the form X →1. In the language
of total maps, a bound for p, q: X →1 + 1 is a map b: X →(1 + 1) + 1 with
···
··✎✎
b = p and ···
··✴✴✎✎✎✎
b = q, where ···
··✎✎, ···
··✴✴✎✎✎✎: (1 + 1) + 1 →1 + 1 are the jointly
monic maps (8) in the deﬁnition of an eﬀectus. The actual sum is then given
by p > q = (∇+ id) b: X →1 + 1.
In this special case of predicates there is more than PCM-structure: predi-
cates on X form an eﬀect algebra and also an eﬀect module. This will be shown
next. We begin with the deﬁnition.
Deﬁnition 15. An eﬀect algebra is a partial commutative monoid (M, >, 0)
with an orthosupplement operation (−)⊥: M →M such that for each x ∈M:
1. x⊥is the unique element with x > x⊥= 1, where 1 = 0⊥;
2. x ⊥1 implies x = 0.
A homomorphism of eﬀect algebras f : M →N is a homomorphism of PCMs
satisfying f(1) = 1. We write EA for the resulting category.
The unit interval [0, 1] is an example of an eﬀect algebra, with r ⊥s iﬀ
r + s ≤1, and in that case r > s = r + s. The orthosupplement is given by
r⊥= 1 −r. Every Boolean algebra is also an eﬀect algebra with x ⊥y iﬀ
x ∧y = 0, and in that case x > y = x ∨y. The orthosupplement is negation
x⊥= ¬x. In particular, the set 2 = {0, 1} is an eﬀect algebra. It is initial in
the category EA of eﬀect algebras.
In [JM12a] it is shown that the category EA of eﬀect algebras is symmetric
monoidal, where the unit for the tensor ⊗is the initial eﬀect algebra 2 = {0, 1}.
Each eﬀect algebra carries an order, deﬁned by x ≤y iﬀx > z = y for some
z. We collect some basic results. Proofs can be found in the literature on eﬀect
algebras, see e.g. [DP00].
Exercise 16. In an eﬀect algebra one has:
1. orthosupplement is an involution: x⊥⊥= x;
2. cancellation: x > y = x > y′ implies y = y′;
3. positivity: x > y = 0 implies x = y = 0;
4. ≤is a partial order with 1 as top and 0 as bottom element;
5. x ≤y implies y⊥≤x⊥;
6. x > y is deﬁned iﬀx ⊥y iﬀx ≤y⊥iﬀy ≤x⊥;
7. x ≤y and y ⊥z implies x ⊥z and x > z ≤y > z;
8. the downset ↓y = {x | x ≤y} is again an eﬀect algebra, with y as top,
orthosupplement x⊥y = (y⊥> x)⊥, and sum x >y x′ which is deﬁned iﬀ
x ⊥x′ and x > x′ ≤y, and in that case x >y x′ = x > x′.
□
29

The uniqueness of the orthosupplement x⊥is an important property in the
proof of this exericse. For instance it gives us f(x⊥) = f(x)⊥for a map of eﬀect
algebras, since:
f(x⊥) > f(x) = f(x⊥> x) = f(1) = 1 = f(x)⊥> f(x).
A test in an eﬀect algebra is a ﬁnite set of elements x1, . . . , xn which are
pairwise orthogonal and satisfy x1 >. . .>xn = 1. Each eﬀect algebra thus gives
rise to a functor (presheaf) N →Sets, sending a number n to the collection of
n-element tests. This structure is investigated in [SU15].
Recall that we write Pred(X) for the collection of predicates X →1 + 1 and
f ∗= (−) f for the substitution map Pred(X) →Pred(Y ), where f : Y →X.
Proposition 17. Let B be an eﬀectus. Then:
1. Pred(X) is an eﬀect algebra, for each object X ∈B;
2. sending X 7→Pred(X) and f 7→f ∗gives a functor Pred: B →EAop.
Proof From Proposition 13 (1) we know that Pred(X) is a PCM. We show that
it is an eﬀect algebra with the orthosupplement p⊥= [κ2, κ1] p from (5).
The three equations below show that b = κ1 p: X →(1 + 1) + 1 is a bound
for p and p⊥, yielding p > p⊥= 1.
···
··✎✎
b = [id, κ2] κ1
p = p
···
··✴✴✎✎✎✎
b = [[κ2, κ1], κ2] κ1
p = [κ2, κ1] p = p⊥
(∇+ id) b = (∇+ id) κ1
p = κ1
∇p = κ1 = 1.
Next we show that p⊥is the only predicate with p > p⊥= 1. So assume also
for q: X →1 + 1 we have p > q = 1, say via bound b. Then ···
··✎✎
b = p, ···
··✴✴✎✎✎✎
b = q
and (∇+ id) b = 1 = κ1
!. We use the pullback on the right in (9):
X
b
#
!
&
c
%
1 + 1
κ1

∇
/
❴✤
1
κ1

(1 + 1) + 1 ∇+id / 1 + 1
The fact that the bound b is of the form κ1
c is enough to obtain q = p⊥in:
p⊥= [κ2, κ1] ···
··✎✎
b = [κ2, κ1] [id, κ2] κ1
c
= [[κ2, κ1], κ2] κ1
c = ···
··✴✴✎✎✎✎
b = q.
Next, suppose 1 ⊥p; we must prove p = 0: X →1 + 1. We may assume a
bound b: X →(1 + 1) + 1 with ✄1
b = 1 = κ1
! and ✄2
b = p. We use the
pullback in B on the right in (9) to obtain the unique map X →1 as mediating
30

map in:
X
b

!
'
!
' 1
κ1

❴✤
1
κ1

(1 + 1) + 1
α−1
∼
=
/
···
··✎✎=[✄1,κ2]
5
1 + (1 + 1)
id+∇/ 1 + 1
As before, α is the associativity isomorphism. Hence b = α κ1 ! = κ1 κ1 ! = ‹1›.
Then, as required:
p = ✄2
b = [0, id]
‹1› = [κ2, id] κ1
! = κ2
! = 0.
For the second point of the proposition we only have to prove that substitu-
tion f ∗preserves > and 1. Preservation of > follows from Proposition 13 (2),
and preservation of 1 holds by Exercise 1 (5).
□
In Example 22 below we shall describe this eﬀect algebra structure con-
cretely for our running examples. But we ﬁrst we show that the result can be
strengthened further: predicates in an eﬀectus are not only eﬀect algebras, but
also eﬀect modules. The latter are eﬀect algebras with a scalar multiplication,
a bit like in vector spaces. In examples the scalars are often probabilities from
[0, 1] or Booleans from {0, 1}. But more abstractly they are characterised as
eﬀect monoids.
Deﬁnition 18. An eﬀect monoid is an eﬀect algebra which is at the same time
a monoid, in a coherent way: it is given by an eﬀect algebra M with (total)
associative multiplication operation ·: M × M →M which preserves 0, > in
each coordinate separately, like in the second part of Deﬁnition 12, and satisﬁes
1 · x = x = x · 1.
An eﬀect monoid is commutative if its multiplication is commutative.
More abstractly, using that the category EA of eﬀect algebras is symmet-
ric monoidal [JM12a], an eﬀect monoid (M, ·, 1) is a monoid in the monoidal
category EA of eﬀect algebras of the form:
2
/ M
M ⊗M
o
satisfying the monoid requirements.
Since the tensor unit 2 = {0, 1} is ini-
tial in the category EA, the map on the left is uniquely determined, and the
multiplication map on the right is the only structure.
The unit interval [0, 1] is the prime example of an eﬀect monoid, via its stan-
dard multiplication. It is clearly commutative. This structure can be extended
pointwise to fuzzy predicates [0, 1]X, for a set X, and to continuous predicates
C(Y, [0, 1]) for a topological space Y .
The Booleans {0, 1} also form an eﬀect monoid, via conjunction (multiplica-
tion). More generally, each Boolean algebra is an eﬀect monoid, with conjunc-
tion as multiplication.
31

Recall that any order unit group gives rise to an eﬀect algebra by considering
its unit interval. If the order unit group carries an associative bilinear positive
multiplication for which the order unit is neutral, then its unit interval is an
eﬀect monoid. We should warn that this does not apply to C∗-algebras: their
self-adjoint elements form an order unit group, but their multiplication is not
positive and does not restrict to self-adjoint elements — except when the C∗-
algebra is commutative. Indeed, we shall see in Section 9 that predicates in a
‘commutative’ eﬀectus form commutative eﬀect monoids, see esp. Lemma 57 (2).
Most obvious examples of an eﬀect monoid are commutative.
But here
is an example of a non-commutative eﬀect monoid.
Consider R5 with stan-
dard basis e1, . . . , e5 ordered lexicographically such that e1 ≫e2 ≫. . . ≫e5,
where v ≫w denotes v ≥λw for any λ > 0. There is a unique associative bi-
linear positive product ∗ﬁxed by e1 ∗ej = ej ∗e1 = ej, e2 ∗e2 = e4, e3 ∗e2 = e5
and in the remaining cases ei ∗ej = 0. For details, see [Wes13].
Scalars in an eﬀectus are predicates 1 →1 + 1 on the ﬁnal object 1. They
form an eﬀect algebra by Proposition 17 (1). When we view scalars as partial
maps 1 →1, we directly see that they also carry a monoid structure, namely
Kleisli/partial composition
. The latter preserves the sums >, 0 in each co-
ordinate by Proposition 13 (2).
Since the scalar 1 is the ﬁrst coprojection
κ1 : 1 →1 + 1, it is the identity map on 1 in the category of partial maps, and
thus the unit for . We now summarise the situation.
Deﬁnition 19. For an arbitrary eﬀectus B with ﬁnal object 1, we write Pred(1) =
Par(B)(1, 1) for the eﬀect monoid of scalars with partial composition
.
Once we know what scalars are, we can deﬁne associated modules having
scalar multiplication.
Deﬁnition 20. Let M be an eﬀect monoid.
1. An eﬀect module over M is an eﬀect algebra E with a scalar multiplication
(action) M ⊗E →E in EA. In such a module we have elements r·e ∈E,
for r ∈M and e ∈E, satisfying, apart from preservation of 0, > in each
coordinate, 1 · e = e and r · (s · e) = (r · s) · e.
2. A map of eﬀect modules is a map of eﬀect algebras f : E →D satisfying
f(r · e) = r · f(e) for each r ∈M, e ∈E. We write EModM for the
category of eﬀect modules over M, with eﬀect module maps as morphisms
between them.
We can also deﬁne eﬀect modules more abstractly: an eﬀect monoid M
is a monoid M ∈EA in the symmetric monoidal category of eﬀect algebras.
Hence the functor M ⊗(−) is a monad on EA.
The category EModM of
eﬀect modules over M is the resulting category of Eilenberg-Moore algebras of
this monad, i.e. the category of actions of the monoid M. There is an obvious
forgetful functor EModM →EA.
Eﬀect modules over the Booleans {0, 1} are just eﬀect algebras.
Almost
always in examples we encounter eﬀect modules over the probabilities [0, 1].
That’s why we often simply write EMod for EMod[0,1].
In the context of
eﬀect modules, the elements of the underlying eﬀect monoid are often called
scalars.
For each set X, the collection [0, 1]X of ‘fuzzy predicates’ on X is an eﬀect
algebra, by Proposition 17, where p ⊥q iﬀp(x) + q(x) ≤1 for all x ∈X, and
32

in that case (p > q)(x) = p(x) + q(x). The orthosupplement p⊥is deﬁned by
p⊥(x) = 1 −p(x) = p(x)⊥. This eﬀect algebra [0, 1]X is an eﬀect module over
[0, 1], via scalar multiplication r · p deﬁned as (r · p)(x) = r · p(x). This mapping
X 7→[0, 1]X yields a functor Sets →EModop.
We can now strengthen Proposition 17 in the following way.
Theorem 21 (From [Jac15a]). For each eﬀectus B the mapping X 7→Pred(X)
yields a predicate functor:
B
Pred
/

EModM
op
where
M = Pred(1).
This functor Pred preserves ﬁnite coproducts and the ﬁnal object.
This theorem says that predicates in an eﬀectus form eﬀect modules over
the eﬀect monoid Pred(1) of scalars in the eﬀectus.
Proof For a predicate p: X →1 on X and a scalar s: 1 →1 we deﬁne scalar
multiplication simply as partial composition s
p. The PCM-structure >, 0 is
preserved in each coordinate by Proposition 13 (2). We have r (s p) = (r s) p
by associativity of partial composition, and 1 p = p because 1 = κ1 : 1 →1 + 1
is the identity on 1 for partial composition .
For a (total) map f : Y →X in B we see that substitution f ∗preserves
scalar multiplication:
f ∗(s
p) = (s
p) f = (s
p)
‹f› = s
(p
‹f›) = s
f ∗(p).
We still have to prove that the functor Pred: B →(EModM)op preserves ﬁnite
coproducts and the ﬁnal object. This means that it sends coproducts in B to
products in EModM, and the ﬁnal object to the initial one in EModM.
• There is precisely one predicate 0 →1+1, so Pred(0) is a singleton, which
is ﬁnal in EModM.
• The scalars M = Pred(1) are initial in EModM.
• For objects X, Y ∈B, there is an isomorphism of eﬀect modules:
Pred(X + Y )
⟨κ∗
1,κ∗
2⟩
-
∼=
Pred(X) × Pred(Y )
[−,−]
m
□
With this ﬁnal object M and these ﬁnite coproducts the category (EModM)op
is an eﬀectus. Its scalars are precisely the elements of the eﬀect monoid M.
Example 22. We brieﬂy review what this theorem means concretely for the
running examples from Subsection 3.1.
1. The scalars in the eﬀects Sets of sets and functions are the Booleans
2 = {0, 1}, see Example 8.
Since eﬀect modules over 2 are just eﬀect
algebras, the predicate functor takes the form Pred: Sets →EAop. It
sends a set X to the eﬀect algebra P(X) of subsets of X. As is well-known,
these predicates P(X) form a Boolean algebra, but that is a consequence
33

of the fact that Sets is a special, ‘Boolean’ eﬀectus, see Proposition 61.
For a function f : Y →X, the associated substitution functor f ∗: P(X) →
P(Y ) is inverse image:
f ∗(U) = {y ∈Y | f(y) ∈U}.
2. We recall from Example 9 that scalars in the Kleisli category Kℓ(D) are
the probabilities [0, 1], and predicates on a set X are functions X →[0, 1].
Indeed, as we saw before Theorem 21, the set of fuzzy predicates [0, 1]X
is an eﬀect module over [0, 1]. For a map f : Y →X in Kℓ(D), that is, for
a function f : Y →D(X), the associated substitution map f ∗: [0, 1]X →
[0, 1]Y is deﬁned as:
f ∗(p)(y) = P
x∈X f(y)(x) · p(x).
This map f ∗is indeed a homomorphism of eﬀect modules. Hence we have
a predicate functor Kℓ(D) →EModop.
3. The scalars in the eﬀectus OUGop of order unit groups are the Booleans
2 = {0, 1}, and the predicates on an order unit group G are the eﬀects
in the unit interval, [0, 1]G = {x ∈G | 0 ≤x ≤1}, see Example 10. For
a map f : G →H in OUGop, that is, for a homomorphism of order unit
groups f : H →G the substitution function f ∗: [0, 1]H →[0, 1]G is given
simply by function application:
f ∗(x) = f(x).
This is well-deﬁned since f is positive, so that f(x) ≥0, and unital so
that f(x) ≤f(1) = 1. In this case we have a predicate functor OUGop →
EAop.
For the special case of order unit spaces, the scalars in the relevant eﬀectus
OUSop are the probabilities [0, 1]. In this case the predicate functor is of
the form Pred: OUSop →EModop. It is full and faithful.
4. The situation is similar for the eﬀectus vNAop of von Neumann algebras,
see Example 11: the scalars are the probabilities [0, 1], and the predicates
on a von Neumann algebra A are the eﬀects in [0, 1]A = {a ∈A | 0 ≤
a ≤1}. This is an eﬀect module since r · a ∈[0, 1]A for r ∈[0, 1] and
a ∈[0, 1]A . Substitution f ∗works, like for order unit groups, via function
application:
f ∗(a) = f(a).
We thus obtain a predicate functor vNAop →EModop. It is also full
and faithful, see [FJ15].
In (the proof of) Theorem 21 we have seen scalar multiplication s
p via
partial post-composition, for a scalar s: 1 →1 and a predicate p: X →1.
The same trick can be used for substates ω: 1 →X via partial pre-composition.
Substates thus form a PCM with scalar multiplication (which is a map of PCMs
34

in each coordinate). We call these structure partial commutative modules (PC-
modules, for short). They are organised in a category PCMod in the obvious
manner. We have to keep in mind that writing partial composition
in the
usual order gives ‘right’ modules, with the scalar written on the right.
Lemma 23. The sets SStat(X) of substates ω: 1 →X in an eﬀectus are partial
commutative modules over the eﬀect monoid of scalars Pred(1), via ω
s.
Proof Obviously, this deﬁnition ω
s determines a right action of the monoid
Pred(1) of scalars on the set SStat(X) of substates.
It preserves the PCM
structure in each coordinate by Proposition 13 (2).
□
Later, in Section 10 we shall see that in the presence of tensor products ⊗
all partial homsets, and not just the ones of substates, become PC-modules.
This scalar multiplication on substates makes it possible to deﬁne when a
substate is pure. In quantum theory a state is called pure is it is not a mixture
(convex combination) of other states.
In the current setting this takes the
following form.
Deﬁnition 24. A non-zero substate ω: 1 →X in an eﬀectus is called pure if
for each pair of orthogonal substates ω1, ω2 : 1 →X with ω = ω1 > ω2 there is a
scalar s with:
ω1 = ω
s
and
ω2 = ω
s⊥.
For instance, subdistributions of the form r|x⟩∈D≤1(X), for r > 0, are
pure: if r|x⟩= ω1 > ω2, for ω1, ω2 ∈D≤1(X), then ω1(y) + ω2(y) = (ω1 >
ω2)(y)r|x⟩(y) = 0 for y ̸= x.
Hence ω1(y) = ω2(y) = 0. This means that
ω1 = r1|x⟩and ω2 = r2|x⟩for certain r1, r2 ∈[0, 1] with r1 + r2 = r. Hence we
take s = r1
r ∈[0, 1]. Clearly:
s · ω = r1
r · r|x⟩= r1|x⟩= ω1.
And:
s⊥· ω = (1 −r1
r ) · r|x⟩= (r −r1)|x⟩= r2|x⟩= ω2.
5
State and eﬀect triangles
In quantum theory there is a basic duality between states and eﬀects, see
e.g. [HZ12]. This duality can be formalised in categorical terms as an adjunction
EModop ⇆Conv between the opposite of the category of eﬀect modules and
the category of convex sets. This adjunction will be described in more detail
below.
The duality between states and eﬀects is related to the diﬀerent approaches
introduced by two of the founders of quantum theory, namely Erwin Schr¨odinger
and Werner Heisenberg. Schr¨odinger’s approach is state-based and works in a
forward direction, whereas Heisenberg’s describes how quantum operations work
on eﬀects, in a backward direction. It turns out that the diﬀerence between these
two approaches is closely related to a well-known distinction in the semantics of
computer programs, namely between state transformer semantics and predicate
35

transformer semantics, see [Jac15b]. The situation can be described in terms of
a triangle:
✞
✝
☎
✆
Heisenberg
✞
✝
☎
✆
Schr¨odinger
Logop =
 
predicate
transformers
!
-
⊤
 
state
transformers
!
m

computations

Pred
f◆◆◆◆◆◆◆◆
Stat
8♣
♣
♣
♣
♣
♣
♣
♣
(14)
The main result of this section shows that each eﬀectus gives rise to a such a
‘state and eﬀect’ triangle.
We start with a closer inspection of the structure of states in an eﬀectus.
Recall that a state is a map of the form ω: 1 →X. We will show that states
are closed under convex combinations P
i riωi, where the ri are scalars 1 →
1 + 1. We recall from Deﬁnition 19 that these scalars form an eﬀect monoid.
Hence we need to understand convexity with respect to such eﬀect monoids,
generalising the usual form of convexity with respect to the eﬀect monoid [0, 1]
of probabilities.
Deﬁnition 25. Let M be an eﬀect monoid.
1. A convex set over M is a set X with sums of convex combinations with
scalars from M.
More precisely, for each n-tuple r1, . . . , rn ∈M with
>i ri = 1 and n-tuple x1, . . . , xn ∈X there is an element P
i rixi ∈X.
These convex sums must statisfy the following two properties:
1x = x
and
P
i ri
  P
j sijxij

= P
ij(ri · sij)xij
2. A function f : X →Y between two convex sets is called aﬃne if it pre-
serves sums of convex combinations: f(P
i rixi) = P
i rif(xi). Convex
sets and aﬃne functions between them form a category ConvM.
Convex sets over M can be described more abstractly as an Eilenberg-Moore
algebra of a distribution monad DM deﬁned in terms of formal convex combi-
nations with scalars from M, see [Jac15a]. This explains the form of the above
two equations.
Convex sets over the unit interval [0, 1] have sums of ‘usual’ convex com-
binations, with scalars from [0, 1]. That’s why we often simply write Conv
for the category Conv[0,1] — just like EMod is EMod[0,1]. Convex sets over
the Booleans {0, 1} are ordinary sets: in an n-tuple r1, . . . , rn ∈{0, 1} with
>i ri = 1 there is precisely one i with ri = 1, and rj = 0 for j ̸= i. In that case
we can deﬁne P
j rjxj = xi. This works for any set X. Hence Conv2 ∼= Sets.
The next result gives a categorical formalisation of the duality between states
and eﬀects in quantum physics. It goes back to [Jac10a].
Proposition 26. Let M be an eﬀect monoid.
By “homming into M” one
obtains an adjunction:
 EModM
op
Hom(−,M)
-
⊤
ConvM
Hom(−,M)
m
36

Proof Given a convex set X ∈ConvM, the homset Conv(X, M) of aﬃne
maps is an eﬀect module, with f ⊥g iﬀ∀x ∈X. f(x) ⊥g(x) in M. In that
case one deﬁnes (f > g)(x) = f(x) > g(x). It is easy to see that this is again
an aﬃne function. Similarly, the pointwise scalar product (r · f)(x) = r · f(x)
yields an aﬃne function. This mapping X 7→Conv(X, M) gives a contravariant
functor since for h: X →X′ in ConvM pre-composition with h yields a map
(−) ◦h: Conv(X′, M) →Conv(X, M) of eﬀect modules.
In the other direction, for an eﬀect module E ∈EModM, the homset
EMod(E, M) of eﬀect module maps yields a convex set: a convex sum f =
P
j rjfj, where fj : E →M in EModM and rj ∈M, can be deﬁned as
f(y) = >j rj · fj(y).
This f forms a map of eﬀect modules.
Again, func-
toriality is obtained via pre-composition.
The dual adjunction between EModM and ConvM involves a bijective cor-
respondence that is obtained by swapping arguments.
□
Lemma 27. Let B be an eﬀectus, with eﬀect monoid of scalars Pred(1).
1. For each object X the set of states Stat(X) = B(1, X) is a convex set over
the eﬀect monoid Pred(1) of scalars in B.
2. Each (total) map f : X →Y in B gives rise to an aﬃne function f∗=
f
(−): Stat(X) →Stat(Y ).
Thus we have a state functor:
B
Stat
/ ConvM
where
M = Pred(1).
Proof We ﬁrst have to prove that convex sums exist in the set of states Stat(X).
So let r1, . . . , rn ∈Pred(1) be scalars with >i ri = 1. This means that there
is a bound b: 1 →n · 1 = 1 + · · · + 1 with ✄i
b = ri and ∇
b = 1: 1 →1,
where ∇: n · 1 →1 is the n-ary codiagonal. The equation ∇
b = 1 translates
to (∇+ id) b = κ1 !: 1 →1 + 1. Hence b is a total map 1 →n · 1, of the form
b = κ1
s in:
1
b
"
!
%
s
#
n · 1

κ1

∇
/
❴✤
1
κ1

n · 1 + 1 ∇+id / 1 + 1
For an n-tuple of states ωi : 1 →X we now deﬁne [ω1, . . . , ωn]
s to be the
convex sum P
i riωi.
Post-composition with f : X →Y is clearly aﬃne, since:
f∗
  P
i riωi

= f
[ω1, . . . , ωn] s
= [f
ω1, . . . , f
ωn] s = P
i rif∗(ωi).
□
When we combine this result with Theorem 21 and Proposition 26 we obtain
the following result.
37

Theorem 28. Let B be an eﬀectus, with M = Pred(1) = Stat(1 + 1) its eﬀect
monoid of scalars. There is a ‘state and eﬀect’ triangle of the form:
(EModM)op
Hom(−,M)
-
⊤
ConvM
Hom(−,M)
m
B
Hom(−,1+1)=Pred
e❑❑❑❑❑❑❑❑❑❑
Stat=Hom(1,−)
;✇
✇
✇
✇
✇
✇
✇
✇
✇
(15)
For a predicate (eﬀect) p: X →1 + 1 and a state ω: 1 →X we deﬁne the
validity ω |= p as the scalar obtained by composition:
(ω |= p) = p ◦ω: 1 →1 + 1.
(16)
We call this abstract deﬁnition the Born rule, see Example 29 (4) below.
This validity |= satisﬁes the following Galois correspondence:
f∗(ω) |= q = q f
ω = ω |= f ∗(q),
(17)
where f : X →Y , ω: 1 →X, and q: Y →1 + 1.
This validity relation |= gives rise to two natural transformations in:
(EModM)op
ConvM
B
Stat
6
Hom(Pred(−),M)
F
✼✼✼✼
Hom(Stat(−),M)
\
Pred
g
☛☛☛☛AI
(18)
Proof Most of this is a summary of what we have seen before. We concentrate
on the natural transformations in the last part of the theorem.
The natu-
ral transformation Hom(Stat(−), M) ⇒Pred consists of functions Pred(X) →
M Stat(X) in EModM, given by p 7→(ω 7→ω |= p).
Similarly, the natural
transformation Stat ⇒Hom(Pred(−), M) consists of aﬃne maps Stat(X) →
M Pred(X) given by ω 7→(p 7→ω |= p). Naturality of these functions is given by
the equations (17).
□
Notice that we do not require that the triangle (15) commutes (up to iso-
morphism), that is, that the natural transformations in (18) are isomorphisms.
In some examples they are, in some examples they are not.
Example 29. We shall review the running examples in the remainder of this
section.
1. For the eﬀectus Sets the triangle (15) takes the following form.
EAop
Hom(−,2)
,
⊤
Sets
Hom(−,2)
l
Sets
2(−)=Pred
d■■■■■■■■■
Stat=id
;✈
✈
✈
✈
✈
✈
✈
✈
✈
Here we use that convex sets over the eﬀect monoid 2 = {0, 1} of scalars in
Sets are just sets. The predicate functor 2(−) is powerset, see Example 8.
38

For a state x ∈X and a predicate p ∈2X the Born rule 16 gives an
outcome in {0, 1} determined by membership:
x |= p = p(x).
2. For the eﬀectus Kℓ(D) we have a triangle:
EModop
Hom(−,[0,1])
,
⊤
Conv
Hom(−,[0,1])
m
Kℓ(D)
[0,1](−)=Pred
e❑❑❑❑❑❑❑❑❑❑
Stat
:✉
✉
✉
✉
✉
✉
✉
✉
✉
For a Kleisli map f : X →D(Y ) the associated state transformer function
f∗: D(X) →D(Y ) is Kleisli extension, given by:
f∗(ω)(y) = P
x ω(x) · f(x)(y).
This is ‘baby’ integration. For the Giry monad G it is proper integration,
see [Jac13]. For a state ω ∈D(X) and a predicate p ∈[0, 1]X the Born
rule gives the expected value:
ω |= p = P
x ω(x) · p(x) ∈[0, 1].
The (Born) validity rules for discrete and continuous probability have been
introduced in [Koz81, Koz85], in the context of semantics of probabilistic
programs.
For continuous probability, the correspondence (17) occurs
in [Jac13] for the Giry monad as an equation:
f∗(ω) |= q =
Z
q df∗(ω) =
Z
f ∗(q) dω = ω |= f ∗(q).
Here, f : X →G(Y ) is a measurable function, q: Y →[0, 1] is a (measur-
able) predicate on Y and a maesure/state ω ∈G(X). The operation f∗is
Kleisli extension and f ∗is substitution.
3. The state and eﬀect triangle for the eﬀectus OUGop of order unit groups
is:
EAop
Hom(−,2)
,
⊤
Sets
Hom(−,2)
l
OUGop
[0,1](−)=Pred
e▲▲▲▲▲▲▲▲▲▲
Stat=Hom(−,Z)
9s
s
s
s
s
s
s
s
s
For a predicate e ∈[0, 1]G and a state ω: G →Z validity is:
ω |= e = ω(e) ∈{0, 1}.
39

4. The eﬀectus vNAop of von Neumann algebras yields:
EModop
Hom(−,[0,1])
-
⊤
Conv
Hom(−,[0,1])
m
vNAop
[0,1](−)=Pred
f▼▼▼▼▼▼▼▼▼▼
Stat=Hom(−,C)
9s
s
s
s
s
s
s
s
s
s
For a predicate e ∈[0, 1]A and a state ω: A →C one interpretes validity
again as expected probability:
ω |= e = ω(e) ∈[0, 1].
An interesting special case is A = B(H ), where H is a Hilbert space,
with associated von Neumann algebra B(H ) of bounded operators H →
H . It is well-known that (normal) states ω: B(H ) →C correspond to
density matrices ρ: H →H , via ω = tr(−ρ). The Born rule formula (16),
for an eﬀect E ∈[0, 1]B(H ) = {F : H →H | 0 ≤F ≤id} becomes the
Born rule:
tr(−ρ) |= E = tr(Eρ).
Remark 30. In Theorem 21 we have seen that the predicate functor Pred: B →
(EModM)op of an eﬀectus B preserves ﬁnite coproducts. The same preservation
property does not hold in general for the states functor Stat: B →ConvM from
Lemma 27. The matter is investigated in [JWW15], for the case where the eﬀect
monoid M is [0, 1].
It turns out that preservation of ﬁnite coproducts by the states functor is
closely related to normalisation of substates. This works as follows.
We say that an eﬀectus B satisﬁes normalisation if for each non-zero substate
ω: 1 →X there is a unique state ρ: 1 →X with:
ω = ‹ρ›
1
ω.
(19)
This says that the substate ω is scalar multiplcation ‹ρ›
s in the sense of
Lemma 23, where the scalar s = 1
ω: 1 →1 is determined by ω itself.
We brieﬂy show that the eﬀectuses Kℓ(D) and vNAop satisfy normalisation.
1. A substate in Kℓ(D) is a subdistribution ω ∈D≤1(X). Let us assume that
it is non-zero, so that the associated scalar s = 1
ω = P
x ω(x) ∈[0, 1]
is non-zero.
We take ρ =
ω
s = P
x
ω(x)
s |x⟩.
This ρ is a proper state
(distribution) since:
P
x ρ(x) = P
x
ω(x)
s
= 1.
Moreover, we have s · ρ = ω by construction.
2. A state in the eﬀectus vNAop is a positive subunital map ω: A →C.
If it is non-zero, then s = ω(1) ∈[0, 1] is a non-zero scalar, so we can
deﬁne ρ: A →C as ρ(a) = ω(a)
s . By construction ρ is unital, and satisﬁes
ω = s · ρ.
40

6
Eﬀectuses from biproduct categories
This section describes a construction that turns a biproduct category with a
suitable ‘ground’ map into an eﬀectus. The construction is inspired by causal
maps in the context of CP∗-categories, see [CHK14].
A biproduct category is a category with ﬁnite biproducts (0, ⊕). This means
ﬁrst of all that the object 0 is both initial and ﬁnal, and thus gives rise to zero
maps 0: X →0 →Y between arbitrary objects X, Y . Next, for each pair of
objects X1, X2, the object X1 ⊕X2 is both a product, and a coproduct, with
coprojections and projections:
Xi
κi
/ X1 ⊕X2
πj
/ Xj
satisfying
πj ◦κi =
(
id
if i = j
0
if i ̸= j
It follows immediately that κ1 = ⟨π1 ◦κ1, π2 ◦κ1⟩= ⟨id, 0⟩and π1 = [π1 ◦
κ1, π1 ◦κ2] = [id, 0], and similarly for κ2 and π2. Moreover, each homset of
maps X →Y is a commutative monoid, with sum of maps f, g : X →Y given
by:
f + g =

X
∆=⟨id,id⟩/ X ⊕X
f⊕g
/ Y ⊕Y
∇=[id,id]/ Y

The zero element for this addition + is the zero map 0: X →Y .
Deﬁnition 31. We call a category A a grounded biproduct category if A has
ﬁnite biproducts (⊕, 0) and has a special object I with for each X ∈A a ‘ground’
map
X : X →I satisfying the four requirements below. We omit the subscript
X in
X when it is clear from the context.
1. the ground on I is the identity:
I = idI : I →I;
2. coprojections commute with ground:
 Xi
κi
−→X1 ⊕X2 −→I

=
 Xi −→I

.
3. ground maps are ‘zero-monic’, that is
◦f = 0 implies f = 0
4. ‘subcausal cancellation’ holds: if f + g = f + h =
: X →I, then g = h.
A map f : X →Y in A is called causal if
Y ◦f =
X. We write Caus(A) ֒→A
for the subcategory with causal maps.
As we shall see in Examples 33 and 34 below, these ground maps describe a
unit elements, possibly in opposite direction. Causal maps preserve this units,
and may thus be called unital — or co-unital. The idea of deﬁning them causal
maps in this way occurs in [CL13], building on the causality axiom in [CDP11].
The above second point says that coprojections are causal. Third point, about
cancellation, fails in the CP∗-category obtained from the category of relations,
where union ∪is used as sum +.
We can now state and prove the main result, which was obtained jointly
with Aleks Kissinger.
Theorem 32. The category Caus(A) of causal maps, for a grounded biproduct
category A, is an eﬀectus.
41

Proof The category Caus(A) has coproduct ⊕since the coprojections κi are
causal by deﬁnition, and the cotuple [f, g] is causal if f : X →Z, g : Y →Z are
causal by requirement (2) in Deﬁnition 31:
Z ◦[f, g] = [
Z ◦f,
Z ◦g] = [
X,
Y ]
(2)
= [
X+Y ◦κ1,
X+Y ◦κ2] =
X+Y .
The zero object 0 in A is initial in Caus(A) since !X : 0 →X is causal. We have
X ◦!X = !I =
0. The object I ∈A is ﬁnal in Caus(A), since: the ground map
X : X →I is causal because
I ◦
X = idI ◦
X =
X. Further, any causal
map f : X →I satisﬁes f = idI ◦f =
I ◦f =
X.
We have to prove that the two diagrams from Deﬁnition 2 (1) are pullbacks
in Caus(A).
X ⊕Y
id⊕
/
⊕id 
X ⊕I
⊕id

X
/
κ1 
I
κ1

I ⊕Y
id⊕
/ I ⊕I
X ⊕Y
⊕
/ I ⊕I
For the diagram on the left let A ∈A be an object with causal maps f : A →
X ⊕I and g : A →I ⊕Y satisfying (
⊕id) ◦f = (id ⊕
) ◦g. There is an
obvious, unique mediating map ⟨π1 ◦f, π2 ◦g⟩: A →X ⊕Y . We only have to
prove that it is causal. First notice that:
Y ◦π1 ◦f = π1 ◦(
⊕id) ◦f = π1 ◦(id ⊕
) ◦g = π1 ◦g =
I ◦π1 ◦g.
Now we have that:
X⊕Y =
X⊕Y ◦[κ1, κ2] = [
X⊕Y ◦κ1,
X⊕Y ◦κ2]
= [
X,
Y ] = ∇◦(
X ⊕
Y ).
(∗)
Hence:
◦⟨π1 ◦f, π2 ◦g⟩
(∗)
= ∇◦(
⊕
) ◦⟨π1 ◦f, π2 ◦g⟩
= ∇◦⟨
◦π1 ◦f,
◦π2 ◦g⟩
= ∇◦⟨
◦π1 ◦g,
◦π2 ◦g⟩
as shown above
= ∇◦(
⊕
) ◦⟨π1 ◦g, π2 ◦g⟩
(∗)
=
◦g
=
.
The ⟨π1 ◦f, π2 ◦g⟩is causal, and the diagram on the left is a pullback.
For the above diagram on the right, let f : A →X ⊕Y be a causal map
satisfying (
⊕
) ◦f = κ1 ◦
. The obvious mediating map is π1 ◦f : A →X.
It is causal since
◦π1 ◦f = π1 ◦(
⊕
) ◦f = π1 ◦κ1 ◦
=
. We obtain
π2 ◦f = 0 via Deﬁnition 31 (3) from:
◦π2 ◦f = π2 ◦(
⊕
) ◦f = π2 ◦κ1 ◦
= 0 ◦
= 0.
We now get:
f = ⟨π1 ◦f, π2 ◦f⟩= ⟨π1 ◦f, 0⟩= ⟨id, 0⟩◦π1 ◦f = κ1 ◦π1 ◦f.
42

Hence π1 ◦f : A →X is the required unique mediating (causal) map.
Finally we have to prove that the following two maps ···
··✎✎and ···
··✴✴✎✎✎✎are jointly
monic, in:
(I ⊕I) ⊕I
···
··✎✎/
···
··✴✴✎✎✎✎
/ I ⊕I
where
( ···
··✎✎= [id, κ2] = ⟨π1 ◦π1, (π2 ◦π1) + π2⟩
···
··✴✴✎✎✎✎= [[κ2, κ1], κ2] = ⟨π2 ◦π1, (π1 ◦π1) + π2⟩.
Let f, g : X →(I⊕I)⊕I be causal maps satisﬁng ···
··✎✎◦f = ···
··✎✎◦g and ···
··✴✴✎✎✎✎◦f = ···
··✴✴✎✎✎✎◦g.
Then π1 ◦f = π1 ◦g since:
π1 ◦π1 ◦f = π1 ◦···
··✎✎◦f = π1 ◦···
··✎✎◦g = π1 ◦π1 ◦g
π2 ◦π1 ◦f = π1 ◦···
··✴✴✎✎✎✎◦f = π1 ◦···
··✴✴✎✎✎✎◦g = π2 ◦π1 ◦g.
Hence it suﬃces to show π2 ◦f = π2 ◦g : X →I. For this we use subcausal
cancellation from Deﬁnition 31 (4):
(∇◦π1 ◦f) + (π2 ◦f) = ∇◦⟨∇◦π1 ◦f, π2 ◦f⟩
= ∇◦(∇⊕idI) ◦f
=
I ◦∇◦(∇⊕idI) ◦f
since
I = idI
=
X,
where the last equality holds since f is causal, and causal maps are closed under
composition, cotuple and coproduct. Similarly we have (∇◦π1◦g)+(π2◦g) =
X.
By π1◦f = π1◦g and the cancellation in Deﬁnition 31 (4) we obtain π2◦f = π2◦g.
Hence f = g, showing that ···
··✎✎and ···
··✴✴✎✎✎✎are jointly monic.
□
In the remainder of this section we show how each of our four running ex-
ample eﬀectuses can be understood as category of causal maps in a grounded
biproduct category.
Example 33. Let S be a semiring which is positive and cancellative, that is,
it satisﬁes x + y = 0 ⇒x = y = 0 and x + y = x + z ⇒y = z. We write
MS : Sets →Sets for the multiset monad with scalars from S. Thus, elements
of MS(X) are ﬁnite formal sums P
i si|xi ⟩with si ∈S and xi ∈X. It is easy
to see that MS is a monad, with unit η(x) = 1|x⟩. It is an ‘additive’ monad
(see [CJ13]), since MS(0) ∼= 1 and MS(X + Y ) ∼= MS(X) × MS(Y ). The
Kleisli category Kℓ(MS) then has ﬁnite biproducts (+, 0).
We claim that Kℓ(MS) is a grounded biproduct category. We take I = 1
and use that MS(1) ∼= S. We thus take as map
: X →1 in Kℓ(MS) the
function X →S given by
(x) = 1 ∈S for all x ∈X. We note that each map
f in Kℓ(MS), of the form f = η ◦g for g : X →Y in Sets, is causal, since in
Kℓ(MS):
 ◦f

(x) =
 µ ◦MS( ) ◦η ◦g

(x)
=
 µ ◦η ◦
◦g

(x) =
(g(x)) = 1 =
(x).
We now brieﬂy check that the ground maps
in Kℓ(MS) satisfy the four re-
quirements from Deﬁnition 31.
43

1. The ground map
: 1 →1 in Kℓ(MS) is
(∗) = 1, which is the unit η of
the monad MS, and thus the identity in Kℓ(MS).
2. The coprojection κ1 : X →X + Y in Kℓ(MS) is η ◦k1, where, for the
moment, we write k1 for the coprojection in Sets. Hence it is causal, as
noted above.
3. If
◦f = 0 in Kℓ(MS), for a Kleisli map f : X →Y , then P
y f(x)(y) ·
(y) = 0 for each x ∈X. Since S is positive, we get f(x)(y) = 0, for each
y ∈Y . But then f(x) = 0 ∈MS(X), and thus f = 0.
4. If f + g = f + h =
, for f, g, h: 1 →MS(X), then we may identify f, g, h
with multisets in MS(X) that satisfy f(x) + g(x) = f(x) + h(x) = 1, for
each x ∈X. But then g(x) = h(x) by cancellation in S, for each x ∈X,
and thus g = h.
We now consider two special choices for the semiring S.
• By taking S = N we obtain the category Sets as the eﬀectus of causal
maps in Kℓ(MN). Indeed, maps f : X →MN(Y ) with P
y f(x)(y) = 1,
for each x ∈X are determined by a unique y ∈Y with f(x)(y) = 1. Hence
f corresponds to a function X →Y .
• Next we take S = R≥0, the semiring of non-negative real numbers. We
now obtain the Kleisli category Kℓ(D) as eﬀectus of causal maps in the
grounded biproduct category Kℓ(MR≥0), since maps f : X →MR≥0(Y )
with P
y f(x)(y) = 1, for each x, are precisely the maps X →D(Y ).
Example 34. It is well-known that the category Ab of Abelian groups has ﬁnite
biproducts (⊕, {0}), given by cartesian products. These biproducts restrict to
the category OAb of ordered Abelian groups with positive/monotone group
homomorphisms (described in Example 10). Let’s use the ad hoc notation OUG
for the category with order unit groups as objects, but with positive group
homomorphisms as maps. Hence we have a full and faithful functor OUG →
OAb since we do not require that units are preserved. It is not hard to see that
OUG also has biproducts.
We claim that OUGop is a grounded biproduct category. It has biproducts
since they are invariant under taking the opposite. We take I = Z. For an
order unit group G we have to deﬁne a ground map G →Z in OUGop. We
deﬁne this function
: Z →G simply as
(k) = k · 1 ∈G. We check the four
requirements from Deﬁnition 31.
1. The ground map
: Z →Z is given by
(k) = k · 1 = k and is thus the
identity.
2. We have a commuting diagram in OUG:
Z
/
'❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
G1 ⊕G2
πi

Gi
since πi( (k)) = πi(k · (1, 1)) = π1(k · 1, k · 1) = k · 1 =
(k).
44

3. If f : G →H in OUG satisﬁes f ◦
= 0, then f(1) = 0. From this we
obtain f(x) = 0 for an arbitrary x ∈G in the following way. Since G is
an order unit group there is an n ∈N with −n · 1 ≤x ≤n · 1. But then
because f is monotone:
0 = −n · f(1) = f(−n · 1) ≤f(x) ≤f(n · 1) = n · f(1) = 0.
Hence f = 0.
4. If f + g = f + h =
: Z →G, then f, g, h can be identiﬁed with elements
of G satisfying f + g = f + h = 1. By subtracting f on both sides we
obtain g = h.
It is now easy to see that OUGop is the subcategory Caus(OUGop) and is
thus an eﬀectus. Indeed, a map f : G →H in OUG with f ◦
=
is unital:
f(1) = f( (1)) =
(1) = 1. Hence f is a map in the category OUG of order
unit groups.
In the same way one can prove that the opposite OUSop of the category
OUS of order unit spaces is an eﬀectus. Since there is an equivalence of category
OUS ≃EMod, see [JM12b] for details, the opposite EModop of the category
of eﬀect modules (over [0, 1]) is also an eﬀectus.
In an analogous way one can deﬁne a category vNA of von Neumann alge-
bras with completely positive maps and show that its opposite is a grounded
biproduct category. The category of von Neumann algebras with completely
positive unital maps is the associated eﬀectus of causal maps. In particular, it
forces this quantum model to be ‘non-signalling’, see [CK15, §5.3].
Remark 35. As mentioned in the beginning of this section, the CP∗-categories
from [CHK14] form an inspiration for the construction in this section. A cat-
egory CP∗(C) is obtained from a dagger-compact category C, and forms a
grounded biproduct if:
1. C has ﬁnite biproducts;
2. the dagger in C yields a “positive deﬁnite inner product”, that is, for all
ψ: I →X, if ψ† ◦ψ = 0, then ψ = 0;
3. “uniqueness of positive resolutions” holds: for all positive maps p, q, q′, if
p + q = id = p + q′, then q = q′. We recall that a map p is called positive
in a dagger-category if there exists g such that p = g† ◦g.
The main point of this section is to show that inside a grounded biproduct
category there is an eﬀectus of causal maps. The grounded biproduct category
can then be seen as a larger, ambient category of the eﬀectus. One can also
go in the other direction, that is, produce an ambient grounded biproduct cat-
egory from an eﬀectus via a (universal) totalisation construction. This will be
described elsewhere.
7
Kernels and images
Kernels and images (and cokernels) are well-known constructions in (categorical)
algebra. Standardly, for a map f : A →B its kernel ker(f) and image im(f) are
45

understood as maps, of the form ker(f): K ֌ A and im(f): B ։ C, satisfying
certain universal properties. Here we deﬁne kernels and images as predicates,
namely ker(f): A →1 + 1 and im(f): B →1 + 1. Later on, in the presence of
comprehension and quotients, our kernels and images (as predicates) will give
rise to kernels and images/cokernels in the traditional sense, see in particular
Lemma 80 (2) and Lemma 83 (14). When confusion might occur we speak of
kernel/image predicates versus kernel/image maps. But our default meaning is:
predicate.
In the context of eﬀectuses there is an important diﬀerence between kernels
and images: kernels always exist, but the presence of images is an additional
property of an eﬀectus.
We recall from (6) on page 10 the two forms of substitution that we use, for
total and partial maps, namely: f ∗(p) = p f and g✷(p) = [p, κ1] g = (p⊥g)⊥,
with their basic properties described in Exercise 1. The predicate g✷(p) may
be read as the ‘weakest liberal precondition’ of p for the partial computation g.
Informally it says: if g terminates, then p holds. The ‘strong’ version g✸(p) =
p
g says: g terminates and then p holds. As usual, there is the De Morgan
relationship g✸(p⊥) = g✷(p)⊥.
At this stage we know that the predicates Pred(X) on an object X in an
eﬀectus form an eﬀect module, and are in particular partially ordered (see Ex-
ercise 16). We know that the total substitution map f ∗preserves the eﬀect
module structure. This is diﬀerent for the partial substitution map g✷. So far
we only know that it preserves truth, see Exercise 1 (6). But there is a bit more
that we can say now.
Lemma 36. For a partial map g : X →Y in an eﬀectus the partial substitution
map g✷: Pred(Y ) →Pred(X) preserves 1, ? and is monotone — where ? is
the De Morgan dual of > given by p ? q = (p⊥> q⊥)⊥.
Proof We use that partial pre-composition (−)
g preserves >, see Proposi-
tion 13 (2). If p⊥⊥q⊥, then:
g✷(p ? q) =
 (p ? q)⊥
g
⊥=
 (p⊥> q⊥)
g
⊥
=
 (p⊥
g) > (q⊥
g)
⊥
= (p⊥
g)⊥? (q⊥
g)⊥
= g✷(p) ? g✷(q).
As a consequence g✷is monotone, since p ≤q iﬀq⊥≤p⊥iﬀq⊥> r⊥= p⊥for
some r, that is, q ? r = p.
□
7.1
Kernels
In linear algebra the kernel of a (linear) map f : A →B is the subspace {a ∈
A | f(a) = 0} of those elements that get mapped to 0. This also works for partial
maps X →Y + 1 where we intuitively understand the kernel as capturing those
elements of X that get sent to 1 in the outcome Y + 1.
Deﬁnition 37. Let B be an eﬀectus. The kernel of a partial map f : X →Y
is the predicate ker(f): X →1 + 1 given by:
ker(f)
def
= f ✷(0)
= [0, κ1] f = [κ2, κ1] (! + id) f =
 (! + id) f
⊥.
(20)
46

We call f an internal mono if ker(f) = 0.
Sometimes it is easier to work with the orthosupplement of a kernel, and so
we introduce special notation ker⊥for it:
ker⊥(f)
def
= ker(f)⊥
= (! + id) f = ‹!›
f = [κ1
!, κ2] f = 1
f.
This ker⊥(f) is sometimes called the ‘domain predicate’ since it captures
the ‘domain of f’, where f is deﬁned, that is, ‘non-undeﬁned’. Here we call it
the kernel-supplement. We shortly see that internal monos are not related to
‘external’ monos, in the underling category, but they are part of a factorisation
system, see Proposition 84. Similarly, the internal epis that will be deﬁned later
on in this section form part of a factorisation system, see Proposition 95 (7).
We review the situation for our running examples.
Example 38. In the eﬀectus Sets the kernel of a partial function f : X →Y +1
the partial substitution map f ✷: P(Y ) →P(X) is given by:
f ✷(V ) = {x ∈X | ∀y ∈Y . f(x) = κ1y ⇒y ∈V }.
(21)
Hence we obtain as kernel predicate:
ker(f) = f ✷(0) = {x ∈X | ∀y ∈Y . f(x) = κ1y ⇒y ∈∅}
= {x ∈X | f(x) = ∗},
where we write ∗for the sole element of the ﬁnal set/object 1.
In the eﬀectus Kℓ(D) for discrete probability a partial map f : X →Y + 1
may be described either as a function f : X →D(Y + 1) or as f : X →D≤1(Y ),
see Example 9. We consider both cases.
1. For f : X →D(Y + 1) the partial substitution map f ✷: [0, 1]Y →[0, 1]X
is given by:
f ✷(q)(x) = P
y∈Y f(x)(y) · q(y) + f(x)(∗).
(22)
Hence the ker(f) ∈[0, 1]X is the fuzzy predicate:
ker(f)(x) = f ✷(0)(x) = f(x)(∗) = 1 −P
y∈Y f(x)(y).
The kernel thus assigns to x ∈X the probability that f(x) is undeﬁned.
2. For a function f : X →D≤1(Y ) we have:
f ✷(q)(x) = P
y∈Y f(x)(y) · q(y) +
 1 −P
y f(x)(y)

.
(23)
It gives essentially the same description of the kernel:
ker(f)(x) = 1 −P
y f(x)(y)
so that
ker⊥(f)(x) = P
y f(x)(y).
47

In the eﬀectus OUGop of order unit groups the kernel of a partial map
f : G →H can also be described in two ways, via the correspondences from
Example 10. We choose to understand f as a positive subunital map H →G.
Then, for an eﬀect e ∈[0, 1]H we have:
f ✷(e) = f(e) + f(1)⊥.
(24)
As a result, if identify e ∈[0, 1]H with the corresponding map e: H →Z ⊕Z,
then:
e ◦f = f ✷(e⊥)⊥
by Exercise 1 (4)
= 1 −f(e⊥) −f(1)⊥
by (24)
= 1 −f(1) + f(e) −f(1)⊥
= f(1)⊥+ f(e) −f(1)⊥
= f(e).
(25)
Moreover, we simply have:
ker(f) = f(1)⊥
and so
ker⊥(f) = f(1).
The same descriptions apply in the eﬀectus vNAop of von Neumann algebras.
We continue with some basic properties of kernels.
Lemma 39. The kernel operation ker(−) in an eﬀectus B satisﬁes:
1. ker(p) = p⊥for a predicate p: X →1, and so ker⊥(p) = p;
2. ker(f) = 1 iﬀker⊥(f) = 0 iﬀf = 0;
3. ker(✄1) = [0, 1] and ker(✄2) = [1, 0], for the partial projections ✄i deﬁned
in (1);
4. f is internally monic, that is ker(f) = 0, iﬀf is total;
5. ker(g
f) = f ✷ ker(g)

6. ker(g
f) ≥ker(f);
7. ker(‹h›
f) = ker(f);
8. the internally monic maps form a subcategory of Par(B);
9. if g
f and g are internally monic, then so is f;
10. f ✷(p⊥) = f ✷(p)⊥> ker(f).
Proof This involves some elementary reasoning in an eﬀectus.
1. Clearly, ker(p) = [0, κ1] p = [κ2
!, κ2] p = [κ2, κ1] p = p⊥.
2. First, ker(0) = ker(κ2 !) = [0, κ1] κ2 ! = κ1 ! = 1. Next, if 1 = ker(f),
then (! + id) f = ker⊥(f) = 0, so that f = 0 by Lemma 7.
48

3. We simply calculate:
ker(✄1) = [0, κ1] (id + !) = [0, κ1
!] = [0, 1]
ker(✄2) = [0, κ1] [κ2
!, κ1] = [κ1
!, 0] = [1, 0].
4. On the one hand the kernel of a total map is 0 since:
ker(‹g›) = [κ2
!, κ1] κ1
g = κ2
! g = κ2
! = 0.
On the other hand, if ker(f) = 0, then 1
f = ker⊥(f) = 1 so that we f
is total by Lemma 7.
5. We have by Exercise 1 (2):
ker(g
f) = (g
f)✷(0) = f ✷ g✷(0)

= f ✷ ker(g)

.
6. From 0 ≤ker(g) we get by Lemma 36 and point (5):
ker(f) = f ✷(0) ≤f ✷(ker(g)) = ker(g
f).
7. By a straightforward computation:
ker(‹h›
f) = [0, κ1] (h + id) f = [0, κ1] f = f ✷(0) = ker(f).
8. Internally monic maps are total by point (4), and these total map form a
subcategory by Lemma 7.
9. Let g
f and g be internally monic. Write g = ‹h›. Then f is internally
monic since by point (7),
ker(f) = ker(‹h›
f) = ker(g
f) = 0.
10. Let f : X →Y be a partial map and p a predicate on Y . We ﬁrst observe
that:
1 =
 1
f

>
 1
f
⊥=
 (p > p⊥)
f

> ker(f)
=
 p
f

>
 p⊥
f

> ker(f)
= f ✷(p⊥)⊥> f ✷(p)⊥> ker(f).
This last equation is based on Exercise 1 (4). By uniqueness of orthosup-
plements we obtain f ✷(p⊥) = f ✷(p)⊥> ker(f).
□
We can now see that ‘internally monic’ does not imply ‘monic’.
Indeed
‘internally monic’ means ‘total’, and not every total function in Par(Sets) is
also monic in Par(Sets), like the truth function {0, 1} →1 + 1.
More generally, it is not hard to see that a partial map f : X →Y + 1 is
monic in the category Par(B) of partial maps of an eﬀectus B if and only if its
Kleisli extension [f, κ2]: X + 1 →Y + 1 is monic in B.
49

But also: not all ‘external monos’ are ‘internal monos’. For instance the
partial function f : X →D(X +1) given by f(x) = 3
4|x⟩+ 1
4|∗⟩has ker(f)(x) =
f(x)(∗) = 1
4, so ker(f) ̸= 0 in [0, 1]X, and thus f is not internally monic. Still f
is an external mono in Par(Kℓ(D)): if ω, ω′ ∈D(X + 1) satisfy f∗(ω) = f∗(ω′),
then for each x ∈X we have ω(x) = 4
3 · f∗(ω)(x) = 4
3 · f∗(ω′)(x) = ω′(x), and
ω(∗) = 4 · f∗(ω)(∗) = 4 · f∗(ω′)(∗) = ω′(∗).
The following technical but important result about kernel-supplements, and
the subsequent proposition, are due to [Cho15].
Lemma 40. Let B be an eﬀectus, with objects X, Y ∈B. The kernel-supplement
map
Par(B)
 X, Y )
ker⊥
/ Pred(X)
is a map of PCMs, that preserves and reﬂects both 0 and orthogonality ⊥.
Moreover, this kernel-supplement map is ‘dinatural’ in the situation:
Bop × B
Par(B)(−,−)
+
Pred1=Pred◦π1
3
✤✤✤✤ ker⊥
Sets
Indeed, for each map f : X →Y in B we have a commuting diagram:
Par(B)(X, X)
ker⊥
X/ Pred1(X, X) = Pred(X)
Pred1(X,f)=id
❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
❖
Par(B)(Y, X)
Par(B)(f,X)=(−) f
7♥
♥
♥
♥
♥
♥
♥
♥
♥
Par(B)(Y,f)=(f+id) (−)
'P
P
P
P
P
P
P
P
P
Pred(X) = Pred1(X, Y )
Par(B)(Y, Y )
ker⊥
Y
/ Pred1(Y, Y ) = Pred(Y )
Pred1(f,Y )=f ∗
7♦
♦
♦
♦
♦
♦
♦
♦
(26)
Proof First, the map ker⊥preserves and reﬂects 0, since ker⊥(f) = 0 iﬀf = 0
by Lemma 39 (2) — or equivalently, Lemma 7. It also preserves > by Proposi-
tion 13 (2): if parallel partial maps f, g are orthogonal, then:
ker⊥(f > g) = 1
(f > g) = (1
f) > (1
g) = ker⊥(f) > ker⊥(g).
The main challenge is to prove that ker⊥(f) ⊥ker⊥(g) implies f ⊥g. So let
b: X →1 + 1 be a bound for ker⊥(f) and ker⊥(g). Then ✄1
b = ker⊥(f) =
1
f = ‹!›
f and similarly ✄2
b = ‹!›
g. We use the projection pullbacks in
Par(B) from (10) in Lemma 3 (2) in two steps below, ﬁrst to get a map c, and
then d.
X
f
"
b
$
c
"
X
g
"
c
%
d
#
Y + 1
‹!›+id/
✄1

❴✤
1 + 1
✄1

Y + Y
id+‹!›/
✄2

❴✤
Y + 1
✄2

Y
‹!›
/ 1
Y
‹!›
/ 1
50

The outer diagram on the right commutes since:
✄2
c = ✄2
(‹!› + id)
c = ✄2
b = ‹!›
g.
This d is a bound for f, g, showing f ⊥g. By construction ✄2
d = g, and:
✄1
d = ✄1
(id + ‹!›)
d = ✄1
c = f.
Finally we check commutation of the dinaturality diagram (26): for a total
map f : X →Y and a partial map g ∈Par(B)(Y, X) we have:
 f ∗◦ker⊥
Y ◦((f + id) −)

(g) = f ∗ ker⊥
Y ((f + id) g)

= (! + id) (f + id) g
f
= (! + id) g
f
= ker⊥
X(g
f)
=
 ker⊥
X ◦(−f)

(g).
□
This reﬂection of orthogonality is a quite powerful property. First we use it
to say more about the PCM-structure (>, 0) on homsets of partial maps from
Proposition 13.
Proposition 41. Let B be an eﬀectus. Then:
1. the sum > on partial homsets Par(B)(X, Y ) is positive: f > g = 0 implies
f = g = 0;
2. it is also cancellative in the sense: f > g = g implies f = 0;
3. Par(B)(X, Y ) is a partial order via f ≤g iﬀf > h = g for some h; pre-
and post-composition of partial maps is thus monotone.
As a result of the last point the category Par(B) of partial maps is not
only enriched over PCMs, but also over pointed posets (with a bottom element,
preserved under composition).
Proof If f > g = 0, then ker⊥(f) > ker⊥(g) = ker⊥(f > g) = 0, so that
ker⊥(f) = ker⊥(g) = 0 since the eﬀect module Pred(X) is positive. But then
f = g = 0 by Lemma 39 (2).
If f > g = g, then by similarly applying ker⊥(−) we get ker⊥(f) = 0 in
Pred(X), and thus f = 0.
Obviously, the order ≤on Par(B)(X, Y ) is reﬂexive and transitive. But it
is also anti-symmetric: if f ≤g and g ≤f, say via f > h = g and g > k = f,
then f > (h > k) = f, so that h > k = 0 by point (2), and thus h = k = 0 by
point (1). Hence f = g.
□
We include a second result that uses reﬂection of orthogonality by kernel-
supplements. The fact that normalisation of substates holds in the two examples
Kℓ(D) and vNAop in Remark 30 is an instance of the following result due to
Sean Tull.
Lemma 42. Let B be an eﬀectus whose scalars are given by the unit interval
[0, 1] of R. Then normalisation holds in B: non-zero substates can be normalised
to proper states, that is, for each non-zero ω: 1 →X there is a unique ρ: 1 →X
with ω = ‹ρ›
r for the (non-zero) scalar r = 1
ω: 1 →1.
51

In particular, this means that in the context of [JWW15], where all eﬀectuses
have [0, 1] as scalars, normalisation comes for free.
Proof Let ω: 1 →X be a non-zero substate, with corresponding scalar r =
1
ω ∈[0, 1].
Since r ̸= 0 — by Lemma 7 — we can ﬁnd an n ∈N and
r′ ∈[0, 1] with r′ ≤r and n · r + r′ = 1. More abstractly, we can ﬁnd scalars
s1, . . . , sm ∈[0, 1] with >i si · r = 1. We now form the scalar multiplication
ω
si : 1 →X as in Lemma 23. The scalars 1
ω
si = r
si are orthogonal, so
the maps ω
si are orthogonal too, since 1
(−) = ker⊥reﬂects orthogonality,
by Lemma 40. But then we have the following equalities of maps 1 →1.
1 >i(ω
si) = >i 1
ω
si = >i r
si = 1.
Lemma 7 tells that the partial map >i(ω
si): 1 →X is total, so we can write
it as ‹ρ›, for a unique state ρ: 1 →X. By construction we have ‹ρ›
1
ω = ω
as in (19).
If also ρ′ : 1 →X satisﬁes ‹ρ′›
r = ω = ‹ρ›
r, then we obtain ρ′ = ρ from
faithfulness of ‹−›: B →Par(B):
‹ρ› = ‹ρ› >i r
si = >i‹ρ›
r
si
= >i‹ρ′›
r
si = ‹ρ′› >i r
si = ‹ρ′›.
□
Tull’s result is a bit more general and generalises the crucial property used in
the lemma to the requirement that the scalars satisfy: for each non-zero scalar
r there are scalars s1, . . . , sm with >i si · r = r = >i r · si. This condition
does not apply to eﬀectuses that have a cube [0, 1]n as scalars. For instance
(r, 0) ∈[0, 1]2 is non-zero, for r ̸= 0, but there is no way to raise (r, 0) to the
top element (1, 1) ∈[0, 1]2 via multiply-and-add. This means that the product
of two eﬀectuses with normalisation need not have normalisation.
By generalising the requirement to all sets of predicates one can normalise
all non-zero partial maps, via the scalar multiplication from Lemma 67.
Once again using reﬂection of orthogonality we can give an alternative de-
scription of the partial pairing ⟨⟨f, g⟩⟩from Lemma 6. It exists for maps f, g
satisfying 1
f = (1
g)⊥. In the terminology of the present section we can
rephrase this assumption as ker⊥(f) = ker(g), or as ker⊥(f) > ker⊥(g) = 1.
Lemma 43. Let f : Z →X and g : Z →Y be to partial maps in an eﬀectus
with ker⊥(f) = ker(g). Then we can describe the resulting total pairing map
⟨⟨f, g⟩⟩: Z →X + Y as the unique one satisfying in the homset of partial maps
Z →X + Y :
‹⟨⟨f, g⟩⟩› = (κ1
f) > (κ2
g).
(27)
As special case of this equation we obtain, using the equation ⟨⟨✄1, ✄2⟩⟩= id
from (11), a new relationship between projections and coprojections:
id = (κ1
✄1) > (κ2
✄2).
More generally, there is the following bijective correspondence (from [Cho15]):
Z
f
/ X1 + · · · + Xn
==============================
Z
fi
/ Xi
with ker⊥(fi) orthogonal
(28)
52

Moreover, the map f above the lines is total if and only if the maps fi below the
lines satisfy >i ker⊥(fi) = 1.
Proof For the sum > on the right in the equation (27) we take as bound
b: Z →(X +Y )+(X +Y ) the map b = ‹κ1+κ2› ⟨⟨f, g⟩⟩= (‹κ1›+‹κ2›) ⟨⟨f, g⟩⟩.
Then:
✄1
b = ✄1
(‹κ1› + ‹κ2›) ⟨⟨f, g⟩⟩= ‹κ1›
✄1
⟨⟨f, g⟩⟩= ‹κ1›
f = κ1
f.
Similarly we get ✄2
b = κ2
g. Then:
(κ1
f) > (κ2
g) = ∇
b = ‹∇›
‹κ1 + κ2› ⟨⟨f, g⟩⟩
= ‹id› ⟨⟨f, g⟩⟩
= ‹⟨⟨f, g⟩⟩›.
The equation (κ1
✄1) > (κ2
✄2) = id holds by (11), for k = id.
In the bijective correspondence (28) we send a map f : Z →X1 + · · · + Xn
to the n-tuple of maps fi = ✄i
f. These maps are all orthogonal, via f as
bound. Hence the maps ker⊥(fi) = 1 ◦fi are also orthogonal. If f is total, then
by an n-ary version of (27),
1 = 1
f = 1 >i(κi
fi) = >i 1
κi
fi = >i 1
fi = >i ker(fi).
In the other direction, let fi : Z →Xi be maps for which the kernel-supplements
ker⊥(fi) = 1◦fi : Z →1 are orthogonal. The maps κi fi : Z →X1+· · ·+Xn are
then orthogonal too since the maps 1 κi fi = 1 fi are orthogonal and ker⊥=
1
(−) reﬂects orthogonality, by Lemma 40. Hence we take f = >i(κi
fi).
This map f is total if > ker(fi) = 1 by following the previous chain of equations
backwards.
We get a bijective correspondence since >i(κi ✄i f) = f like in (27), and:
✄j >i(κi
fi) = >i(✄j
κi
fi) = >i
(
id
fi if j = i
0
if j ̸= i
)
= fj.
□
The bijective correspondence (28) extends the pairing from Lemma 6 to
n-ary form and to partial maps, see the end for Discussion 54 for more details.
7.2
Images
A kernel is a predicate on the domain of a partial map. An image is a predicate
on its codomain. An eﬀectus always has kernels. But the existence of images
must be required explicitly.
There is one more notion that we need in the description of images. In an
eﬀect algebra an element s is called sharp if s ∧s⊥= 0. One may argue that
the meet ∧may not exist. But the deﬁnition of sharpness only requires that the
particular meet s ∧s⊥exists and is equal to 0. Equivalently, without meets: s
is sharp if for each element x one has: x ≤s and x ≤s⊥implies x = 0. Notice
that 0 and 1 are sharp elements, and that if s is sharp then its orthosupplement
s⊥is sharp too.
53

Deﬁnition 44. We say that an eﬀectus has images if for each partial map
f : X →Y there is a least predicate q on Y with f ✷(q) = 1. In that case we
write im(f) for this predicate q. We say that the eﬀectus has sharp images if
these image predicates im(f) are sharp.
Like kernel-supplements ker⊥we also uses image-complements im⊥deﬁned
as im⊥(f) = im(f)⊥.
We call f an internal epi if im(f) = 1.
In all our examples images are sharp. Since many basic results about images
can be proven without assuming sharpness, we shall not use sharp images until
we really need them.
Let’s see if we have images in our running examples.
Example 45. In the eﬀectus Sets, each partial map f : X →Y has an image,
namely the subset of Y given by:
im(f) = {y ∈Y | ∃x ∈X. f(x) = κ1y}.
It is easy to see that im(f) is the least subset V ⊆Y with f ✷(V ) = 1, using the
deﬁnition of f ✷from (21).
The eﬀectus Kℓ(D) also has images: for a partial map f : X →D(Y + 1)
take the (sharp) predicate im(f): Y →[0, 1] given by:
im(f)(y) =
(
1
if there is an x ∈X with f(x)(y) > 0
0
otherwise.
We have, using the description of f ✷from (22),
f ✷(im(f))(x) = P
y f(x)(y) · im(f)(y) + f(x)(∗)
= P
y f(x)(y) + f(x)(∗)
= 1.
Further, if q ∈[0, 1]Y satisﬁes f ✷(q) = 1, then P
y f(x)(y) · q(y) + f(x)(∗) = 1
for each x ∈X. But this can only happen if q(y) = 1 if f(x)(y) > 0, that is, if
im(f) ≤q.
In the eﬀectus OUGop of order unit groups, images need not exist. To see
this, let A = [0, 1]2 be the unit square, which is clearly a convex set.
The
set Aﬀ(A) of bounded aﬃne functions A →R forms an order unit group with
coordinatewise operations and order. Let ϕ: Aﬀ(A) →R be the map given by
ϕ(f) = f(0, 0) for all f ∈Aﬀ(A). We claim that ϕ, seen as arrow R →Aﬀ(A)
in OUGop, has no image. Towards a contradiction, let ϕ have image f = im(ϕ)
in the unit interval of predicates [0, 1]Aﬀ(A), see Example 10. Then:
1 = ϕ✷(f)
(24)
= ϕ(f) + ϕ(1)⊥= f(0, 0) + 1(0, 0)⊥= f(0, 0).
Consider the functions f1, f2 ∈Aﬀ(A) given by f1(x, y) = 1 −x and f2(x, y) =
1 −y.
Clearly, ϕ✷(f1) = f1(0, 0) = 1 and ϕ✷(f2) = f2(0, 0) = 1.
Hence
f ≤f1, f2 by minimality of images. Then f(1, y) ≤f1(1, y) = 0 and f(x, 1) ≤
f2(x, 1) = 0.
In particular f(1, 1) = 0.
We now consider the middle point
54

( 1
2, 1
2) ∈A. It can be written in two ways as convex combination of extreme
points, namely as:
1
2(1, 0) + 1
2(0, 1)
(a)
= ( 1
2, 1
2)
(b)
=
1
2(0, 0) + 1
2(1, 1).
By applying the aﬃne function f on both sides we obtain a contradiction. Start-
ing from the above equation (a) we get:
f
  1
2, 1
2

= f
  1
2(1, 0) + 1
2(0, 1)

= 1
2f(1, 0) + 1
2f(0, 1) = 0.
But starting from the equation (b) we obtain a diﬀerent outcome:
f
  1
2, 1
2

= f
  1
2(0, 0) + 1
2(1, 1)

= 1
2f(0, 0) + 1
2f(1, 1) = 1
2.
The conclusion is that the map ϕ in the eﬀectus OUGop has no image.
In the eﬀectus vNAop of von Neumann algebra the image of a subunital
map f : A →B does exist, and is given by the following (sharp) eﬀect of A .
im(f) =
^
{p ∈A | p is a projection with f(p) = f(1)}.
(29)
Here we use that projections are the sharp elements and form a complete lattice,
see e.g. [Sak71, Prop. 1.10.2] One can prove: f(a) = 0 implies im(f) ≤a⊥, for
an arbitrary element a ∈[0, 1]A , see also Lemma 47 (3) below.
It can be shown that in a von Neumann algebra the sharp elements are
precisely the projections, that is, the eﬀects e with e · e = e.
Later on, in
Proposition 106 (5), we prove this in abstract form.
In general, images need not exist in an eﬀectus, but they do exist for a few
special maps: identity maps, coprojections, and partial projections.
Lemma 46. In the category Par(B) of partial maps of an eﬀectus B,
1. im(id) = 1, for the identity map id : X →X;
2. im(0) = 0, for the zero map 0: X →Y ;
3. im(κ1) = [1, 0] and im(κ2) = [0, 1];
4. im(✄1) = 1 and also im(✄2) = 1, so that the partial projections ✄i are
internally epic.
Proof We show each time that the claimed predicate has the universal property
of an image (the least sharp one such that . . . ).
1. By Exercise 1 (2) we have id✷(p) = p. Hence id✷(p) = 1 iﬀp = 1, so that
im(id) = 1.
2. Let 0✷(p) = 1. Then 1 = [p, κ1] κ2
! = κ1
!. This equation imposes no
restrictions on p, so the least predicate for which this holds is the falsity
predicate 0. Hence im(0) = 0.
3. Formally a coprojection in Par(B) is of the form ‹κi› = κ1
κi.
By
Exercise 1 (3) we have ‹κ1›✷([1, 0]) = κ∗
1([1, 0]) = [1, 0] κ1 = 1. Further,
if also ‹κ1›✷(p) = 1, then p κ1 = 1. Since p ◦κ2 ≥0, we get p ≥[1, 0].
Similarly one shows that im(κ2) = [0, 1].
55

4. Let ✄✷
1 (p) = 1. Then 1 = [p, κ1] ✄1 = [p, κ1] (id + !) = [p, κ1 !] = [p, 1].
But then p = [p, 1] κ1 = 1 κ1 = 1. The ✄2-case is left to the reader. □
Having seen this result we can say that the following is an ‘internal’ short
exact sequence in the category of partial maps an eﬀectus.
0
/ X
κ1
/ X + Y
✄2 / Y
/ 0
(30)
Exactness means that the image of one map is the kernel of the next one. This
works because the coprojections are total in the category of partial maps, and
thus internally monic, the partial projections are internally epic, and im(κ1) =
[1, 0] = ker(✄2). But there is more: the sequence 30 involves two splittings,
making κ1 a split mono, and ✄2 a split epi:
0
/ X
κ1
/ X + Y
✄2 /
✄1
b
Y
/
κ2
c
0
(31)
This is a reformulation of the ‘butterﬂy’ diagram (4).
Lemma 47. In an eﬀectus B with images one has:
1. ker(f) = f ✷ im⊥(f)

;
2. im(f) = 0 iﬀker(f) = 1;
3. p
f = 0 iﬀp ≤im⊥(f); in particular, im⊥(f)
f = 0;
4. im(g
f) ≤im(g);
5. im(f) ≤g✷ im(g
f)

;
6. im(g
f) = im(g) if f is a internal epi;
7. g
f = 0 iﬀim(f) ≤ker(g);
8. if g
f and f are internally epic, then so is g;
9. internal epis form a subcategory;
10. a partial map f is internally epic iﬀfor each predicate q on its codomain:
f ✷(q) = 1 ⇐⇒q = 1;
11. ‘external’ epis are internal epis: each epi f in Par(B) satisﬁes im(f) = 1;
12. im([f, g]) = im(f) ∨im(g), for predicates f, g with the same codomain.
Proof All of the points are obtained by elementary arguments.
1. The equation ker(f) = f ✷ im⊥(f)

follows directly from Lemma 39 (10):
f ✷ im⊥(f)

= f ✷(im(f))⊥> ker(f) = 1⊥> ker(f) = ker(f).
2. If im(f) = 0, then by the previous point:
ker(f) = f ✷ im⊥(f)

= f ✷(0⊥) = f ✷(1) = 1.
Conversely, if 1 = ker(f) = f ✷(0), then im(f) ≤0 since it is minimal.
56

3. First, we have:
im⊥(f)
f = [im⊥(f), κ2] f
= [κ2, κ1] [im(f), κ1] f = f ✷(im(f))⊥= 1⊥= 0.
Hence if p ≤im⊥(f), then p
f ≤im⊥(f)
f = 0, using Lemma 36.
In the other direction, if p
f = 0, then:
f ✷(p⊥). = (p
f)⊥= 0⊥= 1.
Hence im(f) ≤p⊥by minimality of images, and so p ≤im(f)⊥= im⊥(f).
4. In order to prove im(g
f) ≤im(g) it suﬃces to show (g
f)✷(im(g)) = 1.
But the latter is easy, since (g f)✷(im(g)) = f ✷ g✷(im(g))

= f ✷(1) = 1.
5. The inequality im(f) ≤g✷ im(g
f)

follows by minimality of images
from:
f ✷
g✷ im(g
f)

= (g
f)✷ im(g
f)

= 1.
6. By point (4) we only have to prove im(g
f) ≥im(g). This follows if we
can show g✷ im(g
f)

= 1. But this is a consequence of the previous
point, since im(f) = 1 because f is by assumption an internal epi.
7. Let g
f = 0. Then, by Lemma 39 (5), we have f ✷(ker(g)) = ker(g
f) = ker(0) = 1, so that im(f) ≤ker(g). Conversely, if im(f) ≤ker(g),
then 1 = f ✷(im(f)) ≤f ✷(ker(g)) = ker(g
f). But then g
f = 0 by
Lemma 39 (2).
8. Let g f and f be internally epic. Then g is internally epic too, by point (6)
since: im(g) = im(g
f) = 1.
9. Lemma 46 (1) says that the partial identity is internally epic. And if g, f
are internal epis, then by point (6), g
f too, since im(g
f) = im(g) = 1.
10. Let f be internally epic. Clearly, if q = 1, then f ✷(q) = f ✷(1) = 1. In the
other direction, if f ✷(q) = 1, then, by minimality of images, 1 = im(f) ≤
q.
Conversely, assume f ✷(q) = 1 ⇐⇒q = 1 for each predicate q.
Take
q = im(f); since by deﬁnition f ✷(im(f)) = 1, we get q = im(f) = 1, so
that f is internally epic.
11. Let f : X →Y be epic in Par(B). By point (3) we have im⊥(f)
f = 0.
But also 0 f = 0. Hence im⊥(f) = 0 since f is epic, and thus im(f) = 1,
so that f is internally epic.
12. We use point (3) to show that for an arbitrary predicate p,
im([f, g]) ≤p ⇐⇒p⊥≤im⊥([f, g])
⇐⇒p⊥
[f, g] = [p⊥
f, p⊥
g] = 0
⇐⇒p⊥
f = 0 and p⊥
g = 0
⇐⇒p⊥≤im⊥(f) = 0 and p⊥≤im⊥(g) = 0
⇐⇒im(f) ≤p and im(g) ≤p.
□
57

8
Relating total and partial maps
This section contains the main result of [Cho15], giving a precise relation be-
tween total and partial maps in an eﬀectus. Brieﬂy certain requirements R are
identiﬁed so that:
• for a category C satisfying R, the subcategory Tot(C) of ‘total’ maps in
C is an eﬀectus, and Par(Tot(C)) ∼= C;
• for an eﬀectus B, the category of partial maps Par(B) satisﬁes R, and
Tot(Par(B)) ∼= B.
A category satisfying R is called a FinPAC with eﬀects in [Cho15]. This termi-
nology is explained below.
This correspondence is made precise in [Cho15] in the form of a 2-equivalence
of 2-categories. Here however, we discuss the essentials in more concrete form,
and refer the reader to loc. cit. for further details. This close correspondence
between total and partial maps can be seen as a conﬁrmation of the appropri-
ateness of the notion of eﬀectus. The correspondence and its consquences — for
notation and terminology — are discussed at the end of this section.
We ﬁrst have to explore the notion of ﬁnitely partially additive category, or
FinPAC. This is based on the notion of partially additive category, introduced
in [AM80].
8.1
FinPACs
Recall that an arbitrary category C is PCM-enriched if all its homsets are
PCMs with >, 0, and pre- and post-composition preserve the PCM-structure.
If such a category C has coproducts + too, then we can deﬁne ‘projections’ ✄i
via the zero map 0, like in (2), as:
X
X + Y
✄1=[id,0]
o
✄2=[0,id] / Y
(32)
These projections are automatically natural: ✄i ◦(f1 + f2) = fi ◦✄i.
Since C is any category — not necessarily an eﬀectus — we shall use ordinary
notation, like ◦and →, for composition and maps, and not the special notation
,
and →, →for eﬀectuses.
Deﬁnition 48. A ﬁnitely partially additive category (a FinPAC, for short) is
a PCM-enriched category C with ﬁnite coproducts (+, 0) satisfying both the:
• Compatible Sum Axiom: if there is a bound b: X →Y + Y for maps
f, g : X →Y with ✄1 ◦b = f and ✄2 ◦b = g, then f ⊥g in the PCM
C(X, Y );
• Untying Axiom: if f ⊥g then (κ1 ◦f) ⊥(κ2 ◦g).
The names for these two axioms come from the theory of partially additive
categories, see [AM80, MA86] or [Hag00]. The maps ✄i are often called quasi
projections in that context.
We need some basic results about FinPACs, following [MA86, Cho15].
Lemma 49. In a FinPAC C,
58

1. The initial object 0 ∈C is also ﬁnal, and thus a zero object; the resulting
zero map X →0 →Y is the zero element 0 of the PCM-structure on the
homset C(X, Y );
2. the maps κ1 ◦✄1, κ2 ◦✄2 : X + Y →X + Y are orthogonal with sum
(κ1 ◦✄1) > (κ2 ◦✄2) = id;
3. any map f : Z →X+Y can be written as sum f = (κ1◦✄1◦f)>(κ2◦✄2◦f);
4. the two projection maps ✄i : X1 + X2 →Xi are jointly monic;
5. f1 ⊥f2 iﬀthere is a necessarily unique bound b with ✄i ◦b = fi and
f1 > f2 = ∇◦b.
Proof For the sake of completeness, we include the details.
1. For each object X ∈C there is a map 0: X →0, namely the PCM-zero. It
is the only such map, since each f : X →0 satisﬁes: f = id ◦f = 0◦f = 0.
The resulting map X →0 →Y is thus ! ◦0 = 0.
2. Take as bound b = κ1 + κ2 : X + Y →(X + Y ) + (X + Y ). Then:
✄1 ◦b = [id, 0] ◦(κ1 + κ2) = [κ1, 0] = κ1 ◦[id, 0] = κ1 ◦✄1.
Similarly one obtains ✄2 ◦b = κ2 ◦✄2. This gives (κ1 ◦✄1) ⊥(κ2 ◦✄2) by
the Compatible Sum Axiom. We take their sum s = (κ1 ◦✄1) > (κ2 ◦✄2)
in the homset of maps X +Y →X +Y and obtain s = id from s◦κi = κi,
as in:
s ◦κ2 =
 (κ1 ◦✄1) > (κ2 ◦✄2)

◦κ2
= (κ1 ◦[id, 0] ◦κ2) > (κ2 ◦[0, id] ◦κ2)
= (κ1 ◦0) > κ2
= 0 > κ2
= κ2.
3. Directly by the previous point, for f : Z →X + Y ,
f = id ◦f =
 (κ1 ◦✄1) > (κ2 ◦✄2)

◦f = (κ1 ◦✄1 ◦f) > (κ2 ◦✄2 ◦f).
4. Suppose f, g : Z →X1 + X2 satisfy ✄i ◦f = ✄i ◦g, for i = 1, 2. Then, by
the previous point:
f = (κ1 ◦✄1 ◦f) > (κ2 ◦✄2 ◦f) = (κ1 ◦✄1 ◦g) > (κ2 ◦✄2 ◦g) = g.
5. If a bound exists, then it is unique because the ✄i are jointly monic.
The Compatible Sum Axiom says that existence of a bound b for f1, f2
gives f1 ⊥f2. We have to prove the converse. So let f1 ⊥f2, and thus
(κ1◦f1) ⊥(κ2◦f2) by the Untying Axiom. We take b = (κ1◦f1)>(κ2◦f2).
Then ✄i ◦b = fi, making b a bound. Moreover:
∇◦b = (∇◦κ1 ◦f1) > (∇◦κ2 ◦f2) = f1 > f2.
□
59

The next result shows the relevance of FinPACs in the current setting.
Lemma 50. The category Par(B) of partial maps in an eﬀectus B is a FinPAC.
Proof We know that Par(B) is enriched over PCM by Proposition 13, and
inherits coproducts from B, like any Kleisli category. The Compatible Sum
Axiom holds by deﬁnition of orthogonality, see Proposition 13 (1).
For the
Untying Axiom, let f1, f2 : X →Y satisfy f1 ⊥f2 via bound b: X →Y + Y .
Then c = (κ1 + κ2)
b: X →(Y + Y ) + (Y + Y ) is a bound for κi ◦fi since:
✄i
c = ✄i
(κ1 + κ2)
b = κi
✄i
b = κi
fi.
□
8.2
FinPACs with eﬀects
We now come to the axiomatisation of the category of partial maps in an eﬀectus.
We use the name ‘FinPAC with eﬀects’ from [Cho15]. This is a temporary name,
see Discussion 54 below.
Deﬁnition 51. A category C is called a FinPAC with eﬀects if it is a FinPAC
with a special object I ∈C such that:
1. the homset C(X, I) is not only a PCM, but an eﬀect algebra, for each
object X ∈C;
2. the top/truth element 1 ∈C(X, I) satisﬁes: for all f, g : Y →X,
(1 ◦f) ⊥(1 ◦g) =⇒f ⊥g
3. the bottom/falsity element 0 ∈C(X, I) satisﬁes: for all f : Y →X,
1 ◦f = 0 =⇒f = 0.
These last two points say that the function 1 ◦(−) reﬂects orthogonality and
zero.
A map f : X →Y in such a FinPAC with eﬀects is called total if 1Y ◦f =
1X. We write Tot(C) ֒→C for the ‘wide’ subcategory (with the same objects)
of total maps in C.
These top maps 1: X →I resemble the ground maps
: X →I in Def-
inition 31. Recall that causal maps f satisfy
◦f =
. The corresponding
property 1 ◦f = 1 describes the total maps, as deﬁned above.
Before arriving at the main result of this section, we collect a few facts about
FinPACs with eﬀects.
Lemma 52. In an FinPAC with eﬀects (C, I),
1. split monics are total, so in particular all coprojections and isomorphisms
are total;
2. idI = 1: I →I; as a result, I ∈C is ﬁnal in Tot(C);
3. [1, 1] = 1: X + Y →I;
60

4. for each total map f : X →Y pre-composition (−)◦f : C(Y, I) →C(X, I)
is a map of eﬀect algebras;
5. Tot(C) inherits ﬁnite coproducts (+, 0) from C.
Proof We reason in the category C.
1. Let f ◦m = id, making m a split monic. We have 1 ◦f ≤1, since 1 is
by deﬁnition the top element. Hence by post-composing with m we get:
1 = 1◦f ◦m ≤1◦m, so that 1 = 1◦m. Coprojections κi are split monics
in C, since ✄i ◦κi = id.
2. In the eﬀect algebra C(I, I) we have id ⊥id⊥. Hence (1 ◦id) ⊥(1 ◦
id⊥) since post-composition is a PCM-map. But then 1 ◦id⊥= 0 by
Deﬁnition 15 (2).
This gives id⊥= 0 by Deﬁnition 51 (3), and thus
id = 1.
For each object X there is a total map 1X : X →I, since 1X = idI ◦1X =
1I ◦1X. If f : X →I is total, then f = idI ◦f = 1I ◦f = 1X.
3. For the equation [1, 1] = 1: X + Y →I we use that coprojections are
total, by point (1):
1 = 1 ◦[κ1, κ2] = [1 ◦κ1, 1 ◦κ2] = [1, 1].
4. The map (−) ◦f preserves the PCM-structure by deﬁnition. And it pre-
serves truth 1 since f is total. Hence it is a map of eﬀect algebras, see
Deﬁnition 15.
5. The object 0 is initial in Tot(C), since the unique map !: 0 →X is total:
1X ◦!X = !I = 10 by initiality in C. Coprojections are total by point (1).
If f, g are total, then so is [f, g] since 1 ◦[f, g] = [1 ◦f, 1 ◦g] = [1, 1] = 1
by point (3).
□
We now come to the main result of this section.
Theorem 53. (From [Cho15])
1. For an eﬀectus B, the category of partial maps Par(B) with special object
1 is a FinPAC with eﬀects, and Tot(Par(B)) ∼= B.
2. For a FinPAC with eﬀects (C, I), the subcategory Tot(C) of total maps is
an eﬀectus, and Par(Tot(C)) ∼= C.
Proof Let B be an eﬀectus. Lemma 50 tells that Par(B) is a FinPAC. We take
I = 1, so that Par(B)(X, 1) = B(X, 1+1) = Pred(X) is an eﬀect algebra. Next
if 1 f = ker⊥(f) ⊥ker⊥(g) = 1 g, then f ⊥g since ker⊥reﬂects orthogonality
— and zero too — by Lemma 40. Reﬂection of zero proves requirement (3) in
Deﬁnition 51. In order to prove Tot(Par(B)) ∼= B we have to prove that a map
f : X →Y is total iﬀ1
f = 1. But we already know this from Lemma 7.
For the second point, let (C, I) be a FinPAC with eﬀects. From Lemma 52
we know that the category Tot(C) of total maps has I as ﬁnial object, and has
coproducts (+, 0) as in C. We ﬁrst show that the rectangles in Deﬁnition 2 (1)
61

are pullbacks in Tot(C). We may thus assume that we have total maps f, g, h
in commuting (outer) diagrams:
Z
g
!
f
%
k
#
W
h
"
1
$
✄1◦h
#
X + Y
id+1 /
1+id

X + I
1+id

X
1
/
κ1

I
κ1

I + Y
id+1 / I + I
X + Y
1+1 / I + I
We ﬁrst concentrate on the situation on the left. By assumption, (1 + id) ◦f =
(id + 1) ◦g = b, say. Then (✄1 ◦b) ⊥(✄2 ◦b), by deﬁnition of orthogonality.
But:
✄1 ◦b = ✄1 ◦(1 + id) ◦f = 1 ◦✄1 ◦f = 1 ◦κ1 ◦✄1 ◦f
✄2 ◦b = ✄2 ◦(id + 1) ◦g = 1 ◦✄2 ◦g = 1 ◦κ2 ◦✄2 ◦g.
Hence we have (1 ◦κ1 ◦✄1 ◦f) ⊥(1 ◦κ2 ◦✄2 ◦g), from which we can conclude
(κ1 ◦✄1 ◦f) ⊥(κ2 ◦✄2 ◦g) using Deﬁnition 51 (2). Thus we can deﬁne:
k = (κ1 ◦✄1 ◦f) > (κ2 ◦✄2 ◦g) : W −→X + Y.
Then:
(id + 1) ◦k = ((id + 1) ◦κ1 ◦✄1 ◦f) > ((id + 1) ◦κ2 ◦✄2 ◦g)
= (κ1 ◦✄1 ◦f) > (κ2 ◦1 ◦✄2 ◦g)
= (κ1 ◦✄1 ◦f) > (κ2 ◦✄2 ◦(id + 1) ◦g)
= (κ1 ◦✄1 ◦f) > (κ2 ◦✄2 ◦(1 + id) ◦f)
= (κ1 ◦✄1 ◦f) > (κ2 ◦✄2 ◦f)
= f
by Lemma 49 (3).
Similarly one proves (1 + id) ◦k = g. For uniqueness, let ℓ: W →X + Y also
satisfy (id + 1) ◦ℓ= f and (1 + id) ◦ℓ= g, then:
k = (κ1 ◦✄1 ◦f) > (κ2 ◦✄2 ◦g)
= (κ1 ◦✄1 ◦(id + 1) ◦ℓ) > (κ2 ◦✄2 ◦(1 + id) ◦ℓ)
= (κ1 ◦✄1 ◦ℓ) > (κ2 ◦✄2 ◦ℓ)
= ℓ.
In the above diagram on the right we have (1 + 1) ◦h = κ1 ◦1. We claim
✄2 ◦h = 0. This follows by Deﬁnition 51 (3) from
1 ◦✄2 ◦h = ✄2 ◦(1 + 1) ◦h = ✄2 ◦κ1 ◦1 = 0 ◦1 = 0.
The map h: W →X + Y then satisﬁes, by Lemma 49 (3),
h = (κ1 ◦✄1 ◦h) > (κ2 ◦✄2 ◦h) = (κ1 ◦✄1 ◦h) > (κ2 ◦0) = κ1 ◦✄1 ◦h.
62

Hence ✄1 ◦h: W →X is a mediating map. It is the unique one, since if also
k: W →X satisﬁes κ1 ◦k = h, then ✄1 ◦h = ✄1 ◦κ1 ◦k = k.
We still have to prove that the two maps ···
··✎✎, ···
··✴✴✎✎✎✎: (I + I) + I →I + I are
jointly monic in Tot(C), where ···
··✎✎= [id, κ2] and ···
··✴✴✎✎✎✎= [[κ2, κ1], κ2].
So let
f, g : X →(I + I) + I satisfy ···
··✎✎◦f = ···
··✎✎◦g and ···
··✴✴✎✎✎✎◦f = ···
··✴✴✎✎✎✎◦g. Write:
f1 = ✄1 ◦✄1 ◦f
f2 = ✄2 ◦✄1 ◦f
f3 = ✄2 ◦f.
Then f = (κ1 ◦κ1 ◦f1) > (κ1 ◦κ2 ◦f1) > (κ2 ◦f3). We can write the map g in
a similar manner. The equation ···
··✎✎◦f = ···
··✎✎◦g yields,
(κ1 ◦f1) > (κ2 ◦f2) > (κ2 ◦f3) = (κ1 ◦g1) > (κ2 ◦g2) > (κ2 ◦g3).
Hence by post-composing with ✄1 and with ✄2 we get:
f1 = g1
and
f2 > f3 = g2 > g3.
Similarly, the equation ···
··✴✴✎✎✎✎◦f = ···
··✴✴✎✎✎✎◦g yields:
(κ2 ◦f1) > (κ1 ◦f2) > (κ2 ◦f3) = (κ2 ◦g1) > (κ1 ◦g2) > (κ2 ◦g3).
Post-composing with ✄1 yields f2 = g2. By substitution in our previous ﬁnding
we get f2>f3 = f2>g3. Cancellation in the eﬀect algebra C(X, I) gives f3 = g3.
Hence f = g.
Finally we show that we have an identity-on-objects, full and faithful functor
F : Par(Tot(C)) →C, deﬁned on maps by F(g) = ✄1 ◦g. It is easy to see that
F is indeed a functor. We construct an inverse functor G: C →Par(Tot(C)).
Let f : X →Y be a map in C. We form 1 ◦f : X →I, so that (1 ◦f) ⊥
(1 ◦f)⊥. Now note that 1 ◦f = 1 ◦κ1 ◦f, for κ1 : Y →Y + 1. Next,
(1 ◦f)⊥= idI ◦(1 ◦f)⊥= 1 ◦(1 ◦f)⊥= 1 ◦κ2 ◦(1 ◦f)⊥,
where κ2 : 1 →Y + 1. Hence (1 ◦κ1 ◦f) ⊥(1 ◦κ2 ◦(1 ◦f)⊥), which gives by
Deﬁnition 51 (2) an orthogonality (κ1 ◦f) ⊥(κ2 ◦(1 ◦f)⊥) in the homset of
maps X →Y + 1. We now deﬁne:
G(f) = (κ1 ◦f) > (κ2 ◦(1 ◦f)⊥) : X −→Y + I.
Clearly,
FG(f) = ✄1 ◦G(f) = (✄1 ◦κ1 ◦f) > (✄1 ◦κ2 ◦(1 ◦f)⊥)
= f > (0 ◦(1 ◦f)⊥) = f > 0 = f.
In order to see GF(g) = g, for a total map g : X →Y + I, write g = (κ1 ◦✄1 ◦
g) > (κ2 ◦✄2 ◦g) by Lemma 49 (3), and compare it with:
GF(g) = (κ1 ◦✄1 ◦g) > (κ2 ◦(1 ◦✄1 ◦g)⊥).
Hence it suﬃces to show ✄2 ◦g = (1 ◦✄1 ◦g)⊥. This is done as follows. The
map (1 + id) ◦g : X →I + I satisﬁes (✄1 ◦(1 + id) ◦g) ⊥(✄2 ◦(1 + id) ◦g) and
thus:
(1 ◦✄1 ◦g) > (✄2 ◦g) = ∇◦(1 + id) ◦g = [1, 1] ◦g = 1 ◦g = 1.
But then we are done by uniqueness of orthosupplements in the eﬀect algebra
C(X, I).
□
63

Discussion 54. Now that we have seen the equivalence of ‘eﬀectus’ and ‘Fin-
PAC with eﬀects’ we have a choice — or a dilemma, if you like: which notion
to use? Let’s start by listing some pros and contras.
1. The notion of eﬀectus has the deﬁnite advantage that its deﬁnition is
simple and elegant — see Deﬁnition 2. Surprisingly many results can be
obtained from this relatively weak structure, which are best summarised
in the resulting state-and-eﬀect triangle (15).
A disadvantage of using the notion of eﬀectus is that we have to explicitly
distinguish total and partial maps, for which we have even introduced
separate notation. Another disadvantage is that from a computational
perspective the category Par(B) of partial maps in an eﬀectus B is the
more interesting structure, and not B itself.
In support of the notion
of eﬀectus one could claim that the main examples are most naturally
described as eﬀectus, and not as FinPAC with eﬀects: thus, for instance
the categories Sets and Kℓ(D) with total functions and distributions are
in a sense more natural descriptions, than the categories Par(Sets) and
Par(Kℓ(D)) ∼= Kℓ(D≤1) with partial maps and subdistributions.
2. The deﬁnition of ‘FinPAC with eﬀects’ is much less elegant, see Deﬁ-
nitions 51 and 48: it is not only much more verbose, but also involves
‘structure’, namely the special object I, of which it is even not clear that
it is determined up-to-isomorphism. On the other hand, a deﬁnite advan-
tage is that in a FinPAC with eﬀects the total maps are a natural subclass
of all the maps (understood as the partial ones), and there is no need for
separate notation for total and partial maps. Moreover, the notion of Fin-
PAC with eﬀects gives you in many, computational situations directly the
structure that is of most interest, namely partial maps. This is especially
the case when we discuss comprehension and quotients later on.
How to weigh these arguments? How to proceed from here? We can choose to
work from now on (1) only with eﬀectuses, (2) only with FinPACs with eﬀects,
or (3) switch freely between them, depending on whatever works best in which
situation.
The ﬁrst two options are easiest, but provide limited ﬂexibility. Therefore we
will choose the third approach. We do realise that it does not make the theory
of eﬀectuses easier, since one has to been keenly aware of which description
applies. But we hope that the reader will reach such a level of enlightment that
the diﬀerences become immaterial — and Wittgenstein’s proverbial ladder can
be thrown away, after one has climbed it.
More concretely, in the sequel we will start deﬁnitions and results with either
“let B an eﬀectus in total form”, or with “let C be an eﬀectus in partial form”.
The latter expression will replace the term ‘FinPAC with eﬀects’; it will not be
used anymore in the sequel of this document.
We take another important decision: up to now we have used separate nota-
tion for total ( , →, +) and partial ( , →, +) maps in eﬀectuses (in total form).
From now on:
• we use ordinary categorical notation in an eﬀectus in total form (replacing
, →, + by ◦, →, +) but continue to use special notation ( , →, +) in the
category of partial maps, i.e. in the Kleisli category of the lift monad.
64

• we also use ordinary categorical notation in an eﬀectus in partial form.
In line with such easy switching of contexts we will freely use notation that
we have introduced for partial maps in an eﬀectus in total form for ordinary
maps in eﬀectuses in partial form — where
simply becomes ◦.
Thus for
instance, for such a map f : X →Y in an eﬀectus in partial form we write:
f ✷(q) = (q⊥◦f)⊥
ker(f) = f ✷(0) = (1 ◦f)⊥
ker⊥(f) = 1 ◦f.
Theorem 53 allows us to translate back and forth between the total and partial
world. Thus, the properties of, for instance, Lemma 39, which are formulated
for an eﬀectus in total form, also make sense for an eﬀectus in partial form.
Further, if f is total, then the two forms of substitution f ✷and f ∗concide:
f ✷(q) = q ◦f = f ∗(q).
This follows from uniqueness of orthosupplements:
(q⊥◦f) > (q ◦f) = (q⊥> q) ◦f = 1 ◦f = 1.
There is another topic that we can now understand in greater generality,
namely the partial pairing ⟨⟨f, g⟩⟩.
It was introduced in Lemma 6 for maps
f, g satisfying ker⊥(f) > ker⊥(g) = 1, and produced a total map ⟨⟨f, g⟩⟩. The
bijective correspondence (28), in upwards direction, extends this pairing in two
ways, namely to n-ary pairing and to partial maps fi : Z →Xi. for which the
kernel-supplements ker⊥(fi) are only orthogonal (instead of adding up to 1).
The resulting pairing ⟨⟨f1, . . . , fn⟩⟩: Z →X1 + · · · + Xn is then only a partial
map, deﬁned as >i(κi ◦fi). It is unique in satisfying:
✄i ◦⟨⟨f1, . . . , fn⟩⟩= fi.
Thus, in an eﬀectus in partial form we have partial pairing too.
Recall that this map ⟨⟨f1, . . . , fn⟩⟩is total if >i ker⊥(fi) = 1. In that case
we are back in the situation of Lemma 6. In the sequel we use this pairing in
this more general form, as essentially given by the correspondence (28).
9
Commutative and Boolean eﬀectuses
Partial endomaps X →X play an important role in eﬀectus theory. They give
rise to predicates, by taking their kernel, but they may also be obtained from
predicates, as their associated ‘side eﬀect’. This is a topic that will return many
times in the sequel. For this reason we introduce special notation, and write
End(X) for the set of partial maps X →X, in an eﬀectus in total form. This set
End(X) is a partial commutative monoid (PCM) by Proposition 13 via >, 0, it
carries a partial order by Proposition 41 (3), and it is a (total) monoid via partial
composition
, id. We recall from Lemma 40 that the kernel-orthosupplement
ker⊥forms a PCM-homomorphism
End(X)
ker⊥
/ Pred(X)
65

It reﬂects 0 and ⊥. Explicitly, ker⊥(f) = 1
f = (! + id) ◦f.
We shall write End≤id(X) ֒→End(X) for the subset:
End≤id(X) = {f : X →X | f ≤idX},
where idX = κ1 is the partial identity X →X. We shall understand endomaps
in End≤id(X) as side-eﬀect free morphisms.
Deﬁnition 55. An eﬀectus in total form is called commutative if for each
object X both:
1. the map ker⊥: End≤id(X) →Pred(X) is an isomorphism; we shall write
the inverse as p 7→asrtp, and call it ‘assert’;
2. asrtp
asrtq = asrtq
asrtp, for each pair of predicates p, q ∈Pred(X).
For p, q ∈Pred(X) we deﬁne a new ‘product’ predicate p & q ∈Pred(X) via:
p & q = ker⊥ asrtp
asrtq

= ker⊥ asrtq
asrtp

= q & p.
An eﬀectus is called Boolean if it is commutative and satisﬁes:
asrtp
asrtp⊥= 0, for each predicate p ∈Pred(X).
We shall read the predicate p & q as ‘p andthen q’. This & is a commutative
operation in the present commutative context, but it is non-commutative in a
more general setting, see Section 15.
The conditions in this deﬁnition are given in such a way that they can easily
be re-formulated for an eﬀectus in partial form. Hence, in the sequel, we freely
speak about a commutative/Boolean eﬀectus in partial form.
Later on in Subsection 10.1 we will show that the presence of copiers makes
an eﬀectus commutative.
Example 56. We describe three examples of these subclasses of eﬀectuses.
1. The eﬀectus Sets is Boolean. For a predicate P ⊆X, the partial assert
function asrtP : X →X + 1 is given by:
asrtP (x) =
(
κ1x
if x ∈P
κ2∗
if x ̸∈P.
For convenience we often omit these coprojections κ1, κ2 in such descrip-
tions. We have asrtP ≤id since asrtP > asrtP ⊥= id, see the description
of > on partial maps in Example 14. We have:
ker⊥(asrtP ) = {x | asrtP (x) ̸= ∗} = {x | x ∈P} = P.
Next, let f : X →X + 1 satisfy f ≤id. This means f(x) ̸= ∗⇒f(x) = x.
Now we take as predicate P = {x | f(x) ̸= ∗}, so that f = asrtP . Hence
we have an isomorphism End≤id(X) ∼= Pred(X).
We further have:
 asrtP
asrtQ

(x) =
(
x
if x ∈P ∩Q
∗
otherwise
)
=
 asrtQ
asrtP

(x).
66

The product predicate P & Q is thus intersection/conjunction P ∩Q.
The eﬀectus Sets is Boolean since:
 asrtP
asrtP ⊥

(x) =
(
x
if x ∈P ∩¬P
∗
otherwise
)
= ∗= 0(x).
2. As may be expected, the eﬀectus Kℓ(D) is commutative. For a predicate
p ∈[0, 1]X we have an assert map asrtp : X →D(X + 1) given by the
convex sum:
asrtp(x) = p(x)|x⟩+ (1 −p(x))| ∗⟩.
We have asrtp ≤id since asrtp >asrtp⊥= id. Then, following the descrip-
tion of kernels in Kℓ(D) from Example 38, we get:
ker⊥(asrtp)(x) = 1 −ker(asrtp)(x) = 1 −asrtp(∗)
= 1 −(1 −p(x)) = p(x).
We check that we get an isomorphism End≤id(X) ∼= Pred(X). Let f : X →
D(X+1) satisfy f ≤id, where id(x) = 1|x⟩. Then f(x)(x′) ̸= 0 ⇒x′ = x.
Taking p(x) = f(x)(x) then yields f = asrtp.
Next, these assert maps satisfy:
 asrtp
asrtq

(x) = p(x) · q(x)|x⟩+ (1 −p(x) · q(x))| ∗⟩
=
 asrtq
asrtp

(x).
The product predicate p & q is thus the pointwise multiplication (p &
q) = p(x) · q(x).
It is instructive to see why Kℓ(D) is not a Boolean eﬀectus: It satisﬁes:
 asrtp
asrtp⊥

(x) = p(x) · (1 −p(x))|x⟩+ (1 −p(x) · (1 −p(x)))| ∗⟩.
If asrtp asrtp⊥= 0, then p(x)·(1−p(x)) = 0 for each x. But this requires
that p(x) is a Boolean predicate, with p(x) ∈{0, 1} for each x, so that p
restricts to X →{0, 1}. But of course, not every predicate in Kℓ(D) is
Boolean.
3. The eﬀectus CvNAop of commutative von Neumann algebras is commu-
tative. For an eﬀect e ∈[0, 1]A in such a commutative algebra A , we
deﬁne asrte : A →A by asrte(a) = e·a. Clearly, this is a linear subunital
map. We use commutativity to show that it is positive. For a ≥0, say
a = b · b∗we obtain a positive element:
asrte(a) = e · a = √e · √e · b · b∗= √e · b · b∗· √e = (√e · b) · (√e · b)∗.
Here we use that each positive element x has a positive square root √x
and is self-adjoint, that is, satisﬁes x = x∗.
67

Like before, we have asrte > asrte⊥= id, so that asrte ≤id. Further,
following the description in Example 38,
ker⊥(asrte) = asrte(1) = e · 1 = e.
Showing that ker⊥is an isomorphism requires more work. Let f : A →A
be a subunital positive map below the identity. This means f(a) ≤a for
all a ≥0. Deﬁne g : A ⊕A →A by g(x, y) = f(x)+y−f(y). This map is
positive, because if x, y ≥0, then f(x) ≥0 and y −f(y) ≥0, since f(y) ≤
y, and thus g(x, y) ≥0. Clearly, g is unital. More generally, g(x, x) = x,
which can be written more abstractly as g ◦∆= id, where the diagonal
∆: A →A ⊕A preserves multiplication. Hence ‘Tomiyama’ [Tom57]
applies, see [Jac15a, Lemma 38], so that z · g(x, y) = g(∆(z) · (x, y)) =
g(z · x, z · y). The element g(1, 0) = f(1) is central in A since:
x · g(1, 0) = g
 ∆(x) · (1, 0)

= g(x, 0) = g
 (1, 0) · ∆(x)

= g(1, 0) · x.
We thus obtain:
f(x) = g(x, 0) = g(1, 0) · x = f(1) · x = asrtf(1)(x) = asrtker⊥(f)(x).
Finally, we have, for arbitrary eﬀects e, d ∈[0, 1]A ,
 asrte
asrtd

(a) = e · (d · a) = d · (e · a) =
 asrtd
asrte

(a).
As a result, the product predicate e & d is given by multiplication · in the
von Neumann algebra.
The assert maps, if they exist, give rise to many interesting properties.
Lemma 57. Let B be a commutative eﬀectus in total form.
1. Each PCM End≤id(X) is an eﬀect algebra; in fact, with composition
, id
it is a commutative eﬀect monoid.
2. The assert map Pred(X) →End≤id(X) is an (iso)morphism of eﬀect
algebras, and makes Pred(X) with & also a commutative eﬀect monoid.
3. p
f = 0 iﬀasrtp
f = 0.
4. asrts = s for each scalar s: 1 →1.
5. asrt[p,q] = asrtp + asrtq : X + Y →X + Y .
6. The instrument map instrp = ⟨⟨asrtp, asrtp⊥⟩⟩: X →X + X satisﬁes ∇◦
instrp = id.
7. p & q = q
asrtp, and thus p & q ≤q and also p & q ≤p.
8.
 asrtp
✷(q) = (p & q) > p⊥.
9. The following points are equivalent, for an arbitrary predicate p.
68

(a) asrtp
asrtp = asrtp
(b) p & p = p
(c) asrtp
asrtp⊥= 0
(d) p & p⊥= 0
(e) p is sharp, that is, p ∧p⊥= 0.
The instrument map instrp : X →X+X from point (6) can be understood as
a ‘case’ expression, sending the input to the left component in X +X if p holds,
and to the right component otherwise. The property ∇◦instrp = id says that
this instrument map has no side-eﬀects. We will encounter instrument maps in
a non-commutative setting in Section 15 where they do have side-eﬀects. Such
side-eﬀects are an essential aspect of the quantum world. They don’t exist in
the current commutative setting.
Proof We handle these points one-by-one.
1. First we have to produce an orthosupplement for an arbitrary f ∈End≤id(X).
Since f ≤id, we have f > g = id for some g ∈End(X).
Clearly
g ≤id. It is unique with this property, since if f > h = id = f > g,
then ker⊥(f)>ker⊥(g) = 1 = ker⊥f >ker⊥(h). Hence ker⊥(g) = ker⊥(h)
by cancellation in the eﬀect algebra Pred(X). But then g = h since ker⊥
is an isomorphism.
We see that id = 0⊥∈End≤id(X).
If id ⊥f in End≤id(X), then
ker⊥(id) = 1 ⊥ker⊥(f). Hence ker⊥(f) = 0 in Pred(X), and thus f = 0
since ker⊥reﬂects 0.
The partial composition operation
on End≤id(X) preseves >, 0 by Propo-
sition 13 (2). Moreover, the top element id ∈End≤id(X) obviously satis-
ﬁes p
id = p = id
p. Hence End≤id(X) is an eﬀect monoid, see Deﬁni-
tion 18. We show that it is commutative. For arbitrary maps f, g : X →X
write p = ker⊥(f) and q = ker⊥(g), so that f = asrtp and g = asrtq. Then
we are done by Deﬁnition 55 (2):
f
g = asrtp
asrtq = asrtq
asrtp = g
f.
2. We have asrt1 = id, since 1 = ker⊥(id). Next, if p ⊥q in Pred(X), then
ker⊥(asrtp) = p ⊥q = ker⊥(asrtq), and thus asrtp ⊥asrtq since ker⊥
reﬂects ⊥. In that case asrtp>q = asrtp > asrtq since:
ker⊥(asrtp>q) = p > q = ker⊥(asrtp) > ker⊥(asrtq)
= ker⊥ asrtp > asrtq

.
By construction, ker⊥: End≤id(X)
∼
=
−→Pred(X) sends
to &, so that
Pred(X) becomes a commutative eﬀect monoid, and ker⊥an isomorphism
of eﬀect monoids.
3. By Lemma 7, using that 1
asrtp = ker⊥(asrtp) = p,
asrtp
f = 0 ⇐⇒1
asrtp
f = 0 ⇐⇒p
f = 0.
69

4. We obtain asrts = s for a scalar s from Lemma 39 (1):
ker⊥(asrts) = s = ker⊥(s).
5. The equation asrt[p,q] = asrtp + asrtq follows from:
ker⊥ asrtp + asrtq

= 1
[κ1
asrtp, κ2
asrtq]
= [1
κ1
asrtp, 1
κ2
asrtq]
= [1
asrtp, 1
asrtq]
since coprojections are total
= [ker⊥(asrtp), ker⊥(asrtq)]
= [p, q]
= ker⊥(asrt[p,q]).
6. For a predicate p ∈Pred(X) we have by deﬁnition: ker(asrtp) = p⊥=
ker⊥(asrtp). Hence we can use the pairing from Lemma 6 and can form
the (total) instrument map instrp = ⟨⟨asrtp, asrtp⊥⟩⟩: X →X + X. We
obtain ∇◦instrp = id from:
‹∇◦instrp› = ∇◦‹instrp›
(27)
= ∇◦
 (κ1 ◦asrtp) > (κ2 ◦asrtp⊥)

= (∇◦κ1 ◦asrtp) > (∇◦κ2 ◦asrtp⊥)
= asrtp > asrtp⊥
= ‹id›.
7. Simply: p & q = ker⊥(asrtq
asrtp) = 1
asrtq
asrtp = q
asrtp.
Since asrtp ≤id, we get p & q = q
asrtp ≤q
id = q. By commutativity
we obtain: p & q = q & p ≤p.
8. We have:
 asrtp
✷(q) =
 asrtp
✷(q⊥⊥)
=
 asrtp
✷(q⊥)⊥> ker(asrtp)
by Lemma 39 (10)
= (q
asrtp) > p⊥
= (p & q) > p⊥.
9. The equivalences (9a) ⇔(9b) and (9c) ⇔(9d) are obvious, via the iso-
morphism ker⊥. We prove (9a) ⇔(9c) and (9e) ⇔(9a).
For (9a) ⇒(9c), let predicate p satisfy asrtp
asrtp = asrtp. Then:
asrtp = asrtp
id = asrtp
(asrtp > asrtp⊥)
= (asrtp
asrtp) > (asrtp
asrtp⊥)
= asrtp > (asrtp
asrtp⊥).
Hence asrtp
asrtp⊥= 0 by Lemma 41 (2).
70

In the reverse direction, assuming asrtp
asrtp⊥= 0 we obtain:
asrtp = asrtp
id = asrtp
(asrtp > asrtp⊥)
= (asrtp
asrtp) > (asrtp
asrtp⊥)
= (asrtp
asrtp) > 0
= asrtp
asrtp.
For (9c) ⇒(9e) we assume asrtp
asrtp⊥= 0. Let q ≤p and q ≤p⊥. If
we show q = 0, then p ∧p⊥= 0. First, the inequality q ≤p gives:
q
asrtp⊥≤p
asrtp⊥= 1
asrtp
asrtp⊥= 1
0 = 0.
Hence:
q
asrtp = (q
asrtp) > (q
asrtp⊥) = q
(asrtp > asrtp⊥) = q
id = q.
But now the inequality q ≤p⊥gives the required result:
q = q
asrtp ≤p⊥
asrtp = 1
asrtp⊥
asrtp = 1
0 = 0.
Finally, for (9e) ⇒(9c) let p ∧p⊥= 0. We have p & p⊥≤p and also
p & p⊥≤p⊥by point (7). Hence 0 = p & p⊥= ker⊥(asrtp
asrtp⊥).
Since ker⊥reﬂects 0, we obtain asrtp
asrtp⊥= 0.
□
We show how Bayes’ rule can be described abstractly in the current setting.
A type-theoretic formulation of these ideas is elaborated in [AJ15].
Example 58. Let (C, I) be a commutative eﬀectus, in partial form, with nor-
malisation, as described in Remark 30.
Consider a total state ω: 1 →X
and a predicate p: X →I on the same object X.
We obtain a substate
asrtp ◦ω: 1 →X with:
1 ◦asrtp ◦ω = p ◦ω
(16)
= ω |= p.
We thus have by Lemma 7:
asrtp ◦ω = 0 ⇐⇒
 ω |= p

= 0.
Now let the validity ω |= p be non-zero. Then we can normalise the substate
asrtp ◦ω. We write the resulting total ‘conditional’ state as ω|p : 1 →X. It
satisﬁes by construction, see (19):
ω|p ◦(ω |= p) = asrtp ◦ω,
(33)
where composition ◦on the left is scalar multiplication, see Lemma 23. This
new ‘conditional’ state ω|p should be read as the update of state ω after learning
p.
We claim that we now have the following abstract version of Bayes’ rule: for
an arbitrary predicate q on X,
 ω|p |= q

·
 ω |= p

=
 ω |= p & q

.
(34)
71

In presence of division, this equation can be recast in more familiar form:
ω|p |= q = ω |= p & q
ω |= p
.
The proof of Bayes’ equation (34) is easy:
 ω|p |= q

·
 ω |= p

= q ◦ω|p ◦
 ω |= p

(33)
= q ◦asrtp ◦ω
= (p & q) ◦ω
= ω |= p & q.
This abstract description suggests how to do conditional probability in a non-
commutative setting, in presence of assert maps, see Section 15, and see also [LS13].
At this abstract level the total probability law, also known as the rule of belief
propagation [LS13] also holds: for a state ω on X, an n-test p1, . . . , pn on X,
and an arbitrary predicate q on X,
 ω |= q

= >i
 ω|pi |= q

·
 ω |= pi

.
The proof is left to the interested reader.
In the current setting we can take the commutative eﬀectus Kℓ(D) as exam-
ple. For a total state ω ∈D(X) on a set X and a (fuzzy) predicate p ∈[0, 1]X
with ω |= p = P
x ω(x) · p(x) ̸= 0 we obtain as normalised state ω|p ∈D(X),
ω|p =
X
x
ω(x) · p(x)
ω |= p
x

.
Then indeed, for q ∈[0, 1]X,
ω|p |= q = P
x ωp(x) · q(x) = P
x
ω(x) · p(x) · q(x)
ω |= p
= ω |= p & q
ω |= p
.
We brieﬂy mention the continuous probabilistic case, given by the Kleisli
category Kℓ(G) of the Giry monad G on measurable spaces. For a measurable
space X, with set ΣX of measurable subsets, let ω ∈G(X) be a probablity
distribution. Each measurable subset M ∈ΣX gives rise to predicate 1M : X →
[0, 1] with 1M(x) = 1 if x ∈M and 1M(x) = 0 otherwise. We claim that the
conditional state ω|1M ∈G(X), as described above, is the conditional probability
measure ω(−| M), if ω(M) ̸= 0.
Indeed, the subprobability measure asrt1M ◦ω: ΣX →[0, 1] is given by
A 7→
R
1M∩A dω = ω(M ∩A). Normalisation gives the conditional probability:
ω|1M(A) = ω(M ∩A)
ω(M)
= ω(A | M).
We turn to Boolean eﬀectuses and collect some basic results.
Lemma 59. Let B now be a Boolean eﬀectus, that is, a commutative eﬀectus
in which asrtp
asrtp⊥= 0 holds for each predicate p.
1. All assert maps are idempotent, that is, asrtp
asrtp = asrtp, and all
predicates p are sharp, that is, p ∧p⊥= 0.
72

2. The predicate p & q is the meet/conjunction p∧q in Pred(X). Disjunctions
then also exist via De Morgan: p ∨q = (p⊥∧q⊥)⊥.
3. p ⊥q iﬀasrtp
asrtq = 0 iﬀp ∧q = 0.
4. If p ⊥q, then p > q = p ∨q.
5. Conjunction ∧distributes over disjunction ∨, making each eﬀect algebra
Pred(X) a Boolean algebra.
Proof Most of these points are relatively easy, except the last one.
1. Directly by Lemma 57 (9).
2. We have p & p = ker⊥(asrtp
asrtp) = ker⊥(asrtp) = p.
This allows
us to show that p & q is the meet of p, q. We already have p & q ≤p
and p & q ≤q by Lemma 57 (7). Next, let r be a predicate with r ≤p
and r ≤q. Since product r & (−) preserves >, by Lemma 57 (1), it is
monotone. Hence: r = r & r ≤p & q.
3. The equivalence asrtp
asrtq = 0 iﬀp ∧q = 0 follows from the previous
point and Lemma 57 (9). So let p ⊥q, so that q ≤p⊥. Then p ∧q ≤
p ∧p⊥= 0. Conversely, if asrtp
asrtq = 0 then:
asrtp = asrtp
id = asrtp
(asrtq > asrtq⊥)
= (asrtp
asrtq) > (asrtp
asrtq⊥)
= 0 > (asrtp
asrtq⊥)
= asrtp
asrtq⊥.
Hence p = p ∧q⊥, so that p ≤q⊥, and thus p ⊥q.
4. Let p ⊥q. We intend to prove that the sum p > q, if it exists, is the join
p ∨q. In any eﬀect algebra, p > q is an upperbound of both p and q, so
we only need to prove that it is the least upperbound. Let p ≤r and
q ≤r. The inequality p ≤r says p ⊥r⊥and thus asrtr⊥
asrtp = 0 by
the previous point. Similarly q ≤r gives asrtr⊥
asrtq = 0. But then:
asrtr⊥
asrtp>q = asrtr⊥
 asrtp > asrtq

=
 asrtr⊥
asrtp

>
 asrtr⊥
asrtq

= 0 > 0 = 0.
Hence p > q ⊥r⊥, again by the previous point, and thus p > q ≤r.
5. This result can be traced back to [BF95, Thm. 3.11]. However, we give our
own proof of distributivity p ∧(q ∨r) = (p ∧q) ∨(p ∧r), for all predicates
p, q, r ∈Pred(X). We repeatedly use the equivalence
x ≤y⊥⇐⇒x ∧y = 0
(∗)
from point (3).
The inequality p ∧(q ∨r) ≥(p ∧q) ∨(p ∧r) always holds, so we need to
prove the inequality:
p ∧(q ∨r) ≤(p ∧q) ∨(p ∧r) =

(p ∧q)⊥∧(p ∧r)⊥⊥.
73

That is, by (∗) we have to prove:
p ∧(q ∨r) ∧(p ∧q)⊥∧(p ∧r)⊥= 0.
We pick an arbitrary predicate x for which:
(a) x ≤p
(b) x ≤p ∨r
(c) x ≤(p ∧q)⊥
(d) x ≤(p ∧r)⊥.
We need to prove x = 0. The inequality (a) is equivalent to x ∧p = x.
By (∗), (c) and (d) are equivalent to x ∧p ∧q = 0 and x ∧p ∧r = 0. But
then x∧q = 0 and x∧r = 0, so that x ≤q⊥and x ≤r⊥again by (∗). We
now have x ≤q⊥∧r⊥= (p∨r)⊥, which, together with (b) and point (??)
gives the required conclusion:
x ≤(p ∨r) ∧(p ∨r)⊥= 0.
□
Remark 60. The commutation requirement asrtp
asrtq = asrtq
asrtp from
Deﬁnition 55 (2) holds automatically in a Boolean eﬀectus.
More precisely,
it follows from the ‘Boolean’ requirement asrtp
asrtp⊥= 0 in Deﬁnition 55,
assuming the assert isomorphism in point (1). This works as follows.
Let p, q be arbitrary predicates on the same object. The associated assert
maps satisfy:
0 = asrtp
asrtp⊥= asrtp
id
asrtp⊥
= asrtp
 asrtq > asrtq⊥

asrtp⊥
=
 asrtp
asrtq
asrtp⊥

>
 asrtp
asrtq⊥
asrtp⊥

.
By Proposition 41 (1) we obtain:
asrtp
asrtq
asrtp⊥
(a)
= 0.
Similarly,
asrtp⊥
asrtq
asrtp
(b)
= 0.
We can now derive commutation of assert maps:
asrtp
asrtq = asrtp
asrtq
 asrtp > asrtp⊥

=
 asrtp
asrtq
asrtp

>
 asrtp
asrtq
asrtp⊥

(a)
=
 asrtp
asrtq
asrtp

> 0
(b)
=
 asrtp
asrtq
asrtp

>
 asrtp⊥
asrtq
asrtp

=
 asrtp > asrtp⊥

asrtq
asrtp
= asrtq
asrtp.
It is not known if this commutation property can be derived from the assert
isomorphism in Deﬁnition 55 (1).
The next result justiﬁes the name Boolean eﬀectuses. It uses the category
BA of Boolean algebras, which is a subcategory BA ֒→EA of the category of
eﬀect algebras.
Proposition 61. For a Boolean eﬀectus B, all predicates are sharp, and the
predicate functor restricts to Pred: B →BAop.
74

Proof For each X ∈B the collection Pred(X) contains only sharp predicates
and is a Boolean algebra, by Lemma 59 (5). We have to prove that for each
map f : Y →X in B the total substitution functor f ∗: Pred(X) →Pred(Y ) is
a map of Boolean algebras. For this it suﬃces that f ∗preserves disjunctions ∨.
First, let p, q ∈Pred(X) be disjoint, that is, p ∧q = 0. By Lemma 59 (3)
and (4), using that f ∗is a map of eﬀect algebras,
f ∗(p ∨q) = f ∗(p > q) = f ∗(p) > f ∗(q) = f ∗(p) ∨f ∗(q).
For arbitrary p, q we can always rewrite the join p ∨q in a Boolean algebra as
a disjoint join:
p ∨q = (p ∧q⊥) ∨(p ∧q) ∨(q ∧p⊥).
Since substitution f ∗preserves disjoint joins we get:
f ∗(p ∨q) = f ∗(p ∧q⊥) ∨f ∗(p ∧q) ∨f ∗(q ∧p⊥)
= f ∗(p ∧q⊥) ∨f ∗(p ∧q) ∨f ∗(p ∧q) ∨f ∗(q ∧p⊥)
= f ∗ (p ∧q⊥) ∨(p ∧q)

∨f ∗ (p ∧q) ∨(q ∧p⊥)

= f ∗(p) ∨f ∗(q).
□
Later, in Section 13, we return to Boolean eﬀectuses and describe their close
relationship to extensive categories. But we ﬁrst need the notions of compre-
hension and quotient, see Section 11 and 12.
10
Monoidal eﬀectuses
In this section we shall consider eﬀectuses with tensors ⊗. Such tensors are used
for parallel composition, which is an important part of quantum theory. For
background information on symmetric monoidal categories we refer to [Mac71].
Deﬁnition 62. An eﬀectus in total form B is called monoidal if it is a sym-
metric monoidal category such that:
1. the tensor unit is the ﬁnal object 1;
2. the tensor distributes over ﬁnite coproducts (+, 0); this means that the
following canonical maps are isomorphisms:
(X ⊗A) + (Y ⊗A)
/ (X + Y ) ⊗A
0
/ 0 ⊗A
(35)
This says that the functor (−) ⊗A preserves ﬁnite coproducts (+, 0). By
symmetry A ⊗(−) then also preserves (+, 0).
We recall the notation that is standardly used for monoidal natural isomor-
phisms, and add notation for the distributivity isomorphism (35).
1 ⊗X
λ
∼
= / X
X ⊗Y
γ
∼
= / Y ⊗Y
X ⊗(Y ⊗Z)
α
∼
= / (X ⊗Y ) ⊗Z
X ⊗I
ρ=λ◦γ/ X
(X ⊗A) + (Y ⊗A)
[κ1⊗id,κ2⊗id] .
∼=
(X + Y ) ⊗A
dis
n
75

Because the ﬁnal object 1 is the tensor unit there are projections X ←
X ⊗Y →Y deﬁned in:
X
X ⊗Y
π1
o
id⊗!
v♥♥♥♥♥♥♥♥♥
π2
/
!⊗id
(P
P
P
P
P
P
P
P
P
Y
X ⊗1
ρ
∼
=
O
1 ⊗Y
λ
∼
=
O
(36)
These projections take the marginal, see Example 64. They are natural in the
sense that πi ◦(f1 ⊗f2) = fi ◦πi. A monoidal category in which the tensor unit
is ﬁnal is sometimes called semicartesian.
We have described tensors in the ‘total’ case, for eﬀectuses. But they can
equivalently be described in the ‘partial’ case. This is the topic of the next
result.
Proposition 63. Let B be an eﬀectus in total form. Then: B is monoidal
eﬀectus if and only if
• Par(B) is symmetric monoidal, and the monoidal and distributivity iso-
morphisms (35) are total — so that ⊗distributes over (+, 0) in Par(B);
• the tensor f ⊗g of two total morphisms f, g in Par(B) is again total;
• the ﬁnal object 1 ∈B forms a tensor unit in Par(B).
When we talk about a ‘monoidal eﬀectus in partial form’ we mean an eﬀectus
in partial form that satisﬁes the properties described above for the category of
partial maps Par(B), with 1 as tensor unit. The above second point is equivalent
to: the following diagram of partial maps commutes.
X ⊗Y
✈✈✈
1⊗1
{✈✈✈
❇❇❇
1
!❇❇❇
1 ⊗1
∼
=
/ 1
Proof Given the tensor ⊗on B we obtain ⊗on Par(B) in the same way on
objects. Given partial maps h: X →A and k: Y →B in Par(B) we obtain
h ⊗k: X ⊗Y →A ⊗B in Par(B) as:
X ⊗Y
h⊗k

(A + 1) ⊗(B + 1)
∼(A ⊗B) + (A ⊗1) + (1 ⊗B) + (1 ⊗1)
[κ1,κ2◦!,κ2◦!,κ2◦!]

(A ⊗B) + 1
Then ‹f› ⊗‹g› = ‹f ⊗g›. Remaining details are left to the reader.
□
Example 64. We shall look at monoidal structure in three of our four running
examples. It is not clear if order unit groups have tensors.
1. The eﬀectus Sets has ﬁnite products (×, 1), where functors A × (−) pre-
serve ﬁnite coproducts. Obviously, the ﬁnal object is the unit for ×.
76

2. The eﬀectus Kℓ(D) for discrete probability has tensors because the distri-
bution monad D is monoidal: there are natural maps D(X) × D(Y ) →
D(X × Y ) which commute appropriately with the unit and multiplication
of the monad.
These maps send a pair (ω, ρ) ∈D(X) × D(Y ) to the
distribution in D(X × Y ) given by (x, y) 7→ω(x) · ρ(y).
The resulting tensor on Kℓ(D) is given on objects by cartesian product ×.
For morphisms f : A →D(X) and g : B →D(Y ) there is map f ⊗g in
Kℓ(D) given by the composite:
A × B
f×g / D(X) × D(Y )
/ D(X × Y )
the projection map X ⊗Y →X in Kℓ(D), is, following (36), the function
X × Y
π1
/ D(X)
with
π1(x, y) = 1|x⟩
When applied to a state ω ∈D(X × Y ) = Stat(X × Y ) we obtain the
marginal distribution Stat(π1)(ω) = (π1)∗(ω) ∈Stat(X) given by:
(π1)∗(ω) =
X
x
  P
y ω(x, y)
x

.
3. The eﬀectus vNAop of von Neumann algebras is also monoidal.
Here
it is essential that the morphisms of vNA are completely positive. The
details are quite complicated, see e.g. [Tak01] and [Cho14] for distribu-
tivity results using the ‘minimal’ tensor. The tensor unit is the algebra
C of complex numbers, which is ﬁnal in vNAop. Distribution of ⊗over
coproducts (⊕, 0) is investigated in [Cho14].
The next result is proven explicitly in [Jac15a]. Here we give a more abstract
argument, using partial maps.
Corollary 65. In a monoidal eﬀectus the eﬀect monoid of scalars Pred(1) is
commutative.
Proof It is a well-known fact that the endomaps I →I on the tensor unit
in a monoidal category form a commutative monoid under composition. This
relies on the ‘Eckmann-Hilton’ argument see e.g. [KL80].
We apply this to
the monoidal category Par(B) of a monoidal eﬀectus B. The scalars are pre-
cisely the partial maps 1 →1 on the tensor unit 1, and their multiplication is
partial/Kleisli composition, see Deﬁnition 19.
□
We need to know a bit more about the monoidal structure in categories of
partial maps.
Lemma 66. Let B be a monoidal eﬀectus in total form. Then, in Par(B),
1. f ⊗0 = 0: X ⊗Y →A ⊗B;
2. the following diagram commutes:
X1 ⊗A + X2 ⊗A
∼
=
/
P
P
P
P
P
✄i
(P
P
P
P
(X1 + X2) ⊗A
♦♦♦♦
✄i⊗id
w♦♦♦♦
Xi ⊗A
77

3. f ⊗(g1 > g2) = (f ⊗g1) > (f ⊗g2).
4. The functor ‹−›: B →Par(B) preserves projections: these projections
can be described in Par(B) as:
‹π1› =

X ⊗Y
id⊗1 / X ⊗1
ρ
∼
= / X

‹π2› =

X ⊗Y
1⊗id / 1 ⊗Y
λ
∼
= / Y

These projection maps are natural only wrt. total maps.
Proof We follow the relevant deﬁnitions.
1. We have f ⊗0 = 0 via the following diagram, using that 0 is the zero
object in Par(B).
X ⊗A
f⊗!
/
❙
❙
❙
❙
❙
!
)❙
❙
❙
❙
❙
Y ⊗0
id⊗!
/
≀
Y ⊗B
0
❦
❦
❦
❦
❦
!
5❦
❦
❦
❦
❦
2. We calculate in Par(B), for i = 1,
(✄1 ⊗id)
[κ1 ⊗id, κ2 ⊗id]
= [([id, 0] ⊗id)
(κ1 ⊗id), ([id, 0] ⊗id)
(κ2 ⊗id)]
= [id ⊗id, 0 ⊗id]
= [id, 0]
by point (1)
= ✄1.
3. Let b: Y →B + B be a bound for g1, g2 : Y →B. Then we take as new
bound:
c =

X ⊗Y
f⊗b / A ⊗(B + B)
∼
=
/ A ⊗B + A ⊗B

Then, c is a bound for f ⊗gi, since by point (2),
✄i
c = (id ⊗✄i)
(f ⊗b) = f ⊗(✄i ⊗b) = f ⊗gi.
Hence:
(f ⊗g1) > (f ⊗g2) = ∇
c = (id ⊗∇)
(f ⊗b)
= f ⊗(∇
b)
= f ⊗(g1 > g2).
4. We use that the functor ‹−›: B →Par(B) preserves the tensor, and that
1: X →1 is the unique map to the ﬁnal object in Par(B). Hence the ﬁrst
projection in Par(B) is:
ρ
(id ⊗1) = ρ
(‹id› ⊗‹!›) = (ρ ⊗id) ◦‹id ⊗!›
= κ1 ◦ρ ◦(id ⊗!)
= ‹π1›.
□
78

In Proposition 13 we have seen that homsets of partial maps X →Y in an
eﬀectus form a partial commutative monoid (PCM). In the presence of tensors
one also obtains scalar multiplication on such homsets.
Lemma 67. If B is a monoidal eﬀectus in total form, then each partial homset
Par(B)(X, Y ) is a partial commutative module; partial pre- and post-composition
preserves scalar multiplication, and thus the module structure.
Moreover, the homsets B(X, Y ) are convex sets, and the partial homsets
Par(B)(X, Y ) are subconvex sets; again this structure is preserved by pre- and
post-composition.
Proof For a partial map f : X →Y and a scalar s: 1 →1 we deﬁne s·f : X →Y
in Par(B) as:
s · f =

X
∼
= / 1 ⊗X
s⊗f
/ 1 ⊗Y
∼
= / Y

It is obviously an action, and preserves 0, > in each argument by Lemma 66.
We only show that the homset B(X, Y ) is convex. We essentially proceed
as in (the proof of) Lemma 27: for scalars r1, . . . , rn ∈Pred(1) with >i ri = 1,
the bound b: 1 →n · 1 with ✄i
b = ri and ∇
b = 1: 1 →1 is a total map of
the form b = κ1 s. For an n-tuple of total maps fi : X →X we now deﬁne the
convex sum P
i rifi to be the composite in B:
X
∼
= / 1 ⊗X
s⊗id/ (n · 1) ⊗X
∼
= / n · (1 ⊗X)
∼
= / n · X
[f1,...,fn] / Y
□
In Deﬁnition 24 we have described when substates 1 →X are pure, via
scalar multiplication for such states. With the scalar multiplication for arbitrary
partial maps we can extend the deﬁnition of purity.
Deﬁnition 68. A partial map f : X →Y in a monoidal eﬀectus is called pure
if for each pair of orthogonal partial maps f1, f2 : X →Y with f = f1 >f2 there
is a scalar s with:
f1 = s · f
and
f2 = s⊥· f.
An object X is called pure if the partial identity map id : X →X is pure, in the
above sense.
It can be shown that a von Neumann algebra A is pure if and only if it is
a factor, that is, its center is C, the algebra of compex numbers. The proof will
be given elsewhere.
Here is another notion that requires tensors. It is seen as the key property
of quantum mechanics according to [CDP11].
It will be further elaborated
elsewhere.
Deﬁnition 69. The puriﬁcation of a substate ω: 1 →X is a pure substate
ρ: 1 →X ⊗Y with π1
ρ = ω.
79

10.1
Commutative eﬀectuses via copiers
This section concentrates on special tensors ⊗which come equipped with copier
operations X →X⊗X. It is shown that in presence of such copiers — satisfying
suitable requirements — an eﬀectus is commutative. This result is the logical
contrapositive of the familiar fact that no-cloning holds in the quantum world:
if we do have cloning, we are not in the quantum, but in the probabilistic, world.
Deﬁnition 70. We say that a monoidal eﬀectus B in total form has copiers if
for each object X ∈B there is a copier, or diagonal, map δ: X →X ⊗X such
that the following diagrams commute:
X
X ⊗X
∼
=
γ

X
δ 
X
δ
X
δ /
✈
✈
✈
✈
✈
✈
✈
✈
✈
✈
✈
✈
✈
✈
✈
✈
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
X ⊗X
π1
O
π2

X
δ
;✈
✈
✈
✈
✈
✈
✈
δ
#●
●
●
●
●
●
●
X ⊗X
id⊗δ 
X ⊗X
δ⊗id

X
X ⊗X
X ⊗(X ⊗X)
α
∼
= / (X ⊗X) ⊗X
and additionally, for each partial map f : X →X which is side-eﬀect-free, that
is satisﬁes f ≤id, one has in Par(B):
(f ⊗id)
‹δ› = ‹δ›
f = (id ⊗f)
‹δ›.
(37)
(The two equations are equivalent.)
We now deﬁne an assert map in terms of copying. It’s easiest to do this in
partial form. For a predicate p: X →1 write asrtp for the composite:
asrtp =

X
‹δ› / X ⊗X
p⊗id/ 1 ⊗X
λ
∼
= / X

(38)
Theorem 71. A monoidal eﬀectus with copiers is commutative.
Proof Let B be a monoidal eﬀectus in total form, with copiers. We reason in
Par(B). We ﬁrst show that the map asrtp : X →X from (38) is side-eﬀect-free,
i.e. that it is below the (partial) identity X →X. This follows from:
asrtp > asrtp⊥
=
 λ
(p ⊗id)
‹δ›

>
 λ
(p⊥⊗id)
‹δ›

= λ
 (p ⊗id) > (p⊥⊗id)

‹δ›
by Proposition 13 (2)
= λ
 (p > p⊥) ⊗id

‹δ›
by Lemma 66 (3)
= λ
 1 ⊗id

‹δ›
= ‹π2›
‹δ›
by Lemma 66 (4)
= id.
Next we show that the mapping p 7→asrtp makes the map ker⊥: End≤id(X) →
80

Pred(X) bijective, see Deﬁnition 55 (1).
ker⊥(asrtp) = 1
λ
(p ⊗id)
‹δ›
= λ
(id ⊗1)
(p ⊗id)
‹δ›
= ρ
(p ⊗id)
(id ⊗1)
‹δ›
since λ = ρ: 1 ⊗1 →1
= p
ρ
(id ⊗1)
‹δ›
= p
‹π1›
‹δ›
by Lemma 66 (4)
= p.
In the other direction, let f : X →X satisfy f ≤id. The associated predicate
ker⊥(f) = 1
f : X →1 satisﬁes:
asrtker⊥(f) = λ
(1 ⊗id)
(f ⊗id)
‹δ›
= ‹π1›
‹δ›
f
by (37) and Lemma 66 (4)
= f.
Finally we have to prove that the assert maps commute: asrtp
asrtq =
asrtq
asrtp. Since the kernel-supplement map ker⊥is bijective it suﬃces to
prove the middle equation in:
ker⊥ asrtq
asrtp

= p & q = q & p = ker⊥ asrtp
asrtq

.
Hence we are done by:
p & q = q
asrtp
by Lemma 57 (7)
= q
λ
(p ⊗id)
‹δ›
= λ
(id ⊗q)
(p ⊗id)
‹δ›
= λ
γ
(p ⊗q)
‹δ›
since λ = ρ = λ
γ : 1 ⊗1 →1
= λ
(q ⊗p)
γ
‹δ›
= p
λ
(q ⊗id)
‹δ›
= q & p.
□
We conclude by describing copiers in two of our examples.
Examples 72. In the commutative eﬀectus Kℓ(D) one has copiers δ: X →
X ⊗X given by:
δ(x) = 1|(x, x)⟩.
These copiers are not natural in X. But we do not need naturality for the
above theorem. We do need to check equation (37). So let f : X →D≤1(X)
be side-eﬀect-free map. Then f is of the form f(x) = p(x)|x⟩, for a predicate
p ∈[0, 1]X, see Example (56) (2). But then:
 (f ⊗id) ◦δ

(x) = p(x)|(x, x)⟩=
 δ ◦f

(x).
In the commutative eﬀectus CvNAop of commutative von Neumann alge-
bras copiers δ: A ⊗A →A are given by multiplication:
δ(a ⊗b) = a · b.
81

This map is positive since the multiplication of two positive elements is positive
again in a commutative von Neumann algebra.
If f : A →A is a subunital map below the identity, then f(x) = f(1) · x,
see Example 56 (3). Hence the equation 37 holds:
 δ ◦(f ⊗id)

(a ⊗b) = δ
 f(a) ⊗b

= (f(1) · a) · b
= f(1) · (a · b) =
 f ◦δ

(a ⊗b).
11
Comprehension
Comprehension is the operation that assigns to a predicate p on a type/object
X a new type/object {X|p} which intuitively contains those elements of X
that satisfy p. This comprehension type comes equipped with an inclusion map
πp : {X|p} →X which we call a comprehension map.
In categorical logic comprehension is described nicely via an adjunction, see
e.g. [Jac99], like any logical operation that comes equipped with an introduc-
tion and elimination rule.
The slogan is: comprehension is right adjoint to
truth. Later in Section 12 we shall see a similar situation for quotients, namely:
quotients are left adjoint to falsity.
This truth functor exists as functor that maps an object X to the truth/top
element 1(X) in the set Pred(X) of predicates on X. Our ﬁrst task is to combine
these set Pred(X) into a single category Pred(B) of predicates in an eﬀectus B.
In the partial case there is a slightly diﬀerent category of predicates.
Deﬁnition 73. Let B be an eﬀectus in total form. We write Pred(B) for the
category with:
• objects are pairs (X, p) where p ∈Pred(X) is a predicate p: X →1 + 1 on
X; often we simply talk about objects p in Pred(B) when the carrier X is
clear from the context;
• morphisms f : (X, p) →(Y, q) in Pred(B) are maps f : X →Y in B with
an inequality:
p ≤f ∗(q).
We recall that f ∗(q) = q ◦f is total substitution, which is a map of eﬀect
modules by Theorem 21.
We obtain a category Pred(B) by Exercise 1 (1).
It comes equipped with a
forgetful functor Pred(B) →B which is so trivial that we don’t bother to give it
a name.
There are truth and falsity functors 1, 0: B →Pred(B) given by the truth/top
element 1(X) ∈Pred(X) and the falsity/bottom 0(X) ∈Pred(X) respectively.
These functors form left and right adjoints to the forgetful functor in:
Pred(B)
⊣
⊣

B
0
>
1
`
(39)
82

The forgetful functor Pred(B) →B is an example of a ‘ﬁbration’, or ‘indexed
category’, which is a basic structure in categorical logic and type theory [Jac99].
Here however we use this functor concretely, without going into the general
theory.
The adjunction 0 ⊣forget ⊣1 in (39) exists because there are obvious
bijective correspondences:
X
f
/ Y
in B
===============
(X, p)
f
/ (Y, 1) = 1(Y )
in Pred(B)
And:
X
f
/ Y
in B
======================
0(Y ) = (X, 0)
f
/ (Y, q)
in Pred(B)
These trivial correspondences exist because one always has p ≤f ∗(1) = 1 and
0 ≤f ∗(q).
There is a similar, but slightly diﬀerent, way to combine predicates in a
category in the partial case.
Deﬁnition 74. Let (C, I) be an eﬀectus in partial form. We write Pred✷(C)
for the category with:
• objects (X, p), where p: X →I is a predicate on X;
• morphisms f : (X, p) →(Y, q) are maps f : X →Y in C satisfying:
p ≤f ✷(q)
where f ✷(q) = (q⊥◦f)⊥is partial substitution, which is monotone and
preserves truth by Lemma 36. This yields a category by Exercise 1 (2).
Like in the total case we have falsity and truth functors as left and right adjoints
to the forgetful functor.
Pred✷(C)
⊣
⊣

C
0
>
1
`
(40)
The adjoint correspondences in (40) work just like in the total case. They
use that partial substution f ✷preserves truth.
The above deﬁnition for an eﬀectus in partial form applies in particular to
the category Par(B) of partial maps of an eﬀectus B. This is the topic of the
next result.
Lemma 75. Let B be an eﬀectus in total form, with its inclusion functor
‹−›: B →Par(B).
Then we have a diagram in which everything from left
to right commutes:
Pred(B)
⊣
⊣

/ Pred✷(Par(B))
⊣
⊣

B
0
>
1
`
‹−›
/ Par(B)
0
>
1
`
83

Proof The functor ‹−›: B →Par(B) lifts to Pred(B) →Pred✷(Par(B)) since
a map f : (X, p) →(Y, q) in Pred(B) yields a map ‹f›: (X, p) →(Y, q). The
reason is Exercise 1 (3), giving: p ≤f ∗(q) = ‹f›✷(q).
□
We now come to the deﬁnition of comprehension, as right adjoint to truth.
We ﬁrst give seperate formulations for the total and partial case, but we prove
that they are equivalent later on — see Theorem 78. Comprehension will be
a functor from predicates to their underlying objects.
We shall write it as
(X, p) 7→{X|p}. When we consider it as a functor we write {−|−}.
Deﬁnition 76. We give separate formulations of essentially the same notion.
1. An eﬀectus in total form B has comprehension when its truth functor
1: B →Pred(B) has a right adjoint {−|−} such that for each predicate
p: X →1 + 1 and object Y ∈B the canonical map
{X|p} + Y
/ {X + Y | [p, 1]}
(41)
is an isomorphism.
2. An eﬀectus in partial form (C, I) has comprehension if its truth functor
1: C →Pred✷(C) has a right adjoint {−|−} and each counit component
{X|p} →X in C is a total map.
Formally this counit is a map in Pred✷(C) of the form πp : (1, {X|p}) →
(X, p), but in the deﬁnition we have written it as a map in B, for simplicity.
These comprehension maps πp should not be confused with the tensor projec-
tions πi in (36).
Example 77. We describe comprehension for our four running examples. We
shall alternate between the total and partial descriptions. This comprehension
structure occurs already in [CJWW15], except for order unit groups.
1. Recall that predicates on an object/set X in the eﬀectus Sets correspond
to subsets of X. The category Pred(Sets) has such subsets (P ⊆X) as
objects; morphisms f : (P ⊆X) →(Q ⊆Y ) are functions f : X →Y
satisfying P ⊆f −1(Q), that is: x ∈P ⇒f(x) ∈Q.
The comprehension functor Pred(Sets) →Sets is given by (Q ⊆Y ) 7→Q.
The adjoint correspondences for 1 ⊣{−|−} amount to:
1(X) = (X ⊆X)
f
/ (Q ⊆Y )
====================
X
g
/ Q = {Y |Q}
Obviously, if X ⊆f −1(Q), then f(x) ∈Q for each x ∈X, so that f
restricts to a unique map f : X →Q = {Y |Q} with πQ ◦f = f, where
πQ : {Y |Q} ֒→Y is the inclusion.
For a predicate P ⊆X the predicate [P, 1] ⊆X + Y used in (41) is given
by [P, 1] = {κ1x | x ∈P} ∪{κ2y | y ∈Y }. Hence it is immediate that we
have: {X|P} + Y = P + Y = [P, 1] = {X + Y | [P, 1]}.
84

2. For discrete probability we use the eﬀectus in partial form Kℓ(D≤1) ∼=
Par(Kℓ(D)).
The category Pred✷(Kℓ(D≤1)) has fuzzy predicates p ∈
[0, 1]X as objects.
A morphism f : (p ∈[0, 1]X) →(q ∈[0, 1]Y ) is a
function f : X →D≤1(Y ) satisfying, for each x ∈X,
p(x) ≤f ✷(q)(x)
(22)
= P
y f(x)(y) · q(y) + 1 −P
y f(x)(y).
Comprehension sends a predicate q ∈[0, 1]Y to the set {Y |q} = {y ∈
Y | q(y) = 1} of elements where the predicate q holds with certainty.
Let’s check the correspondences:
(1 ∈[0, 1]X)
f
/ (q ∈[0, 1]Y )
in Pred✷(Kℓ(D≤1))
=========================
X
g
/ {y ∈Y | q(y) = 1}
in Kℓ(D≤1)
Let f : X →D≤1(Y ) satisfy 1 ≤P
y f(x)(y) · q(y) + 1 −P
y f(x)(y) for
each x ∈X. Hence P
y f(x)(y) ≤P
y f(x)(y)·q(y). This can only happen
if f(x)(y) > 0 implies q(y) = 1, for each x. But this means that we can
write each f(x) ∈D≤1(Y ) as subconvex sum f(x) = P
y f(x)(y)|y⟩with
q(y) = 1, and thus y ∈{Y |q}. Hence we have f(x) ∈D≤1({Y |q}), so that
f restricts to a unique function f : X →D≤1({Y |q}) with πQ ◦f = f,
where the comprehension map πQ : {Y |q} →D≤1(Y ) is given by πQ(y) =
1|y⟩. Clearly, it is total.
3. The eﬀectus OUSop of order unit groups also has comprehension. The
description is rather confusing because we work in the opposite category.
It turns out that in this model comprehension is given by a quotient! We
follow the relevant description meticulously, in the total case.
The category Pred(OUGop) of predicates has eﬀects e ∈[0, 1]G in order
unit groups G as objects. A morphism f : (e ∈[0, 1]G) →(d ∈[0, 1]H)
is a map f : G →H in OUGop with e ≤f ∗(d). This means that f is a
homomorphism of order unit groups f : H →G with e ≤f(d) in G.
For an eﬀect d ∈H we write ⟨d⟩H ⊆H for the subset given by:
⟨d⟩H = {x ∈H | ∃n ∈N. −n · d ≤x ≤n · d}.
(42)
It is not hard to see that ⟨d⟩H is a subgroup of H. It is an ideal, since it
satisﬁes: −x ≤y ≤x and x ∈⟨d⟩G implies y ∈⟨d⟩H. In fact, ⟨d⟩H is the
smallest ideal containing d. It inherits the order from H and is an order
unit group itself, with d ∈⟨d⟩H as unit.
We now deﬁne comprehension as quotient group:
{H|d} = H/⟨d⊥⟩H
with
(
H
πd
/ {H|d}
x ✤
/ x + ⟨d⊥⟩H
First we have to check that {H|d} is an order unit group. It is easy to
see that the quotient of an ordered Abelian group with an ideal is again
an ordered Abelian group, so we concentrate on checking that {H|d} has
85

an order unit.
We claim that πd(1) = 1 + ⟨d⊥⟩H is the order unit in
H/⟨d⊥⟩H = {H|d}. Indeed, for an arbitrary x ∈H there is an n ∈N with
−n · 1 ≤x ≤n · 1. But then:
−n · πd(1) = −n · 1 + ⟨d⊥⟩H ≤x + ⟨d⊥⟩H ≤n · 1 + ⟨d⊥⟩H = n · πd(1).
The claimed comprehension adjunction involves a bijective correspondence
between:
1(G) = (1 ∈[0, 1]G)
f
/ (H, d)
in Pred
 OUGop
====================
G
g
/ {H|d}
in OUGop
That is, between maps in OUG:
H
f
/ G with f(d) = 1
=====================
{H|d}
g
/ G
This works as follows.
• Let f : H →G in OUG satisfy f(d) = 1. Then for each x ∈⟨d⊥⟩H
we have f(x) = 0. Indeed, if −n · d⊥≤x ≤n · d⊥, then, because
f(d⊥) = f(1 −d) = f(1) −f(d) = 1 −1 = 0, we get:
0 = −n · f(d⊥) = f(−n · d⊥) ≤f(x) ≤f(n · d⊥) = n · f(d⊥) = 0.
Thus there is a unique group homomorphism f : {H|d} = H/⟨d⊥⟩H →
G by f(x+ ⟨d⊥⟩H) = f(x). This map f is clearly monotone and uni-
tal.
• The other direction is easy: given g : {H|d} →G, take g = g ◦
πd : H →G. Then:
g(d) = g
 πd(d)

= g
 d + ⟨d⊥⟩H

= g
 d + d⊥+ ⟨d⊥⟩H

= g
 1 + ⟨d⊥⟩H

= g
 1{H|d}

= 1.
Clearly, f = f ◦πd = f.
And g = g holds by uniqueness, since g(x) =
g(πd(x)) = g(x + ⟨d⊥⟩H).
Finally, for e ∈[0, 1]G the canonical map {G ⊕H|(e, 1)} →{G|e} ⊕H is
the function:
(G ⊕H)/⟨(e, 1)⊥⟩
/ G/⟨e⊥⟩⊕H
(x, y) + ⟨(e, 1)⊥⟩✤
/ (x + ⟨e⊥⟩, y).
The equivalence relation on G ⊕H induced by the ideal ⟨(e, 1)⊥⟩=
⟨(e⊥, 0)⟩is given by (x, y) ∼(x′, y′) iﬀ(x−x′, y−y′) ∈⟨(e⊥, 0)⟩. The latter
means that there is an n ∈N with −n·(e⊥, 0) ≤(x−x′, y−y′) ≤n·(e⊥, 0).
This is equivalent to: −n · e⊥≤x −x′ ≤n · e⊥and y = y′. The above
function is thus well-deﬁned, and clearly an isomorphism, with inverse
(x + ⟨e⊥⟩, y) 7→(x, y) + ⟨(e, 1)⊥⟩.
86

4. The eﬀectus in partial form Par(vNAop) of von Neumann algebras and
subunital maps also has comprehension. The relevant category of predi-
cates Pred✷(Par(vNAop)) has eﬀects e ∈[0, 1]A in a von Neumann alge-
bra A as objects. Morphisms f : (e ∈[0, 1]A ) →(d ∈[0, 1]B) are subunital
completely positive normal maps f : B →A with e ≤f(d) in A .
Recall the sharp predicates on a von Neumann algebra are precisely the
projections. For an eﬀect d ∈[0, 1]B we write ⌊d⌋∈[0, 1]B for the greatest
sharp element s ∈B with s ≤d. The deﬁnition ⌈d⌉= ⌊d⊥⌋⊥then yields
the least sharp element above d.
The projection ⌈d⌉is known as the support projection of d. In other texts
it is often denoted as r(d), as it is as an the projection onto the closed
range of d. Before we construct the comprehension in vNAop, we list a
few properties of ⌈d⌉, which will be useful later on.
(a) The ascending sequence d ≤d
1/2 ≤d
1/4 ≤· · · has supremum ⌈d⌉.
This can be shown using the spectral theorem.
It follows ⌈d⌉=
⌈
√
d⌉= ⌈d2⌉.
(b) We have d = ⌈d⌉· d = d · ⌈d⌉. In fact, ⌈d⌉is the least projection with
this property. This is a consequence of Lemma 99. In combination
with the previous point we obtain, for instance:
√
d·⌈d⌉=
√
d·⌈
√
d⌉=
√
d = ⌈d⌉·
√
d.
Now we can deﬁne comprehension as:
{B|d} = ⌊d⌋B⌊d⌋= {⌊d⌋· x · ⌊d⌋| x ∈B}.
This subset {B|d} is itself a von Neumann algebra, with ⌊d⌋as unit. The
associated comprehension map is the map πd : B →{B|d} in vNA given
by πd(x) = ⌊d⌋· x · ⌊d⌋.
We must show that given a von Neumann algebra A and a subunital
map f : B →A with f(d) = f(1) there is a unique subunital map
g : ⌊d⌋B⌊d⌋→B with g(⌊d⌋· x · ⌊d⌋) = f(x). Put g(x) = f(x); the diﬃ-
culty it to show that f(⌊d⌋· x · ⌊d⌋) = f(d). For the details, see [WW15].
We sketch the proof here. By a variant of Cauchy-Schwarz inequality for
the completely positive map f (see [Pau02, Exc. 3.4]) we can reduce this
problem to proving that f(⌊d⌋) = f(1), that is, f(⌈d⊥⌉) = 0. Since ⌈d⊥⌉is
the supremum of d⊥≤(d⊥)
1/2 ≤(d⊥)
1/4 ≤· · · and f is normal, f(⌈d⊥⌉) is
the supremum of f(d⊥) ≤f((d⊥)
1/2) ≤f((d⊥)
1/4) ≤· · · , all of which turn
out to be zero by Cauchy-Schwarz since f(d) = f(1). Thus f(⌈d⊥⌉) = 0,
and we are done.
We note that with the same argument, one shows that for any 2-positive
normal subunital map h: A →B, we have, for all eﬀects a ∈[0, 1]A ,
h(a) = 0 ⇐⇒h(⌈a⌉) = 0.
(43)
We come to the promised result that relates comprehension in the total and
in the partial case.
87

Theorem 78. An eﬀectus in total form B has comprehension iﬀits eﬀectus in
partial form Par(B) has comprehension.
In both cases the comprehension maps πp : {X|p} →X are monic — in B
and in Par(B) respectively.
Proof Since the left adjoint truth functors 1: B →Pred(B) and 1: Par(B) →
Pred✷(Par(B)) are faithful in both cases, the counits of the adjunctions are
monic by a general categorical result — see e.g. (the dual of) [Mac71, IV.3 Thm.1].
These counits are monic maps ({X|p}, 1) →(X, p) in the categories Pred(B)
and Pred✷(Par(B)) respectively. It is easy to see, using the truth functor 1,
that the underlying maps are then monic in B and Par(B).
First, let 1: B →Pred(B) have a right adjoint {−|−}. The counit is a map
πp : ({X|p}, 1) →(X, p) in Pred(B) satisﬁes 1 ≤π∗
p(p) = p ◦πp by deﬁnition.
The underlying map πp : {X|p} →X is monic in B, as just noted.
We ﬁrst investigate the canonical map (41), call it σ, is the unique one in:
{X|p} + Y
σp
/
πp+id
&▲
▲
▲
▲
▲
▲
▲
{X + Y | [p, 1]}
w
π[p,1]
w♦♦♦♦♦♦♦♦
X + A
(44)
This map σ exists by comprehension because:
(πp + id)∗([p, 1]) = [p, κ1 ◦!] ◦(πp + id)
= [p ◦πp, κ1 ◦!] = [κ1 ◦!, κ1 ◦!] = κ1 ◦[!, !] = κ1 ◦! = 1.
By assumption, this σ is an isomorphism, for each predicate p and object Y .
We now show that the truth functor 1: B →Pred✷(Par(B)) has a right
adjoint, on an object (X, p) given by {X|p}. There is total map ‹πp› = κ1 ◦
π1 : {X|p} →X in Par(B), which satisﬁes by Exercise 1 (3):
‹πp›✷(p) =
 πp
∗(p) = p ◦πp = 1.
Let f : Y →X be an arbitrary partial map satisfying 1 ≤f ✷(p) = [p, κ1] ◦
f = [p, 1] ◦f = f ∗([p, 1]). Then there is a unique total map f : Y →{X +
1 | [p, 1]} with π[p,1] ◦f = f. We now take bf = σ−1 ◦f : Y →{X|p} + 1, using
the isomorphism from (44) with Y = 1. Then:
‹πp›
bf = (πp + id) ◦σ−1 ◦f
(44)
= π[p,1] ◦f = f.
If g : Y →{X|p} also satisﬁes ‹π1›
g = f, then σ ◦g : Y →{X + 1 | [p, 1]}
satisﬁes π[p,1] ◦σp ◦g = (πp + id) ◦g = ‹πp›
g = f. Hence σ ◦g = f, and thus
g = σ−1 ◦f = bf.
In the other direction, we show how comprehension in the partial case yields
comprehension in the total case with the distributivity isomorphism (41). There-
fore, assume that a right adjoint {−|−} to 1: B →Pred✷(Par(B)) exists so that
each counit map {X|p} →X is total. We shall write this counit as ‹πp›, for
πp : {X|p} →X in B. As noted in the very beginning of this proof, the map
‹πp› is monic in Par(B). Further, we have:
p ◦πp =
 πp
∗(p) = ‹πp›✷(p) = 1.
88

The last equation holds because the counit is a map ‹πp›: ({X|p}, 1) →(X, p)
in Pred✷(Par(B)).
We now show that there is also a right adjoint to the truth functor 1: B →
Pred(B), on objects given by (X, p) 7→{X|p}.
Let f : Y →X be a total map satisfying f ∗(p) = 1. Then ‹f› = κ1 ◦f : Y →
X in Par(B) satisﬁes ‹f›✷(p) = f ∗(p) = 1. Hence there is a unique partial map
f : Y →{X|p} with ‹πp›
f = ‹f›. The latter means that the outer diagram
below commutes in the eﬀectus B.
Y
f
&
f
"
b
f
$
{X|p}
πp
/

κ1

❴✤
X
κ1

{X|p} + 1 πp+id/ X + 1
The rectangle in the middle is a pullback by (9). This mediating map bf is what
we need, since it satisﬁes πp◦bf = f by construction. Moreover, if g : Y →{X|p}
in B also satisﬁes πp ◦g = f, then ‹g› = κ1 ◦g : Y →{X|p} in Par(B)
satisﬁes ‹πp›
‹g› = ‹πp ◦g› = ‹f›. Hence ‹g› = f by uniqueness. But then
κ1 ◦g = ‹g› = f = κ1 ◦bf, and so g = bf since κ1 is monic. Thus we have shown
that the truth functor 1: B →Pred(B) has a right adjoint.
We still have to prove that the canonical map σ: {X|p}+Y →{X+Y | [p, 1]}
from (44) is an isomorphism. The inverse σ−1 for σ is obtained via the following
pullback (1) from the deﬁnition of eﬀectus:
{X + Y | [p, 1]}
(!+id)◦π[p,1]
&
f
'
σ−1
(
{X|p} + Y
!+id
/
id+!

❴✤
1 + Y
id+!

{X|p} + 1
!+id / 1 + 1
The auxiliary map f in this diagram is the unique one with ‹πp› f = (id + !) ◦
π[p,1] : {X + Y | [p, 1]} →X + 1. It exists since:
 (id + !) ◦π[p,1]
✷(p) = [p, 1] ◦(id + !) ◦π[p,1]
= [p, 1] ◦π[p,1]
= π∗
[p,1]([p, 1])
= 1.
We get (πp + id)◦σ−1 = π[p,1] : {X + Y | [p, 1]} →X + Y via a similar pullback,
89

with X + Y in the upper left corner, since:
(! + id) ◦(πp + id) ◦σ−1 = (! + id) ◦σ−1
= (! + id) ◦π[p,1]
(id + !) ◦(πp + id) ◦σ−1 = (πp + id) ◦(id + !) ◦σ−1
= (πp + id) ◦f
= (id + !) ◦π[p,1].
From this we can conclude σ ◦σ−1 = id, using that π[p,1] is monic in B, and:
π[p,1] ◦σ ◦σ−1 = (πp + id) ◦σ−1 = π[p,1].
We obtain σ−1 ◦σ = id via uniqueness of mediating maps in the above pullback
deﬁning σ−1:
(! + id) ◦σ−1 ◦σ = (! + id) ◦π[p,1] ◦σ
= (! + id) ◦(πp + id)
= (! + id)
(id + !) ◦σ−1 ◦σ = f ◦σ
(∗)
= (id + !).
The latter, marked equation uses that the map ‹πp› is monic in Par(B):
‹πp›
(f ◦σ) = (πp + id) ◦f ◦σ
= (id + !) ◦π[p,1] ◦σ
= (id + !) ◦(πp + id)
= ‹πp›
(id + !).
□
In the remainder of this section we list several properties of comprehension.
Some of these properties are more naturally formulated in the total case, and
some in the partial case. Therefore we split these results up in two parts.
Lemma 79. Let B be an eﬀectus with comprehension, in total form.
1. A (comprehension) projection map πp : {X|p} ֌ X can be characterised
either as the equaliser in B:
{X|p} / πp
/ X
p
%
1=κ1◦!
9 1+1
or as pullback:
{X|p}

πp

!
/
❴✤
1
κ1

X
p
/ 1 + 1
2. One has p⊥◦πp = 0, and moreover the diagrams below are, respectively,
an equaliser and a pullback in B.
{X|p⊥} /
πp⊥/ X
p
%
0=κ2◦!
9 1+1
{X|p⊥}

πp⊥

!
/
❴✤
1
κ2

X
p
/ 1 + 1
90

3. A projection πp : {X|p} ֌ X is an isomorphism if and only if p = 1.
4. The comprehension {X|0} is initial in B.
5. Projection maps are closed under pullback in B: for each predicate p on
X and map f : Y →X we have a pullback in B:
{Y |f ∗(p)}
/

πf∗(p)

❴✤
{X|p}

πp

Y
f
/ X
(45)
6. The pullback of a coprojection along an arbitrary map exists in B, and is
given as in:
{X|p}
/

πp 
❴✤
Y
κ1

X
f
/ Y + Z
where
p = (! + !) ◦f : X →1 + 1
In particular, the coprojection Y ֌ Y + Z is itself (isomorphic to) a
comprehension map, namely to Y ∼= {Y + Z | [1, 0]} ֌ Y + Z.
7. Projections of orthogonal predicates are disjoint: if p ⊥q, then the diagram
below is a pullback.
0 ❴✤

/ {X|p}

πp

{X|q} /
πq
/ X
8. For predicates p on X and q on Y the sum map πp+πq : {X|p}+{Y |q} →
X + Y is monic in B.
9. For predicates p on X and q on Y there is a (canonical) isomorphism as
on the left below. Using point (1), this implies that the square on the right
is a pullback.
{X|p} + {Y |q} ∼
 
πp+πq
 ❆
❆
❆
❆
❆
❆
❆
{X + Y | [p, q]}
~
π[p,q]
~⑥⑥⑥⑥⑥⑥⑥
X + Y
{X|p} + {Y |q}

πp+πq

/
❴✤
1
κ1

X + Y
[p,q]
/ 1 + 1
Proof We use the formulation of comprehension for eﬀectuses in Deﬁnition 76 (1).
1. This is just a reformulation of the universal property of comprehension.
2. We have p⊥◦πp = [κ2, κ1]◦p◦πp = [κ2, κ1]◦κ1◦! = κ2◦! = 0. If f : Y →X
satisﬁes p◦f = 0, then p⊥◦f = [κ2, κ1]◦p◦f = [κ2, κ1]◦κ2◦! = κ1◦! = 1.
Hence f factors through {X|p⊥} making the diagrams in point (2) an
equaliser and a pullback.
91

3. We ﬁrst show that π1 : {X|1} ֌ X is an isomorphism. The identity map
id : X →X trivially satisﬁes 1 = id∗(1). Hence there is a unique map
f : X →{X|1} with π1 ◦f = id. The equation f ◦π1 = id follows because
the projections are monic: π1 ◦(f ◦π1) = π1 = π1 ◦id.
Conversely, if πp : {X|p} ֌ X is an isomorphism, then, using the pullback
in point (1) we obtain p = 1 by writing:
p =

X
π−1
p
∼
=
/ {X|p}
!
/ 1 / κ1
/ 1 + 1

=

X
1
/ 1 + 1

4. The projection π0 : {X|0} ֌ X gives rise to an equality of predicates
1 = 0: {X|0} →1 + 1 via:
1 = π∗
0(0) = 0 ◦π0 = 0.
Hence we have a situation:
{X|0}
!
"
!
"
" 0

/
/
❴✤
1
κ1

1 /
κ2
/ 1 + 1
Proposition 4 says that the rectangle is a pullback, and that 0 is strict.
This means that the map {X|0} →0 is an isomorphism.
5. The dashed arrow in diagram (45) exists since:
(f ◦πf ∗(p))∗(p) = p ◦f ◦πf ∗(p) = f ∗(p) ◦πf ∗(p) = 1.
The square (45) is a pullback, since if g : Z →Y and h: Z →{X|p}
satisfy f ◦g = πp ◦h, then g factors through πf ∗(p) since:
g∗ f ∗(p)

= p ◦f ◦g = p ◦πp ◦h = 1 ◦h = 1.
6. First we have to check that the rectangle in point (6) commutes. It arrises
in a situation:
{X|p}
/

πp 
Y
κ1

!
/
❴✤
1
κ1 
X
f
/
p
5
Y + Z
!+! / 1 + 1
The outer rectangle is a pullback by point (1). Hence the rectangle on the
left is a pullback, by the Pullback Lemma.
92

7. We use that diagram (45) is a pullback, with f = πq.
It yields that
{{X|q}|π∗
q(p)} forms a pullback. But since p ⊥q, and so p ≤q⊥, we have
π∗
q(p) ≤π∗
q(q⊥) = 0. This gives {{X|q}|π∗
q(p)} ∼= 0 by point (4). Hence
the rectangle in point (7) is a pullback.
8. Let f, g : Y →{X|p}+{X|q} satisfy (πp +πq)◦f = (πp +πq)◦g. We must
show that f = g. The next diagram is a pullback in B, see Deﬁnition 2.
{X|p} + {X|q}
❴✤
!+id /
id+!

1 + {X|q}
id+!

{X|p} + 1
!+id
/ 1 + 1
Hence we are done if we can prove f1 = g1 and f2 = g2 where:
(
f1 = (id + !) ◦f
g1 = (id + !) ◦g
(
f2 = (! + id) ◦f
g2 = (! + id) ◦g
We recall from Theorem 78 that the projection maps ‹πq› = κ1 ◦πq are
monic in Par(B). We then get:
‹πp›
f1 = (πp + id) ◦(id + !) ◦f
= (id + !) ◦(πp + πq) ◦f
= (id + !) ◦(πp + πq) ◦g
= (πp + id) ◦(id + !) ◦g
= ‹πp›
g1.
Similarly one gets f2 = g2.
9. For the isomorphism {X|p} + {Y |q} ∼= {X + Y | [p, q]} we deﬁne total
maps in both directions. First, consider the map κ1◦πp : {X|p} →X +Y ,
satisfying:
 κ1 ◦πp
∗([p, q]) = [p, q] ◦κ1 ◦πp = p ◦πp = 1.
This yields a unique map ϕ1 : {X|p} →{X + Y | [p, q]} with π[p,q] ◦ϕ1 =
κ1 ◦πp. In a similar way we get ϕ2 : {Y |q} →{X + Y | [p, q]} with π[p,q] ◦
ϕ2 = κ2 ◦πq. The cotuple ϕ = [ϕ1, ϕ2]: {X|p} + {Y |q} →{X + Y | [p, q]}
gives a map in one direction. It satisﬁes, by construction:
π[p,q] ◦ϕ = [π[p,q] ◦ϕ1, π[p,q] ◦ϕ2] = [κ1 ◦πp, κ2 ◦πq] = πp + πq.
For the other direction we consider the map ✄1 ◦π[p,q] : {X + Y | [p, q]} →
X + 1. It satisﬁes:
 ✄1 ◦π[p,q]
✷(p) = [p, κ1] ◦(id + !) ◦π[p,q] = [p, 1] ◦π[p,q]
= π∗
[p,q]([p, 1])
≥π∗
[p,q]([p, q])
= 1.
93

Hence by (the partial version of) comprehension there is a uniqe map
ψ1 : {X + Y | [p, q]} →{X|p} + 1 with (πp + id) ◦ψ1 = ✄1 ◦π[p,q]. In
a similar way there is a unique ψ2 : {X + Y | [p, q]} →{Y |q} + 1 with
(πq + id) ◦ψ2 = ✄2 ◦π[p,q]. We then obtain the map ψ = ⟨⟨ψ1, ψ2⟩⟩: {X +
Y | [p, q]} →{X|p} + {Y |q}, like in Lemma 6. This pairing exists since:
ker(ψ1) = [κ2, κ1] ◦(! + id) ◦ψ1
= [κ2, κ1] ◦(! + id) ◦(πp + id) ◦ψ1
= ✄2 ◦✄1 ◦π[p,q]
= (! + id) ◦✄2 ◦π[p,q]
= (! + id) ◦(πq + id) ◦ψ2
= (! + id) ◦ψ2
= ker⊥(ψ2).
By (12) and the uniqueness of ⟨⟨−, −⟩⟩we obtain:
(πp + πq) ◦ψ = ⟨⟨‹πp›
ψ1, ‹πq›
ψ2⟩⟩
= ⟨⟨✄1 ◦π[p,q], ✄2 ◦π[p,q]⟩⟩= π[p,q].
Our ﬁnal aim is to show that ϕ and ψ are each others inverses. This is
easy since both π[p,q] and πp + πq are monic — the latter by point (8).
Hence we are done with:
π[p,q] ◦ϕ ◦ψ = (πp + πq) ◦ψ = π[p,q]
(πp + πq) ◦ψ ◦ϕ = π[p,q] ◦ϕ = (πp + πq).
□
We turn to comprehension properties in the partial case. Of particular in-
terest is Diagram (46) below, which shows that in presence of comprehension,
kernel predicates give rise to kernel maps.
Lemma 80. Let (C, I) be an eﬀectus with comprehension, in partial form.
1. For each predicate p one has p ◦πp = 1 and p⊥◦πp = 0.
2. The category C has ‘total’ kernel maps: for each map f : X →Y the
following diagram is an equaliser:
{X| ker(f)} / πker(f) / X
f
)
0
5 Y
(46)
where the comprehension map πker(f) is total, by deﬁnition.
3. For each map f, the composite f ◦πker⊥(f) is total.
4. Comprehension maps are closed under pullback in C: for each map f : X →
Y and predicate p on Y there is a pullback:
{Y |f ✷(p)}
/

πf✷(p)

❴✤
{X|p}

πp

X
f
/ Y
(47)
94

5. In presence of images, every map f : X →Y factors through the compre-
hension map of its image:
X
f
/
(
Y
{Y |im(f)}
6
πim(f)
=
Proof We use the formulation of comprehension in the partial case from Deﬁ-
nition 76 (2).
1. By deﬁnition the counit is a map πp : ({X|p}, 1) →(X, p) in Pred✷(C).
This means 1 ≤π✷
p (p) = (p⊥◦πp)⊥. Hence p⊥◦πp = 0.
Since πp is total, pre-composition (−) ◦πp is a map of eﬀect algebras, see
Lemma 52 (4). Therefore:
p ◦πp = p⊥⊥◦πp =
 p⊥◦πp
⊥= 0⊥= 1.
2. For the kernel predicate ker(f) = (1 ◦f)⊥: X →I of a map f : X →Y
consider the comprehension map πker(f) : {X| ker(f)} ֌ X. It satisﬁes,
by the previous point:
1 ◦f ◦πker(f) = ker⊥(f) ◦πker(f) = 0.
Hence f ◦πker(f) = 0 by Deﬁnition 51 (3).
Next, let g : Z →X satisfy f ◦g = 0 ◦g = 0. Then:
g✷ ker(f)

= ker(f ◦g)
by Lemma 39 (5)
= ker(0)
= 1
by Lemma 39 (2).
Hence there is a necessarily unique map g : Z →{X| ker(f)} with πker(f) ◦
g = g.
3. For each f : X →Y we have a total map f ◦πker⊥(f) since by point (1):
1 ◦f ◦πker⊥(f) = ker⊥(f) ◦πker⊥(f) = 1.
4. The dashed arrow in diagram (47) exists because by Exercise 1 (2):
(f ◦πf ✷(p))✷(p) = π✷
f ✷(p)
 f ✷(p)

= 1.
Next, assume we have maps g : Z →X and h: Z →{X|p} with f ◦g =
πp ◦h. The map g then factors through πf ✷(p) since:
g✷ f ✷(p)

= (g ◦f)✷(p) = (πp ◦h)✷(p) = h✷ π✷
p (p)

= h✷(1) = 1.
5. By deﬁnition f ✷(im(f)) = 1, so that f factors through πim(f).
□
95

12
Quotients
Comprehension sends a predicate p on X to the object {X|p} of elements of X
for which p holds. Quotients form a dual operation: it sends a predicate p on
X to the object X/p in which elements for which p holds are identiﬁed with 0.
We brieﬂy describe comprehension and quotients for vector spaces and Hilbert
spaces (like in [CJWW15]). Let LSub(Vect) and CLSub(Hilb) be the cate-
gories of linear (resp. closed linear) subspaces S ⊆V , where V is a vector (resp.
Hilbert) space. Morphisms are maps between the underlying spaces that re-
strict appropriately. The obvious forgetful functors LSub(Vect) →Vect and
CLSub(Hilb) →Hilb have two adjoints on each side:
LSub(Vect)
⊣
⊣

⊣
(S⊆V )
7→V/S
)
⊣
(S⊆V )
7→S
u
CLSub(Hilb)
⊣
⊣

⊣
(S⊆V )
7→S⊥
)
⊣
(S⊆V )
7→S
u
Vect
0
>
1
`
Hilb
0
>
1
`
We see that in both cases comprehension is right adjoint to the truth functor
0, and is given by mapping a subspace S ⊆V to S itself. This is like for Sets,
see Example 77 (1).
Categorically, quotients have dual description to comprehension: not as right
adjoint to truth, but as left adjoint to falsity 0. We brieﬂy describe the associ-
ated dual correspondences, on the left below for vector spaces, and on the right
for Hilbert spaces.
(S ⊆V )
f
/ ({0} ⊆W)
=====================
V/S
g
/ W
(S ⊆V )
f
/ ({0} ⊆W)
=====================
S⊥
g
/ W
The correspondence on the left says that a linear map f : V →W with S ⊆
f −1({0}) = ker(f) corresponds to a map g : V/S →W. Indeed, this g is given
by g(v + S) = f(v). This is well-deﬁned, because f(v) = f(v′) if v ∼v′, since
the latter means v −v′ ∈S, and thus f(v) −f(v′) = f(v −v′) = 0. This is the
standard universal property of quotients in algebra.
The situation is more interesting for Hilbert spaces. A map f : V →W with
S ⊆ker(f) is completely determined by what it does on the orthosupplement
V ⊥, since each vector v ∈V can be written as sum v = x + y with x ∈S and
y ∈S⊥. Hence f(v) = f(y). This explains why f corresponds uniquely to a
map g : S⊥→W, namely its restriction.
Below we shall see more examples where quotients are given by complements
of comprehension. But ﬁrst we have to say what it means for an eﬀectus to
have quotients. Recall that comprehension can be deﬁned both for eﬀectuses in
total and partial form in an equivalent manner, see Theorem 78. In contrast,
quotients only makes sense in the partial case.
Deﬁnition 81. We say that an eﬀectus in partial form (C, I) has quotients if
its zero functor 0: C →Pred✷(C) has a left adjoint.
We say that an eﬀectus in total form B has quotients if its category Par(B)
of partial maps has quotients.
96

For an eﬀectus in partial form C with both comprehension and quotients we
have a ‘quotient-comprehension chain’, like for vector and Hilbert spaces:
Pred✷(C)
⊣
⊣

⊣
Quotient
(X,p)7→X/p
*
⊣
Comprehension
(X,p)7→{X|p}
t
C
0
>
1
`
We shall study such combinations in Section 14.
The unit of the quotient adjunction is a map in Pred✷(C) which we write
as:
(X, p)
ξp
/ (X/p, 0)
Hence by deﬁnition it is a map ξp : X →X/p in C satisfying p ≤f ✷(0) = ker(f).
Example 82. Each of our four running examples of eﬀectuses has quotients.
1. For the eﬀectus Sets, the associated category Par(Sets) is the category of
sets and partial functions. For a predicate P ⊆X we deﬁne the quotient
set X/P as comprehension of the complement:
X/P
def
= {X|¬P} = {x ∈X | x ̸∈P},
(48)
analogously to the Hilbert space example described above. This gives a
left adjoint to the zero functor 0: Par(Sets) →Pred✷(Par(Sets)), since
there are bijective correspondences:
(P ⊆X)
f
/ 0(Y ) = (∅⊆Y )
=================
{X|¬P}
g
/ Y
Indeed, given f : (P ⊆X) →0(Y ) in Pred✷(Par(Sets)), then f : X →Y
is a partial function satisfying P ⊆f ✷(0) = {x | f(x) = ∗}, see (21).
Thus f is determined by its outcome on the complement ¬P, so that we
can simply deﬁne a corresponding partial function f : {X|¬P} →Y as
f(x) = f(x). And, in the other direction, for g : {X|¬P} →Y we deﬁne
the extension g: X →Y as:
g(x) =
(
∗i.e. undeﬁned
if x ∈P
g(x)
if x ∈¬P
By construction, this g is a map (P ⊆X) →(∅⊆Y ) in Pred✷(Par(Sets))
since:
ker(g) = g✷(0) = {x | g(x) = ∗} ⊇P.
It is easy to see f = f and g = g. The unit ξP : X →X/P is the partial
function with ξP (x) = x if x ∈P and ξP (x) undeﬁned otherwise.
97

2. We recall that the category of partial maps for the eﬀectus Kℓ(D) for
discrete probability is the Kleisli category Kℓ(D≤1) of the subdistribution
monad D≤1, see Example 9. For a predicate p ∈[0, 1]X on a set X we
take as quotient:
X/p
def
= {x ∈X | p(x) < 1}.
(49)
The quotient adjunction involves bijective correspondences:
(p ∈[0, 1]X)
f
/ (0 ∈[0, 1]Y ) = 0(Y )
=========================
X/p
g
/ Y
This works as follows.
• Given f : (p ∈[0, 1]X) →(0 ∈[0, 1]Y ) in Pred✷(Kℓ(D≤1)), then
f : X →D≤1(Y ) satisﬁes p(x) ≤f ✷(0)(x) = ker(f)(x) = 1 −
P
y f(x)(y) for each x ∈X, see (23).
We then deﬁne f : X/p →
D≤1(Y ) as:
f(x) = P
y
f(x)(y)
p⊥(x)
y

= P
y
f(x)(y)
1−p(x)
y

This is well-deﬁned, since p(x) ̸= 1 for x ∈X/p.
• In the other direction, given a function g : X/p →D≤1(Y ) we deﬁne
g : X →D≤1(Y ) as:
g(x) = P
y p⊥(x) · g(x)(y)
y

This g is a morphism (p ∈[0, 1]X) →(0 ∈[0, 1]Y ) in Pred✷(Kℓ(D≤1)),
since we have an inequality p ≤ker(g) via:
ker(g)(x) = 1 −P
y g(x)(y) = 1 −P
y p⊥(x) · g(x)(y)
= p(x) + p⊥(x) −p⊥(x) · P
y g(x)(y)
= p(x) −p⊥(x) · (1 −P
y g(x)(y))
= p(x) + p⊥(x) · ker(g)(x)
≥p(x).
Clearly, the mappings f 7→f and g 7→g are each other’s inverses. The
unit map ξp : X →X/p is given by ξp(x) = p⊥(x)|x⟩= (1 −p(x))|x⟩.
We notice that also in this case we can express the quotient object as
comprehension, namely:
X/p = {x ∈X | p(x) < 1} = {x ∈X | ⌈p⊥⌉(x) = 1} = {X|⌈p⊥⌉},
where, in general, ⌈q⌉is the least sharp predicate above q, given by:
⌈q⌉(x) =
(
1
if q(x) > 0
0
if q(x) = 0
(50)
98

3. For the eﬀectus of order unit groups we recall from Example 10 that
the category Par(OUGop) of partial maps in OUGop contains positive
subunital group homomorphisms as maps. Because of the ‘opposite’ in-
volved, we deﬁne quotients via subgroups, in the following way. For an
eﬀect e ∈[0, 1]G in an order unit group G we take:
G/e
def
= ⟨e⊥⟩G,
(51)
where ⟨e⊥⟩G ⊆G is the subgroup given by ⟨e⟩G = {x ∈G | ∃n ∈N. −n ·
e⊥≤x ≤n · e⊥}, see Example 77 (3). We write the inclusion ⟨e⊥⟩G ⊆G
as a map ξe : ⟨e⊥⟩G →G. This is a positive group homomorphism, which
is subunital since:
ξe(1G/e) = ξe(e⊥) = e⊥∈[0, 1]G.
The quotient adjunction involves a bijective correspondence between:
(G, e)
f
/ 0(H)
in Pred✷
 OUGop
===============
G/e
g
/ H
in Par(OUGop)
That is, between positive subunital (PsU) group homomorphisms:
H
f
/ G with e ≤f ✷(0)
======================
H
g
/ G/e
where f ✷(0) = ker(f) = f(1)⊥, see (24). This works as follows.
• Given f : H →G with e ≤ker(f) = f(1)⊥, we have f(1) ≤e⊥. For
each x ∈H there is an n with −n · 1 ≤x ≤n · 1. Using that f is
positive/monotone we get:
−n · e⊥≤−n · f(1) = f(−n · 1) ≤f(x)
≤f(n · 1) = n · f(1) ≤n · e⊥.
Hence f(x) ∈⟨e⊥⟩G, so that we can simply deﬁne f : H →⟨e⊥⟩G =
G/e as f(x) = f(x).
• Given g : H →G/e = ⟨e⊥⟩G, deﬁne g = ξe ◦g : H →G. This is a
subunital map with:
g✷(0) = g(1)⊥= ξe⊥(g(1))⊥= g(1)⊥
≥
 1⟨e⊥⟩G
⊥=
 e⊥⊥= e.
We have f = ξe ◦f = f, and g = g by injectivity of ξe.
□
4. In the eﬀectus vNAop of von Neumann algebras the partial maps are also
the subunital ones, see Example 11. The quotient of an eﬀect e ∈[0, 1]A
in a von Neumann algebra A is deﬁned as:
A /e
def
= ⌈e⊥⌉A ⌈e⊥⌉= {⌈e⊥⌉· x · ⌈e⊥⌉| x ∈A }.
(52)
99

It uses the ‘ceiling’ ⌈e⊥⌉= ⌊e⌋⊥from Example 77 (4). The quotient map
ξe : A →A /e in vNAop is given by the subunital function A /e →A
with:
ξe(x) =
√
e⊥· x ·
√
e⊥.
(53)
This map incorporates L¨uders rule, see e.g. [BS98, Eq.(1.3)].
The proof that these constructions yield a left adjoint to the zero functor
is highly non-trivial. For details we refer to [WW15]. We conclude that
once again quotient objects can be expressed via comprehension:
{A |⌈e⊥⌉} = ⌊⌈e⊥⌉⌋A ⌊⌈e⊥⌉⌋= ⌈e⊥⌉A ⌈e⊥⌉= A /e.
We continue with a series of small results that hold for quotients.
Lemma 83. Let (C, I) be an eﬀectus with quotients, in partial form.
1. The unit ξp : X →X/p satisﬁes ker(ξp) = p and thus ker⊥(ξp) = p⊥.
2. The unit map ξp : X →X/p is epic in C.
3. For a predicate q: X/p →I one has q ◦ξp ≤p⊥.
4. The functor
Pred✷(C)
ξ(−)
/ Quot(C)
is full and faithful — where Quot(C) is the obvious category with epis ։
as objects and commuting squares between them as arrows.
5. The universal property of quotient amounts to: for each f : X →Y with
p ≤ker(f) there is a unique f : X/p →Y with f ◦ξp = f. But we can say
more: if there is an equality p = ker(f), then f is total.
6. There are total isomorphisms ξ0 : X
∼
=
−→X/0 and 0
∼
=
−→X/1.
7. For each predicate p on X there is a total ‘decomposition’ map dcp : X →
X/p⊥+ X/p, namely the unique map in:
X
ξp⊥
xqqqqqqqqqqq
ξp
&▲
▲
▲
▲
▲
▲
▲
▲
▲
▲
▲
dcp

X/p⊥
X/p⊥+ X/p
✄1
o
✄2 / X/p
(54)
Using the pairing notation of Lemma 6, we can describe it as dcp =
⟨⟨ξp⊥, ξp⟩⟩, and thus also as total sum dcp = (κ1 ◦ξp⊥) > (κ2 ◦ξp) of
two maps X →X/p⊥+ X/p, see Lemma 43.
8. Each total map f : Y →X1 + X2 can be decomposed in the subcategory
Tot(C) ֒→C of total maps as f = (f1 + f2) ◦dcp where p = (! + !) ◦f and
f1, f2 are total, and uniquely determined.
9. For predicates p on X and q on Y the sum map ξp+ξq : X+Y →X/p+Y/q
is epic in C.
100

10. For predicates p on X and q on Y there is a total (canonical) isomorphism
in:
(X/p) + (Y/q)
∼
=
/ (X + Y )/[p, q]
X + Y
ξp+ξq
ff▼▼▼▼▼▼▼▼
ξ[p,q]
8 8q
q
q
q
q
q
q
q
11. Partial projections ✄i are (isomorphic to) quotient maps, via total iso-
morphisms:
X + Y
ξ[0,1]
}}⑤⑤⑤⑤⑤⑤
✄1
 ❂❂❂❂❂❂
X + Y
ξ[1,0]
}}⑤⑤⑤⑤⑤⑤
✄1
 ❂❂❂❂❂❂
(X + Y )/[0, 1]
∼
=
/ X
(X + Y )/[1, 0]
∼
=
/ Y
12. For a predicate p on X there is an isomorphism of eﬀect modules:
Pred(X/p⊥)
p·(−)
,
∼=
↓p = {q ∈Pred(X) | q ≤p}
(−)/p
m
(55)
As a result, if X/p ∼= 0, then p = 1.
13. Quotient maps are closed under composition, up to total isomorphisms.
Given a predicate p on X and q on X/p, there is an isomorphism as on
the left below. It uses the operation p⊥· (−) = (−) ◦ξp from point (12).
(X/p)/q
∼
total X/(p⊥· q⊥)⊥
(X/p)/(r⊥/p⊥)⊥
∼
total
X/r
X/p
ξq
[[✼✼✼✼
X/p
ξ(p⊥/r⊥)⊥
dd❍❍❍❍❍
X
ξp
ZZ✺✺✺
ξ(p⊥·q⊥)⊥
F F☞☞☞☞☞☞☞☞☞☞
X
ξp
cc❋❋❋❋❋
ξr
GG✎✎✎✎✎✎✎✎✎
Equivalently, for predicates p, r on X with p ≤r, there is a total isomor-
phism as on the right above.
14. If our eﬀectus C has images, then it has cokernel maps: for each map
f : X →Y we have a coequaliser in C of the form:
X
f
+
0
3 Y
coker(f)
def
= ξim(f)/ / Y/im(f)
Thus: coker(f) = 0 iﬀim(f) = 1, that is, iﬀf is internally epic.
The decomposition property of maps from point (8) plays an important role
in Section 13 when we relate extensive categories and (Boolean) eﬀectuses.
Proof We reason in the eﬀectus in partial form C and do not use diﬀerent
notation for partial and total maps.
101

1. Since the unit ξp is a map (X, p) →(X/p, 0) in Pred✷(C) we have an
inequality p ≤ξ✷
p (0) = ker(ξp) by deﬁnition. In order to get an equation
p = ker(ξp), notice that the predicate p⊥: X →I is a map (X, p) →(I, 0)
in Pred✷(C), since:
(p⊥)✷(0) =
 0⊥◦p⊥⊥=
 1I ◦p⊥⊥=
 idI ◦p⊥⊥= p.
Hence there is a unique map p: X/p →I with p ◦ξp = p⊥. But then we
are done by Lemma 39 (1) and (6): p = ker(p⊥) = ker(p ◦ξp) ≥ker(ξp).
2. Let maps f, g : X/p →Y satisfy f ◦ξp = g ◦ξp = h, say. This h: X →Y
then satisﬁes p = ker(ξp) ≤ker(f ◦ξp) = ker(h) = h✷(0). Hence there is a
unique h: X/p →Y with h ◦ξp = h. But then f = h = g by uniqueness.
3. For a predicate q on X/p one has:
q ◦ξp =
 q⊥⊥◦ξp
⊥⊥= ξ✷
p (q⊥)⊥≤ξ✷
p (0)⊥
since 0 ≤q⊥
= ker(ξp)⊥
= p⊥
by point (1).
4. Let’s assume we have a commuting diagram in C of the form:
X
ξp 
f
/ Y
ξq

X/p
g
/ Y/q
We have to prove p ≤f ✷(q), making f a map (X, p) →(Y, q) in Pred✷(C).
This follows from:
p = ker(ξp) = ξ✷
p (0) ≤ξ✷
p
 g✷(0)

= f ✷ ξ✷
q (0)

= f ✷ ker(ξq)

= f ✷(q).
5. Clearly, p ≤ker(f) = f ✷(0) means that f is a map (X, p) →(Y, 0) in
Pred✷(C). Hence the unique map f : X/p →Y is the adjoint transpose.
If we have an equation p = ker(f), then we can show that f is total, by
using that the unit map ξp is epic:
1 ◦f ◦ξp = 1 ◦f = ker⊥(f) = p⊥= ker⊥(ξp) = 1 ◦ξp.
6. We ﬁrst show X/0 ∼= X. The identity map in X satisﬁes: ker(idX) = 0.
Hence by point (5) there is a unique total map f : X/0 →X satisfying
f ◦ξ0 = id. The map ξ0 is also total since 1◦ξ0 = ker⊥(ξ0) = 0⊥= 1. We
now get ξ0 ◦f = idX by using that ξ0 is epic: (ξ0 ◦f) ◦ξ0 = ξ0 = id ◦ξ0.
Next, for the isomorphism X/1 ∼= 0, we notice that the zero map 0: X →0
in C satisﬁes ker(0) = (0⊥◦0)⊥= 0⊥= 1, so that there is a unique total
map f : X/1 →0 with f ◦ξ1 = 0.
Obviously, f ◦!X/1 = id0, where
!X/1 : 0 →X/1 is total. We also have !X/1 ◦f = idX/1, since ξ1 is epic
and: (!X/1 ◦f) ◦ξ1 = !X/1 ◦0 = 0 = ξ1. This last equation holds by
Deﬁnition 51 (3) since 1 ◦ξ1 = ker⊥(ξ1) = 1⊥= 0.
102

7. The diagram (54) uniquely deﬁnes dcp = ⟨⟨ξp⊥, ξp⟩⟩as described in Lemma 6.
It satisﬁes [κ2, κ1] ◦dcp = dcp⊥since:
✄1 ◦[κ2, κ1] ◦dcp = [[id, 0] ◦κ2, [id, 0] ◦κ1] ◦dcp
= [0, id] ◦dcp = ✄2 ◦dcp = ξp.
Similarly one proves ✄2 ◦[κ2, κ1] ◦dcp = ξp⊥, so that:
[κ2, κ1] ◦dcp = ⟨⟨ξp, ξp⊥⟩⟩= dcp⊥.
8. Let f : Y →X1 + X2 be total, and write p = (! + !) ◦f : Y →1 + 1 in
the subcategory Tot(C) of total maps. The partial map ✄1 ◦f : Y →X1
satisﬁes:
ker
 ✄1 ◦f

=
 (! + id) ◦(id + !) ◦f
⊥= p⊥.
Hence there is a unique total map f1 : Y/p⊥→X1 with f1 ◦ξp⊥= ✄1 ◦f.
Similarly, from ker
 ✄2 ◦f

= p we obtain a unique total f2 : Y/p →X2
with f2 ◦ξp = ✄2 ◦f. But then in Tot(C), using Lemma 6:
(f1 + f2) ◦dcp = (f1 + f2) ◦⟨⟨ξp⊥, ξp⟩⟩= ⟨⟨f1 ◦ξp⊥, f2 ◦ξp⟩⟩
= ⟨⟨✄1 ◦f, ✄2 ◦f⟩⟩
= f.
9. In an arbitrary category, if f : X ։ A, g : Y ։ B are both epic, then so
is the sum f + g.
10. We ﬁrst have to say what the canonical map τ : (X + Y )/[p, q] →(X/p) +
(Y/q) is. Consider the sum map ξp + ξq in C with:
ker⊥(ξp + ξq) = 1 ◦(ξp + ξq) = [1, 1] ◦(ξp + ξq)
by Lemma 52 (3)
= [1 ◦ξp, 1 ◦ξq]
= [ker⊥(ξp), ker⊥(ξq)]
= [p⊥, q⊥]
= [p, q]⊥
by Theorem 21.
This last step uses the isomorphism of eﬀect modules Pred(X + Y ) ∼=
Pred(X) × Pred(Y ). The resulting equation ker(ξp + ξq) = [p, q] yields
by point (5) a unique total map τ : (X + Y )/[p, q] →X/p + Y/q with
τ ◦ξ[p,q] = ξp + ξq.
In the other direction, consider the two composites:
X
κ1 *❱
❱
❱
❱
❱
X + Y
ξ[p,q] / (X + Y )/[p, q]
Y
κ2
4❤
❤
❤
❤
❤
❤
103

The ﬁrst one satisﬁes:
ker
 ξ[p,q] ◦κ1

=
 1 ◦ξ[p,q] ◦κ1
⊥=
 ker⊥(ξ[p,q]) ◦κ1
⊥
=
 [p⊥, q⊥] ◦κ1
⊥
= p.
Similarly, ker
 ξ[p,q]◦κ2

= q. Hence there are unique total maps f : X/p →
(X + Y )/[p, q] and g : Y/q →(X + Y )/[p, q] with f ◦ξp = ξ[p,q] ◦κ1
and g ◦ξq = ξ[p,q] ◦κ2. We claim that the cotuple [f, g]: X/p + Y/q →
(X + Y )/[p, q] is the inverse of the canonical map τ.
We obtain [f, g] ◦τ = id from the fact that ξ’s are epic:
[f, g] ◦τ ◦ξ[p,q] = [f, g] ◦(ξp + ξq) = [f ◦ξp, g ◦ξq]
= [ξ[p,q] ◦κ1, ξ[p,q] ◦κ2]
= ξ[p,q].
In the other direction we use that the sum map ξp + ξq in C is epic:
τ ◦[f, g] ◦(ξp + ξq) = τ ◦[f ◦ξp, g ◦ξq]
= [τ ◦ξ[p,q] ◦κ1, τ ◦ξ[p,q] ◦κ2]
= [(ξp + ξq) ◦κ1, (ξp + ξq) ◦κ2]
= (ξp + ξq).
11. By points (10) and (6) we have isomorphisms:
X + Y
ξ[0,1]
ss❢❢❢❢❢❢❢❢❢❢❢❢❢❢❢❢❢❢❢❢
ξ0+ξ1sss
yysss
id+!
❅❅❅
 ❅❅
✄1
) )❘
❘
❘
❘
❘
❘
❘
❘
❘
❘
❘
❘
❘
(X + Y )/[0, 1]
∼
(X/0) + (Y/1)
∼
X + 0
∼
X
12. For a predicate q ≤p, we have p⊥≤q⊥= ker(q). Hence there is a unique
predicate, written as q/p: X/p⊥→I, with (q/p) ◦ξp⊥= q. In the other
direction, for r: X/p⊥→I we write p · r = r ◦ξp⊥: X →I. Then p · r ≤p
follows from:
(p · r)⊥= ker(p · r) = ker(r ◦ξp⊥) ≥ker(ξp⊥)
by Lemma 39 (6)
= p⊥.
By construction, p · (q/p) = q. But also (p · r)/p = r, because ξ’s are epic,
and: ((p·r)/p)◦ξp⊥= p·r = r◦ξp⊥. It requires a bit of work to verify that
these mappings (−)/p and p · (−) preserve the eﬀect module structure.
Finally, if X/p ∼= 0, then ↓p⊥∼= Pred(X/p) ∼= Pred(0) ∼= 1. But then
↓p⊥= {0}, so that p⊥= 0 and thus p = 1.
13. Let p be a predicate on X and q on X/p. Then by Lemma 39 (5):
ker(ξq ◦ξp) = ξ✷
p (ker(ξq)) = ξ✷
p (q) =
 q⊥◦ξp
⊥=
 p⊥· q⊥⊥.
104

Hence there is a unique (total) map f : X/(p⊥· q⊥)⊥→(X/p)/q with
f ◦ξX/(p⊥·q⊥)⊥= ξq ◦ξp. In the other direction we proceed in two steps.
First, by construction, p⊥· q⊥≤p⊥, so p ≤(p⊥· q⊥)⊥. This yields a map
g : X/p →X/(p⊥· q⊥)⊥with g ◦ξp = ξ(p⊥·q⊥)⊥. We wish to show that
there is a total map h: (X/p)/q →X/(p⊥· q⊥)⊥with h ◦ξq = g. This
works if ker(g) = q: X/p →I. Because the ξ’s are epic in C we are done
by:
ker⊥(g) ◦ξp = 1 ◦g ◦ξp = 1 ◦ξ(p⊥·q⊥)⊥= ker⊥(ξ(p⊥·q⊥)⊥)
= p⊥· q⊥
= q⊥◦ξp.
We now have (total) maps (X/p)/q ⇄X/(p⊥·q⊥)⊥, which are each other’s
inverses because they commute with the ξ’s.
We leave it to the reader to construct similar maps (X/p)/(r⊥/p⊥)⊥⇄
X/r for p ≤r.
14. Assuming images in C we have for each map f : X →Y a predicate
im(f): Y →I, with quotient map ξim(f) : Y →Y/im(f). We claim that
ξim(f) ◦f = 0: X →X/im(f). This follows by Deﬁnition 51 (3) from:
1 ◦ξim(f) ◦f = ker⊥(ξim(f)) ◦f = im⊥(f) ◦f = f ✷(im(f))⊥= 1⊥= 0.
Now suppose we have a map g : Y →Z with g ◦f = g ◦0 = 0. Then
im(f) ≤ker(g) by Lemma 47 (7). This yields the required unique map
g: Y/im(f) →Z with g ◦ξim(f) = g.
Finally, if im(f) = 1, then Y/im(f) = Y/1 ∼= 0, by point (6), so that
coker(f) = ξim(f) : Y →0 is the zero map. Conversely, let coker(f) = 0.
By Lemma 39 (1) we have ker(im⊥(f)) = im(f): Y →I. Hence there is
a unique map g : X/im(f) →I with im⊥(f) = g ◦ξim(f) = g ◦coker(f) =
g ◦0 = 0. But then im(f) = 1.
□
Several of the points in Lemma 83 are used to prove that quotients give
rise to a factorisation system.
Such a system is given by two collections of
map, called ‘abstract monos’ and ‘abstract epis’, satisfying certain properties,
see e.g. [BW85] for details.
Proposition 84. Each eﬀectus with quotients in partial form has a factorisa-
tion system given by internal monos (i.e. total maps) and quotient maps ξ.
Proof An arbitrary map f : X →Y can be factored as:
X
f
/
ξker(f)
' '
Y
X/ ker(f)
f ′, total
=
The fact that the map f ′ is total follows from Lemma 83 (5).
105

By Lemma 39 (8) the total (internally monic) maps are closed under com-
position. The ξ’s are also closed under composition, by Lemma 83 (13). The
intersection of the these two classes consists of isomorphisms: if ξp : X →X/p is
total, then 1 = 1◦ξp = ker⊥(ξp) = p⊥, so that p = 0, making ξp = ξ0 : X →X/0
an isomorphism, see Lemma 83 (6).
Finally we check the diagonal-ﬁll-in property. In a commuting diagram as on
the left below, there is a unique diagonal as on the right, making both triangles
commute.
X
ξp
/ /
g

X/p
h

X
ξp
/ /
g

X/p
h

z
Y
f
total
/ Z
Y
f
total
/ Z
We have by Lemma 39 (7) and (6), using that f is total,
ker(g) = ker(f ◦g) = ker(h ◦ξp) ≥ker(ξp) = p.
Hence there is a unique map k: X/p →Y with k ◦ξp = g. We obtain f ◦k = h
by using that ξp is epic.
□
13
Boolean eﬀectuses and extensive categories
The main result of this section says that a Boolean eﬀectus with comprehen-
sion is the same thing as an extensive category. This is an important coinci-
dence of two categorical notions, which gives a deeper understanding of what
Boolean eﬀectuses are. These extensive categories are well-known from the lit-
erature [CLW93] and capture well-behaved coproducts.
In this section we shall work in the ‘total’ language of eﬀectuses, and not
the ‘partial’ version.
The reason is that we will work towards a correspon-
dence between extensive categories and certain eﬀectuses in total form— and
not between extensive categories and eﬀectuses in partial form.
We recall from Deﬁnition 55 that an eﬀectus is Boolean if it is commutative
— with assert maps asrtp : X →X + 1 for predicates p: X →1 + 1 as inverse
to ker⊥— which satisfy asrtp
asrtp⊥= 0. We start with an auxiliary result
about comprehension in commutative eﬀectuses.
Lemma 85. In a commutative eﬀectus B with comprehension the following two
diagrams are equalisers in B.
{X|p⊥} /
πp⊥/ X
asrtp )
0
6 X+1
{X|p} / πp
/ X
asrtp )
κ1
6 X+1
Proof The equaliser on the left in B is in essence the kernel map property in
Par(B) from Lemma 80 (2). For the one on the right we recall that asrtp ≤id
in the homset of partial maps X →X, by deﬁnition. Hence:
asrtp ◦πp = asrtp
‹πp› ≤id
‹πp› = κ1 ◦πp.
106

We wish to show that this inequality is actually an equality. So let f : X →X
satisfy (asrtp ◦πp) > f = (κ1 ◦πp). Applying the map of eﬀect algebras ker⊥=
(! + id) ◦(−) on both sides yields in Pred({X|p}),
1 = κ1 ◦! = κ1 ◦! ◦πp = ker⊥(κ1 ◦π1)
= ker⊥(asrtp ◦πp) > ker⊥(f)
= ((! + id) ◦asrtp ◦πp) > ker⊥(f)
= (p ◦πp) > ker⊥(f)
= 1 > ker⊥(f).
Hence ker⊥(f) = 0 by cancellation in the eﬀect algebra Pred({X|p}), and thus
f = 0 by Lemma 39 (2). But then κ1 ◦πp = (asrtp ◦πp) > f = asrtp ◦πp.
Next, let f : Y →X in B satisfy asrtp ◦f = κ1 ◦f. Then:
f ∗(p) = p ◦f = (! + id) ◦asrtp ◦f
= (! + id) ◦κ1 ◦f = κ1 ◦! ◦f = κ1 ◦! = 1.
Hence f factors in a unique way through πp.
□
We turn to extensive categories. There are several equivalent formulations,
see [CLW93], but we use the most standard one.
Deﬁnition 86. A category is called extensive if it has ﬁnite coproducts (+, 0)
such that pullbacks along coprojections exist, and in every diagram of the form,
Z1
/

Z

Z2
o

X
κ1
/ X + Y
Y
κ2
o
the two rectangles are pullbacks if and only if the top row is a coproduct, that
is, the induced map Z1 + Z2 →Z is an isomorphism.
There are many examples of extensive categories, with ‘well-behaved’ co-
products. For instance, every topos — including Sets — is an extensive cate-
gory, see e.g. [CLW93]. At the end of this section we list some concrete examples.
For the record we recall the following basic observation from [CLW93]. The
ﬁrst point is the anologue of Proposition 4 for eﬀectuses.
Lemma 87. In an extensive category,
1. coprojections are are monic and disjoint, and the initial object 0 is strict;
2. If the rectangles on the left below are pullbacks, for i = 1, 2, then the
rectangle on the right is a pulback too.
Ai
fi

gi
/
❴✤
X
f

A1 + A2
f1+f2

[g1,g2] /
❴✤
X
f

Bi
hi
/ Y
B1 + B2
[h1,h2]
/ Y
107

Proof For the ﬁrst point, consider the rectangles:
0
/

Y
κ2

Y
X
κ1
/ X + Y
Y
κ2
o
The top row is a coproduct diagram. Hence the two rectangles are pullbacks.
The one on the left says that coprojections are disjoint, and the one on the right
says that κ2 is monic.
For strictness of 0, we have to prove that a map f : X →0 is an isomorphism.
Consider the diagram:
X
f

❴✤
X
κ1◦f=κ2◦f

X
f

✤❴
0
κ1
/ 0 + 0
Y
κ2
o
The two rectangles are pullbacks because the coprojections are monic. Hence the
top row is a coproduct diagram, so that the codiagonal ∇= [id, id]: X+X →X
is an isomorphism. Using ∇◦κ1 = id = ∇◦κ2 we get κ1 = κ2 : X →X + X.
Now we can now prove that ! ◦f : X →0 →X is the identity, via:
! ◦f = [! ◦f, idX] ◦κ1 = [! ◦f, idX] ◦κ2 = idX.
We turn to the second point. Let a: Z →X and b: Z →B1 + B2 satisfy
f ◦a = [h1, h2] ◦b. Form the pullbacks on the left, and the mediating maps ci
on the right:
Z1 /
k1
/
b1

❴✤
Z
b

Z2
o
k2
o
b2

✤❴
B1 /
κ1
/ B1 + B2
B2
o
κ2
o
and
Zi
bi

a◦ki
 
ci
 
Ai
fi

gi
/
❴✤
X
f

Bi
hi
/ Y
The outer diagram on the right commutes since:
f ◦a ◦ki = [h1, h2] ◦b ◦ki = [h1, h2] ◦κi ◦bi = hi ◦bi.
The unique mediating map is c = (c1 + c2) ◦[k1, k2]−1 : Z →A1 + A2.
□
Proposition 88. Each extensive category with a ﬁnal object is a Boolean ef-
fectus with comprehension.
Proof This is quite a bit of work. So let A be an extensive category with a
ﬁnal object 1. We start by showing that A is an eﬀectus. We ﬁrst concentrate
108

on the two pullbacks in Deﬁnition 2:
X + Y
id+! /
!+id

X + 1
!+id

X
!
/

κ1

1
κ1

1 + Y
id+! / 1 + 1
X + Y
!+! / 1 + 1
(∗)
For convenience, we start with the diagram on the right. We consider it as
turned left-part of the following diagram:
X / κ1
/
!

X + Y
!+!

Y
o
κ2
o
!

1 /
κ1
/ 1 + 1
1
o
κ2
o
Since the top row is a coproduct diagram, both rectangles are pullbacks in an
extensive category, by deﬁnition.
For the diagram on the left in (∗), it suﬃces, by Lemma 87 (2) to prove that
the two diagrams below are pullbacks.
X
κ1
/
!

X + 1
!+id

Y
!
/ 1
κ2
/ X + 1
!+id

1
κ1
/ 1 + 1
Y
!
/ 1
κ2
/ 1 + 1
The rectangle on the left is a pullback just like the diagram on the right in (∗).
Similarly, the right-rectangle on the right is a pullback. The left-rectangle on
the right is obviously a pullback, so we are done by the Pullback Lemma.
The next step is to prove that the two maps ···
··✎✎= [id, κ2], ···
··✴✴✎✎✎✎= [[κ2, κ1], κ2]
are jointly monic. We sketch how to proceed. If f, g : Y →(1 + 1) + 1 satisfy
···
··✎✎◦f = ···
··✎✎◦g and ···
··✴✴✎✎✎✎◦f = ···
··✴✴✎✎✎✎◦g then we decompose f, g each in three parts,
via pulbacks with approriate coprojections 1 →(1 + 1)+ 1, and show that these
three parts are equal. This is left to the interested reader.
We now know that the extensive category A that we started from is an
eﬀectus. We turn to predicates and comprehension. For each predicate p: X →
1 + 1 in A we choose a pullback:
{X|p}

/
πp
/
❴✤
X
p

1 /
κ1
/ 1 + 1
(56)
We will need a number of facts about these maps πp : {X|p} ֌ X.
(a). The following diagrams are also pullbacks.
X
p

{X|p⊥}
o
πp⊥
o

{X|p} + Y
[!,!]=!

/πp+id/ X + Y
[p,1]

1 + 1
1
o
κ2
o
1 /
κ1
/ 1 + 1
109

The combination of the left diagram and Diagram (56) tells us that the
cotuple [πp, πp⊥]: {X|p} + {X|p⊥} →X is an isomorphism. The conse-
quence of the pullback on the right is that {X | [p, 1]} ∼= {X|p} + Y , so
that the eﬀectus A has comprehension, see Deﬁnition 76.
It is easy to see that the above diagram on the left is a pullback: if
f : Y →X satisﬁes p ◦f = κ2 ◦!, then:
p⊥◦f = [κ2, κ1] ◦p ◦f = [κ2, κ1] ◦κ2 ◦! = κ1 ◦! = 1.
Hence f factors uniquely through πp⊥in (56).
The above rectangle on the right is a pullback diagram since one can apply
Lemma 87 (2) to Diagram (56) and a trivial pullback.
(b). The pair of comprehension maps πp, πp⊥is jointly epic.
Indeed, if f ◦πp = g ◦πp and f ◦πp⊥= g ◦πp⊥, then:
f ◦[πp, πp⊥] = [f ◦πp, f ◦πp⊥] = [g ◦πp, g ◦πp⊥] = g ◦[πp, πp⊥].
Hence f = g since the cotuple [πp, πp⊥] is an isomorphism.
We now deﬁne for each predicate p: X →1 + 1 an ‘assert’ map X →X + 1
as:
asrtp
def
=

X
[πp,πp⊥]−1
/ {X|p} + {X|p⊥}
πp+! / X + 1

Again we prove a number of basic facts.
(i). asrtp ◦πp = κ1 ◦πp and asrtp ◦πp⊥= 0.
From [πp, πp⊥] ◦κ1 = πp we obtain [πp, πp⊥]−1 ◦πp = κ1. Hence:
asrtp ◦πp = (πp + !) ◦[πp, πp⊥]−1 ◦πp = (πp + !) ◦κ1 = κ1 ◦πp.
Similarly:
asrtp ◦πp⊥= (πp + !) ◦[πp, πp⊥]−1 ◦πp⊥= (πp + !) ◦κ2 = κ2 ◦! = 0.
(ii). asrtp ≤id in the homset of partial maps X →X, since asrtp>asrtp⊥= id,
via the bound b = κ1 ◦(πp +πp⊥)◦[πp, πp⊥]−1 : X →(X +X)+1. Indeed:
✄1
b = (id + !) ◦(πp + πp⊥) ◦[πp, πp⊥]−1
= (πp + !) ◦[πp, πp⊥]−1
= asrtp
✄2
b = [κ2 ◦!, κ1] ◦(πp + πp⊥) ◦[πp, πp⊥]−1
= [κ2 ◦!, κ1 ◦πp⊥] ◦[πp, πp⊥]−1
= (πp⊥+ !) ◦[κ2, κ1] ◦[πp, πp⊥]−1
= (πp⊥+ !) ◦[πp⊥, πp]−1
= asrtp⊥
asrtp > asrtp⊥= ∇
b
= κ1 ◦∇◦(πp + πp⊥) ◦[πp, πp⊥]−1
= κ1
110

(iii). This mapping p 7→asrtp is the inverse of ker⊥: End≤id(X) →Pred(X).
First, we have:
ker⊥(asrtp) = (! + id) ◦(πp + !) ◦[πp, πp⊥]−1
= (! + !) ◦[πp, πp⊥]−1
= p.
Conversely, let f : X →X satisfy f ≤id. We need to prove f = asrtp, for
p = ker⊥(f) = 1
f = (! + id) ◦f. Consider the diagram:
{X|p} /
πp
/
h

❴✤
X
f

{X|p⊥}
o
πp⊥
o
!

✤❴
X /
κ1
/
!

❴✤
X + 1
!+id

1
o
κ2
o
✤❴
1 /
κ1
/ 1 + 1
Y
o
κ2
o
We ﬁrst show h = πp. Since f ≤id we can write f > g = id for some map
g : X →X. Then:
1 = 1
id = 1
(f > g) = (1
f) > (1
g) = p > (1
g).
Hence 1
g = p⊥. Then: 1
(g ◦πp) = p⊥◦πp = 0, so that g ◦πp = 0 by
Lemma 7. We now get πp = h from:
κ1 ◦πp = (f > g) ◦πp = (f ◦πp) > (g ◦πp) = (κ1 ◦h) > 0 = κ1 ◦h.
Finally we obtain f = asrtp from:
f ◦[πp, πp⊥] = [f ◦πp, f ◦πp⊥] = [κ1 ◦πp, κ2 ◦!] = πp + !.
(iv). asrtp
asrtp⊥= 0.
We simply calculate:
asrtp
asrtp⊥= [asrtp, κ2] ◦(πp⊥+ !) ◦[πp⊥, πp]−1
= [asrtp ◦πp⊥, κ2 ◦!] ◦[πp⊥, πp]−1
(i)
= [κ2 ◦!, κ2 ◦!] ◦[πp⊥, πp]−1
= 0 ◦[πp⊥, πp]−1
= 0.
(v). Commutation of asserts — that is, asrtp
asrtq = asrtq
asrtp — follows
from the previous point, as described in Remark 60.
We may now conclude that the extensive category A is an eﬀectus with
comprehension, by point (a), which is commutative, by points (ii) – (v), and
Boolean in particular, by point (iv).
□
111

We now arrive at the main result of this section.
Theorem 89. Let B be a category with ﬁnite coproducts and a ﬁnal object.
Then: B is extensive if and only if it is a Boolean eﬀectus with comprehension.
In this situation quotients come for free.
Proof By Proposition 88 we only have to prove that a Boolean eﬀectus B with
comprehension is extensive. From Proposition 61 we know that all predicates
are sharp and form Boolean algebras.
For a predicate p on X we have the map asrtp : X →X with ker⊥(asrtp) = p.
In a Boolean eﬀectus we have:
asrt✷
p (p) =
 p⊥
asrtp
⊥=
 1
asrtp⊥
asrtp
⊥=
 1
0
⊥= 1.
We then have a factorisation in Par(B) of the form:
{X|p}
 ‹πp›

X
ξp⊥
3
asrtp
/ X
The notation ξ for these maps is deliberate, because they yield quotients. But
ﬁrst we show that:
ξp⊥
‹πp› = id
and
ξp⊥
‹πp⊥› = 0.
(∗)
The proof uses that ‹πp› is monic in Par(B):
‹πp›
ξp⊥
‹πp› = asrtp
‹πp›
= κ1 ◦π1
by Lemma 85
= ‹πp›
‹πp›
ξp⊥
‹πp⊥› = asrtp
‹πp⊥›
= 0
by Lemma 85
= ‹πp›
0.
We now show that ξp⊥: X →{X|p} is a quotient map, where {X|p} is the
quotient object X/p⊥. First we have:
ker(ξp⊥) =
 1
ξp⊥
⊥=
 1
‹πp›
ξp⊥
⊥=
 1
asrtp
⊥= p⊥.
Next, if f : X →Y satisﬁes p⊥≤ker(f), then:
1
f
asrtp⊥= ker⊥(f)
asrtp⊥≤p
asrtp⊥
= 1
asrtp
asrtp⊥= 1
0 = 0.
This gives f
asrtp⊥= 0, by Lemma 7, and thus:
f = f
id = f
(asrtp > asrtp⊥) = (f
asrtp) > (f
asrtp⊥) = f
asrtp.
112

We obtain f = f ◦πp : {X|p} →Y as mediating map, since:
f
ξp⊥= f
‹πp›
ξp⊥= f
asrtp = f.
This map f is unique, since if g : {X|p} →Y also satisﬁes g
ξp⊥= f, then:
f = f
‹πp› = g
ξp⊥
‹πp›
(∗)
= g
id = g.
Now that we have quotient maps we can form the total ‘decomposition’ map
dcp = ⟨⟨ξp⊥, ξp⟩⟩: X →{X|p} + {X|p⊥} from Lemma 83 (7). We claim that
this map dcp is an isomorphism, with the cotuple [πp, πp⊥] as inverse. We ﬁrst
prove dcp ◦πp = κ1 and dcp ◦πp⊥= κ2 by using (11):
dcp ◦πp = ⟨⟨ξp⊥, ξp⟩⟩◦πp = ⟨⟨ξp⊥◦πp, ξp ◦πp⟩⟩
(∗)
= ⟨⟨κ1, 0⟩⟩= ⟨⟨✄1 ◦κ1, ✄2 ◦κ1⟩⟩= κ1
dcp ◦πp⊥= ⟨⟨ξp⊥, ξp⟩⟩◦πp⊥= ⟨⟨ξp⊥◦πp, ξp ◦πp⊥⟩⟩
(∗)
= ⟨⟨0, κ1⟩⟩= ⟨⟨✄1 ◦κ2, ✄2 ◦κ2⟩⟩= κ2.
At this stage we can prove one part of the claim that the decomposition map
dcp is an isomorphism:
dcp ◦[πp, πp⊥] = [dcp ◦πp, dcp ◦πp⊥] = [κ1, κ2] = id.
For the other direction, we take b = κ1 ◦(πp + πp⊥) ◦dcp : X →X + X and
claim that b is a bound for the pair of maps asrtp, asrtp⊥: X →X. This is the
case, since:
✄1
b = (id + !) ◦(πp + πp⊥) ◦dcp = (πp + id) ◦(id + !) ◦dcp
= (πp + id) ◦ξp⊥
= asrtp
✄2
b = [κ2 ◦!, κ1] ◦(πp + πp⊥) ◦dcp = [κ2, κ1 ◦πp⊥] ◦(! + id) ◦dcp
= [κ2, κ1 ◦πp⊥] ◦[κ2, κ1] ◦ξp
= (πp⊥+ id) ◦ξp
= asrtp⊥.
Since the assert map is a homomorphism of eﬀect algebras we have:
κ1 = asrtp > asrtp⊥= (∇+ id) ◦b = κ1 ◦∇◦(πp + πp⊥) ◦dcp
= κ1 ◦[πp, πp⊥] ◦dcp.
But then [πp, πp⊥] ◦dcp = id, making dcp an isomorphism, as required.
We are ﬁnally in a position to show that the eﬀectus B is an extensive
category, see Deﬁnition 86. Let f : Z →X +Y be an arbitrary map in B. Write
113

p = (! + !) ◦f : Z →1 + 1, and consider the following diagram.
{Z|p} /
πp
/


❴✤
Z
f

{Z|p⊥}
o
πp⊥
o


✤❴
Y
/
κ1
/

❴✤
Y + Z
!+!

Z
o
κ2
o

✤❴
1 /
κ1
/ 1 + 1
1
o
κ2
o
The two lower pullbacks exist because B is an eﬀectus. The two outer ones, with
the curved arrows, exist because B has comprehension. The two upper squares,
with the dashed arrows are then pulbacks by the Pullback Lemma. Thus, the
pullbacks along f of the coprojections Y →Y +Z ←Z exist. Moreover, we have
just seen that the cotuple [πp, πp⊥] of the pulled-back maps is an isomorphism.
This is one part of Deﬁnition 86.
For the other part, consider a similar diagram where the top row is already
a coproduct diagram:
Z1
f1

/ κ1
/ Z1 + Z2
f

Z2
f2

o
κ2
o
X /
κ1
/ X + Y
Y
o
κ2
o
Then:
f = f ◦[κ1, κ2] = [f ◦κ1, f ◦κ2] = [κ1 ◦f1, κ2 ◦f2] = f1 + f2.
But the above two rectangles are then pullbacks by Lemma 3 (1).
□
We thus see that a Boolean eﬀectus with comprehension corresponds to the
well-established notion of extensive category. It is an open question whether
there is a similar alternative notion for a commutative eﬀectus, capturing prob-
abilistic computation.
Each topos is an extensive category, and thus an eﬀectus. Notice that in
a topos-as-eﬀectus the predicates are the maps X →1 + 1, and not the more
general predicates X →Ω, where Ωis the subobject classiﬁer. There are many
extensive categories that form interesting examples of eﬀectuses, such as: the
category Top of topological spaces, and it subcategory CH ֒→Top of com-
pact Hausdorﬀspaces; the category Meas of measurable spaces; the opposite
CRngop of the category of commutative rings, see [CJWW15].
14
Combining comprehension and quotients
In previous sections we have studied comprehension and quotients separately.
We now look at the combination, and derive some more results. First we need
the following observation.
114

Lemma 90. Let C be an eﬀectus in partial form which has comprehension and
also has quotients. Write for a predicate p on an object X ∈C:
{X|p}
θp
def
= ξp⊥◦πp
/ X/p⊥
(57)
Then:
1. this map θp is total;
2. if θp is an isomorphism, then p is sharp.
Proof The ﬁrst point is easy: θp is total by Lemma 80 (1) and Lemma 83 (1):
1 ◦θp = 1 ◦ξp⊥◦πp = ker⊥(ξp⊥) ◦πp = p ◦πp = 1.
For the second point let θp be an isomorphism, and let q ∈Pred(X) satisfy
q ≤p and q ≤p⊥. In order to prove that p is sharp, we must show q = 0. From
p⊥≤q⊥= ker(q) we get a predicate q/p in Pred(X/p⊥) with q/p ◦ξp⊥= q, see
Lemma 83 (12). Then:
q/p = q/p ◦θp ◦θ−1
p
= q/p ◦ξp⊥◦πp ◦θ−1
p
= q ◦πp ◦θ−1
p
≤p⊥◦πp ◦θ−1
p
= 0 ◦θ−1
p
= 0.
Hence q = q/p ◦ξp⊥= 0 ◦ξp⊥= 0.
□
We now consider the condition which enforces an equivalence in the above
second point.
Deﬁnition 91. We say that an eﬀectus in partial form has both quotients and
comprehension if it has comprehension, like in Deﬁnition 76 (2), and quotients,
like in Deﬁnition 81, such that for each sharp predicate p ∈Pred(X) the total
map θp : {X|p} →X/p⊥in (57) is an isomorphism.
We then deﬁne, for each such sharp p ∈Pred(X) the map:
asrtp
def
=

X
ξp⊥/ / X/p⊥
θ−1
p
∼
=
/ {X|p} / πp
/ X

.
(58)
Example 92. We brieﬂy illustrate the map θp : {X|p} →X/p⊥from (57) in
our running examples.
In the eﬀectus Sets we have for a predicate P ⊆X {X|P} = P and also
Q/P ⊥= {X|P ⊥⊥} = P. The map θ is the identity, and is thus always an
isomorphism. Indeed, in this Boolean eﬀectus Sets every predicate is sharp.
More generally, consider an extensive category B with ﬁnal object, as a
Boolean eﬀectus with both comprehension and quotients, see Theorem 89. The
quotient that is constructed in the proof is of the form ξp⊥: X →{X|p}. Hence
we have θp = id : {X|p} →X/p⊥.
In the eﬀectus Kℓ(D) we have for a predicate p ∈[0, 1]X an inclusion:
{X|p} = {x | p(x) = 1}  
θp
/ {x | p(x) > 0} = X/p⊥
115

When p is sharp, we have p(x) ∈{0, 1}, so that θp is the identity.
Next we consider the eﬀectus OUGop of order unit groups. For an eﬀect
e ∈[0, 1]G in an order unit group G we have a map (in the opposite direction):
G/e⊥= ⟨e⟩G
θe
/ G/⟨e⊥⟩G = {G|e}
x ✤
/ x + ⟨e⊥⟩G
This map is unital since:
θe(1G/e⊥) = e + ⟨e⊥⟩G = e + e⊥+ ⟨e⊥⟩G = 1 + ⟨e⊥⟩G = 1{G|e}.
It can be shown that this map θe is an isomorphism for sharp e, if one assumes
that G satisﬁes interpolation, see [Goo86] for details.
Finally, in our eﬀectus vNAop of von Neumann algebras we also have, for
an eﬀect e ∈[0, 1]A , a map of the form:
A /e⊥= ⌈e⌉A ⌈e⌉
θe
/ ⌊e⌋A ⌊e⌋= {A |e}
x ✤
/ x
This map is well-deﬁned since ⌈e⌉· ⌊e⌋= ⌈e⌉= ⌊e⌋· ⌈e⌉, using a more general
fact: a ≤⌈e⌉⇒a · ⌈e⌉= a = ⌈e⌉· a.
In case e is sharp we get ⌈e⌉= e = ⌊e⌋, so that the above map θe is an
isomorphism.
We collect some more results about the maps θ. Since these maps are total,
we switch to the total perspective.
Lemma 93. Let eﬀectus in total form B have quotients and comprehension.
1. For each predicate p ∈Pred(X) the two squares below are pullbacks in B.
X/p⊥

κ1

{X|p}
θp
o
!
/

πp

1
κ2

X/p⊥+ 1
X
ξp⊥
o
ξp
/ X/p + 1
(59)
2. For each predicate p on X, the following triangle commutes.
{X|p} + {X|p⊥}
[πp,πp⊥]
&▼
▼
▼
▼
▼
▼
▼
▼
▼
θp+θp⊥/ X/p⊥+ X/p
X
dcp
9t
t
t
t
t
t
t
t
(60)
Thus, for sharp p the decomposition map dcp is a split epi, and the cotuple
[πp, πp⊥] is a split mono, in B.
3. The maps θ commute with the distributivity isomorphisms from Lemma 79 (9)
and Lemma 83 (10), as in:
{X|p} + {Y |q}
≀
θX+θY
/ X/p⊥+ Y/q⊥
≀
{X + Y | [p, q]}
θ[p,q]
/ (X + Y )/[p, q]⊥= (X + Y )/[p⊥, q⊥]
116

Proof Recall that we are in an eﬀectus in total form.
1. The left square in (59) commutes because θp is total. It forms a pullbacks
since if f : Y →X/p⊥and g : Y →X satisfy κ1 ◦f = ξp⊥◦g, then g
factors uniquely as g = πp ◦g since:
g∗(p) = p ◦g = ker⊥(ξp⊥) ◦g = (! + id) ◦ξp⊥◦g
= (! + id) ◦κ1 ◦θp
= κ1 ◦! ◦θp
= κ1 ◦!
= 1.
Then θp ◦g = f because the coprojection κ1 is monic:
κ1 ◦θp ◦g = ξp⊥◦πp ◦g = ξp⊥◦g = κ1 ◦f.
The rectangle on the right in (59) commutes by Lemma 7 since:
(! + id) ◦ξp ◦πp = ker⊥(ξp) ◦πp = p⊥◦πp = 0.
It is a pullback: if f : Y →X satisﬁes ξp ◦f = κ2 ◦! = 0, then f factors
uniquely through πp since:
f ∗(p) = p ◦f = ker(ξp) ◦f = [κ2, κ1] ◦(! + id) ◦ξp ◦f
= [κ2, κ1] ◦(! + id) ◦κ2 ◦!
= κ1 ◦!
= 1.
2. We use the commuting rectangles (59) and the equations (11) to get:
dcp ◦πp = ⟨⟨ξp⊥, ξp⟩⟩◦πp = ⟨⟨ξp⊥◦πp, ξp ◦πp⟩⟩
= ⟨⟨κ1 ◦θp, 0⟩⟩
= ⟨⟨✄1 ◦κ1 ◦θp, ✄2 ◦κ1 ◦θp⟩⟩= κ1 ◦θp
dcp ◦πp⊥= ⟨⟨ξp, ξp⊥⟩⟩◦πp⊥= ⟨⟨ξp ◦πp⊥, ξp⊥◦πp⊥⟩⟩
= ⟨⟨0, κ1 ◦θp⊥⟩⟩
= ⟨⟨✄1 ◦κ2 ◦θp⊥, ✄2 ◦κ2 ◦θp⊥⟩⟩= κ2 ◦θp⊥.
Hence we see that the triangle (60) commutes:
dcp ◦[πp, πp⊥] = [dcp ◦πp, dcp ◦πp⊥] = [κ1 ◦θp, κ2 ◦θp⊥] = θp + θp⊥.
3. We show that the composite:
{X + Y | [p, q]}
ϕ
∼
= / {X|p} + {Y |q}
θX+θY/ X/p⊥+ Y/q⊥ψ
∼
= / (X + Y )/[p, q]⊥
117

satisﬁes the equation that deﬁnes θ[p,q] as κ1 ◦θ[p,q] = ξ[p,q]⊥◦π[p,q].
κ1 ◦ψ ◦(θp + θq) ◦ϕ
= (ψ + id) ◦κ1 ◦[κ1 ◦θp, κ2 ◦θq] ◦ϕ
= (ψ + id) ◦[(κ1 + id) ◦κ1 ◦θp, (κ2 + id) ◦κ1 ◦θq] ◦ϕ
= (ψ + id) ◦[(κ1 + id) ◦ξp⊥◦πp, (κ2 + id) ◦ξq⊥◦πq] ◦ϕ
= (ψ + id) ◦[(κ1 + id) ◦ξp⊥, (κ2 + id) ◦ξq⊥] ◦(πp + πq) ◦ϕ
= (ψ
(ξp + ξq)) ◦π[p,q]
= ξ[p,q] ◦π[p,q].
□
We continue with properties of the assert map (58) for sharp predicates
p. We have seen ‘assert’ maps in Section 9 as inverse of the kernel-supplement
map ker⊥: End≤id(X) →Pred(X). This isomorphism of eﬀect algebras is a key
aspect of commutative eﬀectuses (including Boolean ones). The assert map (57)
in this section is at the same time more general and also more restricted: it is
not necessarily side-eﬀect free, that is, below the identity, nor a map of eﬀect
algebras; and it is deﬁned only for sharp predicates.
Lemma 94. Let (C, I) be an eﬀectus with quotients and comprehension, in
partial form. Let p be a sharp predicate on X ∈C.
1. asrtp ◦asrtp = asrtp and asrtp ◦asrtp⊥= 0.
2. ker(asrtp) = p⊥, and so ker⊥(asrtp) = p.
3. asrt0 = 0 and asrt1 = id.
4. For each f : X →Y one has:
p⊥≤ker(f) ⇐⇒f ◦asrtp = f.
5. The following two diagrams are equalisers in C.
{X|p⊥} /
πp⊥/ X
asrtp )
0
6 X
{X|p} / πp / X
asrtp )
id
6 X
6. Similarly, the next diagram is a coequaliser.
X
asrtp )
id
6 X
ξp⊥/ / X/p⊥
7. Let f : X →X be a side-eﬀect free endomap, that is f ≤idX in the
poset End≤id(X) of endomaps on X below the identity. If the predicate
p = ker⊥(f) = 1 ◦f is sharp, then f = asrtp.
Moreover, in that case the decomposition map dcp from Lemma 83 (7) is
a total isomorphism:
X
dcp
∼
=
/ X/p⊥+ X/p
118

Proof Recall that asrtp = πp ◦θ−1
p
◦ξp⊥: X →X, see (58).
1. We compute:
asrtp ◦asrtp = πp ◦θ−1
p
◦ξp⊥◦πp ◦θ−1
p
◦ξp⊥
= πp ◦θ−1
p
◦θp ◦θ−1
p
◦ξp⊥
= πp ◦θ−1
p
◦ξp⊥
= asrtp
asrtp ◦asrtp⊥
= πp ◦θ−1
p
◦ξp⊥◦πp⊥◦θ−1
p⊥◦ξp
(59)
= πp ◦θ−1
p
◦0 ◦θ−1
p
◦ξp⊥
= 0.
2. Applying Lemma 39 (7) with the total map πp ◦θ−1
p
yields:
ker(asrtp) = ker
 πp ◦θ−1
p
◦ξp⊥

= ker(ξp⊥) = p⊥.
3. We have asrt0 = 0 since ker⊥(asrt0) = 0 and ker⊥reﬂects 0, see Lemma 40.
Further, there are isomorphisms X/0 ∼= X ∼= {X|1} by Lemma 83 (6) and
Lemma 79 (3). Hence:
asrt1 =

X
ξ0
∼
=
/ X/0
θ−1
1
∼
=
/ {X|1}
π1
∼
=
/ X

= id,
since by deﬁnition θ1 = ξ0 ◦π1, and so θ−1
1
= π−1
1
◦ξ−1
0 .
4. We need to prove the equivalence p⊥≤ker(f) ⇐⇒f ◦asrtp = f. This is
done in two steps.
• If p⊥≤ker(f), then we can write f = f ◦ξp⊥, so that:
f ◦asrtp = f ◦ξp⊥◦πp ◦θ−1
p
◦ξp⊥= f ◦θp ◦θ−1
p
◦ξp⊥
= f ◦ξp⊥
= f.
• And if f ◦asrtp = f, then by Lemma 39 (6),
ker(f) = ker(f ◦asrtp) ≥ker(asrtp) = p⊥.
5. The ﬁrst kernel map equaliser is an instance of Lemma 80 (2), since
ker(asrtp) = p⊥. For the other one, notice that:
asrtp ◦πp = πp ◦θ−1
p
◦ξp⊥◦πp = πp ◦θ−1
p
◦θp = πp.
And if f : Y →X satisﬁes asrtp ◦f = f, then f factors uniquely through
πp via the composite: θ−1
p
◦ξp⊥◦f : Y →{X|p}.
119

6. First,
ξp⊥◦asrtp = ξp⊥◦πp ◦θ−1
p
◦ξp⊥
(59)
= θp ◦θ−1
p
◦ξp⊥= ξp⊥.
Next, if f : X →Y satisﬁes f ◦asrtp = f, then p⊥≤ker(f) by point (4),
so that f = f ◦ξp⊥, for a necessarily uniqe f : X/p⊥→Y .
7. Let f : X →X satisfy f ≤id, say via f > g = id. Further, the predicate
p = ker⊥(f) = 1 ◦f is sharp, by assumption.
Then 1 ◦g = p⊥by
uniqueness of orthosupplements:
p > (1 ◦g) = 1 ◦(f > g) = 1 ◦id = 1.
As a result, 1◦g ◦πp = p⊥◦πp = 0, so that g ◦πp = 0 by Deﬁnition 51 (3).
Hence:
f ◦πp = (f ◦πp) > (g ◦πp) = (f > g) ◦πp = id ◦πp = πp.
By deﬁnition, p⊥= ker(f), so that there is a unique total map f : X/p⊥→
X with f = f ◦ξp⊥. But then:
πp = f ◦πp = f ◦ξp⊥◦πp = f ◦θp.
Hence f = πp ◦θ−1
p , using that p is sharp. Now we can conclude f =
f ◦ξp⊥= πp ◦θ−1
p
◦ξp⊥= asrtp. In a similar way one obtains g = asrtp⊥.
In this situation the decomposition map dcp = ⟨⟨ξp⊥, ξp⟩⟩: X →X/p⊥+
X/p is an isomorphism.
We already know that it has a right inverse
[πp, πp⊥] ◦(θ−1
p
+ θ−1
p⊥) by Lemma 93 (2). We also have:
[πp, πp⊥] ◦(θ−1
p
+ θ−1
p⊥) ◦dcp
= ∇◦(πp + πp⊥) ◦(θ−1
p
+ θ−1
p⊥) ◦⟨⟨ξp⊥, ξp⟩⟩
(12)
= ∇◦⟨⟨πp ◦θ−1
p
◦ξp⊥, πp⊥◦θ−1
p⊥◦ξp⟩⟩
= ∇◦⟨⟨asrtp, asrtp⊥⟩⟩
= f > g
= id.
□
If we add two more assumptions we can prove a lot more. At this stage we
start using images that are sharp.
Proposition 95. Let C be an eﬀectus with quotients and comprehension, in
partial form, which additionally:
• has sharp images
• and satisﬁes, for all sharp predicates p, q ∈Pred(X),
p ≤q
⇐⇒
{X|p}!
πp
!❈
❈
❈
/ {X|q}
}
πq
}④④④
X
(61)
120

Then we can prove the following series of results.
1. Take for an arbitrary predicate p,
⌊p⌋
def
=
im(πp)
and
⌈p⌉
def
=
⌊p⊥⌋⊥.
Then: ⌊p⌋is the greatest sharp predicate below p, and ⌈p⌉is the least sharp
predicate above p.
2. Let p ∈Pred(X). For each total map f : Y →X one has:
f ∗(p) = 1 ⇐⇒f ∗(⌊p⌋) = 1
and
f ∗(p) = 0 ⇐⇒f ∗(⌈p⌉) = 0. (62)
For an arbitrary map g : Y →X we have:
g✷(p) = 1 ⇐⇒g✷(⌊p⌋) = 1.
3. For a sharp predicate p ∈Pred(X), the map asrtp : X →X from (58)
satisﬁes im(asrtp) = p. Hence by Lemma 83 (14) we have a cokernel map:
X
asrtp )
0
6 X
ξp / / X/p
4. For f : X →Y and p ∈Pred(X) put:
P
f(p)
def
= im
 f ◦πp

.
Then there is an adjunction:
ShaPred(X)
P
f
-
⊥
ShaPred(Y )
⌊f ✷(−)⌋
m
(63)
where ShaPred describes the subposet of sharp predicates.
5. Comprehension maps π are closed under composition, up-to-isomorphism.
6. The posets ShaPred(X) ֒→Pred(X) of sharp predicates are orthomodular
lattices.
7. Comprehension maps π and internal epis form a factorisation system in
C.
Proof The fact that images are assumed to be sharp plays an important role.
1. By deﬁnition the image ⌊p⌋= im(πp): X →I is a sharp predicate. This
⌊p⌋is below p by minimality of images, and π✷
p (p) = (p⊥◦πp)⊥= 0⊥= 1.
If s ∈Pred(X) is sharp with s ≤p, then πs factors through π⌊p⌋since:
{X|s} %
πs
%❑
❑
❑
❑
❑
❑
❑
/ {X|p}

πp 
∼
= / {X|⌊p⌋}
x
π⌊p⌋
xqqqqqqqq
X
(64)
121

The dashed arrow exists since by deﬁnition π✷
p (⌊p⌋) = π✷
p (im(πp)) = 1.
Hence we get s ≤⌊p⌋by (61).
We now have ⌊p⊥⌋≤p⊥, and thus p ≤⌊p⊥⌋⊥= ⌈p⌉. If p ≤s, where s is
sharp, then s⊥≤p⊥, so that s⊥≤⌊p⊥⌋, and thus ⌈p⌉= ⌊p⊥⌋⊥≤s.
2. Let f : Y →X be a total map. If f ∗(⌊p⌋) = 1, then f ∗(p) = 1 since
⌊p⌋≤p. In the other direction, if f ∗(p) = 1, then f factors through πp.
But f then also factors through π⌊p⌋, by the isomorphism in Diagram (64),
so that f ∗(⌊p⌋) = 1.
We now get:
f ∗(p) = 0 ⇐⇒f ∗(p⊥) = f ∗(p)⊥= 1
⇐⇒f ∗(⌊p⊥⌋) = 1
as just shown
⇐⇒f ∗(⌈p⌉) = f ∗(⌊p⊥⌋⊥) = f ∗(⌊p⊥⌋)⊥= 0.
For an arbitrary map g : Y →X, if g✷(⌊p⌋) = 1, then g✷(p) = 1 since
g✷is monotone by Lemma 36. In the other direction, if g✷(p) = 1, then
im(g) ≤p by minimality of images, and thus im(g) ≤⌊p⌋by point (1).
But then 1 = g✷(im(g)) ≤g✷(⌊p⌋).
3. For a sharp predicate p we have:
im(asrtp) = im(πp ◦θ−1
p
◦ξp⊥) = im(πp)
by Lemma 47 (6), (11)
= ⌊p⌋
= p
since p is sharp.
4. Let f : X →Y be an arbitrary map. We need to prove for sharp predicates
p ∈Pred(X) and q ∈Pred(Y ),
P
f(p) = im(f ◦πp) ≤q ⇐⇒p ≤⌊f ✷(q)⌋.
This works in the following way.
• Let P
f(p) = im(f ◦πp) ≤q. We have:
1 = (f ◦πp)✷(im(f ◦πp)) ≤(f ◦πp)✷(q) = π✷
p
 f ✷(q)

.
This implies that we have a map {X|p} →{X|f ✷(q)} commuting
with the projections.
We thus get p ≤f ✷(q) by (61), and thus
p ≤⌊f ✷(q)⌋.
• In the other direction, let p ≤⌊f ✷(q)⌋≤f ✷(q). Then:
1 = π✷
p (p) ≤π✷
p
 f ✷(q)

= (f ◦πp)✷(q).
But then P
f(p) = im(f ◦πp) ≤q by minimality of images.
122

5. For two sharp predicates p ∈Pred(X) and q ∈Pred({X|p}) consider the
sharp predicate on X given by:
P
πp(q) = im(πp ◦πq).
Notice that by Lemma 47 (4),
P
πp(q) = im(πp ◦πq) ≤im(πp) = ⌊p⌋= p.
(∗)
We are done if we can show that there are necessarily unique maps ϕ, ψ
in a commuting square:
{{X|p}|q}

πq

ϕ
-
∼=
{X| P
πp(q)}
 πP
πp (q)

ψ
m
{X|p} /
πp
/ X
The existence of the map ϕ is easy since comprehension maps are total
and thus:
1 = (πp ◦πq)✷ im(πp ◦πq)

= (πp ◦πq)∗  P
πp(q)

.
In order to show the existence of the map ψ we use ad hoc notation for:
p ⊓q =

X
ξp⊥/ X/p⊥
θ−1
p
∼
=
/ {X|p}
q
/ I

Then:
π∗
p(p ⊓q) = (p ⊓q) ◦πp = q ◦θ−1
p
◦ξp⊥◦πp = q ◦θ−1
p
◦θp = q.
And thus:
(πp ◦πq)✷(p ⊓q) = (πp ◦πq)∗(p ⊓q) = π∗
q
 π∗
p(p ⊓q)

= π∗
q(q) = 1.
The latter yields P
πp(q) = im(πp ◦πq) ≤p ⊓q by minimality of images.
We now go back to the inequality P
πp(q) ≤p from (∗). It gives a total
map f : {X| P
πp(q)} →{X|p} with πp ◦f = πP
πp(q). This f factors
through πq, and thus restricts to the required map ψ, since:
f ∗(q) = q ◦f = q ◦θ−1
p
◦θp ◦f
= q ◦θ−1
p
◦ξp⊥◦πp ◦f
= (p ⊓q) ◦πP
πp(q)
≥P
πp(q) ◦πP
πp(q)
= 1.
123

6. We ﬁrst show how to obtain conjunction ∧for sharp predicates.
For
p, q ∈ShaPred(X) deﬁne:
p ∧q = P
πp π∗
p(q) = im
 πp ◦π∗
p(q)

.
Since projections are closed under pullback — see Lemma 79 (5) — we
have a total isomorphism ϕ between two pullbacks in:
{{X|p}|π∗
p(q)}
ϕ
∼
=
*
ππ∗p(q)
*
(
{{X|q}|π∗
q(p)}
/
 ππ∗q (p)

{X|p}

πp

{X|q} /
πq
/ X
Hence we can prove that p ∧q is a lower bound of both p and q via
Lemma 47 (4):
p ∧q = im
 πp ◦π∗
p(q)

≤im(πp) = ⌊p⌋= p
p ∧q = im
 πp ◦π∗
p(q)

= im
 πq ◦π∗
q(p) ◦ϕ

≤im(πq) = ⌊q⌋= q.
We show that p∧q is the greatest lower bound in ShaPred(X): inequalities
r ≤p and r ≤q yield maps f : {X|r} →{X|p} and g : {X|r} →{X|q}
with πp ◦f = πr = πq ◦g. The above pullback gives a mediating map
h: {X|r} →{{X|p}|π∗
p(q)} with ππ∗p(q) ◦h = f. But then we are done:
r = ⌊r⌋= im(πr) = im(πp ◦f) = im(πp ◦ππ∗p(q) ◦h)
≤im(πp ◦ππ∗p(q))
= p ∧q.
We now also have joins p ∨q in ShaPred(X) via De Morgan: p ∨q =
(p⊥∧q⊥)⊥. We prove the orthomodularity law in the following way. Let
p ≤q; we have to prove p ∨(p⊥∧q) = q. This is done essentially as
in [HJ10, Prop. 1].
p ∨(p⊥∧q) = (p ∧q) ∨(p⊥∧q)
= P
πq(p) ∨P
πq(p⊥)
= P
πq(p ∨p⊥)
since P
πp is left adjoint, see (63)
= P
πq(1)
since p is sharp
= P
πq(π∗
q(1))
= q ∧1
= q.
7. We ﬁnally have to show that comprehension maps form the ‘abstract
monos’ in a factorisation system, with internal epis as ‘abstract epis’.
124

We recall the factorisation from Lemma 80 (5):
X
f
/
ie(f)
(
Y
{Y |im(f)}
6
πim(f)
=
The map ie(f) is the ‘internal epi’ part of f. Let p: {Y |im(f)} →I be a
predicate with ie(f)✷(p) = 1. If we can show that p = 1, then we know
that the map ie(f) is indeed internally epic. First we have:
0 = ie(f)✷(p)⊥= p⊥◦ie(f) = p⊥◦θ−1
im(f) ◦θim(f) ◦ie(f)
= p⊥◦θ−1
im(f) ◦ξim⊥(f) ◦πim(f) ◦ie(f)
= p⊥◦θ−1
im(f) ◦ξim⊥(f) ◦f.
Lemma 47 (3) then yields:
p⊥◦θ−1
im(f) ◦ξim⊥(f) ≤im⊥(f).
But we also have, by Lemma 83 (3),
p⊥◦θ−1
im(f) ◦ξim⊥(f) ≤im⊥(f)⊥= im(f).
Since images are sharp, by deﬁnition, we obtain:
p⊥◦θ−1
im(f) ◦ξim⊥(f) = 0.
The fact that the map θ−1
im(f) ◦ξim⊥(f) is epic — see Lemma 83 (2) —
yields p⊥= 0, and thus p = 1, as required.
There are a few more requirements of a factorisation system that we need
to check: the internal epis are closed under composition, by Lemma 47 (9);
the comprehension maps are closed under composition, by point (5). We
show that an internally epic comprehension map is an isomorphism. Let
πp be internally epic, that is, 1 = im(πp) = ⌊p⌋, so that π⌊p⌋= π1 is an
isomorphism by Lemma 79 (3). But πp is then an isomorphism too, by
the isomorphism in (64).
Finally we have to check that the diagonal-ﬁll-in property holds: in a
commuting rectangle as below, we need a diagonal.
Y
f
internal epi
/
g

Z
h

w
{X|p} /
πp
/ X
We are done if we can show that h factors through πp, that is, if h✷(p) = 1.
By Lemma 47 (10) this is equivalent to f ✷ h✷(p)

= 1. But:
f ✷ h✷(p)

= g✷ π✷
p (p)

= g✷(1) = 1.
□
125

As a result of points (4) and (6) in Proposition 95 the assignment X 7→
ShaPred(X) gives a functor C →OMLatGal, where OMLatGal is the dagger
kernel category of orthomodular lattices, with Galois connections between them,
as used in [Jac10b] (see also [HJ10]).
Remark 96. In an eﬀectus as considered in Proposition 95 we have two fac-
torisation systems, namely:
• the one with internal monos and quotient maps ξ from Proposition 84;
• the one with comprehension maps π and internal epis from Propostion 95 (7).
The question is how they are related. What is called the ‘ﬁrst isomorphism
theorem’ gives an answer. This ‘theorem’ is the familiar phenomenom, that can
be expressed informally as X/ ker(f) ∼= im(f), for each map f : X →Y . It
holds for many algebraic structures. However, this ‘theorem’ does not hold in
eﬀectuses, in general.
Abstractly this isomorphism is obtained via a canonical map from the ‘coim-
age’ to the ‘image’, which is then an isomorphism. In the setting of an eﬀectus
(in partial form), this canonical map is the dashed one described in the following
diagram — which is the same as diagram (2) in [Gra92] for the ideal of zero
maps.
{X| ker(f)} / πker(f) / X
f
+
0
3
ξ⌊ker(f)⌋
Y
ξim(f) / / Y/im(f)
X/⌊ker(f)⌋
/ {Y |im(f)}
O
πim(f)
O
We brieﬂy explain this diagram, starting on the right.
• The map ξim(f) is the cokernel of f, see Lemma 83 (14). The upgoing
projection πim(f) is its kernel map, because ker(ξim(f)) = im(f).
• On the left, the projection πker(f) is the kernel map of f, see Lemma 80 (2).
Its cokernel is the downgoing map ξ⌊ker(f)⌋since im(πker(f)) = ⌊ker(f)⌋.
The dashed arrow exist, because the evident maps X/⌊ker(f)⌋→Y and X →
{Y |im(f)} restrict appropriately.
This canonical dashed map is in general not an isomorphism. For instance,
for a partial map f : X →D(Y + 1) in the Kleisli category of the distribution
monad D we have:
X/⌊ker(f)⌋= {x ∈X | ⌊ker(f)⌋< 1}
= {x ∈X | ker(f) = 0}
= {x ∈X | f(x)(∗) = 0}
{Y |im(f)} = {y ∈Y | im(f)(y) = 1}
= {y ∈Y | ∃x ∈X. f(x)(y) > 0}.
The canonical map X/⌊ker(f)⌋→{Y |im(f)} in the above diagram is given by
x 7→P
y,f(x)(y)>0 f(x)(y)
y

, which is not an isomorphism.
126

More generally, a total internally epic map need not be an isomorphism. The
situation is reminiscent of Quillen model categories as used in homotopy theory
(see [Qui67]), where one has two factorisation systems, and mediating maps
like the dashed one above which are not necessarily isomorphisms. However, in
model categories the relevant classes of maps satisfy closure properties which
do not hold here.
We have already hinted a few times that an eﬀectus, in partial form, is
similar to, but more general, and less well-behaved, than an Abelian category.
For such an Abelian category A we do have a quotient-comprehension chain:
Sub(A)
⊣
⊣

⊣
Quotient
(U֌X)7→X/U
*
⊣
Comprehension
(U֌X)7→U
t
A
0
>
1
`
Quotients are obtained via cokernels: for a subobject m: U ֌ X one takes the
codomain of the cokernel coker(m): X ։ X/U as quotient unit. In such an
Abelian category the ﬁrst isomorphism theorem does hold.
The general theory that we are after will bear some resemblance to recent
work in (non-Abelian) homological algebra, see in particular [Wei14], where ad-
junction chains like above are studied, but also [Jan94, Gra12]. There, part
of the motivation is axiomatising the category of (non-Abelian) groups, follow-
ing [Mac50]. As a result, stronger properties are used than occur in the current
setting, such as the ﬁrst isomorphism theorem and left adjoints to substitution,
corresponding to biﬁbrations, which do not hold in general here.
We still have to check that the assumptions in Proposition 95 make sense.
This concentrates on the equivalence in (61) saying that for sharp predicates
p, q one has p ≤q iﬀπp ≤πq, that is, πp factors through πq. We check this for
the eﬀectus examples Sets — in fact, more generally, for Boolean eﬀectuses —
for Kℓ(D), and vNAop.
This equivalence (61) obviously holds in the eﬀectus Sets, since the com-
prehension of a predicate P ⊆X is given by P itself. It is less trivial that
the equivalence (61) also holds for Boolean eﬀectuses / extensive categories, see
Theorem 89. Recall that all predicates are automatically sharp in the Boolean
case, see Lemma 59 (1).
Lemma 97. Let A be an extensive category, understood as a Boolean eﬀectus
with comprehension. Then p ≤q iﬀπp ≤πq for all predicates p, q on the same
object.
Proof We proceed in two steps, where we ﬁrst prove that πp ≤πq implies
πq⊥≤πp⊥, and only then that it also implies p ≤q.
So let πp ≤πq, say via a (necessarily unique) map ϕ: {X|p} →{X|q} with
πq ◦ϕ = πp.
1. We ﬁrst need to produce a map {X|q⊥} →{X|p⊥} commuting with the
127

projections. Consider the following diagram in A.
A /
g1
/
f1

❴✤
{X|q⊥}
 πq⊥

B
o
g2
o
f2

✤❴
X
[πp,πp⊥]−1
∼
= 
{X|p} /
κ1
/ {X|p} + {X|p⊥}
{X|p⊥}
o
κ2
o
We now have a situation:
A
f1 
g1
'
∼
=
&
{X|p}
ϕ
+
0
/

❴✤
{X|q⊥}
 πq⊥

{X|q} /
πq
/ Y + 1
The outer diagram commutes since:
πq⊥◦g1 = [πp, πp⊥] ◦[πp, πp⊥]−1 ◦πq⊥◦g1
= [πp, πp⊥] ◦κ1 ◦f1
= πp ◦f1
= πq ◦ϕ ◦f1.
Thus, A ∼= 0, since 0 is strict, by Lemma 87 (1).
Since the cotuple
[g1, g2]: A + B →{X|q⊥} is an isomorphism, we obtain that g2 : B →
{X|q⊥} is an isomorphism. But then f2 ◦g−1
2
: {X|q⊥} →{X|p⊥} is the
required map, since:
πp⊥◦f2 ◦g−1
2
= [πp, πp⊥] ◦κ2 ◦f2 ◦g−1
2
= [πp, πp⊥] ◦[πp, πp⊥]−1 ◦πq⊥
= πq⊥.
2. Our second aim is to prove p ≤q, assuming πp ≤πq via the map ϕ. We
deﬁne a predicate r = ···
··✴✴✎✎✎✎◦((p◦πq)+!)◦[πq, πq⊥]−1 : X →1+1, and claim
that p > r = q. This proves p ≤q.
As bound b: X →(1 + 1) + 1 we take b = ((p ◦πq) + !) ◦[πq, πq⊥]−1. Then
···
··✴✴✎✎✎✎◦b = r holds by construction. We have:
···
··✎✎◦b = [id, κ2] ◦((p ◦πq) + !) ◦[πq, πq⊥]−1
= [p ◦πq, κ2 ◦!] ◦[πq, πq⊥]−1
= p.
The last equation follows from:
[p ◦πq, κ2 ◦!] = p ◦[πq, πq⊥]
and thus from
p ◦πq⊥= 0.
128

As just shown we have πq⊥≤πp⊥, say via a map ψ. Then:
p ◦πq⊥= p ◦πp⊥◦ψ = 0 ◦ψ = 0.
We now obtain:
p > r = (∇+ id) ◦b = (∇+ id) ◦((p ◦πq) + !) ◦[πq, πq⊥]−1
= ((! ◦πq) + !) ◦[πq, πq⊥]−1
= (! + !) ◦[πq, πq⊥]−1
= q,
where the latter equation holds since:
q ◦[πq, πq⊥] = [q ◦πq, q ◦πq⊥] = [κ1 ◦!, κ2 ◦!] = ! + !.
□
Example 98. In the eﬀectus Kℓ(D) we have p ≤q iﬀπp ≤πq for sharp p, q.
Recall from Example 77 (2) that {X|p} = {x | p(x) = 1}, where p(x), q(x) ∈
{0, 1} because p, q are sharp. Let πp ≤πq, say via a function ϕ: {X|p} →
D({X|q}) with πq ◦ϕ = πq. We have to prove p(x) = 1 ⇒q(x) = 1. So assume
p(x) = 1, so that x ∈{X|p}. Write ϕ(x) = P
i ri|xi ⟩with xi ∈{X|q}. The
equation πp = πq ◦ϕ yields:
1|x⟩= πp(x) =
 πq ◦ϕ

(x) = P
i ri|xi ⟩.
This can only happen if ϕ(x) = 1|x⟩, so that x ∈{X|q}. Hence q(x) = 1.
Before showing the equivalence (61) for von Neumann we give a general order
result.
Lemma 99. Let A be a von Neumann algebra with eﬀects a, p ∈[0, 1]A . If p
is a projection (i.e. is sharp), then the following are equivalent.
1. a ≤p
2. ap = a
3. pa = a
4. pap = a
In particular, if a ≤p, then a and p commute.
Proof We will prove (1) ⇒(2) ⇒(3) ⇒(4) ⇒(1). Without loss of generality,
we may assume A is a von Neumann algebra of operators on a Hilbert space H .
(1) ⇒(2) Assume a ≤p. By deﬁnition, ⟨av | v⟩≤⟨pv | v⟩for all v ∈H .
Thus ∥√av∥2 = ⟨av | v⟩≤⟨pv | v⟩= ∥pv∥2. Hence pv = 0 implies av = 0.
In particular, as p(1 −p)v = 0 we have a(1 −p)v = 0. We compute av =
apv + a(1 −p)v = apv. Hence a = ap.
(2) ⇒(3) Assume ap = a. Directly a = a∗= (ap)∗= p∗a∗= pa.
(3) ⇒(4) Assume pa = a. Clearly pap = ap = (pa)∗= a∗= a.
(4) ⇒(1) Assume pap = a. For any v ∈H , we have ⟨av | v⟩= ⟨papv | v⟩=
⟨apv | pv⟩≤⟨pv | pv⟩= ⟨p2v | v⟩= ⟨pv | v⟩. Consequently a ≤p.
□
129

Example 100. The equivalence (61), namely p ≤q iﬀπp ≤πq for sharp p, q,
also holds in the eﬀectus vNAop of von Neumann algebra. Let p, q ∈[0, 1]A be
sharp, that is, be projections, so that p · p = p and q · q = q. We ﬁrst prove that
im(πp) = p, and similarly for q. Since π✷
p (p) = 1 we always have im(πp) ≤p, so
we only have to prove ‘≥’.
Recall from Example 77 (4) that the projection πp is the map πp : A →pA p
in vNA given by p(x) = pxp. Here we use that p is sharp, and thus ⌊p⌋= p.
According to (29) the image of πp is given by:
im(πp) =
^
{s ∈A | s is a projection with πp(s) = psp = p = πp(1)}.
We thus need to prove s ≥p for a projection s with psp = p. Write t = s⊥=
1 −s, so that ptp = pp −psp = p −p = 0. Hence:
0 = ∥ptp∥= ∥pttp∥= ∥(pt) · (pt)∗∥= ∥pt∥2.
But then 0 = pt = p −ps, so that ps = s. Hence p ≤s by Lemma 99.
We can now reason abstractly: if πp ≤πq via a map ϕ: {X|p} →{X|q}
with πq ◦ϕ = πq in vNAop, then we are done by Lemma 47 (4):
p = im(πp) = im(πq ◦ϕ) ≤im(πq) = q.
This concludes the example.
15
Towards non-commutative eﬀectus theory
In the preceding sections we have presented the ﬁrst steps of the theory of eﬀec-
tuses. These sections provide a solid foundation. At this stage we have reached
the boundaries of what we know for sure. We add one more section that is of a
more preliminary nature. It contains a list of postulates for a class of eﬀectuses
that is intended to capture the essential aspects of von Neumann algebras. Al-
though this ‘axiomatisation’ is by no means ﬁxed, we do already have a name
for this notion, namely telos. It is an eﬀectus satisfying the postulates 102 –
105 below. Thus, we are the ﬁrst to admit that the notion of telos is poorly
deﬁned. But by making our current thoughts about this topic explicit, we hope
to generate more research, leading eventually to a properly deﬁned concept.
In the previous sections we have frequently associated a partial ‘assert’ map
asrtp : X →X + 1 with a predicate p: X →1 + 1.
This predicate-action
correspondence occurs for instance in:
• Deﬁnition 55 where the (unique) existence of assert maps as inverse of
kernel-supplements is the essence of the deﬁnitions of ‘commutative’ and
‘Boolean’ eﬀectus;
• Deﬁnition 91 where the map asrtp can be deﬁned, but only for a sharp
predicate p.
(Proposition 94 (7) says that when these two cases overlap, the relevant assert
maps coincide.)
These assert maps asrtp : X →X + 1 incorporate the side-eﬀect map asso-
ciated with a predicate p. This predicate-action correspondence is similar to
130

the situation in Hilbert spaces, where a projection may be described either as
a closed subset (a predicate), or as a function that projects all elements into
this subset (an ‘assert’ map). These assert maps express the dynamic character
of quantum computation. They incorporate the side-eﬀect of an observation, if
any. In the commutative (and Boolean) case the assert maps have no side-eﬀect
— technically, since such assert maps are below the identity. But in the proper
quantum case assert maps need not be below the identity. This is already clear
for the assert maps associated with sharp elements in Deﬁnition 91.
We thus have:
Situation
Question
Assert maps are fully deter-
mined
in
the
commutative
(and Boolean) case, and also
for sharp elements.
Can
we
also
deﬁne
assert
maps in general, in the non-
commutative non-sharp case,
via a certain property, or do
we have to assume them as
separate structure?
This question arises in particular in the eﬀectus vNAop of von Neumann alge-
bras.
Recall from Diagram (58) in Deﬁnition 91 that for a sharp predicate p the
associated assert map is deﬁned via:
asrtp =

X
ξp⊥/ / X/p⊥
θ−1
p
∼
=
/ {X|p} / πp / X

.
(65)
This deﬁnition relies on the assumption that the map θp = ξp⊥◦πp : {X|p} →
X/p⊥is an isomorphism when p is sharp. That assumption does not hold in
general, for non-sharp p.
Still, in the commutative eﬀectus Kℓ(D≤1), in partial form, we have, for
a fuzzy predicate p ∈[0, 1]X, an assert map asrtp : X →D≤1(X) given by
asrtp(x) = p(x)|x⟩.
Intruigingly, this assert map can also be described via
quotient and comprehension, as composite in Kℓ(D≤1) of the form:
X
ξp⊥/ X/p⊥= {x | p(x) > 0} = {X|⌈p⌉}
π⌈p⌉
/ X
x ✤
/ p(x)|x⟩✤
/ p(x)|x⟩
Here we use that there is an equality (or isomorphism) {X|⌈p⌉} →X/p⊥. The
map θp used above is a special case, since ⌈p⌉= p for a sharp predicate p.
It turns out that we can do the same for von Neumann algebras. For an eﬀect
e ∈[0, 1]A in a von Neumann algebra A we can deﬁne, formally in Par(vNAop),
asrte =

A
ξe
/ A /e⊥= ⌈e⌉A ⌈e⌉= ⌊⌈e⌉⌋A ⌊⌈e⌉⌋= {A |⌈e⌉}
π⌈e⌉/ A

The equality in the middle was already mentioned at the end of Example 82 (4).
As subunital map asrte : A →A this composite becomes:
asrte(a) = ξe⊥
 π⌈e⌉(a)

= ξe⊥
 ⌈e⌉a ⌈e⌉

= √e ⌈e⌉a ⌈e⌉√e
= √e a √e.
(66)
131

In this way we obtain L¨uders rule, see [BS98, Eq.(1.3)]. The problem of deﬁnin-
ing assert maps via comprehension and quotient is thus reduced to having an
isomorphism {X|⌈p⌉} ∼= X/p⊥. But: which isomorphism?
We have not found, in general, a canonically deﬁned isomorphism {X|⌈p⌉} ∼=
X/p⊥in an eﬀectus that gives rise to the canonical description (66) in the
eﬀectus of von Neumann algebras. This remains largely an unsolved problem,
although the situation is clearer in the special case of von Neumann algebras, see
Subsection 15.1 below. A related question is: is this apparent lack of canonicity
a ‘bug’ or a ‘feature’?
Accepting for the time being that there is no such canonical isomorphism
{X|⌈p⌉} ∼= X/p⊥, there are two possible ways forward.
1. Simply assume some isomorphism {X|⌈p⌉} ∼= X/p⊥and use it to deﬁne an
assert map as in (65), but with π⌈p⌉instead of πp. Then we can see which
requirements we need for this isomorphism in order to prove reasonable
properties about assert maps.
2. Simply assume maps asrtp : X →X + 1 satisfying some reasonable prop-
erties which induce an isomorphism {X|⌈p⌉} ∼= X/p⊥.
In the sequel we shall follow the second approach. We have already seen various
properties of assert maps — e.g. in Lemmas 57 and 94. Hence we can check
if they hold in the eﬀectus vNAop, and if so, use them as a basis for our
preliminary axiomatisation of what we call a telos.
(This same approach is followed in [Jac15a], where instrument maps instrp =
⟨⟨asrtp, asrtp⊥⟩⟩: X →X +X are assumed, satisfying certain properties, instead
of assert maps. But the diﬀerence between using instruments or assert maps is
inessential.)
Below we describe a number of postulates that together give a preliminary
description of the notion of telos. Each postulate contains a requirement, and
a short discussion about its rationale and consequences.
Postulate 101. Each telos is a monoidal eﬀectus with sharp images. We shall
describe it in partial form (with special object I, as usual).
In the sequel the monoidal structure, see Section 10, plays a modest role, but
it should be included since it is important for combining operations. Similarly,
images are a basic ingredient, see Subsection 7.2.
The next postulate introduces assert maps as actions that are associated with
predicates. Given such maps, we deﬁne an ‘andthen’ operation & on predicates,
as before: p & q = q ◦asrtp, for predicates p, q on the same object. In the
current general situation & is not commutative, like in Section 9.
Postulate 102. For each predicate p on an object X in a telos there is an
assert map asrtp : X →X such that:
1. ker(asrtp) = p⊥, or equivalently, ker⊥(asrtp) = p;
2. im(asrtp) = ⌈p⌉, where ⌈p⌉is the least sharp predicate above p;
3. if f ≤idX, then f = asrtp for p = ker⊥(f) = 1 ◦f;
4. asrt[p,q] = asrtp + asrtq : X + Y →X + Y for p ∈Pred(X), q ∈Pred(Y );
132

5. asrtp⊗q = asrtp ⊗asrtq : X ⊗Y →X ⊗Y , where p⊗q: X ⊗Y →I ⊗I ∼= I.
6. asrtp ◦asrtp = asrtp&p;
7. asrtp ◦f = f ◦asrtf ✷(p) for any predicate p and any map f : Y →X that
preserves sharp elements: f ✷(q) is sharp if q is sharp.
We check that these properties hold in our leading example of a telos: the
opposite vNAop of the category of von Neumann algebras.
Example 103. The eﬀectus vNAop of von Neumann algebras, with assert maps
given by asrtp(x) = √p x √p as in (66), satisﬁes the previous postulate. Clearly
our chosen asrtp map is subunital, linear and positive. It is also completely
positive [Sti55, Thm. 1] and normal [Sak71, Lem. 1.7.4].
See also appendix
of [WW15]. We cover the diﬀerent postulates one at a time.
1. Obviously, ker⊥(asrtp) = asrtp(1) = √p 1 √p = p.
2. From √p ⌈p⌉= √p we obtain √p ⌈p⌉⊥√p = 0 and thus ⌈p⌉⊥◦asrtp = 0.
But then asrt✷
p (⌈p⌉) = (⌈p⌉⊥◦asrtp)⊥= 1, and thus im(asrtp) ≤⌈p⌉by
minimality of images.
Now we prove the reverse inequality ⌈p⌉≤im(asrtp). Write b = im⊥(asrtp).
We have b ◦asrtp = 0 by Lemma 47 (3), so that asrtp(b) = 0 by (25).
That is: √p b √p = 0.
By the C∗-identity ∥b √p∥2 = ∥√p b √p∥= 0.
Hence b √p = 0. But then also √p b = (b √p)∗= 0. Thus p and b com-
mute. By (43) we obtain ⌈p⌉b = 0 = b ⌈p⌉. Since both ⌈p⌉and b are
sharp we obtain that the sum ⌈p⌉+ b is sharp too, and thus an eﬀect.
The latter yields ⌈p⌉+ b ≤1, and thus im⊥(asrtp) = b ≤⌈p⌉⊥. Conse-
quently ⌈p⌉≤im(asrtp) as desired.
3. In Example 56 (3) we have already shown that a subunital map f : A →A
with f ≤id is of the form f(x) = f(1) x, where the element f(1) ∈
[0, 1]A is central in A . Hence
p
f(1) is central too, so that the eﬀect
p = ker⊥(f) = f(1) satiesﬁes:
asrtp(x) =
p
f(1) x
p
f(1) = f(1) x = f(x).
4. Simply:
asrt[p,q](x, y) =
p
(p, q) (x, y)
p
(p, q)
= (√p x √p, √q y √q)
= (asrtp ⊕asrtq)(x, y).
5. The linear span of predicates p ⊗q is ultraweakly dense in A ⊗B, see
e.g. [Cho14, Prop. 4.5.3]. As our chosen asrt map is ultraweakly continuous
and linear, it is suﬃcient to show the equality for product-predicates:
asrtp⊗q(x ⊗y) = √p ⊗q (x ⊗y) √p ⊗q
= (√p ⊗√q) (x ⊗y) (√p ⊗√q)
= (√p x √p) ⊗(√q y √q)
= asrtp(x) ⊗asrtq(y)
= (asrtp ⊗asrtq)(x ⊗y).
133

For the last step, see e.g. [Cho14, Prop. 4.5.5].
6. Note that p & p = √p p √p = p2 and so:
asrtp(asrtp(x)) = √p √p x √p √p
= p x p
=
p
p2 x
p
p2 = asrtp&p(x).
7. A completely positive map f : A →B preserves projections if and only if
it is multiplicative. Hence if f is sharp, then it is a (unital) and preserves
multiplication and thus square roots too. Hence:
f ∗ asrtp(x)

= f
 √p x √p

=
p
f(p) f(x)
p
f(p) = asrtf ∗(p)
 f(x)

.
This concludes the example.
Point (1) allows us to deﬁne (total) instrument maps like in Lemma 57 (6):
X
instrp
def
= ⟨⟨asrtp,asrtp⊥⟩⟩
/ X + X
(67)
The side-eﬀect associated with the predicate p is the map ∇◦instrp : X →X.
We call p side-eﬀect free if this map ∇◦instrp is the identity. Also, it allows us
to deﬁne sequential composition ‘andthen’ on predicates (on the same object)
as:
p & q = q ◦asrtp,
(68)
see Lemma 57 (7). Moreover, we can deﬁne conditional states ω|p in a quantum
context as normalisation of asrtp ◦ω, like in Example 58, if we additionally
assume normalisation in a telos.
Postulate 104. Each assert map in a telos has a total kernel map — that is,
a kernel map which is total — written as:
{X|p⊥} /
πp⊥
total
/ X
asrtp
)
0
5 X
The comprehension notation is deliberate, since this kernel map πp⊥is a compre-
hension map (for p⊥), as in Deﬁnition 76 (2): let f : Y →X satisfy f ✷(p⊥) = 1.
Then:
0 = f ✷(p⊥)⊥= p ◦f = ker⊥(asrtp) ◦f = 1 ◦asrtp ◦f.
But then asrtp ◦f = 0, by Lemma 7, so that f factors through the kernel map
πp⊥.
Notice that the assert maps are structure, but their kernel maps are deter-
mined up to isomorphism, since they form comprehension maps and thus a right
adjoint to the truth functor.
134

Postulate 105. Postulate 102 (2) tells that im(asrtp) = ⌈p⌉. In particular,
asrt✷
p (⌈p⌉) = 1, so that we obtain a factorisation:
{X|⌈p⌉}
 π⌈p⌉

X
ξp⊥
3
asrtp
/ X
using that the kernel maps π are comprehension maps, see Postulate 104. Then,
using Lemma 39 (7),
ker(ξp⊥) = ker(π⌈p⌉◦ξp⊥) = ker(asrtp) = p⊥.
We postulate that in a telos these maps ξp are universal, forming quotients.
In this way the equation X/p⊥= {X|⌈p⌉} that we discussed in the beginning
of this section is built in. Moreover, if p is sharp, then ⌈p⌉= p, so that we have
an equality X/p⊥= {X|p}, as in Deﬁnition 91. Below, in Proposition 106 (6) it
is shown that this means that the canonical map θp from (57) is an isomorphism.
Hence the properties of Lemmas 93 and 94 hold in a telos.
Since the ξ’s are quotient maps and im(asrtp) = ⌈p⌉we have a coequaliser
(cokernel map) diagram by Lemma 83 (14):
X
asrtp )
0
6 X
ξ⌈p⌉/ / X/⌈p⌉
This concludes our description of the notion of telos. We continue with some
basic properties that hold in a telos about the assert maps and the ‘andthen’
operator p & q, written as p ◦q in [GG02], and as [p?](q) in [Jac15a]. Below
we prove the ﬁrst three of the ﬁve requirements for andthen in [GG02, §§3], see
points (2) and (3) below. We also prove that sharpness is related to idempotency
of &, like in C∗-algebras.
Proposition 106. Let C be a telos, that is, C is an eﬀectus in partial form,
satisfying the postulates 102 – 105. Then the following properties hold.
1. The assert maps satisfy asrt1 = id : X →X and asrt0 = 0: X →X for
the truth and falsity predicates 1, 0 on X; moreover, asrts = s: I →I for
each scalar s.
2. For each predicate p on X ∈C we have a map of eﬀect algebras:
Pred(X)
p&(−)
/ ↓p
As a result, p & q ≤p. Moreover, by point (1):
1 & p = p = p & 1
and
0 & p = 0 = p & 0.
3. If p & q = 0, then p & q = q & p.
4. For a predicate p ∈Pred(X) the following side-eﬀect freeness formulations
are equivalent.
135

(a) asrtp ≤id;
(b) asrtp⊥≤id;
(c) ∇◦instrp = id.
5. There are equivalences:
p is sharp ⇐⇒p & p = p.
6. For a sharp predicate p, the map θp = ξp⊥◦πp : {X|p} →X/p⊥from (57)
is the identity. In particular, a telos has both comprehension and quotients
as in Deﬁnition 91.
7. For each predicate p the image of the comprehension map πp is given by
im(πp) = ⌊p⌋. Further, for sharp predicates p, q on the same object we
have p ≤q iﬀπp ≤πq, like in (61). Hence Proposition 95 applies in a
telos.
Proof We must be careful not to assume more about the assert maps than is
postulated above.
1. We use Postulate 102 (3) each time. First, the identity map id : X →X
evidently satisﬁes id ≤id, so that id = asrt1◦id = asrt1.
Similarly,
0 ≤id, so that 0 = asrt1◦0 = asrt0. Further, we have id = 1: I →I, see
Lemma 52 (2). Hence every scalar s: I →I satisﬁes s ≤1 = id, and thus
s = asrt1◦s = asrtid◦s = asrts.
2. By Proposition 13 (2) we have:
p & (q1 > q2) = (q1 > q2) ◦asrtp
= (q1 ◦asrtp) > (q2 ◦asrtp) = (p & q1) > (p & q2).
As a result, p & (−) is monotone, and in particular p & q ≤p. Since p &
1 = p we obtain that p & (−) is a map of eﬀect algebras Pred(X) →↓p.
3. Let p & q = 0, then q ◦asrtp = p & q = 0, so that q ≤im⊥(asrtp) = ⌈p⌉⊥
by Lemma 47 (3). But then ⌈q⌉≤⌈p⌉⊥, since ⌈p⌉⊥is sharp, and thus
p ≤⌈p⌉≤⌈q⌉⊥= im⊥(asrtq). Hence, again by Lemma 47 (3), q & p =
p ◦asrtq = 0 = p & q.
4. For the implication (4a) ⇒(4b), let asrtp ≤id. Then there is a map
f : X →X with asrtp > f = id. This f then also satisﬁes f ≤id, so that
f = asrtq for q = ker⊥(f) by Postulate 102 (3). We have:
1 = ker⊥(id) = ker⊥(asrtp > f) = ker⊥(asrtp) > ker⊥(f) = p > ker⊥(f).
Hence p⊥= ker⊥(f) = q. But then asrtp⊥= asrtq = f ≤id.
For the implication (4b) ⇒(4c) we assume asrtp⊥≤id. By reasoning as
before, we get asrtp⊥> f = id for f = asrtp ≤id. Hence asrtp > asrtp⊥=
id, so that we are done as in the proof of Lemma 57 (6).
136

Finally, for (4c) ⇒(4a), assume an equality of total maps ∇◦instrp =
id : X →X. Then:
asrtp > asrtp⊥
= (∇◦κ1 ◦asrtp) > (∇◦κ2 ◦asrtp⊥)
= ∇◦
 (κ1 ◦asrtp) > (κ2 ◦asrtp⊥)

(27)
= ∇◦⟨⟨asrtp, asrtp⊥⟩⟩
= ∇◦instrp
= id.
Hence asrtp ≤asrtp > asrtp⊥= id.
5. We use equivalences:
p is sharp ⇐⇒im(asrtp) = ⌈p⌉≤p
⇐⇒p⊥≤im⊥(asrtp)
⇐⇒p & p⊥= p⊥◦asrtp = 0
by Lemma 47 (3)
(∗)
⇐⇒(p & p)⊥= 0 in ↓p
⇐⇒p & p = p.
The marked equivalence uses that p & (−) is a map of eﬀect algebras
Pred(X) →↓p, see point (2). Hence it preserves orthosupplements.
6. Let p be a sharp predicate.
Then p & p = p by point (5), and thus
asrtp ◦asrtp = asrtp&p = asrtp by Postulate 102 (6). Using that p = ⌈p⌉,
this last equation yields:
πp ◦ξp⊥◦πp ◦ξp⊥= asrtp ◦asrtp = asrtp = πp ◦ξp⊥.
But then θp = ξp⊥◦πp = id, since πp is monic, and ξp⊥is epic.
7. For an arbitrary predicate p we have im(π⌈p⌉) = im(π⌈p⌉◦ξp⊥) = im(asrtp) =
⌈p⌉, since ξp⊥is externally, and thus internally, epic. In particular, im(πq) =
q if q is sharp.
We always have im(πp) ≤p by minimality of images. We show that im(πp)
is the greatest sharp predicate below p. If q is sharp, and q ≤p, then there
is a (total) map f : {X|q} →{X|p} with πp ◦f = πq. But then we are
done: q = im(πq) ≤im(πp), where the inequality follows from minimality
of images, and:
π✷
q
 im(πp)

= π∗
q
 im(πp)

= f ∗π∗
p
 im(πp)

= f ∗(1) = 1.
Next we prove the equivalence p ≤q ⇐⇒πp ≤πq for sharp predicates
p, q on the same object. The direction (⇒) always holds. For (⇐) we use
p = im(πp) ≤im(πq) = q.
□
Remark 107. Let us try to ﬁnd out in which sense assert maps satisfying the
above postulates are uniquely determined. To this end, assume we have two
sets of assert maps, written as asrtp and asrt′
p.
137

They both have kernel maps like in Postulate 104, written as:
{X|p⊥} /
πp⊥/ X
asrtp )
0
6 X
{X|p⊥}′ /
π′
p⊥/ X
asrt′
p )
0
6 X
In Postulate 104 we have seen that the kernel maps form comprehension maps,
and are thus determined up-to-isomorphism. This means that for each predicate
p there is a (total) isomorphism ϕp in a commuting triangle:
{X|p}!
πp
!❈
❈
❈
❈
❈
ϕp
∼
=
/ {X|p}′
}
π′
p
}③③③③③
X
By factoring like in Postulate 105, we obtain two maps ξp⊥and ξ′
p⊥in:
{X|⌈p⌉}
w
π⌈p⌉
w♦♦♦♦♦♦♦♦♦
∼
=
ϕ⌈p⌉

∼
=
ψp
y
X
ξp⊥
0 0
asrtp
,
ξ′
p⊥
. .
asrt′
p
1 X
{X|⌈p⌉}′
g
π′
⌈p⌉
g❖❖❖❖❖❖❖❖❖
Since both ξ and ξ′ are universal quotient maps, there is a second isomorphism,
written as ψp, with ψp◦ξp⊥= ξ′
p⊥. The endo map ϕ−1
⌈p⌉◦ψp : {X|⌈p⌉} →{X|⌈p⌉}
satisﬁes:
π⌈p⌉◦
 ϕ−1
⌈p⌉◦ψp

◦ξp⊥= π′
⌈p⌉◦ξ′
p⊥= asrt′
p.
15.1
Uniqueness of assert maps, in von Neumann algebras
We have deﬁned a telos to be a special type of eﬀectus (Postulate 101) endowed
with a family of assert maps (Postulate 102) that gives us comprehension (Pos-
tulate 104) and quotients (Postulate 105). We have devoted much eﬀort to see
whether this list of postules (or any extension of it) uniquely determines the
assert maps. In this section, we will show that for the telos of von Neumann
algebras, vNAop, the assert maps are uniquely determined, and are given by
asrtp(x) = √px√p, if we add Postulate 108 to the list. Whether the assert
maps are uniquely determined by these postulates in general remains an open
problem.
We shall call a map f : X →Y a comprehension projection, of simply a
comprehension map if there is a sharp predicate q on Y with an isomorphism:
X
f ✻✻✻✻
∼{Y |q}

πq
✄✄✄
Y
Such a comprehension is automatically monic.
138

Postulate 108. Let p be any predicate on X and π: 1 ֌ X a state that is
also a comprehension map (in a telos). Then:
im(p ∗π) = ⌈p & im(π)⌉,
where p ∗π = asrtp ◦π and p & im(π) = im(π) ◦asrtp as in (68).
The substate p ∗π is an unnormalised version of the conditional state π|p of
Example 58, which makes sense even if the validity probability π |= p is zero.
If (π |= p) ̸= 0, we have
π|p ◦(π |= p) = p ∗π.
Before we come to the main result, we show that this additional postulate
holds in the telos of von Neumann algebras. In doing so we use the following
two properties. For a non-zero r ∈[0, 1],
im(r · f) = im(f)
and
⌈r · p⌉= p,
(69)
for a subunital map f and a projection p.
Example 109. The postulate 108 is true in the eﬀectus vNAop with the stan-
dard asrt-maps asrtp(x) = √p · x · √p from Example 103.
To demonstrate
this, we will ﬁrst study states that are comprehension maps. Let A be a von
Neumann algebra. We will state and prove a number of claims.
1. For a sharp predicate s on A , the mapping:
↓s
/ Pred({A |s}) = [0, 1]{A |s}
a ✤
/ π∗
s(a) = πs(a) = sas
is an order isomorphism — where the downset ↓s is a subset of Pred(A ) =
[0, 1]A . Recall that {A |s} = sA s, see Example 77 (4).
To see this, note that sas ≤s for any sas ∈[0, 1]{A |s} since s is the unit
element in {A |s} = sA s. Hence there is an inclusion-map j : [0, 1]sA s →
↓s. It is the inverse to the above map π∗
s since:
π∗
s
 j(sas)

= s(sas)s = sas
since s is a projection
j
 π∗
s(a)

= sas = a
by Lemma 99 since a ≤s.
2. A comprehension map πs : A →{A |s} for a sharp predicate s on A is a
state if and only if s is a minimal projection.
First, if πs is a state, then {A |s} ∼= C, so that by the previous point we
have an order isomorphism:
↓s ∼= Pred
 {A |s}
 ∼= Pred(C) = [0, 1].
If t ∈↓s is a projection, then it corresponds to sharp element in [0, 1]. But
there are only two sharp elements in [0, 1], namely 0 and 1, so that t = 0
or t = s. Hence s is a minimal projection.
Conversely, if s is a minimal projection, then Pred({A |s}) ∼= ↓s has only
two projections. This means that the von Neumann algebra {A |s} itself
has two projections, and is thus isomorphic two the unique von Neumann
algebra C with two projections.
139

3. Let H be any Hilbert space with element v ∈H . The projection |v⟩⟨v | ∈
B(H ) is minimal, and the corresponding state πv : B(H) →C given by
πv(t) = ⟨tv | v⟩is a comprehension map. One calls a state of this form πv
a vector state. The image in B(H ) of such a vector state πv is given by
the projection |v⟩⟨v |. Any state B(H ) →C which is a comprehension
map is of this form.
4. Any state that is a projection is of the form π: B(H ) ⊕B →C, where
π(a, b) = ⟨av | v⟩for some vector v ∈H . The image of π is then the pair
(|v⟩⟨v |, 0) ∈B(B) ⊕B.
To show this, assume π: A →C is a comprehension map for a (conse-
quently minimal) projection s. Let c(s) denote the central carrier of s that
is: c(s) ∈[0, 1]A is the least central projection above s ∈[0, 1]A . We will
show {A |c(s)} ∼= c(s)A is a (type I) factor, in which the projection c(s)s
is minimal.
Let z ≤c(s) be any central projection in c(s)A . If we can show z = 0
or z = c(s), we may conclude c(s)A is a factor. Note z is central in A
as za = zc(s)a = c(s)az = az for any a ∈A . Clearly zs is a projection
below s. Hence by minimality of s, we have zs = s or zs = 0. For the ﬁrst
case, assume zs = s. Then s ≤z by Lemma 99. Hence c(s) ≤z ≤c(s).
Thus z = c(s), as desired. Now, we cover the other case zs = 0. That
is: zs⊥= z. Hence z ≤s⊥by Lemma 99. So s ≤z⊥. Hence c(s) ≤z⊥.
Thus z ≤c(s)⊥and z ≤c(s). Consequently z = 0.
A fundamental result says that each such (type I) factor is given by
bounded operators on a Hilbert space, see e.g. [Top71, Corrolary 10].
Thus, let c(s)A ∼= B(H ) for some Hilbert space H . Consequently, there
is an isomorphism ϑ: A →B(H ) ⊕c(s)⊥A such that π = π′ ◦π1 ◦ϑ,
where π′ : B(H ) →C is a comprehension map for the minimal projection
corresponding to c(s)s and hence a vector state.
5. We will now show that the additional postulate 108 holds in the te-
los vNAop for the canonical asrt-maps from Example 103. Let π be a state
that is also a comprehension map. With the previous in mind, we may
assume without loss of generality that π is of the form π: B(H )⊕B →C
with π(a, b) = ⟨av | v⟩for some v ∈H . Let e = (e1, e2) and d = (d1, d2)
be arbitrary eﬀects on B(H ) ⊕B. Note that:
(e ∗π)(d) = π
 asrte(d)

= π
 √e1d1√e1, √e2d2√e2

= ⟨√e1d1√e1 v | v⟩
= ⟨d1√e1 v | √e1 v⟩.
Suppose √e1v = 0. Then (e ∗π)(d) = ⟨d1√e1v | √e1v⟩= 0, so that im(e ∗
π) = 0. Also ⌈e & im(π)⌉= 0 since:
e & im(π) = e & (|v⟩⟨v |, 0)
see point (4)
= asrte(|v⟩⟨v |, 0)
= (|√e1v⟩⟨v√e1 |, √e20√e2)
= 0.
140

For the other case, assume √e1v ̸= 0. Then, using what we have seen
above:
(e ∗π)(d) = ⟨d1√e1v | √e1v⟩= ∥√e1v∥2⟨d1
√e1v
∥√e1v∥|
√e1v
∥√e1v∥⟩.
This means e ∗π is a scaled vector state with:
im(e ∗π) = (|
√e1v
∥√e1v∥⟩⟨
√e1v
∥√e1v∥|, 0)
by (69) and point (4)
=
1
∥√e1v∥2 (|√e1v⟩⟨√e1v |, 0)
= ⌈(|√e1v⟩⟨√e1v |, 0) ⌉
by (69)
= ⌈e & im(π)⌉.
Hence, in both cases im(e ∗π) = ⌈e & im(π)⌉, as desired.
Now we are ready to show there is only one choice of assert maps in vNAop
that satisﬁes all the postulates — including 108. The result is a reformulation
of a result from [WW15], which in turn is inspired by the characterization of the
sequential product in Hilbert spaces by Gudder and Latr´emoli`ere, see [GL08].
Our Postulate 108 should be compared with their Condition 1.
Theorem 110. For each von Neumann algebra A and p ∈[0, 1]A , let
asrtp : A −→A
be a completely positive normal subunital map. Assume that these assert maps
on vNAop satisfy Postulate 101, 102, 104, 105, and 108.
Then for every von Neumann algebra A , predicate p ∈[0, 1]A , and x ∈A ,
asrtp(x) = √p x √p.
(70)
Proof Let H be a Hilbert space. We will ﬁrst show that Equation (70) holds
for A = B(H ). Let p ∈[0, 1]B(H ) be given.
By the discussion in Remark 107 we already have the following connection
between the canonical assert map a 7→√pa√p and the one, asrtp, we are given:
there is an automorphism ϑ on ⌈p⌉B(H )⌈p⌉such that, for all a ∈B(H ),
asrtp(a) = √p ϑ( ⌈p⌉a⌈p⌉) √p.
Since ⌈p⌉B(H )⌈p⌉is a type I factor (i.e. isomorphic to a B(K )), it is known
(see Theorem 3 of [Kap52]) that ϑ must be what is called an inner automor-
phism, that is, there is an unitary u ∈⌈p⌉B(H )⌈p⌉such that, ϑ(a) = u∗au
for all a ∈⌈p⌉B(H )⌈p⌉. Note that ⌈p⌉u = u since u ∈⌈p⌉B(H )⌈p⌉, and thus
we have, for all a ∈B(H ),
asrtp(a) = √p u∗a u √p.
Of course, our ultimate goal should be to show that u = 1, or at least that
u = λ · 1 for some λ ∈C with |λ| = 1. Our ﬁrst step is to prove up = pu.
To this end, we extract some information about u from Postulate 108.
Let x ∈H with ∥x∥= 1 be given. Let π: B(H ) →C be given by π(a) =
141

⟨x | ax⟩for a ∈B(H ). Then by Example 109 we know that π is a comprehen-
sion. Thus, by Postulate 108, we know that, in vNAop,
im(asrtp ◦π) = ⌈p & im(π)⌉.
(71)
Before we continue, observe that for y ∈H with ∥y∥≤1 we have
⌈|y⟩⟨y | ⌉= im( ⟨y | (−) y⟩) ) = ( projection onto yC ≡{λy: λ ∈C} ).
Now, let us unfold Equation (71).
( projection onto (√pu∗x)C ) = ⌈| √pu∗x ⟩⟨√pu∗x | ⌉
= ⌈√pu∗|x⟩⟨x | u√p ⌉
= ⌈p & im(π) ⌉
= im(asrtp ◦π)
= im( ⟨x | √pu∗(−)u√px ⟩)
= im( ⟨u√px | (−) u√px ⟩)
= ( projection onto (u√px)C )
Hence, for every x ∈H with ∥x∥= 1 there is α ∈C with α ̸= 0 such that
√pu∗x = α · u√px.
By scaling it is clear that this statement is also true for all x ∈H (and not just
for x ∈H with ∥x∥= 1). While a priori α might depend on x, we will show
that there is α ∈C\{0} such that √pu∗= α · u√p.
First note that √pu∗x = 0 iﬀu√px = 0 for all x ∈H . Thus we may
factor √pu∗and u√p through the quotient map q: H →H /K, where
K = {x ∈H : √pu∗x = 0} = {x ∈H : u√px = 0}.
(Here H /K is just the quotient of H as vector space.) Let t, s: H /K →H
be given by s ◦q = √pu∗and t ◦q = u√p. Then s and t are injective, and
writing V = H /K, it is not hard to see that for every x ∈V there is α ∈C\{0}
with s(x) = α · t(x).
We will show that there is α ∈C\{0} with s = α · t. If V = {0} then this is
clear, so assume that V ̸= {0}. Pick x ∈V with x ̸= 0, and let α ∈C\{0} be
such that s(x) = α·t(x). Let y ∈V be given; we must show that s(y) = α·t(y).
Now, either t(x) and t(y) are linearly independent or not.
Suppose that t(x) and t(y) are linearly independent. Let β, γ ∈C\{0} be
such that s(y) = β · t(y) and s(x + y) = γ · t(x + y). Then
(γ −α) · t(x) + (γ −β) · t(y) = 0.
Thus, as t(x) and t(y) are linearly independent, γ −α = 0 and γ −β = 0, and
so α = β. Hence s(y) = α · t(y).
Suppose that t(x) and t(y) are linearly dependent. Since x ̸= 0, we have
t(x) ̸= 0—as t is injective—, and thus t(y) = ̺t(x) for some ̺ ∈C. Then
t(y −̺x) = 0, and so y = ̺x since t is injective. Then
s(y) = ̺s(x) = ̺αt(x) = αt(y).
142

Thus, in any case, s(y) = αt(y). Hence s = α · t. Thus √pu∗= α · u√p.
It follows that p = √pu∗u√p = α · u√pu√p = u√p√pu∗= upu∗, and so
pu = up. Then also √pu = u√p. Thus √pu∗= αu√p = α√pu.
Now, note that (√pu∗)∗= u√p, and so u√p = α∗√pu∗= α∗αu√p. Then
if u√p ̸= 0 we get α∗α = 1, and if u√p then we can put α = 1 and still have
both √pu∗= αu√p and α∗α = 1.
It follows that, for all b ∈B(H ),
√pu∗b u√p = √pu b u∗√p.
By the universal property of the quotient, we conclude that u∗(−)u = u(−)u∗,
and thus u2b = bu2 for all b ∈B(H ). Hence u2 is central in B(H ).
Since B(H ) is a factor, we get u2 = λ · 1 for some λ ∈C. Then by Postu-
late 102 (6) and using √pu = u√p, we get, for all b ∈B(H ),
p b p = √pu∗√pu∗bu√pu√p = (asrtp ◦asrtp)(b) = asrtp&p(b).
Note that p & p = asrtp(p) = √pu∗pu√p = p2. Thus, for all b ∈B(H ),
asrtp2(b) = p b p.
Since every element of [0, 1]B(H ) is a square, we have proven Equation (70)
when A ≡B(H ).
Now, let us consider the general case (so A need not be of the form B(H )).
Let ω: A →C be any normal state on A . Let a ∈A be given. As normal
states are separating, it suﬃces to prove that ω(asrtp(a)) = ω(√pa√p). Let
̺: A →B(K ) be the GNS-representation of A for the state ω with cyclic
vector x ∈K . Let π: B(K ) →C be given by π(b) = ⟨x | bx⟩for all b ∈A .
Then we have ω = π ◦̺ (in vNA). Thus:
ω(asrtp(a)) = π(̺(asrtp(a)))
= π(asrt̺(p)(̺(a)))
by Postulate 102 (7)
= π(
p
̺(p)̺(a)
p
̺(p))
by uniqueness for B(K )
= π(̺(√pa√p))
= ω(√pa√p)
Hence asrtp(a) = √pa√p. We have proven Equation (70).
□
16
Conclusions and future work
This text collects deﬁnitions and results about the new notion of eﬀectus in
categorical logic. Already at this early stage it is clear that the theory of eﬀec-
tuses includes many examples that are of interest in quantum (and probability)
theory.
But much remains to be done.
We list a few directions for further
research.
1. Which constructions exist to obtain new eﬀectuses from old, such as prod-
ucts, slices, (co)algebras of a (co)monad, etc.? A related matter is the def-
inition of an appropriate notion of morphism of eﬀectuses: one can take a
functor that preserves ﬁnite coproducts and the ﬁnal object; alternatively,
one can take adjoints as morphisms, like in geometric morphisms between
toposes.
143

2. Tensors in eﬀectuses have been discussed in Section 10, but only in a
very superﬁcial way.
They deserve more attention, leading to a closer
connection with the work done in the Oxford school (see the introduction).
For instance, the combination of tensors ⊗and coproducts + could lead
to a 3-dimensional graphical calculus that combines (parallel) composition
and eﬀect logic.
3. The approach in this text is very much logic-oriented. Connections with
quantum theory are touched upon, but should be elaborated further. In
particular, the formulation (and correctness!) of concrete quantum proto-
cols in the present setting is missing.
4. An internal language for eﬀectuses, along the lines of [Ada14, AJ15], may
be useful for the veriﬁcation of probabilistic and/or quantum protocols.
5. The possibility of doing homological algebra (in abstract form, see [Gra92,
Gra12] also deserves attention.
Acknowledgements
This document beneﬁtted from discussion with and/or feedback from: Robin
Adams, Tobias Fritz, Robert Furber, Aleks Kissinger, Mathys Rennela, Sam
Staton, Sean Tull, Sander Uijlen, and Fabio Zanasi. We like to thank them all.
144

References
[AC04]
S. Abramsky and B. Coecke. A categorical semantics of quantum
protocols.
In Logic in Computer Science, pages 415–425. IEEE,
Computer Science Press, 2004.
[Ada14]
R. Adams. QPEL: Quantum program and eﬀect language. In B. Co-
ecke, I. Hasuo, and P. Panangaden, editors, Quantum Physics and
Logic (QPL) 2014, number 172 in Elect. Proc. in Theor. Comp.
Sci., pages 133–153, 2014.
[AJ15]
R. Adams and B. Jacobs.
A type theory for probabilistic and
Bayesian reasoning. See arxiv.org/abs/1511.09230, 2015.
[AM80]
M. Arbib and E. Manes.
Partially additive categories and ﬂow-
diagram semantics. Journal of Algebra, 62(1):203–227, 1980.
[BF95]
M. Bennett and D. Foulis. Phi-symmetric eﬀect algebras. Phys.
Review Letters, 25(12):1699–1722, 1995.
[BS98]
P. Busch and J. Singh. L¨uders theorem for unsharp quantum mea-
surements. Phys. Letters A, 249:10–12, 1998.
[BW85]
M. Barr and Ch. Wells. Toposes, Triples and Theories. Springer,
Berlin, 1985. Revised and corrected version available from URL:
www.cwru.edu/artsci/math/wells/pub/ttt.html.
[CD11]
B. Coecke and R. Duncan.
Interacting quantum observables:
categorical algebra and diagrammatics.
New Journ. of Physics,
13(4):043016, 2011.
[CDP10]
G. Chiribella, G.M. D’Ariano, and P. Perinotti. Probabilistic the-
ories with puriﬁcation. Phys. Rev. A, 81:062348, 2010.
[CDP11]
G. Chiribella, G.M. D’Ariano, and P. Perinotti.
Informational
derivation of quantum theory. Phys. Rev. A, 84:012311, 2011.
[CHK14]
B. Coecke, C. Heunen, and A. Kissinger. Categories of quantum
and classical channels. Quantum Information Processing, pages 1–
31, 2014.
[Cho14]
K. Cho. Semantics for a quantum programming language by op-
erator algebras. In B. Coecke, I. Hasuo, and P. Panangaden, edi-
tors, Quantum Physics and Logic (QPL) 2014, number 172 in Elect.
Proc. in Theor. Comp. Sci., pages 165–190, 2014.
[Cho15]
K. Cho. Total and partial computation in categorical quantum foun-
dations. In C. Heunen, P. Selinger, and J. Vicary, editors, Quantum
Physics and Logic (QPL) 2015, number 195 in Elect. Proc. in Theor.
Comp. Sci., pages 116–135, 2015.
[CJ13]
D. Coumans and B. Jacobs. Scalars, monads and categories. In
C. Heunen, M. Sadrzadeh, and E. Grefenstette, editors, Quan-
tum Physics and Linguistics. A Compositional, Diagrammatic Dis-
course, pages 184–216. Oxford Univ. Press, 2013.
145

[CJWW15] K. Cho, B. Jacobs, A. Westerbaan, and B. Westerbaan. Quotient
comprehension chains. In C. Heunen, P. Selinger, and J. Vicary,
editors, Quantum Physics and Logic (QPL) 2015, number 195 in
Elect. Proc. in Theor. Comp. Sci., pages 136–147, 2015.
[CK95]
F. Chovanec and F. Kˆopka. D-lattices. Int. Journ. Theor. Physics,
34(8):1297–1302, 1995.
[CK15]
B. Coecke and A. Kissinger.
Categorical quantum mechanics I:
Causal quantum processes. http://arxiv.org/abs/1510.05468,
2015.
[CKar]
B. Coecke and A. Kissinger. Picturing Quantum Processes. A First
Course in Quantum Theory and Diagrammatic Reasoning. Cam-
bridge Univ. Press, 2016, to appear.
[CL13]
B. Coecke and R. Lal. Causal categories: Relativistically interacting
processes. Found. Physics, 43(4):458–501, 2013.
[CLW93]
A. Carboni, S. Lack, and R. Walters. Introduction to extensive and
distributive categories. Journ. of Pure & Appl. Algebra, 84(2):145–
158, 1993.
[DP00]
A. Dvureˇcenskij and S. Pulmannov´a.
New Trends in Quantum
Structures. Kluwer Acad. Publ., Dordrecht, 2000.
[FB94]
D. Foulis and M. Bennett. Eﬀect algebras and unsharp quantum
logics. Found. Physics, 24(10):1331–1352, 1994.
[FJ15]
R. Furber and B. Jacobs.
From Kleisli categories to commuta-
tive C∗-algebras: Probabilistic Gelfand duality. Logical Methods in
Comp. Sci., 11(2):1–28, 2015.
[GG94]
R. Giuntini and H. Greuling. Toward a formal language for unsharp
properties. Found. Physics, 19:769–780, 1994.
[GG02]
S. Gudder and R. Greechie. Sequential products on eﬀect algebras.
Reports on Math. Physics, 49(1):87–111, 2002.
[GL08]
S Gudder and F. Latremoliere. Characterization of the sequential
product on quantum eﬀects. arXiv preprint arXiv:0803.3867, 2008.
[Goo86]
K. Goodearl. Partially Ordered Abelian Groups with Interpolation,
volume 20 of Mathematical Surveys. Amer. Math. Soc., 1986.
[Gra92]
M. Grandis.
On the categorical foundations of homological and
homotopical algebra. Cah. de Top. et G´eom. Diﬀ. Cat´egoriques,
30:135–175, 1992.
[Gra12]
M. Grandis. Homological Algebra: The Interplay of Homology with
Distributive Lattices and Orthodox Semigroups. World Scientiﬁc,
Singapore, 2012.
[Hag00]
E. Haghverdi. Unique decomposition categories, geometry of inter-
action and combinatory logic. Math. Struct. in Comp. Sci., 10:205–
231, 2000.
146

[HJ10]
C. Heunen and B. Jacobs. Quantum logic in dagger kernel cate-
gories. Order, 27(2):177–212, 2010.
[HV15]
C. Heunen and J. Vicary.
Categories for Quantum Theory: an
Introduction, volume 17 of Oxford Graduate Texts in Math. Oxford
Univ. Press, 2015.
[HZ12]
T. Heinosaari and M. Ziman. The Mathematical Language of Quan-
tum Theory. From Uncertainty to Entanglement. Cambridge Univ.
Press, 2012.
[Jac99]
B. Jacobs. Categorical logic and type theory. North Holland, Ams-
terdam, 1999.
[Jac10a]
B. Jacobs. Convexity, duality, and eﬀects. In C. Calude and V. Sas-
sone, editors, IFIP Theoretical Computer Science 2010, number
82(1) in IFIP Adv. in Inf. and Comm. Techn., pages 1–19. Springer,
Boston, 2010.
[Jac10b]
B. Jacobs. Orthomodular lattices, Foulis semigroups and dagger
kernel categories. Logical Methods in Comp. Sci., 6(2), 2010.
[Jac13]
B. Jacobs. Measurable spaces and their eﬀect logic. In Logic in
Computer Science. IEEE, Computer Science Press, 2013.
[Jac15a]
B. Jacobs. New directions in categorical logic, for classical, proba-
bilistic and quantum logic. Logical Methods in Comp. Sci., 11(3):1–
76, 2015.
[Jac15b]
B. Jacobs.
A recipe for state and eﬀect triangles.
In L. Moss
and P. Sobocinski, editors, Conference on Algebra and Coalgebra
in Computer Science (CALCO 2015), LIPIcs, 2015.
[Jan94]
Z. Janelidze. On the form of subobjects in semi-abelian and regular
protomodular categories.
Appl. Categorical Struct., 22(5-6):755–
766, 1994.
[JM12a]
B. Jacobs and J. Mandemaker. Coreﬂections in algebraic quantum
logic. Found. of Physics, 42(7):932–958, 2012.
[JM12b]
B. Jacobs and J. Mandemaker. The expectation monad in quantum
foundations.
In B. Jacobs, P. Selinger, and B. Spitters, editors,
Quantum Physics and Logic (QPL) 2011, volume 95 of Elect. Proc.
in Theor. Comp. Sci., pages 143–182, 2012.
[Joh02]
P. Johnstone.
Sketches of an Elephant: A Topos Theory Com-
pendium. Number 44 in Oxford Logic Guides. Oxford Univ. Press,
2002. 2 volumes.
[JWW15]
B. Jacobs, B. Westerbaan, and A. Westerbaan. States of convex
sets. In A. Pitts, editor, Foundations of Software Science and Com-
putation Structures, number 9034 in Lect. Notes Comp. Sci., pages
87–101. Springer, Berlin, 2015.
147

[Kad56]
R. Kadison. Operator algebras with a faithful weakly-closed repre-
sentation. Annals of Mathematics, pages 175–181, 1956.
[Kap52]
Irving Kaplansky. Algebras of type I. Annals of Mathematics, pages
460–472, 1952.
[KL80]
M. Kelly and M. Laplaza. Coherence for compact closed categories.
Journ. of Pure & Appl. Algebra, 19:193–213, 1980.
[Koz81]
D. Kozen. Semantics of probabilistic programs. Journ. Comp. Syst.
Sci, 22(3):328–350, 1981.
[Koz85]
D. Kozen. A probabilistic PDL. Journ. Comp. Syst. Sci, 30(2):162–
178, 1985.
[KR97]
R. Kadison and J. Ringrose. Fundamentals of the theory of operator
algebras. American Mathematical Soc., 1997.
[LS13]
M. Leifer and R. Spekkens.
Towards a formulation of quantum
theory as a causally neutral theory of Bayesian inference. Phys.
Rev. A, 88(5):052130, 2013.
[MA86]
E. Manes and M. Arbib. Algebraic Approaches to Program Seman-
tics. Texts and Monogr. in Comp. Sci. Springer, Berlin, 1986.
[Mac50]
S. Mac Lane. An algebra of additive relations. Bull. Amer. Math.
Soc., 56:485–516, 1950.
[Mac71]
S. Mac Lane. Categories for the Working Mathematician. Springer,
Berlin, 1971.
[MM92]
S. Mac Lane and I. Moerdijk. Sheaves in Geometry and Logic. A
First Introduction to Topos Theory. Springer, New York, 1992.
[Nag74]
R. Nagel. Order unit and base norm spaces. In A. Hartk¨amper
and H. Neumann, editors, Foundations of Quantum Mechanics and
Ordered Linear Spaces, number 29 in Lect. Notes Physics, pages
23–29. Springer, Berlin, 1974.
[Pau02]
V. Paulsen. Completely bounded maps and operator algebras, vol-
ume 78. CUP, 2002.
[Qui67]
D. Quillen. Homotopical algebra. Number 43 in Lect. Notes Math.
Springer, Berlin, 1967.
[Ren14]
M. Rennela. Towards a quantum domain theory: Order-enrichment
and ﬁxpoints in w∗-algebras. Electronic Notes in Theoretical Com-
puter Science, 308:289–307, 2014.
[Sak71]
S. Sakai. C∗-algebras and W ∗-algebras, volume 60 of Ergebnisse der
Mathematik und ihrer Grenzgebiete. Springer, 1971.
[Sti55]
W. Stinespring. Positive functions on C∗-algebras. Proceedings of
the American Mathematical Society, 6(2):211–216, 1955.
148

[SU15]
S. Staton and S. Uijlen. Eﬀect algebras, presheaves, non-locality
and contextuality. In M. Halld´orsson, K. Iwama, N. Kobayashi,
and B. Speckmann, editors, Int. Coll. on Automata, Languages and
Programming, number 9135 in Lect. Notes Comp. Sci., pages 401–
413. Springer, Berlin, 2015.
[Tak01]
M. Takesaki. Theory of Operator Algebras I, volume 124 of Ency-
clopedia of Mathematical Sciences. Springer, 2nd edition, 2001.
[Tom57]
J. Tomiyama. On the projection of norm one in W ∗-algebras. Pro-
ceedings of the Japan Academy, 33(10):608–612, 1957.
[Top71]
D. Topping.
Lectures on von Neumann algebras.
Van Nostrand
Reinhold, 1971.
[Tul16]
S. Tull. Operational theories of physics as categories. forthcoming,
2016.
[Wei14]
T. Weighill. Biﬁbrational duality in non-abelian algebra and the
theory of databases. MSc Thesis, 2014.
[Wes13]
B. Westerbaan.
Sequential product on eﬀect logics.
Mas-
ter’s thesis,
Radboud Univ. Nijmegen,
2013.
Available at
http://westerbaan.name/~bas/math/master.pdf.
[Wil12]
A. Wilce. Symmetry and self-duality in categories of probabilistic
models. In B. Jacobs, P. Selinger, and B. Spitters, editors, Quantum
Physics and Logic (QPL) 2011, volume 95 of Elect. Proc. in Theor.
Comp. Sci., pages 275–279, 2012.
[WW15]
B.
Westerbaan
and
A.
Westerbaan.
A
universal
prop-
erty
of
sequential
measurement.
Preprint
available
at
http://westerbaan.name/~bas/math/univ-prop-seq-prod.pdf,
2015.
149

Notation Index
[f, g], cotuple of maps f, g, 7
B(H ), space of operators on a Hilbert
space H , 40
End(X), homset of partial maps X →
X, 65
···
··✎✎, 11
Pred(X), collection of predicates on
an object X, 11
SStat(X), collection of substates of
an object X, 11
ShaPred(X), collection of sharp pred-
icates on an object X, 121
Stat(X), collection of states of an
object X, 11
···
··✴✴✎✎✎✎, 11
asrtp, assert map for predicate p
in a commutative eﬀectus, 66
in a monoidal eﬀectus with copiers,
80
asrtp, assert map for predicate p
in a telos, 133
when p is sharp, 115
!, unique map from an initial, or to
a ﬁnal, object, 8
{X|p}, comprehension of predicate
p on X, 84
⟨⟨f, g⟩⟩, partial pairing of f, g, 16
, ground map, 41
im(f), image of a map f, 54
im⊥(f), image-supplement of a map
f, 54
instrp, instrument map for predicate
p, 68, 134
κi, i-th coprojection, 7
ker(f), kernel of a map f, 46
ker⊥(f), kernel-supplement of a map
f, 47
|x⟩, element x as part of a formal
sum, 18
‹h› = κ1 ◦h, embedding into Kleisli
category of the lift monad,
8
|=, validity given by the Born rule,
38
∇= [id, id], codiagonal, 8
ω|p, conditional state, 71
1,
truth predicate, 10
truth functor, 82
⊥, orthogonality, 26
>, partial sum, 26
, composition in the Kleisli cate-
gory of the lift monad, 7
πi, i-th projection in a monoidal ef-
fectus, 76
+ sum of partial maps, 9
→, partial map, 7
✄i, i-th partial projection, 9
End≤id(X), set of partial maps X →
X below the identity, 66
, composition, 7
+, sum of total maps, 7
tr, trace operation, 40
→, total map, 7
0,
falsity functor, 82
falsity predicate, 10
zero map, 8
p & q, sequential composition of pred-
icates p, q, 66
p⊥, orthosupplement of predicate p,
10
x⊥, orthosupplement in an eﬀect al-
gebra, 29
Ab, category of Abelian groups, 20
BA, category of Boolean algebras,
74
Caus(A), category of causal maps,
41
ConvM, category of convex sets over
an eﬀect monoid M, 36
CvNA, category of commutative von
Neumann algebras, 23
EA, category of eﬀect algebras, 29
EModM, category of eﬀect mod-
ules over an eﬀect monoid
M, 32
Kℓ(−), Kleisli category, 19
OAb, category of ordered Abelian
groups, 20
OUG, category of order unit groups,
20
150

OUS, category of order unit spaces,
21
PCM, category of partial commu-
tative monoids, 26
Pred✷(C), category of predicates in
an eﬀectus in partial form
C, 83
Par(B) Kleisli category of the lift
monad on B, 8
Pred(B) category of predicates in
an eﬀectus in total form B,
82
Sets, category of sets, 18
Tot(C), category of total maps in a
FinPAC with eﬀects C, 60
vNA, category of von Neumann al-
gebras, 21
copier, 80
D, distribution monad, 18
G, Giry monad, 19
M, multiset monad, 43
D≤1, subdistribution monad, 19
semicartesian, 76
g✷, modal predicate transformer for
partial map g, 10
g✸, modal predicate transformer for
partial map g, 10
f ∗, substitution predicate transformer
for total map f, 10
f∗, state transformer associated with
total map f, 37
151

Subject Index
W ∗-algebra, 22
Abelian
– group, 20
– category, 126
aﬃne function, 36
Bayes’ rule, 71
biproduct, 41
– category, 41
grounded – category, 41
Boolean
– eﬀectus, 66
– algebra, 29, 73
Born rule, 38
bound, 27
C∗-algebra, 22
cancellation, 29, 51
category
biproduct –, 41
extensive –, 107
ﬁnitely additive –, 58
grounded biproduct –, 41
causal map, 41
cokernel
– map, 46
– in an eﬀectus, 101
– predicate, 46
commutative
– eﬀectus, 66
– von Neumann algebra, 23
completely positive map, 23
comprehension, 84
conditional state, 71
convex
– combination, 18
– set, 36
dinaturality, 51
distribution
– monad, 18
discrete probability –, 19
eﬀect
– monoid, 31
– algebra, 29
– module, 32
eﬀectus, 11
– with comprehension, 84
– in partial form, 64
– in total form, 64
– with quotients, 96
– with both quotients and com-
prehension, 115
Boolean –, 66
commutative –, 66
monoidal –, 75
extensive category, 107
factorisation system
– via comprehension maps, 121
– via quotient maps, 105
ﬁnitely additive category, 58
FinPAC, see ﬁnitely additive cate-
gory
– with eﬀects, 60
fuzzy predicate, 19
Giry monad, 19
ground map, 41
grounded biproduct category, 41
group
Abelian –, 20
order unit –, 20
image, 54
sharp –, 54
internal
– mono, 47
– epi, 54
involutive map, 22
kernel, 46
– predicate, 46
– map, 46
– in an eﬀectus, 94
monad
distribution –, 18
Giry –, 19
subdistribution –, 19
monoid
eﬀect –, 31
152

partial commutative –, 26
monoidal eﬀectus, 75
multiplicative map, 22
normal map, 23
normalisation, 40, 51, 71
order unit
– group, 20
– space, 21
orthomodular lattice, 121
partial
– map, 8
– pairing, 16
– projection, 9
PCM, see partial commutative monoid
positive
– element, 22
– map, 20
– sum, 29, 51
completely –, 23
positive map between von Neumann
algebras, 22
predicate
– functor, 33
– in an eﬀectus, 11
fuzzy –, 19
PsU, positive subunital, 21
PU, positive unital, 20
pullback lemma, 12
pure state, 35
– of a qubit, 23
qubit, 23
quotients, 96
re-indexing, 10
scalar multiplication
– in an eﬀect module, 32
– on homsets, in presence of ten-
sor, 79
– on substates, 35
self-adjoint, 22
sharp
– element of an eﬀect algebra,
53
– predicate
– on a qubit, 23
– on a von Neumann algebra,
86
collection of –, 121
side-eﬀect free map, 66
state
– functor, 37
– in an eﬀectus, 11
conditional –, 71
pure –, 35
— of a qubit, 23
state and eﬀect triangle, 38
strict initial object, 14
subconvex combination, 19
subdistribution monad, 19
substate in an eﬀectus, 11
substitution, 10
subunital map
– between von Neumann alge-
bras, 22
– in an order unit group, 21
telos, 130
total map
– in a FinPAC with eﬀects, 60
– in a category of partial maps,
8
ultraweak
– continuity, 25
– convergence, 25
– topology, 25
unital map
– between von Neumann alge-
bras, 22
– in an order unit group, 20
von Neumann algebra, 22
commutative –, 23
153

